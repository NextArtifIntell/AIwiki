<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NEUCOM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="neucom---1433">NEUCOM - 1433</h2>
<ul>
<li><details>
<summary>
(2022). Output synchronization of reaction–diffusion neural networks
under random packet losses via event-triggered sampled–data control.
<em>NEUCOM</em>, <em>514</em>, 563–573. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For space-varying reaction–diffusion neural networks (RDNNs), this article mainly studies the output synchronization via an event-triggered sampled-data (ETSD) control under spatially point measurements (SPMs) with random packet losses. To reduce the communication burden, an ETSD control scheme is adopted to decrease the unnecessary SD and the update frequency of the controller. Meanwhile, the problem of random packet losses in the communication channels from controller to actuator is considered. Some synchronization criteria based on spatial linear matrix inequalities (SLMIs) are established through an ETSD controller under SPMs with random packet losses to guarantee the mean square exponential stability of synchronization error system with drive and response dynamics via utilizing inequality techniques and Lyapunov functional. Furthermore, we express SLMIs as LMIs for solving the ETSD control design problem for output synchronization of space-varying RDNNs. Finally, the effectiveness of the proposed method is demonstrated by one numerical example.},
  archive      = {J_NEUCOM},
  author       = {Feng-Liang Zhao and Zi-Peng Wang and Huai-Ning Wu and Jin-Liang Wang and Tingwen Huang and Fellow, IEEE},
  doi          = {10.1016/j.neucom.2022.09.105},
  journal      = {Neurocomputing},
  pages        = {563-573},
  shortjournal = {Neurocomputing},
  title        = {Output synchronization of reaction–diffusion neural networks under random packet losses via event-triggered sampled–data control},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). UniInst: Unique representation for end-to-end instance
segmentation. <em>NEUCOM</em>, <em>514</em>, 551–562. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing instance segmentation methods have achieved impressive performance but still suffer from a common dilemma: redundant representations (e.g., multiple boxes, grids, and anchor points) are inferred for one instance, which leads to multiple duplicated predictions. Thus, mainstream methods usually rely on a hand-designed non-maximum suppression (NMS) post-processing step to select the optimal prediction result, consequently hindering end-to-end training. To address this issue, we propose a box-free and NMS-free end-to-end instance segmentation framework, dubbed UniInst , which yields only one unique representation for each instance. Specifically, we design an instance-aware one-to-one assignment scheme, named O nly Y ield O ne R epresentation ( OYOR ). It dynamically assigns one unique representation to each instance according to the matching quality between predictions and ground truths. Then, a novel prediction re-ranking strategy is elegantly integrated into the framework to address the misalignment between the classification score and mask quality, enabling the learned representation to be more discriminative. With these techniques, our UniInst, the first FCN-based box-free and NMS-free end-to-end instance segmentation framework, achieves competitive performance, e.g., 39.0 mask AP using ResNet-50-FPN and 40.2 mask AP using ResNet-101-FPN on COCO test-dev . Moreover, the proposed instance-aware method is robust to occlusion scenes because of non-dependent on box and NMS. It outperforms common baselines by remarkable mask AP on the heavily-occluded OCHuman benchmark. Code is available at https://github.com/b03505036/UniInst.},
  archive      = {J_NEUCOM},
  author       = {Yimin Ou and Rui Yang and Lufan Ma and Yong Liu and Jiangpeng Yan and Shang Xu and Chengjie Wang and Xiu Li},
  doi          = {10.1016/j.neucom.2022.09.112},
  journal      = {Neurocomputing},
  pages        = {551-562},
  shortjournal = {Neurocomputing},
  title        = {UniInst: Unique representation for end-to-end instance segmentation},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural architectures for aggregating sequence labels from
multiple annotators. <em>NEUCOM</em>, <em>514</em>, 539–550. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Labelled data for training sequence labelling models can be collected from multiple annotators or workers in crowdsourcing. However, these labels could be noisy because of the varying expertise and reliability of annotators. In order to ensure high quality of data, it is crucial to infer the correct labels by aggregating noisy labels. Although label aggregation is a well-studied topic, only a number of studies have investigated how to aggregate sequence labels. Recently, neural network models have attracted research attention for this task. In this paper, we explore two neural network-based methods. The first method combines Hidden Markov Models with networks while also learning distributed representations of annotators (i.e., annotator embedding); the second method combines BiLSTM with autoencoders. The experimental results on three real-world datasets demonstrate the effectiveness of using neural networks for sequence label aggregation. Moreover, our analysis shows that annotators’ embeddings not only make our model applicable to real-time applications, but also useful for studying the behaviour of annotators.},
  archive      = {J_NEUCOM},
  author       = {Maolin Li and Sophia Ananiadou},
  doi          = {10.1016/j.neucom.2022.09.081},
  journal      = {Neurocomputing},
  pages        = {539-550},
  shortjournal = {Neurocomputing},
  title        = {Neural architectures for aggregating sequence labels from multiple annotators},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anchor-based incomplete multi-view spectral clustering.
<em>NEUCOM</em>, <em>514</em>, 526–538. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past decade, multi-view clustering has become a research hot spot of machine learning . In traditional multi-view clustering methods , all views of the data points are assumed to be complete. However, in the practical applications, some views of data points may be missing and incomplete multi-view clustering methods are developed to handle these incomplete multi-view data. The existing incomplete multi-view clustering methods still have some defects such as insufficient use of missing information or neglecting the underlying relations among different views. To address these limitations, we propose an Anchor-based Incomplete Multi-view Spectral Clustering (AIMSC) approach. Specifically, AIMSC utilizes anchor points to connect all instances of each view and recover the missing information. Then, the similarities between all data points are derived from the similarities between data points and anchor points. Finally, anchor-based spectral clustering is executed to generate the clustering results . Experimental results on multiple benchmark datasets demonstrate the superiority of AIMSC.},
  archive      = {J_NEUCOM},
  author       = {Jun Yin and Runcheng Cai and Shiliang Sun},
  doi          = {10.1016/j.neucom.2022.09.142},
  journal      = {Neurocomputing},
  pages        = {526-538},
  shortjournal = {Neurocomputing},
  title        = {Anchor-based incomplete multi-view spectral clustering},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Relay knowledge distillation for efficiently boosting the
performance of shallow networks. <em>NEUCOM</em>, <em>514</em>, 512–525.
(<a href="https://doi.org/10.1016/j.neucom.2022.09.143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce the computational consumption and memory footprint of powerful deep neural networks for applications on edge devices, many model compression methods have been proposed. Among them, knowledge distillation , a topic that has been widely studied, aims at training a lightweight and powerful student network under the guidance of a well-trained but cumbersome teacher network. Most existing knowledge distillation methods focus on how to better define knowledge and the student is forced to mimic the representation space of the teacher, ignoring leveraging the powerful teacher architecture to improve the student intermediate representations for approaching the proficient performance of the teacher. Since the teacher naturally has more powerful feature extraction ability and is always available at the training process of the student, we introduce Relay Knowledge Distillation (ReKD) for efficiently boosting the student performance. Concretely, ReKD transfers the student intermediate representations to the teacher, making the student trained with the teacher in an interactive manner. By directly utilizing the teacher powerful feature extraction ability to improve the student intermediate representations, the knowledge of the teacher is implicitly distilled to the student. Extensive experiments on diverse image classification datasets demonstrate the proposed ReKD can significantly improve the student performance, even making it possible for the student to outperform the teacher.},
  archive      = {J_NEUCOM},
  author       = {Shipeng Fu and Zhibing Lai and Yulun Zhang and Yiguang Liu and Xiaomin Yang},
  doi          = {10.1016/j.neucom.2022.09.143},
  journal      = {Neurocomputing},
  pages        = {512-525},
  shortjournal = {Neurocomputing},
  title        = {Relay knowledge distillation for efficiently boosting the performance of shallow networks},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pth moment synchronization of stochastic impulsive neural
networks with time-varying coefficients and unbounded delays.
<em>NEUCOM</em>, <em>514</em>, 500–511. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is devoted to the investigation of the p p th moment synchronization problem for stochastic impulsive neural networks (SINNs) with time-varying coefficients and unbounded delays. First of all, one novel impulse generation rule is proposed, which generates the more general impulsive sequences. In order to cope with time-varying coefficients, unbounded delays and impulsive disturbances, some impulsive differential inequalities are developed by utilizing the comparison principle. With the help of the established impulsive inequalities, the synchronization of SINNs is analyzed in detail, and both p p th moment exponential synchronization and asymptotical synchronization are realized by designing appropriate feedback controllers . Finally, several simulation examples are provided to illustrate the validity of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Chi Zhao and Yinfang Song and Yurong Liu and Fawaz E. Alsaadi},
  doi          = {10.1016/j.neucom.2022.10.010},
  journal      = {Neurocomputing},
  pages        = {500-511},
  shortjournal = {Neurocomputing},
  title        = {Pth moment synchronization of stochastic impulsive neural networks with time-varying coefficients and unbounded delays},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-level object detection by multi-sensor perception of
traffic scenes. <em>NEUCOM</em>, <em>514</em>, 486–499. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is a hot research topic in the communities of computer vision and intelligent transportation system. In this paper, we propose a novel framework for multi-level object detection by mutli-sensor perception from road scenes. Firstly, two types of 2D object detection methods are proposed based on multi-level feature processing. Among them, an improved 2D object detection method is designed based on CenterNet, which introduces a centripetal offset module and a deformable convolution module to improve the corner matching accuracy and solve the problem of missed detection. Moreover, an improved 2D object detection method based on RetinaNet is designed by the optimization of the sub-network of ResNet. The coordinate attention mechanism and bidirectional feature fusion mechanism are incorporated. Finally, we propose a 3D object detection method based on an improved PointNet network. The point cloud data are projected into a frustum according to the 2D detection result, then the frustum is segmented according to the linearly increased steps. The experimental results on the KITTI dataset and TSD-max dataset well demonstrate the effectiveness of the proposed framework.},
  archive      = {J_NEUCOM},
  author       = {Sheng Yuan and Qi Zhang and Li Zhu and Su Wang and Yujie Zang and Xi Zhao},
  doi          = {10.1016/j.neucom.2022.09.020},
  journal      = {Neurocomputing},
  pages        = {486-499},
  shortjournal = {Neurocomputing},
  title        = {Multi-level object detection by multi-sensor perception of traffic scenes},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). KAConv: Kernel attention convolutions. <em>NEUCOM</em>,
<em>514</em>, 477–485. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the previous network optimization works applied attention mechanism to feature maps, but neglected to embed attention into convolution kernel of the end-to-end network that is convenient to deploy. To address this issue, we present a novel attention convolution method named Kernel Attention Convolution (KAConv) to enhance the flexibility of convolution. The proposed KAConv generates different attention weights for different spatial positions of convolution kernels based on the input features, so as to dynamically adjust the parameters of convolution kernels during the forward propagation to enhance the flexibility of convolution. We decompose the convolution kernels into subkernels spatially, and generate the corresponding feature maps through which attention weights are obtained. The final refined feature maps are aggregated by the attention weighted feature maps corresponding to each subkernel. KAConv is a computationally lightweight convolution method, which not only incorporates attention into kernels but also enhances informative representations. By replacing the standard convolution with the proposed KAConv in convolutional neural networks (CNNs), the networks yield significant performance improvement. Extensive experiments on the ImageNet-1K benchmark demonstrate that KAConv outperforms existing attention mechanism-based methods. We also carry out experiments on the MS COCO and PASCAL VOC datasets to show the generalization ability of our method.},
  archive      = {J_NEUCOM},
  author       = {Xinxin Shan and Tai Ma and Yutao Shen and Jiafeng Li and Ying Wen},
  doi          = {10.1016/j.neucom.2022.10.017},
  journal      = {Neurocomputing},
  pages        = {477-485},
  shortjournal = {Neurocomputing},
  title        = {KAConv: Kernel attention convolutions},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust consensus-aware network for 3D point registration.
<em>NEUCOM</em>, <em>514</em>, 464–476. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier correspondence removal is an important task for feature-based point cloud registration. Given putative correspondences contaminated by outliers between two overlapped scans, we propose a Robust Consensus-Aware Network, which labels the correspondences as inliers or outliers and predicts the rigid transformation to align the point clouds. The proposed method dedicates to mining the global consensus of correct correspondences (inliers). So it can learn distinctive features for each correspondence. Specifically, the proposed network comprises three novel operations. First, by capturing the global consensus information in an attentive manner, the network projects the input correspondences into a discriminative feature space. Next, we exploit the feature similarity among correspondences to establish interactions within inlier or outlier correspondences, and aggregate the features of correct correspondences for outlier removal . Finally, we recover the rigid transformation by mining multi-level context with a motion estimation module. Extensive experiments on real-world datasets demonstrate that our approach achieves high registration accuracy and efficiency.},
  archive      = {J_NEUCOM},
  author       = {Fan Yang and Zhi Chen and Kun Sun and Liman Liu and Wenbing Tao},
  doi          = {10.1016/j.neucom.2022.10.009},
  journal      = {Neurocomputing},
  pages        = {464-476},
  shortjournal = {Neurocomputing},
  title        = {Robust consensus-aware network for 3D point registration},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mutually activated residual linear modeling GAN for
pose-guided person image generation. <em>NEUCOM</em>, <em>514</em>,
451–463. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Translating a pose of a given person to another desired pose is popular in computer vision applications . However, previous works usually directly utilized pose information to guide appearance information for the generation without deep consideration of the interaction between these two kinds of information. Moreover, the global long-range relation that exists in both kinds of data has not been well modeled due to the physical design of convolutional filters . In this paper, a novel Mutually Activated Residual Linear Modeling Generative Adversarial Network (MARLM-GAN) is proposed to address these two challenges. The MARLM-GAN consists of T cascaded MARLM modules for learning the latent transformation progressively from both appearance and pose codes. In each MARLM module, there are two mutually-activated residual linear modeling blocks for both appearance and pose pathways. In addition, an information update strategy is also developed, which makes the latent appearance and pose representations benefit each other interactively. Our experiments on two challenging datasets demonstrate that the proposed MARLM-GAN can achieve competitive results in terms of objective evaluation metrics and subjective visual realness compared with recent state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Ji Liu and Yuesheng Zhu},
  doi          = {10.1016/j.neucom.2022.09.089},
  journal      = {Neurocomputing},
  pages        = {451-463},
  shortjournal = {Neurocomputing},
  title        = {Mutually activated residual linear modeling GAN for pose-guided person image generation},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). In search of a robust facial expressions recognition model:
A large-scale visual cross-corpus study. <em>NEUCOM</em>, <em>514</em>,
435–450. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many researchers have been seeking robust emotion recognition system for already last two decades. It would advance computer systems to a new level of interaction, providing much more natural feedback during human–computer interaction due to analysis of user affect state. However, one of the key problems in this domain is a lack of generalization ability : we observe dramatic degradation of model performance when it was trained on one corpus and evaluated on another one. Although some studies were done in this direction, visual modality still remains under-investigated. Therefore, we introduce the visual cross-corpus study conducted with the utilization of eight corpora, which differ in recording conditions, participants’ appearance characteristics, and complexity of data processing. We propose a visual-based end-to-end emotion recognition framework, which consists of the robust pre-trained backbone model and temporal sub-system in order to model temporal dependencies across many video frames. In addition, a detailed analysis of mistakes and advantages of the backbone model is provided, demonstrating its high ability of generalization. Our results show that the backbone model has achieved the accuracy of 66.4\% on the AffectNet dataset, outperforming all the state-of-the-art results. Moreover, the CNN-LSTM model has demonstrated a decent efficacy on dynamic visual datasets during cross-corpus experiments, achieving comparable with state-of-the-art results. In addition, we provide backbone and CNN-LSTM models for future researchers: they can be accessed via GitHub.},
  archive      = {J_NEUCOM},
  author       = {Elena Ryumina and Denis Dresvyanskiy and Alexey Karpov},
  doi          = {10.1016/j.neucom.2022.10.013},
  journal      = {Neurocomputing},
  pages        = {435-450},
  shortjournal = {Neurocomputing},
  title        = {In search of a robust facial expressions recognition model: A large-scale visual cross-corpus study},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rethinking mask heads for partially supervised instance
segmentation. <em>NEUCOM</em>, <em>514</em>, 426–434. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on partially supervised instance segmentation where only a subset of categories are mask-annotated ( seen ) and the model is expected to generalize to unseen categories for which only box annotations are provided to eliminate laborious mask annotations. Many recent studies train a class-agnostic segmentation network to distinguish foreground areas in each proposal. However, class-agnostic models behave poorly in complex contexts when the foreground object overlaps with other irreverent objects. Identifying specific object categories is simpler than distinguishing foreground from background since the definition of the foreground is ambiguous even for a human. However, training class-specific model is unfeasible under the partially supervised setting since the mask annotations of unseen categories are absent during training. To overcome this issue, we put forward a teacher-student architecture where the teacher learns general yet comprehensive knowledge and the students, guided by the teacher, delve deeper into specific categories. Concretely, the teacher learns to segment foreground from proposals and the student is devoted to segmenting objects of specific categories. Extensive experiments on the challenging COCO dataset demonstrate our method consistently improve the performance of several recent state-of-the-art methods for the partially setting. Especially, for overlapped objects, our method significantly outperforms the competitors with a clear margin, demonstrating the superiority of our method.},
  archive      = {J_NEUCOM},
  author       = {Kai Zhao and Xuehui Wang and Xingyu Chen and Ruixin Zhang and Wei Shen},
  doi          = {10.1016/j.neucom.2022.10.003},
  journal      = {Neurocomputing},
  pages        = {426-434},
  shortjournal = {Neurocomputing},
  title        = {Rethinking mask heads for partially supervised instance segmentation},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymptotical synchronization for complex-valued stochastic
switched neural networks under the sampled-data controller via a
switching law. <em>NEUCOM</em>, <em>514</em>, 414–425. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the asymptotic synchronization problem of delayed complex-valued stochastic switched neural networks under sampled-data controller is considered. Using linear matrix inequality, switching laws and Lyapunov functional, sufficient conditions for asymptotic synchronization of the system under different controllers are obtained. Finally, an example and simulation are used to illustrate the rationality of our conclusions.},
  archive      = {J_NEUCOM},
  author       = {Jianglian Xiang and Junwu Ren and Manchun Tan},
  doi          = {10.1016/j.neucom.2022.09.152},
  journal      = {Neurocomputing},
  pages        = {414-425},
  shortjournal = {Neurocomputing},
  title        = {Asymptotical synchronization for complex-valued stochastic switched neural networks under the sampled-data controller via a switching law},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PCNet: Paired channel feature volume network for accurate
and efficient depth estimation. <em>NEUCOM</em>, <em>514</em>, 403–413.
(<a href="https://doi.org/10.1016/j.neucom.2022.09.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most state-of-the-art deep learning based depth estimation methods follow the pipeline of firstly forming a 4D cost volume (feature dimension, max disparity, height, and width) and then regressing disparity from the cost volume by several 3D convolutional layers . Applying 3D operations on the 4D tensor leads to unacceptable computational complexity and memory cost. To solve the problem, we aim at replacing the 4D cost volume with 3D cost volume so that the disparity can be regressed by 2D convolutions to achieve a good balance between efficiency and effectiveness. To this end, a light-weighted network, called PCNet, is proposed to generate 3D cost volume. The main novelty lies in the proposed Paired Channel Feature Volume (PCFV) which is capable of combining the features of stereo pairs with specially designed 3D filters to preliminarily encode the relationship between each pair of the channels. Moreover, a densely connected aggregation on the outputs of PCFV is performed to exploit much richer contextual information. Experimental results on the SceneFlow, KITTI 2012, and KITTI 2015 datasets demonstrate that the proposed PCNet achieves comparable accuracy with state-of-the-art methods and keeps high efficiency as well.},
  archive      = {J_NEUCOM},
  author       = {Dayu Jia and Yanwei Pang and Jiale Cao and Jing Pan},
  doi          = {10.1016/j.neucom.2022.09.024},
  journal      = {Neurocomputing},
  pages        = {403-413},
  shortjournal = {Neurocomputing},
  title        = {PCNet: Paired channel feature volume network for accurate and efficient depth estimation},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning for stuttering identification: Review,
challenges and future directions. <em>NEUCOM</em>, <em>514</em>,
385–402. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stuttering is a speech disorder during which the flow of speech is interrupted by involuntary pauses and repetition of sounds. Stuttering identification is an interesting interdisciplinary domain research problem involving pathology, psychology, acoustics, and signal processing, making it hard and complicated to detect. Recent developments in the machine and deep learning have dramatically revolutionized the speech domain, however minimal attention has been given to stuttering identification. This work fills the gap by trying to bring researchers together from interdisciplinary fields. In this paper, we comprehensively review acoustic features, and statistical and deep learning-based stuttering/disfluency classification methods. We also present several challenges and possible future directions.},
  archive      = {J_NEUCOM},
  author       = {Shakeel A. Sheikh and Md Sahidullah and Fabrice Hirsch and Slim Ouni},
  doi          = {10.1016/j.neucom.2022.10.015},
  journal      = {Neurocomputing},
  pages        = {385-402},
  shortjournal = {Neurocomputing},
  title        = {Machine learning for stuttering identification: Review, challenges and future directions},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transmission schedule for jointly optimizing remote state
estimation and wireless sensor network lifetime. <em>NEUCOM</em>,
<em>514</em>, 374–384. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies scheduling multiple sensors for jointly optimizing remote state estimation and wireless sensor network lifetime. Each sensor in the network sends its packet to the remote center for further estimation over wireless communication channels. Sensors in the network will inevitably run out of battery power due to transmission consumption and then reach the end of sensor network lifetime. This article focuses on the problem how to schedule multiple sensors minimizing the total remote estimation errors and simultaneously prolonging the sensor network lifetime. The problem is formulated as a special class of Markov decision process (MDP), stochastic shortest path (SSP) problem. Under this framework, we first derive a set of conditions to guarantee the optimality of structural policies in SSP. Subsequently, threshold structure of the optimal scheduling scheme is obtained by verifying the conditions. Moreover, two Value-of-Information-based multi-sensor scheduling algorithms and a linear-architecture-based learning algorithm are designed to tackle the curse of dimensionality and unknown channel statistics in large-scale sensor networks. Numerical simulations are given to validate effectiveness of our results.},
  archive      = {J_NEUCOM},
  author       = {Jiang Wei and Dan Ye},
  doi          = {10.1016/j.neucom.2022.10.011},
  journal      = {Neurocomputing},
  pages        = {374-384},
  shortjournal = {Neurocomputing},
  title        = {Transmission schedule for jointly optimizing remote state estimation and wireless sensor network lifetime},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Underwater self-supervised depth estimation.
<em>NEUCOM</em>, <em>514</em>, 362–373. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate underwater depth estimation is a cornerstone of reaching autonomous underwater exploration. However, it is incredibly tricky due to the inherent attenuation character and heavy noise. Fortunately, the depth-changing trend and underwater light attenuation are closely correlated, providing powerful clues for underwater depth estimation. Rather than simulating the underwater attenuation through formulas, we propose an underwater self-supervised depth estimation neural network in our work. With the guidance of multiple constraints, which are meticulously designed based on the comprehensive analyses of underwater characters, this network can learn the depth-changing trend by itself from attenuation information in underwater monocular videos. Our detailed experiments on underwater datasets prove that the proposed framework can obtain accurate and fine-grained depth maps. We believe the work may provide an economical solution for underwater perception.},
  archive      = {J_NEUCOM},
  author       = {Xuewen Yang and Xing Zhang and Nan Wang and Guoling Xin and Wenjie Hu},
  doi          = {10.1016/j.neucom.2022.09.122},
  journal      = {Neurocomputing},
  pages        = {362-373},
  shortjournal = {Neurocomputing},
  title        = {Underwater self-supervised depth estimation},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MGML: Momentum group meta-learning for few-shot image
classification. <em>NEUCOM</em>, <em>514</em>, 351–361. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, image classification covers more and more fields, and it is often difficult to obtain enough data for learning in some specific scenarios, such as medical fields, personalized customization of robots, etc. Few-shot image classification aims to quickly learn new classes of features from few images, and the meta-learning method has become the mainstream due to its good performance. However, the generalization ability of the meta-learning method is still poor and easy to be disturbed by low-quality images. In order to solve the above problems, this paper proposes Momentum Group Meta-Learning (MGML) to achieve a better effect of few-shot learning, which contains Group Meta-Learning module (GML) and Adaptive Momentum Smoothing module (AMS). GML obtains an ensemble model by training multiple episodes in parallel and then grouping them, which can reduce the interference of low-quality samples and improve the stability of meta-learning training. AMS includes the adaptive momentum update rule to further optimally integrate models between different groups, so that the model can memorize experience in more scenarios and enhance the generalization ability. We conduct experiments on miniImageNet and tieredImageNet datasets. The results show that MGML improves the accuracy, stability and cross-domain transfer ability of few-shot image classification, and can be applied to different few-shot learning models.},
  archive      = {J_NEUCOM},
  author       = {Xiaomeng Zhu and Shuxiao Li},
  doi          = {10.1016/j.neucom.2022.10.012},
  journal      = {Neurocomputing},
  pages        = {351-361},
  shortjournal = {Neurocomputing},
  title        = {MGML: Momentum group meta-learning for few-shot image classification},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new hybrid optimizer for stochastic optimization
acceleration of deep neural networks: Dynamical system perspective.
<em>NEUCOM</em>, <em>514</em>, 341–350. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic optimization acceleration is extremely significant and challenging for deep neural networks (DNNs). In recent years, several novel proportional-integral–differential-based (PID-based) optimizers have been proposed to speed up the optimization by alleviating the oscillation behavior of stochastic gradient descent with momentum (SGD-M), yet lacked theoretical analysis. Along this line of research, this paper adopts dynamical system theory to design a new hybrid optimizer and present theoretical analysis. Firstly, it is found that DNN optimization is equivalent to a discrete time dynamical system . Building upon the equivalence, high order augmented dynamical system viewpoint is utilized to design a PI-like optimizer for ensuring high accuracy, which is more stable than SGD-M. Then, hybrid dynamical system viewpoint is employed to improve the PI-like optimizer as a new hybrid form for suppressing oscillation and accelerating optimization. Lyapunov method, Taylor series , matrix theory and equilibrium are combined to theoretically investigate the convergence and the oscillation of loss function, showing that the proposed hybrid optimizer can alleviate oscillation, boost optimization speed, and maintain high accuracy. In theoretical analyses, explicit conditions of hyper-parameters that guarantee training stability are calculated and presented, practically guiding the adjustment of hyper-parameters and promoting the application of hybrid optimizer. Experiments are presented on three commonly used benchmark datasets, i.e., MNIST, CIFAR10 and CIFAR100, demonstrating that the hybrid optimizer obtains up to 42\% acceleration with competitive accuracy relative to state-of-the-art optimizers. In short, this paper not only presents a new hybrid optimizer for accelerating optimization, but also provides a novel, theoretical and systematic perspective to find and analyze new optimizer for DNNs.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Xie and Weishan Tang and Yujia Kuang},
  doi          = {10.1016/j.neucom.2022.09.147},
  journal      = {Neurocomputing},
  pages        = {341-350},
  shortjournal = {Neurocomputing},
  title        = {A new hybrid optimizer for stochastic optimization acceleration of deep neural networks: Dynamical system perspective},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). 3D mesh transformer: A hierarchical neural network with
local shape tokens. <em>NEUCOM</em>, <em>514</em>, 328–340. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-attention networks have revolutionized Natural Language Processing (NLP) and are making impressive strides in image analysis tasks such as image classification and object detection. Inspired by this success, we specifically design a novel self-attention mechanism between local shapes and build a shape Transformer. We split the 3D mesh model into shape patches, which we call shape tokens, and provide polynomial fitting representations of these patches as input to the shape Transformer. The shape token encodes local geometric information and resembles the token (word) status in NLP. The simplification of the mesh model provides a hierarchical multiresolution structure, which allows us to realize the feature learning of a multilayer Transformer. We set high-level features formed by the shape Transformer as visual tokens and propose a vector-type self-attention mechanism to construct a 3D visual Transformer. Finally, we realized a hierarchical network structure based on local shape tokens and high-level visual tokens. Experiments show that our fusion network of 3D shape Transformer with explicit local shape context augmentation and 3D visual Transformer with multi-level structural feature learning achieves excellent performance on shape classification and part segmentation tasks .},
  archive      = {J_NEUCOM},
  author       = {Yu Chen and Jieyu Zhao and Lingfeng Huang and Hao Chen},
  doi          = {10.1016/j.neucom.2022.09.138},
  journal      = {Neurocomputing},
  pages        = {328-340},
  shortjournal = {Neurocomputing},
  title        = {3D mesh transformer: A hierarchical neural network with local shape tokens},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-source manifold feature transfer learning with domain
selection for brain-computer interfaces. <em>NEUCOM</em>, <em>514</em>,
313–327. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning uses the knowledge in source domains to improve the learning performance in the target domain, which is useful in electroencephalogram (EEG) based brain-computer interfaces (BCIs) with small training datasets. However, the existing transfer learning methods for EEG based BCI mainly consider the knowledge transfer from single-to-single (STS) domain or simply merge different source domains into a bigger one. In this paper, we propose a multi-source manifold feature transfer learning (MMFT) framework to transfer multi-source knowledge for EEG signals classification. MMFT minimizes marginal probability distribution on the Riemannian manifold using Riemannian alignment and Grassmann manifold feature learning , then transfers the manifold features with a conditional probability distribution adaptation in the structural risk minimization (SRM) function. Based on MMFT, w-MMFT is proposed to tackle the class imbalance issue for SRM, and the label similarity analysis (LSA) is proposed to select source domains for MMFT, forming a new LSA-MMFT framework. Experimental results on six datasets demonstrate that the proposed MMFT has achieved superior performance in classification accuracy and computational efficiency compared to state-of-the-art methods. The LSA-MMFT can get more stable performance than two other domain selection methods.},
  archive      = {J_NEUCOM},
  author       = {Qingshan She and Yinhao Cai and Shengzhi Du and Yun Chen},
  doi          = {10.1016/j.neucom.2022.09.124},
  journal      = {Neurocomputing},
  pages        = {313-327},
  shortjournal = {Neurocomputing},
  title        = {Multi-source manifold feature transfer learning with domain selection for brain-computer interfaces},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy support vector machine with graph for classifying
imbalanced datasets. <em>NEUCOM</em>, <em>514</em>, 296–312. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since support vector machine (SVM) considers all the training samples equally, it suffers from the problems of noise/outliers and class imbalance. Although many fuzzy support vector machines (FSVMs) have been proposed to suppress the effect of noise/outliers and class imbalance, most of them ignore the impact of the curse of dimensionality on the discriminative performance of fuzzy membership function and do not give the fuzzy membership function corresponding to the kernel space, which seriously reduces the performance of FSVM. To solve these problems, we propose the fuzzy support vector machine with graph (GraphFSVM) in this paper. Specifically, we first design a graph-based fuzzy membership function to accurately assess the importance of samples in original feature space and prove that the function can mine discriminative information between samples in high-dimensional data. Additionally, since the data distribution in kernel space is different from those in the original feature space, a method is provided to calculate the fuzzy membership function in the kernel space. Finally, the GraphFSVM model analyzes samples of each class independently, this suppresses the effect of class imbalance. Following the above principles, we design the graph-based fuzzy support vector machine and propose a detailed optimization method. Experimental results on UCI, gene expression, and image datasets show that the GraphFSVM has better generalization and robustness than other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Baihua Chen and Yuling Fan and Weiyao Lan and Jinghua Liu and Chao Cao and Yunlong Gao},
  doi          = {10.1016/j.neucom.2022.09.139},
  journal      = {Neurocomputing},
  pages        = {296-312},
  shortjournal = {Neurocomputing},
  title        = {Fuzzy support vector machine with graph for classifying imbalanced datasets},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cascade wavelet transform based convolutional neural
networks with application to image classification. <em>NEUCOM</em>,
<em>514</em>, 285–295. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pooling has been the core ingredient of modern convolutional neural networks (CNNs). Although classic pooling methods are simple and effective, it will inevitably lead to the problem that some features that make a great contribution to classification may be ignored. To solve this issue, this paper presents a novel cascade wavelet transform module, which makes full use of different frequency components and can be seamlessly integrated into the existing CNNs by replacing the existing pooling operation. In our method, wavelet transforms are performed in both spatial and channel domain. In spatial domain, using 2D discrete wavelet transform , we design a spatial pooling layer with attention mechanism by integrating low-frequency and high-frequency information. In channel domain, based on 1D discrete wavelet transform, a channel pooling layer with the attention mechanism is proposed for the final feature reconstruction. We call the proposed cascade wavelet transform based CNNs CasDWTNets. Compared to the traditional CNNs, experiments demonstrate that CasDWTNets obtain outstanding consistency and accuracy in image classification . Code will be made available.},
  archive      = {J_NEUCOM},
  author       = {Jieqi Sun and Yafeng Li and Qijun Zhao and Ziyu Guo and Ning Li and Tao Hai and Wenbo Zhang and Dong Chen},
  doi          = {10.1016/j.neucom.2022.09.149},
  journal      = {Neurocomputing},
  pages        = {285-295},
  shortjournal = {Neurocomputing},
  title        = {Cascade wavelet transform based convolutional neural networks with application to image classification},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NaNG-ST: A natural neighborhood graph-based self-training
method for semi-supervised classification. <em>NEUCOM</em>,
<em>514</em>, 268–284. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The self-training method has been favored by scholars in semi-supervised classification. One of the greatest challenges in self-training methods is finding high-confidence unlabeled samples at each iteration. While multiple variations of self-training methods are developed, the strategy of finding high-confidence unlabeled samples heavlies on parameters and only utilizes labeled data alone, which makes the self-training method limited by the distribution of labeled data. To solve the above issues, a novel natural neighborhood graph-based self-training method (NaNG-ST) is proposed. In NaNG-ST, a parameter-free natural neighborhood graph (NaNG) is first constructed. The NaNG roughly reveals the real data distribution by exploiting unlabeled and labeled data. Based on NaNG, homogeneous and heterogeneous edges are defined to divide unlabeled samples into three cases. After that, homogeneous and heterogeneous edges can use the revealed distribution rather than labeled data alone to help NaNG-ST fast and effectively find confident unlabeled samples without any parameters. Besides, they also help NaNG-ST not to be limited by the distribution of initial labeled data. When a few initial labeled data can not roughly represent the distribution of the entire data, the NaNG helps NaNG-ST restore the real data distribution better. Intensive experiments on real-world data sets prove that NaNG-ST outperforms 7 popular semi-supervised self-taught approaches in terms of classification accuracy , mean F -measure and required running time.},
  archive      = {J_NEUCOM},
  author       = {Junnan Li},
  doi          = {10.1016/j.neucom.2022.08.010},
  journal      = {Neurocomputing},
  pages        = {268-284},
  shortjournal = {Neurocomputing},
  title        = {NaNG-ST: A natural neighborhood graph-based self-training method for semi-supervised classification},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AFE-CNN: 3D skeleton-based action recognition with action
feature enhancement. <em>NEUCOM</em>, <em>514</em>, 256–267. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing 3D skeleton-based action recognition approaches reach impressive performance by encoding handcrafted action features to image format and decoding by CNNs. However, such methods are limited in two ways: a) the handcrafted action features are difficult to handle challenging actions, and b) they generally require complex CNN models to improve action recognition accuracy, which usually occur heavy computational burden. To overcome these limitations, we introduce a novel AFE-CNN , which devotes to enhance the features of 3D skeleton-based actions to adapt to challenging actions. We propose feature enhance modules from key joint, bone vector, key frame and temporal perspectives, thus the AFE-CNN is more robust to camera views and body sizes variation, and significantly improve the recognition accuracy on challenging actions. Moreover, our AFE-CNN adopts a light-weight CNN model to decode images with action feature enhanced, which ensures a much lower computational burden than the state-of-the-art methods. We evaluate the AFE-CNN on three benchmark skeleton-based action datasets: NTU RGB + D, NTU RGB + D 120, and UTKinect-Action3D, with extensive experimental results demonstrate our outstanding performance of AFE-CNN .},
  archive      = {J_NEUCOM},
  author       = {Shannan Guan and Haiyan Lu and Linchao Zhu and Gengfa Fang},
  doi          = {10.1016/j.neucom.2022.10.016},
  journal      = {Neurocomputing},
  pages        = {256-267},
  shortjournal = {Neurocomputing},
  title        = {AFE-CNN: 3D skeleton-based action recognition with action feature enhancement},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BDA-SketRet: Bi-level domain adaptation for zero-shot SBIR.
<em>NEUCOM</em>, <em>514</em>, 245–255. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficacy of zero-shot sketch-based image retrieval (ZS-SBIR) models is governed by two challenges. The immense distributions-gap between the sketches and the images requires a proper domain alignment. Moreover, the fine-grained nature of the task and the high intra-class variance of many categories necessitates a class-wise discriminative mapping among the sketch, image, and the semantic spaces. Under this premise, we propose BDA-SketRet, a novel ZS-SBIR framework performing a bi-level domain adaptation for aligning the spatial and semantic features of the visual data pairs progressively. In order to highlight the shared features and reduce the effects of any sketch or image-specific artifacts, we propose a novel symmetric loss function based on the notion of information bottleneck for aligning the semantic features while a cross-entropy-based adversarial loss is introduced to align the spatial feature maps. Finally, our CNN-based model confirms the discriminativeness of the shared latent space through a novel topology-preserving semantic projection network . Experimental results on the extended Sketchy, TU-Berlin, and QuickDraw datasets exhibit sharp improvements over the literature.},
  archive      = {J_NEUCOM},
  author       = {Ushasi Chaudhuri and Ruchika Chavan and Biplab Banerjee and Anjan Dutta and Zeynep Akata},
  doi          = {10.1016/j.neucom.2022.09.104},
  journal      = {Neurocomputing},
  pages        = {245-255},
  shortjournal = {Neurocomputing},
  title        = {BDA-SketRet: Bi-level domain adaptation for zero-shot SBIR},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting double h.266/VVC compression with the same coding
parameters. <em>NEUCOM</em>, <em>514</em>, 231–244. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of video double compression with the same coding parameters is a difficult problem in video forensics, since the recompression traces are extremely slight in this case. Although a series of methods have been proposed, detection of Versatile Video Coding (H.266/VVC) double compression with the same coding parameters is rarely reported. To address this issue, we propose a novel algorithm for the detection of H.266/VVC double compression with the same coding parameters in this paper. We first analyze the generation of H.266/VVC double compression traces, and explore the variation of coding modes caused by multiple compressions. Then we define Minimum Unit Mapping (MUM) and Subunit Prediction Mapping (SPM) to facilitate feature construction. The strength of the variation in the number of coding unit (CU) in each compression is calculated to form CU partition modes based feature set. We also use the consistency ratios of adjacent prediction mode pairs in the horizontal, vertical, major diagonal, and minor diagonal directions after multiple compressions to obtain prediction modes based feature set. These feature sets are further concatenated into a fusion feature for detection. With the thorough comparison to the state-of-the-art algorithms, it is verified that the proposed algorithm outperforms other current works in the field. Besides, the proposed method is robust against various encoding configurations.},
  archive      = {J_NEUCOM},
  author       = {Qiang Xu and Dongmei Xu and Hao Wang and Zhongjie Mi and Zhe Wang and Hong Yan},
  doi          = {10.1016/j.neucom.2022.09.153},
  journal      = {Neurocomputing},
  pages        = {231-244},
  shortjournal = {Neurocomputing},
  title        = {Detecting double H.266/VVC compression with the same coding parameters},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Adaptive context- and scale-aware aggregation with feature
alignment for one-shot object detection. <em>NEUCOM</em>, <em>514</em>,
216–230. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a query image of a novel object category at the inference stage, One-Shot Object Detection (OSOD) aims to target the detection towards reference category through the guidance of query image without fine-tuning. It can be widely applied to many realistic applications but remains challenging so far. Existing attention-based models mainly utilize query features to modulate the target branch to finish features retrieval and information propagation, which generally cannot comprehensively exploit context extracted from the only template to mine out co-occurrent object features, also neglect the cross-scale and feature spatial misalignment problems, leading to imprecise results. Observing these problems, we propose an adaptive context- and scale-aware feature aggregation module (ACS), that harnesses global–local context enrichment to fully preserve contextual features, and performs conditioned multi-scale interaction to learn scale-invariant representations. To tackle the spatial misalignment issue between the query image and generated proposals, we leverage the spatial transformer network (STN) to align features, which facilitates the subtask of classification. Extensive experiments on multiple OSOD benchmarks show that our proposed approach significantly outperforms the baseline by a large margin and achieves state-of-the-art results, demonstrating its effectiveness. Meanwhile, the visualization results of geometric semantic matching between query-target image pairs also verify the robustness of our proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Wenwen Zhang and Chengdong Dong and Jun Zhang and Hangguan Shan and Eryun Liu},
  doi          = {10.1016/j.neucom.2022.09.155},
  journal      = {Neurocomputing},
  pages        = {216-230},
  shortjournal = {Neurocomputing},
  title        = {Adaptive context- and scale-aware aggregation with feature alignment for one-shot object detection},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convolutional modulation theory: A bridge between
convolutional neural networks and signal modulation theory.
<em>NEUCOM</em>, <em>514</em>, 195–215. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although there have been a lot of researches on convolutional neural networks (CNNs), still what happens in this black box remains a mystery. In this paper, we establish the connection between CNNs and signal modulation . From a signal modulation point of view, the forward-propagation process of CNNs can be explained as a process of modulating the input signals to the vicinity of a special energy spectrum distribution, and the back-propagation process is searching for the appropriate distribution which is better for classification or other tasks. Several experiments have been carried out to verify the modulated explanation of CNNs. Furthermore, we verify that modulating the signal to the appropriate energy spectrum distribution in advance can effectively improve the classification and segmentation accuracy.},
  archive      = {J_NEUCOM},
  author       = {Fuzhi Wu and Jiasong Wu and Youyong Kong and Chunfeng Yang and Guanyu Yang and Huazhong Shu and Guy Carrault and Lotfi Senhadji},
  doi          = {10.1016/j.neucom.2022.09.088},
  journal      = {Neurocomputing},
  pages        = {195-215},
  shortjournal = {Neurocomputing},
  title        = {Convolutional modulation theory: A bridge between convolutional neural networks and signal modulation theory},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Dual branch parallel steganographic framework based on
multi-scale distillation in framelet domain. <em>NEUCOM</em>,
<em>514</em>, 182–194. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intuition behind image steganography is to hide secret image into cover image, thereby analysis and retrieval are avoided. Image steganography methods based on deep learning have recently gained popularity in comparison to traditional methods. However, most steganography methods have poor perceptibility and restoration robustness, resulting in weak quality of stego images and revealed images. To address this gap, we propose DBPSNet, an original dual branch parallel steganographic network based on knowledge distillation in framelet domain. Wavelet frame transform performed on cover image is used to migrate the steganographic framework in spatial domain to framelet domain. Afterwards, we establish the steganographic framework based on knowledge distillation , where the teacher branch produces feature maps layer-by-layer to guide student branch in learning how to generate reliable and realistic stego image. In addition, the random noise layer is used in reconstruction network, which helps improve the robustness of model by attempting to reveal image from the noisy stego image. Extensive controlled experiments on BOSSBase show that DBPSNet is ahead of some mainstream image steganography methods in terms of steganography and reconstruction effects, algorithm security and model robustness.},
  archive      = {J_NEUCOM},
  author       = {Zhengze Li and Xiaoyuan Yang and Kangqing Shen and Fazhen Jiang and Jin Jiang and Huwei Ren and Yixiao Li},
  doi          = {10.1016/j.neucom.2022.09.146},
  journal      = {Neurocomputing},
  pages        = {182-194},
  shortjournal = {Neurocomputing},
  title        = {Dual branch parallel steganographic framework based on multi-scale distillation in framelet domain},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adversarial attacks and defenses in deep learning for image
recognition: A survey. <em>NEUCOM</em>, <em>514</em>, 162–181. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, researches on adversarial attacks and defense mechanisms have obtained much attention. It’s observed that adversarial examples crafted with small malicious perturbations would mislead the deep neural network (DNN) model to output wrong prediction results. These small perturbations are imperceptible to humans. The existence of adversarial examples poses great threat to the robustness of DNN-based models. It is necessary to study the principles behind it and develop their countermeasures. This paper surveys and summarizes the recent advances in attack and defense methods extensively and in detail, analyzes and compares the pros and cons of various attack and defense schemes. Finally we discuss the main challenges and future research directions in this field.},
  archive      = {J_NEUCOM},
  author       = {Jia Wang and Chengyu Wang and Qiuzhen Lin and Chengwen Luo and Chao Wu and Jianqiang Li},
  doi          = {10.1016/j.neucom.2022.09.004},
  journal      = {Neurocomputing},
  pages        = {162-181},
  shortjournal = {Neurocomputing},
  title        = {Adversarial attacks and defenses in deep learning for image recognition: A survey},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantic multimodal violence detection based on
local-to-global embedding. <em>NEUCOM</em>, <em>514</em>, 148–161. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic violence detection has received continuous attention due to its broad application prospects. However, most previous work prefers building a generalized pipeline while ignoring the complexity and diversity of violent scenes. In most cases, people judge violence by a variety of sub-concepts, such as blood, fighting, screams, explosions, etc., which may show certain co-occurrence trends. Therefore, we argue that parsing abstract violence into specific semantics helps to obtain the essential representation of violence. In this paper, we propose a semantic multimodal violence detection framework based on local-to-global embedding. The local semantic detection is designed to capture fine-grained violent elements in the video via a set of local semantic detectors, which is generated from a variety of external word embeddings . Also, we introduce a global semantic alignment branch to mitigate the intra-class variance of violence, in which violent video embeddings are guided to form a compact cluster while keeping a semantic gap with non-violent embeddings. Furthermore, we construct a multimodal cross-fusion network (MCN) for multimodal feature fusion , which consists of a cross-adaptive module and a cross-perceptual module. The former aims to eliminate inter-modal heterogeneity, while the latter suppresses task-irrelevant redundancies to obtain robust video representations. Extensive experiments demonstrate the effectiveness of the proposed method, which has a superior generalization capacity and achieves competitive performance on five violence datasets.},
  archive      = {J_NEUCOM},
  author       = {Yujiang Pu and Xiaoyu Wu and Shengjin Wang and Yuming Huang and Zihao Liu and Chaonan Gu},
  doi          = {10.1016/j.neucom.2022.09.090},
  journal      = {Neurocomputing},
  pages        = {148-161},
  shortjournal = {Neurocomputing},
  title        = {Semantic multimodal violence detection based on local-to-global embedding},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated layer-wise solution for ensemble deep randomized
feed-forward neural network. <em>NEUCOM</em>, <em>514</em>, 137–147. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The randomized feed-forward neural network is a single hidden layer feed-forward neural network that enables efficient learning by optimizing only the output weights. The ensemble deep learning framework significantly improves the performance of randomized neural networks. However, the framework’s capabilities are limited by traditional hyper-parameter selection approaches. Meanwhile, different random network architectures, such as the existence or lack of a direct link and the mapping of direct links, can also strongly affect the results. We present an automated learning pipeline for the ensemble deep randomized feed-forward neural network in this paper, which integrates hyper-parameter selection and randomized network architectural search via Bayesian optimization to ensure robust performance. Experiments on 46 UCI tabular datasets show that our strategy produces state-of-the-art performance on various tabular datasets among a range of randomized networks and feed-forward neural networks. We also conduct ablation studies to investigate the impact of various hyper-parameters and network architectures.},
  archive      = {J_NEUCOM},
  author       = {Minghui Hu and Ruobin Gao and Ponnuthurai N. Suganthan and M. Tanveer},
  doi          = {10.1016/j.neucom.2022.09.148},
  journal      = {Neurocomputing},
  pages        = {137-147},
  shortjournal = {Neurocomputing},
  title        = {Automated layer-wise solution for ensemble deep randomized feed-forward neural network},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feedback neural network for constrained bi-objective convex
optimization. <em>NEUCOM</em>, <em>514</em>, 127–136. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bi-objective optimization problems occur widely in engineering and science. This paper considers lexicographic method solution of the bi-objective optimization problems , feedback neural networks are adopted as optimization tools. The two objectives are sorted according to their priority, and then the bi-objective optimization problem is converted to two optimization problems with single-objective, namely, the high-priority optimization problem and the low-priority optimization problem. First, a classical neural network is applied for the high-priority optimization problem. Then, a novel feedback neural network is constructed to find an optimal solution of the low-priority optimization problem in the optimal solution set of the high-priority optimization problem. It is proved that any accumulation point of the state sequence of the proposed feedback neural network is a Pareto optimal solution to the considered bi-objective optimization problem. In contrast with the existing neural networks , the proposed neural network has simple structure and relies on weaker convergence conditions. Finally, some numerical examples and an application in fuzzy optimization show the effectiveness of the proposed neural network.},
  archive      = {J_NEUCOM},
  author       = {Na Liu and Zhiyuan Su and Yueting Chai and Sitian Qin},
  doi          = {10.1016/j.neucom.2022.09.120},
  journal      = {Neurocomputing},
  pages        = {127-136},
  shortjournal = {Neurocomputing},
  title        = {Feedback neural network for constrained bi-objective convex optimization},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Consistent affinity representation learning with dual
low-rank constraints for multi-view subspace clustering.
<em>NEUCOM</em>, <em>514</em>, 113–126. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering aims to achieve better accuracy of data clustering by leveraging complementary information embedded in multi-view data. How to learn a consistent clustering-friendly affinity representation matrix is a crucial issue. In this paper, we propose a consistent affinity representation learning method with dual low-rank constraints for multi-view subspace clustering. To be specific, for capturing the high-order correlations and global consensus among views, we collect the subspace representations of all views into a 3-order tensor, which is imposed with the tensor singular value decomposition (t-SVD) based tensor nuclear norm for achieving the low-rank recovery. Thus, we learn a consistent affinity matrix by fusing multiple subspace representations on the Grassmann manifold rather than handling them in the Euclidean space. In order to enhance the global cluster structure in the uniform subspace, the low-rank constraint is imposed on the consistent affinity matrix . Furthermore, the local geometric structure of the uniform subspace is encoded via graph regularization . The established model can be solved via the alternating direction method of multipliers algorithm (ADMM). Ultimately, the proposed method is experimentally validated to be superior to other state-of-the-art clustering algorithms .},
  archive      = {J_NEUCOM},
  author       = {Lele Fu and Jieling Li and Chuan Chen},
  doi          = {10.1016/j.neucom.2022.09.145},
  journal      = {Neurocomputing},
  pages        = {113-126},
  shortjournal = {Neurocomputing},
  title        = {Consistent affinity representation learning with dual low-rank constraints for multi-view subspace clustering},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). UFKT: Unimportant filters knowledge transfer for CNN
pruning. <em>NEUCOM</em>, <em>514</em>, 101–112. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the deep learning models have been widely used in recent years, there is a high demand for reducing the model size in terms of memory and computation without much compromise in the model performance. Filter pruning is a very widely adopted strategy for model compression . The existing filter pruning methods identify the unimportant filters and prune them without worrying about information loss. They try to recover the same by fine-tuning the remaining filters, limiting their performance. In this paper, we tackle this problem by utilizing the knowledge from unimportant filters before pruning to minimize information loss. First, the proposed method identifies the unimportant and important filters by exploiting the lower and higher importance, respectively, using the L 1 L1 -norm of filters. Next, the proposed custom UFKT-Reg regularizer ( R ufkt Rufkt ) transfers the knowledge from unimportant filters before pruning to remaining filters, notably to a fixed number of important filters. Hence, the proposed method minimizes information loss due to the removal of unimportant filters. The experiments are conducted using the three benchmark datasets, including MNIST, CIFAR-10, and ImageNet. The proposed filter pruning method outperforms many recent state-of-the-art filter pruning methods. An improvement over the baseline in terms of accuracy is observed even after removing 95.15\%, 62.28\%, and 62.39\% of the Floating Point OPerations (FLOPs) from architectures LeNet-5, ResNet-56, and ResNet-110, respectively. After pruning 53.25\% of FLOPS from ResNet-50, only 1.02\% and 0.47\% of drops are observed in top-1 and top-5 accuracies, respectively. The code used in this paper will be publicly available at ( https://github.com/sarvanichinthapalli/UFKT ).},
  archive      = {J_NEUCOM},
  author       = {Sarvani CH and Shiv Ram Dubey and Mrinmoy Ghorai},
  doi          = {10.1016/j.neucom.2022.09.150},
  journal      = {Neurocomputing},
  pages        = {101-112},
  shortjournal = {Neurocomputing},
  title        = {UFKT: Unimportant filters knowledge transfer for CNN pruning},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Membership-function-dependent fuzzy control of
reaction-diffusion memristive neural networks with a finite number of
actuators and sensors. <em>NEUCOM</em>, <em>514</em>, 94–100. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the fuzzy control design problem for reaction-diffusion memristive neural networks (MNNs). Initially, by introducing the logical switched functions, the original reaction-diffusion MNN is transformed into another model form. Subsequently, a Takagi-Sugeno (T-S) fuzzy PDE model is devoted to accurately representing the reaction-diffusion MNN. Then, via the obtained T-S fuzzy model, under the hypothesis that the actuators and sensors are collocated while the spatial domain is separated into several subdomains, a Lyapunov-based membership-function-dependent fuzzy control design employing a finite number of actuators and sensors is developed in terms of linear matrix inequalities, such that the closed-loop reaction-diffusion MNN is exponentially stable. In final, numerical simulations illustrate the effectiveness of the proposed fuzzy control design method.},
  archive      = {J_NEUCOM},
  author       = {Xiao-Wei Zhang and Huai-Ning Wu and Jin-Liang Wang and Zhijie Liu and Ruoxia Li},
  doi          = {10.1016/j.neucom.2022.09.126},
  journal      = {Neurocomputing},
  pages        = {94-100},
  shortjournal = {Neurocomputing},
  title        = {Membership-function-dependent fuzzy control of reaction-diffusion memristive neural networks with a finite number of actuators and sensors},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep manifold embedding of attributed graphs.
<em>NEUCOM</em>, <em>514</em>, 83–93. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised attribution graph embedding is challenging because the structure and attribute information should be represented in the latent space. Existing reconstruction-based methods may corrupt the manifold of the attributed graph because they indirectly optimize the latent space with the help of decoders. Therefore, we propose a new graph embedding framework called Deep Manifold Embedding of Attribution Graphs (DMEAG). DMEAG directly imposes constraints on the latent space without decoders, thus better preserving the structural information. Further, we propose a node-to-node geodesic similarity metric to measure data relationships. And we design a novel loss function based on Bergman divergence to minimize the difference between embedding and structure/features. Extensive experiments on graphical and image datasets demonstrate the superiority of DMEAG. Furthermore, the proposed DMEAG outperforms state-of-the-art methods in three downstream tasks: clustering, link prediction, and visualization.},
  archive      = {J_NEUCOM},
  author       = {Zelin Zang and Siyuan Li and Di Wu and Jianzhu Guo and Yongjie Xu and Stan Z. Li},
  doi          = {10.1016/j.neucom.2022.09.100},
  journal      = {Neurocomputing},
  pages        = {83-93},
  shortjournal = {Neurocomputing},
  title        = {Deep manifold embedding of attributed graphs},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). USIS: A unified semantic image synthesis model trained on a
single or multiple samples. <em>NEUCOM</em>, <em>514</em>, 70–82. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic image synthesis methods learn to generate new images conditioned on predefined semantic label maps. Existing methods require access to large-volume samples labeled with semantic maps, which limits their applications. We propose USIS, a Unified Semantic Image Synthesis model which can be trained on only a single or multiple pairs of images and semantic maps. Once trained, a USIS model can generate new images according to unseen semantic maps, as existing semantic image synthesis methods do. Specifically, we design a hierarchical architecture to reconstruct training samples and gradually learn the distributions of multi-scale patches in samples from coarse to fine. To avoid the error accumulation across scales, we propose a mixed training strategy to stabilize the training process. Extensive experiments on one- or multiple-sample datasets show our proposed model achieves state-of-the-art performance in terms of visual fidelity.},
  archive      = {J_NEUCOM},
  author       = {Pei Chen and Zejian Li and Yangkang Zhang and Yongchuan Tang and Lingyun Sun},
  doi          = {10.1016/j.neucom.2022.09.092},
  journal      = {Neurocomputing},
  pages        = {70-82},
  shortjournal = {Neurocomputing},
  title        = {USIS: A unified semantic image synthesis model trained on a single or multiple samples},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rethinking prediction alignment in one-stage object
detection. <em>NEUCOM</em>, <em>514</em>, 58–69. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to their excellent performance and efficiency, one-stage detectors have been widely used in multimedia tasks, such as temporal action detection, object tracking, and video detection. However, misalignment between classification and regression branches limits the accuracy of the detector. Most existing works add an auxiliary branch or adopt a specific sample assignment strategy to alleviate this problem, but with little effect. In this paper, we attribute this to incomplete branch interactions and propose a comprehensive Predictive Aligned Object Detector (PAOD), which can better correlate two subtasks. Specifically, our proposed PAOD achieves a better trade-off between prediction-interactive and prediction-specific by adopting an Iterative Aggregation Module (IAM) and a Mutual Constraint Module (MCM). We also design an aligned label assignment with an adaptive metric and re-weighting mechanism to further narrow the misalignment between prediction heads. With negligible additional overhead, PAOD achieves 50.4 AP at single-model single-scale testing on the MS-COCO branch, which demonstrates the effectiveness of our proposal. Notably, PAOD consistently outperforms previous sota such as ATSS (47.7 AP), BorderDet (48.0 AP) and GFL (48.2 AP) by a large margin on COCO test-dev dataset, and achieves better performance than various dense detectors on Pascal VOC and CrowdHuman datasets. Code is available at https://github.com/JunruiXiao/PAOD.},
  archive      = {J_NEUCOM},
  author       = {Junrui Xiao and He Jiang and Zhikai Li and Qingyi Gu},
  doi          = {10.1016/j.neucom.2022.09.132},
  journal      = {Neurocomputing},
  pages        = {58-69},
  shortjournal = {Neurocomputing},
  title        = {Rethinking prediction alignment in one-stage object detection},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Fast and scalable learning of sparse changes in
high-dimensional graphical model structure. <em>NEUCOM</em>,
<em>514</em>, 39–57. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on the problem of estimating the change in the dependency structures of two p -dimensional Gaussian Graphical models (GGMs). Previous studies for sparse change estimation in GGMs involve expensive and difficult non-smooth optimization. We propose a novel method, DIFFEE for estimating DIFF erential networks via an E lementary E stimator under a high-dimensional situation. DIFFEE is solved through a faster and closed-form solution that enables it to work in large-scale settings. Notice that GGM assumes data are generated from a Gaussian distribution. However, the Gaussian assumption is too strict and can not be satisfied with all the real-world data generated from a complex process. Therefore, we further extend DIFFEE to NPN-DIFFEE by assuming that data are drawn from the nonparanormal distribution (a large family of distributions) instead of a multivariate Gaussian distribution. Thus, NPN-DIFFEE is applicable to more general conditions. We conduct a rigorous statistical analysis showing that surprisingly DIFFEE achieves the same asymptotic convergence rates as the state-of-the-art estimators that are much more difficult to compute. Our experimental results on multiple synthetic datasets and one real-world data about brain connectivity show strong performance improvements over baselines, as well as significant computational benefits.},
  archive      = {J_NEUCOM},
  author       = {Beilun Wang and Jiaqi Zhang and Haoqing Xu and Te Tao},
  doi          = {10.1016/j.neucom.2022.09.137},
  journal      = {Neurocomputing},
  pages        = {39-57},
  shortjournal = {Neurocomputing},
  title        = {Fast and scalable learning of sparse changes in high-dimensional graphical model structure},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parameter adaptive unit-linking dual-channel PCNN based
infrared and visible image fusion. <em>NEUCOM</em>, <em>514</em>, 21–38.
(<a href="https://doi.org/10.1016/j.neucom.2022.09.157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The properties like pulse synchronization of neurons and global coupling greatly motivated researchers to apply pulse coupled neural network (PCNN) models in accomplishing image fusion. However, manual adjustment of its parameters negatively affects the fusion performance. Moreover, it can process one image at a time. A new parameter adaptive unit-linking dual-channel PCNN model that exhibits all the properties of PCNN and processes two images simultaneously is used in this work to implement a novel fusion algorithm in the non-subsampled contourlet transform (NSCT) domain for the integration of infrared and visible images. At the same time, all the parameters of the proposed model are automatically estimated from the source images. The infrared and visible images are first decomposed using NSCT to provide a sequence of band-pass directional sub-bands and a low-pass sub-band, respectively. The band-pass directional sub-bands are fused using fractal dimension-based linking strength, while the low-pass sub-bands are combined using a new linking strength based on the multi-scale morphological gradient of coefficients. Lastly, the fused image is constructed from the fused sub-bands by applying inverse NSCT. Fourteen state-of-the-art methods are adopted for comparing the performance of the proposed method. The qualitative comparison is done using the human visual system, whereas six objective metrics are considered for the quantitative evaluation. The proposed method is competitive and outperforms some of the existing methods, according to the results of the experiments.},
  archive      = {J_NEUCOM},
  author       = {Chinmaya Panigrahy and Ayan Seal and Nihar Kumar Mahato},
  doi          = {10.1016/j.neucom.2022.09.157},
  journal      = {Neurocomputing},
  pages        = {21-38},
  shortjournal = {Neurocomputing},
  title        = {Parameter adaptive unit-linking dual-channel PCNN based infrared and visible image fusion},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contrastive deep embedded clustering. <em>NEUCOM</em>,
<em>514</em>, 13–20. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep embedded clustering is a popular unsupervised learning method owing to its outstanding performance in data-mining applications. However, existing methods ignore the difficulty in learning discriminative features via clustering due to the lack of supervision, which can be easily obtained in classification tasks . To alleviate this problem, we build a contrastive learning based deep embedded clustering method , i.e., CDEC. Specifically, our model adopts deep auto-encoders to learn a latent discriminative embedded clustering structure . To overcome the problem of lacking label information, the CDEC constructs positive samples and negative samples with the data reconstructed from the data itself and other data, respectively. By maximizing the distance between positive and negative ones, the CDEC can not only obtain the most representative features but also explore the discriminative features . Extensive experiments on several public datasets demonstrate that our method achieves the state-of-the-art clustering effectiveness. Our codes are available at: https://github.com/guoshuaiS/contrastive-deep.},
  archive      = {J_NEUCOM},
  author       = {Guoshuai Sheng and Qianqian Wang and Chengquan Pei and QuanXue Gao},
  doi          = {10.1016/j.neucom.2022.09.116},
  journal      = {Neurocomputing},
  pages        = {13-20},
  shortjournal = {Neurocomputing},
  title        = {Contrastive deep embedded clustering},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Crossmodal bipolar attention for multimodal classification
on social media. <em>NEUCOM</em>, <em>514</em>, 1–12. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal classification of social media is used to classify data from different modalities into different categories, which is essential for understanding user behavior on the web. In this paper, we focus on classifying image-text pairs, specifically user-generated content on social media. Recently, the transformer network, a kind of self-attention network, has been widely studied in the disciplines of visual computing and language processing. In the attention mechanism, positive correlation is considered. However, multimedia content posted on social media is diverse. Images and text are not always consistent, and contrary information is also helpful for representation. Therefore, it is equally important to detect conflicts based on negative or inverse attention. Inspired by the attention mechanism, we propose a novel model, namely Crossmodal Bipolar Attention Network (CBAN). Different from existing positive dot-product and additive attention mechanisms, we propose a bipolar attention mechanism, which fuses visual and textual information through their direct and inverse semantic relationships to classify multimodal data. We conducted experiments on multiple multimodal classification data sets, for performing sentiment analysis , sarcasm detection, crisis categorization and hate-speech detection. Experimental results show that our proposed CBAN consistently outperforms state-of-the-art methods in all classification tasks .},
  archive      = {J_NEUCOM},
  author       = {Tsun-hin Cheung and Kin-man Lam},
  doi          = {10.1016/j.neucom.2022.09.140},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {Crossmodal bipolar attention for multimodal classification on social media},
  volume       = {514},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Imbalance multi-label data learning with label specific
features. <em>NEUCOM</em>, <em>513</em>, 395–408. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A class of machine learning problem where each instance may either belong to one or more than one class simultaneously is known as Multi-label classification problem. A well-known paradigm for multi-label classification is binary relevance (BR) where multi-label classification is decomposed into binary (one-vs-rest) classification subproblems, one for each label. However, it has a number of drawbacks. First, each binary classifier can be affected by the class-imbalance issue. Second, it does not take label correlations into account. Third, it has an inconsistency problem i.e. training instances with multi-label characteristics are considered both as positive as well as negative instance simultaneously. We attempt to resolve these problems in our proposed formulation. The problem of class imbalance is addressed by applying different weights to positive and negative examples depending on the class distribution, the inconsistency issue is addressed by selecting label-specific features. We have also considered the associations that exist among the set of possible labels. We have used hinge loss function which ensures less sensitivity towards outliers and the accelerated proximal gradient method (APG) to efficiently solve the underlying optimization problem . Our proposed approach is competitive with other state-of-the-art approaches according to experimental findings on several benchmark data sets.},
  archive      = {J_NEUCOM},
  author       = {Reshma Rastogi and Sayed Mortaza},
  doi          = {10.1016/j.neucom.2022.09.085},
  journal      = {Neurocomputing},
  pages        = {395-408},
  shortjournal = {Neurocomputing},
  title        = {Imbalance multi-label data learning with label specific features},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Self-supervised learning and semi-supervised learning for
multi-sequence medical image classification. <em>NEUCOM</em>,
<em>513</em>, 383–394. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-sequence medical images are playing an increasingly important role in disease diagnosis because different sequences can provide complementary information. At the same time, deep learning-based methods have been widely used in computer aided diagnosis , but most of the recent success profoundly relies on large amounts of carefully labeled data, which is time-consuming and costly, especially when multiple sequences need to be labeled. To reduce the human effort of labeling multi-sequence medical images, we present a new self-supervised learning method MI-SelfL, a new semi-supervised learning method MI-SemiL, and a combined method MI-SESEL, and all these methods can exploit unlabeled data by exploring the intrinsic relation and the complementarity between multi-sequence images. We conducted extensive experiments on two tasks, hepatocellular carcinoma grading using dynamic contrast enhanced Magnetic Resonance Imaging (MRI) and prostate cancer classification using multiparametric MRI. The results show that compared with the fully-supervised learning baseline, MI-SelfL and MI-SemiL can both improve the model performance, whereas the combined method MI-SESEL can further improve it.},
  archive      = {J_NEUCOM},
  author       = {Yueyue Wang and Danjun Song and Wentao Wang and Shengxiang Rao and Xiaoying Wang and Manning Wang},
  doi          = {10.1016/j.neucom.2022.09.097},
  journal      = {Neurocomputing},
  pages        = {383-394},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised learning and semi-supervised learning for multi-sequence medical image classification},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An approach for applying natural language processing to
image classification problems. <em>NEUCOM</em>, <em>513</em>, 372–382.
(<a href="https://doi.org/10.1016/j.neucom.2022.09.131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A growing interest in applying Natural Language Processing (NLP) models to computer vision problems has recently emerged. This interest is motivated by the success of NLP models in tasks such as translation and text summarization. In this paper, we propose a new method for applying NLP to image classification problems. We aim to represent the visual patterns of objects by using a sequence of alphabet symbols and then train a Gated Recurrent Unit (GRU), Long Short-Term Memory (LSTM), or Transformer using these sequences to classify objects. An extensive experimental evaluation using a limited number of images for training has been conducted to compare our method with the ResNet-50 deep learning architecture. The results obtained by the proposed method outperform ResNet-50 in all test scenarios. In one test, the method achieved an average accuracy of 95.3\% compared to 89.9\% of ResNet-50. The source code ( http://git.inovisao.ucdb.br/inovisao/applying-npl-to-image-classification ) and dataset ( https://doi.org/10.6084/m9.figshare.20055602.v1 ) are publicly available.},
  archive      = {J_NEUCOM},
  author       = {Gilberto Astolfi and Diego André Sant’Ana and João Vitor de Andrade Porto and Fábio Prestes Cesar Rezende and Everton Castelão Tetila and Edson Takashi Matsubara and Hemerson Pistori},
  doi          = {10.1016/j.neucom.2022.09.131},
  journal      = {Neurocomputing},
  pages        = {372-382},
  shortjournal = {Neurocomputing},
  title        = {An approach for applying natural language processing to image classification problems},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive overview of deepfake: Generation, detection,
datasets, and opportunities. <em>NEUCOM</em>, <em>513</em>, 351–371. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When used maliciously, deepfake can pose detrimental implications to political and social forces including reducing public trust in institutions, damaging the reputation of prominent individuals, and influencing public opinions. As there is currently no specific law to address deepfakes, thus deepfake detection, which is an action to discriminate pristine media from deepfake media, plays a vital role in identifying and thwarting deepfake. This paper provides readers with a comprehensive and easy-to-understand state-of-the-art related to deepfake generation and detection. Specifically, we provide a synthesized overview and recent progress in deepfakes by categorizing our review into deepfake generation and detection. We underline publicly available deepfake generation tools and datasets for benchmarking. We also provide research insights, discuss existing gaps, and present trends for future research to facilitate the development of deepfake research.},
  archive      = {J_NEUCOM},
  author       = {Jia Wen Seow and Mei Kuan Lim and Raphaël C.W. Phan and Joseph K. Liu},
  doi          = {10.1016/j.neucom.2022.09.135},
  journal      = {Neurocomputing},
  pages        = {351-371},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive overview of deepfake: Generation, detection, datasets, and opportunities},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Common belief multi-agent reinforcement learning based on
variational recurrent models. <em>NEUCOM</em>, <em>513</em>, 341–350.
(<a href="https://doi.org/10.1016/j.neucom.2022.09.144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tacit cooperation among human teams benefits from the fact that consensus can be reached on a task through common belief. Similar to human social groups, agents in distributed learning systems can also rely on common belief to achieve cooperation under the condition of limited communication. In this paper, we show the role of common belief among agents in completing cooperative tasks, by proposing the Common Belief Multi-Agent (CBMA) reinforcement learning method. CBMA is a novel value-based method that infers the belief between agents with a variational model and models the environment with a variational recurrent neural network. We validate CBMA on two grid-world games as well as the StarCraft II micromanagement benchmark. Experimental results show that the learned common belief by CBMA can improve performance in both discrete and continuous state settings.},
  archive      = {J_NEUCOM},
  author       = {Xianjie Zhang and Yu Liu and Hangyu Mao and Chao Yu},
  doi          = {10.1016/j.neucom.2022.09.144},
  journal      = {Neurocomputing},
  pages        = {341-350},
  shortjournal = {Neurocomputing},
  title        = {Common belief multi-agent reinforcement learning based on variational recurrent models},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HARNet: Hierarchical adaptive regression with location
recovery for crowd counting. <em>NEUCOM</em>, <em>513</em>, 329–340. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers have started to utilize the structures like Feature Pyramid Network (FPN) for crowd counting to extract multi-scale features, which can solve the scale variation problem in traditional density map regression-based methods. However, many downsampling operations in FPN inevitably induce loss of location information, resulting in pixel mismatch of the predicted density map. In this paper, we propose the Location Recovery Module (LRM) to recover the loss of location information. Unlike the basic feature fusion module in FPN, the proposed LRM builds an offset map to modify the position of the downsampled features under the guidance of low-level features. Meanwhile, we design a novel regression strategy to fully utilize the multi-scale information without upsampling operations in the fusion process. Considering that the highest-level feature cannot represent all density-level features well, different-scale features focus more on their related regions in our regression strategy. The proposed HARNet has been tested on four datasets and achieved state-of-the-art on two datasets. The performance metric such as MAE arrives at 52.4, 5.9 and 181.7 on ShanghaiTech A/B and UCF_CC_50 respectively.},
  archive      = {J_NEUCOM},
  author       = {Zhe Zheng and Na Ni and Guangping Xie and Aichun Zhu and Yingna Wu and Tingting Yang},
  doi          = {10.1016/j.neucom.2022.09.091},
  journal      = {Neurocomputing},
  pages        = {329-340},
  shortjournal = {Neurocomputing},
  title        = {HARNet: Hierarchical adaptive regression with location recovery for crowd counting},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Subdomain contraction in deep networks for robust
representation learning. <em>NEUCOM</em>, <em>513</em>, 318–328. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks provide end-to-end tools to learn effective representations from data directly. The deep structure makes it possible to model a complicated pattern, even if it has a variety of changes. This leads to a problem that noises and outliers are usually treated as a specific pattern, which is also learned in the network. It is one reason for overfitting incapable of being addressed sufficiently in deep networks. This paper proposes a new method called subdomain contraction (SDC) to tackle the problem. The idea is that our approach inclines to learn more about the shared features between the subsets of the samples but less about the specific features found in only one or two subsets. To this end, the SDC loss penalizes the distribution distance between sub-domains in the feature space to constrain the sharing level of features. By applying the SDC loss term, the data drive the learning process to an optimal tradeoff between modeling noises and the varieties of the pattern. In this manner, the SDC models the pattern as much as possible and ignores most noises, thus improving the generalization ability . The SDC loss can be efficiently computed in minibatches and can also work collaboratively with other regularization methods such as dropout to further improve the performance. Extensive experiments demonstrate that SDC can improve the effectiveness and robustness of representation learning in deep networks against noises, and the superiority is most remarkable with noisy data.},
  archive      = {J_NEUCOM},
  author       = {Yu Qi and Zhentao Pan and Gang Pan and Yueming Wang},
  doi          = {10.1016/j.neucom.2022.09.084},
  journal      = {Neurocomputing},
  pages        = {318-328},
  shortjournal = {Neurocomputing},
  title        = {Subdomain contraction in deep networks for robust representation learning},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Biologically inspired image classifier based on saccadic eye
movement design for convolutional neural networks. <em>NEUCOM</em>,
<em>513</em>, 294–317. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a model for image classification by attentional search. Analogous to how humans scan an image by a sequence of saccades, in this model, an attentional window of size much smaller than the target size scans the target by a sequence of “saccades”, integrates the information acquired, and makes a classification decision. In order to process a sequence of attended image segments, the network must have memory, which is incorporated through 3 kinds of recurrent elements in the network architecture : Elman connections, Jordan connections, and Flip-flop neurons. The architecture of the model is designed as three separate channels labeled as – classifier network, eye-position network, and saccade network. Multiple attentional windows with different resolutions and a common center are given as input to the classifier network and the saccade network. The heat-map representation of the location of the attentional windows is given as input to the eye-position network. The saccade network predicts the next jump of the attention windows with the help of reward signals received by the classifier network. The output features of all the three channels are concatenated, before finally terminating in two output layers representing class prediction and next saccade prediction. The model is trained using deep Q-learning algorithm. Attentional search model is evaluated on MNIST handwritten digit , Kannada MNIST, Medical-MNIST, OCTMNIST, and QuickDraw datasets. Translated and Cluttered Translated versions of each dataset are generated to perform the task of classification based on local target search. Original datasets are used to show the task of classification based on search with global target integration. We also evaluate the saccade performance on Extended Yale Face B database. In various problem cases, the model exhibits comparable or superior performance to a state-of-the-art recurrent attention model. Demo code is available in this link .},
  archive      = {J_NEUCOM},
  author       = {Sweta Kumari and V. Srinivasa Chakravarthy},
  doi          = {10.1016/j.neucom.2022.09.027},
  journal      = {Neurocomputing},
  pages        = {294-317},
  shortjournal = {Neurocomputing},
  title        = {Biologically inspired image classifier based on saccadic eye movement design for convolutional neural networks},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Input convex neural networks in nonlinear predictive
control: A multi-model approach. <em>NEUCOM</em>, <em>513</em>, 273–293.
(<a href="https://doi.org/10.1016/j.neucom.2022.09.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The presented input convex neural multi-modelling approach to Model Predictive Control (MPC) has two essential advantages. Firstly, the MPC algorithm solves only convex optimisation tasks; complex not convex and multi-modal problems are not considered. Secondly, the model is trained in a simple one-step-ahead configuration and it is not used recurrently for prediction. Two neural multi-model structures are considered: fully input convex and partially input convex ones. The fully convex model structure turns out to be too restrictive for the considered polymerisation reactor benchmark process. The partially convex model leads to very good prediction accuracy and excellent control quality. Development of fully and partially input convex multi-models is thoroughly described, particularly selection of the number of the hidden nodes. Additionally, low effectiveness of a linear multi-model is discussed for comparison.},
  archive      = {J_NEUCOM},
  author       = {Maciej Ławryńczuk},
  doi          = {10.1016/j.neucom.2022.09.108},
  journal      = {Neurocomputing},
  pages        = {273-293},
  shortjournal = {Neurocomputing},
  title        = {Input convex neural networks in nonlinear predictive control: A multi-model approach},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). JMNET: Arbitrary-shaped scene text detection using
multi-space perception. <em>NEUCOM</em>, <em>513</em>, 261–272. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The arbitrary-shape scene text detection faces enormous challenges in accuracy and speed with increasing demand in the industrial sector. Although most studies have introduced segmentation and achieved remarkable performance in text detection tasks, researchers ignored the importance of detection efficiency. This paper proposes a new Joint Multi-Space Perception Network (JMNET) for efficient scene text detection to address this issue. Based on a lightweight feature extraction backbone, we put forward two novel modules, i.e., Scale Spatial Perception Module (SSPM) and Attention Spatial Perception Module (ASPM) to enhance the expression ability of text features with low computational complexity . Moreover, we propose an Unsupervised Embedding Spatial Perception Loss function (UnESP Loss) by introducing the Euclidean distance measurement between the embeddings to overcome the ambiguity of text instance boundary, such as a small line spacing. In this way, text embedding learning is not restricted by specific shapes, and detection robustness can be improved. Extensive experiments on four benchmarks, including the ICDAR2015, MSRA-TD500, CTW1500 and Totaltext, show that the proposed JMNET achieves competitive performance in terms of both accuracy and speed over the state-of-the-art methods. Particularly, our method can reach a remarkable F-measure of 85.5\% at 52 FPS on Totaltext. Code is available at: https://github.com/sakura-910/JMNET .},
  archive      = {J_NEUCOM},
  author       = {Zhijian Lin and Ying Chen and Pingping Chen and Honghui Chen and Feng Chen and Nam Ling},
  doi          = {10.1016/j.neucom.2022.09.095},
  journal      = {Neurocomputing},
  pages        = {261-272},
  shortjournal = {Neurocomputing},
  title        = {JMNET: Arbitrary-shaped scene text detection using multi-space perception},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). SemRegionNet: Region ensemble 3D semantic instance
segmentation network with semantic spatial aware discriminative loss.
<em>NEUCOM</em>, <em>513</em>, 247–260. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The semantic instance segmentation task on 3D data has made great progress. However, for unstructured 3D point cloud data, the mining of regional knowledge and explicit assistance of semantic for the instance segmentation task are still rarely explored. In this paper, we propose a region ensemble structure including random sampling-based set abstraction (RS-SA), an adaptive regional feature complementary (ARFC) module, and an affinity-based regional relational reasoning (AR 3 ) module in feature encoding to enhance the point cloud comprehension. Random sampling is introduced into the set abstraction of feature encoding to improve computational efficiency. The ARFC module aims to complement low-level features to adaptively compensate for the information loss caused by random sampling and inherent non-uniformity of point clouds, and the AR 3 module emphasizes mining the potential reasoning relationships among high-level features based on affinity. Furthermore, a novel semantic spatial aware discriminative loss is proposed to improve the discrimination of instance embedding. The proposed region ensemble structure and semantic spatial awareness for discriminative loss are demonstrated promising boosts on the 3D point cloud semantic instance segmentation task, and the framework achieves state-of-the-art performance on the S3DIS, ScanNet-v2, and ShapeNet datasets.},
  archive      = {J_NEUCOM},
  author       = {Guanghui Zhang and Dongchen Zhu and Wenjun Shi and Jiamao Li and Xiaolin Zhang},
  doi          = {10.1016/j.neucom.2022.09.110},
  journal      = {Neurocomputing},
  pages        = {247-260},
  shortjournal = {Neurocomputing},
  title        = {SemRegionNet: Region ensemble 3D semantic instance segmentation network with semantic spatial aware discriminative loss},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Delving deep into pixelized face recovery and defense.
<em>NEUCOM</em>, <em>513</em>, 233–246. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pixelization is arguably one of the most well-adopted deterministic obfuscation techniques for privacy preservation purposes. Although the recovery of pixelized faces is underexplored, the powerful deep neural networks might combat this problem in a data-driven manner. As a consequence, an unbreakable pixelization approach is desired. To achieve this goal, in this paper, we delve into two contradictory problems of unrecoverable pixelization and its counterpart, depixelization, by leveraging the best recovery to strengthen the robustness of the unrecoverable pixelized patterns. In particular, on the offensive end of recovery, we combat the large and continuous nature of pixelized regions by proposing two strategies, 1) an iterative depixelization network that progressively decomposes and predicts the pixelized regions and thus outer results are used to support inner inferences; 2) a dynamic dilated convolution operation is proposed to stride over the redundant identical pixels from the same pixelized region, enabling the network to adaptively extract valid feature representations. We show that our tailored depixelization method significantly outperforms several baselines or inpainting approaches by over 1.0 FID and 2\% ID-SIM improvements on CelebA dataset which includes 182,732 human face images, and therefore we study how to defend this advanced recovery and produce unrecoverable pixelized patterns. To balance the visual perception and robustness of pixelization, we propose to generate two types of adversarial examples , pixel-wise and block-wise perturbations, which make different trade-offs between quality and robustness. By deploying our depixelization network in a semi-whitebox setting, our pixelization method can generate imperceptible perturbations while being robust to depixelization.},
  archive      = {J_NEUCOM},
  author       = {Zhixuan Zhong and Yong Du and Yang Zhou and Jiangzhong Cao and Shengfeng He},
  doi          = {10.1016/j.neucom.2022.09.141},
  journal      = {Neurocomputing},
  pages        = {233-246},
  shortjournal = {Neurocomputing},
  title        = {Delving deep into pixelized face recovery and defense},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature selection using decomposed mutual information
maximization. <em>NEUCOM</em>, <em>513</em>, 215–232. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection has been recognized for long as an important preprocessing technique to reduce dimensionality and improve the performance of regression and classification tasks. The class of sequential forward feature selection methods based on Mutual Information (MI) is widely used in practice, mainly due to its computational efficiency and independence from the specific classifier. A recent work introduced a theoretical framework for this class of methods which explains the existing proposals as approximations to an optimal target objective function. Such framework made clear the advantages and drawbacks of each proposal. Methods accounting for the redundancy of candidate features using a maximization function and considering the so-called complementary effect are among the best ones. However, they still penalize the complementarity, which is an important drawback. This paper proposes the Decomposed Mutual Information Maximization (DMIM) method, which keeps the good theoretical properties of the best methods proposed so far but overcomes the complementarity penalization by applying the maximization separately to the inter-feature and class-relevant redundancies. DMIM was extensively evaluated and compared with other methods, both theoretically and using two synthetic scenarios and 20 publicly available real datasets applied to specific classifiers. Our results show that DMIM achieves a better classification performance than the remaining forward feature selection methods based on MI.},
  archive      = {J_NEUCOM},
  author       = {Francisco Macedo and Rui Valadas and Eunice Carrasquinha and M. Rosário Oliveira and António Pacheco},
  doi          = {10.1016/j.neucom.2022.09.101},
  journal      = {Neurocomputing},
  pages        = {215-232},
  shortjournal = {Neurocomputing},
  title        = {Feature selection using decomposed mutual information maximization},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unveil the potential of siamese framework for visual
tracking. <em>NEUCOM</em>, <em>513</em>, 204–214. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the existing Siamese tracking methods follow the overall framework of SiamRPN, adopting its general network architecture and the local and linear cross-correlation operation to integrate search and template features, which restricts the introduction of more sophisticated structures for expressive appearance representation as well as the further improvements on tracking performance. Motivated by the recent progresses in vision Transformer and MLP, we first explore to accomplish a global, nonlinear and scale-invariant similarity measuring manner called Dynamic Cross-Attention (DCA). Specifically, template features are first decomposed along the spatial and channel dimension and then the Transformer Encoders are applied to adaptively excavate the long-range feature interdependency , producing reinforced kernels. As the kernels are successively multiplied to the search feature map, similarity scores between all the pixels on feature maps are estimated at once while the spatial scale of search features remains constant. Furthermore, we redesign each part of our Siamese network to further remedy the framework limitation with the assistant of DCA. Comprehensive experimental results on large-scale benchmarks indicate that our Siamese method realizes the efficient feature extraction, aggregation, refinement and interaction, outperforming state-of-the-art trackers.},
  archive      = {J_NEUCOM},
  author       = {Xin Yang and Yong Song and Yufei Zhao and Zishuo Zhang and Chenyang Zhao},
  doi          = {10.1016/j.neucom.2022.09.028},
  journal      = {Neurocomputing},
  pages        = {204-214},
  shortjournal = {Neurocomputing},
  title        = {Unveil the potential of siamese framework for visual tracking},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GSV-cities: Toward appropriate supervised visual place
recognition. <em>NEUCOM</em>, <em>513</em>, 194–203. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to investigate representation learning for large scale visual place recognition, which consists of determining the location depicted in a query image by referring to a database of reference images. This is a challenging task due to the large-scale environmental changes that can occur over time (i.e., weather, illumination, season, traffic, occlusion). Progress is currently challenged by the lack of large databases with accurate ground truth. To address this challenge, we introduce GSV-C ities , a new image dataset providing the widest geographic coverage to date with highly accurate ground truth, covering more than 40 cities across all continents over a 14-year period. We subsequently explore the full potential of recent advances in deep metric learning to train networks specifically for place recognition and evaluate how different loss functions influence performances. In addition, we show that performance of existing methods substantially improves when trained on GSV-C ities . Finally, we introduce a new fully convolutional aggregation layer that outperforms existing techniques, including GeM, NetVLAD and CosPlace, and establish a new state-of-the-art on large-scale benchmarks, such as Pittsburgh, Mapillary-SLS, SPED and Nordland.},
  archive      = {J_NEUCOM},
  author       = {Amar Ali-bey and Brahim Chaib-draa and Philippe Giguère},
  doi          = {10.1016/j.neucom.2022.09.127},
  journal      = {Neurocomputing},
  pages        = {194-203},
  shortjournal = {Neurocomputing},
  title        = {GSV-cities: Toward appropriate supervised visual place recognition},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel intermittent sliding mode control approach to
finite-time synchronization of complex-valued neural networks.
<em>NEUCOM</em>, <em>513</em>, 181–193. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the issue of finite-time synchronization is discussed for complex-valued neural networks (CVNNs) by applying aperiodically intermittent sliding mode control and a non-separation approach. Firstly, to simplify the theoretical analysis process, some new differential inequalities are established, and new estimated time rules are given. Secondly, to avoid the traditional approach of separating CVNNs, a novel complex-valued aperiodically intermittent sliding mode control strategy is designed, which has never been applied to achieve CVNNs synchronization. Furthermore, by adopting the newly established lemmas, novel controllers and Lyapunov functional, some novel finite-time synchronization criteria of CVNNs are acquired. At last, the validity of the resulting conclusions is indicated by some numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Meng Hui and Jiahuang Zhang and Herbert Ho-Ching Iu and Rui Yao and Lin Bai},
  doi          = {10.1016/j.neucom.2022.09.111},
  journal      = {Neurocomputing},
  pages        = {181-193},
  shortjournal = {Neurocomputing},
  title        = {A novel intermittent sliding mode control approach to finite-time synchronization of complex-valued neural networks},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explaining deep neural networks: A survey on the global
interpretation methods. <em>NEUCOM</em>, <em>513</em>, 165–180. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A substantial amount of research has been carried out in Explainable Artificial Intelligence (XAI) models, especially in those which explain the deep architectures of neural networks . A number of XAI approaches have been proposed to achieve trust in Artificial Intelligence (AI) models as well as provide explainability of specific decisions made within these models. Among these approaches, global interpretation methods have emerged as the prominent methods of explainability because they have the strength to explain every feature and the structure of the model. This survey attempts to provide a comprehensive review of global interpretation methods that completely explain the behaviour of the AI models. We present a taxonomy of the available global interpretations models and systematically highlight the critical features and algorithms that differentiate them from local as well as hybrid models of explainability. Through examples and case studies from the literature, we evaluate the strengths and weaknesses of the global interpretation models and assess challenges when these methods are put into practice. We conclude the paper by providing the future directions of research in how the existing challenges in global interpretation methods could be addressed and what values and opportunities could be realized by the resolution of these challenges.},
  archive      = {J_NEUCOM},
  author       = {Rabia Saleem and Bo Yuan and Fatih Kurugollu and Ashiq Anjum and Lu Liu},
  doi          = {10.1016/j.neucom.2022.09.129},
  journal      = {Neurocomputing},
  pages        = {165-180},
  shortjournal = {Neurocomputing},
  title        = {Explaining deep neural networks: A survey on the global interpretation methods},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mean-square synchronization of fractional-order stochastic
complex network via pinning control. <em>NEUCOM</em>, <em>513</em>,
153–164. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the mean-square synchronization problem is considered for the fractional-order stochastic complex network (FOSCN) via pinning control. Firstly, suppose that the dynamics of the node are modeled by continuous-time nonlinear fractional stochastic differential equations (FSDEs). Next, the pinning nodes are selected according to the low-dimensional pinning criteria. Furthermore, the controller is designed for each pinning node, and a set of sufficient conditions are given to guarantee the mean-square synchronization. Then, the convergence analysis of the closed-loop system is finished by directly utilizing the properties of the integral solution. It proved that the mean-square synchronization of FOSCN can be achieved with the designed controller under some conditions. In addition, the synchronization problem of general fractional-order complex networks (FOCN) without stochastic noise is solved by using a similar method. Finally, compared simulation examples are performed to demonstrate the effectiveness of the proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Xiaolin Yuan and Guojian Ren and Hu Wang and Yongguang Yu},
  doi          = {10.1016/j.neucom.2022.09.128},
  journal      = {Neurocomputing},
  pages        = {153-164},
  shortjournal = {Neurocomputing},
  title        = {Mean-square synchronization of fractional-order stochastic complex network via pinning control},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Model-based fault diagnosis methods for systems with
stochastic process – a survey. <em>NEUCOM</em>, <em>513</em>, 137–152.
(<a href="https://doi.org/10.1016/j.neucom.2022.09.134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based methods are widely used for the fault diagnosis of stochastic dynamic systems by simply using the input–output relationship of the system. Despite encouraging results and progress over past decades, developing a reliable and effective diagnostic method for systems with stochastic processes remains a significant challenge. In this paper, a comprehensive review on this topic is performed. Representative main approaches and results are analyzed and compared, and applications in some specific industrial processes are briefly reviewed. The perspectives on current challenges and potential opportunities of future work are discussed, hoping to shed some light on this active topic.},
  archive      = {J_NEUCOM},
  author       = {Zhen Zhao and Peter Xiaoping Liu and Jinfeng Gao},
  doi          = {10.1016/j.neucom.2022.09.134},
  journal      = {Neurocomputing},
  pages        = {137-152},
  shortjournal = {Neurocomputing},
  title        = {Model-based fault diagnosis methods for systems with stochastic process – a survey},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved deep learning approach based on exponential
moving average algorithm for atrial fibrillation signals identification.
<em>NEUCOM</em>, <em>513</em>, 127–136. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Atrial fibrillation (AF) is one of the leading causes of heart diseases worldwide. An accurate AF detection method for timely treatment is attracting great attention by widespread scientific and clinical research in recent years. However, routine AF detection using the visual examination of electrocardiogram data is strenuous and relatively subjective. In this study, an improved Elman neural network (IENN) model is specially designed for automated AF signals identification. Inspired by the exponential moving average (EMA) algorithm, a weight strategy is installed into the existing ENN network that provides more effective and comprehensive discrimination ability to the model for ECG signals recognition. Besides, our IENN network is embedded into a convolutional network architecture and the existing multi-layer perceptron and ENN networks are considered as control subjects to evaluate the validity on two public databases. The results exhibit that the proposed model yields the accuracy, specificity and sensitivity of 97.9\%, 97.8\% and 98.0\% on the MIT-BIH AF database and 97.1\%, 97.1\% and 97.2\% on the MIT-BIH arrhythmia database, respectively. These superior performances enable the proposed IENN model to have considerable potential as an effective tool to aid cardiologists in detecting AF signals accurately.},
  archive      = {J_NEUCOM},
  author       = {Jibin Wang and Shuo Zhang},
  doi          = {10.1016/j.neucom.2022.09.079},
  journal      = {Neurocomputing},
  pages        = {127-136},
  shortjournal = {Neurocomputing},
  title        = {An improved deep learning approach based on exponential moving average algorithm for atrial fibrillation signals identification},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On cropped versus uncropped training sets in tabular
structure detection. <em>NEUCOM</em>, <em>513</em>, 114–126. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated document processing for tabular information extraction is highly desired in many organizations, from industry to government. Prior works addressed this problem under table detection and table structure detection tasks. Proposed solutions that leverage deep learning approaches have been giving promising results; however, the impact of dataset structures on table structure detection has not been investigated. In this study, we provide a comparison of table structure detection performance with cropped and uncropped datasets. The cropped set consists of only table images that are cropped from documents assuming tables are detected perfectly. The uncropped set consists of regular document images . Experiments show that deep learning models can improve the detection performance by up to 9\% in average precision and average recall on the cropped versions. Furthermore, the impact of cropped images is negligible under the Intersection over Union (IoU) values of 50\%-70\% when compared to the uncropped versions in small-scale datasets. However, beyond 70\% IoU thresholds, cropped datasets provide significantly higher detection performance. In a large-scale dataset, cropped version outperforms the uncropped set under all IoU thresholds.},
  archive      = {J_NEUCOM},
  author       = {Yakup Akkaya and Murat Simsek and Burak Kantarci and Shahzad Khan},
  doi          = {10.1016/j.neucom.2022.09.094},
  journal      = {Neurocomputing},
  pages        = {114-126},
  shortjournal = {Neurocomputing},
  title        = {On cropped versus uncropped training sets in tabular structure detection},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reinforcement learning facilitates an optimal interaction
intensity for cooperation. <em>NEUCOM</em>, <em>513</em>, 104–113. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our social interactions vary over time and they depend on various factors that determine our preferences and goals, both in personal and professional terms. Researches have shown that this plays an important role in promoting cooperation and prosocial behavior in general. Indeed, it is natural to assume that ties among cooperators would become stronger over time, while ties with defectors (non-cooperators) would eventually be severed. Here we introduce reinforcement learning as a determinant of adaptive interaction intensity in social dilemmas and study how this translates into the structure of the social network and its propensity to sustain cooperation. We merge the iterated prisoner’s dilemma game with the Bush-Mostelle reinforcement learning model and show that there exists a moderate switching dynamics of the interaction intensity that is optimal for the evolution of cooperation. Besides, the results of Monte Carlo simulations are further supported by the calculations of dynamical pair approximation . These observations show that reinforcement learning is sufficient for the emergence of optimal social interaction patterns that facilitate cooperation. This in turn supports the social capital hypothesis with a minimal set of assumptions that guide the self-organization of our social fabric.},
  archive      = {J_NEUCOM},
  author       = {Zhao Song and Hao Guo and Danyang Jia and Matjaž Perc and Xuelong Li and Zhen Wang},
  doi          = {10.1016/j.neucom.2022.09.109},
  journal      = {Neurocomputing},
  pages        = {104-113},
  shortjournal = {Neurocomputing},
  title        = {Reinforcement learning facilitates an optimal interaction intensity for cooperation},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Congested crowd instance localization with dilated
convolutional swin transformer. <em>NEUCOM</em>, <em>513</em>, 94–103.
(<a href="https://doi.org/10.1016/j.neucom.2022.09.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd localization is a new computer vision task , evolved from crowd counting. Different from the latter, it provides more precise location information for each instance, not just counting numbers for the whole crowd scene, which brings greater challenges, especially in extremely congested crowd scenes. In this paper, we focus on how to achieve precise instance localization in high-density crowd scenes, and to alleviate the problem that the feature extraction ability of the traditional model is reduced due to the target occlusion, the image blur, etc. To this end, we propose a Dilated Convolutional Swin Transformer (DCST) for congested crowd scenes. Specifically, a window-based vision transformer is introduced into the crowd localization task, which effectively improves the capacity of representation learning . Then, the well-designed dilated convolutional module is inserted into some different stages of the transformer to enhance the large-range contextual information. Extensive experiments evidence the effectiveness of the proposed methods and achieve the state-of-the-art performance on five popular datasets. Especially, the proposed model achieves F1-measure of 77.5\% and MAE of 84.2 in terms of localization and counting performance, respectively.},
  archive      = {J_NEUCOM},
  author       = {Junyu Gao and Maoguo Gong and Xuelong Li},
  doi          = {10.1016/j.neucom.2022.09.113},
  journal      = {Neurocomputing},
  pages        = {94-103},
  shortjournal = {Neurocomputing},
  title        = {Congested crowd instance localization with dilated convolutional swin transformer},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Person identification from fingernails and knuckles images
using deep learning features and the bray-curtis similarity measure.
<em>NEUCOM</em>, <em>513</em>, 83–93. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an approach that makes use of knuckle creases and fingernails for person identification is presented. It introduces a framework for automatic person identification that includes localisation of the region of interest (ROI) of many components within hand images, recognition and segmentation of the detected components using bounding boxes, and similarity matching between two different sets of segmented images . The following hand components are considered: i) the metacarpophalangeal (MCP) joint, commonly known as the base knuckle; ii) the proximal interphalangeal (PIP) joint, commonly known as the major knuckle; iii) the distal interphalangeal (DIP) joint, commonly known as the minor knuckle; iv) the interphalangeal (IP) joint, commonly known as the thumb knuckle, and v) the fingernails. Crucial elements of the proposed framework are the feature extraction and similarity matching. This paper exploits different deep learning neural networks (DLNNs), which are essential in extracting discriminative high-level abstract features. We further use various similarity measures for the matching process. We validate the proposed approach on well-known benchmarks, including the 11k Hands dataset and the Hong Kong Polytechnic University Contactless Hand Dorsal Images known as PolyU. The results indicate that knuckle patterns and fingernails play a significant role in the person identification framework. The 11K Hands dataset results indicate that the left-hand results are better than the right-hand results and the fingernails produce consistently higher identification results than other hand components, with a rank-1 score of 100\% 100\% . In addition, the PolyU dataset attains 100\% 100\% in the fingernail of the thumb finger.},
  archive      = {J_NEUCOM},
  author       = {Mona Alghamdi and Plamen Angelov and Lopez Pellicer Alvaro},
  doi          = {10.1016/j.neucom.2022.09.123},
  journal      = {Neurocomputing},
  pages        = {83-93},
  shortjournal = {Neurocomputing},
  title        = {Person identification from fingernails and knuckles images using deep learning features and the bray-curtis similarity measure},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross stage partial connections based weighted
bi-directional feature pyramid and enhanced spatial transformation
network for robust object detection. <em>NEUCOM</em>, <em>513</em>,
70–82. (<a href="https://doi.org/10.1016/j.neucom.2022.09.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural information is an essential component for efficient object detection. In many visual detection tasks, the objects with large structural deformation usually make up a large proportion. The shape, contour, and internal structure of the objects tend toward dramatic change, which easily causes troubles for efficient object detection. Therefore, how to detect these objects robustly and accurately is one of the significant challenges. To address this issue, we introduce a Cross Stage Partial connections-based weighted Bi-directional Feature Pyramid Network (CSP-BiFPN), which allows easy and efficient multi-scale feature fusion by cross-stage partial connections. Second, to enhance the model&#39;s spatial transformation capacity, the multi-scale feature maps extracted from the YOLO backbone network are processed by an enhanced spatial transformation network (ESTN) for spatial deformations. Based on these architectural modifications and optimizations, we further develop a novel real-time robust object detection model called Bi-STN-YOLO. We evaluate the performance of the proposed method on four image datasets. The experimental results demonstrate that the proposed approach achieves significant improvements compared with the typical YOLO families and competitive performance compared to the state-of-the-arts in detection tasks.},
  archive      = {J_NEUCOM},
  author       = {Yan-Feng Lu and Qian Yu and Jing-Wen Gao and Yi Li and Jun-Cheng Zou and Hong Qiao},
  doi          = {10.1016/j.neucom.2022.09.117},
  journal      = {Neurocomputing},
  pages        = {70-82},
  shortjournal = {Neurocomputing},
  title        = {Cross stage partial connections based weighted bi-directional feature pyramid and enhanced spatial transformation network for robust object detection},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantics-driven attentive few-shot learning over clean and
noisy samples. <em>NEUCOM</em>, <em>513</em>, 59–69. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last couple of years, few-shot learning (FSL) has attracted significant attention towards minimizing the dependency on labeled training examples. An inherent difficulty in FSL is handling ambiguities resulting from having too few training samples per class. To tackle this fundamental challenge in FSL, we aim to train meta-learner models that can leverage prior semantic knowledge about novel classes to guide the classifier synthesis process . In particular, we propose semantically-conditioned feature attention and sample attention mechanisms that estimate the importance of representation dimensions and training instances. We also study the problem of sample noise in FSL, towards utilizing meta-learners in more realistic and imperfect settings. Our experimental results demonstrate the effectiveness of the proposed semantic FSL model with and without sample noise.},
  archive      = {J_NEUCOM},
  author       = {Orhun Bugra Baran and Ramazan Gokberk Cinbis},
  doi          = {10.1016/j.neucom.2022.09.121},
  journal      = {Neurocomputing},
  pages        = {59-69},
  shortjournal = {Neurocomputing},
  title        = {Semantics-driven attentive few-shot learning over clean and noisy samples},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Few-shot human motion prediction using deformable
spatio-temporal CNN with parameter generation. <em>NEUCOM</em>,
<em>513</em>, 46–58. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion prediction is to forecast future pose sequence based on the observed pose sequence. Most recent works rely on large datasets for training. However, the model trained by large datasets cannot be directly applied to the few-shot motion prediction task, which requires the model to generalize well on novel motion dynamics with limited training samples. To deal with this issue, we propose a Motion Prediction Network (MoPredNet) for few shot human motion prediction, which elegantly models long term dependency in motion dynamics and can adapt to predict new forms of motion dynamics. Specifically, the MoPredNet dynamically captures the most informative poses in the data stream as masked poses and adaptively learns spatio-temporal structure from the past poses and the masked poses, and thus improves its encoding capability of motion dynamics. We also propose to cluster training samples into pseudo actions to accumulate prior knowledge, and use the accumulated prior knowledge and few training samples to adapt the MoPredNet to unseen motion dynamics. Experimental results demonstrate that our method achieves better performance over state-of-the-art methods in human motion prediction.},
  archive      = {J_NEUCOM},
  author       = {Chuanqi Zang and Menghao Li and Mingtao Pei},
  doi          = {10.1016/j.neucom.2022.09.130},
  journal      = {Neurocomputing},
  pages        = {46-58},
  shortjournal = {Neurocomputing},
  title        = {Few-shot human motion prediction using deformable spatio-temporal CNN with parameter generation},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Episode-based personalization network for gaze estimation
without calibration. <em>NEUCOM</em>, <em>513</em>, 36–45. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Appearance-based methods employing deep convolutional architectures have achieved impressive performance for unconstrained gaze estimation. However, due to inter-personal anatomical differences, existing methods always get biased results for person-independent tasks. Generally, improvements can be achieved by adapting the models to a specified person with few calibration samples. Nevertheless, the calibration-based strategies are likely to collapse to high errors as over-parameterized neural networks easily fall into over-fitting. In this paper, we propose an E pisode- b ased P ersonalization N etwork (EbPN) for person-independent gaze estimation, which does not rely on any calibration samples. Firstly, inspired by multi-task learning, we propose a two-branch gaze estimation network, including appearance-aware network and personalization-aware network. Secondly, during training, our model is optimized with a collection of episodes, each of which is designed to imitate a few-shot gaze estimation task. Through multiple episodes, our EbPN model progressively accumulates the experience on capturing appearance and personalized information of each image, which would help our model get lower errors and generalize well on any new persons. Experiments on GazeCapture, MPIIGaze and ETH-XGaze datasets demonstrate the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyu Zhao and Yaping Huang and Yi Tian and Mei Tian},
  doi          = {10.1016/j.neucom.2022.09.050},
  journal      = {Neurocomputing},
  pages        = {36-45},
  shortjournal = {Neurocomputing},
  title        = {Episode-based personalization network for gaze estimation without calibration},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural network-based event-triggered integral reinforcement
learning for constrained h∞ tracking control with experience replay.
<em>NEUCOM</em>, <em>513</em>, 25–35. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since input constraints and external disturbances are unavoidable in tracking control problems, how to obtain a controller in this case to save communication and data resources at the same time is very challenging. Aiming at these challenges, this paper develops a novel neural network (NN)-based event-triggered integral reinforcement learning (IRL) algorithm for constrained H ∞ H∞ tracking control problems. First, the constrained H ∞ H∞ tracking control problem is transformed into a regulation problem. Second, an event-triggered optimal controller is designed to reduce network transmission burden and improve resource utilization, where a novel threshold is proposed and its non-negativity can be guaranteed. Third, for implementation purpose, a novel NN-based event-triggered IRL algorithm is developed. In order to improve data utilization, the experience replay technique with an easy-to-verify condition is employed in the learning process. Theoretical analysis proves that the tracking error and weight estimation error are uniformly ultimately bounded. Finally, simulation verification shows the effectiveness of the present method.},
  archive      = {J_NEUCOM},
  author       = {Shan Xue and Biao Luo and Derong Liu and Ying Gao},
  doi          = {10.1016/j.neucom.2022.09.119},
  journal      = {Neurocomputing},
  pages        = {25-35},
  shortjournal = {Neurocomputing},
  title        = {Neural network-based event-triggered integral reinforcement learning for constrained h∞ tracking control with experience replay},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Augmentative contrastive learning for one-shot object
detection. <em>NEUCOM</em>, <em>513</em>, 13–24. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an Augmentative Contrastive Learning for One-Shot Object Detection method that is inspired by the co-attention and co-excitation (CoAE) method. In the One-shot Object Detection (OSOD) task, the target image contains rich background information that influences the outcomes of different categories of objects more significantly. As a result, the network frequently suggests objects that do not fall under this category, leading to false detections. To learn the similarity between the target object and the query patch, we built the data augmentation module of object switch by similarity, encourage and restrain module. It primarily consists of the following three components: 1) To improve the contrast between the foreground and background, we propose an object switch module based on data augmentation and feature similarity; 2) To decrease the likelihood of false detections, we propose an encourage and restrain module that allows the network to encourage the recommendation of similar objects while restricting the recommendation of different categories of objects; and 3) To increase classification results , we use the nonlinear projector. We perform tests on the PASCAL VOC and MS COCO datasets to confirm the efficacy of our technique.},
  archive      = {J_NEUCOM},
  author       = {Yaoyang Du and Fang Liu and Licheng Jiao and Zehua Hao and Shuo Li and Xu Liu and Jing Liu},
  doi          = {10.1016/j.neucom.2022.09.125},
  journal      = {Neurocomputing},
  pages        = {13-24},
  shortjournal = {Neurocomputing},
  title        = {Augmentative contrastive learning for one-shot object detection},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Single-node attacks for fooling graph neural networks.
<em>NEUCOM</em>, <em>513</em>, 1–12. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have shown broad applicability in a variety of domains. These domains, e.g., social networks and product recommendations, are fertile ground for malicious users and behavior . In this paper, we show that GNNs are vulnerable to the extremely limited (and thus quite realistic) scenarios of a single-node adversarial attack , where the perturbed node cannot be chosen by the attacker. That is, an attacker can force the GNN to classify any target node to a chosen label, by only slightly perturbing the features or the neighbors list of another single arbitrary node in the graph, even when not being able to select that specific attacker node. When the adversary is allowed to select the attacker node , these attacks are even more effective. We demonstrate empirically that our attack is effective across various common GNN types (e.g., GCN , GraphSAGE, GAT, GIN) and robustly optimized GNNs (e.g., Robust GCN , SM GCN, GAL, LAT-GCN), outperforming previous attacks across different real-world datasets both in a targeted and non-targeted attacks. Our code is available anonymously at https://github.com/gnnattack/SINGLE.},
  archive      = {J_NEUCOM},
  author       = {Ben Finkelshtein and Chaim Baskin and Evgenii Zheltonozhskii and Uri Alon},
  doi          = {10.1016/j.neucom.2022.09.115},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {Single-node attacks for fooling graph neural networks},
  volume       = {513},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel controller design for finite-time synchronization of
fractional-order memristive neural networks. <em>NEUCOM</em>,
<em>512</em>, 494–502. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, it will concentrate on the controller designs for finite-time synchronization(FTS) of fractional-order memristive neural networks(FMNN). According to the features of neural networks , different class of controllers are formed to achieve the finite-time synchronization. Moreover, based on Lyapunov technique and fractional calculus theory, finite-time synchronization conditions have been established, and corresponding upper bound of settling time are presented. At last, a few numerical examples are introduced to illustrate the effectiveness and feasibility of the control algorithms and resulted conclusions.},
  archive      = {J_NEUCOM},
  author       = {Jian Xiao and Lin Wu and Ailong Wu and Zhigang Zeng and Zhe Zhang},
  doi          = {10.1016/j.neucom.2022.09.118},
  journal      = {Neurocomputing},
  pages        = {494-502},
  shortjournal = {Neurocomputing},
  title        = {Novel controller design for finite-time synchronization of fractional-order memristive neural networks},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Characterizing the fuzzy community structure in link graph
via the likelihood optimization. <em>NEUCOM</em>, <em>512</em>, 482–493.
(<a href="https://doi.org/10.1016/j.neucom.2022.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting fuzzy communities in networks is a critical but challenging task in many fields including biology, technology, social system and so on. Current technology is largely reliant on network topology , which can’t provide much useful information such module correlations and hierarchies. This paper introduces a new fuzzy community detection method by maximizing the likelihood function, which can dynamically map the link community structure to the optimal state. To specify the direction and weight of the link graph, the directional node graph is first converted into a new type of link graph. Next, we define a community unit consisting of membership and correlation information in a link graph. Specially, we define this likelihood function with a posteriori probability that aims to find the optimal partition under the prior conditions of given link graph and granularity . Furthermore, based on the spectral analysis of Markov transition matrices , we give a strict mathematical analysis for identifying the optimal number of network communities by analyzing the stability of community structures. Finally, extensive experiments on both artificial benchmarks and real-world networks show that our algorithm consistently achieving higher accuracy than classical methods.},
  archive      = {J_NEUCOM},
  author       = {Hui-Jia Li and Shenpeng Song and Wenze Tan and Zhaoci Huang and Xiaoyan Li and Wenzhe Xu and Jie Cao},
  doi          = {10.1016/j.neucom.2022.09.013},
  journal      = {Neurocomputing},
  pages        = {482-493},
  shortjournal = {Neurocomputing},
  title        = {Characterizing the fuzzy community structure in link graph via the likelihood optimization},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combining multi-view ensemble and surrogate lagrangian
relaxation for real-time 3D biomedical image segmentation on the edge.
<em>NEUCOM</em>, <em>512</em>, 466–481. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time 3D biomedical image segmentation is always preferred considering the exponentially growing medical imaging data for the past decade. Recently deep learning has significantly boosted the performance of automatic medical image segmentation with high computation and memory requirements, especially for 3D biomedical images. Meanwhile, the privacy and security of patient data have always been the primary concern in medical applications among hospitals and clinics, and there also exists some applications which need real-time processing in clinic practice. Thus, 3D biomedical image segmentation is typically required to be performed locally (i.e. on the edge) with limited computation and memory resources. In this paper, we propose to combine multi-view ensemble and Surrogate Lagrangian relaxation (SLR) for real-time 3D biomedical image segmentation on the edge. Instead of directly dealing with 3D biomedical images, our segmentation conducts on the three 2D domains of the 3D images with an ensemble strategy. In addition, Surrogate Lagrangian relaxation is proposed to compress the model to enable high efficiency and real-time processing. Experiments on a typical edge Nvidia GPU show that our method achieves real-time processing which is 1.5 × 1.5× faster with an improvement of 9\% 9\% on accuracy compared with single-view models. It also saves 26 × 26× computational resources and 6 × 6× memory resources compared to 3D segmentation models .},
  archive      = {J_NEUCOM},
  author       = {Shanglin Zhou and Xiaowei Xu and Jun Bai and Mikhail Bragin},
  doi          = {10.1016/j.neucom.2022.09.039},
  journal      = {Neurocomputing},
  pages        = {466-481},
  shortjournal = {Neurocomputing},
  title        = {Combining multi-view ensemble and surrogate lagrangian relaxation for real-time 3D biomedical image segmentation on the edge},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural critic learning for tracking control design of
constrained nonlinear multi-person zero-sum games. <em>NEUCOM</em>,
<em>512</em>, 456–465. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive critic method based on neural networks is established to solve the tracking control problem for multi-person zero-sum games with constrained nonlinear dynamics. First, an augmented system is constructed with the tracking error system and the reference system, an appropriate function is introduced to handle the constrained problem, and a constrained tracking Hamilton–Jacobi-Isaacs (HJI) equation is derived for the augmented system. Then, a constrained tracking design with neural critic learning for multi-person zero-sum games is developed to approximately solve the tracking HJI equation with input constraints. A new updating rule is given and only one critic network is employed during neural critic learning. In addition, we prove that the tracking error in the augmented system is uniformly ultimately bounded by using Lyapunov’s direct method. Finally, an example is given to verify the effectiveness of the proposed method. In this example, we make the number of control inputs less than the number of disturbance inputs.},
  archive      = {J_NEUCOM},
  author       = {Menghua Li and Ding Wang and Junfei Qiao},
  doi          = {10.1016/j.neucom.2022.09.103},
  journal      = {Neurocomputing},
  pages        = {456-465},
  shortjournal = {Neurocomputing},
  title        = {Neural critic learning for tracking control design of constrained nonlinear multi-person zero-sum games},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Label prediction based constrained non-negative matrix
factorization for semi-supervised multi-view classification.
<em>NEUCOM</em>, <em>512</em>, 443–455. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised multi-view classification can improve the performance by leveraging the information from both labeled and unlabeled data . But it is often a challenge to capture the information from the unlabeled multi-view data. By analyzing the relation between labeled and unlabeled data under multi-view scenario, we propose a novel model with the ability of leveraging the latent label information from the unlabeled data. In our model, a label prediction (LP) term is proposed to jointly obtain the predicted labels of unlabeled data from multiple views. The LP term is integrated into a constrained non-negative matrix factorization based multi-view framework. In this way, the LP and the multi-view representation learning are integrated into one joint learning problem, where they boost each other. Particularly, the predicted label vector is formulated to be the one-hot vector, such that the labels can be obtained directly. Moreover, we propose a new lemma about the gradient of the ℓ 2 , 1 ℓ2,1 norm in the case of 3-factor matrix decomposition and its corollary about multi-factor matrix decomposition . Based on which, we develop an efficient algorithm and prove its convergence. Experimental results verify that our method can obtain state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Naiyao Liang and Zuyuan Yang and Zhenni Li and Shengli Xie},
  doi          = {10.1016/j.neucom.2022.09.087},
  journal      = {Neurocomputing},
  pages        = {443-455},
  shortjournal = {Neurocomputing},
  title        = {Label prediction based constrained non-negative matrix factorization for semi-supervised multi-view classification},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ELFpm: A machine learning framework for industrial machines
prediction of remaining useful life. <em>NEUCOM</em>, <em>512</em>,
420–442. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The topic of predictive maintenance has great relevance in the search for the rationalization and efficiency of the industrial plants in the context of Industry 4.0. Monitoring equipment parameters and identifying behavior changes that recognize a future failure allows for anticipation of maintenance while avoiding unnecessary preventive maintenance. There are numerous studies in the literature towards the prediction of the maintenance needs of various types of equipment. However, a piece of equipment may have different behavior depending on the conditions of use or the operating environment. Thus, tools to adjust prediction algorithms to new environments are necessary. This article proposes a framework called ELFpm, designed to predict equipment failures, regardless of location or condition of use. This framework introduces an ontology to store the statistics generated by the prediction algorithms and propose a novel suitability index that selects the appropriate prediction algorithm considering the current status of the equipment. The evaluation of ELFpm considers an engine failure scenario. Results show that ELFpm can predict failures up to three hours before they occur.},
  archive      = {J_NEUCOM},
  author       = {Jovani Dalzochio and Rafael Kunst and Jorge Luis Victória Barbosa and Henrique Damasceno Vianna and Gabriel de Oliveira Ramos and Edison Pignaton and Alecio Binotto and Jose Favilla},
  doi          = {10.1016/j.neucom.2022.09.083},
  journal      = {Neurocomputing},
  pages        = {420-442},
  shortjournal = {Neurocomputing},
  title        = {ELFpm: A machine learning framework for industrial machines prediction of remaining useful life},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Network based on the synergy of knowledge and context for
natural language inference. <em>NEUCOM</em>, <em>512</em>, 408–419. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of natural language inference (NLI) is to judge the logical relationship between sentence pairs, including entailment, contradiction, and neutral. At present, many researchers have shown that the introduction of external knowledge is helpful for NLI. However, the existing models are not effective enough for the utilization of knowledge information and not sufficient for the exploration of context information. In this paper, we propose a multi-branch network based on the synergy of knowledge and context. It applies two kinds of information synergy in the way that both knowledge information and context information promote performance improvement while modeling their separately in independent branches. In the context branch, we present a multi-level and dynamic assisted attention to construct sufficient interaction between sentence pairs. In the knowledge branch, we design a Knowledge-based Graph Attention Network (K-GAT) to capture the structural information of the knowledge, and the attention mechanism is used for knowledge interaction. In addition, for strengthening the relation between sentence pairs, we provide a relation branch to capture the context and knowledge relations of sentence pairs. In order to avoid introducing redundant external knowledge as much as possible, we adopt the introduction of five selected semantic dependencies based knowledge types. Experiments show that our model achieves strong competitive results on all three popular NLI datasets.},
  archive      = {J_NEUCOM},
  author       = {Huiyan Wu and Jun Huang},
  doi          = {10.1016/j.neucom.2022.09.086},
  journal      = {Neurocomputing},
  pages        = {408-419},
  shortjournal = {Neurocomputing},
  title        = {Network based on the synergy of knowledge and context for natural language inference},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Multi-scale graph learning for ovarian tumor segmentation
from CT images. <em>NEUCOM</em>, <em>512</em>, 398–407. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ovarian cancer is the gynecological malignant tumor with low early diagnosis rate and high mortality. Automated and reliable segmentation of ovarian tumor plays an essential role in ovarian cancer radiotherapy, which assists radiologists to assess cancer progresses and make fast therapeutic schedules. However, ovarian cancer is characterized by polycentric tumors and the tumors are irregular in size, which makes the tumor segmentation task challenging. In this paper, a multi-scale graph learning U-Net (MGLU-Net) is proposed for ovarian tumor segmentation. The network adopts an encoder-decoder architecture as the basic backbone. The feature maps of different scales generated by the encoder are projected into graphs with different sizes. On this basis, the graph learning module is designed to jointly exploit local information and long-range dependencies among ovarian tumors at different locations. Meanwhile, multiple graphs with different sizes are constructed to handle the size variation problem. A channel attention module is further designed to highlight the informative features from the channel domain. Extensive experiments are conducted on a real ovarian CT image dataset and Sliver07 challenge dataset. Experiments demonstrate that the proposed method shows superior performance than the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Zihang Liu and Chunhui Zhao and Yan Lu and Yu Jiang and Jingtian Yan},
  doi          = {10.1016/j.neucom.2022.09.093},
  journal      = {Neurocomputing},
  pages        = {398-407},
  shortjournal = {Neurocomputing},
  title        = {Multi-scale graph learning for ovarian tumor segmentation from CT images},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A methodical interpretation of adaptive robotics: Study and
reformulation. <em>NEUCOM</em>, <em>512</em>, 381–397. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent development of industrial manufacturing and social services has witnessed a significant trend of automation and intelligentization due to the wide application of robots and the technology of artificial intelligence (AI). While robots liberate humans from tedious and dangerous work in hazardous environments, AI simplifies the programming of robots by automatically inferring patterns and models from the interaction between the robots and the environment. Nevertheless, the application of robots and AI to more general manufacturing and social tasks is still limited by the lack of flexibility and adaptability to the changes in the task and the environment. Thus, a new concept, adaptive robotics, has been proposed to address the desire that an AI-powered robot should be able to properly reprogram itself to these changes without human intervention. Nevertheless, this concept is yet too abstract to provide any specific guidance to the development of robot programs. In this paper, we attempt to provide methodical redefinition and reformulation of adaptive robotics both in conceptual and mathematical manners based on the study of previous results. First of all, we introduce the essential motivation and the conceptual origination of adaptability of mechanical systems. Then, we review the previous literature and explore the related work of adaptive robotics. Based on this, we provide a uniform mathematical formulation of adaptive robotics based on adaptive and robust Markov-decision process (MDP). Through this work, we attempt to inspire the generic framework of adaptive robotics incorporating the existing immature paradigms, by which we are aiming at a clarified and well-defined context of adaptive robotics for future research on related domains.},
  archive      = {J_NEUCOM},
  author       = {Amir M. Soufi Enayati and Zengjie Zhang and Homayoun Najjaran},
  doi          = {10.1016/j.neucom.2022.09.114},
  journal      = {Neurocomputing},
  pages        = {381-397},
  shortjournal = {Neurocomputing},
  title        = {A methodical interpretation of adaptive robotics: Study and reformulation},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on machine learning models for financial time
series forecasting. <em>NEUCOM</em>, <em>512</em>, 363–380. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial time series (FTS) are nonlinear, dynamic and chaotic. The search for models to facilitate FTS forecasting has been highly pursued for decades. Despite major related challenges, there has been much interest in this topic, and many efforts to forecast financial market pricing and the average movement of various financial assets have been implemented. Researchers have applied different models based on computer science and economics to gain efficient information and earn money through financial market investment decisions. Machine learning (ML) methods are popular and successful algorithms applied in the FTS domain. This paper provides a timely review of ML’s adoption in FTS forecasting. The progress of FTS forecasting models using ML methods is systematically summarized by searching articles published from 2011 to 2021. Focusing on the analysis of ML methods applied to the theoretical basis and empirical application of FTS data forecasting, this paper provides a relevant reference for FTS forecasting and interdisciplinary fusion research against the background of computational intelligence and big data. The literature survey reveals that the most commonly used models for prediction involve long short-term memory (LSTM) and hybrid methods. The main contribution of this paper is not only building a systematic program to compare the merits and demerits of specific FTS forecasting models but also detecting the importance and differences of each model to help researchers and practitioners make good choices. In addition, the limitations to be addressed and future research directions of ML models’ adoption in FTS forecasting are identified.},
  archive      = {J_NEUCOM},
  author       = {Yajiao Tang and Zhenyu Song and Yulin Zhu and Huaiyu Yuan and Maozhang Hou and Junkai Ji and Cheng Tang and Jianqiang Li},
  doi          = {10.1016/j.neucom.2022.09.003},
  journal      = {Neurocomputing},
  pages        = {363-380},
  shortjournal = {Neurocomputing},
  title        = {A survey on machine learning models for financial time series forecasting},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SelfNet: A semi-supervised local fisher discriminant network
for few-shot learning. <em>NEUCOM</em>, <em>512</em>, 352–362. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning, employing small-scale labeled samples to recognize new objects, has received substantial research interest. The prototypical network (ProtoNet) is a simple yet effective meta -learning method to solve this problem. In the few-shot scenario, however, the scarcity of data usually has a negative impact on the representational ability of prototypes. In this paper, a unique semi-supervised few-shot learning architecture, referred to as Semi-supervised local Fisher discriminant network (SelfNet), which integrates few-shot learning with subspace learning, is proposed. Using the union of the support set and the additional unlabeled set, a feature projection module is constructed to achieve the subspace projection. Additionally, a pseudo-labeling strategy, which adds the unlabeled samples with high prediction confidence to the support set, is employed to refine the original prototypes. Experimental results on two few-shot classification benchmarks demonstrate that SelfNet can achieve superior performance to the state-of-the-arts, indicating the benefits of utilizing unlabeled samples for feature projection.},
  archive      = {J_NEUCOM},
  author       = {Rui Feng and Hongbing Ji and Zhigang Zhu and Lei Wang},
  doi          = {10.1016/j.neucom.2022.09.012},
  journal      = {Neurocomputing},
  pages        = {352-362},
  shortjournal = {Neurocomputing},
  title        = {SelfNet: A semi-supervised local fisher discriminant network for few-shot learning},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Multi-embedding space set-kernel and its application to
multi-instance learning. <em>NEUCOM</em>, <em>512</em>, 339–351. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Set-level problems become critical when we are interested in animals in pictures, links in web pages, and components in drugs. The key issue is to measure the similarity between two sets. This paper develops a data-dependent multi-embedding space set-kernel (MSK) with close to linear time complexity and applies it to multi-instance learning (MIL), which is a typical set-level problem. The majority of current set-kernels are independent of the underlying data distribution. In contrast, MSK indirectly measures set similarity by determining the relationship between embedding vectors. Each set’s embedding vectors are new representations with controlled dimensionality in the multi-embedding space. Multi-embedding space is described here as a set containing multiple subspaces based on the distribution of the data set. In addition, the MSK feature map is used to speed up the computation of similarity over the entire data set. Extensive experiments were done on 46 MIL data sets across five application domains. The results demonstrate that MSK has the lowest average classification loss and the highest stability compared with the rival set-kernels. The linear time complexity is also verified. Source codes are available at https://github.com/InkiInki/MSK .},
  archive      = {J_NEUCOM},
  author       = {Mei Yang and Yu-Xuan Zhang and Zhengchun Zhou and Wen-Xi Zeng and Fan Min},
  doi          = {10.1016/j.neucom.2022.09.067},
  journal      = {Neurocomputing},
  pages        = {339-351},
  shortjournal = {Neurocomputing},
  title        = {Multi-embedding space set-kernel and its application to multi-instance learning},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Motifs-based recommender system via hypergraph convolution
and contrastive learning. <em>NEUCOM</em>, <em>512</em>, 323–338. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the strategy of leveraging various motifs to model social semantic information and using self-supervised learning tasks to boost recommendation performance has been proven to be very promising. In this paradigm, each channel describes a common motif (e.g., a triangular social motif) via hypergraph convolution. Richer motifs can be encoded through multiple channels, and self-supervised learning can leverage this multichannel information to build self-supervised tasks (such as contrastive learning tasks), which can greatly improve the recommendation performance in scenarios without enough data labels. However, accurately determining the relationships between different channels and fully utilizing them, while maintaining the uniqueness of each channel, is a problem that has not been well studied or resolved in this field. This paper explores and verifies the disadvantages of directly constructing contrastive learning tasks on different channels with practical experiments and proposes a scheme of interactive modeling and matching representation across different channels. This is the first such attempt in the field of recommender systems , and we believe that this paper will inspire future self-supervised learning research based on multichannel information. To solve this problem, we propose a cross-motif matching representation model based on attentive interaction, which can efficiently model the relationships between cross-motif information. Based on this, we also propose a hierarchical self-supervised learning model that realizes self-supervised learning within and between channels, respectively, which improves the ability of self-supervised learning tasks to autonomously mine different levels of potential information. We have conducted abundant experiments, and various metrics on multiple public datasets show that the method proposed in this paper significantly outperforms the state-of-the-art methods, regardless of the general or cold-start scenario. In the model variant analysis experiment, the benefits of the cross-motif matching representation model and the hierarchical self-supervised model proposed in this paper are also fully verified.},
  archive      = {J_NEUCOM},
  author       = {Yundong Sun and Dongjie Zhu and Haiwen Du and Zhaoshuo Tian},
  doi          = {10.1016/j.neucom.2022.09.102},
  journal      = {Neurocomputing},
  pages        = {323-338},
  shortjournal = {Neurocomputing},
  title        = {Motifs-based recommender system via hypergraph convolution and contrastive learning},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A two-stage deep learning model based on feature combination
effects. <em>NEUCOM</em>, <em>512</em>, 307–322. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning currently provides the best solutions in various industries involving tremendous data, such as object recognition and intrusion detection . In deep learning models , the quality and volume of data are two of the factors that determine task performance. This study concentrates on utilizing high-quality data to simultaneously improve the efficiency and accuracy of deep networks. This paper proposes a two-stage learning model that aims to generate high-quality data with reduced features during the first stage. Then, the selected data subset is regarded as the input in the second stage, i.e., the deep learning stage. However, most existing feature selection methods neglect the combination effect induced by integrated feature subsets. A correlation information entropy-based approach is developed to evaluate the integrated non-linear subspace. Experiments are carried out on six well-known classification datasets. The results indicate that our proposed two-stage learning model performs better than the compared high-dimensional deep learning models in speeding up the learning process and improving classification accuracy . Moreover, our developed feature selection method outperforms state-of-the-art feature selection techniques in terms of time consumption and classification accuracy when combined with three deep learning models.},
  archive      = {J_NEUCOM},
  author       = {Xuyang Teng and Yunxiao Zhang and Meilin He and Meng Han and Erxiao Liu},
  doi          = {10.1016/j.neucom.2022.09.082},
  journal      = {Neurocomputing},
  pages        = {307-322},
  shortjournal = {Neurocomputing},
  title        = {A two-stage deep learning model based on feature combination effects},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Action recognition based on RGB and skeleton data sets: A
survey. <em>NEUCOM</em>, <em>512</em>, 287–306. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action recognition is a major branch of computer vision research. As a widely used technology, action recognition has been applied to human–computer interaction, intelligent pension, and intelligent transportation system . Because of the explosive growth of action recognition related methods, the performance of action recognition on many difficult data sets has improved significantly. In terms of the different data sets used for action recognition, action recognition can mainly be divided into RGB-based action recognition method and skeleton-based action recognition method. The former method can take advantage of the prior knowledge of image recognition. However, it has high requirements for computing power and storage ability, and it is difficult to avoid the influence of irrelevant background and illumination. In contrast, the latter method’s calculation amount and required storage space are reduced significantly. However, it lacks context information that is useful for action recognition. This review provides a comprehensive description of these two methods, covering the milestone algorithms, the state-of-the-art algorithms, the commonly used data sets, evaluation metrics , challenges, and promising future directions. So far as we know, this work is the first survey covering traditional methods of action recognition, RGB-based end-to-end action recognition method, pose estimation, and skeleton-based action recognition in one review. This survey aims to help scholars who study action recognition technology to systematically learn action recognition technology, select data sets, understand current challenges, and choose promising future research directions.},
  archive      = {J_NEUCOM},
  author       = {Rujing Yue and Zhiqiang Tian and Shaoyi Du},
  doi          = {10.1016/j.neucom.2022.09.071},
  journal      = {Neurocomputing},
  pages        = {287-306},
  shortjournal = {Neurocomputing},
  title        = {Action recognition based on RGB and skeleton data sets: A survey},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online active learning for an evolving fuzzy neural
classifier based on data density and specificity. <em>NEUCOM</em>,
<em>512</em>, 269–286. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolving fuzzy neural classifiers are incremental, adaptive models that use new samples to update the architecture and parameters of the models with new incoming data samples, typically occurring in form of data streams for classification problems. Most of the techniques assume that the target labels are permanently given as updating their structures and parameters in a fully supervised manner. This paper aims to implement ideas based on the concept of active learning in order to select the data most relevant for updating the model. This may greatly reduce annoying and costly labeling efforts for users/operators in an online system. Therefore, we propose an online active learning (oAL) methodology, which is closely linked to the internal evolving learning engine for fuzzy neurons, which is based on incremental data-cloud formation. It is thus based on the evaluation of the specificity of the current clouds, and especially by the change in their specificity with new (unsupervised) samples, in order to identify those samples carrying relevant information to the update of previously formed clouds. This is combined with the unsupervised cloud evolution criterion, which upon its fulfillment indicates a new knowledge contained in the data for which the class response needs to be known (thus should be selected for labeling feedback). In synergy to the evolving fuzzy neural classifier, it acts in an incremental single-pass manner, not using any past samples, which makes it extremely fast, as only fuzzy neurons attached to a new sample need to be checked for the degree of their specificity change. To prove the technique’s efficiency, tests with binary classification streams commonly used by the machine learning community were conducted for evaluation purposes. The number of supervised samples for model updates could be significantly reduced with a low or even negligible decrease in the classification accuracy trends, while a random selection of samples (with the same percentages as selected by our oAL approach) showed large performance downtrends. Furthermore, a very similar number of rule evolution trends could be observed with different percentages of selected samples, which indicates good robustness of our method with respect to knowledge extraction (as non-changing).},
  archive      = {J_NEUCOM},
  author       = {Paulo Vitor de Campos Souza and Edwin Lughofer},
  doi          = {10.1016/j.neucom.2022.09.133},
  journal      = {Neurocomputing},
  pages        = {269-286},
  shortjournal = {Neurocomputing},
  title        = {Online active learning for an evolving fuzzy neural classifier based on data density and specificity},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-stream transformer network for sensor-based human
activity recognition. <em>NEUCOM</em>, <em>512</em>, 253–268. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Activity Recognition (HAR) based on wearable devices has always been a hot topic in health applications, human-object interaction, and smart homes. Despite significant improvements achieved by convolutional neural networks , long short-term memory networks, transformer networks and various hybrid models, there are still two fundamental issues. First, the spatial–temporal dependencies of sensor signals are difficult to be effectively modeled. Second, in multimodal environments, sensors placed on various body positions contribute distinctly to the classification results . In this work, we propose a self-attention based Two-stream Transformer Network (TTN). In view of the former issue, we use two streams, named temporal stream and spatial stream , respectively, to extract the readings-over-time and time-over-readings features from sensor signals. These features extracted from two streams are complementary since the time-over-readings features are able to express additional information which cannot be captured from sensor signals directly. To deal with the latter issue, we assign attention weights to each sensor axis in the spatial channel based on their classification scores. It makes sense that different axis-readings with distinct recognition contributions caused by data heterogeneity be treated unequally. Extensive experiments on four available benchmark datasets (PAMAP2, Opportunity, USC–HAD, and Skoda) reveal that our proposed model is better suited for multimodal HAR than previous state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Shuo Xiao and Shengzhi Wang and Zhenzhen Huang and Yu Wang and Haifeng Jiang},
  doi          = {10.1016/j.neucom.2022.09.099},
  journal      = {Neurocomputing},
  pages        = {253-268},
  shortjournal = {Neurocomputing},
  title        = {Two-stream transformer network for sensor-based human activity recognition},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonstationary data stream classification with online active
learning and siamese neural networks✩. <em>NEUCOM</em>, <em>512</em>,
235–252. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have witnessed in recent years an ever-growing volume of information becoming available in a streaming manner in various application areas. As a result, there is an emerging need for online learning methods that train predictive models on-the-fly. A series of open challenges, however, hinder their deployment in practice. These are, learning as data arrive in real-time one-by-one, learning from data with limited ground truth information, learning from nonstationary data, and learning from severely imbalanced data , while occupying a limited amount of memory for data storage. We propose the ActiSiamese algorithm, which addresses these challenges by combining online active learning, siamese networks , and a multi-queue memory. It develops a new density-based active learning strategy which considers similarity in the latent (rather than the input) space. We conduct an extensive study that compares the role of different active learning budgets and strategies, the performance with/without memory, the performance with/without ensembling, in both synthetic and real-world datasets, under different data nonstationarity characteristics and class imbalance levels. ActiSiamese outperforms baseline and state-of-the-art algorithms, and is effective under severe imbalance, even only when a fraction of the arriving instances’ labels is available. We publicly release our code to the community.},
  archive      = {J_NEUCOM},
  author       = {Kleanthis Malialis and Christos G. Panayiotou and Marios M. Polycarpou},
  doi          = {10.1016/j.neucom.2022.09.065},
  journal      = {Neurocomputing},
  pages        = {235-252},
  shortjournal = {Neurocomputing},
  title        = {Nonstationary data stream classification with online active learning and siamese neural networks✩},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). D-NMS: A dynamic NMS network for general object detection.
<em>NEUCOM</em>, <em>512</em>, 225–234. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-maximum Suppression (NMS), which is used to find the optimal inferences among all candidate bounding boxes, is a significant post-processing step in most state-of-the-art object detectors. The fixed threshold scheme in the standard NMS equally treats each input image, which leads to the neglect of uniqueness. Recently, several adaptive NMS methods have been proposed and demonstrated to be superior to the standard NMS with a fixed threshold. However, the adaptability performance of these methods is limited due to the deficiency of measuring the complexity of the input image. In this paper, we propose a dynamic NMS network (D-NMS net) to predict the best NMS threshold for each input image, which can be embedded into most state-of-the-art single-stage object detectors. Concretely, we first propose a unified scene complexity definition for a single image according to the relationship between the P-R curve and the changing NMS threshold. Secondly, we calculate the optimal NMS threshold for each image according to the proposed definition, which is then applied as the supervision label in the training stage. Lastly, we embed the lightweight regression network, D-NMS net, into the mainstream object detectors. Extensive experiments are conducted on challenging datasets. With the help of our D-NMS net, the accuracy and efficiency of detectors have achieved obvious improvements. On Pascal VOC, the mean Average Precision (mAP) of RetinaNet is boosted from 81.60\% to 84.74\%, and the mAP of FCOS is improved from 79.12\% to 84.20\%. On MS-COCO, the Average Precision(AP) of RetinaNet is boosted from 36.4\% to 38.5\%, and the AP of FCOS is improved from 37.2\% to 39.1\%. Meanwhile, the inference speed of our method is increased by 62\% at most.},
  archive      = {J_NEUCOM},
  author       = {Hao Zhao and Jikai Wang and Deyun Dai and Shiqi Lin and Zonghai Chen},
  doi          = {10.1016/j.neucom.2022.09.080},
  journal      = {Neurocomputing},
  pages        = {225-234},
  shortjournal = {Neurocomputing},
  title        = {D-NMS: A dynamic NMS network for general object detection},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic detection of alzheimer’s disease progression: An
efficient information fusion approach with heterogeneous ensemble
classifiers. <em>NEUCOM</em>, <em>512</em>, 203–224. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting Alzheimer’s disease (AD) progression is crucial for improving the management of this chronic disease. Usually, data from AD patients are multimodal and time series in nature. This study proposes a novel ensemble learning framework for AD progression incorporating heterogeneous base learners into an integrated model using the stacking technique. This framework is used to build a 4-class ensemble classifier , which predicts AD progression 2.5 years in the future based on the multimodal time-series data. Statistical measures have been extracted from the longitudinal data to be used by the conventional machine learning models . The examined ensemble members include k-nearest neighbor, extreme gradient boosting , support vector machine , random forest , decision tree , and multilayer perceptron . We utilize three time-series modalities and one static non-time series modality of 1371 subjects from the Alzheimer’s disease neuroimaging initiative (ADNI) to validate our model. Several homogeneous and heterogeneous combinations of ensemble members were implemented, and their performance compared. The balance between accuracy and diversity when selecting ensemble members was investigated. We found that both accuracy and diversity are equally critical metrics to obtain an optimal ensemble model. Furthermore, our testing showed that the proposed model achieves outstanding progression prediction performance. The proposed model achieved a high performance without using neuroimaging data , which means that the model could be implemented in low-cost healthcare environments. The proposed model has achieved superior results compared with the state-of-the-art techniques in Alzheimer’s and ensemble classifiers domains. The proposed framework can be used to implement efficient information fusion ensembles for other medical and non-medical problems.},
  archive      = {J_NEUCOM},
  author       = {Shaker El-Sappagh and Farman Ali and Tamer Abuhmed and Jaiteg Singh and Jose M. Alonso},
  doi          = {10.1016/j.neucom.2022.09.009},
  journal      = {Neurocomputing},
  pages        = {203-224},
  shortjournal = {Neurocomputing},
  title        = {Automatic detection of alzheimer’s disease progression: An efficient information fusion approach with heterogeneous ensemble classifiers},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HyperNTF: A hypergraph regularized nonnegative tensor
factorization for dimensionality reduction. <em>NEUCOM</em>,
<em>512</em>, 190–202. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor decomposition is an effective tool for learning multi-way structures and heterogeneous features from high-dimensional data, such as the multi-view images and multichannel electroencephalography (EEG) signals, are often represented by tensors. However, most of tensor decomposition methods are the linear feature extraction techniques, which are unable to reveal the nonlinear structure within high-dimensional data. To address such problem, a lot of algorithms have been proposed for simultaneously performs linear and non-linear feature extraction. A representative algorithm is the Graph Regularized Nonnegative Matrix Factorization (GNMF) for image clustering. However, the normal 2-order graph can only model the pairwise similarity of objects, which cannot sufficiently exploit the complex structures of samples. Thus, we propose a novel method, named Hypergraph Regularized Nonnegative Tensor Factorization (HyperNTF), which utilizes hypergraph to model the complex connections among samples and employs the factor matrix corresponding with last mode of Canonical Polyadic (CP) decomposition as low-dimensional representation of original data. Extensive experiments on synthetic manifolds, real-world image datasets, and EEG signals, demonstrating that HyperNTF outperforms the state-of-the-art methods in terms of dimensionality reduction, clustering, and classification.},
  archive      = {J_NEUCOM},
  author       = {Wanguang Yin and Youzhi Qu and Zhengming Ma and Quanying Liu},
  doi          = {10.1016/j.neucom.2022.09.036},
  journal      = {Neurocomputing},
  pages        = {190-202},
  shortjournal = {Neurocomputing},
  title        = {HyperNTF: A hypergraph regularized nonnegative tensor factorization for dimensionality reduction},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A neurodynamic optimization approach to nonconvex resource
allocation problem. <em>NEUCOM</em>, <em>512</em>, 178–189. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A neurodynamic optimization approach characterized by a negative subgradient flow (NSF) is proposed to solve distributed nonconvex resource allocation problem (DNRAP). Under some mild assumptions, it is proved that the state solutions of the proposed approach converge to the critical point set of the considered DNRAP. Moreover, benefiting from the well-known nonsmooth Lojasiewicz inequality, analysis results show that the state solutions converge toward a critical point (not set) of the considered DNRAP. The convergence rate of the state solution, including exponential or finite-time convergence, can be evaluated through the quantitative calculation of Lojasiewicz exponent. Furthermore, we assess the related Lojasiewicz exponent of presented NSF in some special situation, for instance, in nonconvex quadratic programming . Finally, simulation illustrates the well performance of presented neurodynamic optimization approach.},
  archive      = {J_NEUCOM},
  author       = {Yiyuan Chai and Guocheng Li and Sitian Qin and Jiqiang Feng and Chen Xu},
  doi          = {10.1016/j.neucom.2022.09.044},
  journal      = {Neurocomputing},
  pages        = {178-189},
  shortjournal = {Neurocomputing},
  title        = {A neurodynamic optimization approach to nonconvex resource allocation problem},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Randomized high order fuzzy cognitive maps as reservoir
computing models: A first introduction and applications.
<em>NEUCOM</em>, <em>512</em>, 153–177. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy Cognitive Maps (FCMs) have emerged as an interpretable signed weighted digraph method consisting of nodes (concepts) and weights which represent the dependencies among the concepts. Although FCMs have attained considerable achievements in various time series prediction applications, designing an FCM model with time-efficient training method is still an open challenge. Thus, this paper introduces a novel univariate time series forecasting technique, which is composed of a group of randomized high order FCM models labeled R-HFCM. The novelty of the proposed R-HFCM model is relevant to merging the concepts of FCM and Echo State Network (ESN) as an efficient and particular family of Reservoir Computing (RC) models, where the least squares algorithm is applied to train the model. From another perspective, the structure of R-HFCM consists of the input layer, reservoir layer, and output layer in which only the output layer is trainable while the weights of each sub-reservoir components are selected randomly and kept constant during the training process. As case studies, in this paper we consider solar energy forecasting with public data for Brazilian solar stations, hourly electric load of the power supply company of the city of Johor in Malaysia, solar energy dataset from United States National Renewable Energy Laboratory (NREL), electric load data from the Global Energy Forecasting Competition 2012 (GEFCom 2012), and PJM hourly energy consumption data. The experiments also include the effect of the map size, activation function , the number of order and the size of the reservoir on the accuracy of R-HFCM method. The obtained results confirm the outperformance of the proposed R-HFCM model in comparison to the other methods. This study provides evidence that FCM can be a new way to implement a reservoir of dynamics in time series modeling. The Python code of the model is publicly available for research replication.},
  archive      = {J_NEUCOM},
  author       = {Omid Orang and Petrônio Cândido de Lima e Silva and Rodrigo Silva and Frederico Gadelha Guimarães},
  doi          = {10.1016/j.neucom.2022.09.030},
  journal      = {Neurocomputing},
  pages        = {153-177},
  shortjournal = {Neurocomputing},
  title        = {Randomized high order fuzzy cognitive maps as reservoir computing models: A first introduction and applications},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Few-shot learning-based RGB-d salient object detection: A
case study. <em>NEUCOM</em>, <em>512</em>, 142–152. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D salient object detection (SOD) aims at detecting general attention-grabbing objects from paired RGB and depth image inputs, and recently has attracted increasing research attention. Despite that many advanced RGB-D SOD models are proposed, almost all of them focus on developing models in a fully supervised manner with a small training dataset that typically has only hundreds of RGB-D samples. This may inevitably incur poor generalizability of these models when being applied to real-world scenarios and applications. To narrow such a gap, we make the first attempt of treating RGB-D SOD as a few-shot learning (FSL) problem, and improve it by introducing extra prior knowledge from a closely related task, i.e., RGB SOD. Inspired by the general taxonomy of FSL techniques, we investigate from two perspectives, namely model and data, of transferring additional knowledge from the RGB SOD dataset to enhance RGB-D SOD performance. For the former, we employ multi-task learning with parameter sharing to constrain the model space, whereas for the latter, we propose to generate the depth from RGB by using an off-the-shelf depth estimator. Representative middle-fusion and late-fusion models are trialed and validated under such a FSL setup. Our experimental results and analyses confirm the feasibility of promoting RGB-D SOD via FSL techniques, while comparative study on different FSL techniques and detection strategies is conducted. We hope this work can serve as a catalyst for bringing RGB-D saliency detection into real applications, as well as for inspiring future works that apply few-shot learning to saliency detection and other multi-modal detection tasks.},
  archive      = {J_NEUCOM},
  author       = {Keren Fu and Jing He and Xiao Yang},
  doi          = {10.1016/j.neucom.2022.09.019},
  journal      = {Neurocomputing},
  pages        = {142-152},
  shortjournal = {Neurocomputing},
  title        = {Few-shot learning-based RGB-D salient object detection: A case study},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Markovian policy network for efficient robot learning.
<em>NEUCOM</em>, <em>512</em>, 130–141. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {What poses a challenge for robot learning is the fact that considerable training samples and time are required to find an optimal policy in the high-dimensional robot state space. To mitigate this problem of robot learning, there is an incentive in incorporating appropriate prior knowledge. In this paper, a novel framework named Markovian Policy Network (MPN) is presented to take full advantage of the structural prior knowledge for robots to achieve efficient robot learning. Specifically, we first make efforts to reveal the Markov Property of the robot, which characterizes the intrinsic prior knowledge for robotic physical structure. Next, the proposed framework is constructed by employing a modified graph neural network to incorporate the Markov Property of the robot into policy networks. By exploiting the structural prior knowledge of robots in our framework, the high-dimensional original state space could be decomposed into several low-dimensional state spaces with conditional independence to realize substantial reductions in the dimensionality of state space. Empirical results on diverse robotic systems including the challenging dexterous manipulation task, demonstrate not only the effectiveness but the robustness of the proposed MPN for robotic skill learning, delivering advancement substantially over traditional policy learning methods.},
  archive      = {J_NEUCOM},
  author       = {Fengyi Zhang and Yurou Chen and Zhiyong Liu},
  doi          = {10.1016/j.neucom.2022.09.059},
  journal      = {Neurocomputing},
  pages        = {130-141},
  shortjournal = {Neurocomputing},
  title        = {Markovian policy network for efficient robot learning},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recognition of characters on curved metal workpiece surfaces
based on multi-exposure image fusion and deep neural networks.
<em>NEUCOM</em>, <em>512</em>, 117–129. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate industry online scene text recognition techniques for character on curved metal-workpieces are investigated. To increase the contrast between the characters and their backgrounds, and to reduce the interactions of corrosion et al., image pyramid fusion method is proposed to synthesize high-quality detail-enhanced images from image sequences with multi-exposure times. With this method, the three most important reflection-related image quality properties: contrast, saturation, and exposure, can be enhanced simultaneously. A Resnet-50 network is then used as a feature extraction network to fuse features from different scales of feature maps, the masks and the envelope contour coordinates of character text lines can then be obtained by combining global contextual information through semantic segmentation . Finally, characters included in the irregular text lines are recognized with an attention mechanism-based text rectification recognition algorithm . The advantages and effectiveness of the proposed method are statistically analyzed with the data from different production lines. Code will be available in https://github.com/HuaxiongWu-ZJLG/CSCM-Recognition.git .},
  archive      = {J_NEUCOM},
  author       = {Zhong Xiang and Huaxiong Wu and Ding Zhou},
  doi          = {10.1016/j.neucom.2022.09.022},
  journal      = {Neurocomputing},
  pages        = {117-129},
  shortjournal = {Neurocomputing},
  title        = {Recognition of characters on curved metal workpiece surfaces based on multi-exposure image fusion and deep neural networks},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Orthogonal multi-view analysis by successive approximations
via eigenvectors. <em>NEUCOM</em>, <em>512</em>, 100–116. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Orthogonality has been demonstrated to admit many desirable properties such as noise-tolerant, good for data visualization, and preserving distances. However, it is often incompatible with existing models and the resulting optimization problem is challenging even if compatible. To address these issues, we propose a trace ratio formulation for multi-view subspace learning to learn individual orthogonal projections for all views. The proposed formulation integrates the correlations within multiple views, supervised discriminant capacity, and distance preservation in a concise and compact way. It not only includes several existing models as special cases, but also inspires new models. Moreover, an efficient numerical method based on successive approximations via eigenvectors is presented to solve the associated optimization problem . The method is built upon an iterative Krylov subspace method which can easily scale up for high-dimensional datasets. Extensive experiments are conducted on various real-world datasets for multi-view discriminant analysis and multi-view multi-label classification. The experimental results demonstrate that the proposed models are consistently competitive to and often better than the compared methods.},
  archive      = {J_NEUCOM},
  author       = {Li Wang and Lei-Hong Zhang and Chungen Shen and Ren-Cang Li},
  doi          = {10.1016/j.neucom.2022.09.018},
  journal      = {Neurocomputing},
  pages        = {100-116},
  shortjournal = {Neurocomputing},
  title        = {Orthogonal multi-view analysis by successive approximations via eigenvectors},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variational quantum extreme learning machine.
<em>NEUCOM</em>, <em>512</em>, 83–99. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme learning machine (ELM), with fast training speed and high generalization performance , has been widely used in many fields. However, it becomes inefficient or even impossible to process data with extremely large feature spaces, which is expected to be solved by quantum computing with an exponentially large quantum state space. Here, we propose a novel variational quantum extreme learning machine (VQELM). In detail, we design a special feature mapping method to achieve nonlinear transformation of the input data, replacing the hard-to-construct activation function on quantum devices . Considering that the Harrow-Hassidim-Lloyd algorithm is difficult to solve the ELM parameters on near-term quantum devices , we adopt a variational framework to facilitate implementation on the near-term noisy intermediate scale quantum computer . On both classification and regression tasks , our proposed method outperforms classical ELM in classical simulations. Moreover, the classification tasks achieved on IBM quantum simulator also show comparable classification accuracy . The final analysis shows that our proposed algorithm has an exponential improvement over classical ones for high-dimensional data processing, and is a powerful application of quantum machine learning on near-term quantum devices.},
  archive      = {J_NEUCOM},
  author       = {Yong Wang and Kuo-Yi Lin and Shuming Cheng and Li Li},
  doi          = {10.1016/j.neucom.2022.09.068},
  journal      = {Neurocomputing},
  pages        = {83-99},
  shortjournal = {Neurocomputing},
  title        = {Variational quantum extreme learning machine},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). SiamAGN: Siamese attention-guided network for visual
tracking. <em>NEUCOM</em>, <em>512</em>, 69–82. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most Siamese-based trackers utilize cross-correlation to calculate the similarity scores between the target template and the search image, which may cause the loss of spatial information and lead to inaccurate target estimation. To address this issue, we propose an attention-guided model under the Siamese framework for object tracking, named SiamAGN. Specifically, we combine the template and search image through the proposed feature fusion module. It contains a self-context interaction (SCI) module, cross-context interaction (CCI) module, and target location module (TLM). SCI based on self-attention learns global context by emphasizing channel-wise complementary features. CCI based on cross-attention explores rich dynamic context via the channel interaction between the template and the search image. TLM based on cross-attention reformulates the template according to the pixel-level similarity scores between the template and the search image, which can keep as much spatial information as possible and enable our model to predict more precise bounding boxes. Extensive experimental results on the GOT10k, OTB100, VOT2016, VOT2018, UAV123 , and LaSOT benchmarks indicate that the proposed tracker SiamAGN achieves competitive performance compared with state-of-the-art trackers.},
  archive      = {J_NEUCOM},
  author       = {Bingbing Wei and Hongyu Chen and Qinghai Ding and Haibo Luo},
  doi          = {10.1016/j.neucom.2022.09.066},
  journal      = {Neurocomputing},
  pages        = {69-82},
  shortjournal = {Neurocomputing},
  title        = {SiamAGN: Siamese attention-guided network for visual tracking},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Realistic acceleration of neural networks with fine-grained
tensor decomposition. <em>NEUCOM</em>, <em>512</em>, 52–68. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the modern deep neural networks (DNNs) have become more and more large-scale and expensive, the topic of DNN compression grows into a hot direction nowadays. Among variant compression methods, tensor decomposition seems to be the most promising and low-cost one because of its solid mathematical foundations and regular data structure . However, most of the existing tensor decompositions are not very good at accelerating DNNs, because there are always necessary transpositions on tensor modes to make the input data calculate with the decomposed factor tensors correctly, and transposition will bring extra memory and time cost for the realistic system without doubt. In this paper, we select a relatively novel Kronecker CANDECOMP/PARAFAC (KCP) tensor decomposition which has fine-grained factor tensors, and propose the transposition-free algorithm to calculate the contractions between the input data and the neural weight in KCP format. The theoretically analysis of computation complexity indicates that the proposed method is much more efficient than the existing algorithms. We further prove that the training complexity of KCP-DNN based on the proposed transposition-free algorithm can also be faster than the traditional ones, and make a comprehensive comparison of space and computation complexity including training and inference stages to show the superiority of our method. As a series of related works pay more attention to the recurrent neural networks (RNNs), we follow these existing practices and focus on the KCP-RNN to make a comprehensive comparison with them, and the experimental results show our KCP-RNN with transposition-free algorithm has systematically advantages including accuracy, space complexity, computation complexity, and realistic running time. Besides, some advanced characteristics of KCP-DNN such as collocation of ranks, have also been discussed.},
  archive      = {J_NEUCOM},
  author       = {Rui Lv and Dingheng Wang and Jiangbin Zheng and Yefan Xie and Zhao-Xu Yang},
  doi          = {10.1016/j.neucom.2022.09.057},
  journal      = {Neurocomputing},
  pages        = {52-68},
  shortjournal = {Neurocomputing},
  title        = {Realistic acceleration of neural networks with fine-grained tensor decomposition},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FPFS: Filter-level pruning via distance weight measuring
filter similarity. <em>NEUCOM</em>, <em>512</em>, 40–51. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) enjoy the welfare of convolution, while also bearing huge computational pressure. Therefore, model compression techniques are used to alleviate this problem, where filter-based neural network has received extensive attention as the research object of this paper. Common approaches treat filters as independent individuals and choose retrained filters by evaluating their performance, while more complex macro methods consider relationship between filters. Therefore, we propose a facile distance-based filter selection method, called FPFS, to visualize the similarity between filters from a global perspective. We calculate and sum the distance between filters to get filters’ “Distance Weight” which is applied as a metric to assess filters. We use four common and appropriate distances for filters evaluation. To verify the performance of our algorithm, we introduce FPFS to classical DCNNs and test it on general classification datasets CIFAR-10, CIFAR-100 and mageNet. For example, FPFS reduces Parameters and FLOPs of the lightweight model DenseNet-40 to about half of the original while maintain accuracy on CIFAR-10 by 94.40\% (the original model is 94.80\%). To ResNet-56 on CIFAR-100, FPFS compresses FLOPs to less than half of the original, while model accuracy reaches 71.46\% (the original model is 71.44\%). About ResNet-50 on ImageNet, FPFS achieves 60.3\% FLOPs pruning rate accompanied by 0.96\% top-1 accuracy loss. We also compare the experimental results with state-of-the-art filter pruning algorithms to highlight the effectiveness of FPFS.},
  archive      = {J_NEUCOM},
  author       = {Wei Zhang and Zhiming Wang},
  doi          = {10.1016/j.neucom.2022.09.049},
  journal      = {Neurocomputing},
  pages        = {40-51},
  shortjournal = {Neurocomputing},
  title        = {FPFS: Filter-level pruning via distance weight measuring filter similarity},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to localize image forgery using end-to-end
attention network. <em>NEUCOM</em>, <em>512</em>, 25–39. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements have increased the prevalence of digital image tampering. Anyone can manipulate multimedia content using editing software to alter the semantic meaning of images to deceive viewers. Since manipulations appear realistic, both humans and machines face challenges detecting forgeries. We propose a novel algorithm for authenticating visual content by localizing forged regions in this work. Our proposed algorithm employs channel attention convolutional blocks in an end-to-end learning framework. The channel attention infers forged regions in an image by extracting attention-aware multi-resolution features in the spatial domain and features in the frequency domain. Therefore, the proposed network is divided into two subnetworks , for extracting attention-aware multi-resolution features in the spatial and frequency domain. To predict the resulting mask, we concatenate the features of both networks. The proposed channel attention network exclusively focuses on the forged region and increases network generalization capabilities on unseen manipulations. Rigorous experiments demonstrate that the proposed algorithm outperforms state-of-the-art methods on five benchmark datasets for localizing a wide range of manipulations.},
  archive      = {J_NEUCOM},
  author       = {Iyyakutti Iyappan Ganapathi and Sajid Javed and Syed Sadaf Ali and Arif Mahmood and Ngoc-Son Vu and Naoufel Werghi},
  doi          = {10.1016/j.neucom.2022.09.060},
  journal      = {Neurocomputing},
  pages        = {25-39},
  shortjournal = {Neurocomputing},
  title        = {Learning to localize image forgery using end-to-end attention network},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). One-shot pruning of gated recurrent unit neural network by
sensitivity for time-series prediction. <em>NEUCOM</em>, <em>512</em>,
15–24. (<a href="https://doi.org/10.1016/j.neucom.2022.09.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep learning models have been successfully adopted in many applications, they are facing challenges to be deployed on energy-limited devices ( e.g. , some mobile devices , etc. ) due to their high computation complexity. In this paper, we focus on reducing the costs of Gated Recurrent Units (GRUs) for time-series prediction tasks and we propose a new pruning method that can recognize and remove the neural connections that have little influence on the network loss, using a controllable threshold on the absolute value of the pre-trained GRU weights. This is different from existing approaches which usually try to find and preserve the connections with large weight values. We further propose a sparse-connection GRU model (SCGRU) that only needs a one-time pruning (with fine-tuning), rather than using multiple prune-retrain cycles. A large number of experimental results demonstrate that the proposed method is able to largely reduce the storage and computation costs while achieving the state-of-arts performance in two datasets. Code is available ( https://github.com/imLingo/SCGRU ).},
  archive      = {J_NEUCOM},
  author       = {Hong Tang and Xiangzheng Ling and Liangzhi Li and Liyan Xiong and Yu Yao and Xiaohui Huang},
  doi          = {10.1016/j.neucom.2022.09.026},
  journal      = {Neurocomputing},
  pages        = {15-24},
  shortjournal = {Neurocomputing},
  title        = {One-shot pruning of gated recurrent unit neural network by sensitivity for time-series prediction},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust deep ensemble method for real-world image denoising.
<em>NEUCOM</em>, <em>512</em>, 1–14. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning-based image denoising methods have achieved promising performance. However, when the distribution of real-world noisy images is unknown, the denoising performance is still limited due to the domain gap between the training set and the testing set. Nonetheless, the unknown noise distribution usually can be modeled as proper combination of existing noise distributions. In this paper, we propose a simple yet effective Bayesian deep ensemble (BDE) method for real-world image denoising , where several representative deep denoisers pre-trained with various training data settings can be fused to improve robustness. The foundation of BDE is that real-world image noises are highly signal-dependent, and heterogeneous noises in a real-world noisy image can be separately handled by different denoisers. In particular, we take well-trained CBDNet, NBNet, HINet, Uformer and GMSNet into denoiser pool, and a U-Net is adopted to predict pixel-wise weighting maps to fuse these denoisers. Instead of solely learning pixel-wise weighting maps, Bayesian deep learning strategy is introduced to predict weighting uncertainty as well as weighting map, by which prediction variance can be modeled for improving robustness on real-world noisy images. Extensive experiments have shown that real-world noises can be better removed by fusing existing denoisers instead of training a big denoiser with expensive cost. Furthermore, our BDE can be extended to other image restoration tasks, i.e. image deblurring, image deraining and single image super-resolution, and also achieves significance gain on benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Pengju Liu and Hongzhi Zhang and Jinghui Wang and Yuzhi Wang and Dongwei Ren and Wangmeng Zuo},
  doi          = {10.1016/j.neucom.2022.09.058},
  journal      = {Neurocomputing},
  pages        = {1-14},
  shortjournal = {Neurocomputing},
  title        = {Robust deep ensemble method for real-world image denoising},
  volume       = {512},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Trust-aware denoising autoencoder with spatial-temporal
activity for cross-domain personalized recommendations. <em>NEUCOM</em>,
<em>511</em>, 477–494. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, cross-domain recommendation systems have been very helpful in improving the quality of recommendation and solving the problem of cold start and data sparsity . Cross-domain recommender systems allow the transfer of knowledge from one domain with dense ratings to other domain with sparse ratings. Such transfer of knowledge helps in addressing the data sparseness and cold start issues in traditional recommender systems . Although cross-domain recommendations have evolved significantly, yet employment of various factors, such as time, trust, and location remains a challenge. Most of the existing approaches ignore the important fact that at what specific time the user may be interested in the recommended item. Moreover, a person’s trust level and sentiments may be influenced by the variation in the location and time, thereby affecting the decision making. In this paper, we propose a cross-domain recommender system that not only takes into account the time at finer granularity levels (e.g., hours, days, weeks, etc.), but also considers a persons location, trust level, and sentiment analysis while computing recommendations. Our proposed model, named as, Trust-Aware Spatial-Temporal Activity based Denoising Autoencoder (TSTDAE), employs autoencoder-based deep-learning models to generate top-N recommendations for a given user and addresses the cold-start problem in the cross-domain scenario of ‘User Overlap’. The proposed work is fivefold: i) Filter out the users’ biased profiles based on sentiment analysis . ii) Learn the features using autoencoder and then perform clustering among the users of source and target domains to discover the best neighbors. iii) Compute the trust and ratio of preference bias between active user (the user to whom top-N items are recommended) and their neighbors and grade the neighbors based on unbiased preferences iv) Project the best time for recommending the items to an active user and generate the top-N recommendations. We have evaluated the proposed model on a public dataset of e-commerce retail service ‘AliExpress’ for the evaluation metrics : Precision, Mean Absolute Precision (MAP), Normalized Discounted Cumulative Gain (NDCG), and Hit Ratio (HR). The experimental results showed improved performance of the proposed system over the existing models.},
  archive      = {J_NEUCOM},
  author       = {Adeel Ahmed and Khalid Saleem and Osman Khalid and Jiechao Gao and Umer Rashid},
  doi          = {10.1016/j.neucom.2022.09.023},
  journal      = {Neurocomputing},
  pages        = {477-494},
  shortjournal = {Neurocomputing},
  title        = {Trust-aware denoising autoencoder with spatial-temporal activity for cross-domain personalized recommendations},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fixed/preassigned-time synchronization for impulsive complex
networks with mismatched parameters. <em>NEUCOM</em>, <em>511</em>,
462–476. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the issue of fixed-time (FT) and preassigned-time (PT) synchronization of impulsive complex networks (ICNs) with mismatched parameters. Firstly, several more succinct conditions are established to achieve FT stability of impulsive systems and an improved estimation for the stable time is given. Subsequently, based on the improved FT stability results, the FT synchronization criteria for ICNs with mismatched parameters are proposed by designing fixed-time controllers without the linear part. Correspondingly, the PT synchronization problem is also considered by developing several innovative control protocols, where the synchronized time can be arbitrary predefined according to task demands and the control gains are bounded. Ultimately, the presented synchronization criteria are verified by numerical simulation.},
  archive      = {J_NEUCOM},
  author       = {Lu Pang and Cheng Hu and Juan Yu and Leimin Wang and Haijun Jiang},
  doi          = {10.1016/j.neucom.2022.09.016},
  journal      = {Neurocomputing},
  pages        = {462-476},
  shortjournal = {Neurocomputing},
  title        = {Fixed/preassigned-time synchronization for impulsive complex networks with mismatched parameters},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-empirical dynamics modeling of a bicycle robot based on
feature selection and RHONN. <em>NEUCOM</em>, <em>511</em>, 448–461. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the difference between a bicycle robot dynamics model based on prior knowledge and a real robot, the robot modeling problem is studied. A set of features is extracted from the dynamics model of a bicycle robot. The trigonometric functions in the features are replaced with a linear combination of several sigmoid functions to form a new set of features. An index describing the importance of features is designed based on the maximal information coefficient (MIC). The features are ranked using the feature importance index. The index of system identification fitness (FIT) is regarded as the likelihood function term in Bayesian information criterion (BIC). The penalty term of BIC is constructed with the number of both the features and weight parameters in the recurrent high order neural network (RHONN) model. A semi-empirical dynamics modeling method based on feature selection is proposed. An inverse optimal controller is designed to stabilize the bicycle robot. The effectiveness of the modeling method is verified through simulation and real robot experiments.},
  archive      = {J_NEUCOM},
  author       = {Lei Guo and Zhiqiang Chen and Yuan Song},
  doi          = {10.1016/j.neucom.2022.09.062},
  journal      = {Neurocomputing},
  pages        = {448-461},
  shortjournal = {Neurocomputing},
  title        = {Semi-empirical dynamics modeling of a bicycle robot based on feature selection and RHONN},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-head pseudo nodes based spatial–temporal graph
convolutional network for emotion perception from GAIT. <em>NEUCOM</em>,
<em>511</em>, 437–447. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent years, the emotion recognition task has attracted a lot of attention in the field of human–computer interaction. Most existing research typically uses aural-visual analysis, which has been an effective approach to capturing emotional features. However, aural-visual signals are difficult to notice, in comparison to other human representations such as gait in remote situations. Recently, human gait can be effectively recognized in more complex backgrounds because of the advancement of Graph Convolutional Networks (GCNs). According to the anatomy of the human body, central torso joints play a key role in GCNs-based human gait recognition systems, instead of the body’s marginal limb joints. As a result, there is a major issue of receptive field imbalance. In this study, we propose a method for perceiving emotions based on the human gait skeleton. We present a multi-head pseudo nodes strategy to alleviate the receptive field imbalance problem and capture the non-local dependencies among different joints. The strategy employs a series of extra nodes that link to all physical human body joints and obtain global information from different feature spaces. The results of the experiments on a public emotion-gait dataset demonstrate that our proposed method outperforms existing skeleton-based methods. Further, to verify the effectiveness of our method, we use publicly available human action recognition datasets. Our results show that our method significantly improves performance in comparison to other baseline methods .},
  archive      = {J_NEUCOM},
  author       = {Shurong Chai and Jiaqing Liu and Rahul Kumar Jain and Tomoko Tateyama and Yutaro Iwamoto and Lanfen Lin and Yen-Wei Chen},
  doi          = {10.1016/j.neucom.2022.09.061},
  journal      = {Neurocomputing},
  pages        = {437-447},
  shortjournal = {Neurocomputing},
  title        = {A multi-head pseudo nodes based spatial–temporal graph convolutional network for emotion perception from GAIT},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Low-rank constraint bipartite graph learning.
<em>NEUCOM</em>, <em>511</em>, 426–436. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bipartite Graph-based multi-view clustering has become an active topic recently due to its efficiency in tackling large scale multi-view data. However, most existing bipartite graph-based multi-view clustering methods have the following disadvantages: 1) the clustering performance heavily depends on the predefined bipartite graph; 2) they fail to explore the complementary information embedded in multiple bipartite graphs and spatial low-rank structure hidden in each bipartite graph. To address these issues, we propose an efficient multi-view clustering method, L earning C onstraint B ipartite G raphs for Multi-view Clustering (LCBG). LCBG adaptively learns each graph S ( v ) ∈ R N × M S(v)∈RN×M such that it well characterizes the relationship between M ( M ≪ N M≪N ) anchors and N samples in the v -th view, and takes both the intra-view and inter-view spatial low-rank structures of the learned bipartite graphs into account by minimizing tensor Schatten p -norm and nuclear norm , respectively. Finally, an efficient algorithm, which scales linearly with the data size, is proposed to solve LCBG. Extensive experimental results on five benchmark datasets indicate our proposed LCBG is superior to the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Qian Zhou and Haizhou Yang and Quanxue Gao},
  doi          = {10.1016/j.neucom.2022.09.002},
  journal      = {Neurocomputing},
  pages        = {426-436},
  shortjournal = {Neurocomputing},
  title        = {Low-rank constraint bipartite graph learning},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PSNet: Parallel symmetric network for RGB-t salient object
detection. <em>NEUCOM</em>, <em>511</em>, 410–425. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-Thermal (RGB-T) salient object detection (SOD) aims to utilize RGB and thermal infrared data to discover the most salient object(s) in an image. Although SOD has achieved great progress, few efforts are devoted to RGB-T SOD. For this task, on the one hand, it is worth paying attention to how to aggregate critical saliency cues from both modalities to enhance salient feature representation and thus produce accurate salient object detection results. On the other hand, effective multi-level feature fusion remains a big challenge. To overcome the above mentioned issues, this paper proposes a Parallel Symmetric Network (PSNet) for RGB-T salient object detection. Specifically, we first develop a cascaded aggregation module (CAM), which fully accumulates and excavates the valuable saliency semantics from two different modalities to strengthen feature representation by cascading the designed residual-based enhancement unit. Then, we design a parallel-symmetric fusion (PSF) module to integrate crucial saliency cues from adjacent layers for saliency prediction in a parallel and symmetric manner. Besides, to make full use of multi-level features, we introduce a guidance strategy that enhances the details of the saliency map with the low-level features to boost the performance of salient object detection. Extensive experiments show that our proposed model significantly outperforms the existing fifteen state-of-the-art models on three challenging benchmark datasets. Moreover, the superior performance on RGB-D SOD also demonstrates the generalization and robustness of the proposed method. The source code will be made publicly available soon.},
  archive      = {J_NEUCOM},
  author       = {Hongbo Bi and Ranwan Wu and Ziqi Liu and Jiayuan Zhang and Cong Zhang and Tian-Zhu Xiang and Xiufang Wang},
  doi          = {10.1016/j.neucom.2022.09.052},
  journal      = {Neurocomputing},
  pages        = {410-425},
  shortjournal = {Neurocomputing},
  title        = {PSNet: Parallel symmetric network for RGB-T salient object detection},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Capped ℓp-norm linear discriminant analysis for robust
projections learning. <em>NEUCOM</em>, <em>511</em>, 399–409. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear Discriminant Analysis (LDA) is one of the most representative supervised robust dimensionality reduction methods for handling high-dimensional data. High-dimensional datasets tend to contain more outliers and other sorts of noise, whereas most of the existing LDA models incorrectly consider the arithmetic mean of samples as the optimal mean, leading to the deviation of the data mean and thus reduce the robustness of LDA. In this paper, we propose a novel robust trace ratio objective in which the calculation of the difference between sample and class mean is converted to the calculation of the difference between each pair of samples. Besides, the within-class scatter and the total scatter are measured by capped ℓ p ℓp -norm. As a result, this novel reformulation can automatically avoid mean calculation and meanwhile mitigate the negative effect of outliers on the objective function. Furthermore, an iterative optimization algorithm is derived to obtain the solution of the model. Extensive experimental results on several benchmark datasets show the superior performance of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Zheng Wang and Haojie Hu and Rong Wang and Qianrong Zhang and Feiping Nie and Xuelong Li},
  doi          = {10.1016/j.neucom.2022.09.006},
  journal      = {Neurocomputing},
  pages        = {399-409},
  shortjournal = {Neurocomputing},
  title        = {Capped ℓp-norm linear discriminant analysis for robust projections learning},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive dynamic event-triggered cluster synchronization in
an array of coupled neural networks subject to cyber-attacks.
<em>NEUCOM</em>, <em>511</em>, 380–398. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with cluster synchronization in an array of coupled neural networks subject to cyber-attacks, where a random variable is employed to reflect the success ration of the launched cyber-attacks. To save the energy consumption and alleviate the transmission load of the network, a novel adaptive distributed dynamic event-triggered communication scheme is presented based on the local stochastic the state sampling information, compared with some existing results, the different event-triggered matrices and auxiliary variables are introduced for each node to adjust its threshold dynamically, which can further reduce the sampled-data transmission, the proposed event-triggered scheme includes some existing event-triggered schemes as special cases. The cluster synchronization controllers are designed based on the states of neighboring nodes at event-triggered instants, a new stochastic sampled-data dependent error model is constructed, some mean-square cluster synchronization criteria can be derived by the Lyapunov stability theory and algebraic graph theory, and the feedback matrices and event-triggered matrices can be obtained by solving some linear matrix inequalities. Finally, two numerical examples are employed to show the validity and advantage of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Hongjie Li and Jinde Cao and Ardak Kashkynbayev and Shuiming Cai},
  doi          = {10.1016/j.neucom.2022.09.047},
  journal      = {Neurocomputing},
  pages        = {380-398},
  shortjournal = {Neurocomputing},
  title        = {Adaptive dynamic event-triggered cluster synchronization in an array of coupled neural networks subject to cyber-attacks},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discrete asymmetric zero-shot hashing with application to
cross-modal retrieval. <em>NEUCOM</em>, <em>511</em>, 366–379. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, cross-modal retrieval technology has attracted extensive attention with the massive growth of multimedia data. However, most cross-modal hashing methods mainly focus on exploring the retrieval of seen classes, while ignoring the retrieval of unseen classes. Therefore, traditional cross-modal hashing methods cannot achieve satisfactory performances in zero-shot retrieval. To mitigate this challenge, in this paper, we propose a novel zero-shot cross-modal retrieval method called discrete asymmetric zero-shot hashing(DAZSH), which fully exploits the supervised knowledge of multimodal data. Specifically, it integrates pairwise similarity , class attributes and semantic labels to guide zero-shot hashing learning. Moreover, our proposed DAZSH method combines the data features with the class attributes to obtain a semantic category representation for each category. Therefore, the relationships between seen and unseen classes can be effectively captured by learning a category representation vector for each instance. Therefore, the supervised knowledge can be transferred from the seen classes to the unseen classes. In addition, we develop an efficient discrete optimization strategy to solve the proposed model. Massive experiments on three benchmark datasets show that our proposed approach has achieved promising results in cross-modal retrieval tasks. The source code of this paper can be obtained from https://github.com/szq0816/DAZSH .},
  archive      = {J_NEUCOM},
  author       = {Zhenqiu Shu and Kailing Yong and Jun Yu and Shengxiang Gao and Cunli Mao and Zhengtao Yu},
  doi          = {10.1016/j.neucom.2022.09.037},
  journal      = {Neurocomputing},
  pages        = {366-379},
  shortjournal = {Neurocomputing},
  title        = {Discrete asymmetric zero-shot hashing with application to cross-modal retrieval},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature disentangling and reciprocal learning with
label-guided similarity for multi-label image retrieval.
<em>NEUCOM</em>, <em>511</em>, 353–365. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image retrieval usually faces scale-variance issues as the amount of image data is rapidly increasing, which calls for more accurate retrieval technology. Besides, existing methods usually treat pair-image similarity as a binary value which indicates whether two images share either at least one common label or none of shared labels. However, such similarity definition cannot truly describe the similarity ranking for different numbers of common labels when handling the multi-label image retrieval problem. In this paper, a Feature Disentangling and Reciprocal Learning (FDRL) method is introduced with label-guided similarity to solve the above multi-label image retrieval problem. Multi-scale features are first extracted by BNInception network and then disentangled to the corresponding high- and low-correlation features under the guidance of estimated global correlations. After that, the disentangled features are combined through a reciprocal learning approach to enhance the feature representation ability. Final hash codes are learned based on the global features derived from BNInception network and the combined features generated by reciprocal learning. The whole network is optimized by the proposed label-guided similarity loss function which aims to simultaneously preserve absolute similarity for hard image pairs and relative similarity for soft image pairs. Experimental results on three public benchmark datasets demonstrate that the proposed method outperforms current state-of-the-art techniques. The code is online here: ‘https://github.com/Yong-DAI/FDRL’.},
  archive      = {J_NEUCOM},
  author       = {Yong Dai and Weiwei Song and Yi Li and Luigi Di Stefano},
  doi          = {10.1016/j.neucom.2022.09.007},
  journal      = {Neurocomputing},
  pages        = {353-365},
  shortjournal = {Neurocomputing},
  title        = {Feature disentangling and reciprocal learning with label-guided similarity for multi-label image retrieval},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TA-BiDet: Task-aligned binary object detector.
<em>NEUCOM</em>, <em>511</em>, 337–352. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary CNN-based object detector, largely saving storage and computation costs, has received high attention recently for the potention of efficient deployment on resource-constrained devices. However, previous designs often suffer from significant accuracy loss when compared to their real-value counterparts. This study demonstrates that the primary reason lies in the mis-alignment of the classification and regression tasks , which is generally caused by the limited representational capacity of the binary neural network and biased training procedures used in traditional detection frameworks. Based on this observation, we propose TA-BiDet (Task-Alignment Binary object Detection) that can guarantee aligned training of the two tasks by adopting a task-aware feature disentanglement (TFD) network architecture with an alignment-oriented learning (AOL) approach. The proposed approaches can ensure more informative and tailored task-specific features to be learned jointly for each task and select the most accurate detected boxes with both high confidence scores and precise locations. Experiments on the PASCAL VOC and COCO datasets have shown that TA-BiDet outperformed state-of-the-art binary object detectors by a considerable margin. Moreover, TA-BiDet has successfully narrowed the performance gap with the real-valued SSD300 detector to only 0.7\% in terms of mAP, and reduced the model size by 4.86 × × and the total OPs by 9.89 × × , respectively.},
  archive      = {J_NEUCOM},
  author       = {Han Pu and Ke Xu and Dezheng Zhang and Li Liu and Lingzhi Liu and Dong Wang},
  doi          = {10.1016/j.neucom.2022.09.038},
  journal      = {Neurocomputing},
  pages        = {337-352},
  shortjournal = {Neurocomputing},
  title        = {TA-BiDet: Task-aligned binary object detector},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interpretable domain adaptation using unsupervised feature
selection on pre-trained source models. <em>NEUCOM</em>, <em>511</em>,
319–336. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a realistic domain adaptation setting where one has access to an already existing “black-box” machine learning model. Indeed, in real-life scenarios, an efficient pre-trained source domain predictive model is often available and required to be preserved. The solution we propose to this problem has the asset of providing an interpretable target to source transformation by seeking a sparse and ordered coordinate-wise adaptation of the feature space in addition to elementary mapping functions. To automatically select the subset of features to be adapted, we first introduce a weakly-supervised process relying on scarce labeled target data. Then, we address a more challenging unsupervised version of this domain adaptation scenario. To this end, we propose a new pseudo-label estimator over unlabeled target examples, which is based on rank-stability in regards to the source model prediction. Such estimated “labels” are further used in a feature selection process to assess whether each feature needs to be transformed to achieve adaptation. We provide theoretical foundations of our method as well as an efficient implementation. Numerical experiments on real datasets show particularly encouraging results since approaching the supervised case, where one has access to labeled target samples.},
  archive      = {J_NEUCOM},
  author       = {Luxin Zhang and Pascal Germain and Yacine Kessaci and Christophe Biernacki},
  doi          = {10.1016/j.neucom.2022.09.031},
  journal      = {Neurocomputing},
  pages        = {319-336},
  shortjournal = {Neurocomputing},
  title        = {Interpretable domain adaptation using unsupervised feature selection on pre-trained source models},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neuro-adaptive fixed-time control with novel command filter
design for nonlinear systems with input dead-zone. <em>NEUCOM</em>,
<em>511</em>, 308–318. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper designs novel command filters (CFs) and a singularity-free controller with fixed-time performance for strict feedback nonlinear systems with input dead-zone. Compared with traditional filter designs, such as dynamic surface control and CFs, the novel CFs designed in this paper can guarantee fixed-time convergence of filter errors and compensating signals. Moreover, the controller design excludes the singularities of control signals, which might result in severe oscillation and usually appear in the conventional fixed-time controller design. To compensate the input dead-zone, a compensation filter is constructed, where controller design and stability analysis can be simplified. In the end, a simulation example is given to verify the effectiveness of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Liqiang Tang and Yongliang Yang and Wencheng Zou and Ruizhuo Song},
  doi          = {10.1016/j.neucom.2022.09.034},
  journal      = {Neurocomputing},
  pages        = {308-318},
  shortjournal = {Neurocomputing},
  title        = {Neuro-adaptive fixed-time control with novel command filter design for nonlinear systems with input dead-zone},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). B-AT-KD: Binary attention map knowledge distillation.
<em>NEUCOM</em>, <em>511</em>, 299–307. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have been extensively used in a number of applications and have shown to be quite effective. As the depth and width of the network expand, not only does prediction accuracy improve, but so does the network’s training complexity. To solve this problem, the knowledge distillation (KD) network, which consists of a teacher and a student network, is established. Furthermore, the widely accessible attention mechanism is important in the KD. Therefore, we build the Binary Attention Map Knowledge Distillation (B-AT-KD) model to enhance the performance of the student network by combining the output of the teacher network and associated attention maps with distinct semantics to supervise the student network. In addition, to improve training results, we propose a new global loss function called KDM-Loss and use hyperparameters search to assign suitable weights. Finally, we compare our B-AT-KD to state-of-the-art KD methods on the CIFAR 10, CIFAR 100, and Mini-ImageNet datasets. Experiments reveal that our proposed approach improves CIFAR 10 precision by 3.98\%, Mini-ImageNet accuracy by 2.30\%, and CIFAR 100 precision by 2.51\% while reducing the number of parameters and computations by more than 50\%.},
  archive      = {J_NEUCOM},
  author       = {Xing Wei and Yuqing Liu and Jiajia Li and Huiyong Chu and Zichen Zhang and Feng Tan and Pengwei Hu},
  doi          = {10.1016/j.neucom.2022.09.064},
  journal      = {Neurocomputing},
  pages        = {299-307},
  shortjournal = {Neurocomputing},
  title        = {B-AT-KD: Binary attention map knowledge distillation},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022d). Global mittag–leffler stability and synchronization of
discrete-time fractional-order delayed quaternion-valued neural
networks. <em>NEUCOM</em>, <em>511</em>, 290–298. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to investigating discrete-time fractional-order delayed quaternion-valued neural networks (DFDQNNs) by utilizing direct quaternion approach. Firstly, a novel lemma and its two corresponding corollaries have been proposed for estimating nabla fractional difference of the quaternion-valued Lyapunov function . Then, the existence and uniqueness of equilibrium point for DFDQNNs is proved by constructing a new quaternion-valued contraction mapping . In addition, by means of our designed Lyapunov functions and the effective feedback controller as well as neoteric nabla difference inequalities, some sufficient criteria have been obtained to ensure the global Mittag–Leffler stability and Mittag–Leffler synchronization of DFDQNNs, respectively. Finally, some numerical examples are provided to verify the yielded results.},
  archive      = {J_NEUCOM},
  author       = {Shenglong Chen and Hong-Li Li and Haibo Bao and Long Zhang and Haijun Jiang and Zhiming Li},
  doi          = {10.1016/j.neucom.2022.09.035},
  journal      = {Neurocomputing},
  pages        = {290-298},
  shortjournal = {Neurocomputing},
  title        = {Global Mittag–Leffler stability and synchronization of discrete-time fractional-order delayed quaternion-valued neural networks},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CTpoint: A novel local and global features extractor for
point cloud. <em>NEUCOM</em>, <em>511</em>, 273–289. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local convolutional operation and global attention-based transformer operation can extract features of the point cloud from two different scales respectively, but few methods can combine them effectively. In this paper, we propose a novel point cloud feature extractor that has the advantages of both convolutional and transformer operation, which is named as CTpoint. Specifically, CTpoint is composed of two branches, where ”C” represents the convolutional branch and “T” represents the transformer branch. The convolutional branch is responsible for extracting the local feature from grouped neighbor points, and the transformer branch performs the attention operation on the entire point cloud to capture the global feature. To make the two branches communicate with each other, the Feature Transmission Element (FTE) is proposed for the alignment of the spatial-feature dimension and the semantic space between the local and global features, so that the extracted local and global features can be effectively fused and the two branches can coordinately learn expressive features. We utilize CTpoint to construct point cloud classification and segmentation networks and evaluate their performance in several public datasets. In addition, we visualize the feature learned by CTpoint. The experimental results show that the expressive features learned by CTpoint make the networks achieve the state of the art performance on the point cloud classification and segmentation tasks .},
  archive      = {J_NEUCOM},
  author       = {Shangwei Guo and Jun Li and Zhengchao Lai and Shaokun Han},
  doi          = {10.1016/j.neucom.2022.09.056},
  journal      = {Neurocomputing},
  pages        = {273-289},
  shortjournal = {Neurocomputing},
  title        = {CTpoint: A novel local and global features extractor for point cloud},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RSKNet-MTSP: Effective and portable deep architecture for
speaker verification. <em>NEUCOM</em>, <em>511</em>, 259–272. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convolutional neural network (CNN) based approaches have shown great success for speaker verification (SV) tasks, where modeling long temporal context and reducing information loss of speaker characteristics are two important challenges significantly affecting the verification performance. Previous works have introduced dilated convolution and multi-scale aggregation methods to address above challenges. However, such methods are also hard to make full use of some valuable information, which make it difficult to substantially improve the verification performance. To address above issues, we construct a novel CNN-based architecture for SV, called RSKNet-MTSP, where a residual selective kernel block (RSKBlock) and a multiple time-scale statistics pooling (MTSP) module are proposed. The RSKNet-MTSP can capture both long temporal context and neighbouring information, and gather more speaker-discriminative information from multi-scale features. In order to design a portable model for real applications with limited resources, we then present a lightweight version of RSKNet-MTSP, namely RSKNet-MTSP-L, which employs a combination technique associating the depthwise separable convolutions with low-rank factorization of weight matrices. Extensive experiments are conducted on two public SV datasets, VoxCeleb and Speaker in the Wild (SITW). The results demonstrate that 1) RSKNet-MTSP significantly outperforms the state-of-the-art deep embedding architectures on all five test sets; 2) RSKNet-MTSP-L achieves competitive performance with 17\%-44\% less network parameters compared to baseline models . The ablation experiments further illustrate that our proposed approaches can achieve substantial improvement over prior methods.},
  archive      = {J_NEUCOM},
  author       = {Yanfeng Wu and Chenkai Guo and Junan Zhao and Xiao Jin and Jing Xu},
  doi          = {10.1016/j.neucom.2022.09.014},
  journal      = {Neurocomputing},
  pages        = {259-272},
  shortjournal = {Neurocomputing},
  title        = {RSKNet-MTSP: Effective and portable deep architecture for speaker verification},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An explainable framework for drug repositioning from disease
information network. <em>NEUCOM</em>, <em>511</em>, 247–258. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring efficient and high-accuracy computational drug repositioning methods has become a popular and attractive topic in drug development. This technology can systematically identify potential drug-disease interactions, which could greatly alleviate the pressures from the high cost and long period taken by traditional drug research and discovery. However, plenty of current computational drug repositioning approaches lack interpretability in predicting drug-disease associations, which will not be friendly to their subsequent in-depth research. To this end, we hereby propose a novel computational framework, called EDEN , for exploring explainable drug repositioning from the disease information network (DIN). EDEN is a graph neural network framework that learns the local semantics and global structure of the DIN, and models the drug-disease associations into the DIN by maximizing the mutual information of both and an end-to-end manner. In this way, the learned biomedical entity and link embeddings are enabled to retain the ability to drug repositioning with the semantical structure of external knowledge, thereby making interpretation possible. Meanwhile, we also propose a matching score based on the final embeddings to generate the predictive drug repositioning explanation. Empirical results on the real-world dataset show that EDEN outperforms other state-of-the-art baselines on most of the metrics. Further studies reveal the effectiveness of the explainability of our approach.},
  archive      = {J_NEUCOM},
  author       = {Chengxin He and Lei Duan and Huiru Zheng and Linlin Song and Menglin Huang},
  doi          = {10.1016/j.neucom.2022.09.063},
  journal      = {Neurocomputing},
  pages        = {247-258},
  shortjournal = {Neurocomputing},
  title        = {An explainable framework for drug repositioning from disease information network},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Jerk-layer repetitive motion and direction control scheme of
redundant robot resolved via new discretized zeroing neural network
model. <em>NEUCOM</em>, <em>511</em>, 237–246. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, repetitive motion control and end-effector direction control of a redundant robot are investigated to effectively address the joint-angle drift problem and simultaneously regulate the end-effector direction at the joint-jerk layer. Specifically, a jerk-layer repetitive motion and direction control (JLRMDC) scheme with quadratic-programming-type formulation is first proposed, and then a continuous zeroing neural network (CZNN) model is developed. Subsequently, by utilizing a seven-step look-ahead discretization rule to discretize the CZNN model, a new discretized zeroing neural network (DZNN) model with high precision is proposed to resolve the JLRMDC scheme. Finally, both theoretical analyses and comparative numerical experiments demonstrate the validity, precision, and superiority of the proposed JLRMDC scheme and DZNN model.},
  archive      = {J_NEUCOM},
  author       = {Binbin Qiu and Xiao-Dong Li},
  doi          = {10.1016/j.neucom.2022.09.015},
  journal      = {Neurocomputing},
  pages        = {237-246},
  shortjournal = {Neurocomputing},
  title        = {Jerk-layer repetitive motion and direction control scheme of redundant robot resolved via new discretized zeroing neural network model},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). QDL-CMFD: A quality-independent and deep learning-based
copy-move image forgery detection method. <em>NEUCOM</em>, <em>511</em>,
213–236. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the prevalent methods of image forgery is copy-move, where one or more regions of an image are duplicated and moved elsewhere in the image. It is usually difficult to detect this type of forgery due to the similarity of the copied and forged areas. Also, forgers perform pre-processing and/or post-processing operations on the manipulated regions to make it even more difficult to detect. In this study, an image quality-independent method based on deep learning approach, termed QDL-CMFD, is presented for detecting this type of forgery. QDL-CMFD utilizes generative adversarial networks for image quality enhancement, and convolutional neural networks (CNN) for forgery detection . A tailored dual-branch CNN architecture is introduced consisting of two subnetworks, namely a manipulation detection subnetwork and a similarity detection subnetwork. Accordingly, unlike most existing methods, QDL-CMFD is able to simultaneous detection of several forged areas, as well as determining the source and target of the forgery. Also, QDL-CMFD is robust against various pre-processing/post-processing attacks. It shows excellent performance for detecting low-quality forged images and small areas. Experiments conducted on the CASIA and CoMoFoD benchmark datasets confirm that QDL-CMFD performs significantly better than the competitors. All the implementation source codes of QDL-CMFD are available at https://github.com/MehradAria/QDL-CMFD .},
  archive      = {J_NEUCOM},
  author       = {Mehrad Aria and Mahdi Hashemzadeh and Nacer Farajzadeh},
  doi          = {10.1016/j.neucom.2022.09.017},
  journal      = {Neurocomputing},
  pages        = {213-236},
  shortjournal = {Neurocomputing},
  title        = {QDL-CMFD: A quality-independent and deep learning-based copy-move image forgery detection method},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DRDNN: A robust model for time-variant nonlinear
optimization under multiple equality and inequality constraints.
<em>NEUCOM</em>, <em>511</em>, 198–212. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {External disturbances ubiquitously exist in time-variant problems, including the time-variant nonlinear optimization problems. To develop feasible neural network for time-variant nonlinear optimization restricted to multiple equality and inequality constraints is a bottleneck problem due to its high complexity. In this paper, a novel disturbance rejection dynamic neural network (DRDNN) is proposed to handle nonlinear optimization with multiple equality and inequality constraints concerning external disturbances. According to Lagrange multiplier rule and Karush–Kuhn–Tucker condition, the original optimization problem restricted to multiple equality and inequality constraints is firstly transformed into a time-variant dynamic equation set. Then, detailed design process of the DRDNN model is developed accordingly. The proposed DRDNN inherently possesses the effectiveness and robustness by leveraging the time-derivative as well as the time-integration information. Theorems and proofs about stability, convergence property , and robustness against different forms of disturbances are provided. Finally, different examples, comparisons as well as tests substantiate the accuracy, superiority and robustness of DRDNN for nonlinear optimization limited by multiple equality and inequality constraints in disturbed scenarios.},
  archive      = {J_NEUCOM},
  author       = {Dechao Chen and Shuai Li},
  doi          = {10.1016/j.neucom.2022.09.043},
  journal      = {Neurocomputing},
  pages        = {198-212},
  shortjournal = {Neurocomputing},
  title        = {DRDNN: A robust model for time-variant nonlinear optimization under multiple equality and inequality constraints},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effect of state transition triggered by reinforcement
learning in evolutionary prisoner’s dilemma game. <em>NEUCOM</em>,
<em>511</em>, 187–197. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative behavior is essential for conflicts between collective and individual benefits, and evolutionary game theory provides a key framework to solve this problem. Decision-making of human or automata agent occurs not only in a static environment , but also in the dynamic interactive environment. Since the reinforcement learning algorithm is well performed at explaining the problem in regard to state, action, and environment, we propose a game model with individual state transition which is influenced by the self-regarding Q -learning algorithm. In detail, we at the first time investigate a two-state two-action game, where agents can choose either to participate in the network game (i.e., active agent) or to cut off all the links based on its Q -table (i.e., inactive agent), involving in a dynamic interactive environment. Through numerical simulations, it is shown that cooperation can reach the maximal level in the moderate value space of fixed reward obtained by inactive agents. In particular, long-term expectations and large learning rates are more productive in promoting cooperation. Furthermore, when the dynamic interactive environment reaches a stable state, the number of active neighbors of active cooperators is larger than that of active defectors, which is further larger than the number of active neighbors of inactive agents. Finally, we testify the results of theoretical analysis from the perspective of state transition.},
  archive      = {J_NEUCOM},
  author       = {Hao Guo and Zhen Wang and Zhao Song and Yuan Yuan and Xinyang Deng and Xuelong Li},
  doi          = {10.1016/j.neucom.2022.08.023},
  journal      = {Neurocomputing},
  pages        = {187-197},
  shortjournal = {Neurocomputing},
  title        = {Effect of state transition triggered by reinforcement learning in evolutionary prisoner’s dilemma game},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards efficient full 8-bit integer DNN online training on
resource-limited devices without batch normalization. <em>NEUCOM</em>,
<em>511</em>, 175–186. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Huge computational costs brought by convolution and batch normalization (BN) have caused great challenges for the online training and corresponding applications of deep neural networks (DNNs), especially in resource-limited devices. Existing works only focus on the convolution or BN acceleration and no solution can alleviate both problems with satisfactory performance. Online training has gradually become a trend in resource-limited devices like mobile phones while there is still no complete technical scheme with acceptable model performance, processing speed, and computational cost. In this research, an efficient online-training quantization framework termed EOQ for abbreviation is proposed by combining Fixup initialization and a novel quantization scheme for the online training in resource-limited devices. Based on the proposed framework, we have successfully realized full 8-bit integer network training and removed BN in large-scale DNNs. Especially, weight updates are quantized to 8-bit integers for the first time. Theoretical analyses of EOQ utilizing Fixup initialization for removing BN have been further given using a novel Block Dynamical Isometry theory with weaker assumptions. Benefiting from rational quantization strategies and the absence of BN, the full 8-bit networks based on EOQ can achieve state-of-the-art accuracy and immense advantages in computational cost and processing speed. Experiments show that the 8-bit EOQ networks achieve 2.78\%, 3.85\%, and 4.31\% accuracy improvements compared with existing full 8-bit integer networks in ResNet-18/34/50. At the same time, the 8-bit EOQ networks can improve the computing speed greatly, and decrease the power consumption and circuit area by about an order of magnitude compared with 32-bit floating-point vanilla networks. In addition to the huge advantages brought by quantization in convolution operations , 8-bit networks based on EOQ without BN can realize &gt; &amp;gt; 66 × × lower in power, &gt; &amp;gt; 13 × × faster in the processing speed compared with the traditional 32-bit floating-point BN in the inference process. What’s more, the design of deep learning chips can be profoundly simplified in the absence of unfriendly square root operations in BN. Beyond this, EOQ has been evidenced to be more advantageous in small-batch online training with fewer batch samples. In summary, the EOQ framework is specially designed for reducing the high cost of convolution and BN in network training, demonstrating a broad application prospect of online training in resource-limited devices.},
  archive      = {J_NEUCOM},
  author       = {Yukuan Yang and Xiaowei Chi and Lei Deng and Tianyi Yan and Feng Gao and Guoqi Li},
  doi          = {10.1016/j.neucom.2022.08.045},
  journal      = {Neurocomputing},
  pages        = {175-186},
  shortjournal = {Neurocomputing},
  title        = {Towards efficient full 8-bit integer DNN online training on resource-limited devices without batch normalization},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature importance in machine learning models: A fuzzy
information fusion approach. <em>NEUCOM</em>, <em>511</em>, 163–174. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread use of machine learning to support decision-making, it is increasingly important to verify and understand the reasons why a particular output is produced. Although post-training feature importance approaches assist this interpretation, there is an overall lack of consensus regarding how feature importance should be quantified, making explanations of model predictions unreliable. In addition, many of these explanations depend on the specific machine learning approach employed and on the subset of data used when calculating feature importance. A possible solution to improve the reliability of explanations is to combine results from multiple feature importance quantifiers from different machine learning approaches coupled with re-sampling. Current state-of-the-art ensemble feature importance fusion uses crisp techniques to fuse results from different approaches. There is, however, significant loss of information as these approaches are not context-aware and reduce several quantifiers to a single crisp output. More importantly, their representation of “importance” as coefficients may be difficult to comprehend by end-users and decision makers. Here we show how the use of fuzzy data fusion methods can overcome some of the important limitations of crisp fusion methods by making the importance of features easily understandable.},
  archive      = {J_NEUCOM},
  author       = {Divish Rengasamy and Jimiama M. Mase and Aayush Kumar and Benjamin Rothwell and Mercedes Torres Torres and Morgan R. Alexander and David A. Winkler and Grazziela P. Figueredo},
  doi          = {10.1016/j.neucom.2022.09.053},
  journal      = {Neurocomputing},
  pages        = {163-174},
  shortjournal = {Neurocomputing},
  title        = {Feature importance in machine learning models: A fuzzy information fusion approach},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prescribed-time adaptive neural feedback control for a class
of nonlinear systems. <em>NEUCOM</em>, <em>511</em>, 155–162. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies prescribed-time stabilization for a class of unknown strict-feedback nonlinear systems . Adaptive time-varying feedback control method and non-scaling transformation strategies are employed to reduce the computation burden caused by the scaling functions. Besides, the proposed method uses a constrained function to avoid the possibility of an oversized signal when time approaches to the prescribed settling time. Based on the backstepping method, a neural prescribed-time controller is constructed to achieve finite-time regulation. Under the action of the proposed strategy, all the closed-loop signals are bounded and the system is stable in prescribed finite time. Finally, two simulation examples illustrate the effectiveness of the results.},
  archive      = {J_NEUCOM},
  author       = {Zhiliang Liu and Chong Lin and Yun Shang},
  doi          = {10.1016/j.neucom.2022.09.072},
  journal      = {Neurocomputing},
  pages        = {155-162},
  shortjournal = {Neurocomputing},
  title        = {Prescribed-time adaptive neural feedback control for a class of nonlinear systems},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning for covid-19 forecasting: State-of-the-art
review. <em>NEUCOM</em>, <em>511</em>, 142–154. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Covid-19 pandemic has galvanized scientists to apply machine learning methods to help combat the crisis. Despite the significant amount of research there exists no comprehensive survey devoted specifically to examining deep learning methods for Covid-19 forecasting. In this paper, we fill the gap in the literature by reviewing and analyzing the current studies that use deep learning for Covid-19 forecasting. In our review, all published papers and preprints, discoverable through Google Scholar, for the period from Apr 1, 2020 to Feb 20, 2022 which describe deep learning approaches to forecasting Covid-19 were considered. Our search identified 152 studies, of which 53 passed the initial quality screening and were included in our survey. We propose a model-based taxonomy to categorize the literature. We describe each model and highlight its performance. Finally, the deficiencies of the existing approaches are identified and the necessary improvements for future research are elucidated. The study provides a gateway for researchers who are interested in forecasting Covid-19 using deep learning.},
  archive      = {J_NEUCOM},
  author       = {Firuz Kamalov and Khairan Rajab and Aswani Kumar Cherukuri and Ashraf Elnagar and Murodbek Safaraliev},
  doi          = {10.1016/j.neucom.2022.09.005},
  journal      = {Neurocomputing},
  pages        = {142-154},
  shortjournal = {Neurocomputing},
  title        = {Deep learning for covid-19 forecasting: State-of-the-art review.},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GCN-FFNN: A two-stream deep model for learning solution to
partial differential equations. <em>NEUCOM</em>, <em>511</em>, 131–141.
(<a href="https://doi.org/10.1016/j.neucom.2022.09.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel two-stream deep model based on graph convolutional network (GCN) architecture and feed-forward neural networks (FFNN) for learning the solution of nonlinear partial differential equations (PDEs). The model aims at incorporating both graph and grid input representations using two streams corresponding to GCN and FFNN models, respectively. Each stream layer receives and processes its input representation. As opposed to FFNN which receives a grid-like structure, the GCN stream layer operates on graph input data where the neighborhood information is incorporated through the adjacency matrix of the graph. In this way, the proposed GCN-FFNN model learns from two types of input representations, i.e. grid and graph data, obtained via the discretization of the PDE domain. The GCN-FFNN model is trained in two phases. In the first phase, the model parameters of each stream are trained separately. Both streams employ the same error function to adjust their parameters by enforcing the models to satisfy the given PDE as well as its initial and boundary conditions on grid or graph collocation (training) data. In the second phase, the learned parameters of two-stream layers are frozen and their learned representation solutions are fed to fully connected layers whose parameters are learned using the previously used error function. The learned GCN-FFNN model is tested on test data located both inside and outside the PDE domain. The obtained numerical results demonstrate the applicability and efficiency of the proposed GCN-FFNN model over individual GCN and FFNN models on 1D-Burgers, 1D-Schrödinger, 2D-Burgers, and 2D-Schrödinger equations.},
  archive      = {J_NEUCOM},
  author       = {Onur Bilgin and Thomas Vergutz and Siamak Mehrkanoon},
  doi          = {10.1016/j.neucom.2022.09.054},
  journal      = {Neurocomputing},
  pages        = {131-141},
  shortjournal = {Neurocomputing},
  title        = {GCN-FFNN: A two-stream deep model for learning solution to partial differential equations},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Expression-tailored talking face generation with adaptive
cross-modal weighting. <em>NEUCOM</em>, <em>511</em>, 117–130. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key of talking face generation is to synthesize the identity-preserving natural facial expressions with accurate audio-lip synchronization. To accomplish this, it requires to disentangle and fuse the latent features from multiple modalities, including the visual identity, facial expressions, and audio, etc. In this paper, we propose an end-to-end Expression-Tailored Generative Adversarial Network with Adaptive Cross-modal Weighting (ET-GAN-ACW). Different from previous talking face generation based on the identity image and audio, an expression video of arbitrary identity serves as the source in our system. On the one hand, multiple encoders are presented to disentangle the expression-tailored representation, audio-lip embedding, and face position localization in parallel. Additionally, instead of using a single image as the target identity, a multi-image identity encoder is proposed by exploring the different views of faces and merging them into a unified representation. These informative features from different modalities are then adaptively weighted and fused by the proposed Adaptive Cross-modal Weighting (ACW) mechanism. On the other hand, multiple discriminators are exploited to create the image-aware and video-aware realistic details, including a frame discriminator for the frame authenticity, and a spatial–temporal discriminator for the visual coherence of facial expression movements. Extensive quantitative evaluations on reconstruction error, identity preserving, expression retention, and audio-visual synchronization verify the superiority of our method. Qualitative results also demonstrate the effectiveness of our method in generating high-quality talking face videos.},
  archive      = {J_NEUCOM},
  author       = {Dan Zeng and Shuaitao Zhao and Junjie Zhang and Han Liu and Kai Li},
  doi          = {10.1016/j.neucom.2022.09.025},
  journal      = {Neurocomputing},
  pages        = {117-130},
  shortjournal = {Neurocomputing},
  title        = {Expression-tailored talking face generation with adaptive cross-modal weighting},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combating spatial redundancy with spectral norm attention in
convolutional learners. <em>NEUCOM</em>, <em>511</em>, 105–116. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is an inherent and longstanding challenge for vision learners to exploit informative features from digital images with spatial redundancy . Given pre-processing image methods require task-specific customization and may rise unanticipated poor performance due to redundancy removal, we explore improving vision learners to combat spatial redundancy during vision learning, a task-agnostic and robust solution. Among popular vision learners, vision transformers with self-attention can mitigate pixel redundancy by capturing global dependencies, while convolutional learners fall into locality via a limited receptive field. To this end, based on investigating inter-pixel spatial redundancy of images, in this work, we propose spectral norm attention (SNA), a novel yet efficient attention block to help convolutional neural networks (CNNs) highlight informative features. We can seamlessly plug SNA into off-the-shelf CNNs to suppress the contributions of redundant features by globally differentiating and weighting. In particular, SNA performs singular value decomposition (SVD) on intermediate features of each image within a mini-batch to obtain its spectral norm. The features in the direction of the spectral norm are most informative, while the discriminative features in other directions leave less. Hence, we apply the rank-one approximation of the spectral norm direction as attention weights to enhance informative features. Besides, we adopt the power iteration algorithm to approximate the spectral norm to significantly reduce the matrix computation overhead during training, thus keeping inference speed on par with vanilla CNNs. We extensively evaluate our SNA on four mainstream natural datasets to demonstrate the effectiveness and favourability of our SNA against its counterparts. In addition, the experimental results of image classification and object detection show our SNA can bring more gains to medical images with heavy redundancy than other state-of-the-art attention modules.},
  archive      = {J_NEUCOM},
  author       = {Jiansheng Fang and Dan Zeng and Xiao Yan and Yubing Zhang and Hongbo Liu and Bo Tang and Ming Yang and Jiang Liu},
  doi          = {10.1016/j.neucom.2022.09.075},
  journal      = {Neurocomputing},
  pages        = {105-116},
  shortjournal = {Neurocomputing},
  title        = {Combating spatial redundancy with spectral norm attention in convolutional learners},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed neurodynamic-based economic dispatch strategy
for we-energy. <em>NEUCOM</em>, <em>511</em>, 91–104. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the distributed collaborative energy management of distributed cyber-energy system with consideration of multiple types of coupled energy sources and loads. Firstly, the energy structure of We-Energy (WE) and the characteristics of multi-energy interconversion are studied. With this effort, the concept of general loads are modeled based on transform loss and compensation coefficient, which enables multiple controllable loads interconverting with each other to reduce energy consumption. As a result, the system capacity costs can be greatly reduced. Furthermore, a new fully distributed neurodynamics-based algorithm is proposed to solve the economic dispatch problem of multiple WEs. The proposed method can only use seldom shared variables to obtain the optimal solutions and does not require the objective function to be strictly convex and smooth in solving convex optimization problems . Meanwhile, the proposed possesses faster convergence speed by employing application-specific integrated circuits. Moreover, we prove that the proposed neurodynamics-based algorithm can asymptotically converge to the global optimal point based on Lyapunov analysis method. Finally, simulation results demonstrate the validity of the algorithm and the effect of general load on the overall operating cost of the WE system.},
  archive      = {J_NEUCOM},
  author       = {Rufei Ren and Yushuai Li and Qiuye Sun and Jing Dai and Huaguang Zhang},
  doi          = {10.1016/j.neucom.2022.09.033},
  journal      = {Neurocomputing},
  pages        = {91-104},
  shortjournal = {Neurocomputing},
  title        = {Distributed neurodynamic-based economic dispatch strategy for we-energy},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dual-granularity feature alignment for cross-modality person
re-identification. <em>NEUCOM</em>, <em>511</em>, 78–90. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-infrared cross-modality person re-identification is a challenging image retrieval task due to the intra-class variations and cross-modality discrepancy. However, it is insufficient for existing methods to identify discriminative patterns with different granularities and align them across granularity and modalities in a synergistic manner. In this paper, we propose Dual-granularity Feature Alignment (DFA) approach for cross-modality re-ID, which accommodates dual-granularity feature extraction and cross-granularity feature alignment. More specifically, a feature extractor is introduced to generate discriminative patterns by dividing feature map into different granularities . Based on the above features, prototype learning is developed to assign different granularity features of the same identity to the same prototype and adaptively build the alignment across different granularities. To mine contextual relationships between training samples, a similarity inference is presented to enforce the similarity matrix closing to identity matrix . This allows model to find feature that conserves as much modality-shared information as possible while being least possible modality-specific information. Both modules work in a collaborative way to obtain the optimal intra-class compactness and inter-class separability for cross-modality image matching. Extensive experiments on several benchmarks demonstrate that our DAF surpasses the state-of-the-art methods. The code is available at https://github.com/PRIS-CV/DFA.},
  archive      = {J_NEUCOM},
  author       = {Junhui Yin and Zhanyu Ma and Jiyang Xie and Shibo Nie and Kongming Liang and Jun Guo},
  doi          = {10.1016/j.neucom.2022.09.077},
  journal      = {Neurocomputing},
  pages        = {78-90},
  shortjournal = {Neurocomputing},
  title        = {Dual-granularity feature alignment for cross-modality person re-identification},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022d). Dual-discriminator adversarial framework for data-free
quantization. <em>NEUCOM</em>, <em>511</em>, 67–77. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to the potential to address the privacy and security issues, data-free quantization that generates samples based on the prior information in the model has recently been widely investigated. However, existing methods failed to adequately utilize the prior information and thus cannot fully restore the real-data characteristics and provide effective supervision to the quantized model, resulting in poor performance. In this paper, we propose Dual-Discriminator Adversarial Quantization (DDAQ), a novel data-free quantization framework with an adversarial learning style that enables effective sample generation and learning of the quantized model. Specifically, we employ a generator to produce meaningful and diverse samples directed by two discriminators, aiming to facilitate the matching of the batch normalization (BN) distribution and maximizing the discrepancy between the full-precision model and the quantized model, respectively. Moreover, inspired by mixed-precision quantization, i.e., the importance of each layer is different, we introduce layer importance prior to both discriminators, allowing us to make better use of the information in the model. Subsequently, the quantized model is trained with the generated samples under the supervision of the full-precision model. We evaluate DDAQ on various network structures for different vision tasks, including image classification and object detection, and the experimental results show that DDAQ outperforms all baseline methods with good generality.},
  archive      = {J_NEUCOM},
  author       = {Zhikai Li and Liping Ma and Xianlei Long and Junrui Xiao and Qingyi Gu},
  doi          = {10.1016/j.neucom.2022.09.076},
  journal      = {Neurocomputing},
  pages        = {67-77},
  shortjournal = {Neurocomputing},
  title        = {Dual-discriminator adversarial framework for data-free quantization},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sampling-invariant fully metric learning for few-shot object
detection. <em>NEUCOM</em>, <em>511</em>, 54–66. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot object detection (FSOD) aims to learn models to detect unseen objects with a few annotated exemplars. Despite great success in FSOD, existing metric-based methods heavily rely on class prototypes extracted from limited training data and thus suffer severely from data shift, which can learn inductive bias and produce inconsistent performance across multiple runs. According to statistic law, data shift happens more frequently under low-shot scenarios than that in many-shot scenarios. However, there is insufficient research about utilizing intrinsic and robust properties of limited data for data-stable results instead of blindly achieving high performance on a specific dataset. This inspires us to model intrinsic properties of limited data for building a set of robust class prototypes. To this end, we propose a novel Sampling-Invariant Fully metric learning Network (SIF-Net) that enhances class prototypes in three aspects. Specifically, our model includes three novel modules: (1) a multi-scale context matching (MSCM) module that aggregates more accurate class concepts in a scale-matching manner, (2) a semantic drift correlation (SDC) module that recovers distorted class prototypes through object context, and (3) a fully metric learning (FML) module that encodes both class and spatial priors into class prototypes, which is fundamentally different from previous metric-based approaches. As a result, our SIF-Net is robust to various settings of few-shot data quality. Extensive experiments show that our fully metric-based framework is superior to other metric-based approaches and achieves state-of-the-art performance on PASCAL VOC and MS COCO datasets.},
  archive      = {J_NEUCOM},
  author       = {Jiaxu Leng and Taiyue Chen and Xinbo Gao and Mengjingcheng Mo and Yongtao Yu and Yan Zhang},
  doi          = {10.1016/j.neucom.2022.09.040},
  journal      = {Neurocomputing},
  pages        = {54-66},
  shortjournal = {Neurocomputing},
  title        = {Sampling-invariant fully metric learning for few-shot object detection},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leveraging convergence behavior to balance conflicting tasks
in multi-task learning. <em>NEUCOM</em>, <em>511</em>, 43–53. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Task Learning is a learning paradigm that uses correlated tasks to improve performance generalization . A common way to learn multiple tasks is through the hard parameter sharing approach , in which a single architecture is used to share the same subset of parameters, creating an inductive bias between them during the training process. Due to its simplicity, potential to improve generalization, and reduce computational cost, it has gained the attention of the scientific and industrial communities. However, tasks often conflict with each other, which makes it challenging to define how the gradients of multiple tasks should be combined to allow simultaneous learning. To address this problem, we use the idea of multi-objective optimization to propose a method that takes into account temporal behaviour of the gradients to create a dynamic bias that adjusts the importance of each task during backpropagation . The result of this method is to give more attention to tasks that are diverging or not being benefited during the last iterations, ensuring that the simultaneous learning is heading to the performance maximization of all tasks. As a result, we empirically show that the proposed method outperforms the state-of-the-art approaches on learning conflicting tasks. Unlike the adopted baselines, our method ensures that all tasks reach good generalization performances.},
  archive      = {J_NEUCOM},
  author       = {Angelica Tiemi Mizuno Nakamura and Valdir Grassi Jr and Denis Fernando Wolf},
  doi          = {10.1016/j.neucom.2022.09.042},
  journal      = {Neurocomputing},
  pages        = {43-53},
  shortjournal = {Neurocomputing},
  title        = {Leveraging convergence behavior to balance conflicting tasks in multi-task learning},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatial–temporal modeling for prediction of stylized human
motion. <em>NEUCOM</em>, <em>511</em>, 34–42. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion prediction refers to forecasting human motion in the future given a past motion sequence, which has significant applications in human tracking, automatic motion generation, autonomous driving, human-robotics interaction, etc. Previous works usually used RNN-based methods, focusing on modeling the temporal dynamics of human motion, which have made great effort on content motions. However, it is unclear for their performance on stylized motion, which is with more expressive emotions and states of the human motion. Different styles within the same motion type have similar motion patterns but also subtle variances. This makes it difficult to be predicted. The main idea of this paper is to learn the spatial characteristic of stylized motion and combine it with the temporal dynamics to achieve accurate prediction. We adopt a transformer-based style encoder to learn the motion representation in the pose space and then maps it to the latent space modeled by the constant variance Gaussian mixture model; meanwhile, we use the hierarchical multi-scale RNN as a temporal encoder to capture the temporal dynamics of human motion; finally, we feed the spatial and temporal features into the prediction decoder to predict the next frame. Our experiments on the Human 3.6 M and Stylized MotionDatasets demonstrate that our model has comparable prediction performance with the state-of-the-art motion prediction works on Human 3.6 M and outperforms previous works on stylized human motion prediction.},
  archive      = {J_NEUCOM},
  author       = {Chongyang Zhong and Lei Hu and Shihong Xia},
  doi          = {10.1016/j.neucom.2022.08.075},
  journal      = {Neurocomputing},
  pages        = {34-42},
  shortjournal = {Neurocomputing},
  title        = {Spatial–temporal modeling for prediction of stylized human motion},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Warping resilient scalable anomaly detection in time series.
<em>NEUCOM</em>, <em>511</em>, 22–33. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data is ubiquitous in the real-world problems across various domains including healthcare, social media, and crime surveillance. Detecting anomalies , or irregular and rare events, in time series data, can enable us to find abnormal events in any natural phenomena, which may require special treatment. Moreover, labeled instances of anomaly are hard to get in time series data. On the other hand, time series data, due to its nature, often exhibits localized expansions and compressions in the time dimension which is called warping. These two challenges make it hard to detect anomalies in time series as often such warpings could get detected as anomalies erroneously. Our objective is to build an anomaly detection model that is robust to such warping variations. In this paper, we propose a novel unsupervised time series anomaly detection method, WaRTEm-AD, that operates in two stages. Within the key stage of representation learning , we employ data augmentation through bespoke time series operators which are passed through a twin autoencoder architecture to learn warping-robust representations for time series data. Second, adaptations of state-of-the-art anomaly detection methods are employed on the learnt representations to identify anomalies. We will illustrate that WaRTEm-AD is designed to detect two types of time series anomalies: point and sequence anomalies. We compare WaRTEm-AD with the state-of-the-art baselines and establish the effectiveness of our method both in terms of anomaly detection performance and computational efficiency.},
  archive      = {J_NEUCOM},
  author       = {S. Abilasha and Sahely Bhadra and P. Deepak and Anish Mathew},
  doi          = {10.1016/j.neucom.2022.09.051},
  journal      = {Neurocomputing},
  pages        = {22-33},
  shortjournal = {Neurocomputing},
  title        = {Warping resilient scalable anomaly detection in time series},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust unsupervised feature selection via sparse and
minimum-redundant subspace learning with dual regularization.
<em>NEUCOM</em>, <em>511</em>, 1–21. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature selection, one of the important dimensionality reduction methods for high-dimensional data, has been paid more and more attention by researchers due to its effectiveness of processing the data without labels. However, most unsupervised feature selection methods do not take into account the fact that real data tends to be mixed with noise or outliers, or only consider the sensitivity of the model to them. In addition, the local manifold structure of data is usually preserved by a simple graph based on fixed k k nearest neighbors. On the one hand, the different sample distributions of different data are considered without distinction. On the other hand, simple graph can not well capture the inherent relations between samples when facing multi-modal data. In view of the above problems, a robust unsupervised feature selection algorithm, sparse and minimum-redundant subspace learning with dual regularization (SMRSDR), is proposed in this paper. Specifically, a self-paced learning regularization based on soft weight allocation is introduced into SMRSDR to strictly control the samples’ entry into model learning. Normal samples are allowed to enter model learning in order of their importance, while noise or outliers are strictly blocked out of model learning. Besides, considering the difference in sample distribution and the multimodal nature of data, the traditional simple graph Laplacian regularization is replaced by the hypergraph Laplacian regularization based on adaptive nearest neighbors selection. Furthermore, the sparsity and minimum-redundancy constraints are imposed on the subspace learning framework so that the most representative and minimum-redundant features can be selected. Finally, the objective function of SMRSDR is solved by an alternating iterative optimization algorithm . And a series of experiments are performed to comprehensively prove the effectiveness and superiority of SMRSDR.},
  archive      = {J_NEUCOM},
  author       = {Congying Zeng and Hongmei Chen and Tianrui Li and Jihong Wan},
  doi          = {10.1016/j.neucom.2022.09.074},
  journal      = {Neurocomputing},
  pages        = {1-21},
  shortjournal = {Neurocomputing},
  title        = {Robust unsupervised feature selection via sparse and minimum-redundant subspace learning with dual regularization},
  volume       = {511},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hyperbolic tangent variant-parameter robust ZNN schemes for
solving time-varying control equations and tracking of mobile robot.
<em>NEUCOM</em>, <em>510</em>, 218–232. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-varying Lyapunov and Stein matrix equations (TVLSMEs) are very ubiquitous in engineering applications. To solve TVLSMEs, many zeroing neural networks (ZNNs) activated by nonlinear activation functions have been proposed. In the conventional ZNN schemes, the designed convergence parameters (DCPs) before the nonlinear activation functions are extraordinarily important because DCPs determine their convergent rates basically. However, the DCPs are usually stated to be constant, which is not practical because the DCPs are usually time-varying in realistic hardware situations, especially the external noises injected. Hence, many varying-parameter ZNNs (VP-ZNNs) with time-varying DCPs have been proposed previously. Compared with finite-parameter ZNNs, these traditional VP-ZNNs are proved to have better convergence, however their downside is that DCPs usually increases over time, and becomes even infinite eventually. Evidently, infinity large DCPs would be lack of robustness are unacceptable in practice, especially the external noises injected. Additionally, even if VP-ZNNs converge over time, the growth of DCPs will result in a huge waste of computing resources. Inspired by that, a new hyperbolic tangent varying-parameter ZNNs (HTVP-ZNNs) with time-varying DCPs are proposed in this paper. Considering the noisy environment , we also develop the robust HTVP-ZNNs (HTVPR-ZNNs). Both of them are able to solve the time-variant Lyapunov and Stein matrix equations in prescribed-time. Theoretically the convergent prescribed-time of the HTVPR-ZNN and the upper time threshold of the DCPs are analyzed mathematically. And numerical experiments and trajectory tracking tasks of the mobile robot substantiate the outstanding convergence of the HTVPR-ZNN schemes.},
  archive      = {J_NEUCOM},
  author       = {Jiawei Luo and Hui Yang and Lingli Yuan and Hong Chen and Xuhuan Wang},
  doi          = {10.1016/j.neucom.2022.08.066},
  journal      = {Neurocomputing},
  pages        = {218-232},
  shortjournal = {Neurocomputing},
  title        = {Hyperbolic tangent variant-parameter robust ZNN schemes for solving time-varying control equations and tracking of mobile robot},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic proximal unrolling network for compressive imaging.
<em>NEUCOM</em>, <em>510</em>, 203–217. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressive imaging aims to recover a latent image from under-sampled measurements, suffering from a serious ill-posed inverse problem . Recently, deep neural networks have been applied to this problem with superior results, owing to the learned advanced image priors. These approaches, however, require training separate models for different imaging modalities and sampling ratios , leading to overfitting to specific settings. In this paper, a dynamic proximal unrolling network (dubbed DPUNet) was proposed, which can handle a variety of measurement matrices via one single model without retraining. Specifically, DPUNet can exploit both the embedded observation model via gradient descent and imposed image priors by learned dynamic proximal operators, achieving joint reconstruction. A key component of DPUNet is a dynamic proximal mapping module, whose parameters can be dynamically adjusted at the inference stage and make it adapt to different imaging settings. Moreover, in order to eliminate the image blocking artifacts, an enhanced version DPUNet + is developed, which integrates a dynamic deblocking module and reconstructs jointly with DPUNet to further improve the performance. Experimental results demonstrate that the proposed method can effectively handle multiple compressive imaging modalities under varying sampling ratios and noise levels via only one trained model, and outperform the state-of-the-art approaches. Our code is available at https://github.com/Yixiao-Yang/DPUNet-PyTorch.},
  archive      = {J_NEUCOM},
  author       = {Yixiao Yang and Ran Tao and Kaixuan Wei and Ying Fu},
  doi          = {10.1016/j.neucom.2022.08.034},
  journal      = {Neurocomputing},
  pages        = {203-217},
  shortjournal = {Neurocomputing},
  title        = {Dynamic proximal unrolling network for compressive imaging},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SiSL-net: Saliency-guided self-supervised learning network
for image classification. <em>NEUCOM</em>, <em>510</em>, 193–202. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergent studies and success on contrastive self-supervised learning have been well verified in the pretext task of instance discrimination, which learns visual representations by maximizing agreement between different augmented views of the same image sample (positive pairs). However, randomly cropping on original images may cause that the augmented view contains interference from a large proportion of the backgrounds, referred to as noisy data. Aiming to optimize the data augmentation and improve positive pairs, a Saliency-Augmented Module is proposed to obtain the augmented views, which only contain the ”latent” object area, referred to as clean data. Furthermore, a Saliency-Guided Self-Supervised Learning Network (SiSL-Net) is constructed as a new pattern of contrastive learning. A symmetric structure of trunk net and branch net is trained to learn a feature mapping from the clean data space and the noisy data space. Besides, a novel loss function is designed, including the embedding contrastive loss and distribution consistency loss, to optimize the feature representations during network training. The linear classification performance of our SiSL-Net is evaluated on the mini ImageNet dataset with ResNet-50. Experiments show that our method achieves the top-1 accuracy from 64.67\% to 69.02\%, outperforming the state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Kun Liu and Rui Meng and Longteng Li and Jingkun Mao and Haiyong Chen},
  doi          = {10.1016/j.neucom.2022.09.029},
  journal      = {Neurocomputing},
  pages        = {193-202},
  shortjournal = {Neurocomputing},
  title        = {SiSL-net: Saliency-guided self-supervised learning network for image classification},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A robust scheme for copy detection of 3D object point
clouds. <em>NEUCOM</em>, <em>510</em>, 181–192. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing 3D geometry copy detection research focused on 3D watermarking, which first embeds “watermarks” and then detects the added watermarks. However, this kind of methods is non-straightforward and may be less robust to attacks such as cropping and noise. In this paper, we focus on a fundamental and practical research problem: judging whether a point cloud is plagiarized or copied to another point cloud in the presence of several manipulations (e.g., similarity transformation, smoothing). We propose a novel method to address this critical problem. Our key idea is first to align the two point clouds and then calculate their similarity distance. We design three different measures to compute the similarity. We also introduce two strategies to speed up our method. Comprehensive experiments and comparisons demonstrate the effectiveness and robustness of our method in estimating the similarity of two given 3D point clouds.},
  archive      = {J_NEUCOM},
  author       = {Jiaqi Yang and Xuequan Lu and Wenzhi Chen},
  doi          = {10.1016/j.neucom.2022.09.008},
  journal      = {Neurocomputing},
  pages        = {181-192},
  shortjournal = {Neurocomputing},
  title        = {A robust scheme for copy detection of 3D object point clouds},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MFF: Multi-modal feature fusion for zero-shot learning.
<em>NEUCOM</em>, <em>510</em>, 172–180. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Zero-Shot Learning (ZSL) methods generally generate pseudo-samples/features based on the semantic description information of unseen classes, thereby transforming ZSL tasks into traditional supervised learning tasks. Under this learning paradigm, the quality of pseudo-samples/features guided by the classes’ semantic description information is the key to the success of the model. However, the semantic description information used in the existing generative methods is mainly the low-dimensional representation (e.g., attributes) of classes, which leads to the low quality of the generated pseudo-samples/features and may aggravate the problem of domain shift. To alleviate this problem, we introduce the visual principal component feature, which is extracted by a principal component analysis network, to make up for the deficiency of using only semantic description information and propose a novel Variational Auto-Encoder (VAE) and Generative Adversarial Network (GAN) based generative method for ZSL, which we call Multi-modal Feature Fusion algorithm (MFF). In MFF, the input of different modal information enables VAE better fit the original data distribution and the proposed alignment loss ensures the consistency of the generated visual features and the corresponding semantic features. With the help of high-quality pseudo-samples/features, the ZSL model can make more accurate predictions for unseen classes. Extensive experiments on five public datasets demonstrate that our proposed algorithm outperforms several state-of-the-art methods under both ZSL and generalized ZSL settings.},
  archive      = {J_NEUCOM},
  author       = {Weipeng Cao and Yuhao Wu and Chengchao Huang and Muhammed J.A. Patwary and Xizhao Wang},
  doi          = {10.1016/j.neucom.2022.09.070},
  journal      = {Neurocomputing},
  pages        = {172-180},
  shortjournal = {Neurocomputing},
  title        = {MFF: Multi-modal feature fusion for zero-shot learning},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hypothesis-driven method based on machine learning for
neuroimaging data analysis. <em>NEUCOM</em>, <em>510</em>, 159–171. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There remains an open question about the usefulness and the interpretation of machine learning (ML) approaches for discrimination of spatial patterns of brain images between samples or activation states. In the last few decades, these approaches have limited their operation to feature extraction and linear classification tasks for between-group inference. In this context, statistical inference is assessed by randomly permuting image labels or by the use of random effect models that consider between-subject variability. These multivariate ML-based statistical pipelines, whilst potentially more effective for detecting activations than hypotheses-driven methods, have lost their mathematical elegance, ease of interpretation, and spatial localization of the ubiquitous General linear Model (GLM). Recently, the estimation of the conventional GLM parameters has been demonstrated to be connected to an univariate classification task when the design matrix in the GLM is expressed as a binary indicator matrix . In this paper we explore the complete connection between the univariate GLM and ML-based regressions . To this purpose we derive a refined statistical test with the GLM based on the parameters obtained by a linear Support Vector Regression (SVR) in the inverse problem (SVR-iGLM). Subsequently, random field theory (RFT) is employed for assessing statistical significance following a conventional GLM benchmark . Experimental results demonstrate how parameter estimations derived from each model (mainly GLM and SVR) result in different experimental design estimates that are significantly related to the predefined functional task. Moreover, using real data from a multisite initiative the proposed ML-based inference demonstrates statistical power and the control of false positives , outperforming the regular GLM.},
  archive      = {J_NEUCOM},
  author       = {J.M. Gorriz and R. Martín-Clemente and C.G. Puntonet and A. Ortiz and J. Ramírez and SiPBA group and J. Suckling},
  doi          = {10.1016/j.neucom.2022.09.001},
  journal      = {Neurocomputing},
  pages        = {159-171},
  shortjournal = {Neurocomputing},
  title        = {A hypothesis-driven method based on machine learning for neuroimaging data analysis},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Residual inpainting using selective free-form attention.
<em>NEUCOM</em>, <em>510</em>, 149–158. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has dominated the methodology of image inpainting in recent years. However, many of the existing methods still suffer from the defects of unnatural structure and blurry textures when filling large-area holes. To address this issue, we propose a novel coarse-to-fine residual inpainting framework: we first reconstruct the downsampled low-frequency coarse profile at a low computational cost, we then solely focus on generating high-frequency details, which will be added as residuals to the coarse profile, such that structure and texture details in composited result can be better preserved. Meanwhile, we notice that the existing attention mechanism used to build long-distance dependency is unreasonable: either does not adapt to free-form holes, or lacks filtering for invalid information sources, which could compromise feature map reconstruction. To solve this, we propose an improved Selective Free-Form Attention (SFFA) module, selectively allowing the information flow from the valid sources to hole area with free-form shape. We verify the incremental effectiveness of our contributions. We further show that our model outperforms recent state-of-the-art methods both qualitatively and quantitatively on benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Shiyuan Yang and Yi Wang and Huaiyu Cai and Xiaodong Chen},
  doi          = {10.1016/j.neucom.2022.09.041},
  journal      = {Neurocomputing},
  pages        = {149-158},
  shortjournal = {Neurocomputing},
  title        = {Residual inpainting using selective free-form attention},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical multi-view metric learning with HSIC
regularization. <em>NEUCOM</em>, <em>510</em>, 135–148. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the information era develops rapidly, it’s common to utilize multiple features from different sources to represent one object. Measuring the similarity between multi-view objects is the fundamental task in multi-view learning. To effectively measure the similarity between multi-view samples, multi-view metric learning has gained extensive attention recently. Nevertheless, most existing methods merely focus on the closeness of similar pairs and the separability of dissimilar ones inside each view, so that rich consensus properties existing in multi-views data might be ignored to some extent. To mitigate this issue, we come up with a novel method entitled Hierarchical Multi-view Metric learning with HSIC regularization (HM 2 H). HM 2 H aims to simultaneously maintain the closeness of similar points and the separability of dissimilar ones in intra-view and inter-view. Since multiple views depict different perspectives of the same object, the shared metric is introduced to capture the consensus information among those views. Moreover, we take advantage of the Hilbert–Schmidt Independence Criterion to seek the maximum distribution agreement of the multi-view dataset. Correspondingly, an algorithm based on Alternating Direction Method is provided to solve the proposed HM 2 H. Finally, various experimental results on five visual recognition datasets confirm the effectiveness and feasibility of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Huiyuan Deng and Xiangzhu Meng and Huibing Wang and Lin Feng},
  doi          = {10.1016/j.neucom.2022.09.073},
  journal      = {Neurocomputing},
  pages        = {135-148},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical multi-view metric learning with HSIC regularization},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multivariate change point detection for heterogeneous
series. <em>NEUCOM</em>, <em>510</em>, 122–134. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multivariate change point detection problem has been encountered across various fields. Most approaches to this problem assume the series is homogeneous, i.e., all the coordinates change concurrently. Hence, the specific subset of the coordinates containing the change points cannot be determined. In this work, we propose S-MCPD , which is capable of detecting the position of multivariate change points for heterogeneous series by identifying specific coordinates of those changed. Specifically, the problem is discussed in the context of variable selection and transformed into the form of sparse group lasso. In simulation studies, we compared S-MCPD with four existing methods, inspect , sbs , dc , and cpm . The results showed that the performance of S-MCPD was comparable to that of inspect and was superior to other methods in terms of evaluation metrics . In addition, S-MCPD can determine not only the positions of change points, but also the subset of coordinates containing the change points, while other existing methods are unable to achieve this. Moreover, S-MCPD does not depend on the constant variance assumption and works quite well even when the covariance changes, which makes our method more practical. These are the two important contributions of our work. Finally, we applied S-MCPD to two real-world datasets to show its effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Yuxuan Guo and Ming Gao and Xiaoling Lu},
  doi          = {10.1016/j.neucom.2022.09.021},
  journal      = {Neurocomputing},
  pages        = {122-134},
  shortjournal = {Neurocomputing},
  title        = {Multivariate change point detection for heterogeneous series},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Cross-individual affective detection using EEG signals with
audio-visual embedding. <em>NEUCOM</em>, <em>510</em>, 107–121. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affective computing is an increasing interdisciplinary research field that provides great potential to recognize, understand and express human emotions. Recently, multimodal analysis starts to gain more popularity in affective studies, which could provide a more comprehensive view of emotion dynamics based on the diverse and complementary information from different data modalities. However, the stability and generalizability of current multimodal analysis methods have not been thoroughly developed yet. In this paper, we propose a novel multimodal analysis method ( EEG-AVE : EEG with audio-visual embedding) for cross-individual affective detection, where EEG signals are exploited to identify the emotion-related individual preferences and audio-visual information is leveraged to estimate the intrinsic emotions involved in the multimedia content . EEG-AVE is composed of two main modules. For EEG-based individual preferences prediction module, a multi-scale domain adversarial neural network is developed to explore the shared dynamic, informative, and domain-invariant EEG features across individuals. For video-based intrinsic emotions estimation module, a deep audio-visual feature-based hypergraph clustering method is proposed to examine the latent relationship between semantic audio-visual features and emotions. Through an embedding model, both estimated individual preferences and intrinsic emotions are incorporated with shared weights and further contribute to affective detection across individuals. Experiments on two well-known emotional databases indicate that the proposed EEG-AVE model achieves a better performance under a leave-one-individual-out cross-validation individual-independent evaluation protocol. The results demonstrate that EEG-AVE is an effective model with good reliability and generalizability , which has practical significance in the development of multimodal analysis in affective computing.},
  archive      = {J_NEUCOM},
  author       = {Zhen Liang and Xihao Zhang and Rushuang Zhou and Li Zhang and Linling Li and Gan Huang and Zhiguo Zhang},
  doi          = {10.1016/j.neucom.2022.09.078},
  journal      = {Neurocomputing},
  pages        = {107-121},
  shortjournal = {Neurocomputing},
  title        = {Cross-individual affective detection using EEG signals with audio-visual embedding},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IAMOT: Multi-object tracking with integrated heads and
attention mechanism. <em>NEUCOM</em>, <em>510</em>, 95–106. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-object tracking is one of the most fundamental problems in computer vision with wide industrial applications. It involves the association of multiple targets across consecutive frames. The current trend has been gradually switched from tracking-by-detection paradigm to one-shot trackers. While special efforts have been made on anchor-free methods which turned out to be more suitable for the extraction of re-ID features (than anchor-based methods). However, most of the works used center points to represent the targets and regressed other properties, which lost global information and were unfavorable to ID switches. To address the above issues, we propose IAMOT, a simple yet effective network based on anchor-free architecture. Our network predicts the center point and derives the corner points of an object to obtain a refined bounding box through integrated heads. It also utilizes an additional attention module to weaken the occurrence of ID switches. Extensive experiments have been conducted on 4 mainstream datasets, where IAMOT exhibits superior performances by surpassing other state-of-the-art methods. Especially, we achieve 60.6\% MOTA on MOT15, 75.8\% MOTA on MOT16, 74.4\% MOTA on MOT17 and 64.1\% MOTA on MOT20, respectively.},
  archive      = {J_NEUCOM},
  author       = {Yaoyao Si and Yi Zhang},
  doi          = {10.1016/j.neucom.2022.09.045},
  journal      = {Neurocomputing},
  pages        = {95-106},
  shortjournal = {Neurocomputing},
  title        = {IAMOT: Multi-object tracking with integrated heads and attention mechanism},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep multi-view graph-based network for citywide
ride-hailing demand prediction. <em>NEUCOM</em>, <em>510</em>, 79–94.
(<a href="https://doi.org/10.1016/j.neucom.2022.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban ride-hailing demand prediction is a crucial but challenging task for intelligent transportation system construction. Predictable ride-hailing demand can facilitate more reasonable vehicle scheduling and online car-hailing platform dispatch. Conventional deep learning methods with no external structured data can be accomplished via hybrid models of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) by meshing plentiful pixel-level labeled data, but data sparsity of high grid granularity in spatial perspective and limited learning capabilities of long-term dependencies in temporal perspective are still two striking bottlenecks. To address these problems, we propose a novel virtual graph modeling approach to focus on significant demand regions and a novel Deep Multi-View Spatio-temporal Virtual Graph Neural Network (DMVST-VGNN) to strengthen the learning capabilities of spatial dynamics and long-term temporal dependencies. Specifically, DMVST-VGNN integrates structures of 1D CNN, Multi-Graph Attention Neural Network and Transformer Network, which correspond to short-term temporal dynamics view, spatial dynamics view and long-term temporal dynamics view respectively. In this paper, multiple experiments are conducted on two large-scale New York City datasets in higher granularity prediction scenes. And the experimental results demonstrate the effectiveness of DMVST-VGNN framework in ride-hailing demand prediction, no matter in spatial scale or the temporal scale.},
  archive      = {J_NEUCOM},
  author       = {Guangyin Jin and Zhexu Xi and Hengyu Sha and Yanghe Feng and Jincai Huang},
  doi          = {10.1016/j.neucom.2022.09.010},
  journal      = {Neurocomputing},
  pages        = {79-94},
  shortjournal = {Neurocomputing},
  title        = {Deep multi-view graph-based network for citywide ride-hailing demand prediction},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). KDM: A knowledge-guided and data-driven method for few-shot
video action recognition. <em>NEUCOM</em>, <em>510</em>, 69–78. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few Shot-Video Action Recognition (FS-VAR) has recently aroused great interest with the rise of meta-learning. The generalization ability of complex meta-learning is limited despite that it is effective and prevalent. In this work, we propose a knowledge-guided and data-driven method for FS-VAR, termed as KDM. FV-R(2 + 1) D is initiated in the paper as the feature extraction architecture, which adopts the self-attention mechanism of BERT to cope the time-series in the video and takes full advantage of the data in the training set to guide the construction of support set features. Meanwhile, a transductive inference is incorporated into the N -way K -shot task of FS-VAR, that is, the samples of query set are taken as data-driver, and the statistical information of unlabeled samples in the task is utilized to optimize a fusion loss. Our claim is supported by conducting extensive experiments on three datasets (Kinetics, Something-Something-v2 (SSv2) and HMDB51) that our proposal outperfoms the state-of-the-art FS-VAR methods (more than 10\% average improvement on all settings). In more challenging and realistic FS-VAR scenario, three powerful benchmarks (more ways, more shots and domain shift) are presented, which can be used as benchmarks for future research.},
  archive      = {J_NEUCOM},
  author       = {Yanfei Qin and Baolin Liu},
  doi          = {10.1016/j.neucom.2022.09.011},
  journal      = {Neurocomputing},
  pages        = {69-78},
  shortjournal = {Neurocomputing},
  title        = {KDM: A knowledge-guided and data-driven method for few-shot video action recognition},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ASCL: Adversarial supervised contrastive learning for
defense against word substitution attacks. <em>NEUCOM</em>,
<em>510</em>, 59–68. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attacks with adversarial examples can tremendously worsen the performance of deep neural networks (DNNs). Hence, defending against such adversarial attacks is crucial for nearly all DNN-based applications. Adversarial training is an effective and extensively adopted approach for increasing the robustness of DNNs in which benign examples and their adversarial counterparts are considered together in the training stage. However, this may result in a decrease in accuracy on benign examples because it does not account for the inter-class distance of benign examples. To overcome the aforementioned dilemma, we devise a novel defense approach named adversarial supervised contrastive learning (ASCL), which combines adversarial training with supervised contrastive learning to enhance the robustness of DNN-based models while maintaining their clean accuracy. We validate the effectiveness of the proposed ASCL approach in the scenario of defending against word substitution attacks by means of extensive experiments on benchmark tasks and datasets. The experimental results show that ASCL reduces the attack success rate to 20\% while maintaining the accuracy for clean inputs within a 2\% margin.},
  archive      = {J_NEUCOM},
  author       = {Jiahui Shi and Linjing Li and Daniel Zeng},
  doi          = {10.1016/j.neucom.2022.09.032},
  journal      = {Neurocomputing},
  pages        = {59-68},
  shortjournal = {Neurocomputing},
  title        = {ASCL: Adversarial supervised contrastive learning for defense against word substitution attacks},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PcmNet: Position-sensitive context modeling network for
temporal action localization. <em>NEUCOM</em>, <em>510</em>, 48–58. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal action localization, which aims to locate temporal regions where actions take place and recognize their corresponding classes in untrimmed real-world videos, is a challenging task. As a critical cue to video understanding, exploiting the video context has become an important strategy to boost the localization performance. However, previous methods mainly focus on exploring semantic context which captures the feature similarity among frames or proposals. The temporal position context which is also vital for temporal action localization is less explored. In this paper, we propose a position-sensitive context modeling approach to fuse both semantic and position context for more precise action localization. Specifically, we first propose a position encoding method tailored for temporal action localization on both frame-level and proposal-level, which ensures that the generated position representations can model the distance and chronological relationships among frames or proposals. Then we conduct attention-based context aggregation to produce discriminative features and help with precise boundary detection and proposal evaluation. Our method achieves state-of-the-art performance on two widely used datasets, THUMOS-14 and ActivityNet-1.3, demonstrating the effectiveness and generalizability of our method.},
  archive      = {J_NEUCOM},
  author       = {Xin Qin and Hanbin Zhao and Guangchen Lin and Hao Zeng and Songcen Xu and Xi Li},
  doi          = {10.1016/j.neucom.2022.08.040},
  journal      = {Neurocomputing},
  pages        = {48-58},
  shortjournal = {Neurocomputing},
  title        = {PcmNet: Position-sensitive context modeling network for temporal action localization},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decentralized adaptive neural asymptotic control of switched
nonlinear interconnected systems with predefined tracking performance.
<em>NEUCOM</em>, <em>510</em>, 37–47. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article aims at the problem of decentralized adaptive neural asymptotic tracking for switched nonlinear interconnected systems with unknown strong interconnections and predefined transient performance. Technically, unknown strong interconnection terms are handled by intrinsic properties of the basis function vector. In addition, unlike prescribed performance bound control, a new error-dependent transformation with a time-varying function is proposed, which completely circumvents the initial condition-dependence problem. With such transformation and a class of integral bounded-based tuning functions, a decentralized adaptive neural asymptotic control strategy is established so that closed-loop stability can be preserved, and the output tracking error not only asymptotically converges to zero but also evolves within the prescribed boundary. Finally, illustrative examples validate the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Danping Zeng and Zhi Liu and C.L. Philip Chen and Yun Zhang and Zongze Wu},
  doi          = {10.1016/j.neucom.2022.08.062},
  journal      = {Neurocomputing},
  pages        = {37-47},
  shortjournal = {Neurocomputing},
  title        = {Decentralized adaptive neural asymptotic control of switched nonlinear interconnected systems with predefined tracking performance},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Video segmentation via target objectness constraint and
multi-head soft aggregation. <em>NEUCOM</em>, <em>510</em>, 24–36. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objectness is a notion of how a generic object looks like. Recently, matching-based methods have yielded impressive video object segmentation results. However, these methods suffer from mis-segmentation of distractors that are distant from the targets due to the lack of objectness constraint. The segmentation mask has a very low objectness when both the correct object and the distant distractor are considered as a target. Position information is also ignored in matching-based methods. In this paper, a video object segmentation method based on target objectness constraint and multi-head soft aggregation is proposed. The target objectness constraint is introduced by forcing the network to learn to predict object center and pixel-to-object boundary distances. The problem of mis-segmentation of objects or regions with similar appearance at a distance is alleviated. Besides, the target position consistency constraint is strengthened by introducing the target position information in the feature matching of adjacent frames. Furthermore, an instance attention mechanism is implemented using multi-head soft aggregation to re-calibrate channel importance. Multi-head soft aggregation enables better utilization of target feature information than global average pooling. Comprehensive experiments demonstrate that the proposed method obtains a competitive performance, surpassing many other existing methods.},
  archive      = {J_NEUCOM},
  author       = {Hui Wang and Weibin Liu and Weiwei Xing and Shunli Zhang},
  doi          = {10.1016/j.neucom.2022.08.065},
  journal      = {Neurocomputing},
  pages        = {24-36},
  shortjournal = {Neurocomputing},
  title        = {Video segmentation via target objectness constraint and multi-head soft aggregation},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Category-learning attention mechanism for short text
filtering. <em>NEUCOM</em>, <em>510</em>, 15–23. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In machine translation, the attention mechanism highlights relevant words according to the distances between the source and target vectors dynamically. However, its ability to optimize text classification is limited because this mechanism only calculates weights inside the same text. There is an uneven distribution of words between ham (not spam) and spam categories, and this category-level feature has not previously been utilized in the attention mechanism for filtering short texts. In addition, short text filtering is uniquely challenging due to the length, sparsity and informal writing of texts, as well as a need for rapid processing. We propose a novel category-level attention mechanism called “category-learning attention,” which highlights words intensely distributed in the same category by dynamically calculating a category differentiation matrix for each short text. The category-learning attention mechanism is extended to the category-learning scaled-dot-product attention and the category-learning multi-head attention (CL-MHA) mechanisms. The CL-MHA mechanism is then applied to a bidirectional gate recurrent unit (Bi-GRU) model for performance evaluation by using the SMS spam collection dataset hosted at the University of California, Irvine. Performance metrics including the accuracy, precision, recall, and F1 score demonstrate that the CL-MHA mechanism significantly improves the performance of Bi-GRU for short text filtering with an accuracy of 99.35\%, higher than any previously reported machine learning models. In addition, experiments conducted on three datasets - a Chinese SMS spam dataset, a benchmark movie review dataset, and a benchmark customer review dataset - further validate the effectiveness of the proposed model. The proposed CL-MHA Bi-GRU model has an accuracy of 99.46\% when evaluated on the Chinese SMS spam dataset.},
  archive      = {J_NEUCOM},
  author       = {Tian Xia and Xuemin Chen},
  doi          = {10.1016/j.neucom.2022.08.076},
  journal      = {Neurocomputing},
  pages        = {15-23},
  shortjournal = {Neurocomputing},
  title        = {Category-learning attention mechanism for short text filtering},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary bagging for ensemble learning. <em>NEUCOM</em>,
<em>510</em>, 1–14. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning has gained success in machine learning with major advantages over other learning methods. Bagging is a prominent ensemble learning method that creates subgroups of data, known as bags, that are trained by individual machine learning methods such as decision trees . Random forest is a prominent example of bagging with additional features in the learning process. Evolutionary algorithms have been prominent for optimisation problems and also been used for machine learning. Evolutionary algorithms are gradient-free methods that work with a population of candidate solutions that maintain diversity for creating new solutions. In conventional bagged ensemble learning, the bags are created once and the content, in terms of the training examples, are fixed over the learning process. In our paper, we propose evolutionary bagged ensemble learning, where we utilise evolutionary algorithms to evolve the content of the bags in order to iteratively enhance the ensemble by providing diversity in the bags. The results show that our evolutionary ensemble bagging method outperforms conventional ensemble methods (bagging and random forests) for several benchmark datasets under certain constraints. We find that evolutionary bagging can inherently sustain a diverse set of bags without reduction in performance accuracy.},
  archive      = {J_NEUCOM},
  author       = {Giang Ngo and Rodney Beard and Rohitash Chandra},
  doi          = {10.1016/j.neucom.2022.08.055},
  journal      = {Neurocomputing},
  pages        = {1-14},
  shortjournal = {Neurocomputing},
  title        = {Evolutionary bagging for ensemble learning},
  volume       = {510},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Long-tailed visual recognition with deep models: A
methodological survey and evaluation. <em>NEUCOM</em>, <em>509</em>,
290–309. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real world, large-scale datasets for visual recognition typically exhibit a long-tailed distribution, where only a few classes contain adequate samples but the others have (much) fewer samples. With the advancement of data-hungry deep models for visual recognition, the low-tail power-law data distribution that biases the model training has attracted significant attention. When training with the long-tailed data, the majority classes dominate the training procedure, resulting in poor performance in instance-scarce classes. To tackle this problem, numerous strategies, such as re-sampling, cost-sensitive loss, meta-learning and transfer learning , have been proposed. This paper systematically reviews contemporary approaches for the long-tailed visual recognition task and categorizes these methods based on the stage applied as training, fine-tuning, and inference. Furthermore, we categorize training stage methods into data augmentation , re-sampling strategy, cost-sensitive loss, as well as multiple experts and transfer learning . Next, comprehensive comparisons are made in the balanced test set performance of long-tailed benchmarks and method robustness in diverse test distributions using metrics including top-1 accuracy, per-class accuracy, multi-class ROC AUC and Expected Calibration Error (ECE). At last, we outline the challenges in this field and future research trends. Our reviews and intriguing findings can be a tutorial for researchers working in the field of open-world deep learning .},
  archive      = {J_NEUCOM},
  author       = {Yu Fu and Liuyu Xiang and Yumna Zahid and Guiguang Ding and Tao Mei and Qiang Shen and Jungong Han},
  doi          = {10.1016/j.neucom.2022.08.031},
  journal      = {Neurocomputing},
  pages        = {290-309},
  shortjournal = {Neurocomputing},
  title        = {Long-tailed visual recognition with deep models: A methodological survey and evaluation},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on low speed low power axial flux generator design
and optimization using simulation. <em>NEUCOM</em>, <em>509</em>,
272–289. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Axial Flux Generator is a permanent magnet generator commonly used for low-speed power generation using wind power. This generator can generate useful amount of power even under very low revolutions per minute (rpm). Over the last three decades, many researchers and engineers have developed plethora of designs with varying success. Due to the commercial availability of rare-earth magnets such as NdFeB with very high magnetic flux density at very low prices, the propensity to develop new designs have sky rocketed. Yet, many designs even with the availability of many advanced analytical software tools have failed to produce useful amount of power under very low wind speeds. When the world is heading towards a more conscionable climate policy, wind power remains in the forefront of green energy. However, one major challenge in utilizing wind power is the inability of the small-scale generators to generate useful amount of power at very low wind speeds. This poses a formidable challenge to the scientific community to come up with the simplest, affordable and the most efficient design in harnessing wind power at very low wind speeds; that is the most common situation around the world. This research is the result of comprehensive and an exhaustive effort in bringing the best designs into the forefront of research by critiquing innovative designs for their strengths and weaknesses. Almost all the work in the literature has failed to realize the impact of the crucial parameters such as coil shape, coil distance and rare-earth magnet shape and their distances from each other on the eventual generator efficiency. This has resulted in most of the designs producing a very low output at very low revolutions. This article will present a comprehensive survey of best designs in axial flux generators followed by a mathematical analysis of coil shapes, magnet shapes and gaps between these coils and magnets. Then the article will present a very comprehensive electromagnetic simulations with multiple iterations in an effort to optimize the many parameters which have not been analysed in previous works. This new insight will open the research to a new height in achieving high efficiency in future designs.},
  archive      = {J_NEUCOM},
  author       = {Prashan Premaratne and Inas Jawad Kadhim and Muhammad Qadim Abdullah and Brendan Halloran and Peter James Vial},
  doi          = {10.1016/j.neucom.2022.07.004},
  journal      = {Neurocomputing},
  pages        = {272-289},
  shortjournal = {Neurocomputing},
  title        = {A survey on low speed low power axial flux generator design and optimization using simulation},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Corrigendum to “deep learning for brain disorder diagnosis
based on fMRI images” [neurocomputing 469 (2022) 332–345].
<em>NEUCOM</em>, <em>509</em>, 271. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Wutao Yin and Longhai Li and Fang-Xiang Wu},
  doi          = {10.1016/j.neucom.2022.08.074},
  journal      = {Neurocomputing},
  pages        = {271},
  shortjournal = {Neurocomputing},
  title        = {Corrigendum to “Deep learning for brain disorder diagnosis based on fMRI images” [Neurocomputing 469 (2022) 332–345]},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A conditional one-output likelihood formulation for
multitask gaussian processes. <em>NEUCOM</em>, <em>509</em>, 257–270.
(<a href="https://doi.org/10.1016/j.neucom.2022.08.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multitask Gaussian processes (MTGP) are the Gaussian process (GP) framework’s solution for multioutput regression problems in which the T T elements of the regressors cannot be considered conditionally independent given the observations. Standard MTGP models assume that there exist both a multitask covariance matrix as a function of an intertask matrix, and a noise covariance matrix . These matrices need to be approximated by a low rank simplification of order P P in order to reduce the number of parameters to be learnt from T 2 T2 to TP TP . Here we introduce a novel approach that simplifies the multitask learning process by reducing it to a set of conditioned univariate GPs without the need for any low rank approximations, therefore completely eliminating the need to select an adequate value for hyperparameter P P . At the same time, by extending this approach with both a hierarchical and an approximate model, the proposed extensions are capable of recovering the multitask covariance and noise matrices after learning only 2 T 2T parameters, avoiding the validation of any model hyperparameter and reducing the overall complexity of the model as well as the risk of overfitting. Experimental results over synthetic and real problems confirm the advantages of this inference approach in its ability to accurately recover the original noise and signal matrices, as well as the achieved performance improvement in comparison to other state of art MTGP approaches. We have also integrated the model with standard GP toolboxes, showing that it is computationally competitive with state of the art options.},
  archive      = {J_NEUCOM},
  author       = {Óscar García-Hinde and Manel Martínez-Ramón and Vanessa Gómez-Verdejo},
  doi          = {10.1016/j.neucom.2022.08.064},
  journal      = {Neurocomputing},
  pages        = {257-270},
  shortjournal = {Neurocomputing},
  title        = {A conditional one-output likelihood formulation for multitask gaussian processes},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep transform and metric learning network: Wedding deep
dictionary learning and neural network. <em>NEUCOM</em>, <em>509</em>,
244–256. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On account of its many successes in inference tasks and imaging applications, Dictionary Learning (DL) and its related sparse optimization problems have garnered a lot of research interest. In DL area, most solutions are focused on single-layer dictionaries, whose reliance on handcrafted features achieves a somewhat limited performance. With the rapid development of deep learning, improved DL methods called Deep DL (DDL), have been recently proposed an end-to-end flexible inference solution with a much higher performance. The proposed DDL techniques have, however, also fallen short on a number of issues, namely, computational cost and the difficulties in gradient updating and initialization. While a few differential programming solutions have been proposed to speed-up the single-layer DL, none of them could ensure an efficient, scalable, and robust solution for DDL methods. To that end, we propose herein, a novel differentiable programming approach, which yields an efficient, competitive and reliable DDL solution. The novel DDL method jointly learns deep transforms and deep metrics, where each DL layer is theoretically reformulated as a combination of one linear layer and a Recurrent Neural Network (RNN). The RNN is also shown to flexibly account for the layer-associated approximation together with a learnable metric. Additionally, our proposed work unveils new insights into Neural Network (NN) and DDL, bridging the combinations of linear and RNN layers with DDL methods. Extensive experiments on image classification problems are carried out to demonstrate that the proposed method can not only outperform existing DDL several counts including, efficiency, scaling and discrimination, but also achieve better accuracy and increased robustness against adversarial perturbations than CNNs.},
  archive      = {J_NEUCOM},
  author       = {Wen Tang and Emilie Chouzenoux and Jean-Christophe Pesquet and Hamid Krim},
  doi          = {10.1016/j.neucom.2022.08.069},
  journal      = {Neurocomputing},
  pages        = {244-256},
  shortjournal = {Neurocomputing},
  title        = {Deep transform and metric learning network: Wedding deep dictionary learning and neural network},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting human-object interactions in videos by modeling
the trajectory of objects and human skeleton. <em>NEUCOM</em>,
<em>509</em>, 234–243. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on the task of detecting human-object interactions (HOI) in videos, with the goal of identifying objects interacting with humans and predicting human-object interaction classes. Two frameworks are proposed which detect human-object interactions in videos by modeling the trajectory of objects and human skeleton. The first framework (knowledge-based spatial–temporal HOI) treats the entire scene to be a HOI graph made up of the human skeleton and objects. It has fewer parameters and a higher possibility for knowledge embedding. The second framework (hierarchical spatial–temporal HOI) constructs a HOI graph after obtaining the feature of the human skeleton and objects. It outperforms the competition in terms of performance and generalization. Experimental results in CAD-120 dataset and SYSU-HOI dataset show that the proposed frameworks are more advanced than the state-of-the-art methods, with smaller parameters and shorter inference time. Such results confirm that the proposed frameworks effectively reduce parameters and inference time while maintaining detection accuracy in HOI videos.},
  archive      = {J_NEUCOM},
  author       = {Qiyue Li and Xuemei Xie and Chen Zhang and Jin Zhang and Guangming Shi},
  doi          = {10.1016/j.neucom.2022.08.008},
  journal      = {Neurocomputing},
  pages        = {234-243},
  shortjournal = {Neurocomputing},
  title        = {Detecting human-object interactions in videos by modeling the trajectory of objects and human skeleton},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Novel global exponential stability results for a class of
two-coupled-hub nonlinear genetic regulatory networks with time-varying
delays. <em>NEUCOM</em>, <em>509</em>, 221–233. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work studies global exponential stability analysis for a class of nonlinear genetic regulatory networks (GRNs) with two-coupled-hub structure and time-varying delays. It is important to study the influence of hub genes in GRNs problem, due to there is the complexity arising from the interactions among hub gene nodes. In this article, the existence of GRN’s nonnegative equilibriums is presented and a sufficient condition such that all nonnegative equilibriums are positive can be further proved. In addition, novel global exponential stability (GES) criteria of coupled nonlinear GRN is established based on a Metzler matrix method. Furthermore, under the proposed delay-dependent and -independent GES sufficient conditions, it proves the considered GRNs has a unique non-negative GES equilibrium point. Compared with the existing GES criteria, it is worth stressing that the proposed GES conditions are easily verified by computing relative matrices eigenvalues and induced norms. Finally, the validity of the theoretical results is verified by three simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Xiaona Yang and Xin Wang and Zexing Liu and Thach Ngoc Dinh},
  doi          = {10.1016/j.neucom.2022.08.063},
  journal      = {Neurocomputing},
  pages        = {221-233},
  shortjournal = {Neurocomputing},
  title        = {Novel global exponential stability results for a class of two-coupled-hub nonlinear genetic regulatory networks with time-varying delays},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stability analysis of quaternion-valued BAM neural networks
fractional-order model with impulses and proportional delays.
<em>NEUCOM</em>, <em>509</em>, 206–220. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a class of quaternion-valued BAM neural networks (QVBAMNNs) fractional-order model with impulses and proportional delays is proposed in discrete-time case. The QVBAMNNs fractional-order model is investigated directly rather than through real decomposition method or the plural one. By employing homeomorphic mapping theorem, Lyapunov stability theory and inequality technology, several criteria for the discrete-time QVBAMNNs fractional-order model are derived to guarantee the existence, uniqueness and global exponential stability (GES) of equilibrium point. The novelty of these results comes from the generality with the fractional-order systems and the integer-order ones. Finally, two examples are given to demonstrate the effectiveness and availability of the derived criteria.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Mao and Xiaomei Wang and Hongying Qin},
  doi          = {10.1016/j.neucom.2022.08.059},
  journal      = {Neurocomputing},
  pages        = {206-220},
  shortjournal = {Neurocomputing},
  title        = {Stability analysis of quaternion-valued BAM neural networks fractional-order model with impulses and proportional delays},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A transformer-based low-resolution face recognition method
via on-and-offline knowledge distillation. <em>NEUCOM</em>,
<em>509</em>, 193–205. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been widely noticed the performance of algorithms for high-resolution face recognition (HRFR) degrades significantly for low-resolution face recognition (LRFR). In this paper, we discover the main source of this performance degradation comes from the human-defined inductive bias of CNN, which constrains the model to absorb effective information and leads to overfitting. To overcome the shortcoming, for the first time, we adopt a transformer-based DNN algorithm named DeiT to accomplish LRFR tasks. On the other hand, we further borrow the form of knowledge distillation . Traditional knowledge distillation network for LRFR sets the student model to be simpler than or the same as the teacher model while using the teacher model off-the-shelf, leading to the model capacity gap. Instead, we fuse an online network into the original parameter-fixed teacher model to learn how to transfer knowledge. The final “knowledge” is the sum fusion of the outputs of both the teacher model and the student model. Experiments show that even without training on LR face images, the performance of our model can be comparable to recent baselines delicately designed for LRFR tasks on certain LR face datasets. After the entire training process, in either real-world LR datasets, artificially down-sampled datasets, or generated LR face datasets, our method performs favorably against the state-of-the-art (SOTA) algorithms.},
  archive      = {J_NEUCOM},
  author       = {Yaozhe Song and Hongying Tang and Fangzhou Meng and Chaoyi Wang and Mengmeng Wu and Ziting Shu and Guanjun Tong},
  doi          = {10.1016/j.neucom.2022.08.058},
  journal      = {Neurocomputing},
  pages        = {193-205},
  shortjournal = {Neurocomputing},
  title        = {A transformer-based low-resolution face recognition method via on-and-offline knowledge distillation},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep neural network methods for solving forward and inverse
problems of time fractional diffusion equations with conformable
derivative. <em>NEUCOM</em>, <em>509</em>, 177–192. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fractional diffusion equations with conformable derivative have become an important research topic in Newtonian mechanics, quantum mechanics, arbitrary time scale problems, diffusion transport, neutron dynamics and other fields. In this paper, we propose to study time fractional diffusion equations with conformable derivative by using physics-informed neural networks (PINNs) for the first time. By solving the supervised learning task, we design a new spatio-temporal function approximator with high data efficiency. L-BFGS algorithm is used to optimize our loss function, and back propagation algorithm is used to update our parameters to give the numerical solutions. Since the conformable derivative satisfies the Leibniz rule and the chain rule, we can directly derive the network through automatic differentiation without any additional numerical discretization or truncation. For the forward problem, we can take IC/BCs as the data, and use PINNs to solve the corresponding partial differential equation . Three numerical examples are carried out to demonstrate the effectiveness of our methods. In particular, when the order of the conformable fractional derivative α α tends to 1, a class of weighted PINNs is introduced to overcome the accuracy degradation caused by the singularity of solutions. For the inverse problem , we use the obtained data to train the neural network and specify the estimation of the parameter λ λ in the equation. Numerical results show that the proposed method is easy to implement and can accurately identify parameters, even when the training data is corrupted by 1\% uncorrelated noise.},
  archive      = {J_NEUCOM},
  author       = {Yinlin Ye and Hongtao Fan and Yajing Li and Xinyi Liu and Hongbing Zhang},
  doi          = {10.1016/j.neucom.2022.08.030},
  journal      = {Neurocomputing},
  pages        = {177-192},
  shortjournal = {Neurocomputing},
  title        = {Deep neural network methods for solving forward and inverse problems of time fractional diffusion equations with conformable derivative},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-attention eidetic 3D-LSTM: Video prediction models for
traffic flow forecasting. <em>NEUCOM</em>, <em>509</em>, 167–176. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video prediction is extremely challenging in a traffic flow forecasting problem due to dynamic spatiotemporal dependence. Eidetic 3D convolutional long short-term memory (E3D-LSTM) network, a state-of-the-art video prediction model, proposes a gate-controlled self-attention module called recall gate in the LSTM mechanism to make the present memory state interact with its historical records for long-term relations. Instead of using the gate-controlled self-attention mechanism, we introduce a query-key-value self-attention mechanism into E3D-LSTM for long-term relations from the perspectives of algorithm (internal) and network architecture (external). As for the algorithm (internal) perspective, we replace the original recall gate inside the E3D-LSTM cell with a query-key-value self-attention (SA) module. While for the network architecture (external) perspective, we propose an independent residual query-key-value self-attention (RSA) block outside E3D-LSTM networks in conjunction with the original recall gate. In a traffic flow forecasting problem, we find that both the models from the internal perspective and the external one, named SAE3D-LSTM and RSA-E3D-LSTM, outperform E3D-LSTM and seven other baseline models on three traffic datasets. This validates the effectiveness of the query-key-value self-attention mechanism for long-term relations. Furthermore, we find that SAE3D-LSTM performs better than RSA-E3D-LSTM. This indicates that the query-key-value self-attention mechanism alone can capture long-term relations, dispensing with the gate-controlled self-attention mechanism.},
  archive      = {J_NEUCOM},
  author       = {Xiao Yan and Xianghua Gan and Rui Wang and Taojie Qin},
  doi          = {10.1016/j.neucom.2022.08.060},
  journal      = {Neurocomputing},
  pages        = {167-176},
  shortjournal = {Neurocomputing},
  title        = {Self-attention eidetic 3D-LSTM: Video prediction models for traffic flow forecasting},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Balanced spatial feature distillation and pyramid attention
network for lightweight image super-resolution. <em>NEUCOM</em>,
<em>509</em>, 157–166. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the attention mechanism became the key issue for image super-resolution (SR) because it has the ability to extract different features from the image according to the used attention type. Despite the great success of attention-based methods, the conflict among features of different attention types can affect the SR performance. In this paper, we propose an efficient single image SR model called balanced spatial feature distillation and pyramid attention (BSPAN). The idea of BSPAN is based on the trade-off among the extracted features of different attention types. Also, we propose a balanced spatial feature distillation block (BSFDB) as the backbone of BSPAN so that the network can effectively advantage from the different attention features. Two different attention types, namely spatial attention residual feature distillation (SARFD) and classical attention (CA) are considered in the BSFDB to achieve a leveling between them based on the contents of the low-resolution feature map using the balancing attention block. The BSFDB block is designed to improve the SR performance and has lightweight parameters and low computation complexity. Moreover, to further improve the SR performance, the pyramid attention is introduced in the middle of the BSPAN network for extracting long-range features at a variety of locations and scales. Evaluation based on five benchmark datasets, we concluded that the balancing between features of a variety of attention types can effectively improve the SR performance. So, the proposed BSPAN model achieves significant enhancements in comparison with the state-of-the-art and superior visual quality and reconstruction accuracy .},
  archive      = {J_NEUCOM},
  author       = {Garas Gendy and Nabil Sabor and Jingchao Hou and Guanghui He},
  doi          = {10.1016/j.neucom.2022.08.053},
  journal      = {Neurocomputing},
  pages        = {157-166},
  shortjournal = {Neurocomputing},
  title        = {Balanced spatial feature distillation and pyramid attention network for lightweight image super-resolution},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Preventing oversmoothing in VAE via generalized variance
parameterization. <em>NEUCOM</em>, <em>509</em>, 137–156. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational autoencoders (VAEs) often suffer from posterior collapse, which is a phenomenon in which the learned latent space becomes uninformative. This is often related to the hyperparameter resembling the data variance. It can be shown that an inappropriate choice of this hyperparameter causes the oversmoothness in the linearly approximated case and can be empirically verified for the general cases. Moreover, determining such appropriate choice becomes infeasible if the data variance is non-uniform or conditional. Therefore, we propose VAE extensions with generalized parameterizations of the data variance and incorporate maximum likelihood estimation into the objective function to adaptively regularize the decoder smoothness. The images generated from proposed VAE extensions show improved Fréchet inception distance (FID) on MNIST and CelebA datasets.},
  archive      = {J_NEUCOM},
  author       = {Yuhta Takida and Wei-Hsiang Liao and Chieh-Hsin Lai and Toshimitsu Uesaka and Shusuke Takahashi and Yuki Mitsufuji},
  doi          = {10.1016/j.neucom.2022.08.067},
  journal      = {Neurocomputing},
  pages        = {137-156},
  shortjournal = {Neurocomputing},
  title        = {Preventing oversmoothing in VAE via generalized variance parameterization},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Brain-computer interface (BCI)-generated speech to control
domotic devices. <em>NEUCOM</em>, <em>509</em>, 121–136. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A brain-computer interface (BCI) is a type of technology that establishes a communication channel between a user and certain devices in the environment via the brain signals of the user. The UMA-BCI Speller tool allows for easy configuration of a BCI, permitting it to be manipulated without the need for much technical knowledge. However, adapting a BCI system so that it can communicate with devices is a challenging task. A simpler technology that is increasingly used to enable communication with devices in the environment is based on voice commands. The aim of the present work is therefore to create a system to facilitate communication between a BCI and devices in the environment using voice commands. Twelve healthy participants and three amyotrophic lateral sclerosis (ALS) patients were asked to control a BCI home automation system. The devices to be controlled were a television, an air conditioner , a smart light bulb, a smart plug, and the WhatsApp and Spotify apps. Performance measures were recorded, and subjective measures were collected based on the System usability scale , NASA-TLX and ad hoc questionnaires. The results of this study validate the proposed system as a suitable option to facilitate communication between a BCI and commercial devices that have been previously adapted to operate based on voice commands.},
  archive      = {J_NEUCOM},
  author       = {Francisco Velasco-Álvarez and Álvaro Fernández-Rodríguez and Ricardo Ron-Angevin},
  doi          = {10.1016/j.neucom.2022.08.068},
  journal      = {Neurocomputing},
  pages        = {121-136},
  shortjournal = {Neurocomputing},
  title        = {Brain-computer interface (BCI)-generated speech to control domotic devices},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Capsule networks for image classification: A review.
<em>NEUCOM</em>, <em>509</em>, 102–120. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few years, the computer vision domain has evolved and made a revolutionary transition from human-engineered features to automated features to address challenging tasks. Computer vision is an ever-evolving domain with its roots deeply correlated with neuroscience ; any new findings that trigger a more intuitive understanding and working of the human visual system generally impact the design strategy of computer vision algorithms . The convolutional neural network is one such algorithm that is currently the de facto standard for most computer vision tasks such as image classification , object detection, image segmentation , etc. As convolutional neural networks are associated with inherent constraints such as the requirement for an immense amount of labeled data and an inefficient data routing policy, capsule networks could be a viable alternative. Upheld by the backpropagation and the dynamic routing algorithm , the capsule network has set the new paradigm for developing reliable computer vision algorithms . Despite the phenomenal theoretical backing from neuroscience and the groundbreaking performance on benchmark datasets, the lack of information concerning the conception and working of capsule networks becomes the major impediment to adopting them for computer vision algorithms. This paper presents a concise overview of capsule network-based classification architectures, routing algorithms, performance analysis, limitations, and future scope, helping the research community to adopt capsule networks at the forefront of modern computer vision research.},
  archive      = {J_NEUCOM},
  author       = {S.J. Pawan and Jeny Rajan},
  doi          = {10.1016/j.neucom.2022.08.073},
  journal      = {Neurocomputing},
  pages        = {102-120},
  shortjournal = {Neurocomputing},
  title        = {Capsule networks for image classification: A review},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LSNet: Real-time attention semantic segmentation network
with linear complexity. <em>NEUCOM</em>, <em>509</em>, 94–101. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From high-resolution images to get context information remains a challenge in real-time semantic segmentation . Despite recent advances in context information acquisition based on Self-Attention,the Self-Attention module will cause the calculation degree to increase exponentially when facing the semantic segmentation task. In this article, we propose a real-time semantic segmentation network (LSNet) which strikes a balance between segmentation accuracy and inference speed. Firstly, we propose a linear attention module to reduce the computational complexity of Self-Attention from O ( n 2 ) O(n2) to O ( n ) O(n) . Secondly, we propose a context information fusion module by using a cross-attention mechanism to fill in a lot of spatial details for high-level semantic information. Finally, we design a real-time semantic segmentation network LSNet to greatly improve the real-time inference speed and ensure the accuracy of network segmentation . To verify the effectiveness of the LSNet network, we conducted a lot of comparative experiments on CamVid, Cityscapes, COCO-Stuff datasets, and the experimental results show that LSNet achieves an excellent trade-off between accuracy and speed on both Cityscapes, CamVid and COCO-Stuff datasets.},
  archive      = {J_NEUCOM},
  author       = {Pengpeng Sheng and Yanli Shi and Xin Liu and Huan Jin},
  doi          = {10.1016/j.neucom.2022.08.049},
  journal      = {Neurocomputing},
  pages        = {94-101},
  shortjournal = {Neurocomputing},
  title        = {LSNet: Real-time attention semantic segmentation network with linear complexity},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-media retrieval of scientific and technological
information based on multi-feature fusion. <em>NEUCOM</em>,
<em>509</em>, 85–93. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, People’s lives are filled with all kinds of information. Scientific and technological information is utilized for scholars to understand the current technology trends, and to think about the source of information for future development prospects. More and more scholars are no longer satisfied with single-modal retrieval methods . However, to get more intelligent cross-media retrieval results we should give higher requirements to the search engine. And how to span the semantic gap between different modalities is a key issue that needs to be solved. In response to the above problems, this paper proposes a Multi-feature Fusion based Cross-Media Retrieval (MFCMR) method. Our method is capable of integrating multiple features to promote semantic understanding, and adopting adversarial learning to further improve the accuracy of public subspace representation. Then we use similarity in the same space to sort the retrieval results. We conduct a lot of experiments on real datasets, and the results show that our method obtains better cross-media retrieval performance than other methods.},
  archive      = {J_NEUCOM},
  author       = {Yang Jiang and Junping Du and Zhe Xue and Ang Li},
  doi          = {10.1016/j.neucom.2022.06.061},
  journal      = {Neurocomputing},
  pages        = {85-93},
  shortjournal = {Neurocomputing},
  title        = {Cross-media retrieval of scientific and technological information based on multi-feature fusion},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recurrent neural network-induced gaussian process.
<em>NEUCOM</em>, <em>509</em>, 75–84. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we develop a recurrent neural network-induced Gaussian process (RNNGP) to model sequence data. We derive the equivalence between infinitely wide neural networks and Gaussian processes (GPs) for a relaxed recurrent neural network (RNN) with untied weights. We compute the covariance function of the RNNGP using an analytical iteration formula derived through the RNN procedure with an error-function-based activation function. To simplify our discussion, we use the RNNGP to perform Bayesian inference on vanilla RNNs for various problems, such as Modified National Institute of Standards and Technology digit identification, Mackey–Glass time-series forecasting, and lithium-ion battery state-of-health estimation. The results demonstrate the flexibility of the RNNGP in modeling sequence data. Furthermore, the RNNGP predictions typically outperform those of the original RNNs and GPs , demonstrating the efficiency of the RNNGP as a data-driven model. Moreover, the RNNGP can quantify the uncertainty in the predictions, which implies the significant potential of the RNNGP in uncertainty quantification analyses.},
  archive      = {J_NEUCOM},
  author       = {Xiang Sun and Seongyoon Kim and Jung-Il Choi},
  doi          = {10.1016/j.neucom.2022.07.066},
  journal      = {Neurocomputing},
  pages        = {75-84},
  shortjournal = {Neurocomputing},
  title        = {Recurrent neural network-induced gaussian process},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bert-QAnet: BERT-encoded hierarchical question-answer
cross-attention network for duplicate question detection.
<em>NEUCOM</em>, <em>509</em>, 68–74. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community Question Answering (CQA) provides platforms for users with different backgrounds to share information and knowledge. With the increasing popularity of CQA, more and more question-answer (Q-A) pairs, with numerous duplicates, have accumulated. Therefore, many researchers focus on detecting duplicate questions in CQA. However, most existing techniques utilize only questions to solve the duplicate question detection task, while paired answers which may also contain necessary information are not considered. In this paper, we propose a BERT-encoded Hierarchical Question-Answer Cross-Attention Network for Duplicate Question Detection (Bert-QAnet) for detecting duplicate questions. Our model applies BERT to encode text and extract text features. Further, we use cross-attention to integrate word-level features both in question and answer. Also, inner attention is used to capture the interaction between question and answer. Hence, our model Bert-QAnet makes full use of semantic information in paired answers at both word-level and sentence-level. We evaluate our model on two datasets: the Yahoo! Answers dataset and the Stack Overflow dataset. To meet the special requirements of this study, both datasets are extended by paired answers. Experimental results demonstrate that our proposed model achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Xuan Zhao and Jimmy Xiangji Huang},
  doi          = {10.1016/j.neucom.2022.08.044},
  journal      = {Neurocomputing},
  pages        = {68-74},
  shortjournal = {Neurocomputing},
  title        = {Bert-QAnet: BERT-encoded hierarchical question-answer cross-attention network for duplicate question detection},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Saliency detection network with two-stream encoder and
interactive decoder. <em>NEUCOM</em>, <em>509</em>, 56–67. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been an increasing amount of works on improving the salient object detection performance based on the edge information. However, previous studies applied a parameter-sharing encoder to extract edge features and region features, leading to incomplete regions and blurry edges. In this paper, we focus on the independence and complementarity between salient edges and regions, and propose a novel salient object detection network with two-stream encoder and interactive decoder(TSEID). Specifically, instead of a parameter-sharing encoder, we construct a two-stream encoder consisting of the region extraction branch and the edge extraction branch to balance the feature domain differences between the regions and edges. Meanwhile, we develop a super-pixel segmentation-based method to extract the salient edges, so that the generated distinctive edges will ensure the integrality of edge features. The region features are obtained via a feature pyramid network and hierarchically enhanced with Channel Adaptation (CA) and Spatial Adaptation (SA). Further, the extracted region features and edge features are fed into an interactive decoder to explore their complementarity. Accordingly, a location guidance module (LGM) and an edge compensation module (ECM) are designed to refine object positions, enrich object boundaries, and generate saliency features. Extensive experiments on five challenging benchmarks well demonstrate that our approach outperforms existing deep learning-based methods, including the latest edge-guided ones.},
  archive      = {J_NEUCOM},
  author       = {Aiping Yang and Simeng Cheng and Shangyang Song and Jinbin Wang and Zhong Ji and Yanwei Pang and Jiale Cao},
  doi          = {10.1016/j.neucom.2022.08.051},
  journal      = {Neurocomputing},
  pages        = {56-67},
  shortjournal = {Neurocomputing},
  title        = {Saliency detection network with two-stream encoder and interactive decoder},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain adaptive multi-task transformer for low-resource
machine reading comprehension. <em>NEUCOM</em>, <em>509</em>, 46–55. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, low-resource Machine Reading Comprehension (MRC) attracts increasing attention. Due to the difficulty in data collecting, current low-resource MRC approaches often suffer from poor generalizing capability: the model only learns limited task-aware and domain-aware knowledge from a small-scale training dataset. Previous works generally address such deficiency by learning the required knowledge from out-of-domain MRC datasets and in-domain self-supervised datasets. However, such approaches also introduce domain noise and task noise. This paper proposes a Domain Adaptive Multi-Task Transformer (DAMT 2 ) to tackle these noises. For task noise, DAMT 2 utilizes a well-designed Multi-Task Transformer (MT 2 ) as the backbone to model the high-level features separately from different tasks. For domain noise, two kinds of domain adaptation approaches are incorporated into MT 2 to learn domain-invariant representations. The experimental results show that our method outperforms several baselines on multiple datasets, and especially achieves a new SOTA on the RRC dataset. Moreover, using only 40\%-60\% training data, our work achieves comparable performance with the classic BERT model.},
  archive      = {J_NEUCOM},
  author       = {Ziwei Bai and Baoxun Wang and Zongsheng Wang and Caixia Yuan and Xiaojie Wang},
  doi          = {10.1016/j.neucom.2022.08.057},
  journal      = {Neurocomputing},
  pages        = {46-55},
  shortjournal = {Neurocomputing},
  title        = {Domain adaptive multi-task transformer for low-resource machine reading comprehension},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-users interaction anomalous subgraph detection for
event mining. <em>NEUCOM</em>, <em>509</em>, 34–45. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event detection on networks is an important research task in data mining. Most previous approaches usually detect a particular type of event that satisfies the predefined rules in the model, i.e., data-driven methods. However, few methods consider the diverse interests of multiple experts during the detection process to discover unexplored events. In this paper, we regard interactive event detection on attributed networks as Multi-users Interaction Anomalous Subgraph Detection (MIASD), where events are represented as connected subgraphs on networks. The core of our method is automatically maximizing a non-parametric scan statistic over connected subgraphs to identify the most anomalous subgraph as the event and integrating the interactions from multiple experts simultaneously, i.e., under both data-driven and user-driven paradigm. In our approach, we first define individual and shared environments of experts on attributed networks to model the interests of experts, including the interactive operations and Recommended Interaction Domain. Afterwards, we propose an efficient anomalous subgraph detection algorithm in which each expert gives feedback separately on the vertices in the Recommended Interaction Domain; then, the non-parametric scan statistic over the connected subgraph is approximately maximized by integrating various feedback from experts into the iterative subgraph expansion process. In this way, our method retrieves the most anomalous subgraph on the network as the final event, which contains the potential unexplored information. We have conducted extensive experiments on three real-world datasets and proved that our algorithm could achieve better performance compared with several competitive baselines. Furthermore, the case study shows that our method could detect global abnormal events effectively.},
  archive      = {J_NEUCOM},
  author       = {Yang Yu and Wenjun Wang and Minglai Shao and Nannan Wu and Ying Sun and Yueheng Sun and Qiang Tian},
  doi          = {10.1016/j.neucom.2022.08.072},
  journal      = {Neurocomputing},
  pages        = {34-45},
  shortjournal = {Neurocomputing},
  title        = {Multi-users interaction anomalous subgraph detection for event mining},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diminishing-feature attack: The adversarial infiltration on
visual tracking. <em>NEUCOM</em>, <em>509</em>, 21–33. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deeply understanding machine learning is a challenging task because its backbone technology is still obscure. The adversarial attack is established toward the vulnerability of deep models and can be utilized for understanding deep neural networks and enhancing model robustness. Adversarial attacks on tracking models can generate imperceptible noise to an input and consequently increase the cumulative error of tracking displacement. In general, existing adversarial visual-attacking models are white-box attacks. Although it successfully deceives the baseline tracker, the training model’s attacking effect is insufficiently transferred to blind trackers. Here, we present a new approach, the diminishing-feature attack, that generates a subtle perturbation into the input frame. The malicious noise in the proposed model is generated to disturb the feature heatmap to distract the classification score and annihilate bounding-box prediction. The adversarial noise generator is solely trained from SiamRPN++ ResNet features of template frames without search frames or other parameters. Our method requires fewer computing resources than other visual tracking attackers when malfunctioning visual trackers. To validate the proposed model, we benchmark the adversarial input frame with the tracker on four tracking datasets: OTB100, VOT2018, LaSOT and UAV123. Our attacking method achieves a high performance drop that is comparable to the other existing adversarial attackers in visual tracking, yet our adversarial noise is lower than the aforementioned attackers. Furthermore, the transferability attacking of our algorithm is excellent on state-of-the-art visual tracking, for example, SiamRPN, DaSiam and DiMP.},
  archive      = {J_NEUCOM},
  author       = {Wattanapong Suttapak and Jianfu Zhang and Liqing Zhang},
  doi          = {10.1016/j.neucom.2022.08.071},
  journal      = {Neurocomputing},
  pages        = {21-33},
  shortjournal = {Neurocomputing},
  title        = {Diminishing-feature attack: The adversarial infiltration on visual tracking},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-domain knowledge distillation for text classification.
<em>NEUCOM</em>, <em>509</em>, 11–20. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most text classification methods achieve great success based on the large-scale annotated data and the pre-trained language models . However, the labeled data is insufficient in practice, and the pre-trained language models are difficult to deploy due to their high computing resources and slow inference speed. In this paper, we propose cross-domain knowledge distillation , where the teacher and student tasks belong to different domains. It not only acquires knowledge from multiple teachers but also accelerates inference and reduces model size. Specifically, we train the pre-trained language models on factual knowledge obtained by aligned Wikipedia text to Wikidata triplets and fine-tune it as the teacher model. Then we use the heterogeneous multi-teacher knowledge distillation to transfer knowledge from the multiple teacher models to the student model. Multi-teacher knowledge vote can distill knowledge related to the target domain. Moreover, we also introduce the teacher assistant to help distill large pre-trained language models. Finally, we reduce the difference between the source domain and target domain by multi-source domain adaptation to solve the domain shift problem. Experiments on the multiple public datasets demonstrate that our method can achieve competitive performance while having fewer parameters and less inference time.},
  archive      = {J_NEUCOM},
  author       = {Shaokang Zhang and Lei Jiang and Jianlong Tan},
  doi          = {10.1016/j.neucom.2022.08.061},
  journal      = {Neurocomputing},
  pages        = {11-20},
  shortjournal = {Neurocomputing},
  title        = {Cross-domain knowledge distillation for text classification},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MergedNET: A simple approach for one-shot learning in
siamese networks based on similarity layers. <em>NEUCOM</em>,
<em>509</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifiers trained on disjointed classes with few labelled data points are used in one-shot learning to identify visual concepts from other classes. Recently, Siamese networks and similarity layers have been used to solve the one-shot learning problem, achieving state-of-the-art performance on visual-character recognition datasets. Various techniques have been developed over the years to improve the performance of these networks on fine-grained image classification datasets. They focused primarily on improving the loss and activation functions, augmenting visual features, employing multiscale metric learning, and pre-training and fine-tuning the backbone network. We investigate similarity layers for one-shot learning tasks and propose two frameworks for combining these layers into a MergedNet network. On all four datasets used in our experiment, MergedNet outperformed the baselines based on classification accuracy, and it generalises to other datasets when trained on miniImageNet.},
  archive      = {J_NEUCOM},
  author       = {John Atanbori and Samuel Rose},
  doi          = {10.1016/j.neucom.2022.08.070},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {MergedNET: A simple approach for one-shot learning in siamese networks based on similarity layers},
  volume       = {509},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). HAPZSL: A hybrid attention prototype network for knowledge
graph zero-shot relational learning. <em>NEUCOM</em>, <em>508</em>,
324–336. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph (KG) is becoming increasingly important in current information systems. To expand the coverage of KG, traditional knowledge graph completion research needs to collect enough training instances for newly added relations. However, high-quality training instances are usually difficult to collect. To alleviate this problem, knowledge graph zero-shot relational learning (KGZSL) has attracted more and more attention in recent years. The common method of KGZSL is to leverage Generative Adversarial Networks (GANs) to establish the connection between existing relation descriptions and the knowledge graph domain. However, traditional KGZSL methods often encounter training stability and model collapse problems, which means that these methods cannot stably generate high-quality relation vectors. Inspired by recent advances in prototype networks, we propose an end-to-end hybrid attention prototype framework to generate more plausible relational embeddings and address model collapse and training stability problems in previous studies. The core idea of our method is to obtain the relation prototype and the entity pair representation through the description encoder and the hybrid attention mechanism (HAM), then input them into a latent space, forcing the entity pair to be closer to their relation prototype. Experimental results on the knowledge graph zero-shot relational learning dataset demonstrate that our HAPZSL has a faster convergence speed and achieves state-of-the-art performance on this task.},
  archive      = {J_NEUCOM},
  author       = {Xuewei Li and Jinming Ma and Jian Yu and Tianyi Xu and Mankun Zhao and Hongwei Liu and Mei Yu and Ruiguo Yu},
  doi          = {10.1016/j.neucom.2022.07.038},
  journal      = {Neurocomputing},
  pages        = {324-336},
  shortjournal = {Neurocomputing},
  title        = {HAPZSL: A hybrid attention prototype network for knowledge graph zero-shot relational learning},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Single low-light image brightening using learning-based
intensity mapping. <em>NEUCOM</em>, <em>508</em>, 315–323. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by image-to-curve transformation and multi-exposure fusion, in this paper, we have developed a new method to treat the low light image enhancement tasks as an extended problem with multiple virtual exposures by a non-linear intensity mapping function. Considering that existing image-to-curve methods have difficulty in obtaining the desired detail and brightness recovery in any one iteration without relying on any ground truth, we propose a virtual multi-exposure fusion strategy to merge the outputs from these different iterations. Specifically, a simple CNN is trained to learn a pixel-wise intensity mapping function and accordingly adjust a given image multiple times. Then the results of all iterations are retained together with the original input image for fusion via a WGIF-based Multi-scale pyramid to obtain a final enhanced output. We present experimental results to demonstrate the effectiveness of the new technique and its state-of-the-art performances.},
  archive      = {J_NEUCOM},
  author       = {Xiaochen Wang and Ruimin Hu and Xin Xu},
  doi          = {10.1016/j.neucom.2022.08.042},
  journal      = {Neurocomputing},
  pages        = {315-323},
  shortjournal = {Neurocomputing},
  title        = {Single low-light image brightening using learning-based intensity mapping},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Representation learning of knowledge graphs with the
interaction between entity types and relations. <em>NEUCOM</em>,
<em>508</em>, 305–314. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning of knowledge graphs is the task of representing entities and relations of real-world knowledge as low-dimensional vectors. Some previous works have demonstrated that entity types are beneficial for knowledge representation, but these methods rely too much on prior knowledge or do not have pluggability. To address these limitations, we propose a new method named TRPE which can better explore the entity type information for knowledge graph embedding. We suggest that entities should have multiple representations and each entity type should play a different role in different relations. To better characterize the interaction between entity types and relations, we build the type-relation pairs for each entity and gain each type-relation pair feature through the interaction between type-specific features and relation-specific features. These type-relation pair features are assigned different weights which are aggregated to serve as the transformation of entity embeddings. After that, we divide each entity embedding into some sub-embeddings where each sub-embedding does its own transformation. At the same time, our model is a pluggable module that can be attached to other models. We integrate our model into three baseline models for evaluation on FB15k and FB15k + datasets. The experiment results show that our model brings significant improvement to baseline models . On CoDEx datasets with more noisy entity type data , our model still achieves good results compared with other models, which also demonstrates the generalization ability of our model.},
  archive      = {J_NEUCOM},
  author       = {Shensi Wang and Kun Fu and Xian Sun and Zequn Zhang and Shuchao Li and Shiyao Yan},
  doi          = {10.1016/j.neucom.2022.07.031},
  journal      = {Neurocomputing},
  pages        = {305-314},
  shortjournal = {Neurocomputing},
  title        = {Representation learning of knowledge graphs with the interaction between entity types and relations},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CLIP4Clip: An empirical study of CLIP for end to end video
clip retrieval and captioning. <em>NEUCOM</em>, <em>508</em>, 293–304.
(<a href="https://doi.org/10.1016/j.neucom.2022.07.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video clip retrieval and captioning tasks play an essential role in multimodal research and are the fundamental research problem for multimodal understanding and generation. The CLIP (Contrastive Language-Image Pre-training) model has demonstrated the power of visual concepts learning from web collected image-text datasets. In this paper, we propose a CLIP4Clip model to transfer the knowledge of the image-text pretrained CLIP model to video-text tasks in an end-to-end manner. Furthermore, we conduct several empirical studies including 1) Whether image feature is enough for video-text retrieval and captioning? 2) How a post-pretraining on a large-scale video-text dataset based on the CLIP affect the performance? 3) What is the practical mechanism to model temporal dependency between video frames? And 4) The Hyper-parameters sensitivity of the model. Extensive experimental results present that the CLIP4Clip model transferred from the CLIP can achieve SOTA results on various video-text datasets, including MSR-VTT, MSVD, LSMDC, and DiDeMo for multimodal understanding and generation tasks.},
  archive      = {J_NEUCOM},
  author       = {Huaishao Luo and Lei Ji and Ming Zhong and Yang Chen and Wen Lei and Nan Duan and Tianrui Li},
  doi          = {10.1016/j.neucom.2022.07.028},
  journal      = {Neurocomputing},
  pages        = {293-304},
  shortjournal = {Neurocomputing},
  title        = {CLIP4Clip: An empirical study of CLIP for end to end video clip retrieval and captioning},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TC3KD: Knowledge distillation via teacher-student
cooperative curriculum customization. <em>NEUCOM</em>, <em>508</em>,
284–292. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation aims to improve the performance of a lightweight student network by transferring some knowledge from a large-scale teacher network. Most existing knowledge distillation methods follow the traditional training strategy which feeds the sequence of mini-batches sampled randomly from the training set. Inspired by curriculum learning, we propose a novel knowledge distillation method via teacher-student cooperative curriculum customization. Specifically, a weighted ensemble of teacher and snapshot student is designed to measure the difficulty of samples. Dynamically update the ensemble weights and the snapshot student in the difficulty measurer that customizes appropriate curricula to guide the student network in different training stages. A “fetch and remove in balance” training scheduler is adopted to maintain the training stability and reduce the ranking cost. Extensive experiments on CIFAR-100, CINIC-10 and ImageNet validate the effectiveness of our method. As an independent training strategy of distillation, the proposed teacher-student cooperative curriculum customization paradigm also can be combined with the mainstream knowledge distillation approaches to improve their performance.},
  archive      = {J_NEUCOM},
  author       = {Chaofei Wang and Ke Yang and Shaowei Zhang and Gao Huang and Shiji Song},
  doi          = {10.1016/j.neucom.2022.07.055},
  journal      = {Neurocomputing},
  pages        = {284-292},
  shortjournal = {Neurocomputing},
  title        = {TC3KD: Knowledge distillation via teacher-student cooperative curriculum customization},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Training neural networks for solving 1-d optimal piecewise
linear approximation. <em>NEUCOM</em>, <em>508</em>, 275–283. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the interpretability of deep learning has attracted a lot of attention. A plethora of methods have attempted to explain neural networks by feature visualization, saliency maps, model distillation, and so on. However, it is hard for these methods to reveal the intrinsic properties of neural networks . In this work, we studied the 1-D optimal piecewise linear approximation (PWLA) problem and associated it with a designed neural network, named lattice neural network (LNN). We asked four essential questions as following: (1) What are the characters of the optimal solution of the PWLA problem? (2) Can an LNN converge to the global optimum? (3) Can an LNN converge to the local optimum? (4) Can an LNN solve the PWLA problem? Our main contributions are that we propose the theorems to characterize the optimal solution of the PWLA problem and present the LNN method for solving it. We evaluated the proposed LNNs on approximation tasks, forged an empirical method to improve the performance of LNNs. The experiments verified that our LNN method is competitive with the start-of-the-art method.},
  archive      = {J_NEUCOM},
  author       = {Hangcheng Dong and Jingxiao Liao and Yang Wang and Yixin Chen and Bingguo Liu and Dong Ye and Guodong Liu},
  doi          = {10.1016/j.neucom.2022.07.025},
  journal      = {Neurocomputing},
  pages        = {275-283},
  shortjournal = {Neurocomputing},
  title        = {Training neural networks for solving 1-D optimal piecewise linear approximation},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A robust noise tolerant zeroing neural network for solving
time-varying linear matrix equations. <em>NEUCOM</em>, <em>508</em>,
254–274. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robust noise-tolerant zeroing neural network (ZNN) is introduced for solving time-varying linear matrix equations (TVLME). The convergence speed of designed neural dynamics is analyzed theoretically and compared with the convergence of neural networks which include traditional activation functions , such as the tunable activation function, versatile activation function, and the modified sign-bi-power activation function. The proposed activation is utilized in the development of nonlinear ZNN dynamics for solving time-varying linear matrix equations and the Stein equation. We investigate theoretically and experimentally the behavior of the proposed robust noise-tolerant ZNN with the novel effective activation function. In particular, the convergence analysis of proposed ZNN flows is studied both in the presence of noise and without noise. Simulation tests demonstrate the effectiveness and domination of the suggested activation over already existing activation functions . Further, the introduced noise-tolerant ZNN model is applied in solving the Wheatstone bridge and output tracking control problem.},
  archive      = {J_NEUCOM},
  author       = {Dimitrios Gerontitis and Ratikanta Behera and Yang Shi and Predrag S. Stanimirović},
  doi          = {10.1016/j.neucom.2022.08.036},
  journal      = {Neurocomputing},
  pages        = {254-274},
  shortjournal = {Neurocomputing},
  title        = {A robust noise tolerant zeroing neural network for solving time-varying linear matrix equations},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Learning to recommend journals for submission based on
embedding models. <em>NEUCOM</em>, <em>508</em>, 242–253. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rapid development of electronic journals, selecting appropriate journals to publish research papers has become a significant challenge to researchers. Sometimes, even a high-quality paper may get rejected from the editor due to the mismatch between the topic of the paper and the scope of the journal. To address this issue, we present a framework of learning to recommend journals for submission based on embedding models to assist researchers in journal selection. Specifically, the journal recommendation problem is formulated in the context of multi-class classification, where the Bidirectional Encoder Representations from Transformers (BERT) is deployed to extract the text-level features of representing papers and the AutoEncoder (AE) network is adopted to obtain the feature representation of each journal from the relationship matrix of the paper-journal bipartite graph . The final recommendation of journals is made by using a scoring function and a Softmax classifier. Experimental results obtained on the closed dataset of 10 different journals and the DBLP dataset indicate that we proposed method outperforms several classical approaches in terms of accuracy, F1, MRR, etc. Furthermore, we introduce information entropy as an evaluation index and analyze the model performance from the perspective of prediction uncertainty. This study provides a new approach to the journal recommendation task, and researchers can choose the appropriate embedding methods according to the actual problem.},
  archive      = {J_NEUCOM},
  author       = {Chao Liu and Xizhao Wang and Han Liu and Xiaoying Zou and Si Cen and Guoquan Dai},
  doi          = {10.1016/j.neucom.2022.08.043},
  journal      = {Neurocomputing},
  pages        = {242-253},
  shortjournal = {Neurocomputing},
  title        = {Learning to recommend journals for submission based on embedding models},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive weighted robust iterative closest point.
<em>NEUCOM</em>, <em>508</em>, 225–241. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Iterative Closest Point (ICP) algorithm is one of the most important methods for rigid registration between point sets. However, its performance begins to degenerate with the point data are overly contaminated by noise, outliers, and missing data. In this paper, we propose an adaptive weighted robust ICP method (AW-RICP). A sparse weight vector can be automatically learned by adaptive neighbors assigning process. The sparseness of the weight vector can be achieved by fitting the number of selected samples. The adaptive weight vector leads to the robustness of AW-RICP by eliminating the negative effect caused by point cloud pairs with largest registration errors. Further, the retained point pairs are assigned suitable weights to suppress the noises and outliers. The new error metric can effectively improve the robustness of ICP method. Additionally, we propose an efficient iterative solution to optimize our problem. Experiments on both synthetic and real data sets show that the proposed method can achieve superior performance with other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yu Guo and Luting Zhao and Yan Shi and Xuetao Zhang and Shaoyi Du and Fei Wang},
  doi          = {10.1016/j.neucom.2022.08.047},
  journal      = {Neurocomputing},
  pages        = {225-241},
  shortjournal = {Neurocomputing},
  title        = {Adaptive weighted robust iterative closest point},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Renewable quantile regression for streaming data sets.
<em>NEUCOM</em>, <em>508</em>, 208–224. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online updating is an important statistical method for the analysis of big data arriving in streams due to its ability to break the storage barrier and the computational barrier under certain circumstances. The quantile regression, as a widely used regression model in many fields, faces challenges in model fitting and variable selection with big data arriving in streams. Chen et al. (2019, Annals of Statistics) has proposed a quantile regression method for streaming data, but a strong additional condition is required. In this paper, renewable optimized objective functions for regression parameter estimation and variable selection in a quantile regression are proposed. The proposed methods are illustrated using current data and the summary statistics of historical data. Theoretically, the proposed statistics are shown to have the same asymptotic distributions as the standard version computed on an entire data stream with the data batches pooled into one data set, without additional condition. Both simulations and data analysis are conducted to illustrate the finite sample performance of the proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Rong Jiang and Keming Yu},
  doi          = {10.1016/j.neucom.2022.08.019},
  journal      = {Neurocomputing},
  pages        = {208-224},
  shortjournal = {Neurocomputing},
  title        = {Renewable quantile regression for streaming data sets},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solar power time series forecasting utilising wavelet
coefficients. <em>NEUCOM</em>, <em>508</em>, 182–207. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable prediction of photovoltaic (PV) power output is critical to electricity grid stability and power dispatching capabilities. However, PV power generation is highly volatile and unstable due to different reasons. The wavelet transform (WT) has been utilised in time series applications, such as PV power prediction, to model the stochastic volatility and reduce prediction errors. Yet the existing WT approach has a limitation in terms of time complexity. It requires reconstructing the decomposed components and modelling them separately and thus needs more time for reconstruction, model configuration and training. The aim of this study is to improve the efficiency of applying WT by proposing a new method that uses a single simplified model. Given a time series and its WT coefficients, it trains one model with the coefficients as features and the original time series as labels. This eliminates the need for component reconstruction and training numerous models. This work contributes to the day-ahead aggregated solar PV power time series prediction problem by proposing and comprehensively evaluating a new approach of employing WT. The proposed approach is evaluated using 17 months of aggregated solar PV power data from two real-world datasets. The evaluation includes the use of a variety of prediction models, including Linear Regression, Random Forest , Support Vector Regression , and Convolutional Neural Networks . The results indicate that using a coefficients-based strategy can give predictions that are comparable to those obtained using the components-based approach while requiring fewer models and less computational time.},
  archive      = {J_NEUCOM},
  author       = {Sarah Almaghrabi and Mashud Rana and Margaret Hamilton and Mohammad Saiedur Rahaman},
  doi          = {10.1016/j.neucom.2022.08.016},
  journal      = {Neurocomputing},
  pages        = {182-207},
  shortjournal = {Neurocomputing},
  title        = {Solar power time series forecasting utilising wavelet coefficients},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep attributed network representation learning via
attribute enhanced neighborhood. <em>NEUCOM</em>, <em>508</em>, 170–181.
(<a href="https://doi.org/10.1016/j.neucom.2022.08.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attributed network representation learning aims at learning node embeddings by integrating network structure and attribute information. It is a challenge to fully capture the microscopic structure and the attribute semantics simultaneously, where the microscopic structure includes the one-step, two-step and multi-step relations, indicating the first-order, second-order and high-order proximity of nodes, respectively. In this paper, we propose a deep attributed network representation learning via attribute enhanced neighborhood (DANRL-ANE) model to improve the robustness and effectiveness of node representations. The DANRL-ANE model adopts the idea of the autoencoder , and expands the decoder component to three branches to capture different order proximity. We linearly combine the adjacency matrix with the attribute similarity matrix as the input of DANRL-ANE, where the attribute similarity matrix is calculated by the cosine similarity between the attributes based on the social homophily. Moreover, the sigmoid cross-entropy loss function is extended to capture the neighborhood character, so that the first-order proximity could be well-preserved. We compare our model with the state-of-the-art models, especially, the latest graph autoencoders (GAEs) method, ARGA, and demonstrate the contribution of each module on real-world datasets and two network analysis tasks, i.e. , link prediction and node classification . The DANRL-ANE model performs well on various networks, even on sparse networks or networks with isolated nodes when the attribute information is sufficient.},
  archive      = {J_NEUCOM},
  author       = {Cong Li and Min Shi and Bo Qu and Xiang Li},
  doi          = {10.1016/j.neucom.2022.08.033},
  journal      = {Neurocomputing},
  pages        = {170-181},
  shortjournal = {Neurocomputing},
  title        = {Deep attributed network representation learning via attribute enhanced neighborhood},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved AdaBoost algorithm using misclassified samples
oriented feature selection and weighted non-negative matrix
factorization. <em>NEUCOM</em>, <em>508</em>, 153–169. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the classification performance of existing adaptive boosting (AdaBoost) based algorithms effectively, an improved AdaBoost algorithm based on misclassified samples oriented feature selection and weighted non-negative matrix factorization (WNMF) is proposed in this paper. Firstly, in order to consider the effects of sample weights, a misclassified samples oriented feature selection (called MOFS) is proposed to select the most discriminative features which occur in the samples with high weights. Secondly, the explicit features and the part-based features of the training samples are both considered, and the WNMF algorithm is introduced and combined with MOFS to reduce the dimension of the training sample set. Finally, the concept of misclassification degree is introduced and a fine grained sample weight updating method is proposed to distinguish the samples with different misclassification degrees. Numerical experiments show that the proposed MOFS method achieves higher accuracy compared to traditional feature selection methods, and the proposed MOFS and WNMF based AdaBoost method obtains significant improvement on classification accuracy when comparing with typical existing AdaBoost based algorithms using different classifiers.},
  archive      = {J_NEUCOM},
  author       = {Youwei Wang and Lizhou Feng and Jianming Zhu and Yang Li and Fu Chen},
  doi          = {10.1016/j.neucom.2022.08.015},
  journal      = {Neurocomputing},
  pages        = {153-169},
  shortjournal = {Neurocomputing},
  title        = {Improved AdaBoost algorithm using misclassified samples oriented feature selection and weighted non-negative matrix factorization},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pedestrian intention prediction for autonomous vehicles: A
comprehensive survey. <em>NEUCOM</em>, <em>508</em>, 120–152. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lately, Autonomous vehicles (AV) have been gaining traction globally owing to their huge social, economic and environmental benefits. However, the rising safety apprehensions for vulnerable road users (VRU) alongside have become a stumbling block to the large-scale implementation of AVs. Deciphering intention in advance considering all social norms and context surrounding the VRU is a highly challenging task due to the huge amount of variability in their motion, actions and end goals. Based on this pensiveness, this paper extensively surveys the variety of techniques applied to anticipate pedestrian intention and classifies them from multiple perspectives. Some newly introduced datasets with added complexities of human behaviour on road have also been outlined. It also provides a comparative analysis of the performance of pedestrian intention prediction approaches on several benchmark datasets as per the various assessment parameters available. In addition to this, several potential challenges and their possible solutions paving way for future research initiatives have also been thoroughly analysed in this endeavour.},
  archive      = {J_NEUCOM},
  author       = {Neha Sharma and Chhavi Dhiman and S. Indu},
  doi          = {10.1016/j.neucom.2022.07.085},
  journal      = {Neurocomputing},
  pages        = {120-152},
  shortjournal = {Neurocomputing},
  title        = {Pedestrian intention prediction for autonomous vehicles: A comprehensive survey},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Output synchronization of multi-agent systems via
reinforcement learning. <em>NEUCOM</em>, <em>508</em>, 110–119. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the measured input–output data sequences with pinning gain are proposed via the topology of multi-agent systems (MAS), where the requirement of reinforcement learning algorithm on internal state is avoided by pinning gain and the measured data of leader and neighbors. Besides, a data-based tracking state is given, which can be applied to MAS with different control matrices . According to the sequences and tracking state , a distributed control policy and corresponding reinforcement learning algorithm are proposed for the output synchronization. The proposed algorithm overcomes the shortcoming that previous algorithms can not be applied to MAS with different control matrices in the absence of model information and full-state vector. Finally, the effectiveness of proposed algorithm is verified by simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Yingying Liu and Zhanshan Wang},
  doi          = {10.1016/j.neucom.2022.08.006},
  journal      = {Neurocomputing},
  pages        = {110-119},
  shortjournal = {Neurocomputing},
  title        = {Output synchronization of multi-agent systems via reinforcement learning},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Corrigendum to “coreset: Hierarchical neuromorphic
computing supporting large-scale neural networks with improved resource
efficiency” [neurocomputing (2022) 128–140]. <em>NEUCOM</em>,
<em>508</em>, 109. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Liwei Yang and Huaipeng Zhang and Tao Luo and Chuping Qu and Myat Thu Linn Aung and Yingnan Cui and Jun Zhou and Ming Ming Wong and Junran Pu and Anh Tuan Do and Rick Siow Mong Goh and Weng Fai Wong},
  doi          = {10.1016/j.neucom.2022.06.079},
  journal      = {Neurocomputing},
  pages        = {109},
  shortjournal = {Neurocomputing},
  title        = {Corrigendum to “Coreset: Hierarchical neuromorphic computing supporting large-scale neural networks with improved resource efficiency” [Neurocomputing (2022) 128–140]},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). State estimate via outputs from the fraction of nodes for
discrete-time complex networks with markovian jumping parameters and
measurement noise. <em>NEUCOM</em>, <em>508</em>, 99–108. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the state estimate problem for a class of discrete-time complex networks. The target plant involves Markovian jumping parameters and mode-dependent distributed time-delays. It is assumed that the measurements for the estimate purpose are just from a portion of network nodes, and corrupted by a certain stochastic noise. A unified framework is developed to cope with the state estimation issue based on the outputs from the fraction of nodes for the discrete-time complex networks with distributed time delay and measurement noise. By employing the Lyapunov stability theory and some new techniques, the sufficient conditions are established to ensure the state estimation error is exponentially ultimately mean-square bounded. As the special case when the measurement is noise-free, the resulting criteria are to guarantee that the dynamics of state estimation error is exponentially stable. In addition, the estimator gain matrices are given in the explicit formula. Finally, numerical simulations are presented to illustrate the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Yurong Liu and Hongjian Liu and Changfeng Xue and Naif D. Alotaibi and Fuad E. Alsaadi},
  doi          = {10.1016/j.neucom.2022.08.054},
  journal      = {Neurocomputing},
  pages        = {99-108},
  shortjournal = {Neurocomputing},
  title        = {State estimate via outputs from the fraction of nodes for discrete-time complex networks with markovian jumping parameters and measurement noise},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solve routing problems with a residual edge-graph attention
neural network. <em>NEUCOM</em>, <em>508</em>, 79–98. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For NP-hard combinatorial optimization problems , it is usually challenging to find high-quality solutions in polynomial time . Designing either an exact algorithm or an approximate algorithm for these problems often requires significantly specialized knowledge. Recently, deep learning methods have provided new directions to solve such problems. In this paper, an end-to-end deep reinforcement learning framework is proposed to solve this type of combinatorial optimization problems. This framework can be applied to different problems with only slight changes of input, masks, and decoder context vectors. The proposed framework aims to improve the models in literacy in terms of the neural network model and the training algorithm . The solution quality of TSP and the CVRP up to 100 nodes are significantly improved via our framework. Compared with the best results of the state-of-the-art methods, the average optimality gap is reduced from 4.53\% to 3.67\% for TSP with 100 nodes and from 7.34\% to 6.68\% for CVRP with 100 nodes when using the greedy decoding strategy. Besides, the proposed framework can be used to solve a multi-depot CVRP case without any structural modification. Furthermore, our framework uses about 1/3 ∼ ∼ 3/4 training samples compared with other existing learning methods while achieving better results. The results performed on randomly generated instances , and the benchmark instances from TSPLIB and CVRPLIB confirm that our framework has a linear running time on the problem size (number of nodes) during training and testing phases and has a good generalization performance from random instance training to real-world instance testing.},
  archive      = {J_NEUCOM},
  author       = {Kun Lei and Peng Guo and Yi Wang and Xiao Wu and Wenchao Zhao},
  doi          = {10.1016/j.neucom.2022.08.005},
  journal      = {Neurocomputing},
  pages        = {79-98},
  shortjournal = {Neurocomputing},
  title        = {Solve routing problems with a residual edge-graph attention neural network},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Encoding–decoding-based secure filtering for neural networks
under mixed attacks. <em>NEUCOM</em>, <em>508</em>, 71–78. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the set-membership filtering issue for a class of artificial neural networks subject to mixed attacks. The encoding–decoding communication mechanism is adopted in the processing of data sharing between neurons. During the information exchanges among neurons, both injection and DoS attacks are concurrently considered to reflect the practical operating conditions of the investigated neural networks . The purpose of the addressed problem is to present an algorithm to estimate the neurons’ states in the presence of mixed attacks, while guaranteeing the estimation errors at each neuron are confined within certain prescribed ellipsoidal region. Sufficient conditions are derived, in terms of convex optimization approach, to ensure the existence of desired filter, and the explicit filtering parameters are obtained via solving the provided set of matrix inequalities. Finally, a numerical simulation example is proposed to show the validity of the obtained theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Xiaojian Yi and Huiyang Yu and Pengxiang Wang and Shulin Liu and Lifeng Ma},
  doi          = {10.1016/j.neucom.2022.08.041},
  journal      = {Neurocomputing},
  pages        = {71-78},
  shortjournal = {Neurocomputing},
  title        = {Encoding–decoding-based secure filtering for neural networks under mixed attacks},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel framework for image-to-image translation and image
compression. <em>NEUCOM</em>, <em>508</em>, 58–70. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven paradigms using machine learning are becoming ubiquitous in image processing and communications. In particular, image-to-image (I2I) translation is a generic and widely used approach to image processing problems, such as image synthesis , style transfer, and image restoration. At the same time, neural image compression has emerged as a data-driven alternative to traditional coding approaches in visual communications. In this paper, we study the combination of these two paradigms into a joint I2I compression and translation framework, focusing on multi-domain image synthesis . We first propose distributed I2I translation by integrating quantization and entropy coding into an I2I translation framework (i.e. I2Icodec). In practice, the image compression functionality (i.e. autoencoding) is also desirable, requiring to deploy alongside I2Icodec a regular image codec. Thus, we further propose a unified framework that allows both translation and autoencoding capabilities in a single codec. Adaptive residual blocks conditioned on the translation/compression mode provide flexible adaptation to the desired functionality. The experiments show promising results in both I2I translation and image compression using a single model.},
  archive      = {J_NEUCOM},
  author       = {Fei Yang and Yaxing Wang and Luis Herranz and Yongmei Cheng and Mikhail G. Mozerov},
  doi          = {10.1016/j.neucom.2022.08.048},
  journal      = {Neurocomputing},
  pages        = {58-70},
  shortjournal = {Neurocomputing},
  title        = {A novel framework for image-to-image translation and image compression},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DynHEN: A heterogeneous network model for dynamic bipartite
graph representation learning. <em>NEUCOM</em>, <em>508</em>, 47–57. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning node representations in graphs is a widespread problem in node classification and link prediction. Current research has focused on static heterogeneous, homogeneous networks, and dynamic homogeneous networks. However, many existing graphs, such as citation and social networks, are heterogeneous. Therefore, it is still a great challenge to obtain heterogeneous information in a dynamic heterogeneous graph to assist node representation learning . In this paper, we propose a Dynamic HEterogeneous Network (DynHEN) for user-item bipartite networks. It is a discrete dynamic graph neural network model that can be used directly for node representation learning by utilizing dynamic heterogeneous graphs. Specifically, DynHEN takes a bipartite graph at each time step as input, gets the corresponding embedding by capturing the deep heterogeneous information of the nodes while fusing the temporal information. To illustrate the effectiveness of heterogeneous information for graph representation learning, we compare with the current SOTA methods in the two type experiments of link prediction and node classification , and achieve outstanding results.},
  archive      = {J_NEUCOM},
  author       = {Zhezhe Xing and Rui Song and Yun Teng and Hao Xu},
  doi          = {10.1016/j.neucom.2022.08.050},
  journal      = {Neurocomputing},
  pages        = {47-57},
  shortjournal = {Neurocomputing},
  title        = {DynHEN: A heterogeneous network model for dynamic bipartite graph representation learning},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-supervised semantic segmentation with cross teacher
training. <em>NEUCOM</em>, <em>508</em>, 36–46. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks can achieve remarkable performance in semantic segmentation tasks. However, such neural network approaches heavily rely on costly pixel-level annotation. Semi-supervised learning is a promising resolution to tackle this issue, but its performance still far falls behind the fully supervised counterpart. This work proposes a cross-teacher training framework with three modules that significantly improves traditional semi-supervised learning approaches. The core is a cross-teacher module, which could simultaneously reduce the coupling among peer networks and the error accumulation between teacher and student networks. In addition, we propose two complementary contrastive learning modules. The high-level module can transfer high-quality knowledge from labeled data to unlabeled ones and promote separation between classes in feature space. The low-level module can encourage low-quality features learning from the high-quality features among peer networks. In experiments, the cross-teacher module significantly improves the performance of traditional student–teacher approaches, and our framework outperforms state-of-the-art methods on benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Hui Xiao and Dong Li and Hao Xu and Shuibo Fu and Diqun Yan and Kangkang Song and Chengbin Peng},
  doi          = {10.1016/j.neucom.2022.08.052},
  journal      = {Neurocomputing},
  pages        = {36-46},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised semantic segmentation with cross teacher training},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A robust clustering method with noise identification based
on directed k-nearest neighbor graph. <em>NEUCOM</em>, <em>508</em>,
19–35. (<a href="https://doi.org/10.1016/j.neucom.2022.08.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obtaining the optimal cluster number and generating reliable clustering results in nonlinear manifolds are necessary but challenging tasks. Most existing clustering algorithms have considerable limitations in dealing with local and nonlinear data patterns, while graph-based clustering has shown impressive performance in identifying clusters in such data patterns. In this paper, we propose a robust clustering method with noise cutting based on directed k-nearest neighbor graph (CDKNN) to identify the desired cluster number automatically and produce reliable clustering results simultaneously on nonlinear, non-overlapping but locally tight-connected data patterns. This method draws support from the k-nearest neighbor graph to represent the complex nonlinear datasets and applies parameter adaptive process to make the proposed clustering method better adapt to specific data patterns. The proposed method is robust to the noises of arbitrary shape datasets because it uses a directed K-nearest neighbor to cut out sparse nodes. We use simulation and UCI real-world datasets to prove the validity of the innovatory method by comparing it to k-means, DBSCAN, OPTICS , AP , SC , and CutPC algorithms in terms of clustering ACC, ARI, NMI, and FMI. The experimental results confirm that the proposed method outperforms the alternative nonlinear clustering methods.},
  archive      = {J_NEUCOM},
  author       = {Lin Li and Xiang Chen and Chengyun Song},
  doi          = {10.1016/j.neucom.2022.08.029},
  journal      = {Neurocomputing},
  pages        = {19-35},
  shortjournal = {Neurocomputing},
  title        = {A robust clustering method with noise identification based on directed K-nearest neighbor graph},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on deep learning-based single image crowd counting:
Network design, loss function and supervisory signal. <em>NEUCOM</em>,
<em>508</em>, 1–18. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single image crowd counting is a challenging computer vision problem with wide applications in public safety, city planning, traffic management, etc. With the recent development of deep learning techniques , crowd counting has aroused much attention and achieved great success in recent years. This survey is to provide a comprehensive summary of recent advances on deep learning-based crowd counting techniques via density map estimation by systematically reviewing and summarizing more than 200 works in the area since 2015. Our goals are to provide an up-to-date review of recent approaches, and educate new researchers in this field the design principles and trade-offs. After presenting publicly available datasets and evaluation metrics , we review the recent advances with detailed comparisons on three major design modules for crowd counting: deep neural network designs, loss functions, and supervisory signals. We study and compare the approaches using the public datasets and evaluation metrics . We conclude the survey with some future directions.},
  archive      = {J_NEUCOM},
  author       = {Haoyue Bai and Jiageng Mao and S.-H. Gary Chan},
  doi          = {10.1016/j.neucom.2022.08.037},
  journal      = {Neurocomputing},
  pages        = {1-18},
  shortjournal = {Neurocomputing},
  title        = {A survey on deep learning-based single image crowd counting: Network design, loss function and supervisory signal},
  volume       = {508},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automating t-SNE parameterization with prototype-based
learning of manifold connectivity. <em>NEUCOM</em>, <em>507</em>,
441–452. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We harness topological information about a data manifold revealed through neural prototype-based learning to automate t-SNE parameterization. This information is contained in the CONN (CONNectivity) similarity of neural prototypes, which grades the strength (weakness) of topological connectivity at various points within a data manifold. CONN suggests a data-driven specification of localized versions (varying across the manifold) of t-SNE’s perplexity parameter which, in turn, defines the high-dimensional similarities P that t-SNE attempts to preserve. We further imbue P with CONN’s graded similarity to reduce mismatch between the topology of the manifold and its embedded representation. Experiments show these improvements, collectively called CONNt-SNE , are capable of producing meaningful and trustworthy low-dimensional embeddings without the need to heuristically optimize over (i.e., grid search) t-SNE’s perplexity space. Data-driven t-SNE parameterization improves our confidence that any structure appearing in the embeddings is valid and not merely an artifact of spurious parameterization.},
  archive      = {J_NEUCOM},
  author       = {Josh Taylor and Erzsébet Merényi},
  doi          = {10.1016/j.neucom.2022.07.009},
  journal      = {Neurocomputing},
  pages        = {441-452},
  shortjournal = {Neurocomputing},
  title        = {Automating t-SNE parameterization with prototype-based learning of manifold connectivity},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stabilization and lag synchronization of proportional
delayed impulsive complex-valued inertial neural networks.
<em>NEUCOM</em>, <em>507</em>, 428–440. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with global exponential stabilization (GES) and exponential lag synchronization (ELS) for impulsive complex-valued inertial neural networks (ICVINNs) with proportional delays, without employing the standard order-reduction transformation and the general separation approach of the real and imaginary part of the ICVINNs. Several algebraic criteria involving multi-parameters for examining the GES and ELS of the ICVINNs are built, via establishing an appropriate Lyapunov functional, and utilizing inequality techniques, which can be achieved by the novel design of the adaptive controller . Numerical simulations are shown to sustain the availability and efficiency of the proposed criteria.},
  archive      = {J_NEUCOM},
  author       = {Yongkang Zhang and Liqun Zhou},
  doi          = {10.1016/j.neucom.2022.08.027},
  journal      = {Neurocomputing},
  pages        = {428-440},
  shortjournal = {Neurocomputing},
  title        = {Stabilization and lag synchronization of proportional delayed impulsive complex-valued inertial neural networks},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Boosting few-shot visual recognition via saliency-guided
complementary attention. <em>NEUCOM</em>, <em>507</em>, 412–427. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite significant progress in recent deep neural networks, most deep learning algorithms rely heavily on abundant training samples. To address the issue, few-shot learning (FSL) methods are designed to learn models that can generalize to novel classes with limited training data. In this work, we propose an effective and interpretable FSL approach termed Saliency-Guided Complementary Attention (SGCA). Concretely, SGCA aims to boost few-shot visual recognition from two perspectives: learning generalizable feature representations and building a robust classification module in a unified framework. For generalizable representation learning, we propose to explore the intrinsic structure of natural images by training the feature extractor with an auxiliary task to segment foreground regions from background clutter. The guidance signals are provided during training by a saliency detector which highlights object regions in images corresponding to the human visual system. Moreover, for robust classification module building, we introduce a complementary attention mechanism based on the learned segmentation to make the classification module focus on various informative parts of the image. Extensive experiments on 5 popular FSL datasets demonstrate that SGCA can outperform state-of-the-art approaches by a significant margin. In addition, extensions of SGCA to other challenging scenarios, including generalized, transductive and semi-supervised FSL, also verify the effectiveness and flexibility of our proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Linglan Zhao and Ge Liu and Dashan Guo and Wei Li and Xiangzhong Fang},
  doi          = {10.1016/j.neucom.2022.08.028},
  journal      = {Neurocomputing},
  pages        = {412-427},
  shortjournal = {Neurocomputing},
  title        = {Boosting few-shot visual recognition via saliency-guided complementary attention},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep CNN based image compression with redundancy
minimization via attention guidance. <em>NEUCOM</em>, <em>507</em>,
397–411. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Almost all compression algorithms try to minimize the one or other type of visual redundancy present in the image. Compression becomes challenging while considering the preservation of contextual information and other information. Without considering the contextual information, some of the unwanted features are also learned by the learning-based methods, which leads to the wastage of computational resources. Motivated by this fact, we propose an attention mechanism guided multi-size kernel convolution network-based image compression-decompression algorithm, which focuses on important (local and global) features that are needed for better reconstruction. Among various feature maps obtained after convolution at any stage, channel attention focuses on “what” is meaningful, and spatial attention focuses on “where” the important features are present in the entire feature map. Secondly, we propose to use a perceptual loss function for the task of image compression , which is a combination of contextual, style, and ℓ ℓ -2 loss functions. The proposed network and training it with perceptual loss function helped achieve significant improvements when tested with various datasets like CLIC 2019, Tecnick, Kodak, FDDB, ECSSD, and HKU-IS datasets. When assessed on CLIC 2019 challenging dataset, the MS-SSIM and PSNR of the proposed algorithm outperformed JPEG, JPEG2000 , and BPG by approximately up to 49.6\%, 34.61\%, 20.69\%, and 10.79\%, 1.32\%, 3.36\% respectively, at low-bit rates (around 0.1 bpp). We further investigated the effectiveness of the proposed algorithm on the cartoon images and found them to be superior to other algorithms. Lastly, as the cartoon images are significantly less available for experimentation using deep learning algorithms , we propose a cartoon image dataset, namely CARTAGE.},
  archive      = {J_NEUCOM},
  author       = {Dipti Mishra and Satish Kumar Singh and Rajat Kumar Singh},
  doi          = {10.1016/j.neucom.2022.08.009},
  journal      = {Neurocomputing},
  pages        = {397-411},
  shortjournal = {Neurocomputing},
  title        = {Deep CNN based image compression with redundancy minimization via attention guidance},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A continuous-time neurodynamic algorithm for distributed
nonconvex nonsmooth optimization problems with affine equality and
nonsmooth convex inequality constraints. <em>NEUCOM</em>, <em>507</em>,
383–396. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a distributed nonsmooth nonconvex optimization (DNNO) problem with affine inequality and nonsmooth convex inequality constraints is studied. A continuous-time distributed neurodynamic algorithm is proposed to solve this problem. Under the assumed conditions, for any initial state, the solution of distributed neurodynamic algorithm is bounded and globally exists, and will converge to the critical point set of distributed problems in a finite time. Compared with other DNNO algorithms, distributed neurodynamic algorithm has a lower dimension and does not need to satisfy the assumption that the feasible region is bounded. Finally, a series of numerical examples are given to verify the effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Jianyu Yang and Xing He},
  doi          = {10.1016/j.neucom.2022.08.035},
  journal      = {Neurocomputing},
  pages        = {383-396},
  shortjournal = {Neurocomputing},
  title        = {A continuous-time neurodynamic algorithm for distributed nonconvex nonsmooth optimization problems with affine equality and nonsmooth convex inequality constraints},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic prototypical feature representation learning
framework for semi-supervised skin lesion segmentation. <em>NEUCOM</em>,
<em>507</em>, 369–382. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated skin lesion segmentation is an essential yet challenging task for computer-aided skin disease diagnosis. One major challenge for learning-based segmentation method is the limited manually annotated dermoscopy images. Many semi-supervised methods are proposed to exploit unlabeled data by self-training with pseudo labels. However, the plain pseudo labels are less accurate and the pixel-wise features of unlabeled data are always not well formulated due to the large variations among different lesions. Aiming at producing a good segmentation embedding space in a semi-supervised manner, in this paper, we propose a novel dynamic prototypical feature representation learning framework to address these problems. Specifically, we propose a novel denoised pseudo label generation method, which effectively filters out the unreliable components in plaint pseudo labels and provides the guidance for the subsequent feature representation learning . Then, we propose a memory relation learning method to enhance the intermediate feature representation globally. Additionally, we propose a prototype-based confidence-aware contrastive learning method to learn a better local feature structure in semi-supervised training, strengthening intra-class compactness and inter-class separability. Extensive experiments on two skin lesion segmentation datasets demonstrate that our method outperforms other popular semi-supervised segmentation methods.},
  archive      = {J_NEUCOM},
  author       = {Zhenxi Zhang and Chunna Tian and Xinbo Gao and Cui Wang and Xue Feng and Harrison X. Bai and Zhicheng Jiao},
  doi          = {10.1016/j.neucom.2022.08.039},
  journal      = {Neurocomputing},
  pages        = {369-382},
  shortjournal = {Neurocomputing},
  title        = {Dynamic prototypical feature representation learning framework for semi-supervised skin lesion segmentation},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A fisher score-based multi-instance learning method
assisted by mixture of factor analysis. <em>NEUCOM</em>, <em>507</em>,
358–368. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-instance learning (MIL) is a problem with significant importance due to the existence of ambiguous labels in many practical tasks. The training data in MIL problem is represented by labeled bags containing a various number of unlabeled instances. This inexact label information has brought complexities to the classification of instances and bags. Fisher scores have been utilized to extract fixed-length representation vectors from the MIL bags with the assistance of generative models . However, the generative model utilized by the existing methods might disregard the covariance information. In this paper, we propose a multi-instance learning method (miMFA) utilizing Fisher scores derived from the mixture of factor analysis (MFA) model. The MFA generates nonlinear data with a set of local factor analysis models, while each local model approximates the full covariance Gaussian using latent factors. Thus, the MFA could cover the data distribution and generate Fisher scores effectively. The MFA-based Fisher score is then utilized to form the bag representation. Moreover, a reinforcement vector and the complementary information from auxiliary MIL methods are introduced for performance refinement. The proposed miMFA is evaluated on 11 MIL datasets, and achieves satisfactory results compared with the existing methods.},
  archive      = {J_NEUCOM},
  author       = {Shiluo Huang and Zheng Liu and Wei Jin and Ying Mu},
  doi          = {10.1016/j.neucom.2022.07.075},
  journal      = {Neurocomputing},
  pages        = {358-368},
  shortjournal = {Neurocomputing},
  title        = {A fisher score-based multi-instance learning method assisted by mixture of factor analysis},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forgery-free signature verification with stroke-aware
cycle-consistent generative adversarial network. <em>NEUCOM</em>,
<em>507</em>, 345–357. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the performance of handwritten signature verification (HSV) has been considerably improved by deep learning methods . However, deep HSV still faces significant challenges due to the lack of training data, especially for skilled forgeries. In this context, signature synthesis is a promising alternative to address the problem of insufficient data. Compared with offline modality, online signatures are more likely to produce natural duplicates by virtue of their dynamic information. Therefore, we propose a novel convolutional neural network model for offline HSV, called SigCNN, and utilize CycleGAN in style transfer fields to generate realistic offline signatures from online specimens and their duplicates. To compensate for the deficiency of vanilla CycleGAN in generating diverse stroke widths, we propose a new method, Stoke-cCycleGAN, to generate signatures at desired stroke width levels. By online signature duplication and online-to-offline conversion, our SigCNN model can be trained without requiring skilled forgeries. Experimental results showed that our SigCNN trained on generated signatures achieved competitive results on public datasets compared to existing methods. Code of Stroke-cCycleGAN is available at https://github.com/KAKAFEI123/Stroke-cCycleGAN.},
  archive      = {J_NEUCOM},
  author       = {Jiajia Jiang and Songxuan Lai and Lianwen Jin and Yecheng Zhu and Jiaxin Zhang and Bangdong Chen},
  doi          = {10.1016/j.neucom.2022.08.017},
  journal      = {Neurocomputing},
  pages        = {345-357},
  shortjournal = {Neurocomputing},
  title        = {Forgery-free signature verification with stroke-aware cycle-consistent generative adversarial network},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Salient instance segmentation with region and box-level
annotations. <em>NEUCOM</em>, <em>507</em>, 332–344. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of saliency detection , salient instance segmentation is a novel challenging task that has received widespread attention. Due to the limited scale of the available dataset and the high cost of mask annotations, a substantial quantity of supervision sources is urgently required to train a high-performing salient instance model. To this end, we aim to train a novel salient instance segmentation model by weak supervisions that make full use of the existing salient object detection dataset. In this paper, we present a cyclic global context salient instance segmentation network (CGCNet) supervised by the combination of salient regions and bounding boxes from ready-made salient object detection datasets. To locate salient instances more accurately, a global feature refining layer is designed to expand the size of the features from the region of interest (ROI) to the global field in a scene. Moreover, a labeling updating scheme is embedded in the proposed framework to iteratively update the weak labels. Extensive experimental results demonstrate that our CGCNet trained by weak labels is competitive with the existing fully-supervised state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Jialun Pei and He Tang and Wanru Wang and Tianyang Cheng and Chuanbo Chen},
  doi          = {10.1016/j.neucom.2022.08.038},
  journal      = {Neurocomputing},
  pages        = {332-344},
  shortjournal = {Neurocomputing},
  title        = {Salient instance segmentation with region and box-level annotations},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Emergence of bipartite flocking behavior for cucker-smale
model on cooperation-competition networks with time-varying delays.
<em>NEUCOM</em>, <em>507</em>, 325–331. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the collective behavior of bipartite flocking for a set of autonomous mobile agents based on Cucker-Smale update rules on directed cooperation-competition networks. In our model, cooperative or competitive degree between neighbouring agents is set by a nonlinear function of the communication distance between agents, which is called weight function, and further the influence of communication delays on the system stability and the final distance between agents is analyzed. With the help of related conclusions about sub-stochastic matrices, a sufficient condition relying on the topology structure, weight functions and initial states is established to guarantee the realization of bipartite flocking behavior. In the end the effectiveness of dynamic results is verified through a numerical example.},
  archive      = {J_NEUCOM},
  author       = {Kai Chen and Zhuangzhuang Ma and Libing Bai and Hanmin Sheng and Yuhua Cheng},
  doi          = {10.1016/j.neucom.2022.08.046},
  journal      = {Neurocomputing},
  pages        = {325-331},
  shortjournal = {Neurocomputing},
  title        = {Emergence of bipartite flocking behavior for cucker-smale model on cooperation-competition networks with time-varying delays},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dependency graph enhanced interactive attention network for
aspect sentiment triplet extraction. <em>NEUCOM</em>, <em>507</em>,
315–324. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect sentiment triplet extraction is an extremely daunting task designed to identify the triplets from comments, where each triplet is composed of an aspect term, the related opinion term, and the sentiment between them. Existing research efforts majorly construct a novel tagging scheme to avoid the disadvantages of pipeline methods. However, the improvement is limited due to neglecting the implicit grammatical relationships among the three elements in a triplet. To cope with this limitation, we put forward an innovative Dependency Graph Enhanced Interactive Attention Network , which explicitly introduces the syntactic and semantic relationships between words. Specifically, an interactive attention mechanism is conceived to jointly consider both the contextual features learned from Bi-directional Long Short-Term Memory and the syntactic dependencies learned from the correspondent dependency graph in an iterative interaction manner. In addition, we notice that words with different Part-of-Speech categories have different contributions to the semantic expression of sentences. Accordingly, the information of different Part-of-Speech categories is recognized during the modeling process to properly capture the semantic relationships . Experiments on the benchmark datasets originally derived from SemEval Challenges illustrate that our presented approach has superiority over strong baselines.},
  archive      = {J_NEUCOM},
  author       = {Lingling Shi and Donghong Han and Jiayi Han and Baiyou Qiao and Gang Wu},
  doi          = {10.1016/j.neucom.2022.07.067},
  journal      = {Neurocomputing},
  pages        = {315-324},
  shortjournal = {Neurocomputing},
  title        = {Dependency graph enhanced interactive attention network for aspect sentiment triplet extraction},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Advances in artificial neural networks, machine learning and
computational intelligence. <em>NEUCOM</em>, <em>507</em>, 311–314. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Luca Oneto and Nicoló Navarin and Frank-Michael Schleif},
  doi          = {10.1016/j.neucom.2022.08.001},
  journal      = {Neurocomputing},
  pages        = {311-314},
  shortjournal = {Neurocomputing},
  title        = {Advances in artificial neural networks, machine learning and computational intelligence},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MFRFNN: Multi-functional recurrent fuzzy neural network for
chaotic time series prediction. <em>NEUCOM</em>, <em>507</em>, 292–310.
(<a href="https://doi.org/10.1016/j.neucom.2022.08.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chaotic time series prediction, a challenging research topic in dynamic system modeling, has drawn great attention from researchers around the world. In recent years extensive researches have been done on developing chaotic time series prediction methods, and various models have been proposed. Among them, recurrent fuzzy neural networks (RFNNs) have shown significant potential in this area. Most of the proposed RFNNs learn a single function, but when dealing with chaotic time series, different outputs may be generated for a specific input based on the system’s state. So, a network is required that can learn multiple functions simultaneously. Based on this concept, a novel multi-functional recurrent fuzzy neural network (MFRFNN) is proposed in this paper. MFRFNN consists of two fuzzy neural networks with Takagi-Sugeno-Kang fuzzy rules, one is used to produce the output, and the other to determine the system’s state. There is a feedback loop between these two networks, which makes MFRFNN capable of learning and memorizing historical information of past observations. Employing the states allows the proposed network to learn multiple functions simultaneously. Moreover, a new learning algorithm, which employs the particle swarm optimization algorithm , is developed to train the networks’ weights. The effectiveness of MFRFNN is validated using the Lorenz and Rossler chaotic time series and four real-world datasets, including Box–Jenkins gas furnace, wind speed prediction, Google stock price prediction, and air quality index prediction. Based on the root mean square error, the proposed method shows a decrease of 35.12\% , 13.95\% 35.12\%,13.95\% , and 49.62\% 49.62\% from the second best methods in the Lorenz time series, Box–Jenkins gas furnace, and wind speed prediction dataset, respectively.},
  archive      = {J_NEUCOM},
  author       = {Hamid Nasiri and Mohammad Mehdi Ebadzadeh},
  doi          = {10.1016/j.neucom.2022.08.032},
  journal      = {Neurocomputing},
  pages        = {292-310},
  shortjournal = {Neurocomputing},
  title        = {MFRFNN: Multi-functional recurrent fuzzy neural network for chaotic time series prediction},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monte carlo-based reinforcement learning control for
unmanned aerial vehicle systems. <em>NEUCOM</em>, <em>507</em>, 282–291.
(<a href="https://doi.org/10.1016/j.neucom.2022.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new data-driven reinforcement learning method based on Monte Carlo simulation is developed to solve the optimal control problem of unmanned aerial vehicle (UAV) systems. Based on the data which are generated by Monte Carlo simulation , neural network (NN) is used to construct the dynamics of the UAV system with unknown disturbances, where the mathematical model of the UAV system is unnecessary. An effective iterative framework of action and critic is constructed to obtain the optimal control law. The convergence property is developed to guarantee that the iterative performance cost function converges to a finite neighborhood of the optimal performance cost function. Finally, numerical results are given to illustrate the effectiveness of the developed method.},
  archive      = {J_NEUCOM},
  author       = {Qinglai Wei and Zesheng Yang and Huaizhong Su and Lijian Wang},
  doi          = {10.1016/j.neucom.2022.08.011},
  journal      = {Neurocomputing},
  pages        = {282-291},
  shortjournal = {Neurocomputing},
  title        = {Monte carlo-based reinforcement learning control for unmanned aerial vehicle systems},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EALI: Energy-aware layer-level scheduling for convolutional
neural network inference services on GPUs. <em>NEUCOM</em>,
<em>507</em>, 265–281. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of convolutional neural networks (CNNs) has made low-latency inference services on Graphic Processing Units (GPUs) a hot research topic. However, GPUs are hardware processors with high power consumption. To have the least energy consumption while meeting latency Service-Level-Objective (SLO), batching strategy and dynamic voltage frequency scaling (DVFS) are two important solutions. However, existing studies do not coordinate them and regard CNN as a black box, which makes inference services less energy-efficient. In this paper, we propose EALI, an energy-aware layer-level adaptive scheduling framework that is comprised of a power prediction model, a layer combination strategy, and an energy-aware layer-level scheduler. The power prediction model uses classic machine learning techniques to predict fine-grained layer-level power consumption. The layer combination strategy combines multiple layers into optimization units to lower scheduling overhead and complexity. The energy-aware layer-level scheduler adaptively coordinates batching strategy and layer-level DVFS according to workloads to minimize the energy consumption while meeting SLO. Our experimental results on NVIDIA Tesla M40 and V100 GPUs show that, compared to the state-of-the-art approaches, EALI decreases energy consumption by up to 36.24\% while meeting SLO.},
  archive      = {J_NEUCOM},
  author       = {Chunrong Yao and Wantao Liu and Zhibing Liu and Longchuan Yan and Songlin Hu and Weiqing Tang},
  doi          = {10.1016/j.neucom.2022.08.025},
  journal      = {Neurocomputing},
  pages        = {265-281},
  shortjournal = {Neurocomputing},
  title        = {EALI: Energy-aware layer-level scheduling for convolutional neural network inference services on GPUs},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning in retinal optical coherence tomography (OCT):
A comprehensive survey. <em>NEUCOM</em>, <em>507</em>, 247–264. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal optical coherence tomography (OCT) images provide fundamental information regarding the health of the posterior eye (e.g., the retina and choroid). Thus, the development of automatic image analysis methods (e.g., segmentation) is fundamental to provide clinicians and researchers with quantitative data that facilitates decision making. In recent years, various machine learning (ML) methods have been developed to perform these automated image analyses, improving performance over traditional methods, increasing repeatability, and reducing the use of time-consuming manual analysis. Deep learning (DL), a sub-field of ML, represents a new approach that can improve image processing outcomes. Results published to date demonstrate that DL architectures generally achieve superior performance to previously proposed methods based on traditional image analysis or early ML techniques . Thus, DL methods for OCT image analysis have provided an important advance in the area of retinal layer segmentation in images from healthy eyes as well as those with pathologies. This paper provides a comprehensive narrative literature review of current DL layer segmentation methods applied to OCT images of the posterior segment of the eye. The manuscript provides an overview on the state-of-the-art in deep learning as well as highlighting some important areas for future developments to extend the analysis methods in this field.},
  archive      = {J_NEUCOM},
  author       = {Ignacio A. Viedma and David Alonso-Caneiro and Scott A. Read and Michael J. Collins},
  doi          = {10.1016/j.neucom.2022.08.021},
  journal      = {Neurocomputing},
  pages        = {247-264},
  shortjournal = {Neurocomputing},
  title        = {Deep learning in retinal optical coherence tomography (OCT): A comprehensive survey},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Information flow in deep restricted boltzmann machines: An
analysis of mutual information between inputs and outputs.
<em>NEUCOM</em>, <em>507</em>, 235–246. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Empirical evidence suggests the existence of an entangled relationship between the information flow from inputs features to hidden representations of a deep neural network and its ability to generalize from training samples to unobserved data. For instance, regularization techniques often used to control statistical generalization, are expected to impact this information flow. In this work, we study MI (mutual information) between inputs and representation outputs, and its relationship with various regularization methods commonly used in Restricted Boltzmann Machines (RBM) and their generalizations: Deep Belief Networks and Deep Boltzmann Machines . Our theoretical findings show the existence of fundamental connections between the hyperparameters associated with the regularization and the MI, including relevant practical ingredients such as: network dimension, matrix norms and dropout probability, which are well-known to influence the generalization ability of the network. These results are experimentally corroborated on various visual datasets. Code is avaliable at https://codeocean.com/capsule/3175474/tree .},
  archive      = {J_NEUCOM},
  author       = {Matias Vera and Leonardo Rey Vega and Pablo Piantanida},
  doi          = {10.1016/j.neucom.2022.08.014},
  journal      = {Neurocomputing},
  pages        = {235-246},
  shortjournal = {Neurocomputing},
  title        = {Information flow in deep restricted boltzmann machines: An analysis of mutual information between inputs and outputs},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cosmos propagation network: Deep learning model for point
cloud completion. <em>NEUCOM</em>, <em>507</em>, 221–234. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point clouds measured by 3D scanning devices often have partially missing data due to the view positioning of the scanner. The missing data can reduce the performance of a point cloud in downstream tasks such as segmentation, location, and pose estimation. Consequently, 3D point cloud completion aims to predict the missing regions of incomplete objects for these fundamental 3D vision tasks. However, predicting the complete object can easily diminish the detail or structure of a measured region, which usually does not require repair. This study proposes a novel neural network architecture, Cosmos Propagation Network (CP-Net), for 3D point cloud completion. CP-Net extracts latent features in different scales from incomplete point clouds used as input. For point cloud generation, we propose a novel point expand method using a Mirror Expand module. Compared with existing methods, our Mirror Expand module introduces less information redundancy, which makes the distribution of points more reliable. CP-Net predicts the details of missing regions and maintains a clear general structure. The performance of CP-Net on several benchmarks was compared to that of current baseline methods. Compared to the existing methods, CP-Net showed the best performance for various metrics. Thus, CP-Net is expected to help address various problems related to 3D point cloud completion. Its source code is available at https://github.com/ark1234/CP-Net.},
  archive      = {J_NEUCOM},
  author       = {Fangzhou Lin and Yajun Xu and Ziming Zhang and Chenyang Gao and Kazunori D Yamada},
  doi          = {10.1016/j.neucom.2022.08.007},
  journal      = {Neurocomputing},
  pages        = {221-234},
  shortjournal = {Neurocomputing},
  title        = {Cosmos propagation network: Deep learning model for point cloud completion},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contrastive learning from label distribution: A case study
on text classification. <em>NEUCOM</em>, <em>507</em>, 208–220. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art text classification models are dominated by deep neural networks, but they still struggle to the issue of poor generalization ability when using cross entropy loss for training. One of the reasons is the training samples are usually annotated with hard labels, ignoring the inter-label relationship among these labels. This results in the outputted distributions to violate the label-correlation. Although the widely used contrastive learning is able to learn highly-expressive feature representations that generalize well across the training and test sets, contrastive learning in the embedding space is difficult to model the label correlation and may still output unreasonable label distributions. In this paper, we suggest contrastive learning using label distributions and present a novel label-level contrastive learning (LLCL) paradigm, which can constrain the unreasonable label distributions from model outputs. We hypothesize that the label distributions of the instances in the same class are more similar than those from other classes. We introduce two label-level contrastive learning losses, namely supervised contrastive learning and self-supervised contrastive learning. After adding our proposed losses to the cross-entropy loss as regularizer for the training text classification model, our model obtains the average improvement of 0.74\% over the strong RoBERTa-Large baseline on ten datasets. Particularly, our contrastive learning in the label space can effectively capture label correlations better than that in the embedding space, achieving an improvement of 6.2\% in the top-2 accuracy on the SST-5 dataset. We also demonstrate that our proposed method is more effective, especially in the text classification tasks with a large label space or limited labeled data. Last but not least, our model does not rely on any kind of specialized architectures, data augmentation methods, or additional unsupervised data.},
  archive      = {J_NEUCOM},
  author       = {Tao Qian and Fei Li and Meishan Zhang and Guonian Jin and Ping Fan and Wenhua Dai},
  doi          = {10.1016/j.neucom.2022.07.076},
  journal      = {Neurocomputing},
  pages        = {208-220},
  shortjournal = {Neurocomputing},
  title        = {Contrastive learning from label distribution: A case study on text classification},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Occluded pedestrian detection through bi-center prediction
in anchor-free network. <em>NEUCOM</em>, <em>507</em>, 199–207. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To handle the occlusion issue, this paper proposes a simple but effective pedestrian detector who designs a novel bi-center prediction mechanism (namely Bi-Center) based on the anchor-free network. Specifically, we modify the training loss or ground truth of the two designed center prediction branches in the pedestrian detection head. In the first branch, the negative samples around centers of occluded pedestrians, which are mainly covered by the background region, are down-weighted in a novel weighted Focal Loss according to the occlusion levels. In the second branch, we further integrate the occlusion ratio into the Gaussian mask of center ground truth to improve the predicted probability of occluded pedestrian instances. We optimize the designed detection head of the network in an end-to-end fashion, and utilize the complementary outputs of the designed two center prediction branches to boost the detection performance. The proposed bi-center prediction mechanism forces the network to pay more attention to the occluded pedestrian instances. Experimental results on the challenging CityPersons, Caltech, and CrowdHuman benchmarks sufficiently validate the efficacy of our Bi-Center detector for occlusion handling in pedestrian detection.},
  archive      = {J_NEUCOM},
  author       = {Qiming Li and Yuquan Bi and Rongsheng Cai and Jun Li},
  doi          = {10.1016/j.neucom.2022.08.026},
  journal      = {Neurocomputing},
  pages        = {199-207},
  shortjournal = {Neurocomputing},
  title        = {Occluded pedestrian detection through bi-center prediction in anchor-free network},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust learning of huber loss under weak conditional moment.
<em>NEUCOM</em>, <em>507</em>, 191–198. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the performance of robust learning with Huber loss. As an alternative to traditional empirical risk minimization schemes, Huber regression has been extensively used in machine learning . A new comparison theorem is established in the paper, which characterizes the gap between the excess generalization error and the prediction error. In addition, we refine the error bounds from the perspective of statistical learning theory and improve the convergence rates in the presence of heavy-tailed noise. It is worth mentioning that a new moment condition ∊ E [ | Y | 1 + ∊ | X = x ] ∈ L ρ X 2 E[|Y|1+∊|X=x]∈LρX2 is employed in analysis of error bound and learning rates from a theoretical viewpoint.},
  archive      = {J_NEUCOM},
  author       = {Shouyou Huang},
  doi          = {10.1016/j.neucom.2022.08.012},
  journal      = {Neurocomputing},
  pages        = {191-198},
  shortjournal = {Neurocomputing},
  title        = {Robust learning of huber loss under weak conditional moment},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convolutional neural network and riemannian geometry hybrid
approach for motor imagery classification. <em>NEUCOM</em>,
<em>507</em>, 180–190. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electroencephalogram (EEG) signal is commonly applied in the brain-computer interface (BCI) system of the motor imagery paradigm because it is noninvasive and has a high time resolution. This paper proposes a motor imagery classification method based on convolutional neural networks and Riemannian geometry to overcome the problem of noise and extreme values impacting motor imagery classification performance. The time-domain properties of EEG signals are extracted using multiscale temporal convolutions, whereas the spatial aspects of EEG signals are extracted using multiple convolutional kernels learned by spatial convolution. The extracted features are mapped to a Riemannian manifold space, and bilinear mapping and logarithmic operations are performed on the features to solve the problem of noise and extreme values. The effectiveness of the proposed method is validated using four types of motor imagery in the BCI competition IV dataset 2a to evaluate the classification ability. The experimental results show that the proposed approach has obvious advantages in the classification performance of motor imagery.},
  archive      = {J_NEUCOM},
  author       = {Chang Gao and Wenchao Liu and Xian Yang},
  doi          = {10.1016/j.neucom.2022.08.024},
  journal      = {Neurocomputing},
  pages        = {180-190},
  shortjournal = {Neurocomputing},
  title        = {Convolutional neural network and riemannian geometry hybrid approach for motor imagery classification},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TSPNet: Translation supervised prototype network via
residual learning for multimodal social relation extraction.
<em>NEUCOM</em>, <em>507</em>, 166–179. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal social relation extraction requires sufficient features fusion to identify the relation between different targets. Compared with traditional multimodal social relation extraction, there are many semantic gap issues for the few-shot scenario task, such as insufficient across-modality assistance, lacking explicit supervision, and unbalanced relations. To address the above problems, a novel Translation Supervised Prototype Network (TSPNet) is proposed, which extracts all the features of knowledge triples, not just relation features. First, the triple-level unimodal encoder learns textual and visual representation of knowledge triples from the entire information via two-stream encoding. Second, the triple-level multimodal extractor obtains multimodal knowledge triples by employing the residual learner to build the triple-level interaction across modalities. Finally, the intra-triple translation supervised decoder predicts the few-shot relations based on a prototype network supervised with the intra-triple translation as an explicit constraint. Our model achieves SOTA performance on three challenging benchmark datasets for few-shot multimodal social relation extraction, and further analysis shows that our model is effective and owns a strong generalization ability to avoid bias.},
  archive      = {J_NEUCOM},
  author       = {Hankun Kang and Xiaoyu Li and Li Jin and Chunbo Liu and Zequn Zhang and Shuchao Li and Yanan Zhang},
  doi          = {10.1016/j.neucom.2022.07.079},
  journal      = {Neurocomputing},
  pages        = {166-179},
  shortjournal = {Neurocomputing},
  title        = {TSPNet: Translation supervised prototype network via residual learning for multimodal social relation extraction},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Marginal samples for knowledge distillation.
<em>NEUCOM</em>, <em>507</em>, 157–165. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous work like Category Structure Knowledge Distillation proposes to construct category-wise relations for knowledge distillation by introducing intra-category and inter-category relations based on category centers. However, category centers may be unreliable when feature representations of wrongly classified samples are used to form category centers. Besides, inter-category relations based on category centers are coarse-grained. In this paper, we propose a Marginal Sample Knowledge Distillation (MSKD) to construct reliable category centers and fine-grained inter-category relations by introducing label filtering and marginal samples. Label filtering removes feature representations of wrongly classified samples from the calculation of category centers to create unbiased and reliable category centers. Marginal samples are defined as the correctly classified samples close to category boundaries. Marginal samples contain information of other categories and form fine-grained category boundaries for knowledge distillation. Extensive experiments on different datasets and teacher-student architecture settings show that our method has excellent performances when compared with closely related methods.},
  archive      = {J_NEUCOM},
  author       = {Zailiang Chen and Xianxian Zheng and Hailan Shen and Jinghao Zhang and Peishan Dai and Rongchang Zhao},
  doi          = {10.1016/j.neucom.2022.08.004},
  journal      = {Neurocomputing},
  pages        = {157-165},
  shortjournal = {Neurocomputing},
  title        = {Marginal samples for knowledge distillation},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Binary multi-modal matrix factorization for fast item
cold-start recommendation. <em>NEUCOM</em>, <em>507</em>, 145–156. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hashing technology can support large-scale recommendation very effectively due to its advantages of low storage cost and high recommendation efficiency. However, existing hashing-based recommendation methods often suffer from item cold-start problem. This is because they simply consider the user-item interaction and the single content information of the items, but the full interaction history is not always available and the single auxiliary information may be missing. To solve this issue, in this paper we propose a Binary Multi-modal Matrix Factorization (BMMF) method. First, we propose an efficient consensus multi-modal mapping to transform the heterogeneous multi-modal features to the unified factors by exploiting the complementarity of multiple modalities. Then, binary matrix factorization is simultaneously performed on the multi-modal features of the items and past user preferences to learn the compact binary codes of the users/items in a common Hamming space. In addition, inspired by the observation that similar instances often have similar binary codes within a short Hamming distance , we formulate a semantic structure regularization term to preserve the similarities of the items during the binary embedding process. Finally, we develop an effective Discrete Coordinate Descent (DCD) approach to tackle the formulated discrete hash optimization problem directly. Experiments on three publicly available real-world datasets demonstrate the superiority of the proposed method against the state-of-the-art methods. Our source codes and testing datasets are available at https://github.com/pcm1217/BMMF .},
  archive      = {J_NEUCOM},
  author       = {Chengmei Peng and Lei Zhu and Yang Xu and Yaping Li and Lei Guo},
  doi          = {10.1016/j.neucom.2022.08.013},
  journal      = {Neurocomputing},
  pages        = {145-156},
  shortjournal = {Neurocomputing},
  title        = {Binary multi-modal matrix factorization for fast item cold-start recommendation},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AEP: Aligning knowledge graphs via embedding propagation.
<em>NEUCOM</em>, <em>507</em>, 130–144. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph alignment aims to identify entity pairs having the same meaning between different knowledge graphs, which is essential to the automated construction of a coherent knowledge base. With the development of knowledge representation learning , researchers have proposed several useful embedding-based alignment methods. In practice, some entities are easily aligned with high confidence while others are not. However, there is a lack of effective methods which boost the alignment of implicitly aligned entities based on explicitly aligned ones. This paper presents AEP, which combines several effective schemes for accurate knowledge graph alignment. First, we employ a word-embedding model to encode the semantic information contained in entities’ surface names. We propose an attention-based graph convolutional network model to incorporate the structural information via supervised embedding propagation. Besides, we develop a multi-view bootstrapping strategy to address the over-fitting problem caused by insufficient training sets. Next, an embedding-propagation-based alignment scheme is proposed to improve the alignment accuracy by propagating explicitly aligned entities’ embeddings to implicitly aligned ones in an unsupervised manner . Finally, we conduct extensive experiments to validate the superiority of AEP and evaluate the effects of proposed schemes. Experimental results show that AEP outperforms state-of-the-art methods, and the proposed schemes improve the alignment accuracy significantly.},
  archive      = {J_NEUCOM},
  author       = {Chenxu Wang and Yue Wan and Zhenhao Huang and Panpan Meng and Pinghui Wang},
  doi          = {10.1016/j.neucom.2022.08.018},
  journal      = {Neurocomputing},
  pages        = {130-144},
  shortjournal = {Neurocomputing},
  title        = {AEP: Aligning knowledge graphs via embedding propagation},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Delayed distributed impulsive synchronization of coupled
neural networks with mixed couplings. <em>NEUCOM</em>, <em>507</em>,
117–129. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, synchronization problem of coupled neural networks (CNNs) with both the distributed delay coupling (DDC) and the nonlinear coupling is studied. Firstly, a novel array of delayed inequalities with mixed delays is introduced. Specifically, mixed delays involve the distributed delay and discrete impulsive delays. Stemmed from such newly proposed inequalities, some sufficient conditions ensuring the exponential synchronization of CNNs are obtained by utilizing technique of linear matrix inequalities (LMIs) and Kronecker product . Furthermore, the delay-dependent distributed impulsive controller is devised, where discrete delays can be nonidentical at different impulsive instants. In addition, we pay special attention on synchronization issue of large-scale CNNs and derive some low-dimensional sufficient conditions by employing the technique of the matrix decomposition . Finally, two illustrative numerical examples are provided to demonstrate the effectiveness of theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyu Zhang and Chuandong Li and Hongfei Li and Jing Xu},
  doi          = {10.1016/j.neucom.2022.07.045},
  journal      = {Neurocomputing},
  pages        = {117-129},
  shortjournal = {Neurocomputing},
  title        = {Delayed distributed impulsive synchronization of coupled neural networks with mixed couplings},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Codebook-softened product quantization for high accuracy
approximate nearest neighbor search. <em>NEUCOM</em>, <em>507</em>,
107–116. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Product quantization (PQ) is a fundamental technique for approximate nearest neighbor (ANN) search in many applications such as information retrieval, computer vision and pattern recognition. In the existing PQ-based methods for approximate nearest neighbor search, the reachable best search accuracy is achieved by using fixed codebooks. The search performance is limited by the quality of the hard codebooks. Unlike the existing methods, in this paper, we present a novel codebook-softened product quantization (CSPQ) method to achieve more quantization levels by softening codebooks. We firstly analyze how well the database vectors match the trained codebooks by examining quantization error for each database vector, and select the bad-matching database vectors. Then, we give the trained codebooks b -bit freedom to soften codebooks. Finally, by minimizing quantization errors, the bad-matching vectors are encoded by softened codebooks and the labels of best-matching codebooks are recorded. Experimental results on SIFT1M, GIST1M and SIFT10M show that, despite its simplicity, our proposed method achieves higher accuracy compared with PQ and it can be combined with other non-exhaustive frameworks to achieve fast search.},
  archive      = {J_NEUCOM},
  author       = {Jingya Fan and Zhibin Pan and Liangzhuang Wang and Yang Wang},
  doi          = {10.1016/j.neucom.2022.08.002},
  journal      = {Neurocomputing},
  pages        = {107-116},
  shortjournal = {Neurocomputing},
  title        = {Codebook-softened product quantization for high accuracy approximate nearest neighbor search},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Channel pruning based on convolutional neural network
sensitivity. <em>NEUCOM</em>, <em>507</em>, 97–106. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pruning is a useful technique for decreasing the memory consumption and floating point operations (FLOPs) of deep convolutional neural network (CNN) models. Nevertheless, at modest pruning levels, current structured pruning approaches often lead to considerable declines in accuracy. Furthermore, existing approaches often treat pruning rates as super parameters, neglecting the sensitivity of different convolution layers . In this study, we propose a novel sensitivity-based method for channel pruning that utilizes second-order sensitivity as a criterion. The essential concept is to prune insensitive filters while retaining sensitive ones. We quantify the sensitivity of the filter using the sum of the sensitivities of all weights in the filter, rather than the magnitude-based metric frequently applied in the literature. Furthermore, a layer sensitivity approach based on the Hessian eigenvalues of each layer is introduced into the process of automatically choosing the most appropriate pruning rate for each layer. Experiments on a variety of modern CNN architectures demonstrate that we can considerably enhance the pruning rate while sacrificing a small amount of accuracy, resulting in a reduction of more than 60\% in FLOPs on CIFAR-10. Notably, on ImageNet, pruning based on ResNet50 decreased the FLOPs by 56.3\% while losing only 0.92\% of accuracy.},
  archive      = {J_NEUCOM},
  author       = {Chenbin Yang and Huiyi Liu},
  doi          = {10.1016/j.neucom.2022.07.051},
  journal      = {Neurocomputing},
  pages        = {97-106},
  shortjournal = {Neurocomputing},
  title        = {Channel pruning based on convolutional neural network sensitivity},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel metric learning framework by exploiting global and
local information. <em>NEUCOM</em>, <em>507</em>, 84–96. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance metric learning plays a significant role in improving the generalization of algorithms related to distance metrics. In this paper, we first propose a generalized Mahalanobis metric learning framework (called GLML) to make use of the prior knowledge from the samples including global and local information, the main goal of which is to enlarge the distance of dissimilar sample pairs and shrink the distance of similar sample pairs simultaneously. Specifically, the metric learning problem is guided by a discriminative regularization through incorporating the pair-wise and class-wise information. Moreover, an effective alternating iterative algorithm is developed to optimize the proposed GLML, and the convergence of the algorithm is demonstrated theoretically. Then a boosting algorithm of GLML (BGLML) is proposed, where the low-rank basis learning is jointly optimized with the metric to better uncover the data structure and mitigate the computational burden. Following that, numerical experiments are carried out on binary classification and multi-classification problems. With different assessment criteria, experiment results from different scale datasets confirm that the proposed methods either improve generalization or have comparable results compared with the state-of-the-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Qiangqiang Ren and Chao Yuan and Yifeng Zhao and Liming Yang},
  doi          = {10.1016/j.neucom.2022.08.003},
  journal      = {Neurocomputing},
  pages        = {84-96},
  shortjournal = {Neurocomputing},
  title        = {A novel metric learning framework by exploiting global and local information},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). HIRE: Distilling high-order relational knowledge from
heterogeneous graph neural networks. <em>NEUCOM</em>, <em>507</em>,
67–83. (<a href="https://doi.org/10.1016/j.neucom.2022.08.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers have recently proposed plenty of heterogeneous graph neural networks (HGNNs) due to the ubiquity of heterogeneous graphs in both academic and industrial areas. Instead of pursuing a more powerful HGNN model, in this paper, we are interested in devising a versatile plug-and-play module, which accounts for distilling relational knowledge from pre-trained HGNNs. To the best of our knowledge, we are the first to propose a HI gh-order RE lational ( HIRE ) knowledge distillation framework on heterogeneous graphs, which can significantly boost the prediction performance regardless of model architectures of HGNNs. Concretely, our HIRE framework initially performs first-order node-level knowledge distillation , which encodes the semantics of the teacher HGNN with its prediction logits. Meanwhile, the second-order relation-level knowledge distillation imitates the relational correlation between node embeddings of different types generated by the teacher HGNN. Extensive experiments on various popular HGNNs models and three real-world heterogeneous graphs demonstrate that our method obtains consistent and considerable performance enhancement, proving its effectiveness and generalization ability .},
  archive      = {J_NEUCOM},
  author       = {Jing Liu and Tongya Zheng and Qinfen Hao},
  doi          = {10.1016/j.neucom.2022.08.022},
  journal      = {Neurocomputing},
  pages        = {67-83},
  shortjournal = {Neurocomputing},
  title        = {HIRE: Distilling high-order relational knowledge from heterogeneous graph neural networks},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An ultra-compact and high-speed FFT-based large-integer
multiplier for fully homomorphic encryption using a dual spike-based
arithmetic circuit over GF(p). <em>NEUCOM</em>, <em>507</em>, 54–66. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During last years, fully homomorphic encryption (FHE) has attracted great interest since enables computation on encrypted data and thus can be considered as a potential solution in advanced applications, such as privacy-preserving cloud computing , genomics, electronic voting and bio-metric authentication . Nowadays, software simulations of the FHE schemes on general purpose computers are extremely slow. Therefore, the development of specific hardware architectures open up new horizons in efficient simulation of FHE schemes. Until date, the implementation of FHE schemes in embedded devices remain impractical due to very high processing time and area consumption required to process very large-integer numbers. Specifically, the development of efficient very large-integer finite-field adder and multiplier potentially allows the throughput and area consumption to be improved since these circuits are the most used components in the computation of FHE schemes. This work presents, for the first time, the development of a compact and highly dual finite-field circuit based on spiking neural P systems (SN P), dendritic growth, dendritic pruning, communication on request and structural plasticity. Specifically, this circuit performs either the finite-field addition or multiplication of two variable integers by only reconnecting their synapses dynamically. Hence, the proposed circuit performs both operations employing the same neural network . In this way, we achieve a significant improvement in terms of area consumption and throughput. Since the computation of FHE schemes requires the multiplication of very large-integer numbers, we use the proposed dual finite-field circuit as the basic processing unit to create a very large-integer multiplier based on fast Fourier transform (FFT). Specifically, the creation of the proposed very large-integer multiplier has allowed us to accelerate the key generation and encryption processes involved in the computation of FHE algorithm. This multiplier was implemented in scalable compact neuromorphic architecture, which mimic the dynamic dendritic phenomena, such as dendritic growth and dendritic pruning. To achieve this, we propose a dynamic multiplexing mechanism based on simple multiplexers and an optimized control unit. This have allowed us to significantly improve the area consumption compared with previously reported solution.},
  archive      = {J_NEUCOM},
  author       = {Luis Garcia and Eduardo Vazquez and Gabriel Sanchez and Juan-Gerardo Avalos and Giovanny Sanchez},
  doi          = {10.1016/j.neucom.2022.08.020},
  journal      = {Neurocomputing},
  pages        = {54-66},
  shortjournal = {Neurocomputing},
  title        = {An ultra-compact and high-speed FFT-based large-integer multiplier for fully homomorphic encryption using a dual spike-based arithmetic circuit over GF(p)},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Skeleton-based similar action recognition through
integrating the salient image feature into a center-connected graph
convolutional network. <em>NEUCOM</em>, <em>507</em>, 40–53. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based human action recognition has drawn more and more attention due to its easy implementation and stable application in intelligent human-robot interaction. However, most existing studies only used the skeleton data but completely ignored other image semantic information to build action recognition models, which would confuse the recognition of similar actions because of the ambiguity between skeleton data. Here, a center-connected graph convolutional network enhanced with salient image features (SIFE-CGCN) is proposed to address the problem of similar action recognition. First, a center-connected network (CGCN) is constructed to capture the small differences between similar actions through exploring the possible collaboration between all joints. Subsequently, a metric of movement changes is employed to optimally select the salient image from an action video, and then the EfficientNet is used to achieve the action semantic classification of the salient images. Finally, the recognition results of CGCN are strengthened with the classification results of salient images to further improve the recognition accuracy for similar actions. Additionally, a metric is proposed to measure the action similarity with the skeleton data, and then a similar action dataset is built. Extensive experiments on the datasets of similar action and NTU RGB + D 60/120 were conducted to verify the performance of the proposed methods. Experimental results validated the effectiveness of salient image feature enhancement and showed that the proposed SIFE-CGCN achieved the state-of-the-art performance on the similar action and NTU RGB + D 60/120 datasets.},
  archive      = {J_NEUCOM},
  author       = {Zhongyu Bai and Qichuan Ding and Hongli Xu and Jianning Chi and Xiangyue Zhang and Tiansheng Sun},
  doi          = {10.1016/j.neucom.2022.07.080},
  journal      = {Neurocomputing},
  pages        = {40-53},
  shortjournal = {Neurocomputing},
  title        = {Skeleton-based similar action recognition through integrating the salient image feature into a center-connected graph convolutional network},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MSFNet: MultiStage fusion network for infrared and visible
image fusion. <em>NEUCOM</em>, <em>507</em>, 26–39. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a multistage fusion network to solve the infrared and visible image fusion (IVIF) problem. Unlike other deep learning methods, our network architecture is designed to the complex balance between spatial details and contextualized information. In order to optimally balance these competing goals, our main proposal is a multistage architecture that progressively learns IVIF functions for the source images (infrared and visible images), thereby breaking down the overall recovery process into more manageable steps. Specifically, our model first learns the contextural features using the encoder-decoder architecture with downsampling operations and later combines them with a full-resolution branch that retains local details. Between stages, we introduce a cross-stage fusion module (CSFM) to propagate multiscale contextual features from an earlier stage to a later stage. In addition, we introduce an upsampling module that can conquer both checkerboard artifacts and blurring effect by a bilinear interpolation operation followed by a deformable convolution. The resulting tightly interlinked multistage fusion network, named MSFNet, demonstrates the superiority of our method over state-of-the-art performance on publicly available datasets.},
  archive      = {J_NEUCOM},
  author       = {Chenwu Wang and Junsheng Wu and Zhixiang Zhu and Hao Chen},
  doi          = {10.1016/j.neucom.2022.07.048},
  journal      = {Neurocomputing},
  pages        = {26-39},
  shortjournal = {Neurocomputing},
  title        = {MSFNet: MultiStage fusion network for infrared and visible image fusion},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intuitionistic fuzzy twin support vector machines for
imbalanced data. <em>NEUCOM</em>, <em>507</em>, 16–25. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of imbalanced datasets is one of the main challenges in machine learning techniques . Support vector machine (SVM), which generates a model biased within the majority class, usually has bad performance on the minority class because this class may be considered incorrectly as noises. Moreover, datasets often include noises and outliers, and SVM cannot effectively deal with those datasets. In this paper, to defeat the aforementioned challenges, we propose intuitionistic fuzzy twin support vector machines for imbalanced data (IFTSVM-ID). The proposed method can easily handle imbalanced datasets in the presence of noises and outliers. A reasonable weighting strategy is offered to deal with imbalanced classes, and a margin-based technique is assigned to reduce the impact of noise and outliers. We formulate the linear and non-linear kernel functions to find two non-parallel hyperplanes . One real-world and thirty-two imbalanced datasets are selected to validate the performance of IFTSVM-ID. The Friedman test and the bootstrap technique with 95\% confidence interval are applied to quantify the results statistically. The experimental results show that our proposed method has much better performance in comparison with other similar techniques.},
  archive      = {J_NEUCOM},
  author       = {Salim Rezvani and Xizhao Wang},
  doi          = {10.1016/j.neucom.2022.07.083},
  journal      = {Neurocomputing},
  pages        = {16-25},
  shortjournal = {Neurocomputing},
  title        = {Intuitionistic fuzzy twin support vector machines for imbalanced data},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The reconstitution predictive network for precipitation
nowcasting. <em>NEUCOM</em>, <em>507</em>, 1–15. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precipitation nowcasting is an indispensable task for traffic routing and disaster avoidance. Due to its strenuous movement, even the most recent deep learning techniques in computer vision deliver unsatisfactory performance. The main reason can be attributed to the following two aspects: 1) The traditional convolution in the input has a limited field to extract spatial representation . 2) The convolution in state-to-state connection might lead to mismatch problems and inaccurate strength predictions. To address the two drawbacks, we propose an innovative algorithm the Reconstitute Spatiotemporal LSTM (RST-LSTM) based on Convolutional Recurrent Neural Network (ConvRNN). In the proposed model, we present the local and global reconstitution scheme into the current input and the hidden state respectively. The local reconstitution (LR) can adaptively adjust the perceptual field of convolution so as to extract more useful spatial information and exclude invalid representation. Moreover, in the hidden state, the global reconstitution (GR) is embedded to alleviate the problem of mismatching between the current input and hidden state. Experimental results in MovingMNIST++ show that our approach can achieve the best predictions for those data with more drastic changes in the adjacent time. For radar data in CIKM AnalytiCup 2017 (we name it RadarCIKM in this paper), our method outperforms the state-of-the-art competitors. Furthermore, we notice that GR can promote the nowcasting in the high radar echo region and LR can reduce the error.},
  archive      = {J_NEUCOM},
  author       = {Chuyao Luo and Guangning Xu and Xutao Li and Yunming Ye},
  doi          = {10.1016/j.neucom.2022.07.061},
  journal      = {Neurocomputing},
  pages        = {1-15},
  shortjournal = {Neurocomputing},
  title        = {The reconstitution predictive network for precipitation nowcasting},
  volume       = {507},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain adversarial tangent subspace alignment for
explainable domain adaptation. <em>NEUCOM</em>, <em>506</em>, 418–429.
(<a href="https://doi.org/10.1016/j.neucom.2022.07.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is reaching state of the art in many applications. However, the generalization capabilities of the learned networks are limited to the training or source domain. The predictive power decreases when these models are evaluated in a target domain different from the source domain. Joint adversarial domain adaptation networks are currently the preferred models for source-to-target domain adaptation due to their good empirical performance. These models simultaneously learn a classifier, an invariant representation through an adversarial min–max game, and adapt local structures between domains. For the latter, it is common practice to incorporate pseudo labels that can be, however, unreliable due to false predictions on challenging tasks. This work proposes the Domain Adversarial Tangent Subspace Alignment (DATSA) network, which models data as affine subspaces and adversarially aligns local approximations of manifolds across domains. DATSA addresses the drawbacks of the joint adversarial domain adaptation networks by not requiring pseudo labels for local alignment because it relies on self-supervised learning for subspace alignment. Additionally, DATSA adaptations are explainable to some extent and the results show that they are competitive to other models in terms of accuracy.},
  archive      = {J_NEUCOM},
  author       = {Christoph Raab and Manuel Röder and Frank-Michael Schleif},
  doi          = {10.1016/j.neucom.2022.07.074},
  journal      = {Neurocomputing},
  pages        = {418-429},
  shortjournal = {Neurocomputing},
  title        = {Domain adversarial tangent subspace alignment for explainable domain adaptation},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-flexible video summarization scheme using
property-constraint decision tree. <em>NEUCOM</em>, <em>506</em>,
406–417. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video summarization (VS) technology presents a multi-tendency development. However, there are still certain challenges in shortening a long video into several diverse and concise versions, such as generating various versions and variable lengths of summaries depending on user requirements. In this context, it is critical to extract the spatial–temporal features of video frames. To address these issues, this paper proposes a multi-flexible video summarization scheme using a property-constraint decision. Due to the difficulty of directly transforming user requirements into summary algorithm factors, this paper employs property-constraints as a bridge between user requirements and the video summary algorithm. The specific implementation method is to aggregate and analyze existing research results on summary-oriented properties. It begins with the establishment of a property-constraints library, followed by the translating and mapping of user requirements into VS property-constraints, and ultimately constructing a property-constraints tree for flexible decision versions of VS. In addition, a hybrid cascade bidirectional network (CB-ConvLSTM) based on the Convolutional LSTM Network (ConvLSTM) is designed to extract the spatial–temporal features of the video. On this basis, the VS generator is configured. The goal of this scheme, which combines the VS property constraints and CB-ConvLSTM, is to “analyze once, satisfy multiple factors, generate multiple levels”. Verification experiments and a comparative analysis are conducted on benchmark datasets to evaluate the algorithm in this paper. The results indicate that the proposed algorithm is highly rational, effective, and usable.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyu Teng and Xiaolin Gui and Pan Xu and Yiyang Shao and Jianglei Tong and Tianjiao Du and Huijun Dai},
  doi          = {10.1016/j.neucom.2022.07.077},
  journal      = {Neurocomputing},
  pages        = {406-417},
  shortjournal = {Neurocomputing},
  title        = {A multi-flexible video summarization scheme using property-constraint decision tree},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LiDAR-based detection, tracking, and property estimation: A
contemporary review. <em>NEUCOM</em>, <em>506</em>, 393–405. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection, Person tracking, and Person property estimation (PPE) are identical innovation areas trying to improve their accuracy in different parameters to fit various real applications. For many years, so much research has been done in these fields. Many scientists also used many more techniques and algorithms. But most of the innovations were deeply based on image-based analysis, where cameras were the critical components of data acquisition. Over the years, new technologies arrived, and different types of research are happening. Rather than cameras, some other sensors, like infrared, depth cameras, and very recently LiDAR sensors, are used to estimate person properties, track them, as well as to detect them. Especially, height, age, gender, region, etc., parameters can be measured as person property. Eventually, 3D object detection by LiDAR will be a state-of-the-art research field with the advent of autonomous driving initiations. We studied many articles and found enthusiastic outcomes with these sensor setups to understand contemporary technology and its efficacy. We categorized these research articles into video camera-based studies and other sensor-based studies. So many surveys have been done on video-based analysis, even with deep learning techniques . Another sensor-based research is very recent, and we do not get enough study on it. We thought to summarize these studies in a survey article, especially LiDAR-based analysis. This article covered most of the recent possible sensor-based studies of detection, person tracking and property estimation except cameras (all, RGB, RGB-D, etc.) based learning.},
  archive      = {J_NEUCOM},
  author       = {Mahmudul Hasan and Junichi Hanawa and Riku Goto and Ryota Suzuki and Hisato Fukuda and Yoshinori Kuno and Yoshinori Kobayashi},
  doi          = {10.1016/j.neucom.2022.07.087},
  journal      = {Neurocomputing},
  pages        = {393-405},
  shortjournal = {Neurocomputing},
  title        = {LiDAR-based detection, tracking, and property estimation: A contemporary review},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-level features fusion via cross-layer guided attention
for hyperspectral pansharpening. <em>NEUCOM</em>, <em>506</em>, 380–392.
(<a href="https://doi.org/10.1016/j.neucom.2022.07.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the successful applications of convolutional neural network (CNN) in computer vision have attracted considerable attentions. Particularly, deep learning models with attention mechanisms have shown impressive performance in hyperspectral (HS) pansharpening. However, most of these existing models follow an early/late-fusion strategy and do not take full advantage of the hierarchical features. In this paper, we specifically design a novel end-to-end multi-level feature fusion network with cross-layer guided attention for HS pansharpening, termed as HP-MFFN, which allows the network to extract the hierarchical features level by level. Specifically, as the different levels of the network have different receptive fields and contain different details, the hierarchical features extracted from the HS image and panchromatic (PAN) image are refined by the cross-layer guided attention fusion module (called CLGAF) to yield more effective spatial-spectral features with fine details and rich semantics. The experimental results conducted on widely-used datasets demonstrate that HP-MFFN provides high-quality pansharpened HS images in terms of perceptually and quantitatively.},
  archive      = {J_NEUCOM},
  author       = {Shaoxiong Hou and Song Xiao and Wenqian Dong and Jiahui Qu},
  doi          = {10.1016/j.neucom.2022.07.071},
  journal      = {Neurocomputing},
  pages        = {380-392},
  shortjournal = {Neurocomputing},
  title        = {Multi-level features fusion via cross-layer guided attention for hyperspectral pansharpening},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Semi-global shape-aware attention network for image
segmentation and retrieval. <em>NEUCOM</em>, <em>506</em>, 369–379. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-local operations are usually used to capture long-range dependencies via aggregating global context to each position recently. However, most of the methods cannot preserve object shapes since they only focus on feature similarity but ignore proximity between central and other positions for capturing long-range dependencies, while shape-awareness is beneficial to many computer vision tasks. In this paper, we propose a Semi-Global Shape-aware Network (SGSNet) considering both feature similarity and proximity for preserving object shapes when modeling long-range dependencies. A hierarchical way is taken to aggregate global context. In the first level, each position in the whole feature map only aggregates contextual information in vertical and horizontal directions according to both similarity and proximity. And then the result is input into the second level to do the same operations. By this hierarchical way, each central position gains supports from all other positions, and the combination of similarity and proximity makes each position gain supports mostly from the same semantic object. Moreover, we also propose an efficient algorithm for the aggregation of contextual information, where each of rows and columns in the feature map is treated as a binary tree to reduce similarity computation cost. Experiments on semantic segmentation and image retrieval show that adding SGSNet to existing networks gains solid improvements on both accuracy and efficiency.},
  archive      = {J_NEUCOM},
  author       = {Pengju Zhang and Jiagang Zhu and Chaofan Zhang and Zheng Rong and Yihong Wu},
  doi          = {10.1016/j.neucom.2022.07.069},
  journal      = {Neurocomputing},
  pages        = {369-379},
  shortjournal = {Neurocomputing},
  title        = {Semi-global shape-aware attention network for image segmentation and retrieval},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LDA-GAN: Lightweight domain-attention GAN for unpaired
image-to-image translation. <em>NEUCOM</em>, <em>506</em>, 355–368. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, image-to-image translation has attracted the interest of researchers, which purpose is to learn a mapping between two image domains. However, image translation will become an intrinsically ill-posed problem when given unpaired training data, that is, there are infinite mappings between two domains. Existing methods usually fail to learn a relatively accurate mapping, leading to poor quality of generated results. We believe that if the framework can focus more on the translation of important object regions instead of irrelevant information, such as background, then the difficulty of mapping learning will be reduced. In this paper, we propose a lightweight domain-attention generative adversarial network (LDA-GAN) for unpaired image-to-image translation, which has fewer parameters and lower memory usage. An improved domain-attention module (DAM) is introduced to establish a long-range dependency between two domains. Thus, the generator can focus more on the relevant regions to generate more realistic images. Furthermore, a novel separable-residual block (SRB) is designed to retain depth and spatial information during the translation with a lower computational cost. Extensive experiments show the effectiveness of our model on various image translation tasks according to qualitative and quantitative evaluation.},
  archive      = {J_NEUCOM},
  author       = {Jin Zhao and Feifei Lee and Chunyan Hu and Hongliu Yu and Qiu Chen},
  doi          = {10.1016/j.neucom.2022.07.084},
  journal      = {Neurocomputing},
  pages        = {355-368},
  shortjournal = {Neurocomputing},
  title        = {LDA-GAN: Lightweight domain-attention GAN for unpaired image-to-image translation},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Iterative BTreeNet: Unsupervised learning for large and
dense 3D point cloud registration. <em>NEUCOM</em>, <em>506</em>,
336–354. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D point cloud registration is a computational process that aligns two 3D point clouds through transformation. i.e. finding matching translation and rotation. Existing state-of-the-art learning-based methods require ground-truth transformation as supervision and often perform poorly in dealing with partial point clouds and large scenes that are not trained, resulting in poor generalization for neural networks. In this paper, we propose a novel unsupervised deep learning network - Binary Tree Network (BTreeNet) that consists of a novel forward propagation , which learns features for the rotation separately from the translation and avoids the interference between the estimations of rotation and translation in one single matrix. We then propose an Iterative Binary Tree Network (IBTreeNet) to continuously improve the registration accuracy for large and dense 3D point clouds. The Chamfer Distance and the Earth Mover’s Distance are adopted as the loss function for unsupervised learning . We show that BTreeNet and IBTreeNet outperform state-of-the-art learning-based and traditional methods on partial and noisy point clouds without training them in such scenarios. Most importantly, the proposed methods exhibit remarkable generalization and robustness to unseen large and dense scenes that are never trained.},
  archive      = {J_NEUCOM},
  author       = {Long Xi and Wen Tang and Tao Xue and TaoRuan Wan},
  doi          = {10.1016/j.neucom.2022.07.082},
  journal      = {Neurocomputing},
  pages        = {336-354},
  shortjournal = {Neurocomputing},
  title        = {Iterative BTreeNet: Unsupervised learning for large and dense 3D point cloud registration},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review on the use of deep learning for medical images
segmentation. <em>NEUCOM</em>, <em>506</em>, 311–335. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) algorithms have rapidly become a robust tool for analyzing medical images. They have been used extensively for medical image segmentation as the first and significant components of the diagnosis and treatment pipeline. Medical image segmentation is efficiently addressed by many types of deep neural networks, such as convolutional neural networks, fully convolutional network recurrent networks, adversarial networks, and U-shaped networks. This paper reviews the major DL models and applications pertinent to medical image segmentation and summarizes over 150 contributions to the field. Brief overviews of articles are provided by application area: anatomical structures such as organs, bones, and vessels, and abnormalities such as lesions and calcification. Moreover, we discuss current challenges and suggest directions for future research.},
  archive      = {J_NEUCOM},
  author       = {Manar Aljabri and Manal AlGhamdi},
  doi          = {10.1016/j.neucom.2022.07.070},
  journal      = {Neurocomputing},
  pages        = {311-335},
  shortjournal = {Neurocomputing},
  title        = {A review on the use of deep learning for medical images segmentation},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Road extraction from satellite images with iterative
cross-task feature enhancement. <em>NEUCOM</em>, <em>506</em>, 300–310.
(<a href="https://doi.org/10.1016/j.neucom.2022.07.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent study has shown that road orientation information is highly beneficial to the road extraction task. However, most existing approaches that integrate road extraction with orientation prediction in a naïve multi-task learning framework fail to explore their correlations, leading to unsatisfactory results with severe road discontinuity issues. In order to take full advantages of road orientation information to facilitate accurate road extraction, we propose an iterative cross-task feature enhancement network, which jointly optimizes the deep features for both road extraction and orientation prediction tasks in a mutually beneficial manner. To this end, we present two unique designs, namely, the semantic guided feature enhancement (SGFE) module and the orientation-aware feature aggregation (OAFA) module. The SGFE module is used to refine orientation prediction features by incorporating the semantic information of road extraction feature. Meanwhile, the OAFA module is able to enhance road extraction feature by adaptively deforming its receptive field according to the predicted road orientations. Our proposed network recursively alternates between these modules, permitting the extracted features to be collaboratively improved through cross-task information flow. We set new state of the art on two widely adopted benchmarks (67.00 road IoU on DeepGlobe [5] and 80.06 mIoU on Massachusetts [18] ), which verifies the superiority of our method. 1},
  archive      = {J_NEUCOM},
  author       = {Weiling Yin and Mingyang Qian and Lijun Wang and Jinqing Qi and Huchuan Lu},
  doi          = {10.1016/j.neucom.2022.07.086},
  journal      = {Neurocomputing},
  pages        = {300-310},
  shortjournal = {Neurocomputing},
  title        = {Road extraction from satellite images with iterative cross-task feature enhancement},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time panoptic segmentation with relationship between
adjacent pixels and boundary prediction. <em>NEUCOM</em>, <em>506</em>,
290–299. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Panoptic segmentation has recently received increasing attention since it generates coherent scene segmentation by unifying semantic and instance segmentation . The most popular methods for panoptic segmentation are currently based on an instance segmentation framework with a semantic segmentation branch in parallel. However, these methods are too bloated for real-world applications. In this paper, we propose a simple yet effective fully convolutional network for fast panoptic segmentation. Instead of directly generating the mask for each instance, we leverage a simple graph convolutional layer to construct a pixel relationship head to predict the relationship between two adjacent pixels and determine whether they belong to the same instance. Besides, we leverage boundary information to enhance supervision information and help our method distinguish adjacent objects. Combining predicted category labels for each pixel from the semantic segmentation branch, we can generate a unified panoptic segmentation mask in a parameter-free step. We demonstrate our method’s effectiveness on MS COCO dataset and Cityscapes dataset, which obtain competitive results.},
  archive      = {J_NEUCOM},
  author       = {Xiaoliang Zhang and Hongliang Li and Lanxiao Wang and Haoyang Cheng and Heqian Qiu and Wenzhe Hu and Fanman Meng and Qingbo Wu},
  doi          = {10.1016/j.neucom.2022.07.078},
  journal      = {Neurocomputing},
  pages        = {290-299},
  shortjournal = {Neurocomputing},
  title        = {Real-time panoptic segmentation with relationship between adjacent pixels and boundary prediction},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Entropy-weighted reconstruction adversary and curriculum
pseudo labeling for domain adaptation in semantic segmentation.
<em>NEUCOM</em>, <em>506</em>, 277–289. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised learning has dominated and gradually evolved into a de facto choice for automated semantic segmentation tasks, in spite of the need for large corpora of pixel-level annotated real-world data. Domain adaptation (DA), especially methods based on adversarial machine learning , can lessen labeling costs by securing that knowledge learned from synthetic (source) data with free annotations is transferable to unlabeled real-world data. However, commonly employed approaches in adversarial-based DA merely consider the correlation alignment between the source and target domains while completely neglecting the uncertainty information introduced from the generator. In this paper, we aim to alleviate this issue by introducing a novel entropy-guided adversarial learning framework with the reconstruction error constraint. Firstly, a perceptual-based color space is employed to transform the synthetic source images into the desired new space to approximate the appearances of the real-world images in the target domain. Secondly, an entropy-weighted adversarial framework is designed to enhance the discriminativeness and transferability of the presented model to the target domain via an autoencoder-based discriminator . In addition, a dynamic pseudo-labeling mechanism is introduced to work in conjunction with the curriculum-based self-training strategy to further improve the domain adaptability of the model. Experimental results on two well-known DA benchmarks demonstrate that the proposed method outperforms existing similar approaches in the task of semantic segmentation .},
  archive      = {J_NEUCOM},
  author       = {Xiwen Bi and Xiaohong Zhang and Shidong Wang and Haofeng Zhang},
  doi          = {10.1016/j.neucom.2022.07.073},
  journal      = {Neurocomputing},
  pages        = {277-289},
  shortjournal = {Neurocomputing},
  title        = {Entropy-weighted reconstruction adversary and curriculum pseudo labeling for domain adaptation in semantic segmentation},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attribute assisted teacher-critical training strategies for
image captioning. <em>NEUCOM</em>, <em>506</em>, 265–276. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing image captioning models are usually trained by cross-entropy (XE) loss and reinforcement learning (RL), which set ground-truth words as hard targets and force the captioning model to learn from them. However, the widely adopted training strategies may suffer from misalignment in XE training and inappropriate reward assignment in RL training. To tackle these problems, we introduce an attribute enhanced teacher model that serves as a bridge between the ground-truth captions and the captioning model by generating some easier-to-learn word proposals as soft targets. Currently, most knowledge distillation methods build the teacher model by introducing more model parameters as well as additional training data. In our proposal, we alternatively construct the teacher model by utilizing the ground-truth image attributes which already exist in the ground-truth captions and can be very easily extracted. To effectively learn from the teacher model, we further propose Teacher-Critical Training Strategies (TCTS) for both XE and RL training to facilitate more efficient learning of the captioning model. Experimental evaluations of several widely adopted captioning model architectures on the benchmark MSCOCO dataset show the proposed TCTS comprehensively outperforms these baselines in both subjective metrics and human evaluations. Our codes and pre-trained models will be open-sourced.},
  archive      = {J_NEUCOM},
  author       = {Yiqing Huang and Jiansheng Chen and Huimin Ma and Hongbing Ma and Wanli Ouyang and Cheng Yu},
  doi          = {10.1016/j.neucom.2022.07.068},
  journal      = {Neurocomputing},
  pages        = {265-276},
  shortjournal = {Neurocomputing},
  title        = {Attribute assisted teacher-critical training strategies for image captioning},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leader-following output consensus of t-s fuzzy switched
multi-agent systems under bumpless transfer control and event-triggered
communication. <em>NEUCOM</em>, <em>506</em>, 252–264. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the leader-following output consensus problem of a class of nonlinear switched multi-agent systems described by the T-S fuzzy models. A sufficient condition on the leader-following output consensus and the bumpless transfer performance is developed via co-design of the observer-based bumpless transfer fuzzy controllers and the agent-dependent switching law, which the local stabilizability of all the fuzzy subsystems of each agent is not required. By using the distributed dynamic event-triggered rule, the fuzzy estimator for each agent is constructed to estimate the state of leader. Besides, Zeno behaviour is ruled out via discussing the existence of the lower bound on inter-event intervals. Finally, two examples are given to validate the effectiveness of our results.},
  archive      = {J_NEUCOM},
  author       = {Guangxu He and Jun Zhao},
  doi          = {10.1016/j.neucom.2022.07.064},
  journal      = {Neurocomputing},
  pages        = {252-264},
  shortjournal = {Neurocomputing},
  title        = {Leader-following output consensus of T-S fuzzy switched multi-agent systems under bumpless transfer control and event-triggered communication},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Moving objects segmentation using generative adversarial
modeling. <em>NEUCOM</em>, <em>506</em>, 240–251. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moving Objects Segmentation (MOS) is a crucial step in various computer vision applications , such as visual object tracking, autonomous vehicles, human activity analysis, surveillance, and security. Existing MOS approaches suffer from performance degradation due to extreme challenging conditions in real world complex environments such as varying illumination conditions , camouflage objects, dynamic backgrounds, shadows, bad weathers and camera jitters. To address these problems we proposed a novel generative adversarial based framework for moving objects segmentation. Our framework works with one classifier discriminator , one representation learning network and one generator jointly trained to perform MOS in various challenging scenarios. During training the discriminator network acts as a decision maker between real and fake training samples using conditional least squares loss. While the representation learning network provides the difference between the deep features of real and fake training samples using content loss formulation. Another loss term we have exploited to train our generator network is the reconstruction loss that minimizes the difference between the spatial information of real and fake training samples. Moreover, we also propose a novel modified U-net architecture for our generator network showing improved performance over Vanilla U-net model. Experimental evaluations of our proposed method on four benchmark datasets in comparison with thirty-two existing methods has demonstrated the strength of our proposed model.},
  archive      = {J_NEUCOM},
  author       = {Maryam Sultana and Arif Mahmood and Thierry Bouwmans and Muhammad Haris Khan and Soon Ki Jung},
  doi          = {10.1016/j.neucom.2022.07.081},
  journal      = {Neurocomputing},
  pages        = {240-251},
  shortjournal = {Neurocomputing},
  title        = {Moving objects segmentation using generative adversarial modeling},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural network-based safe optimal robust control for affine
nonlinear systems with unmatched disturbances. <em>NEUCOM</em>,
<em>506</em>, 228–239. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, for the safety–critical systems with unmatched disturbances, a safe optimal robust control method based on neural network is proposed to ensure that the safety–critical system operates within its safe region and learns the optimal control strategy. The cost function which is the goal of the designers is augmented by a control barrier function (CBF) to achieve both safety and optimality. This method does not directly regard security as a constraint on the system state, but influences the cost function through a security penalty mechanism. An additional function is used to approximate the effect of the unmatched disturbances on the safety–critical systems. On the premise of satisfying the security and robustness, the neural network approximation method is used to learn the optimal control strategy. Based on Lyapunov stability theory , it is shown that the neural network-based safe optimal robust controller can guarantee all the signals of the resulting closed-loop systems to be uniformly ultimately bounded. Finally, two simulation examples are given to demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Chunbin Qin and Jinguang Wang and Heyang Zhu and Jishi Zhang and Shaolin Hu and Dehua Zhang},
  doi          = {10.1016/j.neucom.2022.07.072},
  journal      = {Neurocomputing},
  pages        = {228-239},
  shortjournal = {Neurocomputing},
  title        = {Neural network-based safe optimal robust control for affine nonlinear systems with unmatched disturbances},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel convolutional neural network with multiscale cascade
midpoint residual for fault diagnosis of rolling bearings.
<em>NEUCOM</em>, <em>506</em>, 213–227. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Network (CNN) has been widely used in mechanical fault diagnosis system, and has achieved satisfactory results. However, some limitations of the number of network layers and a single fixed convolution kernel are also exposed during performing the task of fault classification. To solve these problems, this paper proposes a multiscale cascade midpoint residual convolutional neural network (MSC-MpResCNN). Firstly, a new multiscale cascade structure is introduced to extract multi-resolution features contained in the original data. Secondly, the improved midpoint residual block is adopted in each branch of multiscale cascade structure to address deep network performance degradation. In addition, exponential linear unit (ELU) replaces the original linear rectification function, which makes the noise resistance of the model stronger and increasesthe robustness and generalization. L2 weight regularization and global average pooling (GAP) are applied to the model to avoid overfitting. The feasibility of the proposed method is validated by the experiments. The results indicates that the method can obtain higher fault recognition rate compared with previous methods by multiscale cascade midpoint residual block. Furthermore, the method has great anti-noise robustness under strong noise environment.},
  archive      = {J_NEUCOM},
  author       = {Zhiqiang Chao and Tian Han},
  doi          = {10.1016/j.neucom.2022.07.022},
  journal      = {Neurocomputing},
  pages        = {213-227},
  shortjournal = {Neurocomputing},
  title        = {A novel convolutional neural network with multiscale cascade midpoint residual for fault diagnosis of rolling bearings},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NPDS toolbox: Neural population (de) synchronization toolbox
for MATLAB. <em>NEUCOM</em>, <em>506</em>, 206–212. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of synchronous or asynchronous in (stochastic) neuronal populations is an important concept both in theory and in practice in neuroscience. The NPDS toolbox provides an interactive simulation platform for exploring such processes in MATLAB, looking through the lens of nonlinear dynamical systems. NPDS includes two main components: neural population (de) synchronization, and neural dynamics. One can investigate distribution controls on various neural models such as HH, FHN, RH, and Thalamic. Also, it supports many numerical approaches for simulation: finite-difference, pseudo-spectral, radial basis function, and Fourier methods. In addition, this toolbox can be used for population phase shifting and clustering.},
  archive      = {J_NEUCOM},
  author       = {Mohammad Mahdi Moayeri and Mohammad Hemami and Jamal Amani Rad and Kourosh Parand},
  doi          = {10.1016/j.neucom.2022.07.060},
  journal      = {Neurocomputing},
  pages        = {206-212},
  shortjournal = {Neurocomputing},
  title        = {NPDS toolbox: Neural population (De) synchronization toolbox for MATLAB},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Input reduction of convolutional neural networks with global
sensitivity analysis as a data-centric approach. <em>NEUCOM</em>,
<em>506</em>, 196–205. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pruning methods are used for dealing with the rapid growth of neural network parameters as the neural network develops. These enable a reduction in not only the size of the network, but also the bandwidth it utilizes. In this article, global sensitivity analysis methods, like Sobol and eFAST, are applied to determine the least significant inputs. Data-centric Artificial Intelligence is a fledgeling science and is gathering more and more attention among top researchers. This methodology is focused on data manipulation and constant model architecture, while the model-centric approach modifies models. This article cuts off itself from typical model-centric pruning methods and is focused solely on data pruning. In the work, principal component analysis is applied as a benchmark for the proposed Global Sensitivity methods. This work is focused on convolutional neural networks. It shows how the accuracy of CNNs is impacted by input reduction – doing so through the example of three image datasets and three series datasets.},
  archive      = {J_NEUCOM},
  author       = {Ernest Jeczmionek and Piotr A. Kowalski},
  doi          = {10.1016/j.neucom.2022.07.027},
  journal      = {Neurocomputing},
  pages        = {196-205},
  shortjournal = {Neurocomputing},
  title        = {Input reduction of convolutional neural networks with global sensitivity analysis as a data-centric approach},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Friend-guard adversarial noise designed for
electroencephalogram-based brain–computer interface spellers.
<em>NEUCOM</em>, <em>506</em>, 184–195. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An electroencephalogram (EEG)–based brain–computer interface (BCI) speller is a system that conveys thought to enable communication between humans and computers using brain conduction. This system is useful for patients with severe disabilities and provides a way for them to communicate with computers or with other people. The EEG-based BCI speller system is being studied in various ways, but it is vulnerable to adversarial examples . An adversarial example is an attack sample created by adding a little noise to an original sample in such a way that it appears normal to humans but will be misclassified by the model. Adversarial examples can be useful in situations such as military scenarios in which there is a mixture of friendly models and enemy models. When a friendly BCI speller and an enemy BCI speller coexist, an adversarial example may be mistakenly taken by the enemy BCI speller to signal an incorrect intention on the part of the person with a disability; in another scenario, an enemy BCI speller may leak personal information of the individual with a disability or initiate unwanted financial transactions. In this paper, we propose a method to create such a sample, called a “friend-guard” EEG adversarial example. In the proposed method, a very small EEG signal is added to an original sample, creating an adversarial example that the friendly model will classify correctly but the enemy model will classify incorrectly. A P300 dataset was used in the experimental evaluation of the method, and linear regression models were used as target models. In the experiment, the proposed method was able to generate friend-guard EEG adversarial examples that were incorrectly classified with success rates of 88.4\% and 69.7\% by the enemy model for subject A and subject B, respectively, while maintaining the accuracy of the friendly model at 85.9\% and 74.4\% for subjects A and B, respectively.},
  archive      = {J_NEUCOM},
  author       = {Hyun Kwon and Sanghyun Lee},
  doi          = {10.1016/j.neucom.2022.06.089},
  journal      = {Neurocomputing},
  pages        = {184-195},
  shortjournal = {Neurocomputing},
  title        = {Friend-guard adversarial noise designed for electroencephalogram-based brain–computer interface spellers},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-modal distillation with audio–text fusion for
fine-grained emotion classification using BERT and wav2vec 2.0.
<em>NEUCOM</em>, <em>506</em>, 168–183. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained emotion classification for mood- and emotion-related physical-characteristics detection and its application to computer technology using biometric sensors has been extensively researched in the field of affective computing . Although text modality has achieved a considerably high performance from the perspective of sentiment analysis , which simply classifies a positive or negative label, fine-grained emotion classification requires additional information besides text. An audio feature can be adopted as the additional information as it is closely associated with text, and the characteristics of the changes in sound pulses can be employed in fine-grained emotion classification. However, the multimodal datasets related to fine-grained emotion are limited, and the scalability and efficiency are insufficient for multimodal training to be applied extensively via the self-supervised learning (Self-SL) approach, which can adequately represent modality. To address these limitations, we propose cross-modal distillation (CMD), which induces the feature spaces of student models with a few parameters while receiving those of the teacher models that can adequately express each modality based on Self-SL. The proposed CMD performs the mapping of a feature space between teacher-student models based on contrastive learning , while two attention mechanisms—cross-attention between audio and text features and self-attention for features in modality—are performed during knowledge distillation . Wav2vec 2.0 and BERT , which are already adequately trained for audio and text via Self-SL, were adopted as teacher models; audio–text transformer models were used as student models. Accordingly, the CMD-based representation learning applies a lightweight model for IEMOCAP , MELD , and CMU–MOSEI datasets with the task of multi-class emotion classification, while exhibiting better fine-grained emotion classification performance than benchmark models with a considerably low uncertainty for prediction.},
  archive      = {J_NEUCOM},
  author       = {Donghwa Kim and Pilsung Kang},
  doi          = {10.1016/j.neucom.2022.07.035},
  journal      = {Neurocomputing},
  pages        = {168-183},
  shortjournal = {Neurocomputing},
  title        = {Cross-modal distillation with audio–text fusion for fine-grained emotion classification using BERT and wav2vec 2.0},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Polarized self-attention: Towards high-quality pixel-wise
mapping. <em>NEUCOM</em>, <em>506</em>, 158–167. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the pixel-wise mapping problem that commonly exists in the fine-grained computer vision tasks , such as estimating keypoint heatmaps and segmentation masks. These tasks require, at low computation overheads, modeling the long-range dependencies among high-resolution inputs and estimating the highly nonlinear pixel-wise outputs. While the attention mechanism added to Deep Convolutional Neural Networks (DCNNs) can boost long-range dependencies, the element-specific attention, such as the Nonlocal block, is highly complex and noise-sensitive to learn, and most of the simplified attention blocks are designed for image-wise classification purposes and simply applied to pixel-wise tasks. In this paper, we present the Polarized Self-Attention (PSA) block targeting the high-quality pixel-wise mapping with: (1) Polarized filtering: keeping high internal resolution in both channel and spatial attention computation while completely collapsing input tensors along their counterpart dimensions. (2) Enhancement: composing non-linearity that directly fits the output distribution of typical pixel-wise mappings, such as the 2D Gaussian distribution (keypoint heatmaps), or the 2D Binormial distribution (binary segmentation masks). Experimental results show that PSA boosts standard baselines by 2–4 points, and boosts state-of-the-arts by 1–2 points on 2D pose estimation and semantic segmentation benchmarks. Codes are available at ( https://github.com/DeLightCMU/PSA ).},
  archive      = {J_NEUCOM},
  author       = {Huajun Liu and Fuqiang Liu and Xinyi Fan and Dong Huang},
  doi          = {10.1016/j.neucom.2022.07.054},
  journal      = {Neurocomputing},
  pages        = {158-167},
  shortjournal = {Neurocomputing},
  title        = {Polarized self-attention: Towards high-quality pixel-wise mapping},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Focal and efficient IOU loss for accurate bounding box
regression. <em>NEUCOM</em>, <em>506</em>, 146–157. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In object detection, bounding box regression (BBR) is a crucial step that determines the object localization performance. However, we find that most previous loss functions for BBR have two main drawbacks: (i) Both ℓ n ℓn -norm and IOU-based loss functions are inefficient to depict the objective of BBR, which leads to slow convergence and inaccurate regression results. (ii) Most of the loss functions ignore the imbalance problem in BBR that the large number of anchor boxes which have small overlaps with the target boxes contribute most to the optimization of BBR. To mitigate the adverse effects caused thereby, we perform thorough studies to exploit the potential of BBR losses in this paper. Firstly, an Efficient Intersection over Union (EIOU) loss is proposed, which explicitly measures the discrepancies of three geometric factors in BBR, i.e., the overlap area, the central point and the side length. After that, we state the Effective Example Mining (EEM) problem and propose a regression version of focal loss to make the regression process focus on high-quality anchor boxes. Finally, the above two parts are combined to obtain a new loss function, namely Focal-EIOU loss. Extensive experiments on both synthetic and real datasets are performed. Notable superiorities on both the convergence speed and the localization accuracy can be achieved over other BBR losses.},
  archive      = {J_NEUCOM},
  author       = {Yi-Fan Zhang and Weiqiang Ren and Zhang Zhang and Zhen Jia and Liang Wang and Tieniu Tan},
  doi          = {10.1016/j.neucom.2022.07.042},
  journal      = {Neurocomputing},
  pages        = {146-157},
  shortjournal = {Neurocomputing},
  title        = {Focal and efficient IOU loss for accurate bounding box regression},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variational learning of deep fuzzy theoretic nonparametric
model. <em>NEUCOM</em>, <em>506</em>, 128–145. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonparametric approaches are a good choice for function approximation as they are flexible, robust to overfitting, and provide well calibrated predictive uncertainty. The nonparametric form of fuzzy modeling can be promising, however, not analytically studied to compete with the Gaussian processes-based Bayesian framework in statistics and machine learning . In this work, a fuzzy modeling framework is built for data analysis of both supervised and unsupervised learning task, as a deterministic fuzzy analogous against the probabilistic Gaussian process, which defines a fuzzy membership over possible membership functions and is updated in light of data via the rules of variational inference. A fast variational inference framework has been suggested to study the propagation of the uncertainty through the layers of the deep model which can jointly infers the inducing inputs and the hyperparameters. The maximization problem is analytically solved using variational optimization with derived lower bound. We provide the sufficient number of experiments to support our argument that the proposed approach works well in practice for the problem which has the requirements to update the model dynamically. In addition, the application potential of the proposed methodology in data representation learning is also investigated, the “auxiliary inducing points” are used to express general features of tasks with smaller datasets. Nevertheless, this study offers new contents to the theory of nonparametric model and presents the potential for the design of practical fuzzy machine learning method.},
  archive      = {J_NEUCOM},
  author       = {Weiping Zhang and Mohit Kumar and Weiping Ding and Xiujuan Li and Junfeng Yu},
  doi          = {10.1016/j.neucom.2022.07.029},
  journal      = {Neurocomputing},
  pages        = {128-145},
  shortjournal = {Neurocomputing},
  title        = {Variational learning of deep fuzzy theoretic nonparametric model},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Object re-identification with distribution corrected ranking
list. <em>NEUCOM</em>, <em>506</em>, 117–127. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object re-identification is a retrieval task to identify the same identity, usually utilizing the ranking list to sort the features. However, most existing ranking lists only calculate the distance from the probe sample to its k -nearest neighbor samples in the gallery set but ignore the distribution of the gallery set. Meanwhile, we find that the gallery set tends to converge into different groups. When the probe lies near the boundary, its k -nearest neighbors often contain samples of different identities from the probe sample. This paper presents a Distribution Corrected Ranking List (DCRL) to correct the ranking by considering the distance between the probe sample and its nearest distribution (i.e., the cluster center). Specifically, given a probe sample, first, we cluster the gallery samples with the agglomerative hierarchical clustering method to obtain the cluster centers. Second, we compute the distance between the probe and the cluster centers. Third, the final ranking list is considered as the weighted combination of the original ranking list (i.e., the distance between the probe sample and its k -nearest neighbor in the gallery) and the distribution ranking list (i.e., the distance between the probe sample and its nearest cluster center). The proposed distribution corrected ranking list is suitable for large datasets because it does not require human intervention or labeled data. Experimental results on several benchmark re-identification datasets, such as Market-1501, DukeMTMC-reID, MSMT17, VeRi-776, and VeRi-Wild, show that the proposed method achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Dongchen Han and Shuai Shao and Weifeng Liu and Bao-Di Liu},
  doi          = {10.1016/j.neucom.2022.07.062},
  journal      = {Neurocomputing},
  pages        = {117-127},
  shortjournal = {Neurocomputing},
  title        = {Object re-identification with distribution corrected ranking list},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review on anchor assignment and sampling heuristics in
deep learning-based object detection. <em>NEUCOM</em>, <em>506</em>,
96–116. (<a href="https://doi.org/10.1016/j.neucom.2022.07.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based object detection is a fundamental but challenging problem in computer vision field, has attracted a lot of study in recent years. State-of-the-art object detection methods rely on the selection of positive samples and negative samples, i.e., called sample assignment, and the definition of a useful set for training, i.e., called sample sampling heuristics. This paper presents a comprehensive review of the advanced anchor assignment and sampling approaches in deep learning-based object detection. Each problem is classified and analyzed systematically. According to the problem-based taxonomy, we identify the advantages and disadvantages of each problem in-depth and present open issues regarding the current methods. Furthermore, this paper also reviews the new trends in solving object detection that has not been discussed during the last two years. To track the latest research, a webpage related to the above problems is provided, which is available at https://github.com/VoXuanThuy/ObjectDetectionReview .},
  archive      = {J_NEUCOM},
  author       = {Xuan-Thuy Vo and Kang-Hyun Jo},
  doi          = {10.1016/j.neucom.2022.07.003},
  journal      = {Neurocomputing},
  pages        = {96-116},
  shortjournal = {Neurocomputing},
  title        = {A review on anchor assignment and sampling heuristics in deep learning-based object detection},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GraMMy: Graph representation learning based on micro–macro
analysis. <em>NEUCOM</em>, <em>506</em>, 84–95. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) are robust variants of deep network models, typically designed to learn from graph-structured data. Despite the recent advancement of GNNs, the basic message passing scheme of learning often holds back these models in effectively capturing the influence of the nodes from higher order neighbourhood. Further, the state-of-the-art approaches mostly ignore the contextual significance of the paths through which the message/information propagates to a node. In order to deal with these two issues, we propose GraMMY as a novel framework for hierarchical semantics-driven gra ph representation learning based on M icro- M acro anal y sis. The key idea here is to study the graph structure from different levels of abstraction, which not only provides an opportunity for flexible flow of information from both local and higher-order neighbours but also helps in more concretely capturing how information travels within various hierarchical structures of the graph. We incorporate the knowledge gained from micro and macro level semantics into the embedding of a node and use this to perform graph classification. Experimentations on four bio-informatics and two social datasets exhibit the superiority of GraMMy over state-of-the-art GNN-based graph classifiers.},
  archive      = {J_NEUCOM},
  author       = {Sucheta Dawn and Monidipa Das and Sanghamitra Bandyopadhyay},
  doi          = {10.1016/j.neucom.2022.07.013},
  journal      = {Neurocomputing},
  pages        = {84-95},
  shortjournal = {Neurocomputing},
  title        = {GraMMy: Graph representation learning based on micro–macro analysis},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A full-function memristive pavlov associative memory circuit
with inter-stimulus interval effect. <em>NEUCOM</em>, <em>506</em>,
68–83. (<a href="https://doi.org/10.1016/j.neucom.2022.07.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time interval between stimuli plays a critical role in Pavlov classical conditioning. In this paper, a full-functional memristive Pavlov associative memory circuit with inter-stimulus interval effect is proposed. Compared with previous works, the proposed circuit extends the Pavlov associative memory with time interval to three complex situations of conditioning and realizes bionic associative memory learning curves called inter-stimulus interval effect. On this basis, the phenomena related to time interval in classical conditioning, blocking and facilitation, are implemented. PSPICE is used to simulate the whole circuit, and the simulation results demonstrate above functions. Furthermore, an application on classification is extended on the basis of the proposed circuit. The application circuit is also verified by the simulation results in PSPICE. This paper provides a reference to associative memory based on memristor in complex time situations.},
  archive      = {J_NEUCOM},
  author       = {Chenyang Sun and Chunhua Wang and Cong Xu},
  doi          = {10.1016/j.neucom.2022.07.044},
  journal      = {Neurocomputing},
  pages        = {68-83},
  shortjournal = {Neurocomputing},
  title        = {A full-function memristive pavlov associative memory circuit with inter-stimulus interval effect},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GCNet: Grid-like context-aware network for RGB-thermal
semantic segmentation. <em>NEUCOM</em>, <em>506</em>, 60–67. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation methods can achieve satisfactory performance under poor lighting conditions by exploiting the complementary cues in RGB and thermal images . However, most methods employ straightforward fusion strategies, which may insufficiently explore complementary information and ignore cross-level information propagation, except spatial information. Further, high-level contextual information may be inadequately enhanced owing to the use of simple perceptive modules. To address these limitations, we introduce a grid-like context-aware network (GCNet) for the semantic segmentation of RGB-thermal images. We use a hybrid fusion module to integrate the complementary information across modalities while considering the propagation of fusion cues by incorporating previously fused features. Considering the significance of contextual cues in semantic segmentation, a grid-like context-aware module is designed to capture rich contextual information. A three-branch discriminator is constructed to evaluate the generated prediction maps and improve the performances of the parsing results. Experiments were performed on two RGB-thermal datasets, and the results show that the proposed network achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Jinfu Liu and Wujie Zhou and Yueli Cui and Lu Yu and Ting Luo},
  doi          = {10.1016/j.neucom.2022.07.041},
  journal      = {Neurocomputing},
  pages        = {60-67},
  shortjournal = {Neurocomputing},
  title        = {GCNet: Grid-like context-aware network for RGB-thermal semantic segmentation},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A commonality-based enhancement for sentence modeling with
supervision. <em>NEUCOM</em>, <em>506</em>, 50–59. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentence pair modeling is a fundamental yet challenging issue for feature mining in natural language processing (NLP) tasks. Recently, most works have generated feature and sentence representation based on the interactive attention mechanism . However, these models have two limitations: (1) they only consider global information through attention coefficient weighting , which makes insufficient utilization of critical features; (2) they only conduct internal training by fine-tuning network parameters, in which attention results are poorly explained. In this paper, inspired by human reasoning, we propose a Commonality Aggregated approach (CA) to enhance the lightweight interaction model by considering phrase features and contextual words. Specifically, we first fuse positional encoding and employ supervised training to extract critical phrase information from the text as the commonality of sentence pairs. Then, we deploy transfer learning and utilize interaction network to combine crucial phrase features, core word features, and positional encoding to enhance sentence pair modeling. Compared with the original network, extensive experiments on multiple benchmark datasets demonstrate the effectiveness of the proposed commonality aggregated method with stronger competitiveness. Further visual analysisanalysies validated the more explicit interpretability of attention, and extended experimental results indicate the excellent generalization of our approach.},
  archive      = {J_NEUCOM},
  author       = {Zhe Chen and Cheng Liu and Jiansi Ren},
  doi          = {10.1016/j.neucom.2022.07.063},
  journal      = {Neurocomputing},
  pages        = {50-59},
  shortjournal = {Neurocomputing},
  title        = {A commonality-based enhancement for sentence modeling with supervision},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ELEKTRA: ELEKTRokardiomatrix application to biometric
identification with convolutional neural networks. <em>NEUCOM</em>,
<em>506</em>, 37–49. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric systems are an uprising technique of identification in today’s world. Many different systems have been used in everyone’s daily life in the past years, such as fingerprint, face scan, and others. We propose a new identification method using Elektrokardiogramms (EKGs) converted into a heatmap of a set of aligned R-peaks (heartbeats), forming a matrix called an Elektrokardiomatrix (EKM). We can build a one-against-many identification system using a Convolutional Neural Network (CNN). We have tested our proposal with one main database (the Normal Sinus Rhythm Database (NSRDB)) and two other databases, which are the MIT-BIH Arrhythmia Database (MIT-BIHDB) and the Physikalisch-Technische Bundesanstalt (PTB) Database. With the NSRDB, we have achieved an accuracy of 99.53\% and offered a False Acceptance Rate (FAR) of 0.02\% and a False Rejection Rate (FRR) of 0.05\%. Very similar results were also obtained with the MIT-BIH and PTB databases. We have performed in-depth experimentation to test the efficiency and feasibility of our novel biometric solution. It is remarkable that with a simple CNN, which has only one convolutional layer , a max-pooling operation, and some regularisation , we can identify users with very high performance and low error rates. Consequently, our model does not need very complex architectures to offer high-performance metrics.},
  archive      = {J_NEUCOM},
  author       = {Caterina Fuster-Barceló and Pedro Peris-Lopez and Carmen Camara},
  doi          = {10.1016/j.neucom.2022.07.059},
  journal      = {Neurocomputing},
  pages        = {37-49},
  shortjournal = {Neurocomputing},
  title        = {ELEKTRA: ELEKTRokardiomatrix application to biometric identification with convolutional neural networks},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Scalable NAS with factorizable architectural parameters.
<em>NEUCOM</em>, <em>506</em>, 25–36. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Architecture Search (NAS) replaces manually designed networks with automatically searched networks and has become a hot topic in machine learning and computer vision. One key factor of NAS, scaling up the search space by adding operators, could help bring about more possibilities for effective architectures. However, existing works require high search costs and are prone to make confused selections caused by competition among similar operators. This paper presents a scalable NAS that utilizes a factorized method, which improves existing art in the following aspects. (1) Our work explores a broader search space. We construct an ample search space through the cartesian product of activation operators and regular operators. (2) Our work experiences a limited computation burden even though searching in a more extensive search space. We factorize a search space into two subspaces and adopt different architectural parameters to control corresponding subspaces. (3) Our work avoids competition among similarly combined operators ( e.g. , ReLU &amp; sep-conv-3x3 and ReLU6 &amp; sep-conv-3x3 and PReLU &amp; sep-conv-3x3 ). That is because our architectural parameters are optimized sequentially. Experimental results show that our approach achieves SOTA on CIFAR10 ( 2 . 38\% 2.38\% test error) and ImageNet ( 23 . 8\% 23.8\% test error). Furthermore, the excellent performance of 35 . 8\% 35.8\% ( AP ) and 55 . 7\% 55.7\% ( AP 50 AP50 ) on COCO further proves the superiority of our factorized method.},
  archive      = {J_NEUCOM},
  author       = {Lanfei Wang and Lingxi Xie and Kaili Zhao and Jun Guo and Qi Tian},
  doi          = {10.1016/j.neucom.2022.07.053},
  journal      = {Neurocomputing},
  pages        = {25-36},
  shortjournal = {Neurocomputing},
  title        = {Scalable NAS with factorizable architectural parameters},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Successive learned image compression: Comprehensive analysis
of instability. <em>NEUCOM</em>, <em>506</em>, 12–24. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, learned image compression relying on deep learning has shown remarkable improvement compared to conventional image compression . While the existing studies on learned image compression focus only on single-step compression, this paper addresses the problem of successive image compression (SIC), which refers to repeated application of encoding and decoding an image. It can be commonly involved in the processes of image sharing, editing, and re-distribution, but the performance of learned image compression during SIC has not been studied in literature. Thus, we provide comprehensive analysis of successive learned image compression in three aspects. First, we newly introduce the issue of instability of learned compression methods during SIC, and analyze its causes and affecting factors. Second, we provide SIC benchmarking studies for the state-of-the-art learned compression methods, based on which we compare different methods and investigate the components affecting the instability in detail. Finally, we propose two methods to mitigate the issue of instability of learned methods during SIC.},
  archive      = {J_NEUCOM},
  author       = {Jun-Hyuk Kim and Soobeom Jang and Jun-Ho Choi and Jong-Seok Lee},
  doi          = {10.1016/j.neucom.2022.07.065},
  journal      = {Neurocomputing},
  pages        = {12-24},
  shortjournal = {Neurocomputing},
  title        = {Successive learned image compression: Comprehensive analysis of instability},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fully convolutional line parsing. <em>NEUCOM</em>,
<em>506</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a one-stage F ully C onvolutional Li ne P arsing network (F-Clip) that detects line segments from images. The proposed network is very simple and flexible with variations that gracefully trade off between speed and accuracy for different applications. F-Clip detects line segments in an end-to-end fashion by predicting each line’s center position, length, and angle. We further customize the design of convolution kernels of our fully convolutional network to effectively exploit the statistical priors of the distribution of line angles in real image datasets. We conduct extensive experiments and show that our method achieves a significantly better trade-off between efficiency and accuracy, resulting in a real-time line detector at up to 73 FPS on a single GPU. Such inference speed makes our method readily applicable to real-time tasks without compromising any accuracy of previous methods. Moreover, when equipped with a performance-improving backbone network , F-Clip is able to significantly outperform all state-of-the-art line detectors on accuracy at a similar or even higher frame rate. In other word, under same inference speed, F-Clip always achieving best accuracy compare with other methods. Source code https://github.com/Delay-Xili/F-Clip .},
  archive      = {J_NEUCOM},
  author       = {Xili Dai and Haigang Gong and Shuai Wu and Xiaojun Yuan and Yi Ma},
  doi          = {10.1016/j.neucom.2022.07.026},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {Fully convolutional line parsing},
  volume       = {506},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bipartite leader-following synchronization of delayed
incommensurate fractional-order memristor-based neural networks under
signed digraph via adaptive strategy. <em>NEUCOM</em>, <em>505</em>,
413–432. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, an adaptive controller , formulated as linear feedback controls plus nonlinear parts , is synthesized to achieve bipartite leader-following synchronization of delayed incommensurate fractional-order memristor-based neural networks (FMNNs), in which follower FMNNs are linearly coupled under a signed digraph . The salient features of this research lie in two aspects: (1) the assumption on time-varying delays is very weak, since it neither requires boundedness of delays nor restricts the differentiation of time delay functions; (2) the adaptive controller contains no delay term, and it is feasible for both bounded and unbounded activation functions . As the preparatory work for stability analysis of the controlled synchronization error system, the ready-made results on delayed incommensurate fractional-order linear positive systems, especially stability condition and comparison principle, are perfected by relaxing premises of time-varying delays. Besides, a group of differential inclusion inequalities are established as a powerful aid in scaling the bipartite synchronization error system. More relevantly, an algebraic synchronization criterion, formulated in terms of coupling strength, inner coupling matrix, Laplacian matrix and FMNN system parameters, is proved with the benefit of vector Lyapunov function and positive system theory. With the controller utilized, linear feedback controls can be exerted merely on partial neurons of some selected FMNNs, which is exemplified by numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Jia Jia and Fei Wang and Zhigang Zeng},
  doi          = {10.1016/j.neucom.2022.06.043},
  journal      = {Neurocomputing},
  pages        = {413-432},
  shortjournal = {Neurocomputing},
  title        = {Bipartite leader-following synchronization of delayed incommensurate fractional-order memristor-based neural networks under signed digraph via adaptive strategy},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fixed-time stability of projection neurodynamic network for
solving pseudomonotone variational inequalities. <em>NEUCOM</em>,
<em>505</em>, 402–412. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel modified neurodynamic network (MNN) based on projection to solve pseudomonotone variational inequalities. Under the strong pseudo-monotonicity and Lipschitz continuous assumptions, the MNN admits a unique solution. The relations between the MNN and the corresponding neurodynamic network are obtained. Moreover, we establish the globally fixed-time stability of the MNN. The convergence time of the MNN is not depended on the initial conditions and uniformly bounded. Numerical examples are also reported to show the effectiveness and superiority of the MNN.},
  archive      = {J_NEUCOM},
  author       = {Jinlan Zheng and Jiawei Chen and Xingxing Ju},
  doi          = {10.1016/j.neucom.2022.07.034},
  journal      = {Neurocomputing},
  pages        = {402-412},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time stability of projection neurodynamic network for solving pseudomonotone variational inequalities},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptable volumetric liver segmentation model for CT images
using region-based features and convolutional neural network.
<em>NEUCOM</em>, <em>505</em>, 388–401. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver plays an important role in metabolic processes, therefore fast diagnosis and potential surgical planning is essential in case of any disease. The automatic liver segmentation approach has been studied during the past years and different segmentation techniques have been proposed, but this task remains a challenge and improvements are still required to further increase segmentation accuracy . In this work, an automatic, deep learning based approach is introduced, which is adaptable and it is able to handle smaller databases, including heterogeneous data . The method starts with a preprocessing to highlight the liver area using probability density function based estimation and supervoxel segmentation. Then, a modification of the 3D U-Net is introduced, which is called 3D RP-UNet and applies the ResPath in the 3D network. Finally, with liver-heart separation and morphological steps, the segmentation results are further refined. Segmentation results on three public databases showed that the proposed method performs robustly and achieves good segmentation performance compared to other state-of-the-art approaches in the majority of the evaluation metrics .},
  archive      = {J_NEUCOM},
  author       = {Vanda Czipczer and Andrea Manno-Kovacs},
  doi          = {10.1016/j.neucom.2022.07.024},
  journal      = {Neurocomputing},
  pages        = {388-401},
  shortjournal = {Neurocomputing},
  title        = {Adaptable volumetric liver segmentation model for CT images using region-based features and convolutional neural network},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Accelerating deep neural network filter pruning with
mask-aware convolutional computations on modern CPUs. <em>NEUCOM</em>,
<em>505</em>, 375–387. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Filter pruning, a representative model compression technique, has been widely used to compress and accelerate sophisticated deep neural networks on resource-constrained platforms. Nevertheless, most studies focus on reducing the cost of model inference, whereas the heavy burden of the pruning optimization process is neglected. In this paper, we propose MaskACC, a mask-aware convolutional computation method, which accelerates the prevailing mask-based filter pruning process on modern CPU platforms. MaskACC dynamically reorganizes the tensors used in convolutions with the mask information to avoid unnecessary computations, thereby improving the computational efficiency of the pruning process. Evaluation with state-of-the-art neural network models on CPU cloud platforms demonstrates the effectiveness of our method, which achieves up to 1.61 × × speedup under commonly-used pruning rates, compared to conventional computations.},
  archive      = {J_NEUCOM},
  author       = {Xiu Ma and Guangli Li and Lei Liu and Huaxiao Liu and Xueying Wang},
  doi          = {10.1016/j.neucom.2022.07.006},
  journal      = {Neurocomputing},
  pages        = {375-387},
  shortjournal = {Neurocomputing},
  title        = {Accelerating deep neural network filter pruning with mask-aware convolutional computations on modern CPUs},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic graph neural network for fake news detection.
<em>NEUCOM</em>, <em>505</em>, 362–374. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread of fake news on social media and other platforms can bring significant damage to the harmony and stability of our society. To defend against fake news, researchers have suggested various ways of dealing with fake news. In recent years, fake news detection has become the research focus in both academic and industrial communities. The majority of existing propagation-based fake news detection algorithms are based on static networks and they assume the whole information propagation network structure is readily available before performing fake news detection algorithms. However, real-world information diffusion networks are dynamic as new nodes joining the network and new edges being created. To address these shortcomings, we proposed a dynamic propagation graph-based fake news detection method to capture the missing dynamic propagation information in static networks and classify fake news. Specifically, the proposed method models each news propagation graph as a series of graph snapshots recorded at discrete time steps. We evaluate our approach on three real-world benchmark datasets, and the experimental results demonstrate the effectiveness of the proposed model.},
  archive      = {J_NEUCOM},
  author       = {Chenguang Song and Yiyang Teng and Yangfu Zhu and Siqi Wei and Bin Wu},
  doi          = {10.1016/j.neucom.2022.07.057},
  journal      = {Neurocomputing},
  pages        = {362-374},
  shortjournal = {Neurocomputing},
  title        = {Dynamic graph neural network for fake news detection},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Handling negative samples problems in span-based nested
named entity recognition. <em>NEUCOM</em>, <em>505</em>, 353–361. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named Entity Recognition (NER) is generally regarded as a sequence labeling task, and faces a serious problem when the named entities are nested. Span-based model, which enumerates all possible spans as potential entity mentions in a sentence and classifies them, is straightforward for nested NER but faces negative samples problems. In this paper, we propose a span-based nested NER model with BERT and try to solve the negative samples problems. In view of the phenomenon that there are too many negative samples in all spans, we employ a multi-task learning method, which divides NER task into entity identification and entity classification task . In addition, we propose the entity IoU loss function to focus our model on the hard negative samples. Our model is evaluated on three nested NER datasets: GENIA, ACE2004 and ACE2005, and the results show that our model outperforms other state-of-the-art models with the same pretrained language model , achieving 79.46\%, 87.30\% and 85.24\% respectively in terms of F1 score.},
  archive      = {J_NEUCOM},
  author       = {Chenxu Liu and Hongjie Fan and Junfei Liu},
  doi          = {10.1016/j.neucom.2022.07.012},
  journal      = {Neurocomputing},
  pages        = {353-361},
  shortjournal = {Neurocomputing},
  title        = {Handling negative samples problems in span-based nested named entity recognition},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fixed-time synchronization of fractional-order
complex-valued neural networks with time-varying delay via sliding mode
control. <em>NEUCOM</em>, <em>505</em>, 339–352. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taking into account fractional-order complex-valued neural networks with time-varying delay, the issue of achieving fixed-time synchronization is discussed in this paper. By utilizing the properties of fractional calculus and fractional-order comparison principle, an improved lemma is proposed to derive the fixed-time synchronization conditions . On the basis of sliding model control and Lyapunov stability theorem, an effective sliding mode surface is constructed, which only uses the synchronization error information of FOCVNNs and is composed of fractional and integer integral terms. Further, a suitable sliding model control is constructed, which makes synchronization error converges to zero in a fixed-time. Beyond that, several sufficient conditions are posed to guarantee fixed-time synchronization of the fractional-order complex-valued neural networks and the upper bound of synchronization settling time is estimated. Finally, two numerical simulations are given to demonstrate the effectiveness of the presented theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Yali Cheng and Taotao Hu and Wenbo Xu and Xiaojun Zhang and Shouming Zhong},
  doi          = {10.1016/j.neucom.2022.07.015},
  journal      = {Neurocomputing},
  pages        = {339-352},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time synchronization of fractional-order complex-valued neural networks with time-varying delay via sliding mode control},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intra-class variations with deep learning-based gait
analysis: A comprehensive survey of covariates and methods.
<em>NEUCOM</em>, <em>505</em>, 315–338. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition is an essential biometric technique that recognizes humans at a distance through their unique walking style. In the present era of deep learning, automated gait analysis has become easier with an increase in processing power. However, the recognition accuracy is affected by many covariates such as clothing conditions, carrying objects, varying viewing angles, occlusion, walking speed variations, and thus, it remains a challenging problem. For this complex problem, huge datasets are required to train for given conditions and predict new situations; thus, deep learning is preferred. In this review paper, we categorize various gait covariates which have been recently handled. There are various approaches, but the most effective approach is deep learning; hence in this paper, we include the most used deep learning approaches for each covariate condition found in the literature. Further, we highlight open problem areas handling these covariates and offer some suggestions about their better handling. Based on the review and our understanding of all the gait pipelines employed in deep learning, we have suggested a comprehensive and universal deep learning pipeline that can handle most gait covariates rather than customized deep learning pipelines. The methods of handling gait covariates are summarized according to appearance, pose, and sensors. A comprehensive comparison of reviewed approaches for real-time scenarios in terms of their novelty, benefits, and limitations is then offered, which led us to identify open research problems related to gait covariates. In the end, the paper concludes with the challenges identified and prospects.},
  archive      = {J_NEUCOM},
  author       = {Anubha Parashar and Rajveer Singh Shekhawat and Weiping Ding and Imad Rida},
  doi          = {10.1016/j.neucom.2022.07.002},
  journal      = {Neurocomputing},
  pages        = {315-338},
  shortjournal = {Neurocomputing},
  title        = {Intra-class variations with deep learning-based gait analysis: A comprehensive survey of covariates and methods},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Symmetrical irregular local features for fine-grained visual
classification. <em>NEUCOM</em>, <em>505</em>, 304–314. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained visual classification (FGVC) has small inter-class variations and large intra-class variations, therefore, recognizing sub-classes belonging to the same meta-class is a difficult task. Recent studies have primarily addressed this problem by locating the most discriminative image regions, and the extracted image regions have been used to improve the ability to capture subtle differences. Most of these studies used regular anchors to extract local features . However, the local features of the target are mostly irregular geometric shapes. These methods cannot fully extract the features and inevitably include a large amount of irrelevant information, resulting in reduced credibility of the evaluation results. However, the spatial relationship between the features is easily overlooked. This study proposes a novel local feature extraction anchor generator (LFEAG) to simulate the shapes of irregular features. Thus, discriminative features can be fully included in the extracted features. In addition, an effective symmetrized local feature extraction module (SLFEM) based on an attention mechanism is proposed to fully use the spatial relationship between the extracted local features and highlight discriminative features . Experiments on six popular fine-grained benchmark datasets: CUB-200-2011, Stanford Dogs, Food-101, Oxford-IIIT Pets, Aircraft and NA-Birds, are conducted to demonstrate the advantages of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Ming Yang and Yang Xu and Zebin Wu and Zhihui Wei},
  doi          = {10.1016/j.neucom.2022.07.056},
  journal      = {Neurocomputing},
  pages        = {304-314},
  shortjournal = {Neurocomputing},
  title        = {Symmetrical irregular local features for fine-grained visual classification},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gated graph convolutional network based on spatio-temporal
semi-variogram for link prediction in dynamic complex network.
<em>NEUCOM</em>, <em>505</em>, 289–303. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction is one of the most important methods to uncover evolving mechanisms of dynamic complex networks. Determining these links raises well-known technical challenges in terms of weak correlation, uncertainty and non-stationary. In this paper, we presented a novel gated graph convolutional network (GCN) based on spatio-temporal semi-variogram (STEM-GCN). It learns spacial and temporal features in order to achieve link prediction in the dynamic networks. In this STEM-GCN model, we first utilized the spatio-temporal semi-variogram to obtain the spacial and temporal correlations from the dynamic networks. Its spacial correlation helped us determine the hyper-parameters of STEM-GCN and speed up its training. The correlation smoothing strategy is also introduced to eliminate the noise through temporal correlation and to improve the accuracy of link prediction. Finally, the network dynamics are captured by propagating the spacial and temporal features between consecutive time steps with stacked memory cell structures. The extensive experiments on real data sets demonstrated the effectiveness of the proposed approach for link prediction in dynamic complex networks.},
  archive      = {J_NEUCOM},
  author       = {Liping Yang and Xin Jiang and Yiming Ji and Hua Wang and Ajith Abraham and Hongbo Liu},
  doi          = {10.1016/j.neucom.2022.07.030},
  journal      = {Neurocomputing},
  pages        = {289-303},
  shortjournal = {Neurocomputing},
  title        = {Gated graph convolutional network based on spatio-temporal semi-variogram for link prediction in dynamic complex network},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Temporal grafter network: Rethinking LSTM for effective
video recognition. <em>NEUCOM</em>, <em>505</em>, 276–288. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long short-term memory (LSTM) networks are widely used to handle temporal or sequential data, and have great potential for video recognition. Existing LSTM-based video recognition methods either insert LSTM modules at the end of 2D convolutional neural networks (CNNs), called global LSTM methods, or build networks solely by stacking multiple LSTM modules. Unfortunately, these LSTM-based video recognition methods are not competitive, compared to state-of-the-art 3D CNNs or two-stream CNNs. In order to fully explore the potential of LSTM, this paper rethinks its role in video recognition network architectures and proposes a novel Temporal Grafter Network (TGN). Specifically, we develop an efficient and effective variant of convolutional LSTM module, which is grafted between different stages of very deep 2D CNNs for temporal modeling and delivery. Our TGN can capture local motion patterns of varying scales inherent in feature maps from high to low resolutions, while attending to the spatial context information and modeling global temporal dependency across the whole video. The proposed TGN can capture and transmit temporal information throughout very deep 2D CNNs, overcoming the downsides of existing LSTM-based methods and being able to make full use of the potential of LSTM for effective video recognition and early action recognition. We perform extensive ablation study to verify the effectiveness of our proposed methods, and experiments on three widely used video benchmarks show that our methods can achieve performance matching or better than the state-of-the-arts.},
  archive      = {J_NEUCOM},
  author       = {Bingbing Zhang and Qilong Wang and Zilin Gao and Ruiren Zeng and Peihua Li},
  doi          = {10.1016/j.neucom.2022.07.040},
  journal      = {Neurocomputing},
  pages        = {276-288},
  shortjournal = {Neurocomputing},
  title        = {Temporal grafter network: Rethinking LSTM for effective video recognition},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LSR: Lightening super-resolution deep network for low-light
image enhancement. <em>NEUCOM</em>, <em>505</em>, 263–275. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In long-range shooting during low-light, we can only obtain a Low-Resolution (LR) image with poor visibility due to the limitation of physical devices. To get high-quality distant images, optical lenses are the optimal choice, but they are quite expensive and bulky. Low-light enhancement and Super-Resolution (SR) are the necessity of mobile phones and surveillance cameras and have wide applications in video surveillance, remote sensing, and night photography. Usually, the images that are taken from long-range in low-light suffer the loss of details not only due to low photon count but also due to low Signal-to-Noise Ratio (SNR), which makes it a highly ill-posed problem. Therefore, to resolve these two problems simultaneously, we propose a Lightening Super-Resolution (LSR) deep network. The proposed network uses the back-projection to learn the enhanced and dark features in low-resolution space iteratively and up-sample the enhanced features at the last stage of the network to get the final enhanced and high-resolution image. In particular, to train the network, the low-light images of the publicly available LOw Light (LOL) dataset are down-sampled using bicubic interpolation, and ground truth images are used as enhanced high-resolution images. For a fair comparison, a series of already available SR networks have been trained on the mentioned dataset, and their performances are compared. The promising results open up many opportunities for future work.},
  archive      = {J_NEUCOM},
  author       = {Muhammad Tahir Rasheed and Daming Shi},
  doi          = {10.1016/j.neucom.2022.07.058},
  journal      = {Neurocomputing},
  pages        = {263-275},
  shortjournal = {Neurocomputing},
  title        = {LSR: Lightening super-resolution deep network for low-light image enhancement},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural mixture models with expectation-maximization for
end-to-end deep clustering. <em>NEUCOM</em>, <em>505</em>, 249–262. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Any clustering algorithm must synchronously learn to model the clusters and allocate data to those clusters in the absence of labels. Mixture model-based methods model clusters with pre-defined statistical distributions and allocate data to those clusters based on the cluster likelihoods. They iteratively refine those distribution parameters and member assignments following the Expectation-Maximization (EM) algorithm. However, the cluster representability of such hand-designed distributions that employ a limited amount of parameters is not adequate for most real-world clustering tasks . In this paper, we realize mixture model-based clustering with a neural network where the final layer neurons, with the aid of an additional transformation, approximate cluster distribution outputs. The network parameters pose as the parameters of those distributions. The result is an elegant, much-generalized representation of clusters than a restricted mixture of hand-designed distributions. We train the network end-to-end via batch-wise EM iterations where the forward pass acts as the E-step and the backward pass acts as the M-step. In image clustering, the mixture-based EM objective can be used as the clustering objective along with existing representation learning methods. In particular, we show that when mixture-EM optimization is fused with consistency optimization, it improves the sole consistency optimization performance in clustering. Our trained networks outperform single-stage deep clustering methods that still depend on k-means, with unsupervised classification accuracy of 63.8\% in STL10, 58\% in CIFAR10, 25.9\% in CIFAR100, and 98.9\% in MNIST.},
  archive      = {J_NEUCOM},
  author       = {Dumindu Tissera and Kasun Vithanage and Rukshan Wijesinghe and Alex Xavier and Sanath Jayasena and Subha Fernando and Ranga Rodrigo},
  doi          = {10.1016/j.neucom.2022.07.017},
  journal      = {Neurocomputing},
  pages        = {249-262},
  shortjournal = {Neurocomputing},
  title        = {Neural mixture models with expectation-maximization for end-to-end deep clustering},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Event-triggered predictive control for linear discrete-time
multi-agent systems. <em>NEUCOM</em>, <em>505</em>, 238–248. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the event-triggered predictive control(ETPC) problem for linear discrete-time multi-agent systems. To achieve accurate state estimation under event-triggered communication between agents, an event-triggered predictive control scheme as well as a novel class of triggering condition are proposed for synchronization of multi-agent systems with single-integrator dynamics, where the control input of each agent no longer remains constant but updates periodically within the time interval between two consecutive triggering instants. Then, the proposed scheme is extended to the general linear multi-agent systems. By comparing with the time-triggered control(TTC) method and the existing event-triggered control(ETC) methods, the control performance of the proposed ETPC scheme is almost the same as that of the TTC approach, and the communication payload between agents is reduced with much less triggering times than existing ETC methods. Finally, two numerical examples are given to verify the theoretical analysis and demonstrate the superiority of the proposed method comparing with some existing methods.},
  archive      = {J_NEUCOM},
  author       = {Tian-Yong Zhang and Yong Xu and Jian Sun},
  doi          = {10.1016/j.neucom.2022.07.052},
  journal      = {Neurocomputing},
  pages        = {238-248},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered predictive control for linear discrete-time multi-agent systems},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RETRACTED: Distilled and filtered deep neural networks for
real-time object detection in edge computing. <em>NEUCOM</em>,
<em>505</em>, 225–237. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article has been retracted: please see Elsevier Policy on Article Withdrawal ( http://www.elsevier.com/locate/withdrawalpolicy ). This article has been retracted at the request of the Editors-in-Chief. The article plagiarizes significant results, observations and findings that had already appeared in the following three papers; Yoshitomo Matsubara, Sabur Baidya, Davide Callegaro, Marco Levorato, and Sameer Singh. 2019. “Distilled Split Deep Neural Networks for Edge-Assisted Real-Time Systems”. In Proceedings of the 2019 Workshop on Hot Topics in Video Analytics and Intelligent Edges (HotEdgeVideo&#39;19). Association for Computing Machinery, New York, NY, USA, 21–26. https://doi.org/10.1145/3349614.3356022 Yoshitomo Matsubara and Marco Levorato. 2020. “Split Computing for Complex Object Detectors: Challenges and Preliminary Results: . In Proceedings of the 4th International Workshop on Embedded and Mobile Deep Learning (EMDL’20). Association for Computing Machinery, New York, NY, USA, 7–12. https://doi.org/10.1145/3410338.3412338 Yoshitomo Matsubara and Marco Levorato, “Neural Compression and Filtering for Edge-assisted Real-time Object Detection in Challenged Networks,” 2020 25th International Conference on Pattern Recognition (ICPR), 2021, pp. 2272–2279, doi: 10.1109/ICPR48806.2021.9412388 , https://ieeexplore.ieee.org/abstract/document/9412388 One of the conditions of submission of a paper for publication is that authors declare explicitly that the paper has not been previously published and is not under consideration for publication elsewhere. Re-use of any data should be appropriately cited. As such this article represents severe abuse of the scientific publishing system. The scientific community takes a very strong view on this matter and apologies are offered to readers of the journal that this was not detected during the submission process.},
  archive      = {J_NEUCOM},
  author       = {Guoping Yang and Bangping Wang and Shaojie Qiao and Lulu Qu and Nan Han and Guan Yuan and He Li and Tao Wu and Yuzhong Peng},
  doi          = {10.1016/j.neucom.2022.07.008},
  journal      = {Neurocomputing},
  pages        = {225-237},
  shortjournal = {Neurocomputing},
  title        = {RETRACTED: Distilled and filtered deep neural networks for real-time object detection in edge computing},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Event-triggered based security consensus control for
multi-agent systems with DoS attacks. <em>NEUCOM</em>, <em>505</em>,
214–224. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work devotes to the security consensus problems for time-varying multi-agent systems (MASs) based on event-triggered control method with denial-of-service (DoS) attacks and parameter uncertainties. During information transmission, DoS attacks exist in both control and measurement channels, regarded as a dwell-time switching scheme, and hence the augmented system can be transformed into a class of discrete-time switched system subject to dwell-time property which contains an unstable and a stable subsystem. To increase the utilization of communication resources, the control input signal can be updated by adopting a novel event-driven mechanism with state-dependent threshold over a given finite horizon. By utilizing multiple Lyapunov functions analysis strategy, two sufficient conditions are obtained to achieve the desired H ∞ H∞ consensus performance. The cone complementary linearization algorithm is employed to cope with the nonlinear terms, and the desired controller gain matrices are calculated via resolving the corresponding linear matrix inequalities. Finally, the effectiveness of this proposed method is verified by providing a simulation example and the multi-automobile system.},
  archive      = {J_NEUCOM},
  author       = {Shenquan Wang and Changbei Zhao and Bangcheng Zhang and Yulian Jiang},
  doi          = {10.1016/j.neucom.2022.07.033},
  journal      = {Neurocomputing},
  pages        = {214-224},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered based security consensus control for multi-agent systems with DoS attacks},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Aperiodically intermittent pinning discrete-time observation
control for exponential synchronization of stochastic multilayer coupled
systems. <em>NEUCOM</em>, <em>505</em>, 203–213. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the exponential synchronization of stochastic multilayer coupled systems via aperiodically intermittent pinning control is fully considered. It is worth noting that the aperiodically intermittent pinning control is based on discrete-time state observation rather than continuous observation during the work time, which is an extension of existing literature. Furthermore, the intermittent control only need to control a fraction of the system nodes. Then, with the aid of Lyapunov method and stochastic analysis techniques, several sufficient conditions are explicitly obtained. In this case, a corollary is given to show that the average control rate method relaxes the constraints on lower or upper boundedness of control/rest widths of intermittent control. Finally, an application with respect to the exponential synchronization of Chua’s circuits and a numerical example are provided to validate the effectiveness of our main results.},
  archive      = {J_NEUCOM},
  author       = {Dongsheng Xu and Ting Wang and Huan Su},
  doi          = {10.1016/j.neucom.2022.07.020},
  journal      = {Neurocomputing},
  pages        = {203-213},
  shortjournal = {Neurocomputing},
  title        = {Aperiodically intermittent pinning discrete-time observation control for exponential synchronization of stochastic multilayer coupled systems},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). STDIN: Spatio-temporal distilled interpolation for electron
microscope images. <em>NEUCOM</em>, <em>505</em>, 188–202. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, flow-based approaches have shown considerable success in interpolating video images. However, in contrast to video images, electron microscope (EM) images are further complex due to noise and severe deformation between consecutive sections. Consequently, conventional flow-based interpolation algorithms , which assume a single offset per position, are not able to robustly model the movement of such complicated data. To address the aforementioned problems, this study propose a novel EM image interpolation framework that accommodates a range of offsets per location and further distills the intermediate features. First, a spatio-temporal ensemble (STE) interpolation module for capturing the missing middle features is presented. The STE is subdivided into two modules: temporal interpolation and residual spatial-correlated block (RSCB). The former predicts the intermediate features in two directions with several offsets at each location. Moreover, the RSCB uses the correlation coefficients for aggregated sampling. Thus, even if intermediate features are severely deformed, the STE effectively improves their accuracy. Second, a stackable feedback distillation block (SFDB) is introduced, which enhances the quality of intermediate features by distilling them from the input, and interpolated images , using a feedback mechanism. Extensive experiments demonstrate that the proposed method presents a superior performance compared with previous studies, both quantitatively and qualitatively.},
  archive      = {J_NEUCOM},
  author       = {Zejin Wang and Guodong Sun and Guoqing Li and Lijun Shen and Lina Zhang and Hua Han},
  doi          = {10.1016/j.neucom.2022.07.037},
  journal      = {Neurocomputing},
  pages        = {188-202},
  shortjournal = {Neurocomputing},
  title        = {STDIN: Spatio-temporal distilled interpolation for electron microscope images},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adherent mist and raindrop removal from a single image using
attentive convolutional network. <em>NEUCOM</em>, <em>505</em>, 178–187.
(<a href="https://doi.org/10.1016/j.neucom.2022.07.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temperature-difference-induced mist and environmentally-induced raindrops adhering to glass products such as windshield and camera lens, can often block vision and severely degrade the image seen through the lens. Despite posing a challenge to various vision systems, including autonomous driving and security surveillance, this problem has not received sufficient attention from researchers. In this work, we discuss the image degradation caused by adherent mist and raindrops. An attentive convolutional network is designed to visually remove the adherent mist and raindrops from a single image. Considering the variations in coexistence and reginal characteristics of adherent mist and raindrops, we propose interpolation-based pyramid attention blocks to perceive spatial information at different scales without rigid priors. Experiments show that the proposed method can improve the visibility of severely degraded images in real-world scenarios, both qualitatively and quantitatively. Further application experiments demonstrate that this practical problem is critical to high-level vision situations.},
  archive      = {J_NEUCOM},
  author       = {Da He and Xiaoyu Shang and Jiajia Luo},
  doi          = {10.1016/j.neucom.2022.07.032},
  journal      = {Neurocomputing},
  pages        = {178-187},
  shortjournal = {Neurocomputing},
  title        = {Adherent mist and raindrop removal from a single image using attentive convolutional network},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Topology identification for fractional complex networks with
synchronization in finite time based on adaptive observers and
event-triggered control. <em>NEUCOM</em>, <em>505</em>, 166–177. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the topology identification issue for fractional complex networks (FCNs) based on the synchronization in finite-time. Firstly, two lemmas with respect to the convergence of a continuous differential function and its Caputo fractional derivative are developed, respectively. Secondly, a fractional auxiliary network, which consists of the isolated chaotic system, is introduced to avoid the requirement for the linear independence condition (LIC). A control protocol with the event-trigger mechanism (ETM) and a adaptive topology observer are designed to achieve the synchronization in finite time and topology identification. In addition, the synchronization conditions in finite time between regulated network and auxiliary network are addressed, and the topology identification is realized under the designed control protocol successfully. Finally, two numerical simulations are provided to illustrate the effectiveness of the proposed scheme and the validity of theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Jing Bai and Huaiqin Wu and Jinde Cao},
  doi          = {10.1016/j.neucom.2022.07.023},
  journal      = {Neurocomputing},
  pages        = {166-177},
  shortjournal = {Neurocomputing},
  title        = {Topology identification for fractional complex networks with synchronization in finite time based on adaptive observers and event-triggered control},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Event-triggered asynchronous synchronization control for
switched generalized neural networks with time-varying delay.
<em>NEUCOM</em>, <em>505</em>, 154–165. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present research is concerned with the ℓ 2 - ℓ ∞ ℓ2-ℓ∞ synchronization control for discrete-time switched generalized neural networks subject to time-varying delay. Distinct from the existing correlative results, a novel synchronization paradigm is established, in which the designed synchronization controller only contains the information of neuron states and switching signal at the certain triggering instants scheduled by the designed dynamic event-triggered mechanism. Also, an interesting asynchronous problem caused by the asynchronization of the switching and triggering actions is taken into consideration. For reducing the conservativeness of the conventional approaches, the time-dependent Lyapunov–Krasovskii functional for the resultant asynchronous situation is then constructed, and the correspondent sufficient conditions are formulated to ensure the exponential stability and weighted ℓ 2 - ℓ ∞ ℓ2-ℓ∞ performance of the concerned synchronization error systems. Finally, the applicability and superiority of the developed synchronization technique are substantiated with two simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Hong Sang and Hong Nie and Jun Zhao},
  doi          = {10.1016/j.neucom.2022.07.021},
  journal      = {Neurocomputing},
  pages        = {154-165},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered asynchronous synchronization control for switched generalized neural networks with time-varying delay},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Amplification trojan network: Attack deep neural networks by
amplifying their inherent weakness. <em>NEUCOM</em>, <em>505</em>,
142–153. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent works found that deep neural networks (DNNs) can be fooled by adversarial examples , which are crafted by adding adversarial noise on clean inputs. The accuracy of DNNs on adversarial examples will decrease as the magnitude of the adversarial noise increase. In this study, we show that DNNs can be also fooled when the noise is very small under certain circumstances. This new type of attack is called Amplification Trojan Attack (ATAttack). Specifically, we use a trojan network to transform the inputs before sending them to the target DNN. This trojan network serves as an amplifier to amplify the inherent weakness of the target DNN. The target DNN, which is infected by the trojan network, performs normally on clean data while being more vulnerable to adversarial examples. Since it only transforms the inputs, the trojan network can hide in DNN-based pipelines, e.g. by infecting the pre-processing procedure of the inputs before sending them to the DNNs. This new type of threat should be considered in developing safe DNNs.},
  archive      = {J_NEUCOM},
  author       = {Zhanhao Hu and Jun Zhu and Bo Zhang and Xiaolin Hu},
  doi          = {10.1016/j.neucom.2022.07.018},
  journal      = {Neurocomputing},
  pages        = {142-153},
  shortjournal = {Neurocomputing},
  title        = {Amplification trojan network: Attack deep neural networks by amplifying their inherent weakness},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The benefits of adversarial defense in generalization.
<em>NEUCOM</em>, <em>505</em>, 125–141. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has shown that models induced by machine learning , and in particular by deep learning , can be easily fooled by an adversary who carefully crafts imperceptible, at least from the human perspective, or physically plausible modifications of the input data. This discovery gave birth to a new field of research, the adversarial machine learning , where new methods of attacks and defense are developed continuously, mimicking what is happening from a long time in cybersecurity. In this paper we will show that the drawbacks of inducing models from data less prone to be misled can actually provide some benefits when it comes to assessing their generalization abilities . We will show these benefits both from a theoretical perspective, using state-of-the-art statistical learning theory , and both with practical examples.},
  archive      = {J_NEUCOM},
  author       = {Luca Oneto and Sandro Ridella and Davide Anguita},
  doi          = {10.1016/j.neucom.2022.07.010},
  journal      = {Neurocomputing},
  pages        = {125-141},
  shortjournal = {Neurocomputing},
  title        = {The benefits of adversarial defense in generalization},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive spatiotemporal graph convolutional network with
intermediate aggregation of multi-stream skeleton features for action
recognition. <em>NEUCOM</em>, <em>505</em>, 116–124. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video-based action recognition is a challenging problem due to the rapid and uncertain changes in human actions. Recent studies show that incorporating video and human body skeleton helps improve action recognition performance. These methods generally use graph convolutional networks (GCNs) to extract structural features of the human body joints from skeleton data. Yet, most GCN-based methods have some limitations in skeleton-based action recognition. (1) The graph structure of the human body joints is time-invariant, making it difficult to represent the changing relationship between joints across actions. (2) Methods relying on single-stream models only utilize limited information of skeleton data, such as joints or bones, and fail to consider coherent features of movements. (3) Methods relying on multi-stream models have considerable parameters and are inefficient for real-life applications. To address these problems, we propose an adaptive spatiotemporal graph convolutional network with intermediate aggregation of multi-stream skeleton features for action recognition. First, our method learns an adaptive graph structure representing the changing relationship between joints. Secondly, we facilitate a multi-stream model to extract various features from the skeleton, including joint-stream, bone-stream, and motion-stream. Moreover, an intermediate aggregation strategy is employed to aggregate these features and to reduce the parameters of this model. The proposed method has been validated on various benchmarks and a real-world abnormal action dataset. Extensive experimental results show that our method achieves excellent performance in skeleton-based action recognition.},
  archive      = {J_NEUCOM},
  author       = {Yukai Zhao and Jingwei Wang and Han Wang and Min Liu and Yunlong Ma},
  doi          = {10.1016/j.neucom.2022.07.046},
  journal      = {Neurocomputing},
  pages        = {116-124},
  shortjournal = {Neurocomputing},
  title        = {Adaptive spatiotemporal graph convolutional network with intermediate aggregation of multi-stream skeleton features for action recognition},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fully distributed quantized secure bipartite consensus
control of nonlinear multiagent systems subject to denial-of-service
attacks. <em>NEUCOM</em>, <em>505</em>, 101–115. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is intended to solve the fully distributed secure bipartite consensus problem of nonlinear multi-agent systems (MASs) with quantized information under Denial-of-Service (DoS) attacks. The attacks, which constrained on attack frequency and duration are studied. Firstly, we propose a novel secure output feedback control protocol integrated of the logarithmic quantizer and relative output measurements of neighboring agents, which can realize secure control under DoS attacks by choosing the design parameters correctly. Secondly, an adaptive control protocol that includes dynamic coupling strengths into the control law and the state observer function is developed. Contrast to the single adaptive control strategy, two adaptive couplings constructed in sensor-to-observer, and controller-to-actuator channels, respectively, which can alleviate the burden of the limited bandwidth and energy consumption more effectively. Furthermore, this control strategy with dynamic coupling gains is fully distributed, under which agents are not required to know a priori knowledge of any global information and the quantizer only needs to quantize the output state error information of agents. Then, theoretical guarantees on the effectiveness of the proposed controllers in steering the system to a secure bipartite (bounded) consensus under quantized output measurements and intermittent DoS attacks are derived. Finally, the numerical simulation inspired by a real-world physical network system is developed to verify the usefulness of the presented controllers.},
  archive      = {J_NEUCOM},
  author       = {Qiang Wang and Lorenzo Zino and Dayu Tan and Jiapeng Xu and Weimin Zhong},
  doi          = {10.1016/j.neucom.2022.07.047},
  journal      = {Neurocomputing},
  pages        = {101-115},
  shortjournal = {Neurocomputing},
  title        = {Fully distributed quantized secure bipartite consensus control of nonlinear multiagent systems subject to denial-of-service attacks},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-scale local cues and hierarchical attention-based LSTM
for stock price trend prediction. <em>NEUCOM</em>, <em>505</em>, 92–100.
(<a href="https://doi.org/10.1016/j.neucom.2022.07.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock price trend prediction is to seek profit maximum of stock investment by estimating future stock price tendency. Nevertheless, it is still a tough task due to noisy and non-stationary properties of stock market. Thus, it is important how to relieve such negative effects and to improve prediction accuracy. In this paper, we leverage four diverse local descriptors in short durations to alleviate noisy fluctuations of stock price. In detail, piecewise aggregate approximation (PAA) collects relatively stable average values; the derivatives of short-time series reflect the change ratio of stock price; the slope implies the short-time price trend; hog-1D aggregates different oriented gradients into histograms in a statistical fashion. They provide diverse and comprehensive cues about the stock price series across different aspects. Building upon such local descriptors , we propose a multi-scale local cues and hierarchical attention-based LSTM model (MLCA-LSTM) to capture the underlying price trend patterns. It has two advantages: 1) multi-scale information is further enriched by performing different scale sliding windows over stock price series to induce diverse local descriptors, 2) temporal dependency and multi-scale interactions are jointly attended and aggregated through the hierarchical attention mechanism and multi-branch LSTM structure. Experiments on the real stock price data confirm the efficacy of the proposed model as compared to the state-of-the-art counterparts.},
  archive      = {J_NEUCOM},
  author       = {Xiao Teng and Xiang Zhang and Zhigang Luo},
  doi          = {10.1016/j.neucom.2022.07.016},
  journal      = {Neurocomputing},
  pages        = {92-100},
  shortjournal = {Neurocomputing},
  title        = {Multi-scale local cues and hierarchical attention-based LSTM for stock price trend prediction},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contextual relation embedding and interpretable triplet
capsule for inductive relation prediction. <em>NEUCOM</em>,
<em>505</em>, 80–91. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation prediction is a task for knowledge graph completion which is targeted at predicting missing relationships between entities. Most previous works focus on learning latent representations of entities and relations, resulting in the limitation of transductive setting where the model is incapable of directly predicting relations for unseen entities. In order to predict relation inductively, recent works provide alternatives to operate on the subgraph surrounding a candidate triplet. However, they only exploit structural information while failing to take full advantage of textual information of relations. Moreover, they pay no attention to interpretability of the model as the inference process is not explainable. In this paper, we introduce an Interpretable Triplet Capsule Network (ITCN) for inductive relation prediction, which extracts textual information of relations by pre-trained BERT and provides interpretation by adapted Capsule Network. Unlike previous subgraph-based inductive models which ignore textual information associated with relations, ITCN leverages pre-trained BERT to learn prior knowledge carried in the semantic meaning of relations and produce Contextual Relation Embedding (CRE). Moreover, as Routing Mechanism of Capsule Network can reveal the relationship between inputted and outputted capsules, we construct triplets in knowledge graph into capsules and adapt the original Routing Mechanism into Sorted Multilayer Routing Mechanism (SMRM) to provide interpretation. Experimental results suggest that ITCN achieves state-of-the-art performance on three benchmark datasets, highlighting the benefit brought by the CRE and interpretability of the model.},
  archive      = {J_NEUCOM},
  author       = {Jianfeng Wu and Sijie Mai and Haifeng Hu},
  doi          = {10.1016/j.neucom.2022.07.043},
  journal      = {Neurocomputing},
  pages        = {80-91},
  shortjournal = {Neurocomputing},
  title        = {Contextual relation embedding and interpretable triplet capsule for inductive relation prediction},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Investigating intensity and transversal drift in
hyperspectral imaging data. <em>NEUCOM</em>, <em>505</em>, 68–79. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When measuring data with hyperspectral cameras drift in the data distribution occurs over time and when the sensing device is changed. Frequently, this drift is characterized by intensity shift or wavelength shifts. In this contribution, we propose novel methods that reverse these shifts and demonstrate their capability to avoid the negative impact of drift on the classification performance. We show that our approaches perform on par or better in comparison to established methods. We also provide a theoretical motivation why one of the proposed methods can deal with both, intensity and wavelength shift provided bounds on the smoothness of the functional data are given.},
  archive      = {J_NEUCOM},
  author       = {Valerie Vaquet and Patrick Menz and Udo Seiffert and Barbara Hammer},
  doi          = {10.1016/j.neucom.2022.07.011},
  journal      = {Neurocomputing},
  pages        = {68-79},
  shortjournal = {Neurocomputing},
  title        = {Investigating intensity and transversal drift in hyperspectral imaging data},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). PointCutMix: Regularization strategy for point cloud
classification. <em>NEUCOM</em>, <em>505</em>, 58–67. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As 3D point cloud analysis has received increasing attention, the insufficient scale of point cloud datasets and the weak generalization ability of networks become prominent. In this paper, we propose a simple and effective augmentation method for the point cloud data to alleviate those problems. It finds the one-to-one correspondence between two point clouds and generates new training data by replacing the points in one sample with their corresponding pairs. Two replacement strategies are proposed to adapt to the accuracy or robustness requirement for different tasks, one of which is to randomly select all replacing points while the other one is to select k nearest neighbors of a single random point. Both strategies consistently and significantly improve the performance of various models on point cloud classification problems. By introducing the saliency maps to guide the selection of replacing points, the performance further improves. Since our method persists local semantic information of the points, we also at the first time extend MSDA for the point cloud segmentation problem. Moreover, PointCutMix is validated to enhance the model’s robustness. When using as a defense method, our method outperforms the state-of-the-art defense algorithms. The code is available at: https://github.com/cuge1995/PointCutMix .},
  archive      = {J_NEUCOM},
  author       = {Jinlai Zhang and Lyujie Chen and Bo Ouyang and Binbin Liu and Jihong Zhu and Yujin Chen and Yanmei Meng and Danfeng Wu},
  doi          = {10.1016/j.neucom.2022.07.049},
  journal      = {Neurocomputing},
  pages        = {58-67},
  shortjournal = {Neurocomputing},
  title        = {PointCutMix: Regularization strategy for point cloud classification},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-rigid multi-modal brain image registration based on
two-stage generative adversarial nets. <em>NEUCOM</em>, <em>505</em>,
44–57. (<a href="https://doi.org/10.1016/j.neucom.2022.07.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper has proposed the two-stage generative adversarial nets (GAN) based multi-modal brain image registration method. The first stage uses the GAN to indirectly recover image deformation and the second stage employs the GAN to directly estimate the registered image. At the first stage, the GAN uses structural representations of reference and float images generated by the improved modality independent neighborhood descriptor (MIND) as inputs, and outputs the predicted structural representation of the registered image. At the second stage, the GAN estimates the intensities of the registered image according to the generated structural representations at the first stage. The two GANs designed based on the U-Net are trained using the different loss functions related to mean square error, mean structural similarity (MSSIM) and the least squares loss. Experiments on the 3D brain images from the Atlas, BrainWeb and RIRE datasets show that compared with state-of-the-art registration methods based on sum of squared differences on entropy images (ESSD), MIND, self-similarity context (SSC), voxelmorph (Morph), volume tweening network (VTN) and adversarial similarity network (ASN), the proposed method has competitive or better registration performance in terms of dice value, MSSIM and computational efficiency.},
  archive      = {J_NEUCOM},
  author       = {Xingxing Zhu and Zhiwen Huang and Mingyue Ding and Xuming Zhang},
  doi          = {10.1016/j.neucom.2022.07.014},
  journal      = {Neurocomputing},
  pages        = {44-57},
  shortjournal = {Neurocomputing},
  title        = {Non-rigid multi-modal brain image registration based on two-stage generative adversarial nets},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Balancing stability and plasticity when learning topic
models from short and noisy text streams. <em>NEUCOM</em>, <em>505</em>,
30–43. (<a href="https://doi.org/10.1016/j.neucom.2022.07.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning hidden topics from short text streams has become crucial in modern applications such as social networks, instant messages, question and answer forums, etc. Building an effective learning method poses two main challenges: Short and noisy data, as well as the stability-plasticity dilemma. In this paper, we investigate carefully how existing methods face these challenges. From our theoretical and empirical analyses, they often deal well with a challenge but ineffectively handle the other. In particular, they often suffer from catastrophic forgetting, because they impose a constraint on the learned knowledge from only the previous time step in the streaming duration. In this paper, we propose a novel method, namely BSP, which has a regularization term based on second-order Taylor expansion to accumulate information from all former minibatches. Moreover, external knowledge and Dropout technique will be combined at each time step to handle better short and noisy texts as well as enhance the model’s plasticity. We empirically evaluate BSP, compared to other state-of-the-art streaming methods in terms of dealing with stability-plasticity dilemma and handling short and noisy texts. The extensive experiments show superior effectiveness of BSP.},
  archive      = {J_NEUCOM},
  author       = {Tung Nguyen and Trung Mai and Nam Nguyen and Linh Ngo Van and Khoat Than},
  doi          = {10.1016/j.neucom.2022.07.019},
  journal      = {Neurocomputing},
  pages        = {30-43},
  shortjournal = {Neurocomputing},
  title        = {Balancing stability and plasticity when learning topic models from short and noisy text streams},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An underwater dam crack image segmentation method based on
multi-level adversarial transfer learning. <em>NEUCOM</em>,
<em>505</em>, 19–29. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crack detection is necessary to ensure the health of dams. Traditional detection methods perform poorly because of weak adaptability and poor image quality. Deep learning shows excellent performance in crack image detection. However, it is difficult to realize supervised learning due to the lack of labelled underwater crack image datasets. Thus, a transfer learning method named MA-AttUNet is proposed. The proposed method realizes knowledge transfer of crack image features using a multi-level adversarial transfer network. With this method, prior knowledge learned from the source domain can be applied to underwater crack image segmentation . Additionally, the attention mechanism is integrated into the segmentation network to eliminate noise interference during detection by assigning different weights to target and background pixels. Experiments show that the proposed method achieves higher segmentation precision than existing works.},
  archive      = {J_NEUCOM},
  author       = {Xinnan Fan and Pengfei Cao and Pengfei Shi and Xinyang Chen and Xuan Zhou and Qian Gong},
  doi          = {10.1016/j.neucom.2022.07.036},
  journal      = {Neurocomputing},
  pages        = {19-29},
  shortjournal = {Neurocomputing},
  title        = {An underwater dam crack image segmentation method based on multi-level adversarial transfer learning},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Dynamic power allocation in IIoT based on multi-agent deep
reinforcement learning. <em>NEUCOM</em>, <em>505</em>, 10–18. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapidly growing fifth generation (5G) wireless data traffic, the cellular network has gradually become an important mode for the Industrial Internet of Things (IIoT). To give full play to the advantages of cellular network , it is desirable to design the optimal allocation strategy under the condition of limited network resources. In this paper, we consider the problem of allocating downlink power to mobile IIoT devices based on multi-agent deep reinforcement learning (MADRL). To maximize the total system capacity, each base station (BS)-user device (UE) is modeled as a RL agent to learn optimal allocation policy. A centralized training and distributed execution learning framework is proposed, the influence of parameter transmission delay on allocation policy is considered. The designed state space and reward function can adapt to large-scale networks on account of their expandability. Simulation results show the effectiveness and superiority of the proposed method in terms of the system sum rate .},
  archive      = {J_NEUCOM},
  author       = {Fenglei Li and Zhixin Liu and Xinzhe Zhang and Yi Yang},
  doi          = {10.1016/j.neucom.2022.07.007},
  journal      = {Neurocomputing},
  pages        = {10-18},
  shortjournal = {Neurocomputing},
  title        = {Dynamic power allocation in IIoT based on multi-agent deep reinforcement learning},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving 2D object detection with binocular images for
outdoor surveillance. <em>NEUCOM</em>, <em>505</em>, 1–9. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting objects and providing their 2D information (e.g., size and center) are crucial for outdoor visual surveillance. Because the cameras are static and their distances to background are fixed in the scenario of surveillance, we argue that, compared to 3D object detection , 2D object detection is usually enough in visual surveillance. To a great extent, determining the existence of objects is more important than determining their precise 3D shapes and locations. In the field of visual surveillance, almost all methods employ a single camera (or independently employing several cameras) to determine the existence and 2D information of objects. In this paper, we propose to improve the performance of the 2D object detection by binocular cameras (images) for the scenario of outdoor surveillance where RGB-D and depth cameras are not applicable due to their low resolutions and high expense. In the proposed binocular-image based 2D object detection framework, most of existing monocular-image based 2D object detection modules can be integrated in. Once integrated in the proposed framework, the object detection accuracy can significantly and consistently be improved. Experimental results on the challenging datasets of Cityscapes and KITTI demonstrate the superiority of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Fuchen Chu and Yanwei Pang and Jiale Cao and Jing Nie and Xuelong Li},
  doi          = {10.1016/j.neucom.2022.07.039},
  journal      = {Neurocomputing},
  pages        = {1-9},
  shortjournal = {Neurocomputing},
  title        = {Improving 2D object detection with binocular images for outdoor surveillance},
  volume       = {505},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive dynamic programming-based visual servoing control
for quadrotor. <em>NEUCOM</em>, <em>504</em>, 251–261. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of image-based visual servoing (IBVS) control for quadrotor is addressed by developing an adaptive dynamic programming (ADP) method. The perspective projection model and image moment feature are used to derive the quadrotor-image dynamic model. By dividing the model into three subsystems, the effective subsystem controllers are designed to make the quadrotor complete the visual servoing task. The height subsystem control is designed with backstepping method and the yaw subsystem control design is based on a direct control method . The lateral subsystem is a time-varying system with input constraints and an ADP-based control is developed. The existence of time-varying terms results in the time-varying Hamilton–Jacobi-Bellman (HJB) equation, which implies the analytic solution is unable to obtain. Thus, the ADP-based IBVS control method is developed by utilizing a critic neural network structure to approximate the time-dependent value function of the HJB equation. It is proved that the ADP method guarantees that the closed-loop system and the estimation error weights are uniformly ultimately bounded. The experimental results demonstrate the effectiveness of the developed ADP-based IBVS control method.},
  archive      = {J_NEUCOM},
  author       = {Xinning Yi and Biao Luo and Yuqian Zhao},
  doi          = {10.1016/j.neucom.2022.06.110},
  journal      = {Neurocomputing},
  pages        = {251-261},
  shortjournal = {Neurocomputing},
  title        = {Adaptive dynamic programming-based visual servoing control for quadrotor},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Progressive representation recalibration for lightweight
super-resolution. <em>NEUCOM</em>, <em>504</em>, 240–250. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the lightweight single-image super-resolution (SISR) task has received increasing attention due to the computational complexities and sizes of convolutional neural network (CNN)-based SISR models and the explosive demand in applications on resource-limited edge devices. Current algorithms reduce the number of layers and channels in CNNs to obtain lightweight models for this task. However, these algorithms may reduce the representation ability of the learned features due to information loss, inevitably leading to poor performance. In this work, we propose the progressive representation recalibration network (PRRN), a new lightweight SISR network to learn complete and representative feature representations. Specifically, a progressive representation recalibration block (PRRB) is developed to extract useful features from pixel and channel spaces in a two-stage approach. In the first stage, PRRB utilizes pixel and channel information to explore important feature regions. In the second stage, channel attention is further used to adjust the distribution of important feature channels. In addition, current channel attention mechanisms utilize nonlinear operations that may lead to information loss. In contrast, we design a shallow channel attention (SCA) mechanism that can learn the importance of each channel in a simpler yet more efficient way. Extensive experiments demonstrate the superiority of the proposed PRRN.},
  archive      = {J_NEUCOM},
  author       = {Ruimian Wen and Zhijing Yang and Tianshui Chen and Hao Li and Kai Li},
  doi          = {10.1016/j.neucom.2022.07.050},
  journal      = {Neurocomputing},
  pages        = {240-250},
  shortjournal = {Neurocomputing},
  title        = {Progressive representation recalibration for lightweight super-resolution},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Applicable artificial intelligence for brain disease: A
survey. <em>NEUCOM</em>, <em>504</em>, 223–239. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain diseases threaten hundreds of thousands of people over the world. Medical imaging techniques such as MRI and CT are employed for various brain disease studies. As artificial intelligence succeeded in image analysis, scientists employed artificial intelligence, especially deep learning technologies, to assist brain disease studies. The AI applications for brain disease studies can be divided into two categories. The first category is preprocessing, including denoising, registration, skull-stripping, intensity normalization, and data augmentation. The second category is the clinical application that contains lesion segmentation, disease detection, grade classification, and outcome prediction. In this survey, we reviewed over one hundred representative papers on how to apply AI to brain disease studies. We first introduced AI-based preprocessing for brain disease studies. Second, we reviewed the influential works of AI-based brain disease studies. At last, we also discussed three development trends in the future. We hope this survey will inspire both expert-level researchers and entry-level beginners.},
  archive      = {J_NEUCOM},
  author       = {Chenxi Huang and Jian Wang and Shui-Hua Wang and Yu-Dong Zhang},
  doi          = {10.1016/j.neucom.2022.07.005},
  journal      = {Neurocomputing},
  pages        = {223-239},
  shortjournal = {Neurocomputing},
  title        = {Applicable artificial intelligence for brain disease: A survey},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An end-to-end heterogeneous network for graph similarity
learning. <em>NEUCOM</em>, <em>504</em>, 210–222. (<a
href="https://doi.org/10.1016/j.neucom.2022.07.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the similarity learning methods used in many deep models can only capture the local context relations among samples in small cliques (e.g. pairs and triplets), so it is difficult to construct and leverage their latent global correlations to further boost the learning of discriminant features. To this end, we propose a novel end-to-end heterogeneous network , in which a global correlation inference model is adopted to induce the learning of a feature embedding model. Specifically, we design an intersection graph structure to build local context similarity for each sample. Then, taking the learned feature embeddings as nodes, the connection relationship between all nodes is computed through the global correlation inference model. Meanwhile, by combining two loss functions it can feedback the global connection information to push the discriminant learning of the feature embedding model. Consequently, both parts of the proposed heterogeneous network can be optimized from each other during deep similarity learning. The extensive ablation studies and comparative experimental results demonstrate that each component is effective and the whole network is competitive.},
  archive      = {J_NEUCOM},
  author       = {Yan Huang and Jing Huang and Xiaoqiang Chen and Qicong Wang and Hongying Meng},
  doi          = {10.1016/j.neucom.2022.07.001},
  journal      = {Neurocomputing},
  pages        = {210-222},
  shortjournal = {Neurocomputing},
  title        = {An end-to-end heterogeneous network for graph similarity learning},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PyBNesian: An extensible python package for bayesian
networks. <em>NEUCOM</em>, <em>504</em>, 204–209. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian networks are probabilistic graphical models that are commonly used to represent the uncertainty in data. The PyBNesian package provides an implementation for many different types of Bayesian network models and some variants, such as conditional Bayesian networks and dynamic Bayesian networks. In addition, the package can be easily extended with new components that can interoperate with those already implemented. Furthermore, the package also implements other related models such as kernel density estimation using OpenCL 1.2+ to enable GPU acceleration. PyBNesian is totally free and open-source under the MIT license.},
  archive      = {J_NEUCOM},
  author       = {David Atienza and Concha Bielza and Pedro Larrañaga},
  doi          = {10.1016/j.neucom.2022.06.112},
  journal      = {Neurocomputing},
  pages        = {204-209},
  shortjournal = {Neurocomputing},
  title        = {PyBNesian: An extensible python package for bayesian networks},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient hyperspectral image segmentation for biosecurity
scanning using knowledge distillation from multi-head teacher.
<em>NEUCOM</em>, <em>504</em>, 189–203. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foreign species can deteriorate the environment and the economy of a country. To automatically monitor biosecurity threats at country borders, this paper investigates compact deep networks for accurate and real-time object segmentation for hyperspectral images . To this end, knowledge distillation (KD) approaches compress the model by distilling the knowledge of a large teacher network to a compact student network. However, when the student is over-compressed, the performance of standard KD methods degrades significantly due to the large capacity gap between the teacher and the student. This gap can be addressed by adding medium-sized teacher assistants, but training them incurs significant computation and hence is impractical. To address this problem, this paper proposes a new framework called Knowledge Distillation from Multi-head Teacher (KDM), which distills the knowledge of a multi-head teacher to the student. By encapsulating multiple teachers in a single network, our proposed KDM assists the learning of a very compact student and significantly reduces the training time. We also introduce Bio-HSI, a new large benchmark hyperspectral image dataset of 3,125 high-resolution images with dense segmentation ground truth. This new, large dataset can be expected to advance research on deep models for hyperspectral image segmentation. Evaluated on this dataset, the student trained via our KDM has 762 times fewer parameters than the state-of-the-art segmentation model (i.e., HRNet), while achieving competitive accuracy.},
  archive      = {J_NEUCOM},
  author       = {Minh Hieu Phan and Son Lam Phung and Khoa Luu and Abdesselam Bouzerdoum},
  doi          = {10.1016/j.neucom.2022.06.095},
  journal      = {Neurocomputing},
  pages        = {189-203},
  shortjournal = {Neurocomputing},
  title        = {Efficient hyperspectral image segmentation for biosecurity scanning using knowledge distillation from multi-head teacher},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue SOCO 2020: New trends in soft computing and
its application in industrial and environmental problems.
<em>NEUCOM</em>, <em>504</em>, 187–188. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The seven papers included in this special issue represent a selection of extended contributions presented at the 15th International Conference on Soft Computing Models in Industrial and Environmental Applications, SOCO 2020, held in Burgos, Spain, September 2020, and organized by University of Burgos and BISITE and GICAP Research Groups. SOCO 2020 international conference represents a collection or set of computational techniques in machine learning, computer science and some engineering disciplines which investigate, simulate, and analyse very complex issues and phenomena. This special issue is aimed at practitioners, researchers and postgraduate students who are engaged in developing and applying advanced intelligent systems principles to solving real-world problems on the mentioned fields.},
  archive      = {J_NEUCOM},
  author       = {Javier Sedano and Daniel Urda and José Luis Calvo-Rolle and Héctor Quintián and Emilio Corchado},
  doi          = {10.1016/j.neucom.2022.06.078},
  journal      = {Neurocomputing},
  pages        = {187-188},
  shortjournal = {Neurocomputing},
  title        = {Special issue SOCO 2020: New trends in soft computing and its application in industrial and environmental problems},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Apeak-CG: Automatically predicting emotion based dynamic
multi-form knowledge fusion conversation generation. <em>NEUCOM</em>,
<em>504</em>, 174–186. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-turn conversations commonly face the challenges of adequately expressing emotions and enriching or expanding the content of the dialogues. The existing knowledge-based dialogue model can not avoid the problem of too rational response or ignoring appropriate expression of emotion. However, the precise emotions of one conversational bot are crucial to improve user satisfaction. In our work, we design an auto-emotion prediction for a chatting machine that considers six common fine-grained emotions and automatically assigns corresponding emotion for responses according to historical emotion lines and contexts. Moreover, we creatively fuse the multi-forms of knowledge dynamically to improve the response information, which can take advantage of both abundant unstructured latent knowledge in the documents and the information expansion capabilities of the structured knowledge graph. Notably, in the aspect of unstructured knowledge, a novel virtual knowledge base is constructed and a new delay updating algorithm is proposed. We present a new dialogue generation model, A utomatically p redicting e motion based dyn a mic multi-form k nowledge fusion C onversation G eneration ( Apeak-CG ). Both automatic and human evaluation results indicate the effectiveness of our method in terms of emotional coherence and informativeness.},
  archive      = {J_NEUCOM},
  author       = {Feifei Xu and Shanlin Zhou and Xinpeng Wang and Wenkai Zhang},
  doi          = {10.1016/j.neucom.2022.06.105},
  journal      = {Neurocomputing},
  pages        = {174-186},
  shortjournal = {Neurocomputing},
  title        = {Apeak-CG: Automatically predicting emotion based dynamic multi-form knowledge fusion conversation generation},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Qauxi: Cooperative multi-agent reinforcement learning with
knowledge transferred from auxiliary task. <em>NEUCOM</em>,
<em>504</em>, 163–173. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep multi-agent reinforcement learning (MARL) can efficiently learn decentralized policies for real-world applications. However, current MARL methods suffer from the difficulty of transferring knowledge from already learned tasks to improve its exploration. In this paper, we propose a novel MARL method called Qauxi , which forms coordinated exploration scheme to improve the traditional MARL algorithms by reusing the meta-experience transferred from auxi liary task. We also use the weighting function to weight the importance of the joint action in monotonic loss function in order to focus on more important joint actions and thus avoid yielding suboptimal policies. Furthermore, we prove the convergence of Qauxi based on contraction mapping theorem. Qauxi is evaluated on the widely adopted StarCraft benchmarks (SMAC) across easy, hard, and super hard scenarios. Experimental results show that the proposed method outperforms the state-of-the-art MARL methods by a large margin in the most challenging super hard scenarios.},
  archive      = {J_NEUCOM},
  author       = {Wenqian Liang and Ji Wang and Weidong Bao and Xiaomin Zhu and Guanlin Wu and Dayu Zhang and Liyuan Niu},
  doi          = {10.1016/j.neucom.2022.06.091},
  journal      = {Neurocomputing},
  pages        = {163-173},
  shortjournal = {Neurocomputing},
  title        = {Qauxi: Cooperative multi-agent reinforcement learning with knowledge transferred from auxiliary task},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Doubly stochastic scaling unifies community detection.
<em>NEUCOM</em>, <em>504</em>, 141–162. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph partitioning , or community detection, has been widely investigated in network science. Yet, the correct community structure on a given network is essentially data-driven. Thus, instead of a formal definition, diverse measures have been conceived to capture intuitive desirable properties shared by most of the community structures. In this work, we propose a preprocessing based on a doubly stochastic scaling of network adjacency matrices , to highlight these desirable properties. By investigating a range of community detection measures, and carefully generalising them to doubly stochastic graphs, we show that such a scaling unifies a whole category of these measures—namely, the so-called linear criteria—onto two unique measures to set up. Finally, to help practitioners setting up these measures, we provide an extensive numerical comparison of the capacity of these measures to uncover community structures within stochastic block models, using the Louvain algorithm.},
  archive      = {J_NEUCOM},
  author       = {Luce Le Gorrec and Sandrine Mouysset and Daniel Ruiz},
  doi          = {10.1016/j.neucom.2022.06.090},
  journal      = {Neurocomputing},
  pages        = {141-162},
  shortjournal = {Neurocomputing},
  title        = {Doubly stochastic scaling unifies community detection},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive neural networks optimal control of permanent magnet
synchronous motor system with state constraints. <em>NEUCOM</em>,
<em>504</em>, 132–140. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates an adaptive neural network (NN) optimal control problem for a permanent magnet synchronous motor (PMSM) system. The addressed PMSM system contains unknown nonlinear dynamics and constraint states. The neural networks (NNs) are employed to identify the unknown nonlinear dynamics and by constructing barrier performance index functions and barrier Lyapunov functions , an adaptive NN optimal control method is developed under the framework of the actor-critic architecture and backstepping control technique. It is proved that the presented optimal control strategy can not only ensure the closed-loop system stable, but also guarantee the angular velocity , stator current and other state variables of PMSM are within given bounds. Furthermore, it can minimize the performance index functions. The effectiveness of the developed NN adaptive optimal controller is verified by computer simulation results.},
  archive      = {J_NEUCOM},
  author       = {Sihui Zhou and Shuai Sui and Shaocheng Tong},
  doi          = {10.1016/j.neucom.2022.06.114},
  journal      = {Neurocomputing},
  pages        = {132-140},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural networks optimal control of permanent magnet synchronous motor system with state constraints},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to predict diverse trajectory from human motion
patterns. <em>NEUCOM</em>, <em>504</em>, 123–131. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diverse and reasonable multi-modal trajectory prediction of pedestrian is vital for the safety of intelligent autonomous systems . Currently, most of existing methods primarily focus on modeling the extrinsic interactions of pedestrians, but neglect to take advantage of the intrinsic properties of pedestrian motion, which may generate unrealistic pedestrian movement. We investigate the natural motion of pedestrians and explore future motion patterns of pedestrians with similar observed trajectories , which provides a new perspective for multi-modal prediction of pedestrian trajectories. On this basis, we propose a novel model to learn diverse trajectories from human motion patterns, which is mainly composed of a motion pattern selector and a multi-modal trajectory generator. With a constructed pattern gallery, the motion pattern selector mines the possible future motion patterns based on the similar observed trajectories . Subsequently, the diverse future motion patterns are fed into the multi-modal trajectory generator, in which these motion patterns are selected and refined through a scoring network and a regression network, and then directly generate multiple diverse trajectories. We use two public pedestrian trajectory ETH/UCY datasets to compare our method with several baseline methods . Experimental results show that our model outperforms most of the state-of-the-art approaches both in accuracy and diversity by fully leveraging the intrinsic information of trajectories.},
  archive      = {J_NEUCOM},
  author       = {Miao Kang and Jingwen Fu and Sanping Zhou and Songyi Zhang and Nanning Zheng},
  doi          = {10.1016/j.neucom.2022.06.115},
  journal      = {Neurocomputing},
  pages        = {123-131},
  shortjournal = {Neurocomputing},
  title        = {Learning to predict diverse trajectory from human motion patterns},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Event-triggered impulsive synchronization of coupled delayed
memristive neural networks under dynamic and static conditions.
<em>NEUCOM</em>, <em>504</em>, 109–122. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to address the exponential synchronization issue of coupled delayed memristive neural networks (CDMNNs) via event-triggered impulsive control (ETIC). To do this, a fresh controller based on the hybrid state feedback and impulsive effects is devised to efficiently lessen the communication load and economic cost. Then, the event-triggered conditions for two types of strategies including static event-triggered impulsive control (SETIC) and dynamic event-triggered impulsive control (DETIC) are presented. Furthermore, some algebraic criteria are derived to synchronize the CDMNNs by utilizing the Lyapunov method, the interval matrix method and impulsive system theory. Moreover, it can be guaranteed that the Zeno phenomenon does not emerge. Ultimately, the availability and feasibility of the propounded scheme are substantiated through an illustrated instance.},
  archive      = {J_NEUCOM},
  author       = {Lirong Liu and Haibo Bao},
  doi          = {10.1016/j.neucom.2022.06.098},
  journal      = {Neurocomputing},
  pages        = {109-122},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered impulsive synchronization of coupled delayed memristive neural networks under dynamic and static conditions},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RMDC: Rotation-mask deformable convolution for object
detection in top-view fisheye cameras. <em>NEUCOM</em>, <em>504</em>,
99–108. (<a href="https://doi.org/10.1016/j.neucom.2022.06.116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in top-view fisheye cameras is more difficult than standard cameras. This article summarizes the issues regarding object detection accuracy in top-view fisheye cameras into two challenges: Rotation and Distortion. There is a lack of methods to deal with both challenges simultaneously. To solve this problem, we propose the Rotation-Mask Deformable Convolution, named RMDC, which rotates convolution filters adaptively and introduces the Center-Fixed Deformable Convolution. The RMDC improves the learning ability of the convolution kernels for rotated objects in top-view fisheye images and addresses the spatial distortion problem. The effectiveness of the RMDC is verified on the SEU-fisheye which contains 10233 top-view fisheye images and annotates 127053 people. Finally, we confirm the optimal network structure in the baseline with the RMDC.},
  archive      = {J_NEUCOM},
  author       = {Xuan Wei and Yun Wei and Xiaobo Lu},
  doi          = {10.1016/j.neucom.2022.06.116},
  journal      = {Neurocomputing},
  pages        = {99-108},
  shortjournal = {Neurocomputing},
  title        = {RMDC: Rotation-mask deformable convolution for object detection in top-view fisheye cameras},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monogenic features based single sample face recognition by
kernel sparse representation on multiple riemannian manifolds.
<em>NEUCOM</em>, <em>504</em>, 82–98. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel method for single sample face recognition, characterized by the use of grayscale monogenic features of the face images, and the kernel sparse representation on multiple Riemannian manifolds. To indicate regional face discriminability , the multi-scale extended monogenic features are firstly locally extracted from different regions of an image, according to a specific face partition scheme, and then the intrinsic subspace of the feature vector set corresponding to each region is further extracted and modeled as a point of a Grassmann manifold. The congeneric local feature scheme is also exploited to entire image for the extraction of co-occurrence distributions of the grouped feature images of intersectional dimensions, based on a special binarization scheme applied to the resultant feature images . This derives the auxiliary marginal distribution-based descriptors residing on the closures of multiple multinomial manifolds. To train the kernel sparse representation classifier using the combined descriptors for a recognition task, the strategy of kernel alignment combining column L 2 -norm-based kernel matrix normalization are adopted for multiple kernel fusion, where the used kernels are all derived from Riemannian geometries of two types of manifolds. The superiority of our method is demonstrated through extensive experiments.},
  archive      = {J_NEUCOM},
  author       = {Jian Zou and Yue Zhang and Hongjian Liu and Lifeng Ma},
  doi          = {10.1016/j.neucom.2022.06.113},
  journal      = {Neurocomputing},
  pages        = {82-98},
  shortjournal = {Neurocomputing},
  title        = {Monogenic features based single sample face recognition by kernel sparse representation on multiple riemannian manifolds},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mutual ensemble learning for brain tumor segmentation.
<em>NEUCOM</em>, <em>504</em>, 68–81. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is challenging to reduce the generalization errors of brain tumor segmentation models on test data, as the nature of the high diversity of tumors. The model ensemble combining multiple models to make the final prediction is a reliable strategy to reduce generalization errors. Conventionally, these models that acted as member networks of the ensemble are trained separately. Each member network is trained independently on a data subset or a single perspective of 3D brain volumes. To enable each member network to be trained on the complete training dataset as well as 3D images, we propose a mutual learning method to mutually train multiple 3D segmentation networks of the ensemble, called mutual ensemble learning (MEL). Mutual learning can enable knowledge exchange between networks and let them teach each other during the training process so that each member can converge to a better local minimum compared with when trained separately. Meanwhile, mutual learning also keeps the partially independent errors made by different member networks, and combining these member networks can reduce overall errors on the test set. In a word, combining these stronger members gives better ensemble results and it would not bring more cost in the test stage. To realize the mutual learning of multiple 3D brain tumor segmentation networks, we introduce a novel loss called Consensus Dice loss to explicitly exchange information among different networks during training. This loss considers the overlap of prediction probabilities by multiple networks and ground truth to enhance the overlapping pixels’ probabilities. Extensive experiments are conducted on the brain tumor segmentation, i.e., BRATS 2015 and 2018 datasets. Results on the databases indicate that the proposed approach consistently improves the segmentation performance of the baseline network. Furthermore, our proposed method achieves state-of-the-art performance on the BRATS 2018 online validation set, and it is flexible to be extended by diverse homogeneous and heterogeneous state-of-the-art networks.},
  archive      = {J_NEUCOM},
  author       = {Jingyu Hu and Xiaojing Gu and Xingsheng Gu},
  doi          = {10.1016/j.neucom.2022.06.058},
  journal      = {Neurocomputing},
  pages        = {68-81},
  shortjournal = {Neurocomputing},
  title        = {Mutual ensemble learning for brain tumor segmentation},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-step prediction of photovoltaic power based on
two-stage decomposition and BILSTM. <em>NEUCOM</em>, <em>504</em>,
56–67. (<a href="https://doi.org/10.1016/j.neucom.2022.06.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate photovoltaic power forecasting is crucial for power dispatch planning, maintenance scheduling and regulation. In this paper, a hybrid photovoltaic power forecasting model is proposed based on two-stage decomposition, correlation heatmap and bidirectional long-short term memory network. Firstly, appropriate model input is selected from meteorological factors through correlation heatmap. Seconldly, the original time series is decomposed into a series of intrinsic mode functions with different characteristics via using ensemble empirical mode decomposition , and then the first subsequence of the intrinsic mode functions is further decomposed by variational mode decomposition. Thirdly, bidirectional long-short term memory network is utilized to extract the relationship between photovoltaic power sequences and environmental factors, and obtain the prediction results of each subsequences, then the eventual predicted results are obtained by reconstructing the predicted values of each subsequences. The result of example analysis shows that the proposed prediction model is superior to other algorithms in accuracy, which has great prospects in the development of photovoltaic power prediction.},
  archive      = {J_NEUCOM},
  author       = {Wenshuai Lin and Bin Zhang and Hongyi Li and Renquan Lu},
  doi          = {10.1016/j.neucom.2022.06.117},
  journal      = {Neurocomputing},
  pages        = {56-67},
  shortjournal = {Neurocomputing},
  title        = {Multi-step prediction of photovoltaic power based on two-stage decomposition and BILSTM},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inductive-transductive learning for very sparse fashion
graphs. <em>NEUCOM</em>, <em>504</em>, 42–55. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assortments of global retailers are composed of hundreds of thousands of products linked by several types of relationships such as style compatibility, “bought together”, “watched together”, etc. Graphs are a natural representation for assortments, where products are nodes and relations are edges. Style compatibility relations are produced manually and do not cover the whole graph uniformly. We propose to use inductive learning to enhance a graph encoding style compatibility of a fashion assortment, leveraging rich node information comprising textual descriptions and visual data. Then, we show how the proposed graph enhancement substantially improves the performance on transductive tasks with a minor impact on graph sparsity . Although demonstrated in a challenging and novel industrial application case, the approach we propose is general enough to be applied to any node-level or edge-level prediction task in very sparse, large-scale networks.},
  archive      = {J_NEUCOM},
  author       = {Haris Dukic and Shahab Mokarizadeh and Georgios Deligiorgis and Pierpaolo Sepe and Davide Bacciu and Marco Trincavelli},
  doi          = {10.1016/j.neucom.2022.06.050},
  journal      = {Neurocomputing},
  pages        = {42-55},
  shortjournal = {Neurocomputing},
  title        = {Inductive-transductive learning for very sparse fashion graphs},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Superdense-scale network for semantic segmentation.
<em>NEUCOM</em>, <em>504</em>, 30–41. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Great progress has been made in semantic segmentation based on deep convolutional neural networks . However, semantic segmentation in complex scenes remains challenging due to the large-scale variation problem. To handle this problem, the existing methods usually employ multiple receptive fields to capture multiscale features. Some works have verified that the denser the different receptive fields (scales), the easier it is to address the large-scale variation problem. To make denser scales, we propose a superdense-scale network (SDSNet). Specifically, we design a simple yet effective structure named the parallel-serial structure of atrous convolutions (PSSAC) in which superdense-scale high-level features are captured by explicitly adjusting the neuron’s receptive field. The PSSAC is an improvement over ASPP and DenseASPP by employing exponentially increasing scales with a serially connected multiple parallel structure. To extract more accurate features, we construct an SDSNet consisting of a modified aligned Xcepiton71 backbone followed by a PSSAC. Extensive experiments of semantic segmentation are conducted to evaluate our SDSNet on three datasets, namely, Cityscapes, PASCAL VOC 2012, and ADE20K. Experimental results show that our SDSNet achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Zhiqiang Li and Jie Jiang and Xi Chen and Honggang Qi and Qingli Li and Jiapeng Liu and Laiwen Zheng and Min Liu and Yundong Zhang},
  doi          = {10.1016/j.neucom.2022.06.103},
  journal      = {Neurocomputing},
  pages        = {30-41},
  shortjournal = {Neurocomputing},
  title        = {Superdense-scale network for semantic segmentation},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MLFNet: Monocular lifting fusion network for 6DoF
texture-less object pose estimation. <em>NEUCOM</em>, <em>504</em>,
16–29. (<a href="https://doi.org/10.1016/j.neucom.2022.06.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenge of 6DoF texture-less object pose estimation from a single RGB image . Many recent works have shown that two-stage deep learning approaches based on the fusion of 2D geometric intermediate representations achieve remarkable results. These methods implicitly explore the mapping from the 2D appearance domain to the 3D structure domain. However, due to the lack of 3D geometric constraints from depth maps, it is difficult to extract enough clues based on appearance features to master the geometric relation of projection from 3D viewpoints to 2D planes, and this estimation process is extremely sensitive to occlusion. We propose a novel network called MLFNet that lifts the feature space from 2D to 3D based on hybrid 3D geometric intermediate representations. For the first time, we propose the surface normals in the object coordinate system as an intermediate representation of pose; its violent change provides strong clues for the keypoints usually located at the abrupt change of object surface. Dense 3D surfaces can enhance the geometric consistency of multi-representation constraints and retain more information in occluded scenes. With the proposed multi-modality dual attention mechanism and the embedding of standard 3D shape knowledge, the 2D geometric representation learning process explicitly depends on the fusion of 2D appearance features and 3D geometric features. This standardized information fusion pattern among 2D intermediate representations, 3D intermediate representations, and CAD models prior significantly reduces the network learning space. The proposed method achieves competitive performance on the Linemod dataset and outperforms the state-of-the-art methods on the Occlusion Linemod and T-Less datasets, which demonstrates the feasibility of the pose multi-representation fusion technique. The project site is at https://github.com/JJJano/MLFNet .},
  archive      = {J_NEUCOM},
  author       = {Junjie Jiang and Zaixing He and Xinyue Zhao and Shuyou Zhang and Chenrui Wu and Yang Wang},
  doi          = {10.1016/j.neucom.2022.06.096},
  journal      = {Neurocomputing},
  pages        = {16-29},
  shortjournal = {Neurocomputing},
  title        = {MLFNet: Monocular lifting fusion network for 6DoF texture-less object pose estimation},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). A hierarchical attention network for stock prediction based
on attentive multi-view news learning. <em>NEUCOM</em>, <em>504</em>,
1–15. (<a href="https://doi.org/10.1016/j.neucom.2022.06.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock prediction with news released on media platform is helpful for investors to make good investment decisions. Recent researches are generally based on single news view, e.g., headline or body, as a predictive indicator and thus information received is insufficient or incomplete which also lacks of study on market information, then bring low performances of models. In this research, we propose a hierarchical attention network based on attentive multi-view news learning (NMNL) to excavate more useful information from news and the stock market for stock prediction. The core of our approach is a news encoder and a market information encoder. In the news encoder, we learn multi-view news information representation from news headlines, bodies and sentiments by regarding them as three independent parts. We find that the combination of headline, body and sentiment outperforms conventional models on single news view. In the market information encoder, we employ the attention mechanism to capture pivotal news information and combine technical indicators to represent representative market information. In addition, a temporal auxiliary based on Bi-directional Long Short-Term Memory (Bi-LSTM) model is used to generate the contextual market information for stock prediction. Extensive experiments demonstrate the superiority of NMNL, which outperforms state-of-the-art stock prediction solutions.},
  archive      = {J_NEUCOM},
  author       = {Xingtong Chen and Xiang Ma and Hua Wang and Xuemei Li and Caiming Zhang},
  doi          = {10.1016/j.neucom.2022.06.106},
  journal      = {Neurocomputing},
  pages        = {1-15},
  shortjournal = {Neurocomputing},
  title        = {A hierarchical attention network for stock prediction based on attentive multi-view news learning},
  volume       = {504},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simulated annealing-based dynamic step shuffled frog leaping
algorithm: Optimal performance design and feature selection.
<em>NEUCOM</em>, <em>503</em>, 325–362. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shuffled frog leaping algorithm is a new optimization algorithm proposed to solve the combinatorial optimization problem, which effectively combines the memetic algorithm based on a memetic algorithm and the particle swarm algorithm based on population behavior. The algorithm is widely used because it is easy to implement and requires few parameters to be adjusted. However, there are still some characteristics of this method that need to be improved because it is easy to fall into local optimization or poor search ability. To alleviate this limitation, a new version of the improved SFLA is proposed in this paper, which incorporates a dynamic step size adjustment strategy based on historical information, a specular reflection learning mechanism, and a simulated annealing mechanism based on chaotic mapping and levy flight. Firstly, the dynamic step size adjustment strategy based on historical information effectively helps to balance local exploration and global exploitation and alleviates the problem of falling into local optimum. Second, the specular reflection learning mechanism increases the possibility of searching for valid solutions in feasible domains and enhances the search ability of individuals in the population. Finally, an improved simulated annealing strategy is executed for each memetic, which improves the efficiency of local exploitation. In order to test the performance of the proposed algorithm, 31 test functions were selected from IEEE CEC2014 and 23 essential benchmark functions, and comparative experiments were carried out from the two dimensions of 30 and 100. Furthermore, a series of competing algorithms are selected, which involve nine classical standard algorithms, including PSO, BA, SSA, FA, SCA, WOA, GWO, MFO, and SFLA, as well as, six well-known improved algorithms, including LSFLA, DDSFLA, GOTLBO, ALCPSO, BLPSO, CLPSO. Furthermore, Wilcoxon signed-rank test and Friedman test are used as testing tools to illustrate the scalability of the proposed algorithm. From the analysis of the results, it can be seen that this proposed method has been effectively improved concerning stability and the quality of the optimal solution obtained from the search, both in low and high dimensions, and the ability to jump out of the local optimum has also been enhanced. In addition, to prove that this method has a reliable performance in discrete problems and continuous problems, DSSRLFLA is mapped into a discrete space, and 24 UCI data sets are also selected to evaluate the performance of the new feature selection method. The experimental results illustrate that this improved method can obtain fewer features and higher classification accuracy than some well-known feature selection methods.},
  archive      = {J_NEUCOM},
  author       = {Yun Liu and Ali Asghar Heidari and Zhennao Cai and Guoxi Liang and Huiling Chen and Zhifang Pan and Abdulmajeed Alsufyani and Sami Bourouis},
  doi          = {10.1016/j.neucom.2022.06.075},
  journal      = {Neurocomputing},
  pages        = {325-362},
  shortjournal = {Neurocomputing},
  title        = {Simulated annealing-based dynamic step shuffled frog leaping algorithm: Optimal performance design and feature selection},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A semi-supervised learning approach for COVID-19 detection
from chest CT scans. <em>NEUCOM</em>, <em>503</em>, 314–324. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 has spread rapidly all over the world and has infected more than 200 countries and regions. Early screening of suspected infected patients is essential for preventing and combating COVID-19. Computed Tomography (CT) is a fast and efficient tool which can quickly provide chest scan results. To reduce the burden on doctors of reading CTs, in this article, a high precision diagnosis algorithm of COVID-19 from chest CTs is designed for intelligent diagnosis. A semi-supervised learning approach is developed to solve the problem when only small amount of labelled data is available. While following the MixMatch rules to conduct sophisticated data augmentation, we introduce a model training technique to reduce the risk of model over-fitting. At the same time, a new data enhancement method is proposed to modify the regularization term in MixMatch. To further enhance the generalization of the model, a convolutional neural network based on an attention mechanism is then developed that enables to extract multi-scale features on CT scans. The proposed algorithm is evaluated on an independent CT dataset of the chest from COVID-19 and achieves the area under the receiver operating characteristic curve (AUC) value of 0.932, accuracy of 90.1\%, sensitivity of 91.4\%, specificity of 88.9\%, and F1-score of 89.9\%. The results show that the proposed algorithm can accurately diagnose whether a chest CT belongs to a positive or negative indication of COVID-19, and can help doctors to diagnose rapidly in the early stages of a COVID-19 outbreak.},
  archive      = {J_NEUCOM},
  author       = {Yong Zhang and Li Su and Zhenxing Liu and Wei Tan and Yinuo Jiang and Cheng Cheng},
  doi          = {10.1016/j.neucom.2022.06.076},
  journal      = {Neurocomputing},
  pages        = {314-324},
  shortjournal = {Neurocomputing},
  title        = {A semi-supervised learning approach for COVID-19 detection from chest CT scans},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022d). Optimal echo state network parameters based on behavioural
spaces. <em>NEUCOM</em>, <em>503</em>, 299–313. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quantitative analysis of neural networks is a critical issue to improve performance. In this work, we extend the ideas of this adaptation method to the more commonly used behavioural spaces. The aim is to construct an echo state network (ESN) behavioural space through the generalization rank, kernel rank, and memory capacity. After deriving behavioural spaces, we investigate the influencing factors and methods of reducing the search complexity of behavioural spaces. This investigation reveals that the rule converges to the expected space distributions, even in a random ESN. We propose an optimization algorithm that adopts the novel search genetic algorithm (NSGA), which combines the novelty and quality of individuals. In the novel search process, because the time needed to construct the behaviour space is much lower than the network training time, the network optimization efficiency is greatly improved. According to the characteristics of the behaviour space distribution, we propose a method to shrink the search space to solve the problem of a large search space. This method overcomes the difficulties in traditional ESN parameter selection and the long optimization time of a genetic algorithm and provides behavioural space theory to clarify the influence of reservoir performance on tasks.},
  archive      = {J_NEUCOM},
  author       = {ZhaoZhao Zhang and YingQin Zhu and XiaoHui Wang and Wen Yu},
  doi          = {10.1016/j.neucom.2022.06.008},
  journal      = {Neurocomputing},
  pages        = {299-313},
  shortjournal = {Neurocomputing},
  title        = {Optimal echo state network parameters based on behavioural spaces},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Needle in a haystack: Spotting and recognising
micro-expressions “in the wild.” <em>NEUCOM</em>, <em>503</em>, 283–298.
(<a href="https://doi.org/10.1016/j.neucom.2022.06.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational research on facial micro-expressions has long focused on videos captured under constrained laboratory conditions due to the challenging elicitation process and limited samples that are publicly available. Moreover, processing micro-expressions is extremely challenging under unconstrained scenarios. This paper introduces, for the first time, a completely automatic micro-expression “spot-and-recognize” framework that is performed on in-the-wild videos, such as in poker games and political interviews. The proposed method first spots the apex frame from a video by handling head movements and unconscious actions which are typically larger in motion intensity, with alignment employed to enforce a canonical face pose. Optical flow guided features play a central role in our method: they can robustly identify the location of the apex frame, and are used to learn a shallow neural network model for emotion classification. Experimental results demonstrate the feasibility of the proposed methodology, establishing good baselines for both spotting and recognition tasks – ASR of 0.33 and F1-score of 0.6758 respectively on the MEVIEW micro-expression database. In addition, we present comprehensive qualitative and quantitative analyses to further show the effectiveness of the proposed framework, with new suggestion for an appropriate evaluation protocol. In a nutshell, this paper provides a new benchmark for apex spotting and emotion recognition in an in-the-wild setting.},
  archive      = {J_NEUCOM},
  author       = {Y.S. Gan and John See and Huai-Qian Khor and Kun-Hong Liu and Sze-Teng Liong},
  doi          = {10.1016/j.neucom.2022.06.101},
  journal      = {Neurocomputing},
  pages        = {283-298},
  shortjournal = {Neurocomputing},
  title        = {Needle in a haystack: Spotting and recognising micro-expressions “in the wild”},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Encrypted internet traffic classification using a supervised
spiking neural network. <em>NEUCOM</em>, <em>503</em>, 272–282. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet traffic recognition is essential for access providers since it helps them define adapted priorities in order to enhance user experience , e.g., a high priority for an audio conference and a low priority for a file transfer. As internet traffic becomes increasingly encrypted, the main classic traffic recognition technique, payload inspection , is rendered ineffective. Hence this paper uses machine learning techniques looking only at packet size and time of arrival. For the first time, Spiking neural networks (SNNs), which are inspired by biological neurons, were used for this task for two reasons. Firstly, they can recognize time-related data packet features. Secondly, they can be implemented efficiently on neuromorphic hardware. Here we used a simple feedforward SNN, with only one fully connected hidden layer, and trained in a supervised manner using the new method known as Surrogate Gradient Learning. Surprisingly, such a simple SNN reached an accuracy of 95.9\% on ISCX datasets, outperforming previous approaches. Besides better accuracy, there is also a significant improvement in simplicity: input size, the number of neurons, trainable parameters are all reduced by one to four orders of magnitude. Next, we analyzed the reasons for this good performance. It turns out that, beyond spatial (i.e., packet size) features, the SNN also exploits temporal ones, mainly the nearly synchronous (i.e., within a 200 ms range) arrival times of packets with specific sizes. Taken together, these results show that SNNs are an excellent fit for encrypted internet traffic classification : they can be more accurate than conventional artificial neural networks (ANN), and they could be implemented efficiently on low-power embedded systems.},
  archive      = {J_NEUCOM},
  author       = {Ali Rasteh and Florian Delpech and Carlos Aguilar-Melchor and Romain Zimmer and Saeed Bagheri Shouraki and Timothée Masquelier},
  doi          = {10.1016/j.neucom.2022.06.055},
  journal      = {Neurocomputing},
  pages        = {272-282},
  shortjournal = {Neurocomputing},
  title        = {Encrypted internet traffic classification using a supervised spiking neural network},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent advances on image edge detection: A comprehensive
review. <em>NEUCOM</em>, <em>503</em>, 259–271. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge detection is one of the most important and fundamental problems in the field of computer vision and image processing. Edge contours extracted from images are widely used as critical cues for various image understanding tasks such as image segmentation, object detection, image retrieval, and corner detection. The purpose of this paper is to review the latest developments on image edge detection. Firstly, the definition and properties of edges are introduced. Secondly, the existing edge detection methods are classified and introduced in detail. Thirdly, the existing widely used datasets and evaluation criteria for edge detection methods are summarized. Finally, future research directions for edge detection are elaborated.},
  archive      = {J_NEUCOM},
  author       = {Junfeng Jing and Shenjuan Liu and Gang Wang and Weichuan Zhang and Changming Sun},
  doi          = {10.1016/j.neucom.2022.06.083},
  journal      = {Neurocomputing},
  pages        = {259-271},
  shortjournal = {Neurocomputing},
  title        = {Recent advances on image edge detection: A comprehensive review},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GID: Global information distillation for medical semantic
segmentation. <em>NEUCOM</em>, <em>503</em>, 248–258. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider transferring global information from Transformer to Convolutional Neural Network (CNN) for medical semantic segmentation tasks . Previous network models for medical semantic segmentation tasks often suffer from difficulties in modeling global information or oversized model parameters. Here, to design a compact network with global and local information, we extract the global information modeling capability of Transformer into the CNN network and successfully apply it to the medical semantic segmentation tasks, called Global Information Distillation. In addition, the following two contributions are proposed to improve the effectiveness of distillation: i) We present an Information Transfer Module, which is based on a convolutional layer to prevent over-regularization and a Transformer layer to transfer global information; ii) For purpose of better transferring the teacher’s soft targets, a Shrinking Result-Pixel distillation method is proposed in this paper. The effectiveness of our knowledge distillation approach is demonstrated by the experiments on multi-organ and cardiac segmentation tasks.},
  archive      = {J_NEUCOM},
  author       = {Yong-Sen Ye and Min-Rong Chen and Hao-Li Zou and Bai-Bing Yang and Guo-Qiang Zeng},
  doi          = {10.1016/j.neucom.2022.06.065},
  journal      = {Neurocomputing},
  pages        = {248-258},
  shortjournal = {Neurocomputing},
  title        = {GID: Global information distillation for medical semantic segmentation},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph attention autoencoder inspired CNN based brain tumor
classification using MRI. <em>NEUCOM</em>, <em>503</em>, 236–247. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early and accurate detection is a solitary precaution to overcome the brain tumor. Otherwise, it will result in a deadly disease. Brain tumor (BT) detection using magnetic resonance is an essential and challenging job in the medical domain. To combat the aggressive spreading of BT, clinical imaging (MRI and X-Ray) can be an appropriate method for diagnosis. In this paper, we applied attention based image classification, which is a new paradigm for obtaining improved accuracy than the state-of-the-art models. We propose a GATE-CNN (Graph Attention AutoEncoder-Convolution Neural Network) model in this work for the classification of BT. We calculate the attention values of the neighboring pixels on each and every pixel present in the graph then process the graph using GATE framework and the processed graph with attention values is then passed to CNN framework for generation of final output. Further, we apply Adamax optimizer to optimize the training hyperparameters of CNN. We perform the BT classification using the proposed method on three different datasets among benign and malignant BT for first dataset, glioma and pituitary for second dataset, and normal and abnormal BT images for third dataset; all the three datasets consists of MRI images. We then compare the proposed model with a variety of CNN (Deep-CNN, Multi-Input CNN, and basic CNN) models dealing with several types of medical imaging (thermal image, MRI, X-Ray, etc.). Our model results in the accuracy of 98.27\% for first dataset, 99.83\% for second dataset, and 98.78\% for third dataset demonstrating preferable network performance than the already established state-of-the-art CNN models.},
  archive      = {J_NEUCOM},
  author       = {Lalita Mishra and Shekhar Verma},
  doi          = {10.1016/j.neucom.2022.06.107},
  journal      = {Neurocomputing},
  pages        = {236-247},
  shortjournal = {Neurocomputing},
  title        = {Graph attention autoencoder inspired CNN based brain tumor classification using MRI},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Topological structural analysis based on self-adaptive
growing neural network for shape feature extraction. <em>NEUCOM</em>,
<em>503</em>, 219–235. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-organizing neural network has been widely used to extract the topological structure of image shape because it features topological preservation, dynamic adaptation, clustering and dimensionality reduction. However, it is difficult to automatically extract the topology structure with an appropriate number of neurons from the complex and diverse data. In this paper, a novel self-organizing neural network called self-adaptive growing neural network (SAGNN) is proposed, which can generate an appropriate number of neurons autonomously according to the size of input data without setting the total number of neurons in advance. Firstly, Similarity Evaluation Index (SEI) is proposed to evaluate the similarity between the output network and the input space. Then, on the basis of growing neural gas (GNG) network, the SEI as a network growth control condition is introduced into the SAGNN, so that the SAGNN can grow neurons on demand until the expected quantization error is not significantly improved. Experiments involving both artificial and real data sets show that SAGNN can extract the topological structure from the unsupervised data without any prior conditions (including the appropriate number of neurons).},
  archive      = {J_NEUCOM},
  author       = {Chaoliang Zhong and Shirong Liu and Qiang Lu and Botao Zhang and Jian Wang and Qiuxuan Wu},
  doi          = {10.1016/j.neucom.2022.06.086},
  journal      = {Neurocomputing},
  pages        = {219-235},
  shortjournal = {Neurocomputing},
  title        = {Topological structural analysis based on self-adaptive growing neural network for shape feature extraction},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022d). Hyper-class representation of data. <em>NEUCOM</em>,
<em>503</em>, 200–218. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data representation is usually a natural form with their attribute values. On this basis, data processing is an attribute-centered calculation. However, there are three limitations in the attribute-centered calculation, saying, inflexible calculation, preference computation, and unsatisfactory output. To attempt the issues, a new data representation, named as hyper-classes representation, is proposed for improving recommendation. First, the cross entropy, KL divergence and JS divergence of features in data are defined. And then, the hyper-classes in data can be discovered with these three parameters. Finally, a kind of recommendation algorithm is used to evaluate the proposed hyper-class representation of data, and shows that the hyper-class representation is able to provide truly useful reference information for recommendation systems and makes recommendations much better than existing algorithms, i.e., this approach is efficient and promising.},
  archive      = {J_NEUCOM},
  author       = {Shichao Zhang and Jiaye Li and Wenzhen Zhang and Yongsong Qin},
  doi          = {10.1016/j.neucom.2022.06.082},
  journal      = {Neurocomputing},
  pages        = {200-218},
  shortjournal = {Neurocomputing},
  title        = {Hyper-class representation of data},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ASA-net: Deep representation learning between object
silhouette and attributes. <em>NEUCOM</em>, <em>503</em>, 189–199. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object silhouette and semantic attributes are respectively verified for their effectiveness as auxiliary supervision in image recognition. It encourages us to propose a novel zero-shot recognition model, Attribute-Segmentation-Attribute network (ASA-Net), which jointly conducts object segmentation, attribute prediction and recognition in a multi-task learning manner. Firstly, a feature extraction module is pre-trained based on smooth attribute and category annotations. This module is then adopted to initialize the feature encoding module of a multi-scale segmentation CNN to generate coarse-to-fine object silhouettes. Finally, the segments are multiplied with the original image to obtain regions of interest, and semantic features of these regions are extracted and combined to predict attributes. The obtained attribute prediction is further projected into the category space to accomplish the zero-shot recognition task. Experimental results on two public benchmarks indicate that our ASA-Net performs better than baseline and existing methods in attribute prediction and segmentation tasks , as well as the unseen object recognition. The source code is publicly available online (https://github.com/YsSue/ASA-Net.git).},
  archive      = {J_NEUCOM},
  author       = {Shu Yang and Jing Wang and Lidong Yang and Zesong Fei},
  doi          = {10.1016/j.neucom.2022.06.071},
  journal      = {Neurocomputing},
  pages        = {189-199},
  shortjournal = {Neurocomputing},
  title        = {ASA-net: Deep representation learning between object silhouette and attributes},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel grid-based many-objective swarm intelligence
approach for sentiment analysis in social media. <em>NEUCOM</em>,
<em>503</em>, 173–188. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is a field of study that analyses people&#39;s opinions, evaluations, feelings, ratings, sentiments, and attitudes towards entities such as products, organizations, individuals, services, topics, titles, events, and qualifications. Studies on sentiment analysis problems in social media have generally adopted intelligent classification methods. However, there are conflicting and contradictory objectives to simultaneously optimize, and active research continues into developing a more effective analysis model in terms of many metrics in order to achieve effective usage. This study considers sentiment analysis as a many-objective optimization problem for the first time. For this purpose, it first proposes a Grid-based Adaptive Many-Objective Grey Wolf Optimizer (GAM-GWO) based on the Grey Wolf Optimizer algorithm. Then, it adapts this proposed method for the sentiment analysis problem in order to obtain more successful results in terms of different metrics. The study tests the performance of the proposed approach with three different data sets. Experimental results show that GAM-GWO can achieve non-dominated and competitive results in all data set classes.},
  archive      = {J_NEUCOM},
  author       = {Gungor Yildirim},
  doi          = {10.1016/j.neucom.2022.06.092},
  journal      = {Neurocomputing},
  pages        = {173-188},
  shortjournal = {Neurocomputing},
  title        = {A novel grid-based many-objective swarm intelligence approach for sentiment analysis in social media},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Event-triggered privacy-preserving bipartite consensus for
multi-agent systems based on encryption. <em>NEUCOM</em>, <em>503</em>,
162–172. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the privacy-preserving-based bipartite consensus control problem is investigated for a class of discrete-time nonlinear multi-agent systems (MASs). The classical bipartite consensus control implementation relies on the explicit information exchange between agents, which will lead to the possible leakage of agents’ private information, especially the initial states. Therefore, to prevent data disclosure to neighbors inside the MASs and the outside eavesdroppers, the data is encrypted by means of Paillier encryption scheme during information transmission. This means each agent first sends the relative data in the form of ciphertext to its neighbors for further encryption process , and then restores the control protocol based on the returned encrypted information from the neighbors. Since homomorphic encryption only works for integers, the data must be quantized before encryption, and it will inevitably result in the quantization error . On the other hand, for the purpose of saving communication resources, both decentralized and distributed event-triggered schemes are also proposed. Resorting to the Lyapunov stability theory and algebraic graph theory, sufficient conditions are derived ensuring that the MASs subject to a confidential communication agreement can achieve the bounded bipartite consensus . Two numerical examples are presented to verify the validity of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Zewei Yang and Luyang Yu and Yurong Liu and Naif D. Alotaibi and Fawaz E. Alsaadi},
  doi          = {10.1016/j.neucom.2022.06.074},
  journal      = {Neurocomputing},
  pages        = {162-172},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered privacy-preserving bipartite consensus for multi-agent systems based on encryption},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GPU implementation of evolving spiking neural p systems.
<em>NEUCOM</em>, <em>503</em>, 140–161. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Methods for optimizing and evolving spiking neural P systems (in short, SN P systems) have been previously developed with the use of a genetic algorithm framework. So far, these computations, both evolving and simulating, were done only sequentially. Due to the non-deterministic and parallel nature of SN P systems, it is natural to harness parallel processors in implementing its evolution and simulation. In this work, a parallel framework for the evolution of SN P Systems is presented. This is the result of extending our previous work by implementing it on a CUDA-enabled graphics processing unit and adapting CuSNP design in simulations. Using binary addition and binary subtraction with 3 different categories each as initial SN P systems, the GPU-based evolution runs up to 9x faster with respect to its CPU-based evolution counterparts. Overall, when considering the whole process, the GPU framework is up to 3 times faster than the CPU version.},
  archive      = {J_NEUCOM},
  author       = {Rogelio V. Gungon and Katreen Kyle M. Hernandez and Francis George C. Cabarle and Ren Tristan A. de la Cruz and Henry N. Adorna and Miguel Á. Martínez-del-Amor and David Orellana-Martín and Ignacio Pérez-Hurtado},
  doi          = {10.1016/j.neucom.2022.06.094},
  journal      = {Neurocomputing},
  pages        = {140-161},
  shortjournal = {Neurocomputing},
  title        = {GPU implementation of evolving spiking neural p systems},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of fitness landscape analysis for optimization.
<em>NEUCOM</em>, <em>503</em>, 129–139. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over past few decades, as a powerful analytical tool to characterize the fitness landscape of a problem, fitness landscape analysis (FLA) has been widely concerned and utilized for all kinds of optimization areas. Since its introduction by Sewell Wright in 1932, FLA has attracted more and more attention of researchers for its research significance and application value such as an intuitive understanding features of complex optimization problems , explaining evolutionary algorithm behavior , assessing performances of algorithms, and guiding selections and/or configures of algorithms. This paper attempts to give an overview of fitness landscape analysis and its typical application for optimization so far. We hope that this survey can help to understand features of complex optimization problems in depth and thus to improve the certain algorithm performance of for a given optimization problem.},
  archive      = {J_NEUCOM},
  author       = {Feng Zou and Debao Chen and Hui Liu and Siyu Cao and Xuying Ji and Yan Zhang},
  doi          = {10.1016/j.neucom.2022.06.084},
  journal      = {Neurocomputing},
  pages        = {129-139},
  shortjournal = {Neurocomputing},
  title        = {A survey of fitness landscape analysis for optimization},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ITD3-CLN: Learn to navigate in dynamic scene through deep
reinforcement learning. <em>NEUCOM</em>, <em>503</em>, 118–128. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes iTD3-CLN, a Deep Reinforcement Learning (DRL) based low-level motion controller, to achieve map-less autonomous navigation in dynamic scene. We consider three enhancements to the Twin Delayed DDPG (TD3) for the navigation task : N-step returns, Priority Experience Replay, and a channel-based Convolutional Laser Network (CLN) architecture. In contrast to the conventional methods such as the DWA, our approach is found superior in the following ways: no need for prior knowledge of the environment and metric map, lower reliance on an accurate sensor, learning emergent behavior in dynamic scene that is intuitive, and more remarkably, able to transfer to the real robot without further fine-tuning. Our extensive studies show that in comparison to the original TD3, the proposed approach can obtain approximately 50\%\% reduction in training to get same performance, 50\%\% higher accumulated reward, and 30–50\%\% increase in generalization performance when tested in unseen environments. Videos of our experiments are available at https://youtu.be/BRN0Gk5oLOc (Simulation) and https://youtu.be/yIxGH9TPQCc (Real experiment).},
  archive      = {J_NEUCOM},
  author       = {Haoge Jiang and Mahdi Abolfazli Esfahani and Keyu Wu and Kong-wah Wan and Kuan-kian Heng and Han Wang and Xudong Jiang},
  doi          = {10.1016/j.neucom.2022.06.102},
  journal      = {Neurocomputing},
  pages        = {118-128},
  shortjournal = {Neurocomputing},
  title        = {ITD3-CLN: Learn to navigate in dynamic scene through deep reinforcement learning},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Many-objective optimization meets recommendation systems: A
food recommendation scenario. <em>NEUCOM</em>, <em>503</em>, 109–117.
(<a href="https://doi.org/10.1016/j.neucom.2022.06.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the ever-increasing amount of various information provided by the internet, recommendation systems are now used in a large number of fields as efficient tools to get rid of information overload. The content-based, collaborative-based and hybrid methods are the three classical recommendation techniques, whereas not all real-world problems (e.g. the food recommendation problem) can be best addressed by such classical recommendation techniques. This paper is devoted to solving the food recommendation problem based on many-objective optimization (MaOO). A novel recommendation approach is proposed by transforming the original recommendation problem into an MaOO one that contains four different objectives, i.e., the user preferences, nutritional values, dietary diversity, and user diet patterns. The experimental results demonstrate that the designed recommendation approach provides a more balanced way of recommending food than the classical recommendation methods that only consider individuals’ food preferences.},
  archive      = {J_NEUCOM},
  author       = {Jieyu Zhang and Miqing Li and Weibo Liu and Stanislao Lauria and Xiaohui Liu},
  doi          = {10.1016/j.neucom.2022.06.081},
  journal      = {Neurocomputing},
  pages        = {109-117},
  shortjournal = {Neurocomputing},
  title        = {Many-objective optimization meets recommendation systems: A food recommendation scenario},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Activation functions in deep learning: A comprehensive
survey and benchmark. <em>NEUCOM</em>, <em>503</em>, 92–108. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks have shown tremendous growth in recent years to solve numerous problems. Various types of neural networks have been introduced to deal with different types of problems. However, the main goal of any neural network is to transform the non-linearly separable input data into more linearly separable abstract features using a hierarchy of layers. These layers are combinations of linear and nonlinear functions. The most popular and common non-linearity layers are activation functions (AFs), such as Logistic Sigmoid , Tanh, ReLU, ELU, Swish and Mish. In this paper, a comprehensive overview and survey is presented for AFs in neural networks for deep learning . Different classes of AFs such as Logistic Sigmoid and Tanh based, ReLU based, ELU based, and Learning based are covered. Several characteristics of AFs such as output range, monotonicity, and smoothness are also pointed out. A performance comparison is also performed among 18 state-of-the-art AFs with different networks on different types of data. The insights of AFs are presented to benefit the researchers for doing further research and practitioners to select among different choices. The code used for experimental comparison is released at: https://github.com/shivram1987/ActivationFunctions .},
  archive      = {J_NEUCOM},
  author       = {Shiv Ram Dubey and Satish Kumar Singh and Bidyut Baran Chaudhuri},
  doi          = {10.1016/j.neucom.2022.06.111},
  journal      = {Neurocomputing},
  pages        = {92-108},
  shortjournal = {Neurocomputing},
  title        = {Activation functions in deep learning: A comprehensive survey and benchmark},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Photo-realistic image synthesis from lines and appearance
with modular modulation. <em>NEUCOM</em>, <em>503</em>, 81–91. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The image-to-image translation task has made significant progress by relying on conditional generative adversarial networks . However, for many tasks, multiple condition images are required. This paper considers a very classic application scenario, using lines and appearance to synthesize photo-realistic images, describing structure and appearance information, respectively, for example, generating realistic face images from portrait drawings and color scribbles, and generating photos from sketches and texture patches. The key to this type of task is how to fuse the two conditional information. We propose an image translation system driven by line and appearance images, introducing a modular architecture for condition fusion. Unlike the previous condition fusion schemes, its main body of the generator is composed of stacked modulation units (MUs). Here, structural features and appearance features are progressively incorporated via cascaded MUs, each of which pays attention to the local regions. The visualization experiment shows that such a scheme lets the network automatically learn to decompose the fusion process as multiple sub-steps in latent spaces. Our model produces higher quality results quantitatively and qualitatively compared to the state-of-the-art method on different tasks and datasets. The ablation study demonstrates the effectiveness of the MUs and intuitively explains the process of feature fusion through visualization.},
  archive      = {J_NEUCOM},
  author       = {Wuyang Luo and Su Yang and Weishan Zhang},
  doi          = {10.1016/j.neucom.2022.06.007},
  journal      = {Neurocomputing},
  pages        = {81-91},
  shortjournal = {Neurocomputing},
  title        = {Photo-realistic image synthesis from lines and appearance with modular modulation},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Specified-time group consensus for general linear systems
over directed graphs. <em>NEUCOM</em>, <em>503</em>, 73–80. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the distributed specified-time group consensus control with hard settling-time constraint and milder communication topology constraint. To this end, we propose two distributed control schemes by employing a motion planning approach for the single- and double-integrator systems. Compared with the most existing works over undirected communication topologies, the underlying topology of each group is required to be directed graphs in our proposed distributed controllers. Furthermore, the root vertex of one group is allowed to belong to the other group. The convergence analysis is performed via the algebraic graph theory and matrix theory. The results show that the agents in the same group can reach consensus within any prespecified settling-time instead of a conservative upper bound of the settling-time. Moreover, the designed specified-time group consensus protocols do not require continuous information exchange. Finally, simulation results are provided to illustrate the effectiveness of the proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Lu Ren and Jian Liu and Mengwei Sun and Changyin Sun},
  doi          = {10.1016/j.neucom.2022.05.116},
  journal      = {Neurocomputing},
  pages        = {73-80},
  shortjournal = {Neurocomputing},
  title        = {Specified-time group consensus for general linear systems over directed graphs},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Structured graph optimization for joint spectral embedding
and clustering. <em>NEUCOM</em>, <em>503</em>, 62–72. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral Clustering (SC) is an important method in areas such as data mining, image processing , computer science and so on. It attracts more and more attention owing to its effectiveness in unsupervised learning . However, SC has poor performance in the high-dimensional data. Traditional SC methods conduct the spectral embedding of the affinity matrix among data at the first beginning, and then obtain clustering results by the K -means clustering. The also have drawbacks int two processing steps: the clustering results are sensitive to the affinity matrix which may be inaccurate and the post-processing K -means may also be limited by its initialization problem. In the paper, a new approach which joints spectral embedding and clustering with structured graph optimization (called JSEGO) is proposed. In the new model, the low-dimensional representation of data can first be obtained by the spectral embedding method, which can handle with the high-dimensional data better. Then, the optimization similarity matrix would be obtained with such the embedded data. Furthermore, the learning structure graph gives feedback to the similarity matrix to generate better spectral embedded data. As a result, better similarity matrix and clustering result can be obtained by the iterations simultaneously, which are often conducted in two separate steps in the spectral clustering. As a result, the drawbacks introduced by the two processing introduces can be solved. At last, we use an alternative optimization method in the new model and conduct the theoretical analysis by comparing this proposed method with K -means clustering. Experiments based on synthetic data and actual benchmark data prove the advantage of this new approach.},
  archive      = {J_NEUCOM},
  author       = {Xiaojun Yang and Siyuan Li and Ke Liang and Feiping Nie and Liang Lin},
  doi          = {10.1016/j.neucom.2022.06.087},
  journal      = {Neurocomputing},
  pages        = {62-72},
  shortjournal = {Neurocomputing},
  title        = {Structured graph optimization for joint spectral embedding and clustering},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EPQuant: A graph neural network compression approach based
on product quantization. <em>NEUCOM</em>, <em>503</em>, 49–61. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have been widely used in graph analysis due to their strong performance on a wide variety of tasks. Unfortunately, as the size of graphs keeps growing, large graphs can easily consume Terabytes, and training on such graphs may take days. The high memory footprint limits the usage of GNNs on resource-constrained devices like smartphones and IoT devices. Hence, reducing the storage cost, training time, and inference latency is highly desirable. In this work, we apply Product Quantization (PQ) on GNNs for the first time to achieve superior memory capacity reduction. To alleviate the processing burden caused by PQ and improve compression performance , we propose Enhanced Product Quantization (EPQ). It reduces the input graph data, which tends to dominate memory consumption, and accelerates clustering in PQ. Moreover, an efficient quantization framework 1 for GNNs is proposed, which combines EPQ with Scalar Quantization (SQ), to achieve improved compression performance and computation acceleration on off-the-shelf hardware, enabling the deployment of GNNs on resource-constrained devices. In addition, the proposed quantization framework can be applied to the existing GNNs without too much porting effort. Extensive experimental results show that the proposed quantization scheme can achieve 321.26 × 321.26× and 184.03 × 184.03× memory capacity compression for input graph data and overall storage, respectively. This impressive memory reduction can come with an accuracy loss of less than 1\% 1\% .},
  archive      = {J_NEUCOM},
  author       = {Linyong Huang and Zhe Zhang and Zhaoyang Du and Shuangchen Li and Hongzhong Zheng and Yuan Xie and Nianxiong Tan},
  doi          = {10.1016/j.neucom.2022.06.097},
  journal      = {Neurocomputing},
  pages        = {49-61},
  shortjournal = {Neurocomputing},
  title        = {EPQuant: A graph neural network compression approach based on product quantization},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of moving object detection methods: A practical
perspective. <em>NEUCOM</em>, <em>503</em>, 28–48. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moving object detection is the foundation of research in many computer vision fields. In recent decades, a number of detection methods have been proposed. Relevant surveys mainly focused on the detection accuracy, while different practical detection tasks were not considered. However, in different application tasks, training modes and requirements are completely different. The purpose of this survey is to classify and evaluate recent moving object detection methods from a practical perspective. Two main types of practical application tasks are considered: the detection of seen scenes and the detection of unseen scenes. In the survey, two practical application tasks are defined, corresponding recent moving object detection technologies are reviewed, and future directions are suggested to provide references for researchers and technicians when choosing suitable algorithms in practical work.},
  archive      = {J_NEUCOM},
  author       = {Xinyue Zhao and Guangli Wang and Zaixing He and Huilong Jiang},
  doi          = {10.1016/j.neucom.2022.06.104},
  journal      = {Neurocomputing},
  pages        = {28-48},
  shortjournal = {Neurocomputing},
  title        = {A survey of moving object detection methods: A practical perspective},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SQuadMDS: A lean stochastic quartet MDS improving global
structure preservation in neighbor embedding like t-SNE and UMAP.
<em>NEUCOM</em>, <em>503</em>, 17–27. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multidimensional scaling is a process that aims to embed high dimensional data into a lower-dimensional space; this process is often used for the purpose of data visualisation. Common multidimensional scaling algorithms tend to have high computational complexities , making them inapplicable on large data sets. This work introduces a stochastic, force directed approach to multidimensional scaling with a time and space complexity of O ( N ) O(N) , with N data points. The method can be combined with force directed layouts of the family of neighbour embedding such as t -SNE, to produce embeddings that preserve both the global and the local structures of the data. Experiments assess the quality of the embeddings produced by the standalone version and its hybrid extension both quantitatively and qualitatively, showing competitive results outperforming state-of-the-art approaches. Codes are available at https://github.com/PierreLambert3/SQuaD-MDS-and-FItSNE-hybrid .},
  archive      = {J_NEUCOM},
  author       = {Pierre Lambert and Cyril de Bodt and Michel Verleysen and John A. Lee},
  doi          = {10.1016/j.neucom.2022.06.108},
  journal      = {Neurocomputing},
  pages        = {17-27},
  shortjournal = {Neurocomputing},
  title        = {SQuadMDS: A lean stochastic quartet MDS improving global structure preservation in neighbor embedding like t-SNE and UMAP},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A compact neuromorphic architecture with dynamic
multiplexing to efficiently compute a nearest kronecker product
decomposition based RLS-NLMS algorithm for active noise control
headphones. <em>NEUCOM</em>, <em>503</em>, 1–16. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, embedded applications in resource-constrained electronic appliances are increasingly being used for noise reduction. Specifically, modern headphones are used to mitigate the environmental noise effects using advanced active noise control (ANC) systems. Despite achieving great performance, there is still a great challenge to develop compact ANC headphones since these devices contain a limited area. In addition, there are more challenges linked to improvement of the convergence rate, tracking, and complexity of the adaptive algorithm which is used in these devices to efficiently reduce the environmental noise. Specifically, the convergence properties can be improved by using the cutting-edge advanced adaptive algorithms along with the nearest Kronecker product (NKP) decomposition. In this work, we present a new neuromorphic architecture to efficiently compute an improved variant of the Kronecker product recursive least-squares (RLS). To achieve this architecture, we present three contributions; (1) we made a combination between the filtered-X RLS algorithm and normalized least mean squares (NLMS) algorithm to decrease the computational complexity by reducing the number of arithmetic operations required to efficiently compute the filter coefficients . Therefore, the proposed method requires fewer operations when compared with conventional RLS and RLS-NKP algorithms, respectively; (2) we use the spiking neural P (SN P) systems along with their advanced variants, such as rules on the synapses, colored spikes and dendritic delays to design two compact parallel arithmetic circuits (adder and divisor). In this way, the proposed method can be computed at high processing speeds and expending low area; (3) we propose a new digital neuromorphic architecture to be applied in active noise cancellation in headphones. Specifically, we propose a new adaptive unit core, which contains the proposed parallel neural arithmetic circuits , to perform dual filter operations, i.e, the proposed unit is capable of simulating two adaptive algorithms by using the same core. To achieve this we use the dynamic multiplexing technique . Therefore, our proposal exhibits low area consumption. As a consequence, the implementation of the proposed method can be easily integrated into resource-constrained ANC headphones.},
  archive      = {J_NEUCOM},
  author       = {Angel Vazquez and Luis Garcia and Karina Toscano and Juan-Carlos Sanchez and Gonzalo Duchen and Hector Perez and Juan-Gerardo Avalos and Giovanny Sanchez},
  doi          = {10.1016/j.neucom.2022.06.109},
  journal      = {Neurocomputing},
  pages        = {1-16},
  shortjournal = {Neurocomputing},
  title        = {A compact neuromorphic architecture with dynamic multiplexing to efficiently compute a nearest kronecker product decomposition based RLS-NLMS algorithm for active noise control headphones},
  volume       = {503},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Node embedding and classification with adaptive structural
fingerprint. <em>NEUCOM</em>, <em>502</em>, 196–208. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph attention network (GAT) is a promising framework for message passing on graphs, but how to exploit rich, high-order structural information in the attention mechanism is still an open challenge. Furthermore, increasing the attention range to more than one-hop neighbors can negatively affect the performance of GAT, reflecting the over-smoothing risk of graph neural networks in general. In this paper, we propose an “adaptive structural fingerprint” model to fully exploit complex graph topology in graph attention networks. The key idea is to contextualize each node with its “structural fingerprint” that can automatically adjust to the local graph topology and edge connections in the neighborhood of the node. By doing this, structural interactions between the nodes can be evaluated more accurately and better confined to relevant neighbors, thus contributing to an improved attention mechanism and clearer cluster boundary. Furthermore, our approach provides a useful platform for different subspace of node features and various spatial scale of graph structures to “cross-talk” with each other through multi-head attention, which is more flexible than existing attention mechanism using a fixed, minimal spatial attention scale. Encouraging results are observed on a number of benchmark data sets including citation and social networks.},
  archive      = {J_NEUCOM},
  author       = {Yaokang Zhu and Jun Wang and Jie Zhang and Kai Zhang},
  doi          = {10.1016/j.neucom.2022.05.073},
  journal      = {Neurocomputing},
  pages        = {196-208},
  shortjournal = {Neurocomputing},
  title        = {Node embedding and classification with adaptive structural fingerprint},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep objectness hashing using large weakly tagged photos.
<em>NEUCOM</em>, <em>502</em>, 186–195. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CNN-based hashing methods have greatly boosted the performance of image retrieval , under the strong supervision of large amounts of manually annotated labels. In recent years, a large number of social media images with user tags have been generated on the Internet. These images can be regarded as weakly labeled training data, which can provide rich samples for training hash network, and greatly reduce the cost of obtaining training data. However, there are noise and visual irrelevant tags in user tags, and different tags may describe different objects in the image. In the previous CNN-based hashing method, a training image usually corresponds to a manual label and generates a hash code. These methods are difficult to use the image described by user tags with noise. For solving the above problem, we propose a CNN-based objectness hash learning method using user tags as a guide for training. First of all, the user tags are roughly filtered to remove noise tags that are not related to the visual content of images. Secondly, we quantify user tags into a unified semantic space and extract the highest-frequency words of the semantic space from similar objectness areas as their labels. Then, these objectness areas with their labels are grouped into a series of triple units as training data. So that the generated hash code can inherit the semantic similarity of the objectness areas well, that is, the Hamming distance between hash codes generated by similar objectness areas is closer, the reverse is the farther. Experimental results on NUS-WIDE and Flickr datasets show that our method can effectively extract object-level semantic information from weak user tags, and improve the accuracy of image retrieval.},
  archive      = {J_NEUCOM},
  author       = {Fei Xie and Wanqing Zhao and Ziyu Guan and Hexu Wang and Qun Duan},
  doi          = {10.1016/j.neucom.2022.06.053},
  journal      = {Neurocomputing},
  pages        = {186-195},
  shortjournal = {Neurocomputing},
  title        = {Deep objectness hashing using large weakly tagged photos},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel self-supervised deep LSTM network for industrial
temperature prediction in aluminum processes application.
<em>NEUCOM</em>, <em>502</em>, 177–185. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the influence of pot temperature or electrolyte temperature in the aluminum reduction production. Specifically, these indexes reflect the distribution of the physical and energy field of the reduction cell, the current efficiency, and the lifespan of the aluminum reduction cell. Therefore, the pot temperature detection and identification are two critical and significant issues in the whole production process of aluminum electrolysis. However, due to the low measurement accuracy and high maintenance costs with the thermocouple sensor in the practical production process, the real-time measurement of pot temperature index is still a major challenge, which motivate us to develop a self-supervised soft sensor method based on deep long-short term memory (LSTM). Under the constraint of the limited samples, the proposed method achieves a competitive performance. First, the input variables are selected according to the expert experience. Then, a deep self-supervised model is built. Finally, the proposed self-supervised LSTM model is applied to real-time detection in an industrial electrolysis production case. The performance in the experiment outperforms other existing methods in terms of both accuracy and robustness aspects.},
  archive      = {J_NEUCOM},
  author       = {Yongxiang Lei and Hamid Reza Karimi and Xiaofang Chen},
  doi          = {10.1016/j.neucom.2022.06.080},
  journal      = {Neurocomputing},
  pages        = {177-185},
  shortjournal = {Neurocomputing},
  title        = {A novel self-supervised deep LSTM network for industrial temperature prediction in aluminum processes application},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Memory degradation induced by attention in recurrent neural
architectures. <em>NEUCOM</em>, <em>502</em>, 161–176. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the memory mechanisms in recurrent neural architectures when attention models are included. Pure-attention models like Transformers are more and more popular as they tend to outperform models with recurrent connections in many different tasks. Our conjecture is that attention prevents the recurrent connections from transferring information properly between consecutive next steps. This conjecture is empirically tested using five different models, namely, a model without attention, a standard Loung attention model, a standard Bahdanau attention model, and our proposal to add attention to the inputs in order to fill the gap between recurrent and parallel architectures (for both Luong and Bahdanau attention models). Eight different problems are considered to assess the five models: a sequence-reverse copy problem, a sequence-reverse copy problem with repetitions, a filter sequence problem, a sequence-reverse copy problem with bigrams and four translation problems (English to Spanish, English to French, English to German and English to Italian). The achieved results reinforce our conjecture on the interaction between attention and recurrence.},
  archive      = {J_NEUCOM},
  author       = {Mykola Harvat and José D. Martín-Guerrero},
  doi          = {10.1016/j.neucom.2022.06.056},
  journal      = {Neurocomputing},
  pages        = {161-176},
  shortjournal = {Neurocomputing},
  title        = {Memory degradation induced by attention in recurrent neural architectures},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on hybrid artificial intelligence systems from
HAIS 2020 conference. <em>NEUCOM</em>, <em>502</em>, 159–160. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Enrique de la Cal and José R. Villar and Héctor Quintián and Emilio Corchado},
  doi          = {10.1016/j.neucom.2022.06.001},
  journal      = {Neurocomputing},
  pages        = {159-160},
  shortjournal = {Neurocomputing},
  title        = {Special issue on hybrid artificial intelligence systems from HAIS 2020 conference},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-media video event mining based on attention graph
structure learning. <em>NEUCOM</em>, <em>502</em>, 148–158. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-media association mining based on heterogeneous information network(HIN) has received widespread attention. However, video is described by only a few words, leading to the lack of association between visual and textual information. As a result, the heterogeneous graph is inevitably incomplete, which brings great challenges to event mining. Fortunately, topological relationships can infer correlations between similar nodes. In view of this, a novel framework of web video event mining based on attention graph structure learning is proposed to generate a new adjacency matrix , which reconstructs the association among nodes. First, a novel heterogeneous network is constructed, while each relation subgraph is produced separately. Then, in each relational subgraph, feature graphs are generated by feature similarity, which can capture potential relationships between nodes. Simultaneously, semantic graph is also created by learning semantic structures to describe complex heterogeneous interactions between node semantics. Next, these graphs are fused by channel attention to reconstruct the correlation among nodes. Finally, graph convolutional network(GCN) is applied for web video event mining. Experiments on web videos from YouTube demonstrate that our proposed method is more effective than the state-of-the-art methods with significant improvement.},
  archive      = {J_NEUCOM},
  author       = {Chengde Zhang and Yu Lei and Xia Xiao and Xinzhong Chen},
  doi          = {10.1016/j.neucom.2022.06.028},
  journal      = {Neurocomputing},
  pages        = {148-158},
  shortjournal = {Neurocomputing},
  title        = {Cross-media video event mining based on attention graph structure learning},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting vehicle fuel consumption based on multi-view deep
neural network. <em>NEUCOM</em>, <em>502</em>, 140–147. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of global warming is getting more serious, and vehicle emission is the main cause. In recent years, the number of locomotives in China has been increasing at a rate of more than 20\% per year, and the problem of automobile pollution is becoming more serious. The transportation industry is the main source of fossil fuel combustion and environmental pollution. Therefore, in this paper, we propose a multi-view deep neural network (MVDNN) to analyze the key factors affecting the fuel consumption of automobiles. The experiments show that the introduction of human input improves the prediction accuracy and the root mean square error (RMSE) achieves 0.993. In addition, this paper also finds that for drivers, driving habits, driving frequency, and safety awareness are the most important factors affecting the fuel consumption of vehicles by combining Lasso regression with MVDNN. Finally, by comparing the prediction accuracy of different experiments, relevant policy suggestions are made.},
  archive      = {J_NEUCOM},
  author       = {Yawen Li and Isabella Yunfei Zeng and Ziheng Niu and Jiahao Shi and Ziyang Wang and Zeli Guan},
  doi          = {10.1016/j.neucom.2022.06.047},
  journal      = {Neurocomputing},
  pages        = {140-147},
  shortjournal = {Neurocomputing},
  title        = {Predicting vehicle fuel consumption based on multi-view deep neural network},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards mesh saliency in 6 degrees of freedom.
<em>NEUCOM</em>, <em>502</em>, 120–139. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a novel 6DoF mesh saliency database is developed which provides both the subject’s 6DoF data and eye-movement data. Different from traditional databases, subjects in the experiment are allowed to move freely to view 3D meshes in the virtual reality environment. Based on the database, we first analyze the inter-observer variation and the influence of viewing direction toward subject’s visual attention, then we provide investigations about the subject’s visual attention bias and head movement during observation. As traditional 3D mesh saliency detection algorithms do not taking the subject’s head movement into consideration, we further propose a 6DoF mesh saliency detection algorithm based on the uniqueness measure and the bias preference. To evaluate the proposed approach, we design an evaluation metric accordingly which takes the 6DoF information into consideration, and extend some state-of-the-art 3D saliency detection methods to make comparisons. The experimental results demonstrate the superior performance of our approach for 6DoF mesh saliency detection, in addition to providing benchmarks for the presented 6DoF mesh saliency database. The database and proposed method will be made publicly available for research purposes.},
  archive      = {J_NEUCOM},
  author       = {Xiaoying Ding and Zhenzhong Chen},
  doi          = {10.1016/j.neucom.2022.06.088},
  journal      = {Neurocomputing},
  pages        = {120-139},
  shortjournal = {Neurocomputing},
  title        = {Towards mesh saliency in 6 degrees of freedom},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Offset equivariant networks and their applications.
<em>NEUCOM</em>, <em>502</em>, 110–119. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a framework for the design and implementation of offset equivariant networks, that is, neural networks that preserve in their output uniform increments in the input. In a suitable color space this kind of networks achieves equivariance with respect to the photometric transformations that characterize changes in the lighting conditions. We verified the framework on three different problems: image recognition, illuminant estimation, and image inpainting . Our experiments show that the performance of offset equivariant networks are comparable to those in the state of the art on regular data. Differently from conventional networks, however, equivariant networks do behave consistently well when the color of the illuminant changes.},
  archive      = {J_NEUCOM},
  author       = {Marco Cotogni and Claudio Cusano},
  doi          = {10.1016/j.neucom.2022.06.118},
  journal      = {Neurocomputing},
  pages        = {110-119},
  shortjournal = {Neurocomputing},
  title        = {Offset equivariant networks and their applications},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ICGPN: Interaction-centric graph parsing network for
human-object interaction detection. <em>NEUCOM</em>, <em>502</em>,
98–109. (<a href="https://doi.org/10.1016/j.neucom.2022.06.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-Object Interaction (HOI) detection aims to infer different interactions, which occur between humans and related objects of images. HOI is usually represented by a triplet human , action , object human,action,object and can be modeled as a graph. Thus, with global structural information of images, graph-based methods can detect interactions. However, in existing graph networks, although different fully-connected graphs are built, all detected bounding boxes are regarded as graph nodes equally or different types of nodes according to the category, thereby the dominant role of humans in HOI is ignored. In addition, object node representations mainly focus on appearance features, contributing little to HOI inference. To address these issues, a novel graph-based HOI detection model, named interaction-centric graph parsing network (iCGPN), models one human node as a central node, and other nodes as semantic nodes. Firstly, for each detected human instance, a human-centric fully-connected graph is constructed to learn related HOIs. Secondly, in order to reflect the difference between central nodes and semantic nodes, we design different feature representations and model different edge relationships. Through introducing the attention mechanism , global information related to human-object interaction is explored to enrich the semantic node representation, in which spatial layout , relative locations and object categories information are also combined. Finally, a multi-relation graph convolutional network is applied to update the node feature and infer the HOI. Furthermore, a multi-IOU random shift scheme is proposed to augment the data of the training set to fit the object detection deviation and enhance the generalization ability of our network. Extensive experimental results show that iCGPN achieves very competitive results in comparison with state-of-the-arraph-based methods on the V-COCO and HICO-DET datasets, which demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Wenhao Yang and Guanyu Chen and Zhicheng Zhao and Fei Su and Hongying Meng},
  doi          = {10.1016/j.neucom.2022.06.100},
  journal      = {Neurocomputing},
  pages        = {98-109},
  shortjournal = {Neurocomputing},
  title        = {ICGPN: Interaction-centric graph parsing network for human-object interaction detection},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bounded error modeling using interval neural networks with
parameter optimization. <em>NEUCOM</em>, <em>502</em>, 84–97. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the issue of interval modeling of uncertain systems, this article proposes a data-based interval neural network (INN) optimization modeling method that combines interval analysis with a neural network and particle swarm optimization (PSO) algorithm, adopts an INN model with interval weights and interval thresholds, and constructs an interval multiobjective PSO (IMOPSO) algorithm to evolve the network, thereby modeling an uncertain system under an unknown-but-bounded error (UBBE) condition. Considering the cases of known and unknown error bounds in UBBE, two optimization objectives, i.e., interval coverage and interval width, are constructed to optimize the parameters of INN, aiming to improve the accuracy and reliability of prediction. The proposed method effectively solves many constraints such as the model structure demanded and error bounds known in UBBE modeling, and provides a new method of data-based interval system modeling. The method was applied to model linear and nonlinear systems , and simulation results showed that the established INN models have good prediction effects and dynamic characteristics, which demonstrate the effectiveness of the method.},
  archive      = {J_NEUCOM},
  author       = {Shouping Guan and Xiaoyu Yu},
  doi          = {10.1016/j.neucom.2022.06.093},
  journal      = {Neurocomputing},
  pages        = {84-97},
  shortjournal = {Neurocomputing},
  title        = {Bounded error modeling using interval neural networks with parameter optimization},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A contrastive triplet network for automatic chest x-ray
reporting. <em>NEUCOM</em>, <em>502</em>, 71–83. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest X-ray reporting aims at generating linguistic descriptions automatically for chest X-ray images, in which accurate detection and description of abnormalities are essential. However, the seriously biased data distribution (e.g., the normal cases usually dominate the whole dataset over abnormal cases) causes huge challenges for the data-driven neural models to generate satisfied abnormality descriptions. To this end, we propose a contrastive triplet network (CTN) built on the Transformer architecture for automatic chest X-ray reporting to alleviate the data-bias problem. Our CTN effectively enhances abnormalities by comparing visual and semantic information between normal and abnormal cases using a triplet network. Specifically, triplets including normal and abnormal cases are first constructed. Then, visual tokens of the chest X-ray are extracted and fed to the Transformer to generate an associated report. During training, comparisons between normal and abnormal cases are conducted via contrasting: 1) the visual embedding of the chest X-ray image encoded by the Transformer encoder, and 2) the semantic embedding of the generated report encoded by a pre-trained textual encoder. Comprehensive experiments on two publicly-available databases have shown the good performance of our method.},
  archive      = {J_NEUCOM},
  author       = {Yan Yang and Jun Yu and Hanliang Jiang and Weidong Han and Jian Zhang and Wei Jiang},
  doi          = {10.1016/j.neucom.2022.06.063},
  journal      = {Neurocomputing},
  pages        = {71-83},
  shortjournal = {Neurocomputing},
  title        = {A contrastive triplet network for automatic chest X-ray reporting},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neuromorphic adaptive spiking CPG towards bio-inspired
locomotion. <em>NEUCOM</em>, <em>502</em>, 57–70. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, locomotion mechanisms exhibited by vertebrate animals have been the inspiration for the improvement in the performance of robotic systems. These mechanisms include the adaptability of their locomotion to any change registered in the environment through their biological sensors. In this regard, we aim to replicate such kind of adaptability through a sCPG . This sCPG generates different locomotion (rhythmic) patterns which are driven by an external stimulus, that is, the output of a FSR sensor to provide feedback. The sCPG consists of a network of five populations of LIF neurons designed with a specific topology in such a way that the rhythmic patterns can be generated and driven by the aforementioned external stimulus. Therefore, eventually, the locomotion of an end robotic platform could be adapted to the terrain by using any sensor as input. The sCPG with adaptation has been numerically validated at software and hardware level, using the Brian 2 simulator and the SpiNNaker neuromorphic platform for the latest. In particular, our experiments clearly show an adaptation in the oscillation frequencies between the spikes produced in the populations of the sCPG while the input stimulus varies. To validate the robustness and adaptability of the sCPG, we have performed several tests by variating the output of the sensor. These experiments were carried out in Brian 2 and SpiNNaker; both implementations showed a similar behavior with a Pearson correlation coefficient of 0.905.},
  archive      = {J_NEUCOM},
  author       = {Pablo Lopez-Osorio and Alberto Patiño-Saucedo and Juan P. Dominguez-Morales and Horacio Rostro-Gonzalez and Fernando Perez-Peña},
  doi          = {10.1016/j.neucom.2022.06.085},
  journal      = {Neurocomputing},
  pages        = {57-70},
  shortjournal = {Neurocomputing},
  title        = {Neuromorphic adaptive spiking CPG towards bio-inspired locomotion},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visibility of points: Mining occlusion cues for monocular 3D
object detection. <em>NEUCOM</em>, <em>502</em>, 48–56. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular 3D object detection aims at achieving prediction from two-dimensional image plane to three-dimensional physical world. It is an inevitable problem that occlusion phenomena limit the performance in practice. To solve the challenging problem that directly represents the spatial information of occlusion relation, we propose the visibility states of points to describe the spatial distance relationships of occlusion pairs and the implied orientation information. The visibility state introduction can better represent the level and direction of occlusion information and enhance the network’s understanding of occlusion information. Furthermore, we redesign an end-to-end detector to encode features of visibility states to integrate occlusion ordering cues of the whole image to assist object localization in world space. Experiments on the KITTI3D dataset indicate that our method succeeds in establishing visibility states as occlusion cues and promoting the performance of the original detector. Our method is effective, and the performance is comparable with state-of-the-art approaches, especially outstanding in Moderate and Hard cases. Specifically, our method improves the accuracy of 3D moderate case detection to 42.75\% and hard case to 37.03\% in the KITTI3D dataset.},
  archive      = {J_NEUCOM},
  author       = {Huazhen Chu and Lisha Mo and Rongquan Wang and Tianyu Hu and Huimin Ma},
  doi          = {10.1016/j.neucom.2022.06.099},
  journal      = {Neurocomputing},
  pages        = {48-56},
  shortjournal = {Neurocomputing},
  title        = {Visibility of points: Mining occlusion cues for monocular 3D object detection},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Edge-aware deep image deblurring. <em>NEUCOM</em>,
<em>502</em>, 37–47. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image deblurring is a fundamental and challenging low-level vision problem. Previous vision research indicates that edge structure in natural scenes is one of the most important factors to estimate the abilities of human visual perception. In this paper, we resort to human visual demands of sharp edges and propose a two-phase edge-aware deep network to improve deep image deblurring. An edge detection convolutional subnet is designed in the first phase and a residual fully convolutional deblur subnet is then used for generating deblur results. The introduction of the edge-aware network enables our model with the specific capacity of enhancing images with sharp edges. We successfully apply our framework on standard benchmarks and promising results are achieved by our proposed deblur model.},
  archive      = {J_NEUCOM},
  author       = {Zhichao Fu and Yingbin Zheng and Tianlong Ma and Hao Ye and Jing Yang and Liang He},
  doi          = {10.1016/j.neucom.2022.06.051},
  journal      = {Neurocomputing},
  pages        = {37-47},
  shortjournal = {Neurocomputing},
  title        = {Edge-aware deep image deblurring},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variants of recurrent learning vector quantization.
<em>NEUCOM</em>, <em>502</em>, 27–36. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning Vector Quantization (LVQ) and its cost-function-based variant called Generalized Learning Vector Quantization (GLVQ) are powerful, yet simple and interpretable Machine Learning (ML) algorithms for multi-class classification. Even though GLVQ is an effective tool for classifying vectorial data in its native form, it is not particularly suited to handle raw sequence data of potentially different lengths. Usually, this problem is addressed by manually engineering fixed-length features from the raw data or by employing recurrent networks . Therefore, a natural idea is to try to incorporate recurrent units for data processing into the GLVQ network structure. The processed data can then be compared in a latent space for classification decisions. Yet, not much work has been done in direction as far as we are aware. Existing methods to handle sequential data in the framework of GLVQ are rather unsophisticated and severely outdated. In this paper, we provide a general framework for incorporating recurrent structures in an LVQ network and derive two classification models as variants of Recurrent Learning Vector Quantization, namely RecLVQ and LVQRNN. We also demonstrate the abilities of such approaches on illustrative classification problems.},
  archive      = {J_NEUCOM},
  author       = {Jensun Ravichandran and Marika Kaden and Thomas Villmann},
  doi          = {10.1016/j.neucom.2022.06.035},
  journal      = {Neurocomputing},
  pages        = {27-36},
  shortjournal = {Neurocomputing},
  title        = {Variants of recurrent learning vector quantization},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Event-triggered funnel control for network systems with
unknown dynamic leader based on BP neural networks. <em>NEUCOM</em>,
<em>502</em>, 15–26. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the cooperative adaptive funnel tracking control problem for a class of uncertain nonlinear nonstrict feedback multi-agent systems with nonlinear faults, and the dynamic leader has nonlinear unknown function. By designing two value functions and combining with the back propagation neural networks , an event-triggered strategy that can be adjusted automatically is designed to reduce the waste of communication bandwidth . The Butterworth low-pass filter signal is introduced to solve the non-smooth function problems . In addition, the radial basis function neural networks are used to approximate unknown functions in the system. Then, an event-triggered control protocol is constructed, which can achieve the tracking performance and all signals of the closed-loop system are semiglobally uniformly ultimately bounded. Finally, some simulation results confirm the effectiveness of the proposed control scheme.},
  archive      = {J_NEUCOM},
  author       = {Zeyi Liu and Hongjing Liang and Hong Xue},
  doi          = {10.1016/j.neucom.2022.06.022},
  journal      = {Neurocomputing},
  pages        = {15-26},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered funnel control for network systems with unknown dynamic leader based on BP neural networks},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PSIDP: Unsupervised deep hashing with pretrained semantic
information distillation and preservation. <em>NEUCOM</em>,
<em>502</em>, 1–14. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blending free annotation cost, low memory usage and high query speed into a unity, unsupervised deep hashing has shown extraordinary talents in image retrieval . In order to address the lack of semantic information in unsupervised scenario, related works leverage models pretrained on large-scale datasets (e.g., ImageNet) to the estimate semantic similarity for specific datasets (e.g., FLICKR-25 K). However, most of them discard the original semantic attribute in the pretrained datasets, which results in hash codes being over-fitted to the estimated semantic similarity information. To alleviate this problem, this paper tries to consider the semantic similarity of the specific dataset and preserve the semantic attribute from the pretrained dataset simultaneously. Meanwhile, to build a reliable semantic similarity matrix for the specific dataset, this paper develops a similarity distiller by jointly measuring the semantic similarity with the distance between deep features, the distance on the local manifold and the distance on the connectivity graph . Moreover, an efficient attribute preserver is also designed to maintain the correspondence between the hash codes and the category attributes from the pretrained dataset based on regeneration criteria. The method proposed in this paper is named PSIDP for simplicity and extensive image retrieval experiments on four benchmark datasets demonstrate the superiority of the proposed PSIDP method when compared with other state-of-the-art unsupervised deep hashing methods . The code is available at https://github.com/reresearcher/PSIDP.},
  archive      = {J_NEUCOM},
  author       = {Yufeng Shi and Xinge You and Yue Zhao and Jiamiao Xu and Weihua Ou and Feng Zheng and Qinmu Peng},
  doi          = {10.1016/j.neucom.2022.06.060},
  journal      = {Neurocomputing},
  pages        = {1-14},
  shortjournal = {Neurocomputing},
  title        = {PSIDP: Unsupervised deep hashing with pretrained semantic information distillation and preservation},
  volume       = {502},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unified dual-label semi-supervised learning with top-k
feature selection. <em>NEUCOM</em>, <em>501</em>, 875–888. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised feature selection alleviates the annotation burden of supervised feature learning by exploiting data under a handful of supervision information. The mainstream technique is to employ a linear regression framework that jointly learns labeled and unlabeled samples . However, existing approaches always encounter the deficiencies in two aspects: 1) the performance of models are severely degenerated once predicted labels are unreliable; 2) the balance of objectives in regards to two types of data are not well considered. In the article, we propose unified dual-label semi-supervised learning for top- k feature selection. The technique defines a soft label matrix to indicate the probability of samples belonging to each class. From the probability, the model could recognize unclassifiable samples that lay around the boundaries. Meanwhile, the label matrix is equipped with an exponent parameter γ γ . It endows the soft labels dual effects that the labeled and unlabeled data are tactfully discriminated. For the purpose of feature selection, we impose the ℓ 2 , 0 ℓ2,0 -norm constraint on the projection matrix , such that the exact top- k features are picked out. An iteration algorithm is designed to solve the given problem, by which large-scale data are facilely tackled. We conduct experiments that validate the superiority of the proposed method against the state-of-the-art competitors.},
  archive      = {J_NEUCOM},
  author       = {Han Zhang and Maoguo Gong and Feiping Nie and Xuelong Li},
  doi          = {10.1016/j.neucom.2022.05.090},
  journal      = {Neurocomputing},
  pages        = {875-888},
  shortjournal = {Neurocomputing},
  title        = {Unified dual-label semi-supervised learning with top-k feature selection},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view multi-label learning with view feature attention
allocation. <em>NEUCOM</em>, <em>501</em>, 857–874. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-view multi-label learning, instances can be described by a variety of view features, and they are also associated with a set of labels. Most of the existing multi-view multi-label learning methods extract common and private features from views. However, these methods ignore the fact that the extracted features have different importance for multi-label prediction. To address this issue, this paper proposes a multi-view multi-label learning framework with view feature attention allocation. First, the common and private features between different views are obtained. Then, the original features are compared with the common features to obtain the similarity. Next, the attention weight matrix can be obtained by multiplying the similarity with the synergistic feature matrix. Finally, the acquired attention is used to reconstruct the synergistic feature matrix that indicates the semantic information of the view for multi-label prediction. To verify the effectiveness of the proposed algorithm, experiments are conducted on seven multi-view multi-label datasets, and five advanced algorithms are taken for performance comparison. The extensive experimental results demonstrate the superiority of our algorithm.},
  archive      = {J_NEUCOM},
  author       = {Yusheng Cheng and Qingyan Li and Yibin Wang and Weijie Zheng},
  doi          = {10.1016/j.neucom.2022.06.068},
  journal      = {Neurocomputing},
  pages        = {857-874},
  shortjournal = {Neurocomputing},
  title        = {Multi-view multi-label learning with view feature attention allocation},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FogAdapt: Self-supervised domain adaptation for semantic
segmentation of foggy images. <em>NEUCOM</em>, <em>501</em>, 844–856.
(<a href="https://doi.org/10.1016/j.neucom.2022.05.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents FogAdapt, a novel approach for domain adaptation of semantic segmentation for dense foggy scenes. Although significant research has been directed to reduce the domain shift in semantic segmentation , adaptation to scenes with adverse weather conditions remains an open question. Large variations in the visibility of the scene due to weather conditions, such as fog, smog, and haze, exacerbate the domain shift, thus making unsupervised adaptation in such scenarios challenging. We propose a self-entropy and multi-scale information augmented self-supervised domain adaptation method (FogAdapt) to minimize the domain shift in foggy scenes segmentation. Supported by the empirical evidence that an increase in fog density results in high self-entropy for segmentation probabilities, we introduce a self-entropy based loss function to guide the adaptation method. Furthermore, inferences obtained at different image scales are combined and weighted by the uncertainty to generate scale-invariant pseudo-labels for the target domain. These scale-invariant pseudo-labels are robust to visibility and scale variations. We evaluate the proposed model on real clear-weather scenes to real foggy scenes adaptation and synthetic non-foggy images to real foggy scenes adaptation scenarios. Our experiments demonstrate that FogAdapt significantly outperforms the current state-of-the-art in semantic segmentation of foggy images. Specifically, by considering the standard settings compared to state-of-the-art (SOTA) methods, FogAdapt gains 3.8\% on Foggy Zurich, 6.0\% on Foggy Driving-dense, and 3.6\% on Foggy Driving in mIoU when adapted from Cityscapes to Foggy Zurich.},
  archive      = {J_NEUCOM},
  author       = {Javed Iqbal and Rehan Hafiz and Mohsen Ali},
  doi          = {10.1016/j.neucom.2022.05.086},
  journal      = {Neurocomputing},
  pages        = {844-856},
  shortjournal = {Neurocomputing},
  title        = {FogAdapt: Self-supervised domain adaptation for semantic segmentation of foggy images},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonparametric regression for interval-valued data based on
local linear smoothing approach. <em>NEUCOM</em>, <em>501</em>, 834–843.
(<a href="https://doi.org/10.1016/j.neucom.2022.06.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an interval local linear method (ILLM) to fit the regression model with interval-valued explanatory and response variables. The proposed method has no restriction on the form of the regression function . Moreover, it reduces the boundary effect of interval kernel method . Some experimental studies including two simulations and four real datasets are examined to evaluate the proposed method. Experimental results show that our method has higher predictive accuracy than some existed methods, including the center and range method, the interval least absolute method, the interval kernel method , multi-output support vector regression and the interval multilayer perceptron .},
  archive      = {J_NEUCOM},
  author       = {Lingtao Kong and Xiangjun Song and Xiaomin Wang},
  doi          = {10.1016/j.neucom.2022.06.073},
  journal      = {Neurocomputing},
  pages        = {834-843},
  shortjournal = {Neurocomputing},
  title        = {Nonparametric regression for interval-valued data based on local linear smoothing approach},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical graph attention network with pseudo-metapath
for skeleton-based action recognition. <em>NEUCOM</em>, <em>501</em>,
822–833. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition has gained significant attention in computer vision. Most state-of-the-art (SOTA) approaches view the skeleton as a homogeneous graph. Unlike those approaches, this paper shows that methods in the heterogeneous graph manner can also achieve competitive performance. In this paper, a logical heterogeneous skeleton graph is built under the assumption of the heterogeneity of joints and bones at different positions, and the action recognition task is formulated as message aggregation and prediction on this heterogeneous graph. Specifically, a novel semantic concept named pseudo-metapath is introduced to represent dependencies between joints, based on which a hierarchical graph attention network with the joint-level attention and the semantic-level attention modules is proposed to capture richer skeleton features. The joint-level attention module intends to get the local difference among the joints within each pseudo-metapath, while the semantic-level attention module is capable of learning the global importance of different pseudo-metapaths. Extensive experiments on the NTU-RGB + D 60, NTU-RGB + D 120 and the SYSU datasets, validate that our model can attain comparable performance to the SOTA methods with 15x fewer input frames, 26.3x less FLOPs and 2.8x less parameters.},
  archive      = {J_NEUCOM},
  author       = {Mingdao Wang and XueMing Li and Xianlin Zhang and Yue Zhang},
  doi          = {10.1016/j.neucom.2022.06.024},
  journal      = {Neurocomputing},
  pages        = {822-833},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical graph attention network with pseudo-metapath for skeleton-based action recognition},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-stage 3D object detection guided by position encoding.
<em>NEUCOM</em>, <em>501</em>, 811–821. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voxel-based structures in 3D detection have achieved rapid advancement due to their superior capability for feature extraction. However, the accuracy is usually low because the point cloud is divided into a grid. In order to overcome the above problems and improve detection accuracy, we propose a flexible two-stage 3D object detection architecture, which adopts two branches to refine generated proposals, aggregating voxel features and raw point features simultaneously. We also design a new gating mechanism to achieve fusion features from different levels. In addition, we propose a novel feature aggregation module to reduce the semantic gap between the features of the two types. First, a transformer based on raw points is employed as an encoder to aggregate the contextual information. Then, the point-based channel-wise self-attention mechanism serves as a decoder to aggregate the global features. Experiment results on the KITTI 3D dataset and Waymo Open datest demonstrate that our approach outperforms the state-of-the-art methods and exhibits excellent scalability.},
  archive      = {J_NEUCOM},
  author       = {Wanpeng Xu and Ling Zou and Zhipeng Fu and Lingda Wu and Yue Qi},
  doi          = {10.1016/j.neucom.2022.06.030},
  journal      = {Neurocomputing},
  pages        = {811-821},
  shortjournal = {Neurocomputing},
  title        = {Two-stage 3D object detection guided by position encoding},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The operating system of the neuromorphic BrainScaleS-1
system. <em>NEUCOM</em>, <em>501</em>, 790–810. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BrainScaleS-1 is a wafer-scale mixed-signal accelerated neuromorphic system targeted for research in the fields of computational neuroscience and beyond-von-Neumann computing. Here we present the BrainScaleS Operating System (BrainScaleS OS): the software stack gives users the possibility to emulate networks described in the high-level network description language PyNN with minimal knowledge of the system, as well as expert usage facilitated by allowing access to the system at any depth of the stack. BrainScaleS OS has been used extensively in the commissioning and calibration of BrainScaleS-1 as well as in various neuromorphic experiments, e.g., rate-based deep learning, accelerated physical emulation of Bayesian inference, solving of SAT problems, and others. The tolerance to faults of individual components of the neuromorphic system is reflected in the mapping process based on information stored in an availability database. We evaluate the robustness and compensation mechanisms of the system and software stack. The software stack is designed with performance in mind, with its core implemented in C++ and most user-facing API wrapped automatically to Python. The implemented multi-FPGA orchestration allows for parallel configuration and synchronized experiments facilitating wafer-scale experiments. The initial configuration of a wafer-scale experiment with hundreds of neuromorphic ASICs is performed in a fraction of a minute. Subsequent experiments, that potentially change only a subset of parameters, can be executed with rates of typically 10Hz. The bandwidth from the host machine to the neuromorphic system is fully utilized starting from a quarter of the system’s FPGA count. Operation and development methodologies implemented for the BrainScaleS-1 neuromorphic architecture are presented and the individual components of BrainScaleS OS constituting the software stack for BrainScaleS-1 platform operation are detailed.},
  archive      = {J_NEUCOM},
  author       = {Eric Müller and Sebastian Schmitt and Christian Mauch and Sebastian Billaudelle and Andreas Grübl and Maurice Güttler and Dan Husmann and Joscha Ilmberger and Sebastian Jeltsch and Jakob Kaiser and Johann Klähn and Mitja Kleider and Christoph Koke and José Montes and Paul Müller and Johannes Partzsch and Felix Passenberg and Hartmut Schmidt and Bernhard Vogginger and Jonas Weidner and Christian Mayr and Johannes Schemmel},
  doi          = {10.1016/j.neucom.2022.05.081},
  journal      = {Neurocomputing},
  pages        = {790-810},
  shortjournal = {Neurocomputing},
  title        = {The operating system of the neuromorphic BrainScaleS-1 system},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Relation constraint self-attention for image captioning.
<em>NEUCOM</em>, <em>501</em>, 778–789. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-attention based Transformer has been successfully introduced in the encoder-decoder framework of image captioning, which is superior in modeling the inner relations of inputs, i.e. , image regions or semantic words. However, relations in self-attention are usually too dense to be fully optimized, which may result in noisy relations and attentions. Meanwhile, the prior relations, e.g. , visual relation and semantic relation between objects, which are essential for understanding and describing an image, are ignored by current self-attention. Thus, the relation learning of self-attention in image captioning is biased, which leads to a dilution of the concentration of attentions. In this paper, we propose a Relation Constraint Self-Attention (RCSA) model to enhance the relation learning of self-attention in image captioning by constraining self-attention with prior relations. RCSA exploits the prior visual and semantic relation information from scene graph as constraint factors. And then it builds constraints for self-attention through two sub-modules: an RCSA-E encoder module and an RCSA-D decoder module. RCSA-E introduces the visual relation information to self-attention in encoder, which helps generate a sparse attention map by omitting the attention weights of irrelevant regions to highlight relevant visual features. RCSA-D extends the keys and values of self-attention in decoder with the semantic relation information to constrain the learning of semantic relation, and improve the accuracy of generated semantic words. Intuitively, RCSA-E endows model with an ability to figure out which region to omit and which region to focus by visual relation information; RCSA-D then strengthens the relation learning of the focused regions and improves the sentence generation with semantic relation information. Experiments on the MSCOCO dataset demonstrate the effectiveness of our proposed RCSA.},
  archive      = {J_NEUCOM},
  author       = {Junzhong Ji and Mingzhan Wang and Xiaodan Zhang and Minglong Lei and Liangqiong Qu},
  doi          = {10.1016/j.neucom.2022.06.062},
  journal      = {Neurocomputing},
  pages        = {778-789},
  shortjournal = {Neurocomputing},
  title        = {Relation constraint self-attention for image captioning},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bearing fault diagnosis using transfer learning and
self-attention ensemble lightweight convolutional neural network.
<em>NEUCOM</em>, <em>501</em>, 765–777. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of big data leads to many researchers focusing on improving bearing fault classification accuracy using deep learning models . However, implementing a deep learning model on a limited resources platform such as the smartphone or STM32 includes two difficulties: making the model as lightweight as possible and reducing the dependence on large training samples. To this end, a self-attention ensemble lightweight model combined with the transfer learning (SLTL) method is proposed to solve these intractable problems, which are “small, light, and fast.” Firstly, the raw vibration signal is constructed into time–frequency images by continuous wavelet transform (CWT). Secondly, we build a self-attention lightweight convolutional neural network (SLCNN) model by integrating a self-attention mechanism (SAM) into the optimized SqueezeNet model. Then, based on a well-trained SLCNN in ImageNet, rich parameter knowledge is transferred from the pre-trained model to the target model. Finally, the fever training samples are used to fine-tune the target model. Experimental results on two bearing datasets validate the effectiveness of the SLTL method, which achieves 99.5\% of classification accuracy with fewer training samples than other conventional CNN models. More importantly, the model parameters of SLTL are 0.95 M, and the floating-point operations (FLOPs) are 0.11 M, indicating that SLTL possesses high accuracy while maintaining lightweight, which benefits the platform with limited resources.},
  archive      = {J_NEUCOM},
  author       = {Hongyu Zhong and Yong Lv and Rui Yuan and Di Yang},
  doi          = {10.1016/j.neucom.2022.06.066},
  journal      = {Neurocomputing},
  pages        = {765-777},
  shortjournal = {Neurocomputing},
  title        = {Bearing fault diagnosis using transfer learning and self-attention ensemble lightweight convolutional neural network},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TS4Net: Two-stage sample selective strategy for rotating
object detection. <em>NEUCOM</em>, <em>501</em>, 753–764. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotating object detection has recently attracted increasing attention in aerial photographs, remote sensing images , etc. In this paper, we propose a rotating object detector TS 4 Net, which contains anchor refinement module (ARM) and two-stage sample selective strategy (TS 4 ). The ARM can convert the preset horizontal anchors into high-quality rotated anchors through two-stage refinement, which also adopts a rotated Intersection-over-Union(IoU) prediction branch to improve localization accuracy in the second stage. TS 4 module utilizes different constrained sample selective strategies to allocate positive and negative samples, which is adaptive to the regression task in different stages. Benefiting from the ARM and TS 4 , the TS 4 Net can achieve superior performance for rotating object detection solely with one preset horizontal anchor. Considering that most rotating object detection datasets mainly focus on the field of remote sensing and are shot in high-altitude scenes. We present a low-altitude drone-based dataset, named UAV-ROD, aiming to promote the research and development in rotating object detection and UAV applications. The UAV-ROD dataset can be used in rotating object detection, vehicle orientation recognition, and object counting tasks. Extensive experiments on the UAV-ROD dataset and four datasets demonstrate that our method achieves competitive performance against most state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Jian Zhou and Kai Feng and Weixing Li and Jun Han and Feng Pan},
  doi          = {10.1016/j.neucom.2022.06.049},
  journal      = {Neurocomputing},
  pages        = {753-764},
  shortjournal = {Neurocomputing},
  title        = {TS4Net: Two-stage sample selective strategy for rotating object detection},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Residual attentive feature learning network for salient
object detection. <em>NEUCOM</em>, <em>501</em>, 741–752. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection is one of the basic challenging problems in the area of computer vision. Traditional saliency models usually utilize handcrafted features and various prior cues to locate and segment salient objects from complicated surroundings. Recently, with the development of convolutional neural networks (CNNs), most of existing approaches explore the combination of multi-level feature maps for improving detection performance. However, how to learn powerful feature is still a challenge, and the multi-level and multi-scale feature maps are usually aggregated without distinction. In this paper, we propose a novel salient object detection approach named residual attentive feature learning (RAFL) to uniformly highlight salient objects and effectively suppress background noises. In our proposed RAFL, a global perception (GP) module is designed to obtain rich global features of input image. A pyramid feature extraction (PFE) module is utilized to capture the rich context of side-output information. Moreover, an attentive feature selection (AFS) module is applied to refine these side-output features and generate attentive features, so as to find out the important feature channels having high responses to the salient objects. Finally, a residual feature learning (RFL) module is proposed to make the shallow layers generate more accurate saliency maps with the help of the deep layers which contain more global semantic information. Experimental results show that our proposed approach performs favorably against 18 state-of-the-art representative methods on five benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Qing Zhang and Yanjiao Shi and Xueqin Zhang and Liqian Zhang},
  doi          = {10.1016/j.neucom.2022.06.052},
  journal      = {Neurocomputing},
  pages        = {741-752},
  shortjournal = {Neurocomputing},
  title        = {Residual attentive feature learning network for salient object detection},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view representation learning from local consistency
and global alignment. <em>NEUCOM</em>, <em>501</em>, 727–740. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on learning a feature extractor that can extract the shared information from multi-view data unsupervised . Maximizing the mutual information (MI) between multi-view datasets is an alternative to achieving this, and the contrastive loss is usually used to approximate the MI. However, there are three challenges worthy of our attention. The first is that minimizing the contrastive loss can push away two semantically similar instances. The second is that CL-based models are sensitive to batch size. The last is that CL-based models mine shared information between views in an instance-based manner. It cannot capture the discriminative information contained in the overall distribution of different views. Here, we propose a new method called the Local Consistency and Global Alignment Network (LCGAN) to solve these challenges. LCGAN proposes to use a simple clustering-based ”swap” prediction training mechanism to replace the CL loss, thus alleviating the first two challenges mentioned above. To alleviate the third challenge, LCGAN proposes using the Wasserstein distance to align the distribution among the different views. Empirical evaluations of our proposed series of real ship datasets and several benchmark datasets demonstrate the effectiveness of the proposed LCGAN.},
  archive      = {J_NEUCOM},
  author       = {Lingyu Si and Wenwen Qiang and Jiangmeng Li and Fanjiang Xu and Funchun Sun},
  doi          = {10.1016/j.neucom.2022.06.069},
  journal      = {Neurocomputing},
  pages        = {727-740},
  shortjournal = {Neurocomputing},
  title        = {Multi-view representation learning from local consistency and global alignment},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unified k-means coupled self-representation and neighborhood
kernel learning for clustering single-cell RNA-sequencing data.
<em>NEUCOM</em>, <em>501</em>, 715–726. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-cell RNA sequencing (scRNA-seq) technology obtains transcriptomics information of cells individually, and it allows the detection of cell types and subtypes at the cellular level. Nevertheless, the large number of noise and high dimension of expression profiles in scRNA-seq data cause many problems in down-stream analysis. Subspace clustering has been widely applied to scRNA-seq data analysis and made great progress. However, it only holds for linear subspaces and carries out similarity learning and subsequent clustering separately, which can generate severe information loss. To this end, we develop a novel unified framework for learning a consensus similarity matrix and a representation matrix jointly from the scRNA-seq data. Furthermore, by learning a low-rank kernel matrix, we try to fully exploit the diversity property of the kernel matrix and allow the optimal kernel to reside in the neighborhood of the candidate kernels. In addition, to solve the non-convex resultant optimization problem , an alternating direction method with multipliers (ADMM) is designed. Experimental results on various scRNA-seq datasets (including Cardiac epidermal cells, neural cells, blood cells, etc.) validate the superiority of the proposed approach when compared with other state-of-the-art ones.},
  archive      = {J_NEUCOM},
  author       = {Zheng Li and Chang Tang and Xiao Zheng and Zhenglai Li and Wei Zhang and Lijuan Cao},
  doi          = {10.1016/j.neucom.2022.06.046},
  journal      = {Neurocomputing},
  pages        = {715-726},
  shortjournal = {Neurocomputing},
  title        = {Unified K-means coupled self-representation and neighborhood kernel learning for clustering single-cell RNA-sequencing data},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Direct regression scene text detection with accuracy
scoring. <em>NEUCOM</em>, <em>501</em>, 705–714. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large variation in size and aspect ratio is a common and important characteristic of scene text. Existing scene text detection methods are still inadequate in dealing with large variations in size and aspect ratio. There are two main deficiencies that limit the performance of these methods: the range of the effective receptive field of output features is not wide enough for large variations in size and aspect ratio of text, and the text confidence score of candidate boxes is irrelevant to the size, orientation and location of candidate boxes. We propose a direct regression method of scene text detection, which improves the feature extraction network to enlarge the range of the effective receptive field of output features, and generates a regression accuracy score instead of a text confidence score to represent the regression accuracy of candidate boxes. In the proposed method, we use the Aggregated Feature Pyramid module to generate multi-scale feature maps which contain both high-level and low-level information and have a wide range of effective receptive fields. We also propose a Regression Accuracy Scoring module to calculate the regression accuracy score of each candidate box and keep the one with the highest regression accuracy score for each text instance as the final result. Experiments on datasets ICDAR2015, ICDAR2017 and COCO-Text demonstrate that the proposed method has a comparable performance with state-of-the-art methods while it is more efficient. Meanwhile, we provide abundant ablation experiments to verify the effectiveness of the modules in our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Peirui Cheng and Yuzhong Zhao and Yuanqiang Cai and Weiqiang Wang},
  doi          = {10.1016/j.neucom.2022.06.057},
  journal      = {Neurocomputing},
  pages        = {705-714},
  shortjournal = {Neurocomputing},
  title        = {Direct regression scene text detection with accuracy scoring},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recognizing irrelevant faces in short-form videos based on
feature fusion and active learning. <em>NEUCOM</em>, <em>501</em>,
694–704. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, short-form videos spread rapidly around the world and became a popular way of entertainment for people to share their daily lives. However, many videos record behaviors of other people without their awareness and are uploaded onto the short-form video platforms. Such behavior severely invades personal privacy and can even bring risks of personal information leakage . At present, few studies focus on detecting privacy violations in short-form videos. Meanwhile, due to the difficulty in transferring existing models to the scenario of short-form videos and the lack of reliable datasets, it is very challenging to recognize irrelevant faces in short-form videos. To deal with this problem, we constructed and published an irrelevant faces dataset (IF-Dataset) with 43,965 irrelevant face images and 89,924 relevant face images based on the videos collected from Douyin (the Chinese version of TikTok). In addition, we constructed a framework that implemented our proposed deep learning model M ulti-features M ulti-head F usion Net work (MMFNet) to recognize irrelevant faces from short-form videos. The experimental results show that the F1 score of the MMFNet can reach 87.03\%. We also proposed a novel loss function as well as an active learning system to improve the generalization ability of models, which can reach the Relative Error Reduction (RER) up to 29.58\%. Our work provides both theoretical and practical support for face protection in short-form videos.},
  archive      = {J_NEUCOM},
  author       = {Mingcheng Zhu and Rongchuan Zhang and Haizhou Wang},
  doi          = {10.1016/j.neucom.2022.06.064},
  journal      = {Neurocomputing},
  pages        = {694-704},
  shortjournal = {Neurocomputing},
  title        = {Recognizing irrelevant faces in short-form videos based on feature fusion and active learning},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated vehicles in swarm configuration: Simulation and
analysis. <em>NEUCOM</em>, <em>501</em>, 679–693. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving automation is becoming an increasing trend in the automotive industry as vehicles become more and more intelligent, while information is shared among them and with the infrastructure via wireless communication . Vehicle organization in swarms is considered an interesting approach for future traffic management, since it could significantly improve road efficiency and safety, while saving resources and increasing system resiliency. In this work, modelling and simulation of swarm traffic flow have been addressed. A decision support simulation tool for swarm intelligence traffic flow modelling including different types of vehicles and roads has been implemented using MATLAB. Functionalities such as driving, lane changing, overtaking and swarm cooperation are included. The behaviour of swarms of multi-brand platooning vehicles on different roads and driving conditions has been analyzed. The parameters that define the automated vehicle swarm have also been studied, such as its size, desired speed, inter-vehicle distance, etc., and how the swarm configuration depends on the application (highway traffic, traffic jam assist, …). The result of this research shows how traffic flow can be maximized when vehicles are managed in a swarm configuration.},
  archive      = {J_NEUCOM},
  author       = {Javier Echeto and Matilde Santos and Manuel G. Romana},
  doi          = {10.1016/j.neucom.2021.09.083},
  journal      = {Neurocomputing},
  pages        = {679-693},
  shortjournal = {Neurocomputing},
  title        = {Automated vehicles in swarm configuration: Simulation and analysis},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Divide-and-conquer based large-scale spectral clustering.
<em>NEUCOM</em>, <em>501</em>, 664–678. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering is one of the most popular clustering methods . However, how to balance the efficiency and effectiveness of the large-scale spectral clustering with limited computing resources has not been properly solved for a long time. In this paper, we propose a divide-and-conquer based large-scale spectral clustering method to strike a good balance between efficiency and effectiveness. In the proposed method, a divide-and-conquer based landmark selection algorithm and a novel approximate similarity matrix approach are designed to construct a sparse similarity matrix within low computational complexities . Then clustering results can be computed quickly through a bipartite graph partition process. The proposed method achieves the lower computational complexity than most existing large-scale spectral clustering methods . Experimental results on ten large-scale datasets have demonstrated the efficiency and effectiveness of the proposed method. The MATLAB code of the proposed method and experimental datasets are available at https://github.com/Li-Hongmin/MyPaperWithCode .},
  archive      = {J_NEUCOM},
  author       = {Hongmin Li and Xiucai Ye and Akira Imakura and Tetsuya Sakurai},
  doi          = {10.1016/j.neucom.2022.06.006},
  journal      = {Neurocomputing},
  pages        = {664-678},
  shortjournal = {Neurocomputing},
  title        = {Divide-and-conquer based large-scale spectral clustering},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Adaptive correlation integration for deep image clustering.
<em>NEUCOM</em>, <em>501</em>, 650–663. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep clustering methods often estimate data correlations to guide unsupervised learning . However, since different kinds of correlations capture different data characteristics, a strong data correlation may not be appropriate for every case. In this paper, we propose a novel Teacher-Student framework to adaptively estimate correlation and interactively learn a deep clustering model for various data distributions. Specifically, a teacher module mines and integrates various kinds of correlations from different perspectives. To adapt to various cases, we propose a novel Ad aptive I ntegration Gate (ADI-Gate) to selectively and dynamically integrate different data correlations in a teaching-feedback manner. Furthermore, a student module performs unsupervised clustering inference with the estimated correlation and provides a preference for teacher module. We also design a Pairwise-Weighted loss (PW-loss) to enhance high-confident correlation guidance of data pairs during the learning process of student module. In image clustering experiments on four public datasets, our model achieves consistent improvements over state-of-the-art models.},
  archive      = {J_NEUCOM},
  author       = {Yushan Wu and Rui Wu and Yutai Hou and Jiafeng Liu and Xianglong Tang},
  doi          = {10.1016/j.neucom.2022.06.059},
  journal      = {Neurocomputing},
  pages        = {650-663},
  shortjournal = {Neurocomputing},
  title        = {Adaptive correlation integration for deep image clustering},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PB-GCN: Progressive binary graph convolutional networks for
skeleton-based action recognition. <em>NEUCOM</em>, <em>501</em>,
640–649. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition is an essential yet challenging visual task, whose accuracy has been remarkably improved due to the successful application of graph convolutional networks (GCNs). However, high computation cost and memory usage hinder their deployment on resource-constrained environment. To deal with the issue, in this paper, we introduce two novel progressive binary graph convolutional network for skeleton-based action recognition PB-GCN and PB-GCN * * , which can obtain significant speed-up and memory saving. In PB-GCN, the filters are binarized, and in PB-GCN * * , both filters and activations are binary. Specifically, we propose a progressive optimization, i.e., employing ternary models as the initialization of binary GCNs (BGCN) to improve the representational capability of binary models. Moreover, the center loss is exploited to improve the training procedure for better performance. Experimental results on two public benchmarks (i.e., Skeleton-Kinetics and NTU RGB + D) demonstrate that the accuracy of the proposed PB-GCN and PB-GCN * * are comparable to their full-precision counterparts and outperforms the state-of-the-art methods, such as BWN, XNOR-Net, and Bi-Real Net.},
  archive      = {J_NEUCOM},
  author       = {Mengyi Zhao and Shuling Dai and Yanjun Zhu and Hao Tang and Pan Xie and Yue Li and Chunlei Liu and Baochang Zhang},
  doi          = {10.1016/j.neucom.2022.06.070},
  journal      = {Neurocomputing},
  pages        = {640-649},
  shortjournal = {Neurocomputing},
  title        = {PB-GCN: Progressive binary graph convolutional networks for skeleton-based action recognition},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conversational emotion recognition studies based on graph
convolutional neural networks and a dependent syntactic analysis.
<em>NEUCOM</em>, <em>501</em>, 629–639. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Emotion Recognition for Conversation (ERC) is a challenging multi-class classification task that requires recognizing multiple speakers’ emotions in text, audio, video, and other modalities. ERC has received considerable attention from researchers due to its potential applications in opinion mining, advertising, and healthcare. However, the syntactic structure characteristics of the text itself have not been considered in this study. Taking into account this, this paper proposes a conversational affective analysis model (DSAGCN) combining dependent syntactic analysis and graph convolutional neural networks. Since words that reflect emotional polarity are usually concentrated exclusively in limited regions, the DSAGCN model first employs a self-attention mechanism to capture the most effective words in the dialogue context and obtain a more accurate vector representation of the emotional semantics. Then, based on speaker relationships and dependent syntactic relationships, the multimodal sentiment relationship graphs are constructed. Finally, a graph convolutional neural network is used to complete the recognition of multimodal emotion. In extensive experiments on two real datasets, IEMOCAP and MELD, the DSAGCN model outperforms the existing models in terms of average accuracy and f1 values for multimodal emotion recognition, especially for emotions such as “happiness” and “anger”. Thus, dependent syntactic analysis and self-attention mechanism can enhance the model’s ability to understand emotions.},
  archive      = {J_NEUCOM},
  author       = {Yuntao Shou and Tao Meng and Wei Ai and Sihan Yang and Keqin Li},
  doi          = {10.1016/j.neucom.2022.06.072},
  journal      = {Neurocomputing},
  pages        = {629-639},
  shortjournal = {Neurocomputing},
  title        = {Conversational emotion recognition studies based on graph convolutional neural networks and a dependent syntactic analysis},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Geometry interaction network alignment. <em>NEUCOM</em>,
<em>501</em>, 618–628. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network alignment plays an important role in many fields. The main task of network alignment is to find the node correspondence between different networks, i.e. whether they represent the same natural entity. Most existing alignment methods obtain the relevant information of nodes in the network through network representation learning technology, and then calculate the relationship between different nodes based on the node representations. These methods mostly focus on Euclidean geometry to learn node representations, does Euclidean space fit well with the network alignment? Considering that real-world networks often exhibit hierarchical structure and hyperbolic geometry shows the advantage of expressing network hierarchical structure, some researchers use hyperbolic geometry to learn node representations. But the network is not all hierarchical structure, so we exploit Euclidean and hyperbolic geometries jointly for node representation learning through an interactive learning mechanism to exploit the reliable spatial features in networks. The proposed method can well adapt to the complex structure in the network, providing efficient node representations for network alignment. Extensive experiments on synthetic and real-world datasets show the superiority of our method for network alignment.},
  archive      = {J_NEUCOM},
  author       = {Yinghui Wang and Wenjun Wang and Zixu Zhen and Qiyao Peng and Pengfei Jiao and Wei Liang and Minglai Shao and Yueheng Sun},
  doi          = {10.1016/j.neucom.2022.06.077},
  journal      = {Neurocomputing},
  pages        = {618-628},
  shortjournal = {Neurocomputing},
  title        = {Geometry interaction network alignment},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-view clustering framework via integrating k-means
and graph-cut. <em>NEUCOM</em>, <em>501</em>, 609–617. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-cut and K -means are two classical clustering methods , which are used by most of existing clustering methods . First, a multi-view clustering framework via K -means and graph is proposed and a efficient clustering method is developed based on this framework. Our method calculates the discrete cluster assignment matrix directly and includes the auto-weighted strategy to consider the different contributions of views. Additionally, by generating the distance matrices for views with the corresponding graphs, our method fits both Gaussian and non-Gaussian distributed datasets. Moreover, the proposed algorithm is able to obtain robust results because it does not need initializing and computing cluster centroids . Extensive experiments on a synthetic dataset and four real-world datasets indicate the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Han Lu and Quanxue Gao and Xiangdong Zhang and Wei Xia},
  doi          = {10.1016/j.neucom.2022.05.120},
  journal      = {Neurocomputing},
  pages        = {609-617},
  shortjournal = {Neurocomputing},
  title        = {A multi-view clustering framework via integrating K-means and graph-cut},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An extreme learning machine for unsupervised online anomaly
detection in multivariate time series. <em>NEUCOM</em>, <em>501</em>,
596–608. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised anomaly detection in time series remains challenging, due to the rare and complex patterns of anomalous data. Previous change point detection methods based on extreme learning machine and mutual information (ELM-MI) are potential solutions for this problem. However, the kernels in these methods are randomly initialized on test data, which imposes a constraint that these methods can only be used for offline inference. Moreover, these methods are limited in utilizing temporal contexts, and require the ensemble of multiple models to improve the robustness. To tackle these problems, we introduce a multivariate ELM-MI framework, and combine it with a dynamic kernel selection method, which performs a hierarchical clustering procedure on unlabeled training data and utilizes the clusters to determine the kernels in ELM-MI. In this way, our method can tackle the unsupervised online detection of various anomalous (e.g., point anomalies and group anomalies) and reduce the computational cost. Extensive experiments on three public datasets and our collection of real-life 4G Long-Term Evolution data demonstrate that the proposed method outperforms state-of-the-art methods in terms of effectiveness and efficiency. For demo, see this link: https://personal.ntu.edu.sg/ezplin/NC-demo.htm.},
  archive      = {J_NEUCOM},
  author       = {Xinggan Peng and Hanhui Li and Feng Yuan and Sirajudeen Gulam Razul and Zhebin Chen and Zhiping Lin},
  doi          = {10.1016/j.neucom.2022.06.042},
  journal      = {Neurocomputing},
  pages        = {596-608},
  shortjournal = {Neurocomputing},
  title        = {An extreme learning machine for unsupervised online anomaly detection in multivariate time series},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Patch-DFD: Patch-based end-to-end DeepFake discriminator.
<em>NEUCOM</em>, <em>501</em>, 583–595. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial forgery by DeepFake has recently attracted more public attention. Face image contains sensitive personal information, abuse of such technology will grow into a menace. Since the difference between real and fake faces is usually subtle and local, the general detection framework of applying the backbone network to capture the global features of the entire face and then feeding it into the binary classifier is not optimal. In addition, patch-based schemes are widely used in various computer vision tasks, including image classification. However, how to extract features for location-specific and arbitrary-shaped patches while preserving their original information and spoof patterns as much as possible requires further exploration. In this paper, a novel deep forgery detector called Patch-DFD is proposed, which applies a patch-based solution of Facial Patch Mapping (FPM) to obtain several part-based feature maps, preserving original details of each facial patch to the greatest extent. Besides, the BM-pooling module aims to fix the size of the feature maps while reducing quantization errors. The local voting strategy is finally used to fuse the results of parts detectors, so as to more accurately identify the fake faces generated by deep generative models. Compared to typical patch-wise framework that takes patch inputs, our scheme is more efficient due to the absence of repeated convolution operations. Moreover, extensive experiments conducted on publicly available face forensics datasets have proved that the effectiveness of our framework.},
  archive      = {J_NEUCOM},
  author       = {Miaomiao Yu and Sigang Ju and Jun Zhang and Shuohao Li and Jun Lei and Xiaofei Li},
  doi          = {10.1016/j.neucom.2022.06.013},
  journal      = {Neurocomputing},
  pages        = {583-595},
  shortjournal = {Neurocomputing},
  title        = {Patch-DFD: Patch-based end-to-end DeepFake discriminator},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of variational quantum deep neural networks for
image recognition. <em>NEUCOM</em>, <em>501</em>, 566–582. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parametrized quantum circuits are widely used for supervised learning tasks such as image classification in the noisy intermediate scale quantum era. However, normally, it can only handle low-dimensional data. This study presented a variational quantum deep neural network (VQDNN) model for various scale image recognition tasks. Three classifiers were designed to verify the classification performance of the proposed VQDNN model. In the first classifier, to accommodate the limitations of qubits in both simulation hardware and real quantum hardware – we adopted hybrid principal component analysis – VQDNN architecture. Moreover, the amplitude encoding scheme and the rotation angle coding scheme were employed in the subsequent two classifiers to handle large-size images. Finally, we used the classical neural network and VQDNN model to conduct a comparative experiment of the ten-label classification learning task on the same dataset. The quantum numerical experiment was implemented on two benchmark datasets: the MNIST and UCI databases of handwritten digits . The simulation results showed that the proposed VQDNN classified the two datasets with an accuracy of 100\% for the two-class classification task , while the UCI dataset has an accuracy of 90.87\% for the ten-label classification task . The proposed VQDNN achieved better classification accuracy than the original classical neural network even under a limited number of qubits available in current hardware, indicating the promising application potential of VQDNN in image recognition.},
  archive      = {J_NEUCOM},
  author       = {Yunqian Wang and Yufeng Wang and Chao Chen and Runcai Jiang and Wei Huang},
  doi          = {10.1016/j.neucom.2022.06.010},
  journal      = {Neurocomputing},
  pages        = {566-582},
  shortjournal = {Neurocomputing},
  title        = {Development of variational quantum deep neural networks for image recognition},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SMS-net: Sparse multi-scale voxel feature aggregation
network for LiDAR-based 3D object detection. <em>NEUCOM</em>,
<em>501</em>, 555–565. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time three-dimensional (3D) object detection has become a crucial component of autonomous driving applications. Recent research demonstrates that a voxel-based feature aggregation method is accurate and efficient in large 3D scenes. However, the parameter choice of voxel size has become a sensitive issue because of the contradiction between its detection performance and inference speed. To alleviate this problem, in this paper we propose a sparse multi-scale voxel feature aggregation network (SMS-Net), a novel one-stage, end-to-end network that primarily contains a sparse multi-scale-fusion (SMSF) module and shallow-to-deep regression (SDR) module. First, the raw point clouds are divided into different scales of voxels to construct diverse 3D sparse feature maps. Then, the SMSF module attentively aggregates the point-wise features with a perspective-channel attention mechanism and fuses multi-scale features at 3D sparse feature-map level to achieve more fine-grained shape information. In addition, the new SDR module boosts the localization accuracy and 3D box estimation accuracy through multiple aggregation at feature-map level, which requires less computational overhead. Extensive experiments demonstrate the remarkable performance improvements from each module of the proposed method. On the KITTI 3D object detection benchmark, for example, SMS-Net outperforms most one-stage, state-of-the-art methods and its performance can even be compared to that of two-stage methods. These detection results are achieved with a real-time inference speed of 42 Hz. SMS-Net also achieves state-of-the-art performance on the nuScenes 3D benchmark.},
  archive      = {J_NEUCOM},
  author       = {Sheng Liu and Wenhao Huang and Yifeng Cao and Dingda Li and Shengyong Chen},
  doi          = {10.1016/j.neucom.2022.06.054},
  journal      = {Neurocomputing},
  pages        = {555-565},
  shortjournal = {Neurocomputing},
  title        = {SMS-net: Sparse multi-scale voxel feature aggregation network for LiDAR-based 3D object detection},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hashing-based affinity matrix for dominant set clustering.
<em>NEUCOM</em>, <em>501</em>, 544–554. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dominant set clustering has been widely used to solve a variety of problems such as image segmentation, video analysis, and image retrieval. However, the key problem of it is the need of a given affinity matrix to provide similarity for every pair of data points. The affinity matrix is either user-given or computed using a pairwise computation, which is impractical for big data situations. Therefore, this work proposes a semi-supervised hashing-based affinity matrix computation method (HAM) for dominant set clustering (HAM-DSC) for cases of semi-supervised clustering where labels are available to a portion of data. The HAM computes affinity matrix efficiently based on Hamming distance between learned hash codes, which preserve semantic similarities effectively. To deal with unsupervised clustering problems, an unsupervised extension of the HAM-DSC is also given in this work. Experimental results on 7 real-world datasets show that the HAM-DSC yields an overall better performance together with lower time costs compared to dominant set clustering using other affinity matrix computation methods.},
  archive      = {J_NEUCOM},
  author       = {Qihua Li and Xing Tian and Wing W.Y. Ng and Marcello Pelillo},
  doi          = {10.1016/j.neucom.2022.06.067},
  journal      = {Neurocomputing},
  pages        = {544-554},
  shortjournal = {Neurocomputing},
  title        = {Hashing-based affinity matrix for dominant set clustering},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bid optimization using maximum entropy reinforcement
learning. <em>NEUCOM</em>, <em>501</em>, 529–543. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time bidding (RTB) has become a critical way for online advertising. It allows advertisers to display their ads by bidding on ad impressions. Therefore, advertisers in RTB always seek an optimal bidding strategy to improve their cost-efficiency. Unfortunately, it is challenging to optimize the bidding strategy at the granularity of impression due to the highly dynamic nature of the RTB environment. In this paper, we focus on optimizing the single advertiser’s bidding strategy using a stochastic reinforcement learning (RL) algorithm. Firstly, we utilize a widely adopted linear bidding function to compute every impression’s base price and optimize it with a mutable adjustment factor, thus making the bidding price conform to not only the impression’s value to the advertiser but also the RTB environment. Secondly, we use the maximum entropy RL algorithm (Soft Actor-Critic) to optimize every impression’s adjustment factor to overcome the deterministic RL algorithm’s convergence problem. Finally, we evaluate the proposed strategy on a benchmark dataset (iPinYou), and the results demonstrate it obtained the most click numbers in 9 of 12 experiments compared to baselines.},
  archive      = {J_NEUCOM},
  author       = {Mengjuan Liu and Jinyu Liu and Zhengning Hu and Yuchen Ge and Xuyun Nie},
  doi          = {10.1016/j.neucom.2022.05.108},
  journal      = {Neurocomputing},
  pages        = {529-543},
  shortjournal = {Neurocomputing},
  title        = {Bid optimization using maximum entropy reinforcement learning},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PoseMapGait: A model-based gait recognition method with pose
estimation maps and graph convolutional networks. <em>NEUCOM</em>,
<em>501</em>, 514–528. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition is a particularly effective way to avoid the spread of COVID-19 while people are under surveillance. Because of its advantages of non-contact and long-distance identification. One category of gait recognition methods is appearance-based, which usually extracts human silhouettes as the initial input feature and achieves high recognition rates. However, the silhouette-based feature is easily affected by the view, clothing, bag, and other external variations. Another category is based on model-based, one popular model-based feature is extracted from human skeletons. The skeleton-based feature is robust to many variations because it is less sensitive to human shape. However, the performance of skeleton-based methods suffers from recognition accuracy loss due to limited input information. In this paper, instead of relying on coordinates from skeletons, we exploit that pose estimation maps , the byproduct of pose estimation. It not only preserves richer cues of the human body compared with the skeleton-based feature, but also keeps the advantage of being less sensitive to human shape compared with the silhouette-based feature. Specifically, the evolution of pose estimation maps is decomposed as one heatmaps evolution feature (extracted by gaitMap-CNN ) and one pose evolution feature (extracted by gaitPose-GCN ), which denote the invariant features of whole body structure and body pose joints for gait recognition, respectively. Our method is evaluated on two large datasets, CASIA-B and the CMU Motion of Body (MoBo) dataset. The proposed method achieves the new state-of-the-art performance compared with recent advanced model-based methods.},
  archive      = {J_NEUCOM},
  author       = {Rijun Liao and Zhu Li and Shuvra S. Bhattacharyya and George York},
  doi          = {10.1016/j.neucom.2022.06.048},
  journal      = {Neurocomputing},
  pages        = {514-528},
  shortjournal = {Neurocomputing},
  title        = {PoseMapGait: A model-based gait recognition method with pose estimation maps and graph convolutional networks},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Relaxation LIF: A gradient-based spiking neuron for direct
training deep spiking neural networks. <em>NEUCOM</em>, <em>501</em>,
499–513. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) is a promising learning model due to its computational efficiency for discrete spike events. However, because of the binary output of spiking neurons, the standard backpropagation (BP) method is not suitable for deep SNN training. In this paper, we design a gradient-based spiking neuron named Relaxation Leaky Integrate-and-Fire (RLIF) neuron to enable the direct training of deep SNNs. Specifically, we develop a Re-weighted Straight-Through-Estimator (Re-STE) to model the RLIF neuron and SNNs. The Re-STE decomposes the output of the famous LIF neuron and generates a spike by iteratively re-weighting the membrane potential (MP). Then, the RLIF neuron is built, and the re-weighted MP provides a surrogate gradient for BP training. We theoretically prove that the Re-STE is an approximation of the STE technique with logarithmic activation. Such property guarantees that the designed RLIF neuron mitigates the mismatching gradient problem within limits. Finally, we design the RLIF-based VGG-like and ResNet-like SNNs for classification tasks . Experimental results show that the RLIF-based SNNs perform well on the popular benchmark datasets (MNIST, CIFAR10, CIFAR100, N-MNIST, CIFAR10-DVS, and DVS128-GESTURE) and achieve significant efficiencies in most cases.},
  archive      = {J_NEUCOM},
  author       = {Jianxiong Tang and Jian-Huang Lai and Wei-Shi Zheng and Lingxiao Yang and Xiaohua Xie},
  doi          = {10.1016/j.neucom.2022.06.036},
  journal      = {Neurocomputing},
  pages        = {499-513},
  shortjournal = {Neurocomputing},
  title        = {Relaxation LIF: A gradient-based spiking neuron for direct training deep spiking neural networks},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Observer-based consensus for fractional-order multi-agent
systems with positive constraint. <em>NEUCOM</em>, <em>501</em>,
489–498. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with consensus for fractional-order multi-agent systems by observer-type output feedback with positive constraint depicted by general linear model. First, an observer-based protocol is presented and the sufficient conditions for the consensus for fractional-order multi-agent systems with positive constraint are derived. Then, the simplified conditions without utilizing the detailed topology of the graph are given. In order to simplify the process of the solution of the feedback gain matrix and the observer gain matrix, the linear programming approach is used. When the system matrix is strictly Metzler, semidefinite programming approach is adopted. Finally, some illustration examples are presented as the verification of the obtained methods.},
  archive      = {J_NEUCOM},
  author       = {Siyu Chen and Qing An and Hongtao Zhou and Housheng Su},
  doi          = {10.1016/j.neucom.2022.06.038},
  journal      = {Neurocomputing},
  pages        = {489-498},
  shortjournal = {Neurocomputing},
  title        = {Observer-based consensus for fractional-order multi-agent systems with positive constraint},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sequence to sequence learning for joint extraction of
entities and relations. <em>NEUCOM</em>, <em>501</em>, 480–488. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The relations of two entities contained in the sentence are often complicated. There exists multiple relation tuples which owns one or both the same entities among them. Extracting those overlapped multiple relation tuples faces great challenges. Most existing works employ the famous Seq2Seq model for joint extraction of entities and relations, which cannot handle the multiple relations properly due to the missing of graph structure information of the relations and entities in a sentence. In this paper, we propose Seq2Seq-RE, an end-to-end relation extraction model, which first utilizes the gate graph neural networks (GGNNs) for joint extraction of entities and relations. Unlike previous works, we take the interaction of entities and relations through a GGNNs-based sequence-to-sequence with attention mechanism for better extracting multiple relation tuples. Besides, our graph structure based on the forward-edge, backward-edge, self-edge, and dependency-edge. To our knowledge, we are the first to employ four types of edge into graph-based neural networks for joint extraction of entities and relations and conduct a comprehensive qualitative analysis to investigate what types of edges benefit our task. Experimental results show that our model surpasses the current strong baseline methods by 1.7\% in NYT29 and 0.8\% in NYT24 (F1 score).},
  archive      = {J_NEUCOM},
  author       = {Zeyu Liang and Junping Du},
  doi          = {10.1016/j.neucom.2022.05.074},
  journal      = {Neurocomputing},
  pages        = {480-488},
  shortjournal = {Neurocomputing},
  title        = {Sequence to sequence learning for joint extraction of entities and relations},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A zonotope-based fault detection for multirate systems with
improved dynamical scheduling protocols. <em>NEUCOM</em>, <em>501</em>,
471–479. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the distributed fault detection problem for a class of discrete-time multi-rate systems over sensor networks with an improved communication protocol, where both unknown-but-bounded (UBB) noises and faults are comprised in two zonotopic sequences. Inspired by famous try-once-discard (TOD) protocols, a novel quasi-TOD-based protocol with dynamical weights is proposed to govern the signal transmission between the sensor nodes and the remote filter. In terms of lifting techniques, the augmented filtering error dynamics is set up a unified sampling rate. By resorting to the properties of zonotopes as well as the mathematical induction , a series of zonotopic sets confining filtering errors is first received, and then their F -radii are minimized to derive the desired filter parameters. Furthermore, a zonotope-based residual evaluation mechanism is designed to detect possibly occurred faults. Finally, a numerical example is employed to verify the availability of the presented zonotope-based fault detection scheme .},
  archive      = {J_NEUCOM},
  author       = {Yamei Ju and Hongjian Liu and Derui Ding and Ying Sun},
  doi          = {10.1016/j.neucom.2022.06.003},
  journal      = {Neurocomputing},
  pages        = {471-479},
  shortjournal = {Neurocomputing},
  title        = {A zonotope-based fault detection for multirate systems with improved dynamical scheduling protocols},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A general quadratic negative-determination lemma for
stability analysis of delayed neural networks. <em>NEUCOM</em>,
<em>501</em>, 463–470. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the stability problem of delayed neural networks with time-varying delay. A general quadratic negative-determination lemma (GQNL) is presented in this paper. GQNL takes full use of the introduced parameter and the interval endpoints, which can further reduce the conservatism of stability criteria without increasing the number of decision variables (NoVs). A stability criterion for delayed neural networks is obtained by employing GQNLand the superiority of the proposed criterion is demonstrated by two numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Fang Liu and Weiru Guo and Runmin Zou and Kangzhi Liu},
  doi          = {10.1016/j.neucom.2022.06.040},
  journal      = {Neurocomputing},
  pages        = {463-470},
  shortjournal = {Neurocomputing},
  title        = {A general quadratic negative-determination lemma for stability analysis of delayed neural networks},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural-networks-based event-triggered consensus tracking
control for nonlinear MASs with DoS attacks. <em>NEUCOM</em>,
<em>501</em>, 451–462. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we explore the observer-based event-triggered tracking control problem for nonlinear multi-agent systems (MASs) under denial-of-service (DoS) attacks. To overcome the difficulty introduced by the nonlinear term, an observer based on neural networks (NNs-observer) is introduced to estimate unavailable system states. Besides, this paper designs a new secure distributed controller which can achieve the tracking control objective while maintaining the tolerance to DoS attacks. Furthermore, in order to save network resources, a new event-triggered mechanism is introduced which is mathematically proved to be free of the Zeno phenomenon. Finally, an example is provided to support the effectiveness of the proposed NNs-observer-based event-triggered resilient tracking control scheme.},
  archive      = {J_NEUCOM},
  author       = {Yang Xiao and Wei-Wei Che and Member, IEEE},
  doi          = {10.1016/j.neucom.2022.06.029},
  journal      = {Neurocomputing},
  pages        = {451-462},
  shortjournal = {Neurocomputing},
  title        = {Neural-networks-based event-triggered consensus tracking control for nonlinear MASs with DoS attacks},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Geometrical structure preservation joint with
self-expression maintenance for adaptive graph learning.
<em>NEUCOM</em>, <em>501</em>, 436–450. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Locality preserving projection (LPP) is a subspace learning method that uses pairwise distance to measure the similarity between data points. However, when data points from different clusters are adjacent, the pairwise distance may not accurately reflect the similarity between data points. In this study, a novel graph learning model is proposed to alleviate this problem; it is called adaptive graph learning with geometrical structure preservation and self-expression maintenance (GEAGL), in which a discriminative LPP method is used to extract the geometrical structure of data. By integrating self-expressive learning into the LPP method, a similarity graph that preserves the geometrical structure and self-expressive properties of data can be adaptively learned. The learned similarity graph tends to consist of a block diagonal structure when data points are extracted from independent linear subspaces, which alleviates the cluster interweaving problem. In this study, the relationship between the proposed method and k-means clustering was revealed, and the geometrical structure preservation property of the proposed method was theoretically analyzed. Finally, a graph-based clustering method was developed based on the similarity graph produced by GEAGL. Experimental results of benchmark datasets demonstrate the superiority of the proposed method in comparison with state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yangbo Wang and Can Gao and Jie Zhou},
  doi          = {10.1016/j.neucom.2022.06.045},
  journal      = {Neurocomputing},
  pages        = {436-450},
  shortjournal = {Neurocomputing},
  title        = {Geometrical structure preservation joint with self-expression maintenance for adaptive graph learning},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mining confident supervision by prototypes discovering and
annotation selection for weakly supervised semantic segmentation.
<em>NEUCOM</em>, <em>501</em>, 420–435. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised semantic segmentation methods generate proxy annotations for images based on image-level labels, and further optimize the segmentation network on these annotations with various constraints. However, the performance of current segmentation methods is often constrained by the quality of proxy annotations, even if saliency maps can work as strong background priors. Therefore, how to improve the quality of proxy annotations by mining more confident supervision has become a problem worth exploring and challenging. In this paper, we investigate two novel mechanisms to produce proxy annotations with higher quality: (1) designing a principal prototypical features discovering (PPFD) strategy for object localization, which is capable of utilizing image-level labels and coarse pixel-level annotations jointly, and (2) designing an effective annotation selection and refinement (ASR) strategy for improving annotations’ quality. The proposed strategy can localize foreground pixels by means of extracting prototypical feature from activation features of a group of images. Subsequently, the resulting PPFD based localization maps are utilized to generate proxy annotations for weakly supervised semantic segmentation. In addition, ASR is employed to recognize and refine the low-quality proxy annotations by self-judgment based mask scoring and discriminative regions mining. Experimental results on the PASCAL VOC 2012 and COCO 2014 datasets demonstrate that the proposed algorithm performs better than the state-of-the-art methods on the segmentation benchmark.},
  archive      = {J_NEUCOM},
  author       = {Lei Zhou and Huagui Chen and Yufeng Wei and Xiaoxiao Li},
  doi          = {10.1016/j.neucom.2022.06.037},
  journal      = {Neurocomputing},
  pages        = {420-435},
  shortjournal = {Neurocomputing},
  title        = {Mining confident supervision by prototypes discovering and annotation selection for weakly supervised semantic segmentation},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-uniform nyström approximation for sparse kernel
regression: Theoretical analysis and experimental evaluation.
<em>NEUCOM</em>, <em>501</em>, 410–419. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving a kernel regression problem usually suffers from expensive computation and storage costs due to the large kernel size. To tackle this problem, the Nyström method is proposed and widely applied to large-scale kernel methods as an approximate solution. The key idea of this method is to select a subset of columns of the kernel matrix and rebuilds a low-rank approximation to the dense kernel matrix. To reduce computational costs of sparse kernel regression, we take the merits of the Nyström approximation and present two non-uniform Nyström methods with theoretical guarantees for sparse kernel regression in this paper. In detail, we first provide an upper bound to the solution of sparse kernel regression via Nyström approximation. Based on this bound, we prove the upper bounds of the optimal solutions when adopting two notable non-uniform landmark selection strategies, including Determinantal Point Processes (DPPs) and Ridge Leverage Scores (RLS). Compared with the uniform Nyström method, we empirically demonstrate the superior performance of non-uniform Nyström in sparse kernel regression on a synthetic dataset and several real-world datasets.},
  archive      = {J_NEUCOM},
  author       = {Qian Zhang and Wei Shi and Steven Hoi and Zenglin Xu},
  doi          = {10.1016/j.neucom.2022.05.112},
  journal      = {Neurocomputing},
  pages        = {410-419},
  shortjournal = {Neurocomputing},
  title        = {Non-uniform nyström approximation for sparse kernel regression: Theoretical analysis and experimental evaluation},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). State estimation for memristive neural networks with mixed
time-varying delays via multiple integral equality. <em>NEUCOM</em>,
<em>501</em>, 397–409. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of state estimation for memristive neural networks with leakage, discrete, and distributed delays. Specifically, we firstly take simplified double integration as an example to deriving the multiple integral equality by using the integration properties. And then, we develop a novel Lyapunov–Krasovskii functional (LKF) including multiple integral terms, which improve stability criteria in terms of linear matrix inequalities (LMIs) and present to the superiority of potential efficiency in practice. More importantly, a stability criterion with less conservative has been established by using lemma and the principle of distributed integral calculation. Finally, numerical examples are given to illustrate the effectiveness of the proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Lijuan Chen and Binbin Li and Ruimei Zhang and Jinnan Luo and Chuanbo Wen and Shouming Zhong},
  doi          = {10.1016/j.neucom.2022.06.044},
  journal      = {Neurocomputing},
  pages        = {397-409},
  shortjournal = {Neurocomputing},
  title        = {State estimation for memristive neural networks with mixed time-varying delays via multiple integral equality},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Simple-action-guided dictionary learning for complex action
recognition. <em>NEUCOM</em>, <em>501</em>, 387–396. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex action recognition is an important yet challenging problem because of uncontrolled scenes, such as partial occlusions, viewpoint changes and dynamically changing backgrounds. Meanwhile obtaining a robust and performance model requires sufficient labeled training data, and it is hard to obtain. Due to the fact that each complex action is composed of a sequence of simple actions, they can share the common dictionary. To utilize such decomposition form, we build a simple-action-guided dictionary learning model (SAG-DLM) for complex action recognition. Especially, a common dictionary is learned by simple actions to model action-shared features, and we will transfer the common dictionary to help complex action learning. Further the difference complex action dictionary is studied to better obtain sparse representation . Finally, the complex actions are reconstructed by the common dictionary and the difference complex action dictionary. We validate the proposed SAG-DLM on two complex datasets: Olympic Sports dataset and UCF50 dataset. Extensive experiments prove that the effectiveness of the proposed SAG-DLM, and the learned common dictionary can provide promising improvement.},
  archive      = {J_NEUCOM},
  author       = {Fang Liu and Xiangmin Xu and Xiaofen Xing and Kailing Guo and Lin Wang},
  doi          = {10.1016/j.neucom.2022.06.034},
  journal      = {Neurocomputing},
  pages        = {387-396},
  shortjournal = {Neurocomputing},
  title        = {Simple-action-guided dictionary learning for complex action recognition},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An RBF online learning scheme for non-stationary
environments based on fuzzy means and givens rotations. <em>NEUCOM</em>,
<em>501</em>, 370–386. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning on non-stationary environments is laden with many challenges, as the procedure is usually characterized by drifts and data unavailability; on the other hand, it is of great importance with regard to data stream modeling, where an effective and up-to date model is required as the data stream evolves. This work presents a new method for producing highly accurate models for learning on such environments. The method is based on artificial neural networks (ANNs) and more specifically on the efficient architecture of radial basis function (RBF) networks. A novel RBF online training scheme for real time adaption of both the network structure and parameter values is proposed based on the fuzzy means (FM) algorithm and the Givens rotations technique. Within this integrated framework, it is guaranteed that for each update of the network structure, the optimal values for the synaptic weights are calculated efficiently by maintaining low order matrix updates. The proposed approach is evaluated on 9 real-word and artificial benchmark data streams, including a challenging real-world application which involves precipitation prediction, and is compared to other well-known methodologies from the literature. The results show that the FM-Givens algorithm produces models with highly competitive online accuracy for non-stationary environments in the presence of drifts, while maintaining low model-updating times.},
  archive      = {J_NEUCOM},
  author       = {Despina Karamichailidou and Sotirios Koletsios and Alex Alexandridis},
  doi          = {10.1016/j.neucom.2022.06.016},
  journal      = {Neurocomputing},
  pages        = {370-386},
  shortjournal = {Neurocomputing},
  title        = {An RBF online learning scheme for non-stationary environments based on fuzzy means and givens rotations},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attention-based cropping and erasing learning with
coarse-to-fine refinement for fine-grained visual classification.
<em>NEUCOM</em>, <em>501</em>, 359–369. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained visual classification is challenging due to similarities within classes and discriminative features located in subtle regions. Conventional methods focus on extracting features from the most discriminative parts, which may underperform when these parts are occluded or invisible. And the limited training data also leads to serious overfitting problem. In this paper, we propose an Attention-based Cropping and Erasing Network (ACEN) with a coarse-to-fine refinement strategy to address these problems. By convolving the feature maps from CNN, we obtain a set of attention maps which focus on discriminative object parts. Guided by the attention maps, we propose attention region cropping and erasing operations to augment training data. Moreover, the attention region cropping enhances local discriminative feature learning, and the attention region erasing promotes multi-attention learning. During inference phase, the coarse-to-fine refinement strategy is proposed to refine the model prediction. Extensive experiments demonstrate that our approach achieves state-of-the-art performance on challenging benchmarks, including CUB-200-2011, FGVC-Aircraft and Stanford Cars.},
  archive      = {J_NEUCOM},
  author       = {Jianpin Chen and Heng Li and Junlin Liang and Xiaofan Su and Zhenzhen Zhai and Xinyu Chai},
  doi          = {10.1016/j.neucom.2022.06.041},
  journal      = {Neurocomputing},
  pages        = {359-369},
  shortjournal = {Neurocomputing},
  title        = {Attention-based cropping and erasing learning with coarse-to-fine refinement for fine-grained visual classification},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Why KDAC? A general activation function for knowledge
discovery. <em>NEUCOM</em>, <em>501</em>, 343–358. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning oriented named entity recognition (DNER) has gradually become the paradigm of knowledge discovery, which greatly promotes domain intelligence. However, the activation function of DNER fails to treat gradient vanishing, no negative output or non-differentiable existence, which may impede the exploration of knowledge due to the omission and incomplete representation of the latent semantic. To break through the dilemma, we present a novel activation function termed KDAC. Detailly, KDAC is an aggregation function with multiple conversion modes. The backbone is the interaction between exponent and linearity, and the both ends are extended through adaptive linear divergence, which can surmount the gradient vanishing and no negative output. Crucially, the non-differentiable points can be alerted and eliminated by an approximate smoothing algorithm. KDAC has a series of brilliant properties, such as nonlinear, stable near-linear transformation and derivative, as well as dynamic style, etc. We perform experiments based on BERT-BiLSTM-CNN-CRF model on six benchmark datasets containing different domain knowledge, such as Weibo , Clinical , E-commerce , Resume , HAZOP and People&#39;s daily . The evaluation results show that KDAC is advanced and effective, and can provide more generalized activation to stimulate the performance of DNER. We hope that KDAC can be exploited as a promising activation function to devote itself to the construction of knowledge.},
  archive      = {J_NEUCOM},
  author       = {Zhenhua Wang and Haozhe Liu and Fanglin Liu and Dong Gao},
  doi          = {10.1016/j.neucom.2022.06.019},
  journal      = {Neurocomputing},
  pages        = {343-358},
  shortjournal = {Neurocomputing},
  title        = {Why KDAC? a general activation function for knowledge discovery},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MICQ-IPSO: An effective two-stage hybrid feature selection
algorithm for high-dimensional data. <em>NEUCOM</em>, <em>501</em>,
328–342. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In machine learning and pattern recognition tasks, classification performance is often degraded due to the existence of irrelevant and redundant features, especially for high-dimensional data. As a data preprocessing tool, feature selection can improve classification performance while reducing the number of features. Focusing on high-dimensional data, we propose a novel two-stage hybrid feature selection method that combines the maximum information coefficient (MIC) based Q-learning algorithm and the improved particle swarm optimization (PSO) based algorithm, named as MICQ-IPSO. In the first stage, we employed an intelligent feature pre-screening operation to get a rough feature subset, which introduced MIC value as the correlation measure and automated the determination of the screening threshold by Q-learning. In the second stage, we applied an improved PSO-based method to get an optimal feature subset. During this stage, a swarm initialization strategy based on MIC correlation was used to narrow the search range and accelerate swarm convergence. To further enhance the exploitability, a deeper local search operation was performed in the search region. Moreover, a particle reset strategy was adopted to help particles jump out of the local optimal solution . Finally, we evaluated our algorithm against several state-of-the-art feature selection approaches on 17 benchmark datasets. The experimental results demonstrate the effectiveness and competitiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Xinqian Li and Jia Ren},
  doi          = {10.1016/j.neucom.2022.05.048},
  journal      = {Neurocomputing},
  pages        = {328-342},
  shortjournal = {Neurocomputing},
  title        = {MICQ-IPSO: An effective two-stage hybrid feature selection algorithm for high-dimensional data},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards high-quality thermal infrared image colorization via
attention-based hierarchical network. <em>NEUCOM</em>, <em>501</em>,
318–327. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorization is an effective technology to improve the imaging quality of thermal infrared sensors, which is of great importance to environmental perception systems. Recently, colorization for thermal infrared images has realized obvious improvement with the development of deep learning . However, the performance of current designs is not adequate to achieve satisfied colorization quality. This is mainly because that thermal infrared image colorization requires the abilities of both color prediction and grayscale detail recovery, which poses severe challenges for feature extraction due to the poor quality of thermal infrared images. Furthermore, most of the current networks are based on generative adversarial network , suffering the risks of training instability and mode collapse. In this paper, we propose a high-quality colorization network for thermal infrared images. By leveraging hierarchical architecture, attention mechanism , and proposing a composite loss function, our network not only significantly improves the quality of colorized thermal infrared images but also achieves a speed of 32 fps on NVIDIA 2080Ti GPU platform. In evaluation experiments, PSNR and SSIM can be increased by at least 0.87 dB and 0.0277 compared with previous methods on publicly available datasets. Experimental results demonstrate that the proposed network can produce state-of-the-art colorized thermal infrared images both in objective metrics and subjective quality.},
  archive      = {J_NEUCOM},
  author       = {Hang Wang and Cheng Cheng and Xuchong Zhang and Hongbin Sun},
  doi          = {10.1016/j.neucom.2022.06.021},
  journal      = {Neurocomputing},
  pages        = {318-327},
  shortjournal = {Neurocomputing},
  title        = {Towards high-quality thermal infrared image colorization via attention-based hierarchical network},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantic inpainting on segmentation map via multi-expansion
loss. <em>NEUCOM</em>, <em>501</em>, 306–317. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic Inpainting on Segmentation Map (SISM) aims to manipulate segmentation maps by semantics. Recent works show SISM provides semantic-aware auxiliary information for better style or structure manipulations. Providing structural assistance, segmentation maps have been broadly used as an intermediate interface to achieve better image manipulation. Mainstream solutions of image manipulation use Generative Adversarial Net (GAN) globally, locally or jointly. It is also applicable to SISM. However, the discriminator of global GAN is easier fooled, because the majority of its input is the same as the ground-truth, which is hard to fully mitigate the inconsistency between inpainted areas and the context. The inconsistency is more difficult for local GAN to address, due to the lack of context in its input. To mitigate the inconsistency, we propose a novel Multi-Expansion (MEx) loss. It is implemented by the adversarial loss on MEx areas. Each MEx area has the inpainted area as dominance and keeps knowledge of the scene context, so the consistency of the SISM results can be boosted. We propose an approximation of MEx loss, i.e., A-MEx loss, to further enhance the stability and usability. Besides performing well on SISM tasks, MEx loss also performs impressively on natural image inpainting . Extensive experiments on the two tasks demonstrate the advantages of our model over existing methods on four challenging datasets, such as a 2.59\% increase in Hamm on SISM in Cityscape and a decrease of 5.00\% FID on natural image inpainting in CMP Facade. The code of our work is available at: https://github.com/he159ok/AMEx-MEx-Loss .},
  archive      = {J_NEUCOM},
  author       = {Jianfeng He and Xuchao Zhang and Shuo Lei and Shuhui Wang and Chang-Tien Lu and Bei Xiao},
  doi          = {10.1016/j.neucom.2022.06.025},
  journal      = {Neurocomputing},
  pages        = {306-317},
  shortjournal = {Neurocomputing},
  title        = {Semantic inpainting on segmentation map via multi-expansion loss},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Crafting universal adversarial perturbations with output
vectors. <em>NEUCOM</em>, <em>501</em>, 294–305. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, researches on universal adversarial perturbations have deepened the public’s attention to the security of deep neural networks (DNNs). Most researchers use iterative methods or generative adversarial networks (GANs) to find universal adversarial perturbations (UAPs). However, just focusing on outputs still cannot separate adversarial examples in feature space and there is almost no correlation between the perturbations generated by random noise and the target network. To cope with these problems, we propose a novel end-to-end UAPs generation framework that uses constant activation information as the input of the generator and adopts a feature adaptive loss function. Experiments show that the attack success rate of our UAPs has reached a competitive level against different classification networks on CIFAR-10 and ImageNet where the average fooling rate can reach 86\% and 96\%, leading to 19\% and 16\% improvements over UAP, respectively. Furthermore, we demonstrate the great generalization ability and strong transferability of proposed attacker. Finally, the proposed attacker can achieve lower mAP and mean IoU than several classical white box attackers in object detection task and image segmentation task.},
  archive      = {J_NEUCOM},
  author       = {Xu Kang and Bin Song and Dan Wang and Xiaohui Cai},
  doi          = {10.1016/j.neucom.2022.06.005},
  journal      = {Neurocomputing},
  pages        = {294-305},
  shortjournal = {Neurocomputing},
  title        = {Crafting universal adversarial perturbations with output vectors},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Neighbour feature attention-based pooling. <em>NEUCOM</em>,
<em>501</em>, 285–293. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern convolutional neural networks (CNNs), the pooling layer is seen as one of the primary layers for building the CNN model, which effectively downscales the spatial size of feature maps to reduce memory consumption. Several types of pooling operations, such as average pooling , max pooling, and strided convolution, fail to capture the spatial dependence between the pooling region feature and its neighbour features. In this paper, we propose a simple but effective attention-based pooling method called Neighbour Feature Attention-Based Pooling (NFP), which integrates neighbour features of the pooling region to keep semantic continuity across multiple layers. NFP adopts attention weights encoding with neighbour features by depthwise convolution, which effectively directs local spatial pooling for learning discriminative features . Compared to other pooling methods, the proposed method generates more discriminative features directed by neighbour information of the pooling region. The experiments results show that it consistently improves the performance across various backbone architectures on image classification tasks .},
  archive      = {J_NEUCOM},
  author       = {Xiaosong Li and Yanxia Wu and Yan Fu and Chuheng Tang and Lidan Zhang},
  doi          = {10.1016/j.neucom.2022.05.094},
  journal      = {Neurocomputing},
  pages        = {285-293},
  shortjournal = {Neurocomputing},
  title        = {Neighbour feature attention-based pooling},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Revisiting instance search: A new benchmark using cycle
self-training. <em>NEUCOM</em>, <em>501</em>, 270–284. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance search aims at retrieving a particular object instance from a set of scene images. Although studied in previous competitions like TRECVID, there have been limited literature or datasets on this topic. In this paper, to overcome the generalization issue when arbitrary categories are involved in search and to benefit from the large amount of unlabeled data , we propose a cycle self-training framework which trains the instance search pipeline with automatic supervision. Given the two-stage pipeline with a localization and ranking module, the cycle self-training includes a ranker-guided localizer, and a localizer-guided ranker, each carefully designed to handle noisy labels that come with self-supervision. Furthermore, we build and release large-scale groundtruth annotations for instances to facilitate the algorithm evaluation and analysis in this research topic, especially for small objects in complex background. The datasets are publicly available at https://github.com/instance-search/instance-search . Extensive experiments show the effectiveness of the proposed cycle self-training framework and the superior performance compared with other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yuqi Zhang and Chong Liu and Weihua Chen and Xianzhe Xu and Fan Wang and Hao Li and Shiyu Hu and Xin Zhao},
  doi          = {10.1016/j.neucom.2022.06.027},
  journal      = {Neurocomputing},
  pages        = {270-284},
  shortjournal = {Neurocomputing},
  title        = {Revisiting instance search: A new benchmark using cycle self-training},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A lightweight network for real-time smoke semantic
segmentation based on dual paths. <em>NEUCOM</em>, <em>501</em>,
258–269. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are challenges exist in the segmentation of smoke contours on images currently, the requirements for limited processing resources and low-latency operations based on monitoring platform, and the balance between high accuracy and real-time efficiency of the model performance. Also, smoke always shows to be translucency, resulting in a highly complex mixture of the background and itself, sparse or small smoke is not visually obvious, and its borders are often blurred. Therefore, the task of separating smoke from a single image is challengeable. To overcome the challenges, a dual-path real-time smoke segmentation network based on BiSeNet is adopted in this research, and a PPM to expand the receptive field in the spatial path is added to improve the ability to obtain global information. At the same time, a lightweight ECA channel attention module, included in a context path with fast down-sampling strategy, could reduce the complexity while ensuring the effect of the model. Experimental results show that, on all the self-built dataset, the public synthetic smoke dataset and public videos, the proposed method shows excellent performance, and the detection speed reaches real-time segmentation level, showing high practical value.},
  archive      = {J_NEUCOM},
  author       = {Yuming Li and Wei Zhang and Yanyan Liu and Xiaorui Shao},
  doi          = {10.1016/j.neucom.2022.06.026},
  journal      = {Neurocomputing},
  pages        = {258-269},
  shortjournal = {Neurocomputing},
  title        = {A lightweight network for real-time smoke semantic segmentation based on dual paths},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-feature fusion: Graph neural network and CNN combining
for hyperspectral image classification. <em>NEUCOM</em>, <em>501</em>,
246–257. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its impressive representation power, the graph convolutional network (GCN) has attracted increasing attention in the hyperspectral image (HSI) classification. However, the most of available GCN-based methods for HSI classification utilize superpixels as graph nodes, which ignore the pixel-wise spectral-spatial features. To overcome the issues, we propose a novel multi-feature fusion network (MFGCN), where two different convolutional networks , i.e., multi-scale GCN and multi-scale convolutional neural network (CNN), are utilized in two branches, separately. The multi-scale superpixel-based GCN can reduce the computing power requirements, deal with the problem of labeled deficiency, and refine the multi-scale spatial features from HSI. The multi-scale CNN can extract the multi-scale pixel-wise local features for HSI classification. Furthermore, we introduced a 1D CNN to extract the spectral features for superpixels (nodes), which is different from most existing methods. Finally, a concatenate operation is employed to fuse the complementary multi-scale features. In comparison with the state-of-the-art models on three datasets, the proposed method achieves superior experimental results and outperforms competitive methods.},
  archive      = {J_NEUCOM},
  author       = {Yao Ding and Zhili Zhang and Xiaofeng Zhao and Danfeng Hong and Wei Cai and Chengguo Yu and Nengjun Yang and Weiwei Cai},
  doi          = {10.1016/j.neucom.2022.06.031},
  journal      = {Neurocomputing},
  pages        = {246-257},
  shortjournal = {Neurocomputing},
  title        = {Multi-feature fusion: Graph neural network and CNN combining for hyperspectral image classification},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph-powered learning for social networks. <em>NEUCOM</em>,
<em>501</em>, 244–245. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Zhipeng Cai and Christian Esposito and Tooska Dargahi and Chaokun Wang},
  doi          = {10.1016/j.neucom.2022.05.029},
  journal      = {Neurocomputing},
  pages        = {244-245},
  shortjournal = {Neurocomputing},
  title        = {Graph-powered learning for social networks},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simplified-attention enhanced graph convolutional network
for 3D human pose estimation. <em>NEUCOM</em>, <em>501</em>, 231–243.
(<a href="https://doi.org/10.1016/j.neucom.2022.06.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical motion capture systems have been used intensively to obtain human body poses. However, there still exist several problems. First is the dislocation problem caused by joints being too close together. The second is the joint lost problem. Restricted by severe self-occlusions, cameras may not capture the target joints. Given this observation, we investigate the high-level constraints over human poses to solve these two problems. In this work, we present a Simplified-attention Enhanced Graph Convolutional Network (SaEGC-Net) to extract both spatial and temporal features from monocular videos flexibly. The SaEGC-Net for 3D human pose estimation is U-shaped and involves the Cascaded Spatial-Temporal Graph Convolutional (CST-GC) blocks and the Simplified Spatial-Temporal Attention (SST-Att) blocks, allowing for drawing long-range dependencies between unconnected joints by graph topologies and attention mechanism , respectively. Specifically, the CST-GC block embeds two predefined graph structures into a convolutional network , incorporating discriminative features from distant joints. The proposed SST-Att block disregards redundant information by sharing part of the attention map, which is highly lightweight. It also considers dimension-expanded joint relationships to maintain the diversity of dependence. To evaluate the effectiveness of our method, we conduct extensive experiments on two datasets: Human3.6M and our own dataset FDU-Motion. Results demonstrate that our model achieves excellent performance and can competently handle the above two problems. Also, ablation studies show that our network’s submodules can better exploit the motion information of the human body.},
  archive      = {J_NEUCOM},
  author       = {Tianfeng Wang and Xiaoxu Zhang},
  doi          = {10.1016/j.neucom.2022.06.033},
  journal      = {Neurocomputing},
  pages        = {231-243},
  shortjournal = {Neurocomputing},
  title        = {Simplified-attention enhanced graph convolutional network for 3D human pose estimation},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spiking neural p systems with cooperative synapses.
<em>NEUCOM</em>, <em>501</em>, 222–230. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural P systems (SN P systems) are a class of neuron-inspired computation models, where each synapse independently passes a spike produced by the pre-synaptic neuron to the post-synaptic neuron. Motivated by the mechanism of cooperative synapses in biological systems, we propose a variant of SN P systems called spiking neural P systems with cooperative synapses (SNPCS systems). Specifically, for a set of cooperative synapses in an SNPCS system, if all the synapses in the set have spikes passing through, then each post-synaptic neuron of these synapses receives a unit positive potential; if some synapses in the set, instead of all, have spikes passing through, then each post-synaptic neuron of the synapses passing spikes through receives a unit negative potential. The computation power of SNPCS systems is investigated. It is proved that SNPCS systems are Turing universal as function computing devices. Moreover, SNPCS systems are constructed to solve the NP-hard problem, the Subset Sum problem, in a uniform way.},
  archive      = {J_NEUCOM},
  author       = {Luping Zhang and Fei Xu},
  doi          = {10.1016/j.neucom.2022.05.088},
  journal      = {Neurocomputing},
  pages        = {222-230},
  shortjournal = {Neurocomputing},
  title        = {Spiking neural p systems with cooperative synapses},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Label distribution learning through exploring nonnegative
components. <em>NEUCOM</em>, <em>501</em>, 212–221. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning (LDL) is a new machine learning paradigm to solve label ambiguity and has drawn increasing attention in recent years. The importance of all labels needs to be considered under the LDL settings. A series of approaches have been proposed to deal with the LDL problem by considering the correlation of labels or instances. However, none of them focuses on finding interpretable bases to reduce the dimensions of the feature space. Inspired by the semi-nonnegative matrix factorization (semi-NMF) method, we propose a new LDL learning framework to deal with the problem through learning nonnegative components. The key insight is to explore the bases, each of which represents a class, through the label distribution and to transform the input matrix into a coefficient matrix of the space constructed by the bases. Consequently, a maximum entropy model can be adopted to learn the label distribution from the coefficient matrix . Experimental results on real-world datasets comparing our method with several state-of-the-art methods validate the performance of our approach.},
  archive      = {J_NEUCOM},
  author       = {Tianyue Zhang and Yingke Mao and Furao Shen and Jian Zhao},
  doi          = {10.1016/j.neucom.2022.06.017},
  journal      = {Neurocomputing},
  pages        = {212-221},
  shortjournal = {Neurocomputing},
  title        = {Label distribution learning through exploring nonnegative components},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IdentityDP: Differential private identification protection
for face images. <em>NEUCOM</em>, <em>501</em>, 197–211. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the explosive growth of face photos as well as their widespread dissemination and easy accessibility in social media, the security and privacy of personal identity information become an unprecedented challenge. Meanwhile, the convenience brought by advanced identity-agnostic computer vision technologies is attractive. Therefore, it is important to use face images while taking careful consideration in protecting people’s identities. Given a face image, face de-identification, also known as face anonymization, refers to generating another image with similar appearance and the same background, while the real identity is hidden. Although extensive efforts have been made, existing face de-identification techniques are either insufficient in photo-reality or incapable of well-balancing privacy and utility. In this paper, we focus on tackling these challenges to improve face de-identification. We propose IdentityDP, a face anonymization framework that combines a data-driven deep neural network with a differential privacy (DP) mechanism. This framework encompasses three stages: facial representations disentanglement, ∊ ∊ ∊ -IdentityDP perturbation and image reconstruction. Our model can effectively obfuscate the identity-related information of faces, preserve significant visual similarity, and generate high-quality images that can be used for identity-agnostic computer vision tasks , such as detection, tracking, etc. Different from the previous methods, we can adjust the balance of privacy and utility through the privacy budget according to practical demands and provide a diversity of results without pre-annotations. Extensive experiments demonstrate the effectiveness and generalization ability of our proposed anonymization framework.},
  archive      = {J_NEUCOM},
  author       = {Yunqian Wen and Bo Liu and Ming Ding and Rong Xie and Li Song},
  doi          = {10.1016/j.neucom.2022.06.039},
  journal      = {Neurocomputing},
  pages        = {197-211},
  shortjournal = {Neurocomputing},
  title        = {IdentityDP: Differential private identification protection for face images},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-weighted graph learning for multi-view clustering.
<em>NEUCOM</em>, <em>501</em>, 188–196. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph-based multi-view clustering has received extensive attention in recent years due to its competitiveness in characterizing the relationship between data and its well defined mathematic. However, the existing graph-based clustering methods only take into account the data similarity of intra-view, while neglecting the similarity of inter-view. Thus, they cannot well exploit the complementary information and spatial structure embedded in graphs of different views. Second, all of them require that the geometric relationship between the data is exactly the same in different views, which makes no sense in real applications. In this paper, we relax this strict constraint and propose an efficient graph learning model for multi-view clustering. Our proposed method considers the similarity of inter-view by minimizing the tensor Schatten p -norm on the third-order tensor whose lateral slices are composed of graphs of different views. Thus, our method exploits the complementary information and spatial structure. Experiments indicate that our method is superior to some state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xiaochuang Shu and Xiangdong Zhang and Qianqian Wang},
  doi          = {10.1016/j.neucom.2022.06.009},
  journal      = {Neurocomputing},
  pages        = {188-196},
  shortjournal = {Neurocomputing},
  title        = {Self-weighted graph learning for multi-view clustering},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced distance-aware self-attention and multi-level match
for sentence semantic matching. <em>NEUCOM</em>, <em>501</em>, 174–187.
(<a href="https://doi.org/10.1016/j.neucom.2022.05.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentence semantic matching is a core research area in natural language processing, which is widely used in various natural language tasks. In recent years, attention mechanism has shown good performance in deep neural networks for sentence semantic matching. Most of the attention-based deep neural networks focus on sentences interaction which ignore modeling the core semantic of the sentence. In other words, they do not consider the importance of the relative distance of words when modeling the sentence semantics, which leads to deviations in modeling the core semantics of the sentence and unstable sentence interaction. Usually, people tend to associate words that are relatively close together when they read and believe that there is a deeper connection between them. Besides, the current interactive matching method after sentence modeling is relatively simple and it may be inadequate. In this paper, we build a well-performed distance-aware self-attention and multi-level matching model (DSSTM) for sentence semantic matching tasks. By considering the importance of different distance tokens, it can get the better original semantics of sentences and hold interactive matching method in multiple level after sentence modeling. To be specific, given two input sentences, we first encode them as contextual embeddings. Then, the contextual embeddings are handled by enhanced distance-aware self-attention to further strengthen the sentence semantic modeling from the whole and local aspect. At the same time, we apply the co-attention layer to extract cross-sentence interaction features while simplifying all the remaining components. Finally, we fuse them into the multi-level matching function to obtain the aggregation vector and learn divers matching representations, which is helpful to capture the diversity of sentence pairs. We conduct experiments on three sentence semantic matching tasks. Experimental results on these public datasets demonstrate that our model outperforms competitive baseline methods and our model has fewer parameters. Our source code is publicly available at https://github.com/xiaodeng-1/DSSTM.},
  archive      = {J_NEUCOM},
  author       = {Yao Deng and Xianfeng Li and Mengyan Zhang and Xin Lu and Xia Sun},
  doi          = {10.1016/j.neucom.2022.05.103},
  journal      = {Neurocomputing},
  pages        = {174-187},
  shortjournal = {Neurocomputing},
  title        = {Enhanced distance-aware self-attention and multi-level match for sentence semantic matching},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Temporal self-attention-based conv-LSTM network for
multivariate time series prediction. <em>NEUCOM</em>, <em>501</em>,
162–173. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series play an important role in many fields, such as industrial control, automated monitoring, and weather forecasting. Because there is often more than one variable in reality problems and they are related to each other, the multivariable time series (MTS) introduced. Using historical observations to accurately predict MTS is still very challenging. Therefore, a new time series prediction model proposed based on the temporal self-attention mechanism, convolutional neural network and long short-term memory (Conv-LSTM). When the standard attention mechanism for time series is combined with recurrent neural network (RNN), it heavily depends on the hidden state of the RNN. Particularly in the first time step, the initial hidden state (typically 0) must be artificially introduced to calculate the attention weight of that step, which results in additional noise in the calculation of the attention weight. To address this problem and increase the flexibility of the attention layer, a new self-attention mechanism designed to extract the temporal dependence of the MTS, which called temporal self-attention. In this attention mechanism , long short-term memory (LSTM) adopted as a sequence encoder to calculate the query, key, and value to obtain a more complete temporal dependence than standard self-attention. Because of flexibility of this structure, the DA-Conv-LSTM model was improved, in which a SOTA attention-based method used for MTS prediction. Our improved model compared with six baseline models on multiple datasets (SML2010 and NASDAQ100), and applied to satellite state prediction (our private dataset). The effectiveness of our temporal self-attention was demonstrated by experiments. And the best short-term prediction performance was achieved by our improved model.},
  archive      = {J_NEUCOM},
  author       = {En Fu and Yinong Zhang and Fan Yang and Shuying Wang},
  doi          = {10.1016/j.neucom.2022.06.014},
  journal      = {Neurocomputing},
  pages        = {162-173},
  shortjournal = {Neurocomputing},
  title        = {Temporal self-attention-based conv-LSTM network for multivariate time series prediction},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PCS-LSTM: A hybrid deep learning model for multi-stations
joint temperature prediction based on periodicity and closeness.
<em>NEUCOM</em>, <em>501</em>, 151–161. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temperature is one of the most important meteorological elements, which affects the daily lives of people all over the world. Owing to the rapid development of meteorological facilities, the number of meteorological observation stations on earth is gradually increasing, which brings challenges to the spatial association between stations. Many researchers focus on how to predict temperature more accurately utilizing these associations. However, the existing deep learning methods of temperature prediction have difficulty in capturing the interactions between neighboring stations in the spatial dimension. In addition, in the time dimension, the temperature in nature exhibits not only nearby variations but also periodic characteristics, which further increases the difficulty of temperature prediction. To solve the aforementioned two problems, we propose the periodicity and closeness social long short-term memory (PCS-LSTM) model, which includes PS-LSTM and CS-LSTM modules. Specifically, to model the relationships between multiple meteorological observation stations, we utilized the social pooling in the PS-LSTM and CS-LSTM modules to establish spatial associations. To further refine the temperature variation, we combine PS-LSTM and CS-LSTM to model the periodicity and closeness of the time series. Compared with the LSTM basic model, the experiments show that the MAE of our model prediction results is reduced by 0.109°C in the next 24 h compared.},
  archive      = {J_NEUCOM},
  author       = {Jun Zhang and Pengli Wu and Xia Xu and Ming Han and Bin Pan},
  doi          = {10.1016/j.neucom.2022.06.015},
  journal      = {Neurocomputing},
  pages        = {151-161},
  shortjournal = {Neurocomputing},
  title        = {PCS-LSTM: A hybrid deep learning model for multi-stations joint temperature prediction based on periodicity and closeness},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bioinspired model to motivate learning of appetitive
signals’ incentive value under a pavlovian conditioning approach.
<em>NEUCOM</em>, <em>501</em>, 135–150. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the general artificial intelligence field aims to emulate some human behavior features in computational models for different objectives. This article proposes a model grounded in neurosciences focusing on individual behavior under appetitive circumstances. Environmental stimuli inspire human behavior because they represent a (learned) incentive value (IV) linked to the satisfaction of motivational states (MSs). That is, the expected behavior is goal-directed. We describe the generation of the incentive learning process. To reach this objective, we propose a computational-bioinspired model exemplifying the IV encoding process of a perceived smell stimulus for its setup, recovery and updating using Pavlovian conditioning. The proposed model highlights the main processes involved in Pavlovian incentive learning (PIL) and complementaries, e.g., an early integration between a smell stimulus and an MS, the generation of a temporal reward history, the prediction of a reward, the calculation of the obtained reward, the evaluation of reward error, among others. The model’s functionality was validated in two phases: the first stage was the acquisition of the IV and the second stage was a go/nogo task based on an incentive value and its MS.},
  archive      = {J_NEUCOM},
  author       = {Alison Muñoz-Capote and Diana G. Gómez-Martínez and Tania Rodriguez-Flores and Francisco Robles and Marco Ramos and Félix Ramos},
  doi          = {10.1016/j.neucom.2022.05.104},
  journal      = {Neurocomputing},
  pages        = {135-150},
  shortjournal = {Neurocomputing},
  title        = {A bioinspired model to motivate learning of appetitive signals’ incentive value under a pavlovian conditioning approach},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Skeleton-based traffic command recognition at road
intersections for intelligent vehicles. <em>NEUCOM</em>, <em>501</em>,
123–134. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding traffic officer commands is a fundamental perception task for intelligent vehicles in driver assistance and autonomous driving . Previous studies have emphasized explicit traffic command gesture recognition but have not considered situations where the traffic officer is controlling the subjects in other directions, which would also influence decision-making of the ego vehicle. To fill in the gap, this article aims to research visual skeleton-based recognition of traffic commands occurring at road intersections, where both command directions and gestures should be determined. Specifically, a two-stage recognition framework for four cross-shaped directions and eight command gestures is proposed. Two kinds of handcrafted features, including upper-body geometric features and keypoint co-occurrence features, are established with estimated 2D human keypoint coordinates and heatmaps and further combined into a deep learning network. The first stage handles human body orientation classification, while the second stage addresses command gesture recognition with extra usage of the output from the first stage. Combining the recognized body orientation and command gesture, the type of traffic command can ultimately be inferred. For training and validation, a dataset termed the Chinese Traffic Command at Intersections (CTCX) is built. The proposed method gains an outperforming edit accuracy of 89.67\% on the CTCX test set, demonstrating its effectiveness. This work provides a foundation in this area and is expected to inspire more research on traffic command recognition with directions in the near future.},
  archive      = {J_NEUCOM},
  author       = {Sijia Wang and Kun Jiang and Junjie Chen and Mengmeng Yang and Zheng Fu and Tuopu Wen and Diange Yang},
  doi          = {10.1016/j.neucom.2022.05.107},
  journal      = {Neurocomputing},
  pages        = {123-134},
  shortjournal = {Neurocomputing},
  title        = {Skeleton-based traffic command recognition at road intersections for intelligent vehicles},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Unsupervised learning of light field depth estimation with
spatial and angular consistencies. <em>NEUCOM</em>, <em>501</em>,
113–122. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning-based depth estimation from light fields has made significant advances in recent years, however, most of these work abandon the traditional non-learning based formulations and start over with an end-to-end deep network framework. Actually traditional methods have also presented many effective and evident depth cues or constraints for light field depth estimation. In this paper, we try to combine the advantages of the learning and non-learning strategies, and incorporate the traditional light field constraints into an unsupervised framework by using a learnable approximation scheme to yield differentiable unsupervised loss functions. Specifically, we first propose an unsupervised coarse-to-fine network architecture for light field depth estimation, and then design an adaptive spatio-angular consistency loss combined with the differentiable versions of modified traditional constraints. Comparative experiments demonstrate that our method is superior to the state-of-the-art unsupervised methods .},
  archive      = {J_NEUCOM},
  author       = {Lili Lin and Qiujian Li and Bin Gao and Yuxiang Yan and Wenhui Zhou and Ercan Engin Kuruoglu},
  doi          = {10.1016/j.neucom.2022.06.011},
  journal      = {Neurocomputing},
  pages        = {113-122},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised learning of light field depth estimation with spatial and angular consistencies},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-strategy mutual learning network for deformable
medical image registration. <em>NEUCOM</em>, <em>501</em>, 102–112. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deformable medical image registration plays a vital role in clinical diagnosis, monitoring treatment, and postoperative recovery. Nevertheless, the existing registration algorithms rely on a single network or training strategy to complete the registration task. Even the most advanced registration algorithms cannot capture sufficiently compelling feature information by a single network or strategy.This paper proposes a new unsupervised and deformable medical image registration network framework to get the compelling feature. The network uses 2D sub-images of 3D images as additional constraint information to supplement the training process. Therefore, the network’s two-dimensional and three-dimensional data images can interactively learn each other’s characteristic information. In addition, we propose to perform secondary registration on the concentrated part of the registration area according to the characteristics of the input image. It enables the complete image and critical regions to learn their characteristic information interactively. This paper uses the image pyramid to integrate the two mutual learning strategies, thus proposing a multi-strategy mutual learning network(MMLN) and conducting many evaluation tests on the public data set OASIS and LPBA40. The test results show that the network can achieve better registration performance than other learning-based methods and traditional algorithms.},
  archive      = {J_NEUCOM},
  author       = {Zhiyuan Zheng and Wenming Cao and Ye Duan and Guitao Cao and Deliang Lian},
  doi          = {10.1016/j.neucom.2022.06.020},
  journal      = {Neurocomputing},
  pages        = {102-112},
  shortjournal = {Neurocomputing},
  title        = {Multi-strategy mutual learning network for deformable medical image registration},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical complementary residual attention learning for
defocus blur detection. <em>NEUCOM</em>, <em>501</em>, 88–101. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defocus blur detection (DBD) aims to extract the in-focus part from a single image. Instead of adopting traditional hand-crafted features, recent deep neural networks based methods achieve DBD in an end-to-end architecture, obtaining many superior performances. However, these approaches are incapable of distinguishing many micro details when the image is complex. To tackle this issue, in this work, we propose Hierarchical Complementary Residual Attention Learning (HCRAL) for defocus blur detection, which employs multi-scale features with the complementary information from the network to guide the optimization of DBD. Specifically, to detect the micro details, residual attention is introduced to learn residual information between different scales, subsequently encouraging the network to re-focus on the easily-ignored boundary and sparse parts. Additionally, instead of only considering in-focus regions like other DBD methods, we capture the in-focus and out-of-focus features jointly. In this complementary mode, information ignored by one side may be learned by the other side, resulting in a positive influence between in-focus learning and out-of-focus learning. Simultaneously, the hierarchical feature guided learning strategy well leverages low- and high-level information and consequently enhances both global object detection and local boundary refinement. Experimental results on three datasets demonstrate the effectiveness and superiority of our methods.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Lin and Huafeng Li and Qing Cai},
  doi          = {10.1016/j.neucom.2022.06.023},
  journal      = {Neurocomputing},
  pages        = {88-101},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical complementary residual attention learning for defocus blur detection},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Compression loss-based spatial-temporal attention module for
compressed video quality enhancement. <em>NEUCOM</em>, <em>501</em>,
75–87. (<a href="https://doi.org/10.1016/j.neucom.2022.05.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning technology has achieved remarkable progress in compressed video quality enhancement. However, the existing methods fail to consider the fact that the regions with different compression losses contain varied effective information. To address this issue, this paper proposes a Compression Loss-based Spatial-Temporal Attention (CLSTA) module that predicts the compression loss-based attention of each pixel when restoring target frames. Based on this, the pixels with lower compression losses contribute more to restoring target frames. Meanwhile, the compression-domain information in the compressed video stream is exploited to overcome the difficulty in inferring compression loss-based attention directly from the pixel-domain. With a slight modification, the CLSTA module can be easily integrated into the existing methods for end-to-end training. A series of experiments have been conducted in this study to validate the effectiveness and generality of the CLSTA module for compressed video quality enhancement. By adding the CLSTA module to the state-of-the-art method STDF, the proposed method achieves an average PSNR improvement of 0.96 dB and a BD-rate reduction of 26.85\% under the Low-Delay P configuration, which is respectively 0.06 dB and 1.83\% better than the baseline STDF. In the best case, the proposed method obtains 0.19 dB higher PSNR than STDF for a single frame.},
  archive      = {J_NEUCOM},
  author       = {Huiguo He and Hongyang Chao and Jian Yin},
  doi          = {10.1016/j.neucom.2022.05.111},
  journal      = {Neurocomputing},
  pages        = {75-87},
  shortjournal = {Neurocomputing},
  title        = {Compression loss-based spatial-temporal attention module for compressed video quality enhancement},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mixture of von mises-fisher distribution with sparse
prototypes. <em>NEUCOM</em>, <em>501</em>, 41–74. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixtures of von Mises-Fisher distributions can be used to cluster data on the unit hypersphere. This is particularly adapted for high-dimensional directional data such as texts. We propose in this article to estimate a von Mises mixture using a l 1 l1 penalized likelihood. This leads to sparse prototypes that improve clustering interpretability . We introduce an expectation–maximisation (EM) algorithm for this estimation and explore the trade-off between the sparsity term and the likelihood one with a path following algorithm. The model’s behaviour is studied on simulated data and, we show the advantages of the approach on real data benchmark. We also introduce a new data set on financial reports and exhibit the benefits of our method for exploratory analysis.},
  archive      = {J_NEUCOM},
  author       = {Fabrice Rossi and Florian Barbaro},
  doi          = {10.1016/j.neucom.2022.05.118},
  journal      = {Neurocomputing},
  pages        = {41-74},
  shortjournal = {Neurocomputing},
  title        = {Mixture of von mises-fisher distribution with sparse prototypes},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Keywords-aware dynamic graph neural network for multi-hop
reading comprehension. <em>NEUCOM</em>, <em>501</em>, 25–40. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-hop reading comprehension (RC) is challenging for machine reading comprehension. It is crucial for multi-hop RC to comprehend complex questions and contents between multiple paragraphs. In this paper, we propose a strategy of keywords-aware dynamic graph neural network (KA-DGN) to improve the performance of multi-hop reading comprehension. First of all, KA-DGN focuses on the salient information in the text, extracts keywords from the question and context. A window is specifically designed to frame the interrogative pronoun/adverb and its nearby words in the question, which encourages the model to focus on the answer. Next, the token-level answer span is predicted under the guidance of the keywords. And the boundary loss function is also invented to enhance the boundary awareness of the model on extracting the answer, which maximizes the probability of answer span bound while minimizing that of the noise. Finally, the model builds a dynamic reasoning graph combining explicit keywords and implicit semantic information among sentences. Graph neural network is applied to predict the sentence-level supporting facts. While evaluating on HotpotQA, the proposed KA-DGN achieves competitive performance in distractor setting.},
  archive      = {J_NEUCOM},
  author       = {Meihuizi Jia and Lejian Liao and Wenjing Wang and Fei Li and Zhendong Chen and Jiaqi Li and Heyan Huang},
  doi          = {10.1016/j.neucom.2022.05.110},
  journal      = {Neurocomputing},
  pages        = {25-40},
  shortjournal = {Neurocomputing},
  title        = {Keywords-aware dynamic graph neural network for multi-hop reading comprehension},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Person-job fit estimation from candidate profile and
related recruitment history with co-attention neural networks.
<em>NEUCOM</em>, <em>501</em>, 14–24. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing online recruitment platforms depend on automatic ways of conducting the person-job fit, whose goal is matching appropriate job seekers with job positions. Intuitively, the previous successful recruitment records contain important information, which should be helpful for the current person-job fit. Existing studies on person-job fit, however, mainly focus on calculating the similarity between the candidate resumes and the job postings on the basis of their contents, without taking the recruiters’ experience ( i.e., historical successful recruitment records) into consideration. In this paper, we propose a novel neural network approach for person-job fit, which estimates p erson- j ob f it from candidate profile and related recruitment history with c o- a ttention n eural n etworks (named PJFCANN). Specifically, given a target resume-job post pair, PJFCANN generates local semantic representations through co-attention neural networks and global experience representations via graph neural networks. The final matching degree is calculated by combining these two representations. In this way, the historical successful recruitment records are introduced to enrich the features of resumes and job postings and strengthen the current matching process. Extensive experiments conducted on a large-scale recruitment dataset verify the effectiveness of PJFCANN compared with several state-of-the-art baselines. The codes are released at: https://github.com/CCIIPLab/PJFCANN .},
  archive      = {J_NEUCOM},
  author       = {Ziyang Wang and Wei Wei and Chenwei Xu and Jun Xu and Xian-Ling Mao},
  doi          = {10.1016/j.neucom.2022.06.012},
  journal      = {Neurocomputing},
  pages        = {14-24},
  shortjournal = {Neurocomputing},
  title        = {Person-job fit estimation from candidate profile and related recruitment history with co-attention neural networks},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A relational model for one-shot classification of images and
pen strokes. <em>NEUCOM</em>, <em>501</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that a deep learning model with built-in relational inductive bias can bring benefits to sample-efficient learning, without relying on extensive data augmentation . Our study shows that excellent results can be achieved with a model in which the relational inductive bias is applied to images, while building an efficient one-shot classifier on top of raw strokes is more challenging. The proposed one-shot classification model performs relational matching of a pair of inputs in the form of local and pairwise attention. Our approach solves with almost perfect accuracy the one-shot image classification Omniglot challenge when combined with a Hungarian matching algorithm and attains competitive results on the same task on characters represented as rotation-augmented strokes.},
  archive      = {J_NEUCOM},
  author       = {Arturs Polis and Alexander Ilin},
  doi          = {10.1016/j.neucom.2022.06.004},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {A relational model for one-shot classification of images and pen strokes},
  volume       = {501},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on neural networks for (cyber-) security and
(cyber-) security of neural networks. <em>NEUCOM</em>, <em>500</em>,
1075–1087. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this systematic and broad survey is to present and discuss the main challenges that are posed by the implementation of Artificial Intelligence and Machine Learning in the form of Artificial Neural Networks in Cybersecurity, specifically in Intrusion Detection Systems. Based on the results of the state-of-the-art analysis with a number of bibliographic methods, as well as their own implementations, the authors provide a survey of the answers to the posed problems as well as effective, experimentally-found solutions to those key issues. The issues include hyperparameter tuning, dataset balancing, increasing the effectiveness of an ANN, securing the networks from adversarial attacks, and a range of non-technical challenges of applying ANNs for IDS, such as societal, ethical and legal dilemmas, and the question of explainability. Thus, it is a systematic review and a summary of the body of knowledge amassed around implementations of Artificial Neural Networks in Network Intrusion Detection, guided by an actual, real-world implementation.},
  archive      = {J_NEUCOM},
  author       = {Marek Pawlicki and Rafał Kozik and Michał Choraś},
  doi          = {10.1016/j.neucom.2022.06.002},
  journal      = {Neurocomputing},
  pages        = {1075-1087},
  shortjournal = {Neurocomputing},
  title        = {A survey on neural networks for (cyber-) security and (cyber-) security of neural networks},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Go ahead and do not forget: Modular lifelong learning from
event-based data. <em>NEUCOM</em>, <em>500</em>, 1063–1074. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifelong learning is a long-standing aim for artificial agents that act in dynamic environments in which an agent needs to accumulate knowledge incrementally without forgetting previously learned representations. Contemporary methods for incremental learning from images are predominantly based on frame-based data recorded by conventional shutter cameras. We investigate methods for learning from data produced by event cameras and compare techniques to mitigate forgetting while learning incrementally. We propose a model that is composed of both, feature extraction and incremental learning. The feature extractor is utilized as a self-supervised sparse convolutional neural network that processes event-based data. The incremental learner uses a habituation-based method that works in tandem with other existing techniques. Our experimental results show that the combination of different existing techniques with our proposed habituation-based method can help avoid catastrophic forgetting even more, while learning incrementally from the features provided by the extraction module.},
  archive      = {J_NEUCOM},
  author       = {Vadym Gryshchuk and Cornelius Weber and Chu Kiong Loo and Stefan Wermter},
  doi          = {10.1016/j.neucom.2022.05.101},
  journal      = {Neurocomputing},
  pages        = {1063-1074},
  shortjournal = {Neurocomputing},
  title        = {Go ahead and do not forget: Modular lifelong learning from event-based data},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SSLNet: A network for cross-modal sound source localization
in visual scenes. <em>NEUCOM</em>, <em>500</em>, 1052–1062. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sound source localization in visual scenes is to associate sounds and their visual producers. Although great progress has been made in this field, the mixed sounds from multiple objects make it intractable to perform efficient localization in the unconstrained scenarios. In this paper, we propose a novel cross-modal sound source localization networks (SSLNet), which is accessible to dispose audio and visual information. First, to encode spatial and temporal information in the spectrogram, we combine convolutional neural networks (CNN) and bidirectional long short-term memory networks (BiLSTM). For different time-step inputs of BiLSTMs, we propose a novel operation, called as grouped global average pooling (GGAP), to divide the 3-D spectrogram feature block into several 1-D vectors. Then, a cross-modal channel attention mechanism is introduced to alleviate the discrepancy of different modalities. Finally, for achieving the pixel-level localization, we propose a fusion approach using cosine and L2 distances to measure the similarity between audio and visual vectors. We implement extensive experiments in benchmark and FAIR-Play datasets. The qualitative results demonstrate the effectiveness of sound source localization. On benchmark dataset, the quantitative results show that SSLNet can improve the localization accuracy by 1.2\% in consensus intersection over union (cIoU) and 16.4\% in area under the curve (AUC). On FAIR-Play dataset, SSLNet also achieves superior performance with Pearson’s correlation coefficient (CC) of 0.779 and similarity metric (SIM) of 0.650.},
  archive      = {J_NEUCOM},
  author       = {Fan Feng and Yue Ming and Nannan Hu},
  doi          = {10.1016/j.neucom.2022.05.098},
  journal      = {Neurocomputing},
  pages        = {1052-1062},
  shortjournal = {Neurocomputing},
  title        = {SSLNet: A network for cross-modal sound source localization in visual scenes},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A probabilistic ensemble approach for knowledge graph
embedding. <em>NEUCOM</em>, <em>500</em>, 1041–1051. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding (KGE) is a technique for embedding entities and relations of knowledge graphs (KGs) into continuous vector spaces while maintaining the inherent structure of KGs, in this way link prediction can be facilitated by scoring candidate triples. Existing KGE models only capture specific features of a KG, however, link prediction capacity heavily relies on comprehensive features of a KG. In this work, we propose an ensemble approach for KGE by incorporating the features captured by different KGE models. As a key step, we propose a probabilistic scoring index for characterizing the link prediction performance of a given KGE model. Based on this we established a theoretical framework to calculate the optimal parameters for the ensemble model and predict its corresponding link prediction rate. In particular, we proved that our ensemble approach can always improve link prediction performance under some assumptions. The Upper Confidence Bound Algorithm is then used to adjust the parameters. Experimental results on two widely used KGs show that the proposed ensemble approach achieves the state-of-the-art link prediction rate.},
  archive      = {J_NEUCOM},
  author       = {Yinquan Wang and Yao Chen and Zhe Zhang and Tian Wang},
  doi          = {10.1016/j.neucom.2022.06.032},
  journal      = {Neurocomputing},
  pages        = {1041-1051},
  shortjournal = {Neurocomputing},
  title        = {A probabilistic ensemble approach for knowledge graph embedding},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Absolute size IoU loss for the bounding box regression of
the object detection. <em>NEUCOM</em>, <em>500</em>, 1029–1040. (<a
href="https://doi.org/10.1016/j.neucom.2022.06.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the wide application of deep learning in the field of computer vision, the technology of object detection continues to make breakthroughs, and the bounding box regression technology is closely related to the accuracy of object detection results. This study proposes an Absolute size IoU (AIoU) loss function for bounding box regression, which further improves the object detection accuracy. Firstly, this study introduces the common location loss functions in bounding box regression, and then describes the limitations of common loss functions based on Intersection over Union (IoU). To overcome these limitations, this study puts forward an AIoU loss function, which can facilitate bounding box regression. Specifically, when the loss penalty term becomes invalid, it can replace the existing penalty term for model optimization. In addition, it can focus the models further on the difficult objects during training. Moreover, as a comprehensive regression factor, this penalty term contains various optimization features. The effectiveness and wide range of application of the AIoU proposed are demonstrated in experiments with three different detectors. It improves the performance of YOLOv4 by 0.61\% mAP on the VOC dataset and by 1.98\% mAP on the COCO dataset. Finally, we have obtained α-AIoU which uses a power function for AIoU improvement, and it achieves the best performance in the experiments. The evaluation results on several different detectors show that the method proposed in this study has important application significance for object detection technology. The code related to the AIoU loss experiment is at https://github.com/tiandii/AIoU-loss-experimental-code-.git .},
  archive      = {J_NEUCOM},
  author       = {Di Tian and Yi Han and Shu Wang and Xu Chen and Tian Guan},
  doi          = {10.1016/j.neucom.2022.06.018},
  journal      = {Neurocomputing},
  pages        = {1029-1040},
  shortjournal = {Neurocomputing},
  title        = {Absolute size IoU loss for the bounding box regression of the object detection},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Functional gradient descent for n-tuple regression.
<em>NEUCOM</em>, <em>500</em>, 1016–1028. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {n -tuple neural networks have recently been applied to a wide range of learning domains. However, for the particular area of regression, existing systems have displayed two shortcomings: little flexibility in the objective function being optimized and an inability to handle nonstationarity in an online learning setting. A novel n -tuple system is proposed to address these issues. The new architecture leverages the idea of functional gradient descent , drawing inspiration from its use in kernel methods . Furthermore, its capabilities are showcased in reinforcement learning tasks, which involves both nonstationary online learning and task-specific objective functions.},
  archive      = {J_NEUCOM},
  author       = {Rafael F. Katopodis and Priscila M.V. Lima and Felipe M.G. França},
  doi          = {10.1016/j.neucom.2022.05.114},
  journal      = {Neurocomputing},
  pages        = {1016-1028},
  shortjournal = {Neurocomputing},
  title        = {Functional gradient descent for n-tuple regression},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic graph recurrent neural network. <em>NEUCOM</em>,
<em>500</em>, 1003–1015. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning over dynamic graphs has attracted much attention because of its wide applications. Recently, sequential probabilistic generative models have achieved impressive results because they can model data distributions. However, modeling the distribution of dynamic graphs is still extremely challenging. Existing methods usually ignore the mutual interference of stochastic states and deterministic states. Besides, the assumption that latent variables follow Gaussian distributions is usually inappropriate. To address these problems, we propose stochastic graph recurrent neural network (SGRNN), a sequential generative model for the representation learning over dynamic graphs. It separates stochastic states and deterministic states in the iterative process. To improve the flexibility of latent variables, we set the prior distribution and posterior distribution as semi-implicit distributions and propose DSI-SGRNN. In addition, to alleviate the KL-vanishing problem in SGRNN, a simple and interpretable structure is proposed based on the lower bound of KL-divergence. The proposed structure introduces a few extra parameters and can be implemented with a few lines of code modification. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed model.},
  archive      = {J_NEUCOM},
  author       = {Tijin Yan and Hongwei Zhang and Zirui Li and Yuanqing Xia},
  doi          = {10.1016/j.neucom.2022.05.105},
  journal      = {Neurocomputing},
  pages        = {1003-1015},
  shortjournal = {Neurocomputing},
  title        = {Stochastic graph recurrent neural network},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CAMA: Class activation mapping disruptive attack for deep
neural networks. <em>NEUCOM</em>, <em>500</em>, 989–1002. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of adversarial examples has aroused widespread attention to the safety of deep learning . Most recent research focuses on how to obtain adversarial examples which make networks’ predictions wrong, and rarely observe the changes in feature embedding space from the perspective of interpretability . In addition, researchers have proposed various attack algorithms for a single task, but there are few general methods that can perform multiple tasks at the same time, such as image classification , object detection, and face recognition. To resolve these issues, we propose a new attack algorithm CAMA for deep neural networks (DNNs). CAMA perturbs each feature extraction layer through adaptive feature measurement function, thereby disrupting the predicted class activation mapping of DNNs. Experiments show that CAMA is good at creating white-box adversarial examples on classification networks and has the highest attack success rate. To solve the problem of the disappearance of aggression caused by image transformation, we propose spread-spectrum compression CAMA, which achieve a better attack success rate under various defensive measures. In addition, we successfully attack face recognition networks and object detection networks using CAMA, and achieve excellent performance. It verifies that our algorithm is a general attack algorithm for attacking different tasks.},
  archive      = {J_NEUCOM},
  author       = {Sainan Sun and Bin Song and Xiaohui Cai and Xiaojiang Du and Mohsen Guizani},
  doi          = {10.1016/j.neucom.2022.05.065},
  journal      = {Neurocomputing},
  pages        = {989-1002},
  shortjournal = {Neurocomputing},
  title        = {CAMA: Class activation mapping disruptive attack for deep neural networks},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human-object interaction detection with depth-augmented
clues. <em>NEUCOM</em>, <em>500</em>, 978–988. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human object interaction (HOI) detection aims to localize and classify triplets of human, object and relationship from a given image. Different from previous methods that only extract vision information in RGB images , we propose a Depth-augmented Relationship Reasoning ( DRR ) (DRR) method that focuses on the RGB images and corresponding depth messages simultaneously. Rethinking principles of photography, we argue that RGB images discard spatial depth carrying third dimension relative distance information between instances. In light of this, we beforehand estimate the depth information for each image, yielding a corresponding depth map. Then we leverage multiple representations encoded by depth information and RGB images to enrich semantic interpretation. Subsequently, we explore a hierarchical attention strategy to fuse these semantic representations and further generate depth-augmented features, being used to reason about fine-grained human-object interactions. Extensive experiments on the benchmark datasets V-COCO, HICO-DET and HCVRD verify the effectiveness of our method and demonstrate the importance of spatial depth information for HOI.},
  archive      = {J_NEUCOM},
  author       = {Yamin Cheng and Hancong Duan and Chen Wang and Zhi Wang},
  doi          = {10.1016/j.neucom.2022.05.014},
  journal      = {Neurocomputing},
  pages        = {978-988},
  shortjournal = {Neurocomputing},
  title        = {Human-object interaction detection with depth-augmented clues},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dual attention and dual fusion: An accurate way of
image-based geo-localization. <em>NEUCOM</em>, <em>500</em>, 965–977.
(<a href="https://doi.org/10.1016/j.neucom.2022.05.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When GPS signal is interfered or lost, the visual geo-localization method is particularly important for Unmanned Aerial Vehicle (UAV). Since matching UAV images with satellite maps is a multi-source and multi-view problem, visual geo-localization is very challenging. Most existing methods use Convolutional Neural Network (CNN), which extract the final output of the backbone Network to predict the similarity between UAV images and satellite maps. Due to continuous stacked convolution and pooling, rich local information is gradually lost while semantic information is acquired. To solve this problem, a dual attention and dual fusion (DADF) scene matching algorithm is proposed. The contributions of this paper are as follows: 1) In order to achieve accurate matching between UAV and satellite images, a visual geo-localization algorithm based on siamese network is designed. 2) In order to improve the ability of semantic feature extraction, a dual-attention model is constructed. The network pays more attention to the parts that are useful for similarity metric. 3) A dual fusion model is established. According to the feature fusion method and multi-level matching result fusion algorithm, the confidence of matching is improved. To verify the performance of the proposed approach, LA850 and NWPU-ChangAn datasets were collected and enhanced. The experimental results show that the proposed algorithm is more efficient than comparison algorithms.},
  archive      = {J_NEUCOM},
  author       = {Yuan Yuan and Bo Sun and Ganchao Liu},
  doi          = {10.1016/j.neucom.2022.05.013},
  journal      = {Neurocomputing},
  pages        = {965-977},
  shortjournal = {Neurocomputing},
  title        = {Dual attention and dual fusion: An accurate way of image-based geo-localization},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finding complete minimum driver node set with guaranteed
control capacity. <em>NEUCOM</em>, <em>500</em>, 949–964. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A critical prerequisite for controlling complex networks is to find a driver node set with a structural controllability guarantee. This paper introduces the control capacity for a driver node set and solves the problem of finding a complete minimum driver node set that not only guarantees network structural controllability but achieves the desired level of control capacity. A novel algorithmic framework is proposed which is based on the concept of equivalent set and approximate matching replacement technique. The proposed algorithmic framework is shown to outperform the state-of-the-art approaches in the literature. The validity of the proposed algorithm is analyzed and the performance is evaluated by experiments on artificial and real-world complex networks.},
  archive      = {J_NEUCOM},
  author       = {Shuai Jia and Yugeng Xi and Dewei Li and Haibin Shao},
  doi          = {10.1016/j.neucom.2022.05.095},
  journal      = {Neurocomputing},
  pages        = {949-964},
  shortjournal = {Neurocomputing},
  title        = {Finding complete minimum driver node set with guaranteed control capacity},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring more concentrated and consistent activation
regions for cross-domain semantic segmentation. <em>NEUCOM</em>,
<em>500</em>, 938–948. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cross-domain semantic segmentation in urban scenes is challenging due to the gap between the source and the target domains. Although the existing methods achieve remarkable performance, these methods have some limitations. First, the region activated by the backbone network is dispersed. The dispersed feature activation region is difficult to help the feature distribution alignment between the two domains. Second, these methods ignore the inconsistent problem between the activation regions of the two domains. Intuitively, the consistent feature activation region between the two domains is beneficial to align the feature distribution. In this paper, we present a novel approach for cross-domain semantic segmentation . Specifically, we propose a kernel-based channel attention (KCA) module and a mutual information domain adaptation (MIDA) module. The KCA module models the relationship between channels by using explicit non-linear kernel mappings for generating KCA features that aim to obtain more concentrated activation regions of the category. The MIDA module is a strategy of the KCA feature distribution alignment between the two domains. Specifically, the MIDA module contains a mutual information loss function and two adversarial learning loss functions. The three loss functions work together to obtain more consistent activation regions of the KCA feature between the two domains. Finally, the aligned KCA feature is fused with the feature of backbone to guide the semantic segmentation. Furthermore, self-supervised learning and image translation methods are leveraged to learn a better cross-domain semantic segmentation model. Extensive experiments demonstrate that the proposed approach achieves competitive performance against the state-of-the-art methods on challenging synthetic-to-real tasks.},
  archive      = {J_NEUCOM},
  author       = {Muxin Liao and Guoguang Hua and Shishun Tian and Yuhang Zhang and Wenbin Zou and Xia Li},
  doi          = {10.1016/j.neucom.2022.05.059},
  journal      = {Neurocomputing},
  pages        = {938-948},
  shortjournal = {Neurocomputing},
  title        = {Exploring more concentrated and consistent activation regions for cross-domain semantic segmentation},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A gentle introduction and survey on computing with words
(CWW) methodologies. <em>NEUCOM</em>, <em>500</em>, 921–937. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human beings have an inherent capability to use linguistic information (LI) seamlessly even though it is vague and imprecise. Computing with Words (CWW) was proposed to impart computing systems with this capability of human beings. The interest in the field of CWW is evident from a number of publications on various CWW methodologies. These methodologies use different ways to model the semantics of the LI. However, to the best of our knowledge, the literature on these methodologies is mostly scattered and does not give an interested researcher a comprehensive but gentle guide about the notion and utility of these methodologies. Hence, to introduce the foundations and state-of-the-art CWW methodologies, we provide a concise but a wide-ranging coverage of them in a simple and easy to understand manner. We feel that the simplicity with which we give a high-quality review and introduction to the CWW methodologies is very useful for investigators or especially those embarking on the use of CWW for the first time. We also provide future research directions to build upon for the interested and motivated researchers.},
  archive      = {J_NEUCOM},
  author       = {Prashant K. Gupta and Javier Andreu-Perez},
  doi          = {10.1016/j.neucom.2022.05.097},
  journal      = {Neurocomputing},
  pages        = {921-937},
  shortjournal = {Neurocomputing},
  title        = {A gentle introduction and survey on computing with words (CWW) methodologies},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Residual-recursive autoencoder for accelerated evolution in
savonius wind turbines optimization. <em>NEUCOM</em>, <em>500</em>,
909–920. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies verified that a genetic algorithm can discover efficient and innovative wind turbines by using image encoding and decoding techniques. To accelerate the optimization, in this work, Residual-Recursion Autoencoder (RRAE) is proposed to extract low-dimensional latent codes from rotors’ cross-section images while maintaining reconstruction accuracy as high as possible. As a kind of neural network framework, the advantages of using RRAE are threefold: 1) RRAE can wrap over different kinds of autoencoders and improve their performance; 2) RRAE is compatible with different kinds of loss functions and works well with very low-dimensional latent codes; 3) RRAE is easy to use and efficient in decoding latent codes which is important to the rapid convergence of the genetic algorithm. The experiment results has shown that the reconstruction loss has decreased by 30.56\% on a recursive autoencoder, 11.40\% to 29.34\% on different feedforward autoencoders. Two RRAE-accelerated optimizations have been carried out in this work. One has used only 14\% of the calculation required by the baseline method without any deterioration in rotor performance. The other one has used 52.33\% and increased the rotor performance by 7.59\%.},
  archive      = {J_NEUCOM},
  author       = {Qianwei Zhou and Baoqing Li and Peng Tao and Zhang Xu and Chen Zhou and Yanzhuang Wu and Haigen Hu},
  doi          = {10.1016/j.neucom.2022.04.103},
  journal      = {Neurocomputing},
  pages        = {909-920},
  shortjournal = {Neurocomputing},
  title        = {Residual-recursive autoencoder for accelerated evolution in savonius wind turbines optimization},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MetricMask: Single category instance segmentation by metric
learning. <em>NEUCOM</em>, <em>500</em>, 896–908. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel single category instance segmentation method, termed MetricMask, which can be used by easily embedding it into most off-the-shelf detection and segmentation methods . Currently, instance segmentation methods usually segment each instance after completing the object detection. Our method can implement segmentation for all instances at once by fusing object detection, semantic segmentation , and metric learning. The contributions are threefold, 1. The instance segmentation is converted to three parallel tasks, including bounding box regression, mask regression, and embedding vector of pixel regression. 2. Random sampling metric loss is proposed to optimize embedding vectors, saving GPU memory without losing instance segmentation accuracy. 3. Based on the model output(bounding box, embedding vector of pixel, and the category-level mask), we propose a Metric Operation to segment each instance. Finally, we conduct experiments on two standard datasets, including the COCO person dataset and the ISOD dataset. The experiment results show that our method has excellent competitiveness with other methods. In particular, our method has an excellent performance on the large object and outperforms the existing state-of-the-art competitors on the ISOD dataset. We hope the MetricMask of our proposed will provide a new method for instance segmentation.},
  archive      = {J_NEUCOM},
  author       = {Yang Wang and Wanlin Zhou and Qinwei Lv and Guangle Yao},
  doi          = {10.1016/j.neucom.2022.05.117},
  journal      = {Neurocomputing},
  pages        = {896-908},
  shortjournal = {Neurocomputing},
  title        = {MetricMask: Single category instance segmentation by metric learning},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhance explainability of manifold learning.
<em>NEUCOM</em>, <em>500</em>, 877–895. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explainability of manifold learning is rarely investigated though there is an urgent need from both AI theory and practice. In this study, we propose a novel degree of locality preservation (DLP) approach to study the interpretability of manifold learning. We estimate the DLPs of the state-of-the-art manifold learning methods: t-SNE and UMAP as well as related methods: LLE, HLLE, and LTSA along with widely used PCA across benchmark datasets classified as low-dimensional and high-dimensional data. Our study provides well-founded explanations of the manifold learning methods in terms of the DLPs. The order of their DLPs follows t-SNE &gt; &amp;gt; UMAP &gt; &amp;gt; LLE &gt; &amp;gt; HLLE/PCA/LTSA, though it may have some exceptions for some high-dimensional data. Both t-SNE and UMAP demonstrate an embedding distance amplification mechanism under the Euclidean distance that forces the latent local data geometry to stand out in dimension reduction. It not only explains why t-SNE and UMAP have higher DLPs than other peers, but also indicates they are not locally isometric under the Euclidean distance . Furthermore, it discovers that t-SNE and UMAP embeddings demonstrate similar nonlinear nature in dimension reduction, besides larger (smaller) data variances for low (high)-dimensional data. To the best of our knowledge, this study is the first work about the explainability of manifold learning. The proposed methods and corresponding results can be also extended to other dimension reduction techniques.},
  archive      = {J_NEUCOM},
  author       = {Henry Han and Wentian Li and Jiacun Wang and Guimin Qin and Xianya Qin},
  doi          = {10.1016/j.neucom.2022.05.119},
  journal      = {Neurocomputing},
  pages        = {877-895},
  shortjournal = {Neurocomputing},
  title        = {Enhance explainability of manifold learning},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic event-triggered state estimation for time-delayed
spatial-temporal networks under encoding-decoding scheme.
<em>NEUCOM</em>, <em>500</em>, 868–876. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the dynamic event-triggered state estimation problem for a class of spatial-temporal networks (STNs) with time-varying delays under an encoding-decoding strategy. For the sake of reducing the unnecessary resources wastes, we establish a dynamic event-triggered mechanism to determine whether the current measurement output data is transmitted to the filter, where the threshold is dynamically adjusted according to a certain rule. In order to enhance the robustness of signal transmission, an encoding-decoding strategy is exploited in the process of the data transmission. To be specific, the original signals encoded as a bit string are transmitted through binary symmetric channels with certain crossover probabilities and then restored by a decoder at the receiver. By constructing Lyapunov-Krasovskii functional, we obtain a sufficient condition to ensure that the estimation error system is exponential mean square ultimately bounded. Subsequently, the desired state estimator is designed in terms of the solution to a certain matrix inequality. Finally, a numerical example is shown to demonstrate that the proposed state estimator is valid for time-delayed STNs.},
  archive      = {J_NEUCOM},
  author       = {Jie Sun and Bo Shen and Yurong Liu and Fuad E. Alsaadi},
  doi          = {10.1016/j.neucom.2022.05.062},
  journal      = {Neurocomputing},
  pages        = {868-876},
  shortjournal = {Neurocomputing},
  title        = {Dynamic event-triggered state estimation for time-delayed spatial-temporal networks under encoding-decoding scheme},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decentralized adaptive neural two-bit-triggered control for
nonstrict-feedback nonlinear systems with actuator failures.
<em>NEUCOM</em>, <em>500</em>, 856–867. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the adaptive neural decentralized two-bit-triggered control problem for interconnected large-scale nonlinear systems in nonstrict-feedback forms (NFF) with actuator failures. Since actuator failures occur frequently in practical systems, it will affect the stability of the interconnected large-scale systems under consideration. Combining radial basis function neural networks (RBF NNs) and a command filter, an adaptive decentralized two-bit-triggered (TBT) control method based on backstepping recursive design is presented to deal with this problem. Different from the traditional event-triggered control, the problem of control signal transmission bit is further considered to save system transmission resources. The proposed control scheme can guarantee that all signals are bounded and have good tracking performance. Finally, two simulation examples are provided to verify the validity of the presented control scheme.},
  archive      = {J_NEUCOM},
  author       = {Fabin Cheng and Huanqing Wang and Liang Zhang and A.M. Ahmad and Ning Xu},
  doi          = {10.1016/j.neucom.2022.05.082},
  journal      = {Neurocomputing},
  pages        = {856-867},
  shortjournal = {Neurocomputing},
  title        = {Decentralized adaptive neural two-bit-triggered control for nonstrict-feedback nonlinear systems with actuator failures},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lightweight single image super-resolution with attentive
residual refinement network. <em>NEUCOM</em>, <em>500</em>, 846–855. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep convolutional neural network (CNN) based single image super-resolution (SISR) methods have been demonstrated impressive performance in terms of quantitative metrics and visual effects. Most CNN-based SISR methods can learn the complex non-linear mapping between low-resolution (LR) images and their corresponding high-resolution (HR) images due to the powerful representation capabilities of deep convolutional neural networks. However, as the depth and width of the SISR networks increase, the parameters of SISR networks will increase dramatically, leading to huge computational cost and large memory consumption, making them impractical in real-world applications. To attack the above issues, we propose an accurate and lightweight deep convolutional neural network , named A ttentive R esidual R e f inement N etwork (ARRFN), to recover the high-resolution image from the original low-resolution image directly for SISR. In general, our proposed ARRFN consists of three parts, a feature extraction block, a stack of attentive residual refinement blocks (ARRFB), and a multi-scale separable upscaling module (MSSU), respectively. Specifically, our ARRFB consists of two branches, a regular residual learning branch and an attentive residual refinement branch. The former conducts regular residual learning by two residual blocks while the latter refines the residual information from the two residual blocks of the former branch with an attentive residual mechanism to further enhance the representation capabilities of the network. Furthermore, a multi-scale separable upsampling module (MSSU) is proposed to replace the regular upsampling operation for better SR results. Extensive experiments on several standard benchmarks show that the proposed method outperforms state-of-the-art SR methods in terms of quantitative metrics, visual quality, memory footprint , and inference time.},
  archive      = {J_NEUCOM},
  author       = {Jinghui Qin and Rumin Zhang},
  doi          = {10.1016/j.neucom.2022.05.066},
  journal      = {Neurocomputing},
  pages        = {846-855},
  shortjournal = {Neurocomputing},
  title        = {Lightweight single image super-resolution with attentive residual refinement network},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Deep multi-view semi-supervised clustering with sample
pairwise constraints. <em>NEUCOM</em>, <em>500</em>, 832–845. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering has attracted much attention thanks to the capacity of multi-source information integration . Although numerous advanced methods have been proposed in past decades, most of them generally overlook the significance of weakly-supervised information and fail to preserve the feature properties of multiple views, thus resulting in unsatisfactory clustering performance. To address these issues, in this paper, we propose a novel D eep M ulti-view S emi-supervised C lustering (DMSC) method, which jointly optimizes three kinds of losses during networks finetuning, including multi-view clustering loss, semi-supervised pairwise constraint loss and multiple autoencoders reconstruction loss. Specifically, a KL divergence based multi-view clustering loss is imposed on the common representation of multi-view data to perform heterogeneous feature optimization, multi-view weighting and clustering prediction simultaneously. Then, we innovatively propose to integrate pairwise constraints into the process of multi-view clustering by enforcing the learned multi-view representation of must-link samples (cannot-link samples) to be similar (dissimilar), such that the formed clustering architecture can be more credible. Moreover, unlike existing rivals that only preserve the encoders for each heterogeneous branch during networks finetuning, we further propose to tune the intact autoencoders frame that contains both encoders and decoders. In this way, the issue of serious corruption of view-specific and view-shared feature space could be alleviated, making the whole training procedure more stable. Through comprehensive experiments on eight popular image datasets, we demonstrate that our proposed approach performs better than the state-of-the-art multi-view and single-view competitors.},
  archive      = {J_NEUCOM},
  author       = {Rui Chen and Yongqiang Tang and Wensheng Zhang and Wenlong Feng},
  doi          = {10.1016/j.neucom.2022.05.091},
  journal      = {Neurocomputing},
  pages        = {832-845},
  shortjournal = {Neurocomputing},
  title        = {Deep multi-view semi-supervised clustering with sample pairwise constraints},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Disturbance observer based inverse optimal control for a
class of nonlinear systems. <em>NEUCOM</em>, <em>500</em>, 821–831. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an inverse optimal composite control (IOCC) method to solve the optimization problem for a class of high-dimensional nonlinear strict-feedback systems with disturbances. Initially, we give these systems an inverse optimal control framework that avoids solving Hamilton–Jacobi-Bellman equations. Then, a nonlinear disturbance observer is designed to estimate the disturbances in the systems. We incorporate these disturbance estimates into the virtual control law design through a backstepping method that gives us a control Lyapunov function . In the end, this control Lyapunov function is utilized to obtain a composite controller that achieves optimality and disturbance rejection. We provide rigorous proofs for the convergence of the proposed composite controller. Simulation studies and comparative results from a real-life application to single-link robots show that the proposed composite controller achieves more robustness and effectiveness than the popular control methods in high-dimensional nonlinear systems .},
  archive      = {J_NEUCOM},
  author       = {Zhong-Xin Fan and Avizit Chandra Adhikary and Shihua Li and Rongjie Liu},
  doi          = {10.1016/j.neucom.2022.05.115},
  journal      = {Neurocomputing},
  pages        = {821-831},
  shortjournal = {Neurocomputing},
  title        = {Disturbance observer based inverse optimal control for a class of nonlinear systems},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Encoding-decoding-based finite-horizon recursive secure
state estimation for dynamic coupled networks with random coupling
strength☆. <em>NEUCOM</em>, <em>500</em>, 809–820. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recursive secure state estimator design issue is investigated in this article for a class of dynamic coupled networks (DCNs) through the encoding-decoding scheme. The random variables distributed over specified intervals are utilized to depict the stochastically varying coupling strengths. For the sake of facilitating the data transmission, saving network resources and cutting down security risks, the two-description coding scheme (TDCS) is employed in the communication channels. Based on the TDCS, the encoders are installed at two independent communication channels, and the packet loss phenomena are considered in two encoder-to-decoder channels. The random denial of service (DoS) attack is taken into account when the decoded data are transmitted to the estimator through the shared communication networks. By recursively dealing with two coupled backward Riccati difference equations (CBRDEs), the desired finite-horizon H ∞ H∞ state estimator gain matrix (EGM) can be determined. Finally, a numerical example is exhibited to illustrate the efficiency of the designed finite-horizon secure state estimator.},
  archive      = {J_NEUCOM},
  author       = {Xueyang Meng and Jianjun Bai and Yun Chen and Anke Xue},
  doi          = {10.1016/j.neucom.2022.05.063},
  journal      = {Neurocomputing},
  pages        = {809-820},
  shortjournal = {Neurocomputing},
  title        = {Encoding-decoding-based finite-horizon recursive secure state estimation for dynamic coupled networks with random coupling strength☆},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CoCycleReg: Collaborative cycle-consistency method for
multi-modal medical image registration. <em>NEUCOM</em>, <em>500</em>,
799–808. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal image registration is an essential step for many medical image analysis applications. Recent advances in multi-modal image registration rely on image-to-image translation to achieve good performance. However, the performance is still limited owing to the poor use of complementary regularization between image registration and translation, which is able to simultaneously enhance both parts’ accuracy. To this end, we propose CoCycleReg, a novel method that formulates image registration and translation in a Co llaborative Cycle - consistency manner. Instead of dividing into two discrete stages, we unify the image registration and translation via cycle-consistency in an end-to-end training process, such that each part can benefit from the other one. To ensure the deformation fields’ reversibility in the cycle, we extensively introduce a novel dual-head registration network, consisting of one single backbone to extract the features and two heads to respectively predict the deformation fields . The experiments on T1-T2(MRI) and CT-MRI datasets validate that the proposed CoCycleReg surpasses the other state-of-the-art conventional and deep learning approaches comprehensively considering the speed, accuracy, and regularity of deformation fields . In the ablation analysis, a method that sets the cycle-consistency Corresponding authors at: Department of Computer Science at School of Informatics, Xiamen University, Xiamen 361005, Chinaconstraints of registration and image-to-image translation separately is compared, and the results demonstrate the effectiveness of collaborative cycle-consistency. In addition, the improvement of image-to-image translation is also verified in further analysis. The code is publicly available at https://github.com/DopamineLcy/cocycle-reg/ .},
  archive      = {J_NEUCOM},
  author       = {Chenyu Lian and Xiaomeng Li and Lingke Kong and Jiacheng Wang and Wei Zhang and Xiaoyang Huang and Liansheng Wang},
  doi          = {10.1016/j.neucom.2022.05.113},
  journal      = {Neurocomputing},
  pages        = {799-808},
  shortjournal = {Neurocomputing},
  title        = {CoCycleReg: Collaborative cycle-consistency method for multi-modal medical image registration},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel multi-domain machine reading comprehension model
with domain interference mitigation. <em>NEUCOM</em>, <em>500</em>,
791–798. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine reading comprehension (MRC), as an important task in natural language processing (NLP), is to automatically answer the question after reading a passage. In this aspect, dominant studies mainly focus on domain-specific models. However, domain-specific models trained only on single domain data often cannot achieve satisfactory performance. Although using data of other domains can bring improvement to some extent, building MRC models specific to each domain also makes deployment more difficult in practice. In this paper, we propose a multi-domain MRC model based on knowledge distillation (KD) with domain interference mitigation . Specifically, we employ KD to train a joint model by simultaneously using the multi-domain data and the output distributions of all domain-specific models. In this way, our joint model can better exploit multi-domain data while enabling simpler deployment at the same time. Moreover, to deal with the gradient conflict caused by using data of different domains, we resort to measuring domain-level gradient similarity, based on which an improved PCGrad (short for p rojecting c onflicting g radients) algorithm with adaptive learning rate is proposed. The algorithm mitigates domain interference to improve our joint model across domains. Experimental results and in-depth analysis demonstrate the effectiveness of our joint model and mitigating domain interference further improves the overall performance of our model on a set of benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Chulun Zhou and Zhihao Wang and Shaojie He and Haiying Zhang and Jinsong Su},
  doi          = {10.1016/j.neucom.2022.05.102},
  journal      = {Neurocomputing},
  pages        = {791-798},
  shortjournal = {Neurocomputing},
  title        = {A novel multi-domain machine reading comprehension model with domain interference mitigation},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A joint framework for mining discriminative and frequent
visual representation. <em>NEUCOM</em>, <em>500</em>, 776–790. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering visual representation in an image category is a challenging issue, because the visual representation should not only be discriminative but also frequently appears in these images. Previous studies have proposed many solutions, however, all of them separately optimized the discrimination and frequency, which consequently makes the solutions sub-optimal. We propose a method to discover the jointly discriminative and frequent visual representation to address this issue, named as JDFR. To ensure discrimination, JDFR employs a classification task with cross-entropy loss. To achieve frequency, we design a novel similarity concentration (SC) loss to concentrate on the samples with the same representation and pull them closer in the feature space, and then mine the frequent visual representations. Moreover, we utilize an attention module to locate the representative region in the image. Extensive experiments on five benchmark datasets (Place365-20, Travel, VOC2012-10, ImageNet-100, and iNaturalist-100) show that the discovered visual representations have better discrimination and frequency than ones mined by the state-of-the-art (SOTA) method with average improvements of 5.37\% on accuracy and 3.06\% on frequency.},
  archive      = {J_NEUCOM},
  author       = {Ying Zhou and Xuefeng Liang and Xiaosong Zhang and Zhihui Liang and Chenyang Wang and Yu Gu and Yifei Yin},
  doi          = {10.1016/j.neucom.2022.05.106},
  journal      = {Neurocomputing},
  pages        = {776-790},
  shortjournal = {Neurocomputing},
  title        = {A joint framework for mining discriminative and frequent visual representation},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A grey convolutional neural network model for traffic flow
prediction under traffic accidents. <em>NEUCOM</em>, <em>500</em>,
761–775. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction can effectively improve traffic efficiency and safety. This has become a trending topic in intelligent transportation systems . However, the occurrence of traffic accidents will cause great fluctuations of traffic flow in a short time, thus affecting the accuracy of flow prediction. This paper analyses the influence of traffic accident information on traffic flow, and proposes a grey convolutional neural network called G-CNN for traffic flow prediction . First, considering the small sample size of traffic accidents and the incomplete information description, the traffic flow and traffic speed change rate are defined to represent traffic accident grey information, and a grey fixed-weight clustering method for extracting the characteristics of traffic accident grey information is established. Second, the spatiotemporal characteristics of traffic flow are analysed, and a third-order tensor is developed to fuse them with the accident characteristics and serve as the input of the G-CNN. Then the G-CNN model is built to predict traffic flow in a traffic accident environment. The Canadian Whitemud Drive experiment on traffic flow without traffic accident information reveals that the developed G-CNN model has a better ability to predict future traffic flow with better accuracy and stability. Meanwhile, it is verified that the fluctuation of the traffic change rate will cause traffic accidents, and the probability of traffic accidents at a certain time point will be obtained through feature extraction of traffic accidents. Finally, the model is verified for the traffic flow of Hangzhou Viaduct in China, which demonstrates that the G-CNN model outperforms all of the compared models.},
  archive      = {J_NEUCOM},
  author       = {Yafang Liu and Chaozhong Wu and Jianghui Wen and Xinping Xiao and Zhijun Chen},
  doi          = {10.1016/j.neucom.2022.05.072},
  journal      = {Neurocomputing},
  pages        = {761-775},
  shortjournal = {Neurocomputing},
  title        = {A grey convolutional neural network model for traffic flow prediction under traffic accidents},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anatomical prior based vertebra modelling for reappearance
of human spines. <em>NEUCOM</em>, <em>500</em>, 750–760. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scoliosis is a disease caused by deformation of the spine, and precise imaging of human spine tissues is crucial and instructive for the subsequent treatment. Currently, radiographs are clinically used to monitor disease progress. However, radiation exposure is a safety concern and is undesirable for regular monitoring during rehabilitation intervention. In this study, we developed a novel technique to generate the 3D structure of human spine from a tracked freehand ultrasound scanning. First of all, we designed an approach for detection and location of every vertebra in the spine by firstly detecting the vertebral landmarks from the ultrasound B-scan sequence, then computing the size, location and posture of every vertebra and finally using a method of interpolation to form the whole spine according to the prior knowledge of vertebral anatomical structure. Deep learning based object detection methods were used to find the landmarks of the vertebrae, and those landmarks were then clustered to model every vertebra (i.e. computing its location, posture and real size). Due to the situations where the vertebra is not clearly seen, we therefore used the technique of interpolation to estimate the location of those missing vertebrae with respect to the anatomical prior. In addition, we reconnected all vertebral models and reappeared the whole spine in 3D space. With that, the Cobb angle could be easily measured. The phantom and in vivo experiments were also conducted to further verify the precision of the proposed approaches. The results have demonstrated its feasibility in the clinical practice of adolescent idiopathic scoliosis patients ( R 2 = 0 . 9780 ,p &lt; 0. 001), which is beneficial for the regular quantitative monitoring of disease progression .},
  archive      = {J_NEUCOM},
  author       = {Qinghua Huang and Hao Luo and Cui Yang and Jianyi Li and Qifeng Deng and Peng Liu and Maoqing Fu and Le Li and Xuelong Li},
  doi          = {10.1016/j.neucom.2022.05.033},
  journal      = {Neurocomputing},
  pages        = {750-760},
  shortjournal = {Neurocomputing},
  title        = {Anatomical prior based vertebra modelling for reappearance of human spines},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A two-factor security authentication scheme for wireless
sensor networks in IoT environments. <em>NEUCOM</em>, <em>500</em>,
741–749. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important part of the Internet of Things , wireless sensor networks have been widely used in all aspects of people&#39;s lives. Identity authentication in wireless sensor networks guarantees security for users to safely access real-time data in sensor nodes . In the literature, numerous research works have been done on designing an efficient and secure authentication scheme for wireless sensor networks, but most of them suffer from various security flaws. In 2019, Sharif et al. proposed an efficient user authentication scheme , which was later found insecure by Chen et al. who then proposed an enhanced scheme. However, we find that Chen et al.’s scheme is vulnerable to off-line password guessing attack, impersonation attack and fails to achieve perfect forward secrecy, user anonymity, and unlinkability. To overcome those weaknesses, we propose a two-factor authentication scheme based on elliptic curve cryptosystem , and prove its security by formal verification tool ProVerif. Compared with related schemes, our scheme provides higher level of security, meanwhile achieves acceptable efficiency in computational cost. To the best of our knowledge, this is the first scheme fulfilling both two-factor security and user anonymity under sensor node captured attack.},
  archive      = {J_NEUCOM},
  author       = {Bin Hu and Wen Tang and Qi Xie},
  doi          = {10.1016/j.neucom.2022.05.099},
  journal      = {Neurocomputing},
  pages        = {741-749},
  shortjournal = {Neurocomputing},
  title        = {A two-factor security authentication scheme for wireless sensor networks in IoT environments},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Density-based structural embedding for anomaly detection in
dynamic networks. <em>NEUCOM</em>, <em>500</em>, 724–740. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic networks continuously change their structure and properties, and anomaly detection methods must identify these structural changes at both local and global levels. Network embedding is considered a powerful tool for low-dimension structural representation of network objects. However, most embedding techniques developed for dynamic networks are incompetent in capturing the changes in global structures. Besides, with incoming edge streams, these techniques change the embeddings of all network objects, including those vertices and edges that do not experience any change in subsequent timestamps. In this paper, we propose an embedding algorithm DSEDN to identify anomalous vertices and edges in dynamic networks utilizing structural changes in networks. The algorithm uses sparse autoencoder to generate network embeddings minimizing the pair-wise and neighborhood distance between vertex representations of every subgraph derived from random walks. The subgraphs have been weighted based on their respective clustering coefficient, and the clustering algorithm is employed to identify network anomalies. The advantages of proposed method include: (i) better accuracy in detecting network anomalies; (ii) structure-preserving embeddings, such that it maintains the local and global structure of every snapshot of growing graphs; (iii) density-based embeddings; (iv) stable embeddings over time such that embeddings of consecutive timestamps do not change much for those network objects that do not experience any change; (v) scalability. We evaluate the proposed algorithm on anomaly detection and graph visualization on five real-world datasets. Our algorithm achieves improvement in AUC, scalability, and stability across all baselines.},
  archive      = {J_NEUCOM},
  author       = {Monika Bansal and Dolly Sharma},
  doi          = {10.1016/j.neucom.2022.05.109},
  journal      = {Neurocomputing},
  pages        = {724-740},
  shortjournal = {Neurocomputing},
  title        = {Density-based structural embedding for anomaly detection in dynamic networks},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An imitation learning framework for generating multi-modal
trajectories from unstructured demonstrations. <em>NEUCOM</em>,
<em>500</em>, 712–723. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main challenge of the trajectory generation problem is to generate long-term as well as diverse trajectories. Generative Adversarial Imitation Learning (GAIL) is a well-known model-free imitation learning algorithm that can be utilized to generate trajectory data , while vanilla GAIL would fail to capture multi-modal demonstrations. Recent methods propose latent variable models to solve this problem; however, previous works may have a mode missing problem. In this work, we propose a novel method to generate long-term trajectories that are controllable by a continuous latent variable based on GAIL and a conditional Variational Autoencoder (cVAE). We further assume that subsequences of the same trajectory should be encoded to similar locations in the latent space. Therefore, we introduce a contrastive loss in the training of the encoder. In our motion synthesis task, we propose to first construct a low-dimensional motion manifold by using a VAE to reduce the burden of our imitation learning model. Our experimental results show that the proposed model outperforms the state-of-the-art methods and can be applied to motion synthesis.},
  archive      = {J_NEUCOM},
  author       = {Jian-Wei Peng and Min-Chun Hu and Wei-Ta Chu},
  doi          = {10.1016/j.neucom.2022.05.076},
  journal      = {Neurocomputing},
  pages        = {712-723},
  shortjournal = {Neurocomputing},
  title        = {An imitation learning framework for generating multi-modal trajectories from unstructured demonstrations},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-layer secure transmission schemes for social internet
of things: Overview, opportunities and challenges. <em>NEUCOM</em>,
<em>500</em>, 703–711. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is regarded as one of the most promising fields for ubiquitous access, information exchange, and real-time analysis. The enormous device population and direct interactions among devices help form social attributes of devices, enabling Social IoT (SIoT) that integrates an IoT system and Social Networks. Despite advantages including network navigability, service scalability, and enhanced trustworthiness of data, there are more severe security issues to be solved urgently in SIoT. We first depict a powerful SIoT and abstract primary social attributes, then present key security issues in SIoT and investigate specific solutions via cross-layer. The core of cross-layer designs is the tradeoff between security and other aspects (e.g., energy or complexity) in essence. Moreover, graph-powered learning has shown its superiority in Social Networks, leading to our discussion about applying graph learning in SIoT cross-layer security schemes for promoting future SIoT security researches.},
  archive      = {J_NEUCOM},
  author       = {Yingzhen Wu and Yan Huo},
  doi          = {10.1016/j.neucom.2021.07.105},
  journal      = {Neurocomputing},
  pages        = {703-711},
  shortjournal = {Neurocomputing},
  title        = {Cross-layer secure transmission schemes for social internet of things: Overview, opportunities and challenges},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leveraging fusion of sequence tagging models for toxic spans
detection. <em>NEUCOM</em>, <em>500</em>, 688–702. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The upsurge of prolific blogging and microblogging platforms enabled the abusers to spread negativity and threats greater than ever. Negative and hateful comments are averting users from sharing their opinion freely on social media platforms . It often breaks people’s confidence and causes extensive damage to their mental health. Hence, identifying these toxic contents and taking appropriate measures against them is crucial to preserve a safe environment on social media. Numerous state-of-the-art approaches classify the whole content as toxic or non-toxic, but they don’t distinguish the precise toxic portion from the whole content. Detecting the toxic portions is essential as it substantially aids to moderate the toxic contents through excluding the abusive parts. This paper describes our proposed approach to detect the toxic portions from text contents efficiently and accurately. We explore an ensemble of sequence labeling models including the word embedding-based Spark NLP NER (named entity recognition) deep learning model , spaCy NER model with custom toxic tags, and ALBERT NER model to identify the toxic spans. The NER-based models usually intend to capture the contextual attributes of phrases and spans that are essential for named entity recognition . As the toxic span detection task also requires us to apprehend the phrasal context for detecting toxic span, the similarity between these two tasks inspires us to exploit these NER models. Finally, we determine the final toxic spans using a prevalence-based fusion of the predictions generated by these models. The fusion strategy enables us to consolidate the diversity of these models for perceiving the phrasal context in all aspects. Experimental results achieved on the SemEval-2021 toxic spans detection dataset depict that our model meticulously captures the toxic fragment and achieves a competitive result among the other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Jannatun Naim and Tashin Hossain and Fareen Tasneem and Abu Nowshed Chy and Masaki Aono},
  doi          = {10.1016/j.neucom.2022.05.049},
  journal      = {Neurocomputing},
  pages        = {688-702},
  shortjournal = {Neurocomputing},
  title        = {Leveraging fusion of sequence tagging models for toxic spans detection},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pre-training on dynamic graph neural networks.
<em>NEUCOM</em>, <em>500</em>, 679–687. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pre-training of the graph neural network model is to learn the general characteristics of large-scale graphs or the similar type of graphs usually through a self-supervised method, which allows the model to work even when node labels are missing. However, the existing pre-training methods do not take the temporal information of edge generation and the evolution process of graph into consideration. To address this issue, this paper proposes a pre-training method based on dynamic graph neural networks (PT-DGNN), which uses the dynamic graph generation task to simultaneously learn the structure, semantics, and evolution features of the graph. The method mainly includes two steps: 1) dynamic subgraph sampling, and 2) pre-training using two graph generation tasks. The former preserves the local time-aware structure of the original graph by sampling the latest and frequently interacting nodes. The latter uses observed edges to predict unobserved edges to capture the evolutionary characteristics of the network. Comparative experiments on three realistic dynamic network datasets show that the proposed pre-training method achieves the best results on the link prediction fine-tuning task and the ablation study and further verifies the effectiveness of the above two steps.},
  archive      = {J_NEUCOM},
  author       = {Ke-Jia Chen and Jiajun Zhang and Linpu Jiang and Yunyun Wang and Yuxuan Dai},
  doi          = {10.1016/j.neucom.2022.05.070},
  journal      = {Neurocomputing},
  pages        = {679-687},
  shortjournal = {Neurocomputing},
  title        = {Pre-training on dynamic graph neural networks},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on firefly algorithms. <em>NEUCOM</em>,
<em>500</em>, 662–678. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firefly algorithm (FA) is one of the popular algorithms of Swarm Intelligence domain. The literature has expanded significantly in the past few years. This paper provides a timely review of the FA and its new variants. The different variants of FA are classified and analyzed. The applications and case studies in the rapidly evolving domain are also reviewed and summarized in detail here. The problems to be further solved and future research directions of firefly algorithms will be given at the end of this paper.},
  archive      = {J_NEUCOM},
  author       = {Jun Li and Xiaoyu Wei and Bo Li and Zhigao Zeng},
  doi          = {10.1016/j.neucom.2022.05.100},
  journal      = {Neurocomputing},
  pages        = {662-678},
  shortjournal = {Neurocomputing},
  title        = {A survey on firefly algorithms},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generic semi-supervised adversarial subject translation for
sensor-based activity recognition. <em>NEUCOM</em>, <em>500</em>,
649–661. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performance of Human Activity Recognition (HAR) models, particularly deep neural networks , is highly contingent upon the availability of the massive amount of annotated training data. Though, data collection and manual labeling in the HAR domain are prohibitively expensive due to human resource dependence in both steps. Hence, domain adaptation techniques are proposed to adapt the knowledge from the existing source of data. More recently, adversarial transfer learning methods have shown promising results for visual classification, yet limited for HAR problems, which are still prone to the unfavorable effects of the imbalanced distribution of samples. This paper presents a novel generic semi-supervised approach that takes advantage of the adversarial framework to tackle these shortcomings by leveraging knowledge from annotated samples exclusively from the source subject and unlabeled ones of the target subject. An extensive subject translation experiments is conducted on three large, middle, and small-size datasets with different levels of imbalance to assess the robustness of the proposed model to the scale as well as the imbalance in the data. The results demonstrate the effectiveness of our proposed algorithms over state-of-the-art methods, which led to up to 13\%, 4\%, and 13\% improvement of our high-level activities recognition metrics for Opportunity, LISSI, and PAMAP2 datasets, respectively.},
  archive      = {J_NEUCOM},
  author       = {Elnaz Soleimani and Ghazaleh Khodabandelou and Abdelghani Chibani and Yacine Amirat},
  doi          = {10.1016/j.neucom.2022.05.075},
  journal      = {Neurocomputing},
  pages        = {649-661},
  shortjournal = {Neurocomputing},
  title        = {Generic semi-supervised adversarial subject translation for sensor-based activity recognition},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An approach to forecasting and filtering noise in dynamic
systems using LSTM architectures. <em>NEUCOM</em>, <em>500</em>,
637–648. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some of the limitations of state-space models are given by the difficulty of modeling certain systems, the filters convergence time, or the impossibility of modeling dependencies in the long term. Having agile and alternative methodologies that allow the modeling of complex problems but still provide solutions to the classic challenges of estimation or filtering, such as the position estimation of a mobile with noisy measurements and unknown motion models, are of high interest. In this work, we address the problem of position estimation of 1-D dynamic systems from a deep learning paradigm, using Long-Short Term Memory (LSTM) architectures designed to solve problems with long term temporal dependencies, in combination with other recurrent networks . A deep neuronal architecture inspired by the Encoder-Decoder language systems is implemented, remarking its limits and finding a solution capable of making predictions of high accuracy with models learnt from training data of a moving object. We use a panel data model for training and validation. In the experimentation, we use sliding overlapping time windows in a recursive and standardized way to avoid the saturation problem of the networks in increasing trend estimates. The results are finally compared with the optimal values from the Kalman filter , obtaining comparable results in error terms. These results show the proposed system has great potential for target tracking.},
  archive      = {J_NEUCOM},
  author       = {Juan Pedro Llerena Caña and Jesús García Herrero and José Manuel Molina López},
  doi          = {10.1016/j.neucom.2021.08.162},
  journal      = {Neurocomputing},
  pages        = {637-648},
  shortjournal = {Neurocomputing},
  title        = {An approach to forecasting and filtering noise in dynamic systems using LSTM architectures},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MIML library: A modular and flexible library for
multi-instance multi-label learning. <em>NEUCOM</em>, <em>500</em>,
632–636. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MIML library is a Java software tool to develop, test, and compare classification algorithms for multi-instance multi-label (MIML) learning. The library includes 43 algorithms and provides a specific format and facilities for data managing and partitioning, holdout and cross-validation methods, standard metrics for performance evaluation, and generation of reports. In addition, algorithms can be executed through xml configuration files without needing to program. It is platform-independent, extensible, free, open-source, and available on GitHub under the GNU General Public License.},
  archive      = {J_NEUCOM},
  author       = {Álvaro Belmonte and Amelia Zafra and Eva Gibaja},
  doi          = {10.1016/j.neucom.2022.05.068},
  journal      = {Neurocomputing},
  pages        = {632-636},
  shortjournal = {Neurocomputing},
  title        = {MIML library: A modular and flexible library for multi-instance multi-label learning},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generating a trading strategy in the financial market from
sensitive expert data based on the privacy-preserving generative
adversarial imitation network. <em>NEUCOM</em>, <em>500</em>, 616–631.
(<a href="https://doi.org/10.1016/j.neucom.2022.05.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying a deep learning algorithm to real financial trading records can effectively establish a profitable trading strategy, but leaking of private information during the process is a concern. To solve this problem, previous studies have proposed a privatized data “release” mechanism, but this mechanism is unable to truly protect privacy. To preserve privacy while still being able to learn useful information, we proposed a privacy-preserving generative adversarial imitation network (PPGAIN), a novel deep learning algorithm that imitates behaviors of general financial investors while preserving individual privacy. The core concept of PPGAIN is to provide class-ambiguous outputs to preserve privacy while generating sequences of trading behavior that are similar to a real investor’s behavior. We used an auxiliary classifier as an adversary to ensure that the generated results are class ambiguous. We also proposed weakness replay to enforce the training of a discriminator . The PPGAIN model was trained in two stages, in the first stage, the model was trained to be realistic. In the second stage, it was trained against the auxiliary classifier to ensure that the outputs were highly realistic but could not be easily classified as an imitation from any specific individual to preserve privacy. Using real and synthetic trading records in TAIEX, we proved that our proposed method (PPGAIN) can achieve a generation quality similar to that obtained using conditional variational autoencoder models and demonstrated that PPGAIN provides better class ambiguity to preserve individual privacy than privacy-preserving adversarial network.},
  archive      = {J_NEUCOM},
  author       = {Hsin-Yi Chen and Szu-Hao Huang},
  doi          = {10.1016/j.neucom.2022.05.039},
  journal      = {Neurocomputing},
  pages        = {616-631},
  shortjournal = {Neurocomputing},
  title        = {Generating a trading strategy in the financial market from sensitive expert data based on the privacy-preserving generative adversarial imitation network},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Transductive distribution calibration for few-shot
learning. <em>NEUCOM</em>, <em>500</em>, 604–615. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot image classification aims at learning a model from previous experiences that can be rapidly adapted to classify images of new classes with a few labeled examples. The learned model is easy to overfit since the distributions of new classes formed by a small number of samples are severely biased. Recently, Distribution Calibration (DC) tackles this problem by transferring the Gaussian statistics of seen classes with sufficient samples to calibrate the distributions of new classes. In this paper, we first take a closer look at the calibration mechanism from the source class distribution to the new class distribution in DC and propose a simplified version using averaged mean and covariance of all base classes as source statistics for all new classes. We further extend the simplified DC to the transductive setting. We extract the Gaussian statistics of unlabeled query samples to calibrate the distributions of new classes. We augment the labeled samples by sampling from the calibrated distributions to train a more accurate task-specific classifier. Our method can be readily applied on top of any existing pre-trained feature extractor and classifier without extra learnable parameters. Extensive experiments on several few-shot learning benchmarks demonstrate the effectiveness of our method. We provide visualizations to show that new classes are better separated under our calibrated distributions.},
  archive      = {J_NEUCOM},
  author       = {Gang Li and Changwen Zheng and Bing Su},
  doi          = {10.1016/j.neucom.2022.05.078},
  journal      = {Neurocomputing},
  pages        = {604-615},
  shortjournal = {Neurocomputing},
  title        = {Transductive distribution calibration for few-shot learning},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Orthogonal multi-view tensor-based learning for clustering.
<em>NEUCOM</em>, <em>500</em>, 592–603. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view spectral clustering aims to improve the performance of spectral clustering through multi-view data. Many multi-view spectral clustering methods have been proposed recently and achieved promising performance. Among these methods, most of them are designed to pursue numerical consistency in multi-view similarity matrices . However, each similarity matrix has its unique statistic distribution, which makes it not appropriate to seek numerical consistency in multi-view similarity matrices or directly average the multi-view similarity matrices. To overcome the aforementioned problem, we propose a novel Orthogonal Multi-view Tensor-based Learning for clustering, abbreviated as OMTL. Specifically, OMTL introduces an orthogonal matrix factorization to eliminate the view-specific statistic distribution and preserve the intrinsic clustering structure of each view, which fully considers the consensus information contained in multiple views to boost multi-view spectral clustering performance. Further, we employ a low-rank tensor constraint to explore the high order correlations among multiple views. By designing an alternating direction method of multipliers (ADMM) based optimization algorithm , the intrinsic similarity matrix of multi-view data can be efficiently learned for spectral clustering. Extensive experiments on several benchmark datasets have illustrated the superior clustering performance of the proposed method compared to several state-of-the-art multi-view clustering methods .},
  archive      = {J_NEUCOM},
  author       = {Shuangxun Ma and Yuehu Liu and Guangcan Liu and Qinghai Zheng and Chi Zhang},
  doi          = {10.1016/j.neucom.2022.05.069},
  journal      = {Neurocomputing},
  pages        = {592-603},
  shortjournal = {Neurocomputing},
  title        = {Orthogonal multi-view tensor-based learning for clustering},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MultiJAF: Multi-modal joint entity alignment framework for
multi-modal knowledge graph. <em>NEUCOM</em>, <em>500</em>, 581–591. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity Alignment (EA) is a crucial task in knowledge fusion, which aims to link entities with the same real-world identity from different Knowledge Graphs (KGs). Existing methods have achieved satisfactory performance, however, they mainly focus on single modal KG, which is difficult to be effectively applied to multi-modal scenes. In this paper, we propose a Multi-modal Joint entity Alignment Framework (MultiJAF), which can effectively utilize the knowledge of various modalities. Concretely, we first learn the embeddings of different modalities, i.e., structure, attribute and image modalities . Next, we adopt an attention-based multi-modal fusion network to integrate these embeddings and use obtained joint embeddings to compute a joint embedding-based similarity matrix S J SJ . Moreover, we design a Numerical Process Module (NPM) to infer a similarity matrix S N SN according to the numerical information of entities. In the end, we utilize a simple late fusion method to ensemble two similarity matrices for the final alignment. In addition, to reduce the cost of labeling data, we propose a novel NPM-based unsupervised multi-modal EA method. Experimental results on two real-world datasets demonstrate the effectiveness of our proposed MultiJAF.},
  archive      = {J_NEUCOM},
  author       = {Bo Cheng and Jia Zhu and Meimei Guo},
  doi          = {10.1016/j.neucom.2022.05.058},
  journal      = {Neurocomputing},
  pages        = {581-591},
  shortjournal = {Neurocomputing},
  title        = {MultiJAF: Multi-modal joint entity alignment framework for multi-modal knowledge graph},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Surgical GAN: Towards real-time path planning for passive
flexible tools in endovascular surgeries. <em>NEUCOM</em>, <em>500</em>,
567–580. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic surgical path planning of the passive flexible tool encounters a prohibitive challenge, typically in endovascular surgery (ES). The key problem is that unstructured surgical environment and tools’ unpredictable motion is hard to be explicitly modeled. We propose a generative adversarial networks (GAN)-based framework (defined as surgical GAN) towards automatic guidewire path planning in real time for ES. A novel GAN architecture is proposed by combining convolutional neural networks (CNN) and long short-term memory networks (LSTM), which extracts and fuses the spatial features in medical images and temporal features of historical tool path as the conditional information. It inputs the surgical state information and continuously outputs the local future path of the guidewire tip. A training dataset (3.5* 10 5 105 samples) is collected under laboratory conditions with 10 surgeons. Effects of different CNN architectures and path planning length on network performance are investigated. User experiments, with the tasks delivering the guidewire tip inside a vascular model (endovascular evaluator) from the aortic arch into the left common carotid artery (LCCA), left subclavian artery (LSCA), or brachiocephalic trunk, are conducted with 10 novice surgeons in an operating room. The results shows significant improvement of a path planning accuracy with surgical GAN compared with baseline networks (from 46.2\%–69.78\%) and the non-rigid registration method (72.94\%). Results of user experiments demonstrate an overall better task performance with the guidance of planned surgical path. Collectively, surgical GAN can achieve real-time path planning of the guidewire in simulated ES, and holds great potential for novice training and robotic ES autonomy.},
  archive      = {J_NEUCOM},
  author       = {Yan Zhao and Yuxin Wang and Jianhua Zhang and Xinke Liu and Youxiang Li and Shuxiang Guo and Xu Yang and Shunming Hong},
  doi          = {10.1016/j.neucom.2022.05.044},
  journal      = {Neurocomputing},
  pages        = {567-580},
  shortjournal = {Neurocomputing},
  title        = {Surgical GAN: Towards real-time path planning for passive flexible tools in endovascular surgeries},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalized fault diagnosis method of transmission lines
using transfer learning technique. <em>NEUCOM</em>, <em>500</em>,
556–566. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent artificial intelligence-based methods have shown great promise in the use of neural networks for real-time detection of transmission line faults and estimation of their locations. The expansion of power systems including transmission lines with various lengths have made the fault detection, classification, and location estimation process more challenging. Transmission line datasets are stream data which are continuously collected by various sensors and hence, require generalized and fast fault diagnosis approaches. Newly collected datasets including voltages and currents for faulty and non-faulty situations might not have adequate and accurate labels that are useful to train neural networks . In this paper, a novel transfer learning framework based on a pre-trained LeNet-5 convolutional neural network is proposed. This method is able to diagnose faults for different transmission line lengths and impedances by transferring the knowledge from a source convolutional neural network to predict a dissimilar target dataset. By transferring this knowledge, faults from various transmission lines, even without sufficient data samples with labels, can be diagnosed faster and more efficiently than the existing methods. To prove the feasibility and effectiveness of this methodology, seven different datasets that include various lengths of transmission lines are used. The robustness of the proposed methodology against the generator voltage fluctuations, variations in fault locations, fault inception angle, fault resistance, and phase difference between the two generators are well studied to prove the reliability of this technique for fault diagnosis of transmission lines.},
  archive      = {J_NEUCOM},
  author       = {Fatemeh Mohammadi Shakiba and Milad Shojaee and S. Mohsen Azizi and MengChu Zhou},
  doi          = {10.1016/j.neucom.2022.05.022},
  journal      = {Neurocomputing},
  pages        = {556-566},
  shortjournal = {Neurocomputing},
  title        = {Generalized fault diagnosis method of transmission lines using transfer learning technique},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel 2D contactless fingerprint matching method.
<em>NEUCOM</em>, <em>500</em>, 547–555. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fingerprint recognition is an important biometric technology . According to the data collection methods, fingerprints can be divided into contact-based and contactless schemes. In recent years, 2D contactless fingerprints have constantly received attention and research attention because of their safety and hygiene advantages and low cost. However, because of its collection mode, contactless fingerprints usually have low-resolution and are prone to posture inconsistency. This issue leads to the poor matching effect of most current fingerprint algorithms on 2D contactless fingerprints, especially for mainstream minutiae-based methods. To address these problems, we propose a novel 2D contactless fingerprint matching method named as fingerprint triplet-GAN (FTG). It is an end-to-end method consisting of a triplet network and a GAN , and it bypasses the conventional extraction of fingerprint minutiae. First, we use a triplet network to perform data balancing and augmentation, and improve the robustness at low-resolution. Furthermore, we design a GAN to help extract posture-independent features to improve the rotation robustness of the model. The effectiveness of the proposed method is evaluated on two databases: PolyU and FVC2004DB1. The experimental results show that it can achieve state-of-the-art performance on 2D contactless fingerprints. Codes are available at: https://github.com/IC-LAB.},
  archive      = {J_NEUCOM},
  author       = {Lei Shi and Sheng Lan and Hao Gui and Yujiu Yang and Zhenhua Guo},
  doi          = {10.1016/j.neucom.2022.05.092},
  journal      = {Neurocomputing},
  pages        = {547-555},
  shortjournal = {Neurocomputing},
  title        = {A novel 2D contactless fingerprint matching method},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Teacher-student knowledge distillation for real-time
correlation tracking. <em>NEUCOM</em>, <em>500</em>, 537–546. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of correlation filter (CF) based visual trackers has been greatly improved with pretrained deep convolutional neural networks . However, these networks limit the application scope of CF based trackers because of high feature dimension, high time consumption of feature extraction and huge memory storage. To alleviate this problem, we introduce a teacher-student knowledge distillation framework to obtain a lightweight network to speed up CF based trackers. Specifically, we take a pretrained deep convolutional neural network from the image classification task as a teacher network, and distill this teacher network into a lightweight student network. During offline distillation training process, we propose an attention transfer loss to ensure the lightweight student network maintains feature representation of the large-capacity teacher network. Meanwhile, we propose a correlation tracking loss to transfer the student network from image classification task to correlation tracking task, which improves the discriminant ability of the student network. Experiments on OTB, VOT2017 and Temple Color show that, using the learned lightweight network model as the feature extractor, the state-of-the-art CF based tracker achieves real-time speed on a single CPU, while maintaining almost the same tracking performance.},
  archive      = {J_NEUCOM},
  author       = {Qihuang Chen and Bineng Zhong and Qihua Liang and Qingyong Deng and Xianxian Li},
  doi          = {10.1016/j.neucom.2022.05.064},
  journal      = {Neurocomputing},
  pages        = {537-546},
  shortjournal = {Neurocomputing},
  title        = {Teacher-student knowledge distillation for real-time correlation tracking},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymptotic behavior of free energy when optimal probability
distribution is not unique. <em>NEUCOM</em>, <em>500</em>, 528–536. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian inference is a widely used statistical method. The free energy and the generalization loss, which are used to estimate the accuracy of Bayesian inference, are known to be small in singular models that do not have a unique optimal parameter. However, their characteristics have not yet been clarified when there are multiple optimal probability distributions. In this paper, we theoretically derive the asymptotic behaviors of the generalization loss and the free energy in the case that the optimal probability distributions are not unique and show that they contain asymptotically different terms from those of the conventional asymptotic analysis.},
  archive      = {J_NEUCOM},
  author       = {Shuya Nagayasu and Sumio Watanbe},
  doi          = {10.1016/j.neucom.2022.05.071},
  journal      = {Neurocomputing},
  pages        = {528-536},
  shortjournal = {Neurocomputing},
  title        = {Asymptotic behavior of free energy when optimal probability distribution is not unique},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep transfer learning-based gaze tracking for behavioral
activity recognition. <em>NEUCOM</em>, <em>500</em>, 518–527. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational Ethology studies focused on human beings is usually referred as Human Activity Recognition (HAR). Specifically, this paper belongs to a line of work on the identification of broad cognitive activities that users carry out with computers. The keystone of this kind of systems is the noninvasive detection of the subject’s gaze fixations in selected display areas. Noninvasiveness is ensured by using the conventional laptop cameras without additional illumination or tracking devices. The gaze ethograms, composed as sequences of gaze fixations, are the basis to identify the user activities. To determine the gaze fixation display areas with the highest accuracy, this paper explores the use of a transfer learning approach applied to several well-known deep learning network (DLN) architectures whose input is the eye area extracted from the face image,and output is the identification of the gaze fixation area in the computer screen. Two different datasets are created and used in the validation experiments. We report encouraging results that may allow the general use of the system.},
  archive      = {J_NEUCOM},
  author       = {Javier de Lope and Manuel Graña},
  doi          = {10.1016/j.neucom.2021.06.100},
  journal      = {Neurocomputing},
  pages        = {518-527},
  shortjournal = {Neurocomputing},
  title        = {Deep transfer learning-based gaze tracking for behavioral activity recognition},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Multi-view learning for hyperspectral image classification:
An overview. <em>NEUCOM</em>, <em>500</em>, 499–517. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral images (HSI) are obtained from hyperspectral imaging sensors to capture the object’s information in hundreds of spectral bands. However, how to make full advantage of spatial and spectral information from a large number of spectral bands to improve the performance of HSI classification remains an open question. Many HSI classification works have recently been reported by employing multi-view learning (MVL) algorithms and have achieved promising results. Generally, MVL based HSI classification can be divided into three steps, i.e. (1) multi-view construction, (2) interactivity enhanced, and (3) multi-view fusion. This paper presents a review of MVL methods in HSI classification based on the general steps of MVL. Specifically, multi-view construction builds various representations from the raw HSI data as different views to adapt to an MVL setup. Secondly, interactivity enhanced aims to interact with different view features, so that the current view contains information from other views and to achieve a pre-fusion effect. Finally, multi-view fusion uses different fusion methods to combine multiple views and classify HSIs using complementary information between the views. In addition, we analyzed and discussed separately representative approaches in each step and their characteristics, and introduced some of the most advanced work. Overall, this survey aims to provide an insightful overview of developments in MVL in HSI classification and help researchers identify its future trends.},
  archive      = {J_NEUCOM},
  author       = {Xuefei Li and Baodi Liu and Kai Zhang and Honglong Chen and Weijia Cao and Weifeng Liu and Dapeng Tao},
  doi          = {10.1016/j.neucom.2022.05.093},
  journal      = {Neurocomputing},
  pages        = {499-517},
  shortjournal = {Neurocomputing},
  title        = {Multi-view learning for hyperspectral image classification: An overview},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attractive and repulsive training to address inter-task
forgetting issues in continual learning. <em>NEUCOM</em>, <em>500</em>,
486–498. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In continual learning over deep neural networks (DNNs), the rehearsal strategy , in which the previous exemplars are jointly trained with new samples, is commonly employed for the purpose of addressing catastrophic forgetting . Unfortunately, due to the memory limit, rehearsal-based techniques inevitably cause the class imbalance issue leading to a DNN biased toward new tasks having more samples. Existing works mostly focus on correcting such a bias in the fully connected layer or classifier. In this paper, we newly discover that class imbalance tends to make old classes even more highly correlated with their similar new classes in the feature space, which turns out to be the major reason behind catastrophic forgetting, called inter-task forgetting . To alleviate inter-task forgetting, we propose a novel class incremental learning method, called attractive &amp; repulsive training (ART) , which effectively captures the previous feature space into a set of class-wise flags , and thereby makes old and new similar classes less correlated in the new feature space. In our empirical study, our ART method is observed to be quite effective to improve the performance of the state-of-the-art methods by substantially mitigating inter-task forgetting. Our implementation is available at: https://github.com/bigdata-inha/ART/ .},
  archive      = {J_NEUCOM},
  author       = {Hong-Jun Choi and Dong-Wan Choi},
  doi          = {10.1016/j.neucom.2022.05.079},
  journal      = {Neurocomputing},
  pages        = {486-498},
  shortjournal = {Neurocomputing},
  title        = {Attractive and repulsive training to address inter-task forgetting issues in continual learning},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Different discrete-time noise-suppression z-type models for
online solving time-varying and time-invariant cube roots in real and
complex domains: Application to fractals. <em>NEUCOM</em>, <em>500</em>,
471–485. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different from the conventional calculation method, the discrete-time noise-suppression zeroing neural dynamic (DTNSZND) model is developed and investigated for online solving the time-varying/time-invariant scalar cube root problem with different disturbances (bounded/unbounded disturbances) from a control perspective in this paper. The solving precision and robustness of different DTNSZND models are generated via various difference rules are discussed and analyzed, and numerical simulations verify that the convergence property of the developed models are closely related to the accuracy of difference rules. The zero-stable, consistent and convergent of different DTNSZND models are demonstrated via theoretical analyses. Furthermore, numerical simulation and comparative results prove that the convergence, robustness and superiority of the presented different DTNSZND models for online solving time-varying/time-invariant cube root problems with different interferences in real domain or complex domain. Finally, different fractals are generated by utilizing the developed DTNSZND model to solve the cube root problem with different noises in complex domain, which are quite different from Newton fractals produced by Newton–Raphson iteration. Therefore, the proposed different DTNSZND models can be considered as a novel iterative algorithm to generate new fractal.},
  archive      = {J_NEUCOM},
  author       = {Jian Li and Yingyi Sun and Gang Wang and Yongbai Liu and Zhongbo Sun},
  doi          = {10.1016/j.neucom.2022.05.089},
  journal      = {Neurocomputing},
  pages        = {471-485},
  shortjournal = {Neurocomputing},
  title        = {Different discrete-time noise-suppression Z-type models for online solving time-varying and time-invariant cube roots in real and complex domains: Application to fractals},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal innovation-based deception attacks with side
information against remote state estimation in cyber-physical systems.
<em>NEUCOM</em>, <em>500</em>, 461–470. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of designing the optimal deception attacks against the remote state estimation in cyber-physical systems is investigated in the scenario where the attacker has the ability to acquire the side information about the system by employing an extra sensor. To degenerate the remote estimation performance, the attacker replaces the transmitted signals with the combination of the innovations from the system sensor and the extra sensor. Under the proposed attacks, the recursion of the error covariance of the remote estimates is derived by utilizing the orthogonality principle and the statistical properties of the related random variables. Then, the design of the attacks is transformed into a quadratic multivariate optimization problem and the optimal distribution of the modified innovations is found by taking advantage of the Lagrange multiplier method . Based on this, it is proved that the optimal policy is the solution to a semi-definite programming (SDP) problem, which results in the largest estimation errors and maintains the deceptiveness concurrently. Finally, simulation examples are given to verify the effectiveness of this work.},
  archive      = {J_NEUCOM},
  author       = {Yi-Gang Li and Guang-Hong Yang},
  doi          = {10.1016/j.neucom.2022.05.085},
  journal      = {Neurocomputing},
  pages        = {461-470},
  shortjournal = {Neurocomputing},
  title        = {Optimal innovation-based deception attacks with side information against remote state estimation in cyber-physical systems},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). DISSEC: A distributed deep neural network inference
scheduling strategy for edge clusters. <em>NEUCOM</em>, <em>500</em>,
449–460. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New applications such as intelligent manufacturing, autonomous vehicles and smart cities drive large-scale deep learning models deployed in the Internet of Things (IoT) edge environments. However, deep learning models require substantial computations, storage and communication resources to run. It is generally difficult to deploy and execute a complete deep neural network (DNN) on a resource-constrained edge device. One possible solution is to slice the DNN into multiple tiles distributed to different edge devices, which can reduce the number of computations and quantity of data on each edge device. In this paper, we propose DISSEC, a distributed scheduling strategy for DNN inference on IoT edge clusters. DISSEC leverages spatial partitioning techniques through fusing the convolutional layers and dividing them into multiple partitions that can be executed independently, and proposes a method to express the dependencies between partitions. It further proposes a search algorithm based on heuristics to produce a distributed parallel strategy with the best overall inference execution latency. The evaluation shows that our strategy can fully utilize the edge device resources by cooperating with multiple edge devices to perform partitioning tasks in parallel. Furthermore, compared to the existing work scheduling strategy, our strategy reduces communication overhead by 20\% and overall execution latency by 9\% under different partitioning granularities and numbers of edge devices.},
  archive      = {J_NEUCOM},
  author       = {Qiang Li and Liang Huang and Zhao Tong and Ting-Ting Du and Jin Zhang and Sheng-Chun Wang},
  doi          = {10.1016/j.neucom.2022.05.084},
  journal      = {Neurocomputing},
  pages        = {449-460},
  shortjournal = {Neurocomputing},
  title        = {DISSEC: A distributed deep neural network inference scheduling strategy for edge clusters},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comparative study on optical flow for facial expression
analysis. <em>NEUCOM</em>, <em>500</em>, 434–448. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical flow techniques are becoming increasingly performant and robust when estimating motion in a scene, but their performance has yet to be proven in the area of facial expression recognition. In this work, a variety of optical flow approaches are evaluated across multiple facial expression datasets, so as to provide a consistent performance evaluation. The aim of this work is not to propose a new expression recognition technique, but to understand better the adequacy of existing state-of-the art optical flow for encoding facial motion in the context of facial expression recognition. Our evaluations highlight the fact that motion approximation methods used to overcome motion discontinuities have a significant impact when optical flows are used to characterize facial expressions.},
  archive      = {J_NEUCOM},
  author       = {B. Allaert and I.R. Ward and I.M. Bilasco and C. Djeraba and M. Bennamoun},
  doi          = {10.1016/j.neucom.2022.05.077},
  journal      = {Neurocomputing},
  pages        = {434-448},
  shortjournal = {Neurocomputing},
  title        = {A comparative study on optical flow for facial expression analysis},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A clustered blueprint separable convolutional neural network
with high precision for high-speed train bogie fault diagnosis.
<em>NEUCOM</em>, <em>500</em>, 422–433. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a clustering method for KMedoids based on dynamic time warping (DTW-KMedoids) is designed to analyze multi-channel signals, and a lightweight network, clustered blueprint separable convolutional neural network (CBS-CNN), is established to perform fault diagnosis of high-speed train (HST) bogie. The motivation for proposing the novel method is to address the problems of large network size and high training cost in deep learning . First, DTW-KMedoids is adopted to cluster the channels of multi-channel signals. Second, based on the principles of blueprint separable convolution (BSConv) and mixed depthwise convolution (MixConv), a lightweight convolution model construction strategy called clustered blueprint separable convolution (CBS-Conv) is proposed, which uses the same blueprint to convolute the data of the channels in a cluster. Third, CBS-CNN is established, with multiple branches to process data from different clusters, and the computational result of each branch is connected by the proposed Connect layer. Finally, by virtue of the learned features from training, the model completes the end-to-end HST bogie fault diagnosis task, where the usefulness of CBS-CNN in detecting bogie failures including component performance degradation , component failures, and composite failures is validated. Further experiments show that CBS-CNN has a remarkable ability to adapt itself to different task environments and objectives.},
  archive      = {J_NEUCOM},
  author       = {Xinming Jia and Na Qin and Deqing Huang and Yiming Zhang and Jiahao Du},
  doi          = {10.1016/j.neucom.2022.05.056},
  journal      = {Neurocomputing},
  pages        = {422-433},
  shortjournal = {Neurocomputing},
  title        = {A clustered blueprint separable convolutional neural network with high precision for high-speed train bogie fault diagnosis},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constructing multi-layer classifier ensembles using the
choquet integral based on overlap and quasi-overlap functions.
<em>NEUCOM</em>, <em>500</em>, 413–421. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensembles of classifiers have been receiving much attention lately, they consist of a collection of classifiers that process the same information and their output is combined in some manner. The combination method is probably the most important part in a ensemble of classifiers however, many works found in literature focus mostly on the classification step, using simple approaches on the combination step, such as majority voting. In this paper, we propose a new combination method based on a generalization of discrete Choquet integrals, combining it with quasi overlap functions to aggregate the outputs of classifiers in an ensemble. We also tested the proposed combination approach in a simple ensemble against other methods in literature to verify if there was a significant gain in performance.},
  archive      = {J_NEUCOM},
  author       = {Thiago Batista and Benjamín Bedregal and Ronei Moraes},
  doi          = {10.1016/j.neucom.2022.05.080},
  journal      = {Neurocomputing},
  pages        = {413-421},
  shortjournal = {Neurocomputing},
  title        = {Constructing multi-layer classifier ensembles using the choquet integral based on overlap and quasi-overlap functions},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic event-triggered security control of cyber-physical
systems against missing measurements and cyber-attacks. <em>NEUCOM</em>,
<em>500</em>, 405–412. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The security control approach is presented for cyber-physical systems (CPSs) with missing measurements and cyber-attacks based on an improved dynamic event-triggered scheme (DETS). The DETS is proposed to decrease the communication workload and reduce the effects of mutation data which may be erroneous. The sensor measurements are assumed to be lost randomly due to the unreliable network. In this paper, an observer-based controller is derived which can be tolerant towards the impacts of the missing measurements and cyber-attacks. The observer-based controller parameters and event-triggered parameter are co-designed. Finally, simulation results verify the validity of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Lijuan Zha and Rongfei Liao and Jinliang Liu and Jinde Cao and Xiangpeng Xie},
  doi          = {10.1016/j.neucom.2022.05.096},
  journal      = {Neurocomputing},
  pages        = {405-412},
  shortjournal = {Neurocomputing},
  title        = {Dynamic event-triggered security control of cyber-physical systems against missing measurements and cyber-attacks},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Balanced knowledge distillation for one-stage object
detector. <em>NEUCOM</em>, <em>500</em>, 394–404. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The latest knowledge distillation (KD) methods have successfully supervised a student model to have a better representation using intermediate layers of a teacher model. However, the previous KD methods did not obtain generalized knowledge for various object scales from a one-stage object detector because the one-stage object detector has a structural property that uses several intermediate layers to extract objects of various scales. In other words, the previous KD methods could not distill and transfer knowledge to intermediate layers of one-stage object detectors in a balanced way. Therefore, we propose a shared knowledge encoder and an averaged prototype transfer to remove or mitigate the distillation and transfer imbalances that adversely affect the KD process. Experimental results show that the proposed KD method outperforms the state-of-the-art methods. For instance, the proposed method provides about 1.3\% and 2.2\% higher accuracy than the baseline on the PASCAL VOC and MS COCO datasets, respectively.},
  archive      = {J_NEUCOM},
  author       = {Sungwook Lee and Seunghyun Lee and Byung Cheol Song},
  doi          = {10.1016/j.neucom.2022.05.087},
  journal      = {Neurocomputing},
  pages        = {394-404},
  shortjournal = {Neurocomputing},
  title        = {Balanced knowledge distillation for one-stage object detector},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adjustable super-resolution network via deep supervised
learning and progressive self-distillation. <em>NEUCOM</em>,
<em>500</em>, 379–393. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the use of convolutional neural networks , Single-Image Super-Resolution (SISR) has advanced dramatically in recent years. However, we notice a phenomenon that the structure of all these models must be consistent during training and testing. This severely limits the flexibility of the model, making the same model difficult to be deployed on different sizes of platforms (e.g., computers, smartphones, and embedded devices). Therefore, it is crucial to develop a model that can adapt to different needs without retraining. To achieve this, we propose a lightweight Adjustable Super-Resolution Network (ASRN). Specifically, ASRN consists of a series of Multi-scale Aggregation Blocks (MABs), which is a lightweight and efficient module specially designed for feature extraction. Meanwhile, the Deep Supervised Learning (DSL) strategy is introduced into the model to guarantee the performance of each sub-network and a novel Progressive Self-Distillation (PSD) strategy is proposed to further improve the intermediate results of the model. With the help of DSL and PSD strategies, ASRN can achieve elastic image reconstruction. Meanwhile, ASRN is the first elastic SISR model, which shows good results after directly changing the model size without retraining.},
  archive      = {J_NEUCOM},
  author       = {Juncheng Li and Faming Fang and Tieyong Zeng and Guixu Zhang and Xizhao Wang},
  doi          = {10.1016/j.neucom.2022.05.061},
  journal      = {Neurocomputing},
  pages        = {379-393},
  shortjournal = {Neurocomputing},
  title        = {Adjustable super-resolution network via deep supervised learning and progressive self-distillation},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy parameterized fuzzy soft k-nearest neighbor
classifier. <em>NEUCOM</em>, <em>500</em>, 351–378. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new k NN algorithm, i.e., Fuzzy Parameterized Fuzzy Soft k NN (FPFS- k NN), based on multiple pseudo-metrics of fuzzy parameterized fuzzy soft matrices ( fpfs -matrices). FPFS- k NN can consider the impacts of parameters on classification using pseudo-metrics of fpfs -matrices – a new concept. Furthermore, FPFS- k NN detects the nearest neighbors for each pseudo-metric and classifies data applying the aforementioned multiple distance functions. To demonstrate the classification success of the proposed method, we carry out an experimental study using 35 UCI datasets and comparing it with the state-of-the-art k NN-based and non- k NN-based algorithms. All the methods are trained and tested for ten runs through five-fold cross-validation. We then compare the results of FPFS- k NN with those of the others in terms of the most frequently used measures, such as accuracy (ACC), precision (PRE), recall (REC), micro F-score (MICF), and macro F-score (MACF). Afterward, we pro-vide a statistical evaluation of the results. Experimental and statistical results manifest that the proposed FPFS- k NN, utilized Pearson’s correlation coefficient and denoted by FPFS- k NN ( P ) (P) , outperforms the state-of-the-art k NN-based algorithms in 24 of 35 datasets in terms of each considered measure and 31 of 35 datasets in terms of accuracy measure. Besides, the results showed that FPFS- k NN ( P ) (P) performs better than the others for 29 datasets in terms of ACC and MICF rates, and 24 datasets in terms of PRE, REC and MACF rates. Finally, we discuss FPFS- k NN for further research.},
  archive      = {J_NEUCOM},
  author       = {S. Memiş and S. Enginoğlu and U. Erkan},
  doi          = {10.1016/j.neucom.2022.05.041},
  journal      = {Neurocomputing},
  pages        = {351-378},
  shortjournal = {Neurocomputing},
  title        = {Fuzzy parameterized fuzzy soft k-nearest neighbor classifier},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-objective berth allocation problem in fuzzy
environment. <em>NEUCOM</em>, <em>500</em>, 341–350. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Berth Allocation Problem (BAP) is an important seaside problem in port logistics, which involves the determination of berthing times and positions of arriving vessels in a wharf. Most studies have considered that vessels arrival and handling times are known fixed quantities available to wharves operators beforehand. However, due to many uncontrollable factors that can affect vessels arrival and handling times, those quantities are highly uncertain and may have a significant impact in the wharf operation. This paper takes fuzzy uncertainty into account and presents a fully fuzzy BAP with two objective functions. Specifically, it is considered the minimisation of the total waiting time of vessels and the makespan of the wharf operation. The problem is solved by using two lexicographic methods for fully fuzzy multi-objective linear programming (FFMOLP). Multiple Pareto optimal fuzzy solutions are obtained using a fuzzy epsilon-constraint method. Results demonstrate the effectiveness of the proposed approaches in handling fuzziness and conflicting objectives in a BAP. Moreover, from a methodological point of view, results show that it is best to use lexicographic ranking criteria instead of linear ranking functions for solving the associated FFMOLP problem .},
  archive      = {J_NEUCOM},
  author       = {Boris Pérez-Cañedo and José Luis Verdegay and Alejandro Rosete and Eduardo René Concepción-Morales},
  doi          = {10.1016/j.neucom.2021.08.161},
  journal      = {Neurocomputing},
  pages        = {341-350},
  shortjournal = {Neurocomputing},
  title        = {A multi-objective berth allocation problem in fuzzy environment},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A temporal fusion transformer for short-term freeway traffic
speed multistep prediction. <em>NEUCOM</em>, <em>500</em>, 329–340. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate short-term freeway speed prediction is a key component for intelligent transportation management and can help travelers plan travel routes. However, very few existing studies focus on predicting one-hour ahead or longer freeway speed. In this study, a novel architecture called Temporal Fusion Transformer (TFT) is adopted to predict freeway speed with the prediction horizons from 5 min to 150 min. The TFT can capture short-term and long-term temporal dependence by a multi-head attention mechanism. Moreover, the TFT utilizes the fusion decoder to import various types of inputs which can improve the prediction accuracy. To demonstrate the advantage of the TFT, traffic speed data collected from an interstate freeway in Minnesota are used to train and test the prediction model. The TFT prediction performance is compared with several classic traffic prediction methods, and the results reveal that the TFT performs best in speed prediction when the prediction horizon is longer than 30 min.},
  archive      = {J_NEUCOM},
  author       = {Hao Zhang and Yajie Zou and Xiaoxue Yang and Hang Yang},
  doi          = {10.1016/j.neucom.2022.05.083},
  journal      = {Neurocomputing},
  pages        = {329-340},
  shortjournal = {Neurocomputing},
  title        = {A temporal fusion transformer for short-term freeway traffic speed multistep prediction},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ZNN for time-variant nonlinear inequality systems: A
finite-time solution. <em>NEUCOM</em>, <em>500</em>, 319–328. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the solution of time-variant nonlinear inequality systems is trapped by the convergence performance of the models, this paper explores an enhanced nonlinear sign-bi-power activation function (AF) and further obtains a zeroing neural network (ZNN) model for solving time-variant nonlinear inequality systems, which is called nonlinear activated finite-time convergent zeroing neural network (NAFTCZNN). The strict theoretical analysis together with two theorems are given to demonstrate the enhanced convergence performance of the NAFTCZNN model. Furthermore, the stability and upper bound of convergent time of the NAFTCZNN model are analyzed and estimated in the theorems, which is more stable and less conservative than the ZNN models using the common sign-bi-power AFs. Numerical example results further validate the effectiveness and excellence of the NAFTCZNN model in terms of solving the time-variant nonlinear inequality systems.},
  archive      = {J_NEUCOM},
  author       = {Lin Xiao and Wentong Song and Lei Jia and Xiaopeng Li},
  doi          = {10.1016/j.neucom.2022.05.067},
  journal      = {Neurocomputing},
  pages        = {319-328},
  shortjournal = {Neurocomputing},
  title        = {ZNN for time-variant nonlinear inequality systems: A finite-time solution},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Blind image quality assessment based on progressive
multi-task learning. <em>NEUCOM</em>, <em>500</em>, 307–318. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the lack of adequate training data and sufficient mining of prior knowledge related to perceived quality, most existing image quality assessment (IQA) methods show limited generalization performance . In this paper, we study the prior knowledge from the factors affecting perceived quality, and introduce a novel progressive multi-task learning based blind IQA method. Inspired by the definition of IQA: human comprehensive perception for degradation of image content, we firstly deconstruct IQA into three elements, i.e., image content, pattern of degradation, and intensity of degradation. Based on these elements, we design the corresponding auxiliary tasks for instructing the network to learn IQA. By statistical analysis on a great deal of data, we find that there is progressive relevance among the four tasks. Furthermore, we mathematically derive that introducing the progressive relevance into a multi-task learning network can effectively constrain the hypothesis space of the main task. Under the guidance of the derivation, we propose an end-to-end IQA framework based on progressive multi-task learning. Experimental results demonstrate the excellent generalization capability of the proposed method, which achieves state-of-the-art performance against these existing IQA methods.},
  archive      = {J_NEUCOM},
  author       = {Aobo Li and Jinjian Wu and Shiwei Tian and Leida Li and Weisheng Dong and Guangming Shi},
  doi          = {10.1016/j.neucom.2022.05.043},
  journal      = {Neurocomputing},
  pages        = {307-318},
  shortjournal = {Neurocomputing},
  title        = {Blind image quality assessment based on progressive multi-task learning},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SybilHunter: Hybrid graph-based sybil detection by
aggregating user behaviors. <em>NEUCOM</em>, <em>500</em>, 295–306. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, online social networks (OSNs) support users in sharing their information and providing valuable data for various applications, e.g., rating and recommendation systems, search engine systems, etc. In such online social network-based applications, information quality is essential. However, the easy-to-use interactive user interfaces and free publication mechanisms facilitate malicious users to launch Sybil Attacks . They create fake identities, pollute user-generated content, and cause server information quality problems , such as buzz, rumor, spam , etc. Most existing graph-based sybil detection approaches only consider the static graph structure features and heavily rely on the prior knowledge of labeled nodes. “Limited-attack-edge” assumption, the critical assumption of these approaches has been proved invalid in many scenarios. In this paper, we propose SybilHunter, a hybrid graph-based sybil detection approach by aggregating user social behavior patterns. Our approach refines the OSN structure, quantifies nodes’ similarity according to the dynamic user behavior features to evaluate user pairs’ trustworthiness and consistency. Then it constructs a weighted-strong-social (WSS) graph, based on which SybilHunter outputs sybil nodes. We simulate and evaluate our approach under a Weibo dataset. The AUC of SybilHunter achieves 0.945, which is significantly higher than typical graph-based sybil detection methods, such as SybilRank, SybilWalk, etc.},
  archive      = {J_NEUCOM},
  author       = {Jian Mao and Xiang Li and Xiling Luo and Qixiao Lin},
  doi          = {10.1016/j.neucom.2021.07.106},
  journal      = {Neurocomputing},
  pages        = {295-306},
  shortjournal = {Neurocomputing},
  title        = {SybilHunter: Hybrid graph-based sybil detection by aggregating user behaviors},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A study of growth based morphological development in neural
network controlled walkers. <em>NEUCOM</em>, <em>500</em>, 279–294. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In nature, the physical development of the body that takes place in parallel to the cognitive development of the individual has been shown to facilitate learning. This opens up the question of whether the same principles could be applied to robots in order to accelerate the learning of controllers and, if so, how to apply them effectively. In this line, several authors have run experiments, usually quite complex and heterogeneous, with different levels of success. In some cases, morphological development seemed to provide an advantage and in others it was clearly irrelevant or even detrimental. Basically, morphological development seems to provide an advantage only under some specific conditions, which cannot be identified before running an experiment. This is due the fact that there is still no agreement on the underlying mechanisms that lead to success or on how to design morphological development processes for specific problems. In this paper, we address this issue through the execution of different experiments over a simple, replicable, and straightforward experimental setup that makes use of different neural network controlled walkers together with a morphological development strategy based on growth. The morphological development processes in these experiments are analyzed both in terms of the results obtained by the different walkers and in terms of how their fitness landscapes change as the morphologies develop. By comparing experiments where morphological development improves learning and where it does not, a series of initial insights have been extracted on how to design morphological development processes.},
  archive      = {J_NEUCOM},
  author       = {M. Naya-Varela and A. Faina and A. Mallo and R.J. Duro},
  doi          = {10.1016/j.neucom.2021.09.082},
  journal      = {Neurocomputing},
  pages        = {279-294},
  shortjournal = {Neurocomputing},
  title        = {A study of growth based morphological development in neural network controlled walkers},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new big data triclustering approach for extracting
three-dimensional patterns in precision agriculture. <em>NEUCOM</em>,
<em>500</em>, 268–278. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision agriculture focuses on the development of site-specific harvest considering the variability of each crop area. Vegetation indices allow the study and delineation of different characteristics of each field zone, generally invisible to the naked-eye. This paper introduces a new big data triclustering approach based on evolutionary algorithms . The algorithm shows its capability to discover three-dimensional patterns on the basis of vegetation indices from vine crops. Different vegetation indices have been tested to find different patterns in the crops. The results reported using a vineyard crop located in Portugal depicts four areas with different moisture stress particularities that can lead to changes in the management of the vineyard. Furthermore, scalability studies have been performed, showing that the proposed algorithm is suitable for dealing with big datasets.},
  archive      = {J_NEUCOM},
  author       = {Laura Melgar-García and David Gutiérrez-Avilés and Maria Teresa Godinho and Rita Espada and Isabel Sofia Brito and Francisco Martínez-Álvarez and Alicia Troncoso and Cristina Rubio-Escudero},
  doi          = {10.1016/j.neucom.2021.06.101},
  journal      = {Neurocomputing},
  pages        = {268-278},
  shortjournal = {Neurocomputing},
  title        = {A new big data triclustering approach for extracting three-dimensional patterns in precision agriculture},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Fast multiplicative algorithms for symmetric nonnegative
tensor factorization. <em>NEUCOM</em>, <em>500</em>, 255–267. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symmetric nonnegative tensor factorization (SNTF) is an important tool for clustering analysis . To date, most of algorithms for SNTF are based on multiplicative update rules, which have many attractive properties, e.g., they are often simple to implement and can enforce nonnegativity without extra projection steps. However, the existing multiplicative algorithms often converge slowly due to the conservative multiplicative learning steps or the use of low-level BLAS (basic linear algebra subprograms) in their implementation. In this paper, three new multiplicative algorithms are proposed for SNTF to overcome the drawback of slow convergence. First, a parallel multiplicative algorithm, which can be implemented with high-level BLAS, is derived by auxiliary optimization. To further accelerate the convergence, two new parallel multiplicative algorithms, which enable larger learning steps for improving efficiency, are developed based on weighted geometric mean and weighted arithmetic mean, respectively. Finally, we apply the proposed algorithms to multiway probabilistic clustering, where a new hyper-stochastic normalization scheme based on Euclidean distance is developed for better data preprocessing . The experiment results on both synthetic and real-world data show that the proposed SNTF algorithms converge faster than the state-of-the-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Peitao Wang and Zhaoshui He and Rong Yu and Beihai Tan and Shengli Xie and Ji Tan},
  doi          = {10.1016/j.neucom.2022.05.046},
  journal      = {Neurocomputing},
  pages        = {255-267},
  shortjournal = {Neurocomputing},
  title        = {Fast multiplicative algorithms for symmetric nonnegative tensor factorization},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fully automatic MRI brain tumor segmentation using efficient
spatial attention convolutional networks with composite loss.
<em>NEUCOM</em>, <em>500</em>, 243–254. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically segmenting tumors from brain magnetic resonance imaging scans is crucial for diagnosis and planning treatment. However, brain tumors are highly diverse in location, contrast, size, and shape, making automatic segmentation extremely challenging. Recent techniques for segmenting brain tumors are mostly built using convolutional neural networks (CNNs). However, most of these existing techniques are inefficient, having slow inference speed and high parameter count. To reduce the diagnostic time, we present an accurate and efficient CNN model having fast inference speed and low parameter count for fully automatic brain tumor segmentation. Our novel CNN, the efficient spatial attention network (ESA-Net), is an improved variant of the popular U-Net. ESA-Net was built using our proposed efficient spatial attention (ESA) blocks containing depthwise separable convolution layers and a lightweight spatial attention module. The ESA blocks significantly improve both efficiency and segmentation accuracy . We also proposed a new composite loss function by combining Dice, focal, and Hausdorff distance (HD) losses to significantly improve the segmentation accuracy by tackling extreme class imbalance and directly optimizing the Dice score and HD. The effectiveness of the proposed network and loss function was evaluated by performing extensive experiments on the BraTS 2021 benchmark dataset. ESA-Net significantly outperformed U-Net in segmentation accuracy while having four times faster inference speed and eight times fewer parameters. In addition, the composite loss outperformed other loss functions. The proposed model achieved significantly better segmentation accuracy than other efficient models while having faster inference speed and fewer parameters. Moreover, it obtained competitive segmentation accuracy against state-of-the-art models. The proposed system segments a patient’s brain in 2.7 s using a GPU and has 157 times faster inference speed and 177 times fewer parameters than other state-of-the-art systems.},
  archive      = {J_NEUCOM},
  author       = {Indrajit Mazumdar and Jayanta Mukherjee},
  doi          = {10.1016/j.neucom.2022.05.050},
  journal      = {Neurocomputing},
  pages        = {243-254},
  shortjournal = {Neurocomputing},
  title        = {Fully automatic MRI brain tumor segmentation using efficient spatial attention convolutional networks with composite loss},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Special issue on “learning to combat online
hostile posts in regional languages during emergency situations.”
<em>NEUCOM</em>, <em>500</em>, 241–242. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current special issue of Neurocomputing was designed to encourage researchers from interdisciplinary domains working on multilingual social media analytics to think beyond the conventional way of combating online hostile posts. The special issue was primarily based on the theme of the First Workshop on Combating Online Hostile Posts in Regional Languages during Emergency Situation (CONSTRAINT) ( https://lcs2.iiitd.edu.in/CONSTRAINT-2021/ ), held with AAAI&#39;2021. We invited a few good quality papers accepted in CONSTRAINT to submit an extended version. We also made the call open for the general audience. The special issue broadly focused on three major points: (i) Regional language: the offensive posts under inspection may be written in low-resource regional languages (e.g., Tamil, Urdu, Bangali, Polish, Czech, Lithuanian, etc.). (ii) Emergency situation: The proposed solutions should be able to tackle misinformation during emergency situations where, due to the lack of enough historical data, learning models need to adopt additional intelligence to handle emerging and novel posts. (iii) Early detection: Since the impact of misinformation during emergency situations is highly detrimental to the society (e.g., health-related misadvice during a pandemic can cost human lives), we encourage the solutions to be able to detect such hostile posts as early as possible after their appearance on social media.},
  archive      = {J_NEUCOM},
  author       = {Tanmoy Chakraborty and Kai Shu and H. Russell Bernard and Huan Liu},
  doi          = {10.1016/j.neucom.2022.05.037},
  journal      = {Neurocomputing},
  pages        = {241-242},
  shortjournal = {Neurocomputing},
  title        = {Editorial: Special issue on “Learning to combat online hostile posts in regional languages during emergency situations”},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards effective detection of elderly falls with CNN-LSTM
neural networks. <em>NEUCOM</em>, <em>500</em>, 231–240. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fall detection is a very challenging task that has a clear impact in the autonomous living of the elderly individuals: suffering a fall with no support increases the fears of the elderly population to continue living by themselves. This study proposes the use of a non-invasive tri-axial accelerometer device placed on a wrist to measure the movements of the participant. The novelty of this study is two fold: on the one hand, the use of a Long-Short Term Memory Neural Network (LSTM) for classification of the Time Series and, on the other hand, the proposal of a novel data augmentation stage that introduces variability in the training by merging the Time Series gathered from both human activities of daily living. The experimentation shows that the combination of a LSTM model together with the data augmentation produces more robust and accurate models that perfectly cope with the validation stage; the high impact fall event detection can be considered solved.},
  archive      = {J_NEUCOM},
  author       = {Enol García and Mario Villar and Mirko Fáñez and José R. Villar and Enrique de la Cal and Sung-Bae Cho},
  doi          = {10.1016/j.neucom.2021.06.102},
  journal      = {Neurocomputing},
  pages        = {231-240},
  shortjournal = {Neurocomputing},
  title        = {Towards effective detection of elderly falls with CNN-LSTM neural networks},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic clustering and modeling of temporal data subject to
common regressive effects. <em>NEUCOM</em>, <em>500</em>, 217–230. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is used in many applicative fields to organize data into a few groups. Motivated by behavioral extraction issues from urban data, this paper proposes a new clustering method to model clusters with dynamic profiles while considering common regressive effects. As maximum likelihood estimation is not suitable in this case, the parameters of the proposed model were estimated using variational approximation. The ability of the model to estimate parameters was evaluated using various simulated data and compared with two other models. The article also proposes an application of this model to the extraction of occupant behavior in buildings using a real open source indoor temperature database. The objective is to classify individual houses according to indoor temperature while estimating the effect of meteorological variables and class profiles that can be interpreted as occupancy behaviors .},
  archive      = {J_NEUCOM},
  author       = {Louise Bonfils and Allou Samé and Latifa Oukhellou},
  doi          = {10.1016/j.neucom.2022.05.038},
  journal      = {Neurocomputing},
  pages        = {217-230},
  shortjournal = {Neurocomputing},
  title        = {Dynamic clustering and modeling of temporal data subject to common regressive effects},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view unsupervised dimensionality reduction with
probabilistic neighbors. <em>NEUCOM</em>, <em>500</em>, 203–216. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view Unsupervised Dimensionality Reduction (MUDR) aims to find an optimal low-dimensional subspace to the original unlabeled high-dimensional multi-view data. Different views of multi-view data describe specific aspects that are independent or complementary with each other. How to make full use of the information from multiple views remains an open issue, especially in the absence of labels. In this study, we propose a novel model referred to as Multi-view unsupervised Dimensionality reduction with Probabilistic Neighbors (MDPN). It learns a multi-view consensus similarity matrix by adaptively weighing each view and properly assigning optimal neighbors for each sample. The consensus matrix has probability attributes and it encodes the probability of sample pairs to become neighbors. During the procedure, a projection matrix and the consensus matrix negotiate with each other to find the optimal subspace that preserves the structure/invariances of the original data. The projection matrix best serves dimensionality reduction. Moreover, considering the imbalance of dimensionality in multiple views, we extend this model to achieve flexible MUDR by projecting data from different views into subspaces of various dimensions. Two two-step iterative algorithms are developed to efficiently optimize the resultant objective problems. Extensive experimental results on synthetic and benchmark datasets demonstrate the superiorities of our models.},
  archive      = {J_NEUCOM},
  author       = {Qianyao Qiang and Bin Zhang and Fei Wang and Feiping Nie},
  doi          = {10.1016/j.neucom.2022.05.040},
  journal      = {Neurocomputing},
  pages        = {203-216},
  shortjournal = {Neurocomputing},
  title        = {Multi-view unsupervised dimensionality reduction with probabilistic neighbors},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mining local geometric structure for large-scale 3D point
clouds semantic segmentation. <em>NEUCOM</em>, <em>500</em>, 191–202.
(<a href="https://doi.org/10.1016/j.neucom.2022.05.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we concentrate on how to preserve fine-grained geometric structure information when extracting local contextual features for efficient large-scale point clouds semantic segmentation . Firstly, the Local Geometric Structure Representation Block is proposed to model fine-grained geometric structures for individual points by fully utilizing relative and global geometric relationships in the neighborhood. Then, we design a Parallel Attentive Fusion Module focusing on geometric structure and semantic information respectively, which reduces the feature’s ambiguity and preserves local geometric structure information. Furthermore, thanks to these two modules, we present a lightweight Local Contextual Features Extractor through the bilateral structure to obtain more discriminate local contextual features. Finally, a deep network named LGS-Net is introduced to predict point’s classes. Extensive experiment shows that our network surpasses the state-of-the-art approaches for semantic segmentation on two public large-scale point clouds datasets Semantic3D, SensatUrban, and achieve competitive performance on S3DIS. Especially, our LGS-Net with minimal model size outperforms the state-of-the-art network by 1.2\%\% on the Semantic3D dataset. Thorough ablation studies and visualizations are presented to understand our network.},
  archive      = {J_NEUCOM},
  author       = {Yuyuan Shao and Guofeng Tong and Hao Peng},
  doi          = {10.1016/j.neucom.2022.05.060},
  journal      = {Neurocomputing},
  pages        = {191-202},
  shortjournal = {Neurocomputing},
  title        = {Mining local geometric structure for large-scale 3D point clouds semantic segmentation},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ω-net: Dual supervised medical image segmentation with
multi-dimensional self-attention and diversely-connected multi-scale
convolution. <em>NEUCOM</em>, <em>500</em>, 177–190. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although U-Net and its variants have achieved some great successes in medical image segmentation tasks , their segmentation performances for small objects are still unsatisfactory. Therefore, in this work, a new deep model, ω ω -Net, is proposed to achieve more accurate medical image segmentations. The advancements of ω ω -Net are mainly threefold: First, it incorporates an additional expansive path into U-Net to import an extra supervision signal and obtain a more effective and robust image segmentation by dual supervision. Then, a multi-dimensional self-attention mechanism is further developed to highlight salient features and suppress irrelevant ones consecutively in both spatial and channel dimensions. Finally, to reduce semantic disparity between the feature maps of the contracting and expansive paths, we further propose to integrate diversely-connected multi-scale convolution blocks into the skip connections, where several multi-scale convolutional operations are connected in both series and parallel. Extensive experimental results on three abdominal CT segmentation tasks show that (i) ω ω -Net greatly outperforms the state-of-the-art image segmentation methods in medical image segmentation tasks; (ii) the proposed three advancements are all effective and essential for ω ω -Net to achieve the superior performances; and (iii) the proposed multi-dimensional self-attention (resp., diversely-connected multi-scale convolution) is more effective than the state-of-the-art attention mechanisms (resp., multi-scale solutions) for medical image segmentations. The code will be released online after this paper is formally accepted.},
  archive      = {J_NEUCOM},
  author       = {Zhenghua Xu and Shijie Liu and Di Yuan and Lei Wang and Junyang Chen and Thomas Lukasiewicz and Zhigang Fu and Rui Zhang},
  doi          = {10.1016/j.neucom.2022.05.053},
  journal      = {Neurocomputing},
  pages        = {177-190},
  shortjournal = {Neurocomputing},
  title        = {ω-net: Dual supervised medical image segmentation with multi-dimensional self-attention and diversely-connected multi-scale convolution},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CleanTS: Automated (AutoML) tool to clean univariate time
series at microscales. <em>NEUCOM</em>, <em>500</em>, 155–176. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data cleaning is one of the most important tasks in data analysis processes. One of the perennial challenges in data analytics is the detection and handling of non-valid data. Failing to do so can result in creating imbalanced observations that can cause bias and influence estimates, and in extreme cases, can even lead to inaccurate analytics and unreliable decisions. Usually, the process of data cleaning is time-consuming due to its growing volume, velocity, and variety. Further, the complexity and difficulty of the cleaning process increase with the amount of data to be analyzed. It is rarely the case that any real-world data is clean and error-free. Thus, pre-processing the data before using it for analysis has become standard practice. This paper is intended to provide an easy-to-use and reliable system which automates the cleaning process for univariate time series data. Also, automating the process reduces the time required for cleaning it. Another issue that the proposed system aims to solve is making the visualization of a large amount of data more effective. To tackle these issues, an R package, cleanTS is proposed. The proposed system provides a way to analyze data on different scales and resolutions. Also, it provides users with tools and a benchmark system for comparing various techniques used in data cleaning.},
  archive      = {J_NEUCOM},
  author       = {Mayur Kishor Shende and Andrés E. Feijóo-Lorenzo and Neeraj Dhanraj Bokde},
  doi          = {10.1016/j.neucom.2022.05.057},
  journal      = {Neurocomputing},
  pages        = {155-176},
  shortjournal = {Neurocomputing},
  title        = {CleanTS: Automated (AutoML) tool to clean univariate time series at microscales},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Information-aware attention dynamic synergetic network for
multivariate time series long-term forecasting. <em>NEUCOM</em>,
<em>500</em>, 143–154. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting is widely used in a variety of fields, such as cyber-physical systems and financial market analysis. Recently, attention-based recurrent neural networks (RNNs) have been paid attention by scholars for its ability to reduce the accumulative errors. Although attention-based RNNs are proved effective, there are still some challenges: 1) the noise in raw data will hurt model performance, 2) the traditional attentions are easy to discard low-weight input vectors, thereby leading to poor accuracy, and 3) encoder-focused attentions are not conducive to maintaining the trend consistency between the prediction and the original sequence. To tackle these problems, we propose a novel Information-aware Attention Dynamic Synergy Network (IADSN), which contains a specially designed information-aware long short-term memory network (IALSTM), a multi-dimensional attention (MA) that fine-grainedly assigns weight to your attention, and an attention dynamic synergy strategy. The novelty of MA lies in assigning a weight vector to the input instead of a single scalar. Therefore, it can identify the importance of each dimension of the input vector, thus alleviating the problem of ignoring low-weight inputs. IALSTM employs internal MA and a gated fusion unit to weaken the influence of input untrusted features on prediction. The attention dynamic synergy strategy maintains the similarity between the predicted and the original series by establishing an association among the current decoder unit, the previous decoder units, and the encoder. Experiments on three fields of energy, air quality, and ecological datasets demonstrate that IADSN not only achieves the state-of-the-art performance, but also effectively maintains the dynamic tendency of the forecast series.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyu He and Suixiang Shi and Xiulin Geng and Lingyu Xu},
  doi          = {10.1016/j.neucom.2022.04.124},
  journal      = {Neurocomputing},
  pages        = {143-154},
  shortjournal = {Neurocomputing},
  title        = {Information-aware attention dynamic synergetic network for multivariate time series long-term forecasting},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leveraging transferability and improved beam search in
textual adversarial attacks. <em>NEUCOM</em>, <em>500</em>, 135–142. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks in NLP are difficult to ward off because of the discrete and highly abstract nature of human languages. Prior works utilize different word replacement strategies to generate semantic-preserving adversarial texts. These query-based methods, however, have limited exploration of the search space. To fully explore the search space, an improved beam search with multiple random perturbing positions is used. Besides, we use the transferable vulnerability from surrogate models to choose vulnerable candidate words for target models. We empirically show that beam search with multiple random attacking positions works better than the commonly used greedy search with word importance ranking. Extensive experiments on three popular datasets demonstrate that our method can outperform three advanced attacking methods under black-box settings. We provide ablation studies to clearly show the effectiveness of our improved beam search which can achieve a higher success rate than the greedy approach under the same query budget.},
  archive      = {J_NEUCOM},
  author       = {Bin Zhu and Zhaoquan Gu and Yaguan Qian and Francis Lau and Zhihong Tian},
  doi          = {10.1016/j.neucom.2022.05.054},
  journal      = {Neurocomputing},
  pages        = {135-142},
  shortjournal = {Neurocomputing},
  title        = {Leveraging transferability and improved beam search in textual adversarial attacks},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph convolutional network with multiple weight mechanisms
for aspect-based sentiment analysis. <em>NEUCOM</em>, <em>500</em>,
124–134. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) aims at determining the sentiment polarity of the given aspect term in a sentence. Recently, graph convolution network (GCN) has been used in the ABSA task and obtained promising results. Despite the proliferation of the methods and their success, prevailing models based on GCN lack a powerful constraint mechanism for the message passing to aspect terms, introducing heavy noise during graph convolution. Further, they simply average the subword vectors from BERT to form word-level embeddings, failing to fully exploit the potentials of BERT. To overcome these downsides, a graph convolutional network with multiple weight mechanisms is proposed for aspect-based sentiment analysis in the paper. Specifically, a dynamic weight alignment mechanism is proposed to encourage our model to make full use of BERT. Then an aspect-aware weight mechanism is designed to control message propagation to aspect during graph convolution operation. Afterwards, an aspect-oriented loading layer is presented to further reduce adverse effects of words irrelevant with aspect term. Finally, the multi-head self attention is used to fuse high order semantic and syntax information. Hence, the model can obtain the premium aspect-specific representations for prediction. Experiments demonstrate that the proposed model can achieve state-of-the-art results compared to other models.},
  archive      = {J_NEUCOM},
  author       = {Ziguo Zhao and Mingwei Tang and Wei Tang and Chunhao Wang and Xiaoliang Chen},
  doi          = {10.1016/j.neucom.2022.05.045},
  journal      = {Neurocomputing},
  pages        = {124-134},
  shortjournal = {Neurocomputing},
  title        = {Graph convolutional network with multiple weight mechanisms for aspect-based sentiment analysis},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Full transformer network with masking future for word-level
sign language recognition. <em>NEUCOM</em>, <em>500</em>, 115–123. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Word-level sign language recognition (SLR) is a significant task which transcribes a sign language video into a word. Currently, deep-learning-based frameworks mostly combine spatial feature extractors based on convolution neural networks (CNNs) and sequence learners. These methods either lack the sufficient capacity to establish the high-level vision semantic knowledge and incorporate the details in images or perform weak intelligence on video frame sequence comprehension. Focusing on gestures and facial expressions is essential to interpreting sign language; however, it is challenging to crop these elements from pictures and distill them end-to-end. In this paper, a full self-attention framework for word-level SLR is proposed to tackle the above issue, which integrates a Vision Transformer as spatial encoder and an improved temporal Transformer. In addition, we introduce the masking future operation to improve the Transformer for the temporal module. The vision Transformer first refines the latent high-level semantic feature sequences from sign language videos and feeds them into the temporal module. Then the masking future Transformer enhances this sequence by making subsequent time invisible at each moment of frames and generates the final recognition. This approach integrates global and local spatial information; furthermore, it can also distinguish the latent semantic features contained in sign language action sequences. To validate the proposed approach, we perform extensive experiments on two datasets. The results and ablation studies demonstrate the effectiveness of this method, and it achieves new state-of-the-art performance on the WLASL dataset by using RGB images alone.},
  archive      = {J_NEUCOM},
  author       = {Yao Du and Pan Xie and Mingye Wang and Xiaohui Hu and Zheng Zhao and Jiaqi Liu},
  doi          = {10.1016/j.neucom.2022.05.051},
  journal      = {Neurocomputing},
  pages        = {115-123},
  shortjournal = {Neurocomputing},
  title        = {Full transformer network with masking future for word-level sign language recognition},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Manhattan-distance IOU loss for fast and accurate bounding
box regression and object detection. <em>NEUCOM</em>, <em>500</em>,
99–114. (<a href="https://doi.org/10.1016/j.neucom.2022.05.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bounding box regression is a crucial step in most object detection algorithms , and directly affects the positioning accuracy and regression speed of convolutional neural networks (CNN). The existing loss functions commonly used in bounding box regression suffer two main disadvantages: firstly , the l n ln -norm loss does not match the evaluation metric Intersection over Union (IOU), leading to poor regression performance. Second, some recently proposed IOU-based loss functions are beneficial to IOU metric, but the negative effects of some terms in these loss functions on bounding box regression lead to slow convergence and inaccurate regression results. To solve these shortcomings, we proposed a Manhattan-Distance IOU (MIOU) loss function here. It takes into account that the Euclidean distance term in the Complete IOU (CIOU) loss and the Efficient IOU (EIOU) loss is unstable in training due to the huge gradient in the early stage of regression, and the Manhattan distance is added to effectively alleviate this defect. In addition, the denominator of the Euclidean distance term in the two loss functions discussed above has an antagonistic effect on loss reduction, and setting it as a normalized coefficient without participating in backpropagation can effectively improve the convergence speed. The effectiveness of the proposed MIOU loss was verified with designed simulation experiments. Moreover, object detection is usually applied to natural scenes and remote sensing scenes, but the application of detection methods are often limited due to varied image characteristics in different scene settings. We incorporated the MIOU loss into YOLO v4 and other mainstream object detection networks to examine its effectiveness in remote sensing and natural object detection scenarios. The experimental results on real remote sensing datasets DOTA and natural datasets MS COCO demonstrate that the MIOU loss has strong robustness in both remote sensing object detection tasks and natural object detection tasks. In summary, as a general regression loss function, the MIOU loss shows excellent performance in the above two types of scenes.},
  archive      = {J_NEUCOM},
  author       = {Yanyun Shen and Feizhao Zhang and Di Liu and Weihua Pu and Qingling Zhang},
  doi          = {10.1016/j.neucom.2022.05.052},
  journal      = {Neurocomputing},
  pages        = {99-114},
  shortjournal = {Neurocomputing},
  title        = {Manhattan-distance IOU loss for fast and accurate bounding box regression and object detection},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AAC: Automatic augmentation for crowd counting.
<em>NEUCOM</em>, <em>500</em>, 90–98. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent crowd management is important for city monitoring. In the task of crowd counting, insufficient training samples with labels are great challenges. In order to improve the performance of the counting model, data augmentation is an effective method. This paper proposes an automatic augmentation framework for counting (AAC) based on the deep reinforcement learning . We first pre-train the model and iteratively generate a data augmentation strategy based on the Deep Deterministic Policy Gradient (DDPG) algorithm on the divided validation dataset . When the optimal augmentation action for the model on a specific dataset is found, the model is fine-tuned by the augmented dataset. At the same time, we release a large-scale crowd counting dataset HaCrowd describing Hajj scenario. Finally, five typical crowd counting models are used to carry out augmentation experiments on four small datasets including HaCrowd. The experimental results show that AAC method can be used to generate flexible augmentation strategy for counting model aimed for specific datasets. With the augmentation dataset to train model, it can further improve the performance of counting model. The download link of the HaCrowd is (https://github.com/KAU-Smart-Crowd/HaCrowd).},
  archive      = {J_NEUCOM},
  author       = {Rui Wang and Reem Alotaibi and Bander Alzahrani and Arif Mahmood and Gaoxiang Wu and Han Xia and Abeer Alshehri and Sahar Aldhaheri},
  doi          = {10.1016/j.neucom.2022.04.100},
  journal      = {Neurocomputing},
  pages        = {90-98},
  shortjournal = {Neurocomputing},
  title        = {AAC: Automatic augmentation for crowd counting},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel tongue segmentation method based on improved u-net.
<em>NEUCOM</em>, <em>500</em>, 73–89. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of tongue image is a prerequisite to intelligent tongue diagnosis. Current tongue segmentation algorithms have good performances in tongue image segmentation in a standard environment. However, tongue segmentation is still challenging to be used in an open environment due to factors such as the complex external open environment and relatively simple equipment. This study aims to construct a novel deep neural network tongue segmentation system suitable for mobile devices, which performs tongue segmentation rapidly in an open environment. Firstly, a new OET-NET is constructed based on U-Net combined with a residual soft connection module and salient image fusion module to train the tongue image from a different device. Secondly, a new loss function is established based on the Focal loss. Finally, the number of network parameters, the inferred time are treated as indicators to evaluate the model. At the same time, MIoU, precision, recall, F1-Score and FLOPs are used to compare with different tongue segmentation frameworks. According to the training results, the proposed OET-NET’s parameter number is 7.75 MB, the required time of tongue segmentation is about 59 ms/piece, the MIoU is 96.98\% and the FLOPs is 15.50 MFLOPs. Compared with U-Net, OET-NET increased the total number of parameters by 0.39 MB and the inference time by 1 ms/piece, but achieved the best segmentation effect compared with the reference models. According to less time consumption and less space, the precision of segmentation results is higher than that of other segmentation models. OET-NET can quickly and accurately extract tongue bodies from the open environment, and its relatively smaller number of model parameters made it suitable for mobile devices. It is potential for OET-NET to be applied to tongue image segmentation on mobile terminals.},
  archive      = {J_NEUCOM},
  author       = {Zonghai Huang and Jiaqing Miao and Haibei Song and Simin Yang and Yanmei Zhong and Qiang Xu and Ying Tan and Chuanbiao Wen and Jinhong Guo},
  doi          = {10.1016/j.neucom.2022.05.023},
  journal      = {Neurocomputing},
  pages        = {73-89},
  shortjournal = {Neurocomputing},
  title        = {A novel tongue segmentation method based on improved U-net},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Medical image segmentation using scalable functional
variational bayesian neural networks with gaussian processes.
<em>NEUCOM</em>, <em>500</em>, 58–72. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian neural networks (BNNs) are widely used in medical image segmentation tasks because they provide a probabilistic view of deep learning models by placing a prior distribution over the model parameters, and allow the representation of uncertainties through posterior distribution over the model parameters. However, it is difficult to choose meaningful prior distributions and fit accurate posterior distributions in a high-dimensional weight space, which limit the practical effectiveness of BNNs. In this study, we propose a scalable functional variational BNN with Gaussian processes (GPs) for the purpose of medical image segmentation. Specifically, we regard the prior and variational posterior distributions as GPs, and perform variational inference in function space. We employ a variant of the functional evidence lower bound (fELBO) with a β -weight on the Kullback–Leibler divergence term as the loss objective, and design a content-aware UNet segmentation network , which utilizes content-aware reassembly of features (CARAFE) as an upsampling operator to extract semantic information from input feature maps . The proposed BNN framework enables efficient training and can perform predictive inference with one forward pass. Extensive experiments are conducted on four segmentation datasets; the experimental results demonstrate that the proposed approach improves the segmentation performance metrics and uncertainty estimates compared with several state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xu Chen and Yue Zhao and Chuancai Liu},
  doi          = {10.1016/j.neucom.2022.05.055},
  journal      = {Neurocomputing},
  pages        = {58-72},
  shortjournal = {Neurocomputing},
  title        = {Medical image segmentation using scalable functional variational bayesian neural networks with gaussian processes},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Discriminative transfer feature learning based on
robust-centers. <em>NEUCOM</em>, <em>500</em>, 39–57. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most feature-based Unsupervised Domain Adaptation (UDA) methods aligned distributions of the source and target domains by minimizing Maximum Mean Discrepancy (MMD) between the two domains. However, MMD using mean values may misalign distributions of the two domains due to outliers. Besides, to enhance the identifiability of learned features, some feature-based UDA methods adopted samples-based distances to measure the intra-class compactness and inter-class separability. But, the number of samples-based distances is a quadratic function of the sample size, feature-based UDA methods using samples-based distances may lead to the inefficient computation of measuring the intra-class compactness and inter-class separability. To overcome the two problems, we propose Discriminative Transfer Feature Learning based on Robust-Centers (DTFLRC) for UDA. First, we design robust-class-centers and robust-domain-centers for decreasing the influence of outliers and establish MMD with robust-centers to align distributions of the two domains. Second, noticing that the number of centers is far smaller than the sample size, we construct three robust-centers-based distances to effectively reduce the number of distances in measuring the intra-class compactness and inter-class separability. Specifically, three robust-centers-based distances include Sample-Class-center , Class-center-Domain-center , and Class-center-Nearest-neighbor-class-center distances, where Sample-Class-center distance measures the intra-class compactness, and Class-center-Domain-center and Class-center-Nearest-neighbor-class-center distances jointly reflect the inter-class separability. Then, the optimization objective of DTFLRC is established to minimize the MMD with robust-centers and Sample-Class-center distance, and maximize Class-center-Domain-center and Class-center-Nearest-neighbor-class-center distances. Finally, experimental results demonstrate that DTFLRC outperforms state-of-the-art methods, where the accuracies of DTFLRC on datasets CMU-PIE, Office-Caltech, ImageCLEF-DA, and VisDA-2017 are 81.8\%, 94.6\%, 90.2\%, and 80.5\%.},
  archive      = {J_NEUCOM},
  author       = {Lei Li and Jun Yang and Xuefeng Kong and Yulin Ma},
  doi          = {10.1016/j.neucom.2022.05.042},
  journal      = {Neurocomputing},
  pages        = {39-57},
  shortjournal = {Neurocomputing},
  title        = {Discriminative transfer feature learning based on robust-centers},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). An information theoretic approach to reducing algorithmic
bias for machine learning. <em>NEUCOM</em>, <em>500</em>, 26–38. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algorithmic bias indicates the discrimination caused by algorithms, which occurs with protected features such as gender and race. Many researchers have tried to define the fairness and devise methods to mitigate bias, but it is still premature to reach the unanimous definition and evaluation metrics of fairness according to society, times and cultures. In this paper, we introduce three evaluation metrics such as parity difference, equalized opportunity and equalized odds that can deal with various definitions of algorithmic bias, and concretely divide the three general approaches further into seven methods with some challenges, resulting in relabeling, generation, fair representation (for pre-processing), constraint optimization , regularization (for in-processing), calibration and thresholding (for post-processing). Among them, the pre-processing method is widely used due to its versatility, but it has limitation to deal with the information on data and features related with bias appropriately. In order to preserve the characteristics of the original data while excluding the information about the features causing bias, we propose a preprocessing approach based on information theory that avoids collision in the dual optimization, where the latent space is divided into two subspaces. Experiments are conducted with the well-known benchmark datasets of Census and COMPAS, and two real-world tasks: facial emotion recognition and text sentiment analysis . The information theoretic approach is promising to achieve fair machine learning by reducing the bias caused by several features such as age, race and gender.},
  archive      = {J_NEUCOM},
  author       = {Jin-Young Kim and Sung-Bae Cho},
  doi          = {10.1016/j.neucom.2021.09.081},
  journal      = {Neurocomputing},
  pages        = {26-38},
  shortjournal = {Neurocomputing},
  title        = {An information theoretic approach to reducing algorithmic bias for machine learning},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Region-of-interest and channel attention-based joint
optimization of image compression and computer vision. <em>NEUCOM</em>,
<em>500</em>, 13–25. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNN) have been widely applied in many computer vision problems. These tasks are often conducted on input images with high quality without consideration of storage and transmission costs, making it necessary to compress the images for bandwidth-constrained networks. Recently, researches on deep learning based image compression show promising performance compared with traditional image compression codecs. However, these image compression approaches focus on improving user-perceived visual quality, rather achieving high DNN inference accuracy for computer vision. In this work, we design a concrete system with the goal of maximizing the computer vision performance metric, subject to a compression ratio constraint. The entire framework is efficiently optimized in an end-to-end manner without multiple training phases. We find that the conventional distortion metric Mean Squared Error (MSE) in compression does not suffice to get desirable computer vision performance in our system. It is essential to exploit machine-centric evaluation metrics for high inference accuracy. We also propose to apply class-agnostic object masks combined with channel attention mechanism to dynamically allocate bits in regions of interest (ROI) and the background regions (BG) so as to optimize computer vision performance over a range of bitrates. We experiment on three diverse applications separately: image classification , human pose estimation and semantic segmentation . Extensive experiments show that our approach not only outperforms many traditional compression codecs in image compression, but also achieves superior computer vision performance than all other counterparts.},
  archive      = {J_NEUCOM},
  author       = {Binglin Li and Linwei Ye and Jie Liang and Yang Wang and Jingning Han},
  doi          = {10.1016/j.neucom.2022.05.047},
  journal      = {Neurocomputing},
  pages        = {13-25},
  shortjournal = {Neurocomputing},
  title        = {Region-of-interest and channel attention-based joint optimization of image compression and computer vision},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrated multi-similarity fusion and heterogeneous graph
inference for drug-target interaction prediction. <em>NEUCOM</em>,
<em>500</em>, 1–12. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug-target interaction (DTI) prediction performs a crucial part in drug discovery and design. Although many computational approaches for such prediction have been proposed, current researches still generally adopt chemical similarities of drugs or the sequence similarities of targets. However, the valuable information of known interactions has not been noticed, and the existing noise and useless information reduce the accuracy of DTI prediction. In addition, many existing computational approaches ignore the behavior information between nodes of the DTI network. In this paper, we develop an ensemble computational approach called integrated multi-similarity fusion and heterogeneous graph inference. First, based on the known DTI network, the degree distribution of drug and target similarities are analyzed and the noise and useless information are removed to improve prediction accuracy. Second, based on drug and target similarities and known DTIs, a strategy of multi-similarity fusion is proposed to capture potential useful information from known interactions that is used for enhancing drug and target similarities. Third, the heterogeneous graph inference is used to predict the DTIs to capture the edge weight (closeness) and behavior information (diffusion) between nodes of a heterogeneous network . To assist the reproducibility of our work and its comparison to published results, we perform experiments on four benchmark datasets. Results show that our approach outperforms some existing approaches and can contribute to predicting potential DTIs.},
  archive      = {J_NEUCOM},
  author       = {Majun Lian and Xinjie Wang and Wenli Du},
  doi          = {10.1016/j.neucom.2022.04.104},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {Integrated multi-similarity fusion and heterogeneous graph inference for drug-target interaction prediction},
  volume       = {500},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel MAS-GAN-based data synthesis method for object
surface defect detection. <em>NEUCOM</em>, <em>499</em>, 106–114. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface defect detection in industrial processes is an essential step in production. The use of surface defect detection technology is of great significance for improving product quality and increasing production efficiency. However, the number of surface defect samples collected in the industrial process is limited, making training deep learning-based object detection models challenging. This paper proposes a multi-scale progressive generative adversarial network (MAS-GAN) that combines non-leaking data augmentation and self-attention mechanisms to solve this problem. The model uses an asymptotic growth strategy to synthesize multi-scale surface defect images and uses a non-leaking data augmentation method to deal with the degradation of the performance of the generative model in the case of insufficient samples. The self-attention mechanism further optimizes the generative adversarial network to make the details of high-resolution images more perfect. Using MAS-GAN to synthesize surface defect images to assist in training a deep learning-based object detection algorithm, both the training convergence speed of the surface defect detection model and the detection accuracy is improved. The experimental results on different datasets show the effectiveness of the proposed data synthesis method in the detection of surface defects of objects.},
  archive      = {J_NEUCOM},
  author       = {Hongbin Zhang and Dong Pan and Jianhua Liu and Zhaohui Jiang},
  doi          = {10.1016/j.neucom.2022.05.021},
  journal      = {Neurocomputing},
  pages        = {106-114},
  shortjournal = {Neurocomputing},
  title        = {A novel MAS-GAN-based data synthesis method for object surface defect detection},
  volume       = {499},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Investigating the geometric structure of neural activation
spaces with convex hull approximations. <em>NEUCOM</em>, <em>499</em>,
93–105. (<a href="https://doi.org/10.1016/j.neucom.2022.05.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks have achieved great success in many tasks, including data classification and pattern recognition. However, how neural networks work and what representations they learn are still not fully understood. For any data sample fed into a neural network, we wondered how its corresponding vectors expanded by activated neurons change throughout the layers and why the final output vector could be classified or clustered. To formally answer these questions, we define the data sample outputs of each layer as activation vectors and the space expanded by them as the activation space . Then, we investigate the geometric structure of the high-dimensional activation spaces of neural networks by studying the geometric characters of the massive activation vectors through approximated convex hulls . We find that the different layers of neural networks have different roles, where the former and latter layers can disperse and gather data points, respectively. Moreover, we also propose a novel classification method based on the geometric structures of activation spaces, called nearest convex hull (NCH) classification, for the activation vectors in each layer of a neural network. The empirical results show that the geometric structure can indeed be utilized for classification and often outperforms original neural networks. Finally, we demonstrate that the relationship among the convex hulls of different classes could be a good metric to help us optimize neural networks in terms of over-fitting detection and network structure simplification.},
  archive      = {J_NEUCOM},
  author       = {Yuting Jia and Shao Zhang and Haiwen Wang and Ying Wen and Luoyi Fu and Huan Long and Xinbing Wang and Chenghu Zhou},
  doi          = {10.1016/j.neucom.2022.05.019},
  journal      = {Neurocomputing},
  pages        = {93-105},
  shortjournal = {Neurocomputing},
  title        = {Investigating the geometric structure of neural activation spaces with convex hull approximations},
  volume       = {499},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adjoint dynamical kernel density for anomaly detection.
<em>NEUCOM</em>, <em>499</em>, 81–92. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomalies affect data quality and lead to unexpected analysis results in data mining. Although techniques to handle anomalies do exist, they can fail in considering density changes of object along with incremental neighbors. This paper proposes an outlier factor based on the change of adjoint dynamical kernel density (ADD) to represent the degree of the object being an anomaly. The factor is equal to the ratios of the adjoint dynamical kernel density fluctuation (ADDF) of the object and the average ADDF of its neighborhood. ADDF is estimated by the difference of ADD, which describes the difference of every two consecutive adjoint kernel densities (AKD) of the object. AKD indicates kernel densities of the object while its neighbors are added one by one. Importantly, the kernel function is adopted to measure the distance between objects where the kernel trick improves discriminability between objects and reduces the computational burden of the algorithm. The experiments are performed on eight datasets to evaluate the effectiveness of the proposed method with different kernel functions. The experimental results have shown that the proposed method with the Gaussian kernel function has better performance of anomalies recognition and higher adaption of the parameter k of k -nearest neighbors over some other anomaly detection methods.},
  archive      = {J_NEUCOM},
  author       = {Panpan Zhang and Hui Cao and Yanbin Zhang and Jingcheng Wang and Lixin Jia and Feihu Hu},
  doi          = {10.1016/j.neucom.2022.05.005},
  journal      = {Neurocomputing},
  pages        = {81-92},
  shortjournal = {Neurocomputing},
  title        = {Adjoint dynamical kernel density for anomaly detection},
  volume       = {499},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effective multiscale deep learning model for COVID19
segmentation tasks: A further step towards helping radiologist.
<em>NEUCOM</em>, <em>499</em>, 63–80. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infection by the SARS-CoV-2 leading to COVID-19 disease is still rising and techniques to either diagnose or evaluate the disease are still thoroughly investigated. The use of CT as a complementary tool to other biological tests is still under scrutiny as the CT scans are prone to many false positives as other lung diseases display similar characteristics on CT scans. However, fully investigating CT images is of tremendous interest to better understand the disease progression and therefore thousands of scans need to be segmented by radiologists to study infected areas. Over the last year, many deep learning models for segmenting CT-lungs were developed. Unfortunately, the lack of large and shared annotated multicentric datasets led to models that were either under-tested (small dataset) or not properly compared (own metrics, none shared dataset), often leading to poor generalization performance . To address, these issues, we developed a model that uses a multiscale and multilevel feature extraction strategy for COVID19 segmentation and extensively validated it on several datasets to assess its generalization capability for other segmentation tasks on similar organs. The proposed model uses a novel encoder and decoder with a proposed kernel-based atrous spatial pyramid pooling module that is used at the bottom of the model to extract small features with a multistage skip connection concatenation approach. The results proved that our proposed model could be applied on a small-scale dataset and still produce generalizable performances on other segmentation tasks. The proposed model produced an efficient Dice score of 90\% on a 100 cases dataset, 95\% on the NSCLC dataset, 88.49\% on the COVID19 dataset, and 97.33 on the StructSeg 2019 dataset as compared to existing state-of-the-art models. The proposed solution could be used for COVID19 segmentation in clinic applications. The source code is publicly available at https://github.com/RespectKnowledge/Mutiscale-based-Covid-_segmentation-usingDeep-Learning-models .},
  archive      = {J_NEUCOM},
  author       = {Abdul Qayyum and Alain Lalande and Fabrice Meriaudeau},
  doi          = {10.1016/j.neucom.2022.05.009},
  journal      = {Neurocomputing},
  pages        = {63-80},
  shortjournal = {Neurocomputing},
  title        = {Effective multiscale deep learning model for COVID19 segmentation tasks: A further step towards helping radiologist},
  volume       = {499},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Observer-based PID control for actuator-saturated systems
under binary encoding scheme. <em>NEUCOM</em>, <em>499</em>, 54–62. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the observer-based proportional-integral-derivative (PID) control problem is investigated for a class of actuator-saturated systems affected by multiplicative noises under the binary encoding scheme (BES). The communication between the sensors and the observers is implemented via a shared network, in which the measurement signals are transmitted by the BES. During the transmission, random bit errors may occur in the bit string due to the channel noises. The aim of this paper is to design an observer-based PID controller such that the closed-loop system is exponentially mean-square ultimately bounded with the consideration of random bit errors, actuator saturations and multiplicative noises . Sufficient conditions are presented to guarantee the expected performance of the resulted tracking error, and the controller gain matrices are obtained by solving a set of matrix inequalities. Finally, the effectiveness of the proposed PID control scheme is verified by a simulation example.},
  archive      = {J_NEUCOM},
  author       = {Pengyu Wen and Hongli Dong and Fengcai Huo and Jiahui Li and Xuqing Lu},
  doi          = {10.1016/j.neucom.2022.05.035},
  journal      = {Neurocomputing},
  pages        = {54-62},
  shortjournal = {Neurocomputing},
  title        = {Observer-based PID control for actuator-saturated systems under binary encoding scheme},
  volume       = {499},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-head collaborative learning for graph neural networks.
<em>NEUCOM</em>, <em>499</em>, 47–53. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, graph neural networks (GNNs) have been widely used for graph-structured data representation. However, existing GNNs generally either employ one classifier head which usually makes the model fall into local minima or multiple classifier heads independently which lack of exploiting the correlation of them. To overcome this issue, in this paper, we propose to employ Multi-head Collaborative Learning for Graph Neural Networks (MCL-GNNs). The MCL-GNNs provide a collaborative learning process via multiple classifiers to complement each other’s information. Experimental results on several benchmark data sets show that our method has better generality and stability than other comparison methods.},
  archive      = {J_NEUCOM},
  author       = {Haiyun Xu and Bo Jiang and Lili Huang and Jin Tang and Shaojie Zhang},
  doi          = {10.1016/j.neucom.2022.05.027},
  journal      = {Neurocomputing},
  pages        = {47-53},
  shortjournal = {Neurocomputing},
  title        = {Multi-head collaborative learning for graph neural networks},
  volume       = {499},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Geolocation estimation of target vehicles using image
processing and geometric computation. <em>NEUCOM</em>, <em>499</em>,
35–46. (<a href="https://doi.org/10.1016/j.neucom.2021.10.127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating vehicles’ locations is one of the key components in intelligent traffic management systems (ITMSs) for increasing traffic scene awareness. Traditionally, stationary sensors have been employed in this regard. The development of advanced sensing and communication technologies on modern vehicles (MVs) makes it feasible to use such vehicles as mobile sensors to estimate the traffic data of observed vehicles. This study aims to explore the capabilities of a monocular camera mounted on an MV in order to estimate the geolocation of the observed vehicle in a global positioning system (GPS) coordinate system. We proposed a new methodology by integrating deep learning, image processing, and geometric computation to address the observed-vehicle localization problem. To evaluate our proposed methodology, we developed new algorithms and tested them using real-world traffic data. The results indicated that our proposed methodology and algorithms could effectively estimate the observed vehicle’s latitude and longitude dynamically.},
  archive      = {J_NEUCOM},
  author       = {Elnaz Namazi and Rudolf Mester and Chaoru Lu and Jingyue Li},
  doi          = {10.1016/j.neucom.2021.10.127},
  journal      = {Neurocomputing},
  pages        = {35-46},
  shortjournal = {Neurocomputing},
  title        = {Geolocation estimation of target vehicles using image processing and geometric computation},
  volume       = {499},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A more compact object detector head network with feature
enhancement and relational reasoning. <em>NEUCOM</em>, <em>499</em>,
23–34. (<a href="https://doi.org/10.1016/j.neucom.2022.05.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling feature interaction patterns is of significant importance to object detection tasks. However, reasoning about the relationship between instance features is challenging in two-stage detectors due to the overuse of hand-crafted components. To tackle this problem, we analyze three different levels of feature interaction relationships, namely, the dependency relationship between the cropped local features and global features, the feature autocorrelation within the instance, and the cross-correlation relationship between the instances. To this end, we propose a more c ompact o bject d etector h ead network ( CODH ), which can not only preserve global context information and condense the information density, but also allows instance-wise feature enhancement and relational reasoning in a larger matrix space. Without bells and whistles, our method can effectively improve the detection performance while significantly reducing the parameters of the model, e.g. , with our method, the parameters of the head network is 0.6 × 0.6× smaller than the state-of-the-art Cascade R-CNN. Yet, the performance boost is 1.3\% on COCO test-dev. Without losing generality, we can also build a lighter head network for other multi-stage detectors by assembling our method, including Faster R-CNN, Libra R-CNN, and Double Head R-CNN.},
  archive      = {J_NEUCOM},
  author       = {Wenchao Zhang and Chong Fu and Xiangshi Chang and Tengfei Zhao and Xiang Li and Chiu-Wing Sham},
  doi          = {10.1016/j.neucom.2022.05.034},
  journal      = {Neurocomputing},
  pages        = {23-34},
  shortjournal = {Neurocomputing},
  title        = {A more compact object detector head network with feature enhancement and relational reasoning},
  volume       = {499},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing real-world adversarial patches through 3D modeling
of complex target scenes. <em>NEUCOM</em>, <em>499</em>, 11–22. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial examples have proven to be a concerning threat to deep learning models, particularly in the image domain. While many studies have examined adversarial examples in the real world, most of them relied on 2D photos of the attack scene. As a result, the attacks proposed may have limited effectiveness when implemented in realistic environments with 3D objects or varied conditions. Some studies on adversarial learning have used 3D objects, however in many cases, other researchers are unable to replicate the real-world evaluation process. In this study, we present a framework that uses 3D modeling to craft adversarial patches for an existing real-world scene. Our approach uses a 3D digital approximation of the scene to simulate the real world. With the ability to add and manipulate any element in the digital scene, our framework enables the attacker to improve the adversarial patch’s impact in real-world settings. We use the framework to create a patch for an everyday scene and evaluate its performance using a novel evaluation process that ensures that our results are reproducible in both the digital space and the real world. Our evaluation results show that the framework can generate adversarial patches that are robust to different settings in the real world.},
  archive      = {J_NEUCOM},
  author       = {Yael Mathov and Lior Rokach and Yuval Elovici},
  doi          = {10.1016/j.neucom.2022.05.031},
  journal      = {Neurocomputing},
  pages        = {11-22},
  shortjournal = {Neurocomputing},
  title        = {Enhancing real-world adversarial patches through 3D modeling of complex target scenes},
  volume       = {499},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attention-based cross-layer domain alignment for
unsupervised domain adaptation. <em>NEUCOM</em>, <em>499</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) aims to learn transferable knowledge from a labeled source domain and adapts a trained model to an unlabeled target domain. To bridge the gap between source and target domains, one prevailing strategy is to minimize the distribution discrepancy by aligning their semantic features extracted by deep models. The existing alignment-based methods mainly focus on reducing domain divergence in the same model layer. However, the same level of semantic information could distribute across model layers due to the domain shifts. To further boost model adaptation performance, we propose a novel method called Attention-based Cross-layer Domain Alignment (ACDA), which captures the semantic relationship between the source and target domains across model layers and calibrates each level of semantic information automatically through a dynamic attention mechanism . An elaborate attention mechanism is designed to reweight each cross-layer pair based on their semantic similarity for precise domain alignment, effectively matching each level of semantic information during model adaptation. Extensive experiments on multiple benchmark datasets consistently show that the proposed method ACDA yields state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Xu Ma and Junkun Yuan and Yen-wei Chen and Ruofeng Tong and Lanfen Lin},
  doi          = {10.1016/j.neucom.2022.04.086},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {Attention-based cross-layer domain alignment for unsupervised domain adaptation},
  volume       = {499},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic analysis of delayed neural networks: Event-triggered
impulsive halanay inequality approach. <em>NEUCOM</em>, <em>498</em>,
98–107. (<a href="https://doi.org/10.1016/j.neucom.2022.04.116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a generalized impulsive Halanay inequality from the impulsive control standpoints, where the impulse action is event-triggered. Namely, the control task is executed when an external event generated by the state-dependent event-triggered mechanism ( ETM ) is activated, rather than at a fixed time. It is shown that under the proposed event-triggered impulsive control ( ETIC ) strategy, the solution of the underlying inequality is guaranteed to converge to zero asymptotically. Moreover, the key point is the introduction of monitoring value to ensure a positive minimum inter-execution time, which exactly assists ETIC with reducing the pressure of information transmission. Then, the generalized impulsive Halanay inequality with appropriate ETIC scheme is utilized to the analysis of delayed neural networks (DNNs). In particular, some synchronization and asymptotic stability criteria of DNNs are derived, where the design of impulsive controller is based on ETIC strategy. At last, some numerical examples are provided to illustrate the validity of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Wenlu Liu and Xueyan Yang and Rajan Rakkiyappan and Xiaodi Li},
  doi          = {10.1016/j.neucom.2022.04.116},
  journal      = {Neurocomputing},
  pages        = {98-107},
  shortjournal = {Neurocomputing},
  title        = {Dynamic analysis of delayed neural networks: Event-triggered impulsive halanay inequality approach},
  volume       = {498},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Controllability of markovian jump boolean control networks:
A graphical approach. <em>NEUCOM</em>, <em>498</em>, 89–97. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the controllability of Markovian jump Boolean control networks (MJBCNs) by using graphical approach. To solve this problem, a deterministic directed graph is constructed to describe the stochastic evolutionary process of the considered MJBCN under the framework of semi-tensor product of matrices. Then, combining with breadth-first search, the special subgraph with breadth-first tree as the principal part is obtained. Based on this, the necessary and sufficient conditions to verify the controllability of MJBCNs are deduced, and the problem of determining the minimal controllable time is solved completely. Subsequently, two examples are given to illustrate the validity and correctness of the method.},
  archive      = {J_NEUCOM},
  author       = {Qingle Zhang and Jun-e Feng and Peixin Zhao},
  doi          = {10.1016/j.neucom.2022.04.119},
  journal      = {Neurocomputing},
  pages        = {89-97},
  shortjournal = {Neurocomputing},
  title        = {Controllability of markovian jump boolean control networks: A graphical approach},
  volume       = {498},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PF-SMOTE: A novel parameter-free SMOTE for imbalanced
datasets. <em>NEUCOM</em>, <em>498</em>, 75–88. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance learning is one of the most important topics in the field of machine learning and data mining, and the Synthetic Minority Oversampling Techniques (SMOTE) is the common method to handle this issue. The main shortcomings of the classic SMOTE and its variants is the interpolation of potential noise and unrepresentative examples. This paper is devoted to proposing a novel parameter-free SMOTE mechanism to produce sufficient representative synthetic examples while avoiding interpolating noisy examples. Specifically, two types of minority class examples are defined, namely boundary and safe minority examples. The synthetic examples generation procedure fully reflects the characteristics of the minority class examples with filling the region dominated by the minority class and expanding the margin of the minority class. To verify the effectiveness and robustness of the proposed method, a thorough experimental study on forty datasets selected from real-world applications is carried out. The experimental results indicate that our proposed method is competitive to the classic SMOTE and its state-of-the-art variants.},
  archive      = {J_NEUCOM},
  author       = {Qiong Chen and Zhong-Liang Zhang and Wen-Po Huang and Jian Wu and Xing-Gang Luo},
  doi          = {10.1016/j.neucom.2022.05.017},
  journal      = {Neurocomputing},
  pages        = {75-88},
  shortjournal = {Neurocomputing},
  title        = {PF-SMOTE: A novel parameter-free SMOTE for imbalanced datasets},
  volume       = {498},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Construct informative triplet with two-stage hard-sample
generation. <em>NEUCOM</em>, <em>498</em>, 59–74. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a robust sample generation scheme to construct informative triplets. The proposed hard sample generation is a two-stage synthesis framework that produces hard samples through effective positive and negative sample generators in two stages, respectively. The first stage stretches the anchor-positive pairs with piecewise linear manipulation and enhances the quality of generated samples by skillfully designing a conditional generative adversarial network to lower the risk of mode collapse. The second stage utilizes an adaptive reverse metric constraint to generate the final hard samples. Extensive experiments on several benchmark datasets verify that our method achieves superior performance than the existing hard-sample generation algorithms. Besides, we also find that our proposed hard sample generation method combining the existing triplet mining strategies can further boost the deep metric learning performance.},
  archive      = {J_NEUCOM},
  author       = {Chuang Zhu and Zheng Hu and Huihui Dong and Gang He and Zekuan Yu and Shangshang Zhang},
  doi          = {10.1016/j.neucom.2022.05.032},
  journal      = {Neurocomputing},
  pages        = {59-74},
  shortjournal = {Neurocomputing},
  title        = {Construct informative triplet with two-stage hard-sample generation},
  volume       = {498},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploiting the black-litterman framework through
error-correction neural networks. <em>NEUCOM</em>, <em>498</em>, 43–58.
(<a href="https://doi.org/10.1016/j.neucom.2022.05.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Black-Litterman (BL) model is a particularly essential analytical tool for effective portfolio management in financial services sector since it enables investment analysts to integrate investor views into market equilibrium returns. In this research, we define and study the continuous-time BL portfolio optimization (CTBLPO) problem as a time-varying quadratic programming (TVQP) problem. The investor’s views in the CTBLPO problem are regarded as a forecasting problem, and they are generated by a novel neural network (NN) model. More precisely, employing a novel multi-function activated by a weights-and-structure-determination for time-series (MAWTS) algorithm, a 3-layer feed-forward NN model, called MAWTSNN, is proposed for handling time-series modeling and forecasting problems. Then, using real-world datasets, the CTBLPO problem is approached by two different TVQP NN solvers. These solvers are the zeroing NN (ZNN) and the linear-variational-inequality primal–dual NN (LVI-PDNN). The experiment findings illustrate and compare the performances of the ZNN and LVI-PDNN in three various portfolio configurations, as well as indicating that the MAWTSNN is an excellent alternative to the traditional approaches. To promote and contend the outcomes of this research, we created two MATLAB repositories for the interested user, that are publicly accessible on GitHub.},
  archive      = {J_NEUCOM},
  author       = {Spyridon D. Mourtas and Vasilios N. Katsikis},
  doi          = {10.1016/j.neucom.2022.05.036},
  journal      = {Neurocomputing},
  pages        = {43-58},
  shortjournal = {Neurocomputing},
  title        = {Exploiting the black-litterman framework through error-correction neural networks},
  volume       = {498},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An extensive appraisal of weight-sharing on the
NAS-bench-101 benchmark. <em>NEUCOM</em>, <em>498</em>, 28–42. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weight-sharing (WS) has recently emerged as a paradigm to accelerate the automated search for efficient neural architectures, a process dubbed Neural Architecture Search (NAS). By using and training the same set of weights for the whole search space, WS allows for the quick evaluation of millions of architectures, where classical NAS approaches require lengthy individual trainings. Although very appealing, WS is not without drawbacks and several works have started to question its capabilities on small hand-crafted benchmarks. In this paper, we take advantage of the NAS-Bench-101 dataset to challenge the efficiency of a uniform-sampling based WS variant on several representative search spaces. After reviewing previous studies on WS and highlighting several of their shortcomings, we introduce our own experimental setup, from which we extract several good practices that one should keep in mind when evaluating WS. With our experiments we first establish that, given the correct evaluation procedure, WS is able to produce accuracy scores decently correlated with standalone ones. We then provide evidence that on some search spaces, this WS variant is able to rapidly find better than random architectures, whilst it is equivalent or sometimes even worse than a baseline random search on others, as we find that given the same budget, the probability of superiority of an architecture found using WS over an architecture found through random search can vary between 7\% and 78\% depending on the search space. We present evidence that the search space itself has an intricate effect on the capabilities of WS and can bias weight-sharing towards certain architectural patterns with no clear accuracy advantage. We conclude that the impact of WS is heavily search-space dependent and difficult to anticipate for a given problem.},
  archive      = {J_NEUCOM},
  author       = {Aloïs Pourchot and Kévin Bailly and Alexis Ducarouge and Olivier Sigaud},
  doi          = {10.1016/j.neucom.2022.04.108},
  journal      = {Neurocomputing},
  pages        = {28-42},
  shortjournal = {Neurocomputing},
  title        = {An extensive appraisal of weight-sharing on the NAS-bench-101 benchmark},
  volume       = {498},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GPM: A graph convolutional network based reinforcement
learning framework for portfolio management. <em>NEUCOM</em>,
<em>498</em>, 14–27. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio management is a decision-making process of periodically reallocating a certain amount of funds into a portfolio of assets, with the objective of maximizing the profits constrained to a given risk level. Due to its nature of learning from dynamic interactions and planning for long-run performance, reinforcement learning (RL) recently has received much attention in portfolio management. However, most of existing RL-based PM approaches in general only consider price changes of portfolio assets and the implicit correlations between price changes, while ignoring the rich relations between companies in the market, such as two assets in the same sector or two companies have a supplier-customer relation, which are very important for trading decision making. To address these limitations, in this paper, we propose GPM, a novel graph convolutional network-based reinforcement learning framework for portfolio management, which first employs Relational Graph Convolutional Network (R-GCN) to extract asset relational features, and then combines relational features with multi-scale temporal features to make trading decisions for better performance. We also introduce softmax with temperature to increase portfolio diversity, which leads to further increase in profits. Experimental results on two real-world datasets: NASDAQ and NYSE , validate the effectiveness of GPM over state-of-the-art PM methods. Further, more experiments are conducted to evaluate GPM with different graph neural networks and different number of network layers, to explore proper settings for different markets.},
  archive      = {J_NEUCOM},
  author       = {Si Shi and Jianjun Li and Guohui Li and Peng Pan and Qi Chen and Qing Sun},
  doi          = {10.1016/j.neucom.2022.04.105},
  journal      = {Neurocomputing},
  pages        = {14-27},
  shortjournal = {Neurocomputing},
  title        = {GPM: A graph convolutional network based reinforcement learning framework for portfolio management},
  volume       = {498},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel, parallel and differential synaptic architecture based
on NAND flash memory for high-density and highly-reliable binary neural
networks. <em>NEUCOM</em>, <em>498</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel synaptic architecture based on a NAND flash memory structure is proposed as a high-density synapse capable of exclusive NOR (XNOR) operation for binary neural networks (BNNs). For the first time, a 4T2S-based synaptic architecture with a complementary input voltage that implements an equivalent bitwise XNOR operation is proposed. Two adjacent NAND flash strings connected with the word lines are used as one synaptic string with four input transistors connected to the bit-line. By changing the threshold voltage of the NAND flash cells and input voltages in a complementary fashion, the XNOR operation is successfully demonstrated. The large on/off current ratio (∼7 × 10 5 ) of the NAND flash cells and differential sensing scheme can implement high-density and highly reliable binary neural networks without error correcting codes (ECC), which can reduce the burden of the complementary metal–oxide–semiconductor (CMOS) overhead. Despite the string structure of NAND flash memory, the parallel read scheme significantly reduces the read-out latency when compared to the sequential read scheme. In addition, we show that with only 1 erase/program pulse, sufficiently low bit-error rate (7.6 × 10 −9\%) is achieved without the conventional incremental step pulse programming (ISPP) scheme. Finally, the estimated synapse density of V-NAND flash memory with 128 stacks is ∼103 times that of the 2T2R synapse in resistive random access memory (RRAM).},
  archive      = {J_NEUCOM},
  author       = {Sung-Tae Lee and Hyeongsu Kim and Honam Yoo and Dongseok Kwon and Jong-Ho Lee},
  doi          = {10.1016/j.neucom.2022.05.030},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {Novel, parallel and differential synaptic architecture based on NAND flash memory for high-density and highly-reliable binary neural networks},
  volume       = {498},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). STC-NAS: Fast neural architecture search with source-target
consistency. <em>NEUCOM</em>, <em>497</em>, 227–238. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) has shown very promising results for automatically designing network models. Most existing cell-based NAS approaches generate the target network model from a source super-network, which usually confront inconsistency issues. In this paper, we propose a new NAS method named STC-NAS, a fast neural architecture search with source-target consistency, so that not only the performance of the searched target model is improved but also the search process is boosted. Specifically, during the search phase, we sample the source super-network to let the samples be consistent with the target model. Moreover, we leverage the Jensen-Shannon divergence to ensure the samples are optimized in the direction of being more similar to the target model. Experimental results demonstrate that our method needs only 0.059 GPU-days to search on CIFAR-10. Benefited from its efficiency, STC-NAS can directly search the target super-network on the target task datasets, achieving 2.42\% test error on CIFAR-10, 16.45\% test error on CIFAR-100, and 24.2\% test error on ImageNet datasets.},
  archive      = {J_NEUCOM},
  author       = {Zihao Sun and Yu Hu and Longxing Yang and Shun Lu and Jilin Mei and Yinhe Han and Xiaowei Li},
  doi          = {10.1016/j.neucom.2021.11.082},
  journal      = {Neurocomputing},
  pages        = {227-238},
  shortjournal = {Neurocomputing},
  title        = {STC-NAS: Fast neural architecture search with source-target consistency},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structure-conditioned adversarial learning for unsupervised
domain adaptation. <em>NEUCOM</em>, <em>497</em>, 216–226. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) typically carries out knowledge transfer from a label-rich source domain to an unlabeled target domain by adversarial learning. In principle, existing UDA approaches mainly focus on the global distribution alignment between domains while ignoring the intrinsic local distribution properties. Motivated by this observation, we propose an end-to-end structure-conditioned adversarial learning scheme (SCAL) that is able to preserve the intra-class compactness during domain distribution alignment. By using local structures as structure-aware conditions, the proposed scheme is implemented in a structure-conditioned adversarial learning pipeline. The above learning procedure is iteratively performed by alternating between local structures establishment and structure-conditioned adversarial learning. Experimental results demonstrate the effectiveness of the proposed scheme in UDA scenarios.},
  archive      = {J_NEUCOM},
  author       = {Hui Wang and Jian Tian and Songyuan Li and Hanbin Zhao and Fei Wu and Xi Li},
  doi          = {10.1016/j.neucom.2022.04.094},
  journal      = {Neurocomputing},
  pages        = {216-226},
  shortjournal = {Neurocomputing},
  title        = {Structure-conditioned adversarial learning for unsupervised domain adaptation},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Distributed online convex optimization with a bandit
primal-dual mirror descent push-sum algorithm. <em>NEUCOM</em>,
<em>497</em>, 204–215. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed online convex optimization problem with time-varying constraints for multi-agent networks is addressed in this article. The purpose is to optimize a sequence of time-varying global cost functions defined as the accumulated values of local cost functions, also attempt to meet the requirement of a sequence of time-varying coupled constraint functions which denote the sum of local constraint functions. Cost functions and constraint functions are unknown to agents beforehand. It is supposed that each agent in the network communicates with its neighbours through a uniformly strongly connected sequence of time-varying directed communication topologies. This paper proposes the bandit distributed primal-dual mirror descent push-sum (BDPDMDPS) algorithm constructed by bandit primal-dual, mirror descent and push-sum methods. Operational performance of the presented algorithm is measured by expected regret and expected constraint violation, both of which are proved to be sublinear with respect to the total iteration span T in this paper. Finally, a numerical simulation example is shown, which confirms the results for expected regret and expected constraint violation of BDPDMDPS algorithm.},
  archive      = {J_NEUCOM},
  author       = {Cong Wang and Shengyuan Xu and Deming Yuan and Baoyong Zhang and Zhengqiang Zhang},
  doi          = {10.1016/j.neucom.2022.05.024},
  journal      = {Neurocomputing},
  pages        = {204-215},
  shortjournal = {Neurocomputing},
  title        = {Distributed online convex optimization with a bandit primal-dual mirror descent push-sum algorithm},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Crowd counting method via a dynamic-refined density map
network. <em>NEUCOM</em>, <em>497</em>, 191–203. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, most existing crowd counting methods use density maps to estimate the number of people, so the quality of density maps is particularly important to the counting results. In practical application, the density map generated by the existing methods is easily affected by the change of head proportion, which cannot truly reflect the size of head in the image and affect the counting accuracy. To effectively overcome the above problems, a crowd counting method via a dynamic-refined density map network is proposed in this paper. This method refines the existing ground-truth density maps by jointly training Counting Net and learnable Refine Net, and counts through Counting Net. Specifically, we design a Refine Net, which adaptively adjusts the relationship between the head sizes at different positions in the dot map through the U-shaped network structure and the regional attention module (RAM), so as to obtain a ground truth that is more in line with the real head size. In addition, we propose a Counting Net based on coprime dilation rate convolution groups to ensure the continuity of information. Extensive experiments on four benchmark datasets (ShanghaiTech, UCF_CC_50, UCF-QNRF and JHU-CROWD++) indicate that our method can achieve state-of-the-art counting performance and high robustness.},
  archive      = {J_NEUCOM},
  author       = {Yanbo Liu and Guo Cao and Zixian Ge and Yingxiang Hu},
  doi          = {10.1016/j.neucom.2022.04.106},
  journal      = {Neurocomputing},
  pages        = {191-203},
  shortjournal = {Neurocomputing},
  title        = {Crowd counting method via a dynamic-refined density map network},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local spatial alignment network for few-shot learning.
<em>NEUCOM</em>, <em>497</em>, 182–190. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-Shot Learning (FSL) aims at recognizing the novel classes with extremely limited samples via transferring the learned knowledge from some base classes. Most of the existing metric-based approaches focus on measuring the instance-level feature similarity but neglect the spatial alignment between different instances, which would lead to poor adaptation with inaccurate local spatial matching, especially for he fine-grained classes. In this paper, we propose a model called Local Spatial Alignment Network (LSANet) to measure the instance-to-class similarity via aligning the local spatial regions in a traversal scanning way. Specifically, the local spatial alignment is achieved by continuously sampling the local patches from the query feature map, where each local patch performs as a kernel to filter the most similar local patches from the support feature maps, obtaining the patch-level similarities between the query instance and the support classes. Then, we propose an information aggregation module to aggregate the patch-level similarities into the class prediction score, where the important patches are highlighted and the backgrounds are diluted. In this way, our model is able to both align the local spatial patches and capture the discriminative information, which benefits in adapting for the novel few-shot classes. To evaluate the effectiveness of the proposed model, we conduct extensive experiments on both coarse-grained and fine-grained datasets. The experimental results show that the proposed LSANet performs competitively on the FSL benchmarks of different granularities .},
  archive      = {J_NEUCOM},
  author       = {Yunlong Yu and Dingyi Zhang and Sidi Wang and Zhong Ji and Zhongfei Zhang},
  doi          = {10.1016/j.neucom.2022.05.020},
  journal      = {Neurocomputing},
  pages        = {182-190},
  shortjournal = {Neurocomputing},
  title        = {Local spatial alignment network for few-shot learning},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design of robust h∞ state estimator for delayed polytopic
uncertain genetic regulatory networks: Dealing with finite-time
boundedness. <em>NEUCOM</em>, <em>497</em>, 170–181. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a robust H ∞ H∞ design approach is proposed to accomplish the state estimation task for a class of continuous-time gene regulatory networks (GRNs) in the finite-time framework. For the GRNs under investigation, the distributed inter-node time delays and intra-node time delays are, respectively, taken into account in the feedback regulation function and the translation process. Moreover, the parameter uncertainty with convex polytopic constraint is introduced to characterize the unavoidable modeling errors induced by parameter sensitivity, calibration accuracy, abrupt structural changes and failures, etc. The primary objective of this paper is to design a robust state estimator for the considered GRNs based on the measured concentrations of messenger ribonucleic acid and protein such that the finite-time boundedness and the H ∞ H∞ performance are guaranteed. By resorting to the Lyapunov stability theory , the Jensen’s inequality and the Gronwall inequality, some sufficient conditions are established in terms of linear matrix inequalities. Subsequently, a set of parameter matrices with special structures is designed by means of the convex optimization techniques. Finally, a numerical example is provided to demonstrate the finite-time boundedness and the robust performance of the developed state estimation approach.},
  archive      = {J_NEUCOM},
  author       = {Fuad E. Alsaadi and Yurong Liu and Njud S. Alharbi},
  doi          = {10.1016/j.neucom.2022.05.018},
  journal      = {Neurocomputing},
  pages        = {170-181},
  shortjournal = {Neurocomputing},
  title        = {Design of robust h∞ state estimator for delayed polytopic uncertain genetic regulatory networks: Dealing with finite-time boundedness},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DRFormer: Learning dual relations using transformer for
pedestrian attribute recognition. <em>NEUCOM</em>, <em>497</em>,
159–169. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian attribute recognition is a challenging task because of appearance variations, illumination variations , etc., in pedestrian images. We observe that two typical relations, i.e., relations of regions and relations of attributes, are beneficial to accomplish this task. In this paper, we explore the potential of Transformer on pedestrian attribute recognition task for the first time, and propose a Transformer framework called Dual-Relations Transformer (DRFormer). Vision Transformer (ViT) is adopted as a feature extractor for its nature of modeling long-range relations of regions. Furthermore, an Attribute Relation Module (ARM) is designed with Transformer encoder to capture relations of attributes. In ARM, we encode spatial information and semantic information of attributes into vector embedding representations. Being equipped with spatial information, DRFormer is capable of localizing attribute-related regions. Semantic information enables DRFormer to learn underlying semantic relations among attributes. Extensive experiments are conducted on three popular datasets, including PETA, PA-100K, and RAP, and demonstrate the superiority of our proposed DRFormer over state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Zengming Tang and Jun Huang},
  doi          = {10.1016/j.neucom.2022.05.028},
  journal      = {Neurocomputing},
  pages        = {159-169},
  shortjournal = {Neurocomputing},
  title        = {DRFormer: Learning dual relations using transformer for pedestrian attribute recognition},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent advances on loss functions in deep learning for
computer vision. <em>NEUCOM</em>, <em>497</em>, 129–158. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The loss function, also known as cost function, is used for training a neural network or other machine learning models. Over the past decade, researchers have designed many loss functions for machine learning , such as mean squared error and mean absolute error . However, in deep learning , neurons of the last layer are usually activated by a sigmoid or softmax function. Thus, training with traditional losses would cause lower efficiency and accuracy. Recently, designing loss functions for deep learning methods has become one of the most challenging problems. This paper provides a comprehensive review of the recent progress and frontiers about loss functions in deep learning, especially for computer vision tasks . Specifically, we discuss the loss functions in three main computer vision tasks , i.e., object detection, face recognition, and image segmentation . Scholars have proposed several novel loss functions to cope with the specific problems such as imbalanced data , uncertain distribution of the predicted bounding boxes, varied overlapped mode between two bounding boxes and over-fitting. The survey details the source, derivation, and properties of each loss function. Furthermore, we also provide some advanced challenges about robust losses, generative adversarial networks , noise-tolerant losses, and semantic data augmentation . Finally, we deliver a summary and some promising future research directions.},
  archive      = {J_NEUCOM},
  author       = {Yingjie Tian and Duo Su and Stanislao Lauria and Xiaohui Liu},
  doi          = {10.1016/j.neucom.2022.04.127},
  journal      = {Neurocomputing},
  pages        = {129-158},
  shortjournal = {Neurocomputing},
  title        = {Recent advances on loss functions in deep learning for computer vision},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022e). A survey on multimodal-guided visual content synthesis.
<em>NEUCOM</em>, <em>497</em>, 110–128. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing interest in various creative scenes such as social media, film production, and intelligence courses, people expect to be able to compile rich visual content according to their subjective ideas and actual needs. In this context, visual content synthesis technique based on multimodal data has attracted much attention in recent years. Compared to traditional generative methods, multimodal data offer more flexible and concrete clues that provide an interactive and controllable way to generate the desired visual content. In this survey, we comprehensively summarize the improvements in multimodal-guided visual content synthesis. We first formulate the taxonomy of visual content synthesis and divide it into four different subfields depending on the input modality, including visual-guided visual content synthesis, text-guided visual content synthesis, audio-guided visual content synthesis, and visual content synthesis guided by other modalities. In each subfield, we describe the paradigm of different modality-guided visual content synthesis, and also discuss the signature methods mainly based on Generative Adversarial Networks (GANs). Next, we present commonly used benchmark datasets and metrics for evaluating models, as well as detailed comparisons between different methods. Finally, we provide insight into current research challenges and possible future research directions.},
  archive      = {J_NEUCOM},
  author       = {Ziqi Zhang and Zeyu Li and Kun Wei and Siduo Pan and Cheng Deng},
  doi          = {10.1016/j.neucom.2022.04.126},
  journal      = {Neurocomputing},
  pages        = {110-128},
  shortjournal = {Neurocomputing},
  title        = {A survey on multimodal-guided visual content synthesis},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Orbital collaborative learning in 6G space-air-ground
integrated networks. <em>NEUCOM</em>, <em>497</em>, 94–109. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, 6G is being proposed as a new next-generation communication architecture. The inclusion of satellite communication networks makes it possible to genuinely space-air-ground integrated networks, especially the combination of 6G with machine learning algorithms , which has attracted increasing attention. Of particular note is the combination of collaborative learning with the Internet of Everything , which improves the intelligence and collaboration of devices with more robust privacy protection, higher computing power, and greater energy savings . However, the airspace environment in 6G is extraordinarily dynamic and delay-sensitive for services, and traditional federation learning is a synchronous aggregation model with slow convergence. To address this problem, the paper proposes a hierarchical satellite-ground collaborative architecture with three roles: remote cloud center, orbital edge computing server, and data node. We use the advantages of orbital edge computing and low-orbit satellite network communication to manage the parameter transfer problem during the collaboration process. Meanwhile, we propose an asynchronous adaptive collaborative aggregation algorithm (AFLS) for the satellite-ground architecture, enabling the federated members to update the model parameters in time during the dynamic joining aggregation process. Experiments show that our architecture and algorithm excel in training performance with 95\%\% accuracy and fewer communication rounds in image classification when the roles are in good collaboration.},
  archive      = {J_NEUCOM},
  author       = {Ming Zhao and Chen Chen and Lei Liu and DaPeng Lan and Shaohua Wan},
  doi          = {10.1016/j.neucom.2022.04.098},
  journal      = {Neurocomputing},
  pages        = {94-109},
  shortjournal = {Neurocomputing},
  title        = {Orbital collaborative learning in 6G space-air-ground integrated networks},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). REIN-2: Giving birth to prepared reinforcement learning
agents using reinforcement learning agents. <em>NEUCOM</em>,
<em>497</em>, 86–93. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Reinforcement Learning (Deep RL) has been in the spotlight for the past few years, due to its remarkable abilities to solve problems which were considered to be practically unsolvable using traditional Machine Learning methods. However, even state-of-the-art Deep RL algorithms have various weaknesses that prevent them from being used extensively within industry applications, with one such major weakness being their sample-inefficiency. In an effort to patch these issues, we integrated a meta-learning technique in order to shift the objective of learning to solve a task into the objective of learning how to learn to solve a task (or a set of tasks), which we empirically show that improves overall stability and performance of Deep RL algorithms. Our model, named REIN-2, is a meta-learning scheme formulated within the RL framework, the goal of which is to develop a meta-RL agent (meta-learner) that learns how to produce other RL agents (inner-learners) that are capable of solving given environments. For this task, we convert the typical interaction of an RL agent with the environment into a new, single environment for the meta-learner to interact with. Compared to traditional state-of-the-art Deep RL algorithms, experimental results show remarkable performance of our model in popular OpenAI Gym environments in terms of scoring and sample efficiency, including the Mountain Car hard-exploration environment.},
  archive      = {J_NEUCOM},
  author       = {Aristotelis Lazaridis and Ioannis Vlahavas},
  doi          = {10.1016/j.neucom.2022.05.004},
  journal      = {Neurocomputing},
  pages        = {86-93},
  shortjournal = {Neurocomputing},
  title        = {REIN-2: Giving birth to prepared reinforcement learning agents using reinforcement learning agents},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-supervised regression with manifold: A bayesian deep
kernel learning approach. <em>NEUCOM</em>, <em>497</em>, 76–85. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning (SSL) aims at utilizing the vast unlabeled data to help the supervised training. While existing SSL methods have shown promising results on image classification tasks, most of them rely on the cluster assumption that does not apply to image regression tasks. In this paper, we address the under-studied semi-supervised image regression problem , of which the outputs are continuous values instead of categorical distributions. To tackle this challenging task, we propose an algorithm, called ManiDKL, with the idea that the prediction function should be smooth with respect to the intrinsic manifold of data distribution and behave similarly on both labeled and unlabeled data. In particular, we propose a framework that implements the Tikhonov regularization with generative manifold learning to ensure manifold smoothness of regression function and also reduces the problem to kernel learning. Then a semi-supervised non-parametric Bayesian based deep kernel learning algorithm is proposed, in which unlabeled data are incorporated through posterior regularization. We show the effectiveness of ManiDKL with extensive experiments. It shows that ManiDKL performs comparatively with state-of-the-art SSL image classification methods. Most importantly, we show the superiority of ManiDKL over all existing SSL regression methods on public image datasets.},
  archive      = {J_NEUCOM},
  author       = {Lu Xu and Chen Hu and Kuizhi Mei},
  doi          = {10.1016/j.neucom.2022.05.002},
  journal      = {Neurocomputing},
  pages        = {76-85},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised regression with manifold: A bayesian deep kernel learning approach},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep reinforcement learning based method for real-time
path planning and dynamic obstacle avoidance. <em>NEUCOM</em>,
<em>497</em>, 64–75. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a dynamic environment, the moving obstacle makes the path planning of the manipulator very difficult. Therefore, this paper proposes a path planning with dynamic obstacle avoidance method of the manipulator based on a deep reinforcement learning algorithm soft actor-critic (SAC). To avoid the moving obstacle in the environment and make real-time planning, we design a comprehensive reward function of dynamic obstacle avoidance and target approach. Aiming at the problem of low sample utilization caused by random sampling, in this paper, prioritized experience replay (PER) is employed to change the weight of samples, and then improve the sampling efficiency. In addition, we carry out the simulation experiment and give the results. The result shows that this method can effectively avoid moving obstacles in the environment, and complete the planning task with a high success rate.},
  archive      = {J_NEUCOM},
  author       = {Pengzhan Chen and Jiean Pei and Weiqing Lu and Mingzhen Li},
  doi          = {10.1016/j.neucom.2022.05.006},
  journal      = {Neurocomputing},
  pages        = {64-75},
  shortjournal = {Neurocomputing},
  title        = {A deep reinforcement learning based method for real-time path planning and dynamic obstacle avoidance},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Perspective view of autonomous control in unknown
environment: Dual control for exploitation and exploration vs
reinforcement learning. <em>NEUCOM</em>, <em>497</em>, 50–63. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper overviews and discusses the relationship between Reinforcement Learning (RL) and the recently developed Dual Control for Exploitation and Exploration (DCEE). It is argued that there are two related but quite distinctive approaches, namely, control and machine learning , in tackling intractability arising in optimal decision making/control problems. In the control approach, the original problems (of an infinite horizon) are approximated by finite horizon problems and solved online by taking advantage of the availability of computing power. In the machine learning approach , the optimal solutions are approximated through iterations, or (offline) training through trials when models are not available. When dealing with unknown environments, DCEE as a technique developed from the control approach could potentially solve similar problems as RL while offering a number of advantages, most notably, coping with uncertainty in environment/tasks, high efficiency in learning through balancing exploitation and exploration, and potential in establishing its formal properties like stability. The links between DCEE and other relevant methods like dual control, Model Predictive Control and particularly Active Inference in neuroscience are discussed. The latter provides a strong biological endorsement for DCEE. The methods and discussions are illustrated by autonomous source search using a robot. It is concluded that DCEE provides a promising, complementary approach to RL, and more research is required to develop it as a generic theory and fully realise its potential. The relationships revealed in this paper provide insights into these relevant methods and facilitate cross fertilisation between control, machine learning and neuroscience for developing autonomous control under uncertain environments.},
  archive      = {J_NEUCOM},
  author       = {Wen-Hua Chen},
  doi          = {10.1016/j.neucom.2022.04.131},
  journal      = {Neurocomputing},
  pages        = {50-63},
  shortjournal = {Neurocomputing},
  title        = {Perspective view of autonomous control in unknown environment: Dual control for exploitation and exploration vs reinforcement learning},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Global and local interaction matching model for
knowledge-grounded response selection in retrieval-based chatbots.
<em>NEUCOM</em>, <em>497</em>, 39–49. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge-grounded response selection, the task of selecting a proper response from a set of response candidates given the conversation context and its background knowledge, is important for building intelligent dialogue systems . Challenges for the task mainly lie in how to interact between the context and the knowledge, and how to match between the response and the context-knowledge pair. Existing work mainly focuses on exploiting global or local interaction matching information, and hence cannot fully utilize the information. In this paper, we propose a global and local interaction matching model (GLIMM) that matches a response with the context-knowledge pair from global and local views. For global interaction matching, GLIMM takes the context and the knowledge as long sequences. For local interaction matching, GLIMM treats each context utterance and knowledge sentence separately. GLIMM integrates information from two different views that could provide complementary information for each other. Experiments on two datasets show that the proposed model outperforms the state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Hui Ma and Jian Wang and Hongfei Lin and Liang Yang},
  doi          = {10.1016/j.neucom.2022.05.012},
  journal      = {Neurocomputing},
  pages        = {39-49},
  shortjournal = {Neurocomputing},
  title        = {Global and local interaction matching model for knowledge-grounded response selection in retrieval-based chatbots},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Position-aware image captioning with spatial relation.
<em>NEUCOM</em>, <em>497</em>, 28–38. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image caption aims to generate a language description of a given image. The problem can be solved by learning semantic information of visual objects and generating descriptions based on extracted embedding. However, the spatial relationship between visual objects and their static position is not fully explored by existing methods. In this work, we propose a Position-Aware Transformer (PAT) model that extracts both regional and static global visual features and unify both the regional and global by incorporating spatial information aligned to each visual feature. To make a better representation of spatial information and correlation between extracted visual features, we propose and compare three subtle approaches to explore position embedding with spatial relation information explicitly. Moreover, we jointly consider the static global and regional embedding for spatial modeling. Experimental results illustrate that our proposed model achieves competitive performance on the COCO image captioning dataset, where the PAT model could respectively reach 38.7, 28.6, and 58.6 on BLEU-4, METEOR, and ROUGE-L respectively. Extensive experiments suggest that the proposed PAT model could also reach competitive performance on related visual-language tasks including visual question answering (VQA) and multi-modal retrieval. Detailed ablation studies are conducted to report how each part would contribute to the final performance, which could be a good reference for follow-up spatial information representation works.},
  archive      = {J_NEUCOM},
  author       = {Yiqun Duan and Zhen Wang and Jingya Wang and Yu-Kai Wang and Chin-Teng Lin},
  doi          = {10.1016/j.neucom.2022.05.003},
  journal      = {Neurocomputing},
  pages        = {28-38},
  shortjournal = {Neurocomputing},
  title        = {Position-aware image captioning with spatial relation},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new approach for evaluating node importance in complex
networks via deep learning methods. <em>NEUCOM</em>, <em>497</em>,
13–27. (<a href="https://doi.org/10.1016/j.neucom.2022.05.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation of node importance is a critical research topic in network science, widely applied in social networks, transport systems, and computer networks. Prior works addressing this topic either consider a single metric or assign weights for multiple metrics or select features by handcraft, which exist one-sidedness and subjectivity issues. In this paper, to tackle these problems, we propose a new approach named CGNN to identify influential nodes based on deep learning methods , including Convolutional Neural Networks (CNNs) and Graph Neural Networks (GNNs). CGNN obtains the feature matrices by the contraction algorithm and gets the labels by the Susceptible-Infected-Recovered (SIR) model, which will be leveraged for learning the hidden representations of nodes without utilizing any network metrics as features. We adopt three evaluation criteria to verify CGNN concerning effectiveness and distinguishability, including Kendall’s τ τ correlation coefficient, monotonicity index ( MI MI ), and ranking distribution function ( RDF RDF ). Nine baselines are employed to compare with CGNN on thirty synthetic networks and twelve real-world networks from different domains. Simulation results demonstrate that CGNN manifests better performance than the baselines, in which the values of τ τ are large and significantly increase, the values of MI MI approach to 1, and the points in the RDF RDF curves distribute more uniformly. These results may provide reference significance for controlling epidemic spreading and enhancing network robustness.},
  archive      = {J_NEUCOM},
  author       = {Min Zhang and Xiaojuan Wang and Lei Jin and Mei Song and Ziyang Li},
  doi          = {10.1016/j.neucom.2022.05.010},
  journal      = {Neurocomputing},
  pages        = {13-27},
  shortjournal = {Neurocomputing},
  title        = {A new approach for evaluating node importance in complex networks via deep learning methods},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel hierarchical feature selection method based on large
margin nearest neighbor learning. <em>NEUCOM</em>, <em>497</em>, 1–12.
(<a href="https://doi.org/10.1016/j.neucom.2022.05.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity of data has been increasing not only in the dimension of the data, but also in the interrelated class relationships. Pre-defined hierarchical structure of classes helps to model such relationships in a way, which divides the whole classification problem into a set of subtasks. Feature selection, known as a data preprocessing technique , aims to selecting useful feature to improve the performance of learning algorithms. However, the issue of close class relationships, especially under the same parent node in the hierarchical structure, is adverse to the feature selection. In this paper, we introduce a novel distance metric based feature selection method with large margin nearest neighbor strategy for the hierarchical classification problems. Different from other algorithms, our proposed method is to project the data into a low-dimensional feature space for learning correct metrics, and the weights of features will be indicated in the transformation matrix . A sparsity regularization and iterative optimization ensure that superior feature subsets can be selected. Experimental evaluation on several datasets with hierarchical class structure demonstrates that the proposed approach is comparable or better than some other state-of-the-art hierarchical feature selection methods.},
  archive      = {J_NEUCOM},
  author       = {Jian Zheng and Chuan Luo and Tianrui Li and Hongmei Chen},
  doi          = {10.1016/j.neucom.2022.05.016},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {A novel hierarchical feature selection method based on large margin nearest neighbor learning},
  volume       = {497},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Revisiting audio visual scene-aware dialog. <em>NEUCOM</em>,
<em>496</em>, 227–237. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio Visual Scene-Aware Dialog (AVSD) has drawn intense interests, in which models are required to understand dynamic scenes in videos and dialog contexts in order to converse with human users by generating responses to given questions. Existing works have laid a solid foundation towards solving the AVSD problem. In contrast to previous studies, this paper empirically revisits the AVSD task and argues that this task exhibits a variety of biases in terms of models, dataset, and evaluation metrics : (1) as for the models, we believe that the state-of-the-art frameworks do not utilize multimodal features to their full extent; (2) as for the dataset, we conduct a deep analysis into dataset statistics from different types of questions and find that the dataset is slightly biased in several specific aspects; by simply implementing a caption-only baseline that has never seen the video, we achieve state-of-the-art performance on the AVSD task; (3) as for the evaluation metrics , we argue that the current metrics for AVSD primarily focus on the naturalness of generated responses while ignoring the truthfulness, which makes them fall short of disclosing the consistency of model predictions and the actual visual content. Overall, our analysis aims to provide a detailed inspection of the AVSD task and we hope that our empirical observations can inspire further improvement to the task.},
  archive      = {J_NEUCOM},
  author       = {Aishan Liu and Huiyuan Xie and Xianglong Liu and Zixin Yin and Shunchang Liu},
  doi          = {10.1016/j.neucom.2021.08.151},
  journal      = {Neurocomputing},
  pages        = {227-237},
  shortjournal = {Neurocomputing},
  title        = {Revisiting audio visual scene-aware dialog},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge graph informed fake news classification via
heterogeneous representation ensembles. <em>NEUCOM</em>, <em>496</em>,
208–226. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing amounts of freely available data both in textual and relational form offers exploration of richer document representations, potentially improving the model performance and robustness. An emerging problem in the modern era is fake news detection—many easily available pieces of information are not necessarily factually correct, and can lead to wrong conclusions or are used for manipulation. In this work we explore how different document representations, ranging from simple symbolic bag-of-words, to contextual, neural language model-based ones can be used for efficient fake news identification. One of the key contributions is a set of novel document representation learning methods based solely on knowledge graphs, i.e., extensive collections of (grounded) subject-predicate-object triplets. We demonstrate that knowledge graph-based representations already achieve competitive performance to conventionally accepted representation learners. Furthermore, when combined with existing, contextual representations, knowledge graph-based document representations can achieve state-of-the-art performance. To our knowledge this is the first larger-scale evaluation of how knowledge graph-based representations can be systematically incorporated into the process of fake news classification.},
  archive      = {J_NEUCOM},
  author       = {Boshko Koloski and Timen Stepišnik Perdih and Marko Robnik-Šikonja and Senja Pollak and Blaž Škrlj},
  doi          = {10.1016/j.neucom.2022.01.096},
  journal      = {Neurocomputing},
  pages        = {208-226},
  shortjournal = {Neurocomputing},
  title        = {Knowledge graph informed fake news classification via heterogeneous representation ensembles},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning for weakly-supervised object detection and
localization: A survey. <em>NEUCOM</em>, <em>496</em>, 192–207. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly-Supervised Object Detection (WSOD) and Localization (WSOL), i.e ., detecting multiple and single instances with bounding boxes in an image using image-level labels, are long-standing and challenging tasks in object detection. Hundreds of WSOD and WSOL methods and numerous techniques have been proposed in the deep learning era. To this end, in this paper, we consider WSOL as a sub-task of WSOD and provide a comprehensive survey of the recent achievements of WSOD. Specifically, we firstly describe the formulation and setting of the WSOD, including the background, challenges, basic framework. Meanwhile, we summarize and analyze all advanced techniques and training and test tricks for improving detection performance. Then, we introduce the widely-used datasets and evaluation metrics of WSOD. Lastly, we discuss the future directions of WSOD. We believe that these summaries can help pave a way for future research on WSOD and WSOL.},
  archive      = {J_NEUCOM},
  author       = {Feifei Shao and Long Chen and Jian Shao and Wei Ji and Shaoning Xiao and Lu Ye and Yueting Zhuang and Jun Xiao},
  doi          = {10.1016/j.neucom.2022.01.095},
  journal      = {Neurocomputing},
  pages        = {192-207},
  shortjournal = {Neurocomputing},
  title        = {Deep learning for weakly-supervised object detection and localization: A survey},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FeatInter: Exploring fine-grained object features for
video-text retrieval. <em>NEUCOM</em>, <em>496</em>, 178–191. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we target the challenging task of video-text retrieval. The common way for this task is to learn a text-video joint embedding space by cross-modal representation learning , and compute the cross-modality similarity in the joint space. As videos typically contain rich information, how to represent videos in a joint embedding space is crucial for video-text retrieval. The majority of works typically depend on pre-extracted frame-level features or clip-level features for video representation, which may cause fine-grained object information in videos to be ignored. To alleviate it, we explicitly introduce more fine-grained object-level features to enrich video representation. In order to exploit the potential of the object-level features, we propose a new model named FeatInter , which jointly considers the visual and semantic features of objects. Besides, a visual-semantic interaction and a cross-feature interaction are proposed to mutually enhance object features and frame features. Extensive experiments on two challenging video datasets, i.e., MSR-VTT and TGIF, demonstrate the effectiveness of our proposed model. Moreover, our model achieves a new state-of-the-art on TGIF. While the state-of-the-art methods use seven video features on MSR-VTT, our model with just three features obtains comparable performance.},
  archive      = {J_NEUCOM},
  author       = {Baolong Liu and Qi Zheng and Yabing Wang and Minsong Zhang and Jianfeng Dong and Xun Wang},
  doi          = {10.1016/j.neucom.2022.01.094},
  journal      = {Neurocomputing},
  pages        = {178-191},
  shortjournal = {Neurocomputing},
  title        = {FeatInter: Exploring fine-grained object features for video-text retrieval},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-modal image retrieval with deep mutual information
maximization. <em>NEUCOM</em>, <em>496</em>, 166–177. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the cross-modal image retrieval , where the inputs contain a source image plus some text that describes certain modifications to this image and the desired image. Prior work usually uses a three-stage strategy to tackle this task: 1) extracting the features of the inputs; 2) fusing the features of the source image and its modified text to obtain the fusion feature ; 3) learning a similarity metric between the desired image and the source image plus modified text via deep metric learning. Since classical image/text encoders can learn useful representations and common pair-based loss functions of distance metric learning are enough for cross-modal retrieval, people usually improve retrieval accuracy by designing new fusion networks. However, these methods do not successfully handle the modality gap caused by the inconsistent feature distributions of different modalities, which greatly influences the feature fusion and the similarity learning. To alleviate this problem, we apply the contrastive self-supervised learning method Deep InfoMax (DIM) [1] to our approach to bridge this gap by enhancing the dependence between the text, the image, and their fusion. Specifically, our method narrows the modality gap between the text modality and the image modality by maximizing mutual information between their semantically inconsistent representations. Moreover, we seek an effective common subspace for the semantically consistent features of the fusion and the desired images by utilizing Deep InfoMax between the low-level layer of the image encoder and the high-level layer of the fusion network. Extensive experiments on three large-scale benchmarks show that we have bridged the modality gap between different modalities and achieve the state-of-the-art retrieval performance .},
  archive      = {J_NEUCOM},
  author       = {Chunbin Gu and Jiajun Bu and Xixi Zhou and Chengwei Yao and Dongfang Ma and Zhi Yu and Xifeng Yan},
  doi          = {10.1016/j.neucom.2022.01.078},
  journal      = {Neurocomputing},
  pages        = {166-177},
  shortjournal = {Neurocomputing},
  title        = {Cross-modal image retrieval with deep mutual information maximization},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Role of astrocytes in the self-repairing characteristics of
analog neural networks. <em>NEUCOM</em>, <em>496</em>, 158–165. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-repair is fundamental to biological neural networks . In a neural network with a large number of elements, the probability of failure of each component increases. With the breakdown of each part, there may be a significant difference in the final results that will be completely affected by this defect. The existence of a process for detecting the error and compensating it by recruiting healthy elements leads to improved performance. This is where adjacent synapses proxy faulty synapses to avoid disturbances in the network function, thereby compensating the incurred error. In the present research, a self-repairing analog circuit is designed based on an astrocyte-neuron interaction and new synapse architecture. The designed circuit builds upon a software model of an astrocyte-neuron network with the proven ability to detect errors and undertake self-repair. The results obtained from our circuit show that, when an error occurs in the synapses associated with a neuron, the currents within functioning synapses of the same neuron increase. This increase is made by receiving feedback from adjacent astrocytes and other synapses. The process maintains the network function, compensating incurred errors in the network, presenting a neural network-based analog circuit with self-repairing capability, while considering the effect of astrocytes. In this paper, extensive simulation results using HSPICE with 0.35 μm CMOS technology are provided for the evaluation of the proposed circuit.},
  archive      = {J_NEUCOM},
  author       = {Negin Veisi and Gholamreza Karimi and Mahnaz Ranjbar and Derek Abbott},
  doi          = {10.1016/j.neucom.2022.01.077},
  journal      = {Neurocomputing},
  pages        = {158-165},
  shortjournal = {Neurocomputing},
  title        = {Role of astrocytes in the self-repairing characteristics of analog neural networks},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Model design for networks of heterogeneous hodgkin–huxley
neurons. <em>NEUCOM</em>, <em>496</em>, 147–157. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel modular, scalable and adaptable modelling framework to accurately model neuronal networks composed of neurons with different dynamic properties and distinct firing patterns based on a control-inspired feedback structure. We consider three important classes of neurons: inhibitory Fast spiking neurons, excitatory regular spiking with adaptations neurons, and excitatory intrinsic bursting neurons. We also take into consideration two basic means of neuronal interconnection: electrical and chemical synapses . By separating the neuronal dynamics from the network dynamics, we have developed a fully flexible feedback structure that can be further augmented to incorporate additional types of neurons and/or synapses. We use an augmented version of the Hodgkin–Huxley model to describe the individual neuron dynamics and graph theory to define the network structure. We provide simulation results for small fundamental neuron motifs as well as bigger neuronal networks and we verify the accuracy, flexibility and scalability of the proposed method. Therefore, we provide the basis for a comprehensive modelling framework that is able to imitate the dynamics of individual neurons and neuronal networks and is able to replicate basic normal brain function. The structure of the proposed framework is ideal for applications of control and optimization methods both for modelling the effect of pharmacological substances as well as for modelling diseased neuron and network conditions.},
  archive      = {J_NEUCOM},
  author       = {A.G. Giannari and A. Astolfi},
  doi          = {10.1016/j.neucom.2022.04.115},
  journal      = {Neurocomputing},
  pages        = {147-157},
  shortjournal = {Neurocomputing},
  title        = {Model design for networks of heterogeneous Hodgkin–Huxley neurons},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Hybrid supervised instance segmentation by learning label
noise suppression. <em>NEUCOM</em>, <em>496</em>, 131–146. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reach top accuracy, current fully supervised instance segmentation methods severely rely on large-scale pixel-wise labeled datasets. They are usually expensive and time-consuming to obtain. Though weakly or semi-supervised methods utilize cheap bounding box labeled, image-level labeled or unlabeled samples to save the labeling cost, their performance is largely sacrificed. To save labeling cost without losing much performance, in this paper, we present a pipeline that can utilize economical bounding box labels and accurate pixel-wise labels in a hybrid way. Specifically, we design two ancillary models to learn label noise suppression and obtain accurate pseudo pixel-wise labels from bounding box labels for training. One is designed to suppress mislabeling between foreground and background, and the other is designed to suppress noise from mislabeling of instances. Moreover, we exploit category-aware spatial attention module, category constraint module, instance constraint module, and self-learning training approach to improve the accuracy of pseudo labels. Experiments on the PASCAL VOC 2012 and the Cityscapes datasets show that our method can achieve competitive performance with much less labeling cost.},
  archive      = {J_NEUCOM},
  author       = {Linwei Chen and Ying Fu and Shaodi You and Hongzhe Liu},
  doi          = {10.1016/j.neucom.2022.05.026},
  journal      = {Neurocomputing},
  pages        = {131-146},
  shortjournal = {Neurocomputing},
  title        = {Hybrid supervised instance segmentation by learning label noise suppression},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learn-to-adapt: Concept drift adaptation for hybrid multiple
streams. <em>NEUCOM</em>, <em>496</em>, 121–130. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing concept drift adaptation (CDA) methods aim to continually update outdated classifiers in a single-labeled stream scenario. However, real-world data streams are massive, with hybrids of labeled and unlabeled streams. In this paper, we discuss CDA in multiple data streams that may contain unlabeled drifting streams. To address this realistic and complex problem, we rethink the concept drift problem by adopting a meta-learning approach and introduce a L earn-to- A dapt framework ( L 2 A ). The L 2 A framework simultaneously 1) makes adaptations for drifting labeled streams, and 2) leverages knowledge from labeled drifting streams to make adaptations for unlabeled stream prediction. In L 2 A , a meta-representor with an adapter in the meta-training stage is designed to learn the invariant representations for drifting streams, enabling the model to quickly produce a good generalization of new concepts with limited training samples. In the online stage, the meta-representor will be adapted continually under the control of the adapter and will contribute to adapting the classifiers for unlabeled drifting stream prediction. Compared to existing CDA methods which mostly only adapt the classifiers, L 2 A adapts the feature extractor and classifier in a feedback process, which is advanced in dealing with more complex and high-dimensional data streams.},
  archive      = {J_NEUCOM},
  author       = {En Yu and Yiliao Song and Guangquan Zhang and Jie Lu},
  doi          = {10.1016/j.neucom.2022.05.025},
  journal      = {Neurocomputing},
  pages        = {121-130},
  shortjournal = {Neurocomputing},
  title        = {Learn-to-adapt: Concept drift adaptation for hybrid multiple streams},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective optimization-based adaptive class-specific
cost extreme learning machine for imbalanced classification.
<em>NEUCOM</em>, <em>496</em>, 107–120. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced classification is a challenging task in the fields of machine learning and data mining. Cost-sensitive learning can tackle this issue by considering different misclassification costs of classes. Weighted extreme learning machine (W-ELM) takes a cost-sensitive strategy to alleviate the learning bias towards the majority class to achieve better classification performance. However, W-ELM may not achieve the optimal weights for the samples from different classes due to the adoption of empirical costs. In order to solve this issue, multi-objective optimization-based adaptive class-specific cost extreme learning machine (MOAC-ELM) is presented in this paper. To be specific, the initial weights are first assigned depending on the class information. Based on that, the representation of the minority class could be enhanced by adding penalty factors. In addition, a multi-objective optimization with respect to penalty factors is formulated to automatically determine the class-specific costs, in which multiple performance criteria are constructed by comprehensively considering the misclassification rate and generalization gap. Finally, ensemble strategy is implemented to make decisions after optimization. Accordingly, the proposed MOAC-ELM is an adaptive method with good robustness and generalization performance for imbalanced classification problems. Comprehensive experiments have been performed on several benchmark datasets and a real-world application dataset. The statistical results demonstrate that MOAC-ELM can achieve competitive results on classification performance.},
  archive      = {J_NEUCOM},
  author       = {Yanjiao Li and Jie Zhang and Sen Zhang and Wendong Xiao and Zhiqiang Zhang},
  doi          = {10.1016/j.neucom.2022.05.008},
  journal      = {Neurocomputing},
  pages        = {107-120},
  shortjournal = {Neurocomputing},
  title        = {Multi-objective optimization-based adaptive class-specific cost extreme learning machine for imbalanced classification},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rough maximal cliques enumeration in incomplete graphs based
on partially-known concept learning. <em>NEUCOM</em>, <em>496</em>,
96–106. (<a href="https://doi.org/10.1016/j.neucom.2021.08.160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emerging massive noisy and incomplete data is transforming the conventional graph to the uncertain graph. In this paper, we study rough maximal cliques enumeration (RMCE) in incomplete graphs, which we define as the novel problem of enumerating all maximal cliques where some of edges are unknown to users. The hardness of RMCE is proved to NP-complete. To tackle this problem, an efficient framework for obtaining the rough maximal cliques based on P artially- K nown C oncept L earning (PKCL). With this framework, a given incomplete graph is initially represented as an incomplete formal context. Then, the partially-known SE-ISI concept lattice is generated through the constructed incomplete formal context. Based on the constructed SE-ISI concept lattice , an equivalence theorem between SE-ISI equiconcepts and rough maximal cliques is presented. The detailed topological structural analysis from the point of views of roughness and SE-ISI concept stability of rough maximal cliques are separately discussed. The evaluation results demonstrate that our proposed PKCL algorithm can better identify the rough maximal cliques under different probability distribution models of links compared to the existing baseline algorithms.},
  archive      = {J_NEUCOM},
  author       = {Fei Hao and Yifei Sun and Yaguang Lin},
  doi          = {10.1016/j.neucom.2021.08.160},
  journal      = {Neurocomputing},
  pages        = {96-106},
  shortjournal = {Neurocomputing},
  title        = {Rough maximal cliques enumeration in incomplete graphs based on partially-known concept learning},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discrete-time dynamic graph echo state networks.
<em>NEUCOM</em>, <em>496</em>, 85–95. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relations between entities evolving through discrete time-steps can be represented by discrete-time dynamic graphs. Examples include hourly interactions between social network users or daily infection spreading. In this paper, we present Dynamic Graph Echo State Network (DynGESN), a reservoir computing model for the efficient processing of discrete-time dynamic temporal graphs. We prove a sufficient condition for the echo state property, which ensures that graph embeddings are independent of initial conditions, and we briefly analyze reservoir dynamics. DynGESN is compared against temporal graph kernels (TGKs) on twelve graph classification tasks, and against ten different end-to-end trained temporal graph convolutional networks (TGNs) on four vertex regression tasks, since TGKs are limited to graph-level tasks. Compared to TGKs that need to hold the entire history of vertex interactions, our model provides a vector encoding for the dynamic graph that is updated at each time-step without requiring training. Experiments show that our model achieves accuracy in line with TGKs that have comparable computational complexity, while still offering space and time requirements better suited to scale to large-size data. Moreover, DynGESN overall achieves superior or on par accuracy with respect to TGNs, while improving efficiency by up ten times on inference and training time.},
  archive      = {J_NEUCOM},
  author       = {Alessio Micheli and Domenico Tortorella},
  doi          = {10.1016/j.neucom.2022.05.001},
  journal      = {Neurocomputing},
  pages        = {85-95},
  shortjournal = {Neurocomputing},
  title        = {Discrete-time dynamic graph echo state networks},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust landmark graph-based clustering for high-dimensional
data. <em>NEUCOM</em>, <em>496</em>, 72–84. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional data has attracted much attention because it contains more comprehensive information about samples. How to cluster these high-dimensional data has become a crucial topic in unsupervised learning . Existing clustering methods often show limited applicability due to their high computational complexity and low anti-noise ability. To address this issue, we propose a novel robust landmark graph-based clustering algorithm for high-dimensional data (RLGCH), which inherits the advantages of both k-means++ and graph-based clustering by using the results of k-means++ as pseudo labels for landmark graph-based clustering. In particular, RLGCH can achieve more reasonable clustering effectiveness than methods that just operate in the low-dimensional space or the original space since it performs k-means++ in the low-dimensional space and landmark graph-based spectral clustering in the original feature space. To avoid post-processing after optimization, the embedded factor matrix is constrained as an indicator matrix rather than a simple nonnegative matrix. To enhance the clustering robustness, the L 2 , 1 L2,1 -norm is adopted to minimize the error of results between k-means++ and landmark graph-based clustering. To solve the model of RLGCH, we established a novel efficient optimization strategy to obtain all sample categories directly. Combining our clustering model and optimization strategy , the computational complexity is reduced to linear and insensitive to data dimensions. Extensive experiments on seven real-world datasets and sixteen noisy datasets show that compared with other state-of-the-art methods, RLGCH can improve the clustering efficiency and robustness greatly while guaranteeing comparable or even better clustering effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Ben Yang and Jinghan Wu and Aoran Sun and Naying Gao and Xuetao Zhang},
  doi          = {10.1016/j.neucom.2022.05.011},
  journal      = {Neurocomputing},
  pages        = {72-84},
  shortjournal = {Neurocomputing},
  title        = {Robust landmark graph-based clustering for high-dimensional data},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of structural representation learning for social
networks. <em>NEUCOM</em>, <em>496</em>, 56–71. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks have a plethora of applications, and analysis of these applications has been gaining much interest from the research community. The high dimensionality of social network data poses a significant obstacle in its analysis, leading to the curse of dimensionality. The mushrooming of representation learning in various research fields facilitates network representation learning (also called network embedding), which will help us address the above-mentioned issue. Structural Representation Learning aims to learn low-dimensional vector representations of high-dimensional network data, allowing maximal preservation of network structural information. This representation can then serve as a backbone for various network-based applications. First, we investigate the techniques used in network representation learning and similarity indices. We then categorize the representative algorithms into three types based on the network structural level used in their learning process. We also introduce algorithms for representation learning of edges, subgraphs, and the whole network. Finally, we introduce the evaluation metrics and the applications of network representation learning and promising future research directions.},
  archive      = {J_NEUCOM},
  author       = {Qi Luo and Dongxiao Yu and Akshita Maradapu Vera Venkata Sai and Zhipeng Cai and Xiuzhen Cheng},
  doi          = {10.1016/j.neucom.2022.04.128},
  journal      = {Neurocomputing},
  pages        = {56-71},
  shortjournal = {Neurocomputing},
  title        = {A survey of structural representation learning for social networks},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Graph based emotion recognition with attention pooling for
variable-length utterances. <em>NEUCOM</em>, <em>496</em>, 46–55. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous speech emotion recognition (SER) methods normally deal with variable-length utterance inputs by padding shorter ones or clipping longer ones into equal-length utterances, which may introduce invalid information or discard useful emotional segments. To address this issue, in this paper, we cast the SER problem into a graph classification task by transforming variable-length utterances into graphs to avoid padding or cutting. In our approach, frames (short windowed segments) in an utterance are presented as nodes in a graph. Acoustic features extracted from frames are treated as node feature vectors and nodes are connected according to their temporal relationship. Different graph convolutional networks (GCNs) are explored for node/frame embedding learning, and kinds of graph pooling methods are compared to obtain graph/utterance-level emotional representation from node embeddings . Extensive experiments with different GCN components and pooling mechanisms are conducted on the IEMOCAP and MSP-IMPRO datasets. The experimental results show that a combination of GraphSAGE with multi-head attention pooling (MHAPool) achieves the best weighted accuracy (WA) and comparable unweighted accuracy (UA) on both datasets compared with other state-of-the-art SER models, which demonstrates the effectiveness of the proposed graph-based network for SER task.},
  archive      = {J_NEUCOM},
  author       = {Jiawang Liu and Haoxiang Wang and Mingze Sun and Yao Wei},
  doi          = {10.1016/j.neucom.2022.05.007},
  journal      = {Neurocomputing},
  pages        = {46-55},
  shortjournal = {Neurocomputing},
  title        = {Graph based emotion recognition with attention pooling for variable-length utterances},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A neural refinement network for single image view synthesis.
<em>NEUCOM</em>, <em>496</em>, 35–45. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen an increasing interest in single image view synthesis. It remains however a challenging task due to the lack of comprehensive colour and depth information from different views. In this paper, we propose a novel view synthesis approach that incorporates a Neural Image Refinement Network (NIRN) and generates both depth and colour images for the target view in an end-to-end manner. The appearance of the colour image greatly benefits from the generated depth image as it provides an intermediate projection relationship for the object in the 3D world. Since the direct application of geometric projection mapping will result in empty regions and/or distortions, our approach proposes to embed a novel refinement network into the view synthesis pipeline for improved performance. Experimental results on three publicly available datasets demonstrate that our NIRN outperforms other state-of-the-art view synthesis methods.},
  archive      = {J_NEUCOM},
  author       = {Lei Jiang and Haibin Cai and Gerald Schaefer and Qinggang Meng},
  doi          = {10.1016/j.neucom.2022.04.123},
  journal      = {Neurocomputing},
  pages        = {35-45},
  shortjournal = {Neurocomputing},
  title        = {A neural refinement network for single image view synthesis},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-adaptive loss balanced physics-informed neural
networks. <em>NEUCOM</em>, <em>496</em>, 11–34. (<a
href="https://doi.org/10.1016/j.neucom.2022.05.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks (PINNs) have received significant attention as a representative deep learning-based technique for solving partial differential equations (PDEs). The loss function of PINNs is a weighted sum of multiple terms, including the mismatch of observed data, boundary and initial constraints, as well as PDE residuals. In this paper, we observe that the performance of PINNs is susceptible to the weighted combination of competitive multiple loss functions. Therefore, we establish Gaussian probabilistic models to define the self-adaptive loss function through the adaptive weights for each loss term. In particular, we propose a self-adaptive loss balanced method that automatically assigns the weights of losses by updating adaptive weights in each epoch based on the maximum likelihood estimation. Finally, we perform a series of numerical experiments with self-adaptive loss balanced physics-informed neural networks (lbPINNs), including solving Poisson, Burgers, Helmholtz, Navier–Stokes, and Allen–Cahn equations in regular and irregular areas. We also test the robustness of lbPINNs by varying the initial adaptive weights, numbers of observations, hidden layers, and neurons per layer. These experimental results demonstrate that lbPINNs consistently achieve better performance than PINNs, and reduce the relative L2 error by about two orders of magnitude.},
  archive      = {J_NEUCOM},
  author       = {Zixue Xiang and Wei Peng and Xu Liu and Wen Yao},
  doi          = {10.1016/j.neucom.2022.05.015},
  journal      = {Neurocomputing},
  pages        = {11-34},
  shortjournal = {Neurocomputing},
  title        = {Self-adaptive loss balanced physics-informed neural networks},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Memristive residual CapsNet: A hardware friendly multi-level
capsule network. <em>NEUCOM</em>, <em>496</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capsule network is a promising network architecture in computer vision that integrates feature information and feature relationships of images. However, the original capsule network performs poorly with complex datasets, and the network is computationally intensive, which is not conducive to deployment in end-side devices. In this paper, a novel hardware-friendly capsule network named MRCapsNet is proposed to improve the performance of the capsule network and make it deployable in end-side devices. In the proposed network, the multi-level residual capsule block is constructed to extract features with multi-granularity from images. Moreover, a novel reconstruction subnetwork is designed to facilitate network training. Experiments show that MRCapsNet achieved competitive results on the CIFAR-10 (90.34\%\% ) and SVHN (96.59\%\% ) datasets compared with other variants of CapsNet. Further, the hardware implementation scheme of MRCapsNet based on memristor crossbars is designed to provide a nano-scale, low-power capsule network deployment scheme. Finally, the power consumption of the core computing unit built by memristor elements is analyzed and calculated, and the maximum power consumption of a memristive neuron is only 6.4 μ μ W during the inference of the network, which is significantly less than the CMOS-based circuit.},
  archive      = {J_NEUCOM},
  author       = {Peng He and Yue Zhou and Shukai Duan and Xiaofang Hu},
  doi          = {10.1016/j.neucom.2022.04.088},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {Memristive residual CapsNet: A hardware friendly multi-level capsule network},
  volume       = {496},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unified structure learning framework for graph attention
networks. <em>NEUCOM</em>, <em>495</em>, 194–204. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have achieved state-of-the-art performance in many fields and attracted a lot of attention in the communit. Most Graph Neural Networks can be merely used when graph-structured data is available. However, many graph structures have noise, or data itself has no graph structures, so learning the dynamic and adaptive graph structures is necessary. In this paper, we propose a unified structure learning framework for Graph Attention Networks. Specifically, we first design a strategy to learn the graph structures. Then we develop a novel attention mechanism based on structure context information of graph and node representations. Further, we devise Structure Learning Graph Attention Networks (SLGAT) and Structure Learning Attention-based Graph Neural Networks (SLAGNN) by using the new attention mechanism on the new graph. Finally, we demonstrate that our approaches outperform competing methods on six standard datasets for the semi-supervised node classification task.},
  archive      = {J_NEUCOM},
  author       = {Jinliang Yuan and Meng Cao and Hao Cheng and Hualei Yu and Junyuan Xie and Chongjun Wang},
  doi          = {10.1016/j.neucom.2022.01.064},
  journal      = {Neurocomputing},
  pages        = {194-204},
  shortjournal = {Neurocomputing},
  title        = {A unified structure learning framework for graph attention networks},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explaining adversarial vulnerability with a data sparsity
hypothesis. <em>NEUCOM</em>, <em>495</em>, 178–193. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite many proposed algorithms to provide robustness to deep learning (DL) models, DL models remain susceptible to adversarial attacks . We hypothesize that the adversarial vulnerability of DL models stems from two factors. The first factor is data sparsity which is that in the high dimensional input data space, there exist large regions outside the support of the data distribution. The second factor is the existence of many redundant parameters in the DL models. Owing to these factors, different models are able to come up with different decision boundaries with comparably high prediction accuracy. The appearance of the decision boundaries in the space outside the support of the data distribution does not affect the prediction accuracy of the model. However, it makes an important difference in the adversarial robustness of the model. We hypothesize that the ideal decision boundary is as far as possible from the support of the data distribution. In this paper, we develop a training framework to observe if DL models are able to learn such a decision boundary spanning the space around the class distributions further from the data points themselves. Semi-supervised learning was deployed during training by leveraging unlabeled data generated in the space outside the support of the data distribution. We measured adversarial robustness of the models trained using this training framework against well-known adversarial attacks and by using robustness metrics. We found that models trained using our framework, as well as other regularization methods and adversarial training support our hypothesis of data sparsity and that models trained with these methods learn to have decision boundaries more similar to the aforementioned ideal decision boundary. We show that the unlabeled data generated by noise in our framework is almost as effective on adversarial robustness as unlabeled data sourced from existing datasets or generated by synthesis algorithms. The code for our training framework is available online.},
  archive      = {J_NEUCOM},
  author       = {Mahsa Paknezhad and Cuong Phuc Ngo and Amadeus Aristo Winarto and Alistair Cheong and Chuen Yang Beh and Jiayang Wu and Hwee Kuan Lee},
  doi          = {10.1016/j.neucom.2022.01.062},
  journal      = {Neurocomputing},
  pages        = {178-193},
  shortjournal = {Neurocomputing},
  title        = {Explaining adversarial vulnerability with a data sparsity hypothesis},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient person search via learning-to-normalize deep
representation. <em>NEUCOM</em>, <em>495</em>, 169–177. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of person search is to search for the target pedestrian in the scene images with the given query image, which means to perform detection and re-identification at the same time. In this paper, we propose a one-step method to jointly handle the two subtasks of person search using an end-to-end framework. The proposed framework contains the feature learning module and the multi-task learning module. We explore the performance of learning-to-normalize deep representation on the feature learning module, which allows the network to achieve normalizer selection on each normalization layer. To solve the imbalance problem of hard-to-classify examples, we introduce the focal loss in the multi-task learning module. Besides, we adopt the gradient generalization centralization technique, which makes the training process more stable and enhances the generalization ability of the model. We present extensive experiments on two benchmark datasets, i.e., CUHK-SYSU and PRW. Experimental results prove that our method outperforms the state-of-the-art one-step methods and has a competitive performance compared with two-step methods.},
  archive      = {J_NEUCOM},
  author       = {Ning Lv and Xuezhi Xiang and Xinyao Wang and Jie Yang and Rokia Abdein},
  doi          = {10.1016/j.neucom.2022.01.028},
  journal      = {Neurocomputing},
  pages        = {169-177},
  shortjournal = {Neurocomputing},
  title        = {Efficient person search via learning-to-normalize deep representation},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CDiNN – convex difference neural networks. <em>NEUCOM</em>,
<em>495</em>, 153–168. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks with ReLU activation function have been shown to be universal function approximators and learn function mapping as non-smooth functions. Recently, there is considerable interest in the use of neural networks in applications such as optimal control. It is well-known that optimization involving non-convex, non-smooth functions are computationally intensive and have limited convergence guarantees. Moreover, the choice of optimization hyper-parameters used in gradient descent/ascent significantly affect the quality of the obtained solutions. A new neural network architecture called the Input Convex Neural Networks (ICNNs) learn the output as a convex function of inputs thereby allowing the use of efficient convex optimization methods. Use of ICNNs for determining the input for minimizing output has two major problems: learning of a non-convex function as a convex mapping could result in significant function approximation error, and we also note that the existing representations cannot capture simple dynamic structures like linear time delay systems. We attempt to address the above problems by introduction of a new neural network architecture, which we call the CDiNN, which learns the function as a difference of polyhedral convex functions from data. We also discuss that, in some cases, the optimal input can be obtained from CDiNN through difference of convex optimization with convergence guarantees and that at each iteration, the problem is reduced to a linear programming problem.},
  archive      = {J_NEUCOM},
  author       = {Parameswaran Sankaranarayanan and Raghunathan Rengaswamy},
  doi          = {10.1016/j.neucom.2022.01.024},
  journal      = {Neurocomputing},
  pages        = {153-168},
  shortjournal = {Neurocomputing},
  title        = {CDiNN – convex difference neural networks},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Object recognition datasets and challenges: A review.
<em>NEUCOM</em>, <em>495</em>, 129–152. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object recognition is among the fundamental tasks in the computer vision applications, paving the path for all other image understanding operations. In every stage of progress in object recognition research, efforts have been made to collect and annotate new datasets to match the capacity of the state-of-the-art algorithms. In recent years, the importance of the size and quality of datasets has been intensified as the utility of the emerging deep network techniques heavily relies on training data. Furthermore, datasets lay a fair benchmarking means for competitions and have proved instrumental to the advancements of object recognition research by providing quantifiable benchmarks for the developed models. Taking a closer look at the characteristics of commonly-used public datasets seems to be an important first step for data-driven and machine learning researchers. In this survey, we provide a detailed analysis of datasets in the highly investigated object recognition areas. More than 160 datasets have been scrutinized through statistics and descriptions. Additionally, we present an overview of the prominent object recognition benchmarks and competitions, along with a description of the metrics widely adopted for evaluation purposes in the computer vision community. All introduced datasets and challenges can be found online at github.com/AbtinDjavadifar/ORDC.},
  archive      = {J_NEUCOM},
  author       = {Aria Salari and Abtin Djavadifar and Xiangrui Liu and Homayoun Najjaran},
  doi          = {10.1016/j.neucom.2022.01.022},
  journal      = {Neurocomputing},
  pages        = {129-152},
  shortjournal = {Neurocomputing},
  title        = {Object recognition datasets and challenges: A review},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Chain centre loss: A psychology inspired loss function for
image sentiment analysis. <em>NEUCOM</em>, <em>495</em>, 118–128. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a novel loss function called a chain center loss for image sentiment analysis . The proposed loss is derived from two famous deep metric loss functions, a center loss and a triplet loss, for latent space construction. Specifically, inspired by both previous loss functions, the proposed loss supervises the local and global spatial distributions. As for the local spatial distribution, the chain center loss generates center points by the Gaussian distribution and integrates visual features extracted from the images of the same sentiment. Moreover, different from the previous deep metric measures, we newly introduce sentiment correlations revealed by psychology theories into the chain center loss to capture the global spatial distribution. Concretely, the proposed loss applies anchor-related-negative triplets to the loss computation inspired by the triplet loss and updates the center points with consideration of the correlations among sentiments. As a result, with the use of the proposed loss, a latent space that strongly represents sentiment correlations can be constructed with high robustness. Improvement in the performance of the chain center loss was confirmed from experimental results.},
  archive      = {J_NEUCOM},
  author       = {Yun Liang and Keisuke Maeda and Takahiro Ogawa and Miki Haseyama},
  doi          = {10.1016/j.neucom.2022.04.016},
  journal      = {Neurocomputing},
  pages        = {118-128},
  shortjournal = {Neurocomputing},
  title        = {Chain centre loss: A psychology inspired loss function for image sentiment analysis},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving NMF clustering by leveraging contextual
relationships among words. <em>NEUCOM</em>, <em>495</em>, 105–117. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-negative Matrix Factorization (NMF) and its variants have been successfully used for clustering text documents. However, NMF approaches like other models do not explicitly account for the contextual dependencies between words. To remedy this limitation, we draw inspiration from neural word embedding and posit that words that frequently co-occur within the same context (e.g., sentence or document) are likely related to each other in some semantic aspect. We then propose to jointly factorize the document-word and word-word co-occurrence matrices. The decomposition of the latter matrix encourages frequently co-occurring words to have similar latent representations and thereby reflecting the relationships among them. Empirical results, on several real-world datasets, provide strong support for the benefits of our approach. Our main finding is that we can drastically improve the clustering performance of NMF by leveraging the contextual relationships among words explicitly.},
  archive      = {J_NEUCOM},
  author       = {Mickael Febrissy and Aghiles Salah and Melissa Ailem and Mohamed Nadif Professor},
  doi          = {10.1016/j.neucom.2022.04.122},
  journal      = {Neurocomputing},
  pages        = {105-117},
  shortjournal = {Neurocomputing},
  title        = {Improving NMF clustering by leveraging contextual relationships among words},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using brain inspired principles to unsupervisedly learn good
representations for visual pattern recognition. <em>NEUCOM</em>,
<em>495</em>, 97–104. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep learning has solved difficult problems in visual pattern recognition, it is mostly successful in tasks where there are lots of labeled training data available. Furthermore, the global back-propagation based training rule and the amount of employed layers represents a departure from biological inspiration. The brain is able to perform most of these tasks in a very general way from limited to no labeled data. For these reasons it is still a key research question to look into computational principles in the brain that can help guide models to unsupervisedly learn good representations which can then be used to perform tasks like classification. To that end, we start by recalling four key brain-inspired principles that relate to simple vision: modeling ”whats” and ”wheres” separately; including a time component; context dependency; and layer-wise learning. Then, we take these principles and use them to convey an a priori structure to our model that makes the learning problem easier. With that, our model is able to generate such high quality representations for the MNIST data set. We compare the obtained results with similar recent works and verify extremely competitive results.},
  archive      = {J_NEUCOM},
  author       = {Luis Sa-Couto and Andreas Wichert},
  doi          = {10.1016/j.neucom.2022.04.130},
  journal      = {Neurocomputing},
  pages        = {97-104},
  shortjournal = {Neurocomputing},
  title        = {Using brain inspired principles to unsupervisedly learn good representations for visual pattern recognition},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Fixed-time stabilization and synchronization for fuzzy
inertial neural networks with bounded distributed delays and
discontinuous activation functions. <em>NEUCOM</em>, <em>495</em>,
86–96. (<a href="https://doi.org/10.1016/j.neucom.2022.04.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly describes the fixed-time (FXT) stabilization and synchronization for fuzzy inertial neural networks (FINNs). Firstly, the discontinuous system is treated by using differential inclusion theory. Then, in order to guarantee the FXT stabilization and synchronization of FINNs, we use the fixed-time stability (FTS) theories of dynamic systems and design two efficient feedback controllers . Unlike most previous articles, the neural system model with bounded distributed delays and discontinuous activation functions is studied in this paper. In the end, we provide numerical examples showing the validity of the outcomes obtained from the four theorems proved in this paper. At the same time, the simulation results intuitively show the speed of upper settling-time (ST) estimation of different outcomes.},
  archive      = {J_NEUCOM},
  author       = {Yang Liu and Guodong Zhang and Junhao Hu},
  doi          = {10.1016/j.neucom.2022.04.101},
  journal      = {Neurocomputing},
  pages        = {86-96},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time stabilization and synchronization for fuzzy inertial neural networks with bounded distributed delays and discontinuous activation functions},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Adaptive fault-tolerant control for nonlinear high-order
fully-actuated systems. <em>NEUCOM</em>, <em>495</em>, 75–85. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive fault-tolerant control (FTC) strategy is proposed for a class of high-order fully-actuated (HOFA) systems. A pre-closed-loop treatment is presented to simplify the observer design for the nonlinear system with actuator faults but it leads to a new problem that faults may not satisfy the observation matching conditions. Thus, an intermediate variable observer is introduced to adaptively estimate system states and actuator faults simultaneously. Then the influence of observation errors on system stability is analyzed by analyzing matrix singular value perturbation. Under the proposed adaptive FTC method, the closed-loop global uniformly ultimately bounded stability is achieved by Lyapunov synthesis. Finally, the effectiveness of the proposed FTC method is verified by simulations.},
  archive      = {J_NEUCOM},
  author       = {Xueqing Liu and Maoyin Chen and Li Sheng and Donghua Zhou},
  doi          = {10.1016/j.neucom.2022.04.129},
  journal      = {Neurocomputing},
  pages        = {75-85},
  shortjournal = {Neurocomputing},
  title        = {Adaptive fault-tolerant control for nonlinear high-order fully-actuated systems},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attribute-aware heterogeneous graph network for fashion
compatibility prediction. <em>NEUCOM</em>, <em>495</em>, 62–74. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fashion compatibility prediction aims to provide a compatibility score for a set of fashion combinations, making an effort to meet people’s needs for clothing matching in daily life. One difficulty of this problem is that whether the fashion items are compatible depends on a variety of attribute factors, such as design style, material, color. Existing works mostly use the attributes as the item feature representations or integrate attribute features into the compatibility modeling process as auxiliary information in a simple way. These works ignore the fine-grained attributes that can play a role as bridges in establishing the potential compatibility relationship between fashion items. To better take advantage of fashion attributes information, we propose an Attribute-aware Heterogeneous Graph Network (AHGN), which combines the fashion items and their attributes as a heterogeneous graph to integrate the heterogeneous information in the fashion compatibility problem. While fusing the fine-grained attribute information into the item nodes representation, the attributes act as bridges to transfer the characteristics of potential compatible fashion items into the target item node. Previous methods of calculating outfit score by item pairs without considering the effect of outfit compositions. An outfit-based item pairs scoring method is proposed. The feature representation of item pairs is adjusted by integrating the overall outfit information to consider the influence of the outfit environment on the item pairs. We conduct experiments on three tasks (fill-in-the-blank, compatibility prediction, and fashion item retrieval) in two real-world fashion datasets: Fashion32 and IQON3000. Experimental results demonstrate the effectiveness of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Zhouyi Zhou and Zhuo Su and Ruomei Wang},
  doi          = {10.1016/j.neucom.2022.04.121},
  journal      = {Neurocomputing},
  pages        = {62-74},
  shortjournal = {Neurocomputing},
  title        = {Attribute-aware heterogeneous graph network for fashion compatibility prediction},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A local-nonlocal mathematical morphology. <em>NEUCOM</em>,
<em>495</em>, 51–61. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical morphology (MM) is traditional and yet applied in many areas. Among the relevant researches, nonlocal extensions have been studied due to their advantages of adaptivity and nonlocal self-similarity. However, these extensions are fragile to noises and easily result in gray value deviation (the maximum grayscale value is changed significantly). In this paper, a local-nonlocal mathematical morphology (LNLMM) is proposed: we use flat structuring element (SE) to avoid gray value deviation and introduce local information to suppress noises. Moreover, to speed up the nonlocal computation involved, we construct the SE in low-dimensional space. Benefiting from the constraint of k-reciprocal nearest neighbors (KRNN) on the SE, the operators of LNLMM theoretically inherit the important mathematical properties from traditional MM, that gives solid supports in applications. With denoising experiments, the powerful performance of LNLMM is preliminarily verified.},
  archive      = {J_NEUCOM},
  author       = {Zhonggui Sun and Meiqi Lyu and Jie Li and Ying Wang and Xinbo Gao},
  doi          = {10.1016/j.neucom.2022.04.113},
  journal      = {Neurocomputing},
  pages        = {51-61},
  shortjournal = {Neurocomputing},
  title        = {A local-nonlocal mathematical morphology},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MulSimNet: A multi-branch sub-interest matching network for
personalized recommendation. <em>NEUCOM</em>, <em>495</em>, 37–50. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized recommendation serves as an indispensable functionality in many online services, where the key is to model the user’s preference based on past user-item interactions. Many well-known models learn a latent vector for each user and each item. Nevertheless, a single latent vector might not be able to well represent a user’s multifaceted interests revealed by the wide variety of items consumed by him/her. In this paper, we present a flexible framework named Mul ti-branch S ub- i nterest m atching Net work (MulSimNet) for personalized recommendation. Each user is explicitly represented by multiple sub-interest vectors as well as a general interest vector, and an item is matched against these vectors through different branches, where each branch is realized by appropriate neural networks. The compatibility scores output by multiple sub-interest matching branches are first aggregated via the max operator, which is then fused with the output of the general interest matching branch to estimate the user’s affinity with the item. A comprehensive set of experiments on benchmark datasets demonstrate the effectiveness of the proposed framework in fully capturing the user’s multifaceted interests and yielding better top-N recommendations.},
  archive      = {J_NEUCOM},
  author       = {Zerun Fu and Tao Lian and Yuanyuan Yao and Wen Zheng},
  doi          = {10.1016/j.neucom.2022.04.109},
  journal      = {Neurocomputing},
  pages        = {37-50},
  shortjournal = {Neurocomputing},
  title        = {MulSimNet: A multi-branch sub-interest matching network for personalized recommendation},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). New results on anti-synchronization in predefined-time for
a class of fuzzy inertial neural networks with mixed time delays.
<em>NEUCOM</em>, <em>495</em>, 26–36. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the anti-synchronization in predefined-time for fuzzy inertial neural networks (FINNs) with mixed delays. In the light of predefined-time stability theorems, the FINNs can reach anti-synchronization by employing two distinctive bilayer predefined-time control inputs which the setting-time is a explicit value without considering on initial values that has a great improvement over other settlement times in previous researches. Based on Lyapunov stability theory , sufficient conditions are converted to a type of algebraic inequalities which are very concise and avoid complicated calculations. In the end, some numerical examples and applications are illustrated to validate reliability of proposed results here.},
  archive      = {J_NEUCOM},
  author       = {Jing Han and Guici Chen and Junhao Hu},
  doi          = {10.1016/j.neucom.2022.04.120},
  journal      = {Neurocomputing},
  pages        = {26-36},
  shortjournal = {Neurocomputing},
  title        = {New results on anti-synchronization in predefined-time for a class of fuzzy inertial neural networks with mixed time delays},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast and robust active camera relocalization in the wild for
fine-grained change detection. <em>NEUCOM</em>, <em>495</em>, 11–25. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active camera relocalization (ACR) is an important and challenging task, whose feasibility and success highly depend on illumination consistency and convergence speed. If under varied lighting conditions in outdoor scenes, however, both the convergence and accuracy of ACR cannot be guaranteed. In this paper, we propose a fast and robust ACR scheme, namely rACR, that works well under highly varied illuminations. To achieve robustness to lighting variations, rather than using 2D feature matching, we rely on 3D point clouds, acquired by a visual SLAM engine (VSE), to register the current and reference camera coordinate frames. We present a scale-aware point cloud matching function that is minimized by a two-stage coarse-to-fine method, i.e., fast alignment considering only geometric error at first, followed by fine-grained alignment optimizing both geometric, photometric errors and the poses of VSE keyframes. The two aligned point clouds with equalized scales help to bridge current and reference observations, avoiding 2D feature matching that are sensitive to large lighting variances, and can directly generate effective camera pose adjustments. Moreover, to achieve fast convergence speed, we implement the above algorithm with a parallel scheme, which is specifically composed of an initialization procedure and three parallel threads, i.e., VSE thread, pose alignment thread, and pose adjustment thread. Extensive experiments show that, rACR has much higher robustness to lighting variations and 5 × 5× faster convergence rate over state-of-the-art methods, thus significantly improves its feasibility in real-world fine-grained change detection tasks in the wild.},
  archive      = {J_NEUCOM},
  author       = {Qian Zhang and Wei Feng and Yi-Bo Shi and Di Lin},
  doi          = {10.1016/j.neucom.2022.04.102},
  journal      = {Neurocomputing},
  pages        = {11-25},
  shortjournal = {Neurocomputing},
  title        = {Fast and robust active camera relocalization in the wild for fine-grained change detection},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Refined u-net: A new semantic technique on hand
segmentation. <em>NEUCOM</em>, <em>495</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand segmentation aims to segment the hand profile however the biggest challenge is the segmentation hand over the face or skin-related environments. To solve these problems, many previous papers rely on a very deep neural network or collect new large-scale datasets on real-life scenes to increase the diversity and complexity. To perform it on a standard GPU, the training and inference time is still long, and always requires a large amount of GPU memory. In this paper, we propose a new hand segmentation technique , Refined U-Net, based on the original U-Net [1]. The main objective of Refined U-Net is to perform with few parameters and increasing the inference speed while achieving high accuracy during the hand segmentation process . We substantially improve its performance by refining the segmentation results and reducing the gap of feature vectors. In inference time, our Refined U-Net can prune the refinement block to increase the speed and reduce the number of parameters. We also eliminate the disadvantages of the popular dataset and propose a reliable way to create the virtual dataset. Our Refined U-Net can achieve 200 frames per second (FPS) on the GPU (RTX 2080Ti) and outperforms in accuracy for the state-of-the-art designs in Egohands [2] and GTEA [3] datasets.},
  archive      = {J_NEUCOM},
  author       = {Tsung-Han Tsai and Shih-An Huang},
  doi          = {10.1016/j.neucom.2022.04.079},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {Refined U-net: A new semantic technique on hand segmentation},
  volume       = {495},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TranSalNet: Towards perceptually relevant visual saliency
prediction. <em>NEUCOM</em>, <em>494</em>, 455–467. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have significantly advanced computational modelling for saliency prediction. However, accurately simulating the mechanisms of visual attention in the human cortex remains an academic challenge. It is critical to integrate properties of human vision into the design of CNN architectures, leading to perceptually more relevant saliency prediction. Due to the inherent inductive biases of CNN architectures, there is a lack of sufficient long-range contextual encoding capacity. This hinders CNN-based saliency models from capturing properties that emulate viewing behaviour of humans. Transformers have shown great potential in encoding long-range information by leveraging the self-attention mechanism. In this paper, we propose a novel saliency model that integrates transformer components to CNNs to capture the long-range contextual visual information. Experimental results show that the transformers provide added value to saliency prediction, enhancing its perceptual relevance in the performance. Our proposed saliency model using transformers has achieved superior results on public benchmarks and competitions for saliency prediction models. The source code of our proposed saliency model TranSalNet is available at: https://github.com/LJOVO/TranSalNet .},
  archive      = {J_NEUCOM},
  author       = {Jianxun Lou and Hanhe Lin and David Marshall and Dietmar Saupe and Hantao Liu},
  doi          = {10.1016/j.neucom.2022.04.080},
  journal      = {Neurocomputing},
  pages        = {455-467},
  shortjournal = {Neurocomputing},
  title        = {TranSalNet: Towards perceptually relevant visual saliency prediction},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gaussian similarity preserving for cross-modal hashing.
<em>NEUCOM</em>, <em>494</em>, 446–454. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal hashing (CMH) has gained considerable attention due to its low storage and fast query speed. Most existing CMH research pursues the binary codes of each modality by preserving a similarity matrix which is computationally expensive. In this paper, we propose a Gaussian similarity preserving method for cross-modal hashing. By using the semantic transformation, our model can avoid computing the similarity matrix explicitly. We further employ the sequential learning approach to reduce the quantization error . Experimental results on three benchmark datasets clearly show that our proposed method can outperform the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Liuyin Lin and Xin Shu},
  doi          = {10.1016/j.neucom.2022.04.125},
  journal      = {Neurocomputing},
  pages        = {446-454},
  shortjournal = {Neurocomputing},
  title        = {Gaussian similarity preserving for cross-modal hashing},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Face.evoLVe: A cross-platform library for high-performance
face analytics. <em>NEUCOM</em>, <em>494</em>, 443–445. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop face.evoLVe —a comprehensive library that collects and implements a wide range of popular deep learning-based methods for face recognition. The motivation of the software is to lower the technical burdens in reproducing the existing methods for comparison, while users of our library could focus on developing advanced approaches more efficiently. More specifically, Face.evoLVe is well designed with an extensible framework under vibrantly evolving, so that new face recognition approaches can be easily plugged into our framework. The library is available at https://github.com/ZhaoJ9014/face.evoLVe . Face.evoLVe has been widely used for face analytics, receiving 2,700 stars and 683 forks and we have used Face.evoLVe to participate in a number of face recognition competitions and secured the first place.},
  archive      = {J_NEUCOM},
  author       = {Qingzhong Wang and Pengfei Zhang and Haoyi Xiong and Jian Zhao},
  doi          = {10.1016/j.neucom.2022.04.118},
  journal      = {Neurocomputing},
  pages        = {443-445},
  shortjournal = {Neurocomputing},
  title        = {Face.evoLVe: A cross-platform library for high-performance face analytics},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Triple-discriminator GAN for semi-supervised generalized
zero-shot learning. <em>NEUCOM</em>, <em>494</em>, 432–442. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized zero-shot learning (GZSL) is a newly rising topic that has been attracting an increasing amount of attention. However, there is currently a paradox in existing semi-supervised GZSL methods, in that most of them are transductive. This requires prior knowledge of unseen classes, which violates the premise that unseen class samples cannot be obtained in GZSL. In this paper, we consider a more practical setting, the semi-supervised inductive problem. This setting only requires the data of seen classes in the training stage, and each class only needs to label a few samples. After that, we migrate some transductive methods to this the new setting and reevaluate their accuracy. However, most of these methods perform poorly in new setting. We analyze their pros and cons deduce a more reasonable model, and finally, use a trainable network to instantiate it. The model has a dual structure of mutual learning, which can make full use of both labeled data and unlabeled data . Extensive experiments demonstrate the state-of-the-art performance of our model in transductive and semi-supervised inductive settings.},
  archive      = {J_NEUCOM},
  author       = {Zeqing Zhang and Zuodong Gao and Cuihua Lee},
  doi          = {10.1016/j.neucom.2022.04.114},
  journal      = {Neurocomputing},
  pages        = {432-442},
  shortjournal = {Neurocomputing},
  title        = {Triple-discriminator GAN for semi-supervised generalized zero-shot learning},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022f). Discovering regression-detection bi-knowledge transfer for
unsupervised cross-domain crowd counting. <em>NEUCOM</em>, <em>494</em>,
418–431. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite impressive progress in crowd counting over the last years, it is still an open challenge to reliably count crowds across visual domains. This paper addresses this setting, presenting an unsupervised cross-domain crowd counting framework able to perform unsupervised adaptation across domains with available unlabeled target data. We achieve this by learning to discover bi-knowledge transfer between regression- and detection-based models from a labeled source domain. The dual source knowledge of the two models is heterogeneous and complementary as they capture different modalities of crowd distribution. Specifically, we start by formulating the mutual transformations between the outputs of regression- and detection-based models as two scene-agnostic transformers which enable knowledge transfer between the two models. Given the regression- and detection-based models and their mutual transformers learnt on the source, we then introduce a self-supervised co-training scheme to encourage the knowledge transfer between the two models on the target. We further enhance the model adaptation with our modified mixup augmentation strategy. A thorough benchmark analysis against the most recent cross-domain crowd counting methods and detailed ablation studies show the advantage of our method.},
  archive      = {J_NEUCOM},
  author       = {Yuting Liu and Zheng Wang and Miaojing Shi and Shin’ichi Satoh and Qijun Zhao and Hongyu Yang},
  doi          = {10.1016/j.neucom.2022.04.107},
  journal      = {Neurocomputing},
  pages        = {418-431},
  shortjournal = {Neurocomputing},
  title        = {Discovering regression-detection bi-knowledge transfer for unsupervised cross-domain crowd counting},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Consensus of fractional-order multi-agent systems via
event-triggered pinning impulsive control. <em>NEUCOM</em>,
<em>494</em>, 409–417. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the consensus of fractional-order multi-agent systems is studied. By utilizing the unique properties of fractional-order calculus, namely hereditary and infinite memory, a new design scheme of the event-triggered pinning impulsive control strategy is proposed. Compared with the fixed pinning technique, the pinning agents here can be variable at each impulsive instant based on the considered two pinning rules (i.e., selecting randomly and according to the distances of error states). With the introduced rules, sufficient conditions are derived for consensus of systems, and the Zeno behavior is also excluded. Finally, our results show that the distance-ordered pinning can be achieved faster than the one with randomly pinning selection, and the inner impulsive gain of the impulsive controller can not be too large.},
  archive      = {J_NEUCOM},
  author       = {Wanli Lin and Shiguo Peng and Zhiwen Fu and Tao Chen and Zhihua Gu},
  doi          = {10.1016/j.neucom.2022.04.099},
  journal      = {Neurocomputing},
  pages        = {409-417},
  shortjournal = {Neurocomputing},
  title        = {Consensus of fractional-order multi-agent systems via event-triggered pinning impulsive control},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NODE-SELECT: A graph neural network based on a selective
propagation technique. <em>NEUCOM</em>, <em>494</em>, 396–408. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While there exists a wide variety of graph neural networks (GNN) for node classification , only a minority of them adopt mechanisms that effectively target noise propagation during the message-passing procedure. Additionally, a very important challenge that significantly affects graph neural networks is the issue of scalability which limits their application to larger graphs. In this paper we propose our method named NODE-SELECT: an efficient graph neural network that uses subsetting layers which only allow the best sharing-fitting nodes to propagate their information. By having a selection mechanism within each layer which we stack in parallel, our proposed method NODE-SELECT is able to both reduce the amount noise propagated and adapt the restrictive sharing concept observed in real world graphs. Our NODE-SELECT significantly outperformed existing GNN frameworks in noise experiments and matched state-of-the art results in experiments without noise over different benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Steph-Yves Louis and Alireza Nasiri and Fatima J. Rolland and Cameron Mitro and Jianjun Hu},
  doi          = {10.1016/j.neucom.2022.04.058},
  journal      = {Neurocomputing},
  pages        = {396-408},
  shortjournal = {Neurocomputing},
  title        = {NODE-SELECT: A graph neural network based on a selective propagation technique},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A time series transformer based method for the rotating
machinery fault diagnosis. <em>NEUCOM</em>, <em>494</em>, 379–395. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis of rotating machinery is a significant engineering problem. In recent years, fault diagnosis methods have matured based on the Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN). However, these traditional models have the problem of Long-Term Dependencies, leading to their feature extraction ability defect. To address these issues, we proposed a new method based on the Time Series Transformer (TST) to recognize the fault modes of the various rotating machinery. In this paper, firstly, we design a new tokens sequences generation method that can handle data in 1D format, namely time series tokenizer. Then the TST combining time series tokenizer and Transformer is presented. The test results on the given datasets show that the proposed method has better fault identification capability than traditional CNN and RNN models. Secondly, the effect of structural hyperparameters on fault diagnosis performance, computational complexity, and parameters number of the TST is analyzed in detail through experiments. The influence laws of some hyperparameters are obtained as well. Finally, the feature vectors in the embedding space are visualized via the t-Distributed Stochastic Neighbor Embedding (t-SNE) dimensionality reduction method. On this basis, the working pattern of TST is explained to a certain extent. Moreover, we find that the feature vectors extracted by the proposed method show the best intra-class compactness and inter-class separability compared with CNN and RNN models by analyzing their distribution form, which further demonstrates the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yuhong Jin and Lei Hou and Yushu Chen},
  doi          = {10.1016/j.neucom.2022.04.111},
  journal      = {Neurocomputing},
  pages        = {379-395},
  shortjournal = {Neurocomputing},
  title        = {A time series transformer based method for the rotating machinery fault diagnosis},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Investigating synthetic medical time-series resemblance.
<em>NEUCOM</em>, <em>494</em>, 368–378. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Access to private medical data is restricted due to privacy laws, hindering research and real-world use. Synthetic data generation provides a viable solution by generating data with high utility and privacy protection without releasing the real data. Healthcare data records are often longitudinal in nature, being affected by covariates like age, gender, ethnicity, etc. As a result, synthetic healthcare data generation falls in the domain of time-series modeling and requires time-series based measures to investigate real and synthetic data resemblance. Covariate plots can be used for qualitative time-series resemblance but lack an empirical quantitative measure, thus, resulting in interpretations biased towards viewer’s perspective. In this paper, we describe four time-series metrics to quantitatively evaluate the real and synthetic time-series resemblance on datasets from previously published healthcare research studies, both public and private. We apply the metrics on covariate plots for synthetic datasets to investigate the resemblance and compare the results with baseline synthetic datasets . We infer that the metrics effectively capture the time-series resemblance between real and synthetic datasets. The results highlight varying degrees of resemblance across sub-groups of covariates and multivariate time-series.},
  archive      = {J_NEUCOM},
  author       = {Karan Bhanot and Joseph Pedersen and Isabelle Guyon and Kristin P. Bennett},
  doi          = {10.1016/j.neucom.2022.04.097},
  journal      = {Neurocomputing},
  pages        = {368-378},
  shortjournal = {Neurocomputing},
  title        = {Investigating synthetic medical time-series resemblance},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A ranking-system-based switching particle swarm optimizer
with dynamic learning strategies. <em>NEUCOM</em>, <em>494</em>,
356–367. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel ranking-system-based switching particle swarm optimizer (RSPSO) is proposed. In particular, according to a ranking system, the swarm is divided into elite and normal group, then each particle has been assigned a fitness-based (for normal group member) or a distance-based neighborhood (for elite group member). It is remarkable that neighborhood of a particle is time-varying so that communication among swarm during whole searching process is greatly enhanced. In addition, searching process is divided into four stages by the switching framework, where learning strategies and parameter settings are changed in an adaptive way. Moreover, a newly proposed dimensional learning strategy has been hybridized in RSPSO so as to preserve useful information in the swarm and differential evolution algorithm is employed for a further exploration and also diversifying the swarm. Proposed RSPSO is comprehensively evaluated on series of benchmarks including uni-modal, multi-modal and rotated multi-modal functions. Furthermore, ablation study and sensitivity analysis are performed, where influences of the ranking system, time-varying neighborhood as well as other key parameters have been discussed in detail. Experimental results demonstrate the superiority of proposed algorithm which outperforms other five PSO variants on several indicators regarding to both solution accuracy and convergence performance on most benchmarks in a statistic sense.},
  archive      = {J_NEUCOM},
  author       = {Han Li and Juan Li and Peishu Wu and Yancheng You and Nianyin Zeng},
  doi          = {10.1016/j.neucom.2022.04.117},
  journal      = {Neurocomputing},
  pages        = {356-367},
  shortjournal = {Neurocomputing},
  title        = {A ranking-system-based switching particle swarm optimizer with dynamic learning strategies},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bridging the gap between one-to-many and one-to-one label
assignment via NMS-aware alignment module. <em>NEUCOM</em>,
<em>494</em>, 346–355. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recently proposed one-to-one label assignment rules have made it possible for the detector to get rid of its dependence on NMS. However, its performance is inferior to conventional one-to-many label assignment trained detector due to insufficient supervision caused by reduced foreground information. In this paper, to combine the advantages of these two kinds of label assignment rules, we assign two sets of positive samples by one-to-many and one-to-one label assignment rules respectively to train the detector. Furthermore, we introduce the graph convolutional network (GCN) to construct a NMS-aware alignment module. The NMS-aware alignment module is devised to bridge the gap between the two sets of positive samples and generate a mask to select out best detections, which plays the role of NMS. It also gets rid of the limitation of processing the grid-like data structure and effectively aggregates information from the duplicate predictions. Extensive experiments on the COCO dataset show the effectiveness of our method and the proposed method achieves competitive performance against the recent NMS-free detectors. Especially, our proposed method is compatible with both anchor-based and anchor-free or one-stage and two-stage architectures. The code will be made public soon.},
  archive      = {J_NEUCOM},
  author       = {Li Zhu and Lin Zhao and Jing Luo and Liman Liu and Wenbing Tao},
  doi          = {10.1016/j.neucom.2022.04.112},
  journal      = {Neurocomputing},
  pages        = {346-355},
  shortjournal = {Neurocomputing},
  title        = {Bridging the gap between one-to-many and one-to-one label assignment via NMS-aware alignment module},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Overlapping communities detection based on cluster-ability
optimization. <em>NEUCOM</em>, <em>494</em>, 336–345. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting overlapping communities in networks is very important to obtain and understand the overall structural characteristics of real worlds. In this paper, a new approach is proposed based on the optimization of cluster-ability to detect overlapping network communities. Specially, we design a new learning objective, i.e. the cluster - ability , which aims at minimizing the discrepancy between the community indicator matrix and the node similarity matrix . To deal with the optimization problems , the error is qualified by the Kullback–Leibler divergence in place of Euclidean distance . To optimize the objective function, we first use a new form of nonnegative matrix decomposition to find a solution space, and then we formulate a more appropriate and convenient multiplicative algorithm to solve the function. Finally, we systematically evaluate the proposed method on plenty of artificial networks with various network characteristics and real-world network. The results show that our method achieves the best performance on the networks with stronger overlaps, compared with the existing state-of-the-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Changjian Fang and Zhen-Zhou Lin},
  doi          = {10.1016/j.neucom.2022.04.091},
  journal      = {Neurocomputing},
  pages        = {336-345},
  shortjournal = {Neurocomputing},
  title        = {Overlapping communities detection based on cluster-ability optimization},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Visual aggregation of large multivariate networks with
attribute-enhanced representation learning. <em>NEUCOM</em>,
<em>494</em>, 320–335. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a challenging task to explore large-scaled multivariate networks, since nodes of multivariate networks always contain rich information. We propose a novel visual abstraction method to adaptively aggregate nodes and layout multivariate graphs. First, a novel attribute-enhanced graph representation learning model is proposed to transform nodes into an attribute-enhanced vectorized space. Then, we propose a multi-scale aggregation scheme to classify nodes into hierarchical categories with respect to a set of metrics such as structure closeness, attribute homogeneity and cluster account. Further, we design and implement a visualization framework enabling users to conduct attribute-aware visual abstraction, exploration, and clustering of large-scale multivariate graphs. Case studies and quantitative comparisons with three datasets verify the effectiveness of our approach in enhancing the readability of large-scaled multivariate networks.},
  archive      = {J_NEUCOM},
  author       = {Yuhua Liu and Miaoxin Hu and Rumin Zhang and Ting Xu and Yigang Wang and Zhiguang Zhou},
  doi          = {10.1016/j.neucom.2022.04.110},
  journal      = {Neurocomputing},
  pages        = {320-335},
  shortjournal = {Neurocomputing},
  title        = {Visual aggregation of large multivariate networks with attribute-enhanced representation learning},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). End-to-end learning of self-rectification and
self-supervised disparity prediction for stereo vision. <em>NEUCOM</em>,
<em>494</em>, 308–319. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stereo rectification and stereo matching are two critical components for the practical application of stereo vision systems. Previous studies treat them as two individual issues. For stereo rectification, various traditional algorithms are proposed to estimate homography transformations, but the performance and the efficiency are unsatisfactory for real-time deployment. For stereo matching, disparity accuracy has been largely improved by learning based methods. However, the input data of all previous stereo networks are assumed to be a pair of offline pre-rectified images, making them invalidate for accurate matching when the stereo vision system suffers from mechanical misalignment due to external collisions or temperature variations. In this paper, we optimize these two components jointly and propose an end-to-end learning framework to achieve online self-rectification and self-supervised disparity prediction simultaneously. The overall network contains two cascaded subnetworks which enable stereo rectification and stereo matching sequentially for a pair of unrectified images. The experimental results are evaluated on both publicly available datasets and realistic scenarios. Evaluation results demonstrate that, the proposed network produces state-of-the-art results for self-rectification in terms of computation accuracy and speed, and also produces competitive disparity results with previous self-supervised methods. Therefore, the proposed design provides a more practical and efficient solution for stereo vision systems deployed on mobile platforms.},
  archive      = {J_NEUCOM},
  author       = {Xuchong Zhang and Yongli Zhao and Hang Wang and Han Zhai and Hongbin Sun and Nanning Zheng},
  doi          = {10.1016/j.neucom.2022.04.095},
  journal      = {Neurocomputing},
  pages        = {308-319},
  shortjournal = {Neurocomputing},
  title        = {End-to-end learning of self-rectification and self-supervised disparity prediction for stereo vision},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive event-triggered state estimation for a class of
stochastic complex networks subject to coding-decoding schemes and
missing measurements. <em>NEUCOM</em>, <em>494</em>, 297–307. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the adaptive event-triggered recursive state estimation (RSE) issue for a class of nonlinear complex dynamical networks (CDNs) with random coupling parameter, missing measurements (MMs) and coding-decoding-based communication mechanism (CDBCM). First of all, a random variable uniformly distributed in a fixed interval is adopted to model the varying topologies. Then, the Bernoulli random sequence with uncertain statistical properties is considered to characterize the phenomenon of MMs subject to the uncertain occurrence probability situation. Furthermore, in order to ensure the security and reliability of the shared network channel, the adaptive event-triggered scheduling strategy (AETSS) and CDBCM are both employed to govern the data transmission thereby enhancing the communication quality. The aim of this paper is to present an RSE scheme for a class of stochastic CDNs such that for all MMs, AETSS and CDBCM, the state estimation error covariance (SEEC) is given the SEEC upper bound (SEECUB) is derived. Then, the state estimator gain matrix (SEGM) is parameterized by means of optimizing the trace of SEECUB. Moreover, the monotonicity of the trace of SEECUB with respect to the available missing probability is clarified detailed. Finally, an illustrative simulation is executed for the purpose of verifying the validity of the proposed RSE scheme.},
  archive      = {J_NEUCOM},
  author       = {Chaoqing Jia and Jun Hu and Dongyan Chen and Zhipeng Cao and Jinpeng Huang and Hailong Tan},
  doi          = {10.1016/j.neucom.2022.04.096},
  journal      = {Neurocomputing},
  pages        = {297-307},
  shortjournal = {Neurocomputing},
  title        = {Adaptive event-triggered state estimation for a class of stochastic complex networks subject to coding-decoding schemes and missing measurements},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive survey on recent metaheuristics for feature
selection. <em>NEUCOM</em>, <em>494</em>, 269–296. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection has become an indispensable machine learning process for data preprocessing due to the ever-increasing sizes in actual data. There have been many solution methods proposed for feature selection since the 1970s. For the last two decades, we have witnessed the superiority of metaheuristic feature selection algorithms, and tens of new ones are being proposed every year. This survey focuses on the most outstanding recent metaheuristic feature selection algorithms of the last two decades in terms of their performance in exploration/exploitation operators, selection methods, transfer functions, fitness value evaluations, and parameter setting techniques. Current challenges of the metaheuristic feature selection algorithms and possible future research topics are examined and brought to the attention of the researchers as well.},
  archive      = {J_NEUCOM},
  author       = {Tansel Dokeroglu and Ayça Deniz and Hakan Ezgi Kiziloz},
  doi          = {10.1016/j.neucom.2022.04.083},
  journal      = {Neurocomputing},
  pages        = {269-296},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive survey on recent metaheuristics for feature selection},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FPCC: Fast point cloud clustering-based instance
segmentation for industrial bin-picking. <em>NEUCOM</em>, <em>494</em>,
255–268. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance segmentation is an important pre-processing task in numerous real-world applications, such as robotics, autonomous vehicles, and human–computer interaction. Compared with the rapid development of deep learning for two-dimensional (2D) image tasks, deep learning-based instance segmentation of 3D point cloud still has a lot of room for development. In particular, distinguishing a large number of occluded objects of the same class is a highly challenging problem, which is seen in robotic bin-picking. In a usual bin-picking scene, many identical objects are stacked together and the model of the objects is known. Thus, the semantic information can be ignored; instead, the focus in the bin-picking is put on the segmentation of instances. Based on this task requirement, we propose a Fast Point Cloud Clustering (FPCC) for instance segmentation of industrial bin-picking scene. FPCC includes a network named FPCC-Net and a fast clustering algorithm . FPCC-Net extracts features of each point and infers geometric center points of each instance simultaneously. After that, the proposed clustering algorithm clusters the remaining points to the closest geometric center in feature embedding space. Experiments show that FPCC also surpasses the existing works in bin-picking scenes and is more computationally efficient. Our code and data are available at (https://github.com/xyjbaal/FPCC).},
  archive      = {J_NEUCOM},
  author       = {Yajun Xu and Shogo Arai and Diyi Liu and Fangzhou Lin and Kazuhiro Kosuge},
  doi          = {10.1016/j.neucom.2022.04.023},
  journal      = {Neurocomputing},
  pages        = {255-268},
  shortjournal = {Neurocomputing},
  title        = {FPCC: Fast point cloud clustering-based instance segmentation for industrial bin-picking},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Please be polite: Towards building a politeness adaptive
dialogue system for goal-oriented conversations. <em>NEUCOM</em>,
<em>494</em>, 242–254. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Politeness embalms interactions, putting the parties in conversation at ease. Even the most well-intended communication can fall through if there is a manifestation of rudeness. Complementarily, even the most angst-prone situation can be communicated with much less hurt if lathered with politeness. In this paper, we propose a novel task named as Politeness Adaptive Dialogue System (PADS) to incorporate politeness feedback of agents’ actions according to user’s mood and demands. As there is no politeness labeled conversational data available, we annotate the recently released MultiDoGO dataset having six domains with appropriate politeness labels. The proposed end-to-end dialogue system comprises of a transformer-based politeness classifier that interacts with a reinforced learning framework with four different politeness-oriented reward algorithms, forcing the agent to adapt to polite actions upon encountering the user’s dissatisfaction in the dialogue. We train and evaluate PADS by building six different user simulators, each corresponding to a domain. Quantitative and qualitative analysis show that our proposed politeness based reward algorithms improve the task success rate and reduce the dialogue length with state-of-the-art results.},
  archive      = {J_NEUCOM},
  author       = {Kshitij Mishra and Mauajama Firdaus and Asif Ekbal},
  doi          = {10.1016/j.neucom.2022.04.029},
  journal      = {Neurocomputing},
  pages        = {242-254},
  shortjournal = {Neurocomputing},
  title        = {Please be polite: Towards building a politeness adaptive dialogue system for goal-oriented conversations},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NTreeClus: A tree-based sequence encoder for clustering
categorical series. <em>NEUCOM</em>, <em>494</em>, 224–241. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The overwhelming presence of categorical/sequential data in diverse domains emphasizes the importance of sequence mining. The challenging nature of sequences proves the need for continuing research to find a more accurate and faster approach providing a better understanding of their (dis) similarities. This paper proposes a new Model-based approach for clustering sequence data, namely nTreeClus. The proposed method deploys Tree-based Learners, k -mers, and autoregressive models for categorical time series, culminating with a novel numerical representation of the categorical sequences. Adopting this new representation, we cluster sequences, considering the inherent patterns in categorical time series. Accordingly, the model showed robustness to its parameter. Under different simulated scenarios, nTreeClus improved the baseline methods for various internal and external cluster validation metrics for up to 10.7\% and 2.7\%, respectively. The empirical evaluation using synthetic and real datasets, protein sequences, and categorical time series showed that nTreeClus is competitive or superior to most state-of-the-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Hadi Jahanshahi and Mustafa Gokce Baydogan},
  doi          = {10.1016/j.neucom.2022.04.076},
  journal      = {Neurocomputing},
  pages        = {224-241},
  shortjournal = {Neurocomputing},
  title        = {NTreeClus: A tree-based sequence encoder for clustering categorical series},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Meta-learning approaches for learning-to-learn in deep
learning: A survey. <em>NEUCOM</em>, <em>494</em>, 203–223. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to traditional machine learning , deep learning can learn deeper abstract data representation and understand scattered data properties. It has gained considerable attention for its extraordinary performances. However, existing deep learning algorithms perform poorly on new tasks. Meta-learning, known as learning to learn, is one of the effective techniques to overcome this issue. Meta-learning’s generalization ability to unknown tasks is improved by employing prior knowledge to assist the learning of new tasks. There are mainly three types of meta-learning methods: metric-based, model-based, and optimization-based meta-learning. We investigate classical algorithms and recent meta-learning advances. Second, we survey meta-learning application in real world scenarios. Finally, we discuss present challenges and future research directions of meta-learning.},
  archive      = {J_NEUCOM},
  author       = {Yingjie Tian and Xiaoxi Zhao and Wei Huang},
  doi          = {10.1016/j.neucom.2022.04.078},
  journal      = {Neurocomputing},
  pages        = {203-223},
  shortjournal = {Neurocomputing},
  title        = {Meta-learning approaches for learning-to-learn in deep learning: A survey},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unconstrained face sketch synthesis via perception-adaptive
network and a new benchmark. <em>NEUCOM</em>, <em>494</em>, 192–202. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face sketch generation has attracted much attention in the field of visual computing. However, existing methods either are limited to constrained conditions or heavily rely on various preprocessing steps to deal with in-the-wild cases. In this paper, we argue that accurately perceiving facial region and facial components is crucial for unconstrained sketch synthesis. To this end, we propose a novel Perception-Adaptive Network (PANet), which can generate high-quality face sketches under unconstrained conditions in an end-to-end scheme. Specifically, our PANet is composed of: i) a Fully Convolutional Encoder for hierarchical feature extraction, ii) a Face-Adaptive Perceiving Decoder for extracting potential facial region and handling face variations, and iii) a Component-Adaptive Perceiving Module for facial component aware feature representation learning . To facilitate further researches of unconstrained face sketch synthesis, we introduce a new benchmark termed WildSketch, which contains 800 pairs of face photo-sketch with large variations in pose, expression, ethnic origin, background, and illumination. Extensive experiments demonstrate that the proposed method is capable of achieving state-of-the-art performance under both constrained and unconstrained conditions. Our source codes and the WildSketch benchmark are resealed on the project page http://lingboliu.com/unconstrained_face_sketch.html .},
  archive      = {J_NEUCOM},
  author       = {Lin Nie and Lingbo Liu and Zhengtao Wu and Wenxiong Kang},
  doi          = {10.1016/j.neucom.2022.04.077},
  journal      = {Neurocomputing},
  pages        = {192-202},
  shortjournal = {Neurocomputing},
  title        = {Unconstrained face sketch synthesis via perception-adaptive network and a new benchmark},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A pattern-first pipeline approach for entity and relation
extraction. <em>NEUCOM</em>, <em>494</em>, 182–191. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity-relation extraction is the task of extracting entities and their semantic relations from a piece of unstructured text. In recent studies, Machine Reading Comprehension (MRC) based methods have been applied to this task and achieved significant results. As a pipelined approach, these methods always extract head entities first, and then identify related tail entities by enumerating each relationship. These entity-first methods will lead to the entity redundancy problem . They also suffer from the error propagation issue, which is an inherent issue of the multi-step inference process. Moreover, most existing MRC-based models, which use tagging-based methods for entity recognition, could not deal with overlapping entities. To address these, we propose Patti, a Pattern-First Pipeline Approach for Entity and Relation Extraction. Firstly, Patti leverages a novel MRC-based pattern classifier to identify relation patterns. Next, a span-based method was introduced to extract entities under the guidance of questions parameterized by the patterns yield in the first step. Finally, to alleviate the error propagation issue, Patti employs an additional MRC-based classifier to remove falsely extracted candidate entity-relation triples. Experiment results show that our approach significantly outperforms the entity-first baseline models on CoNLL04 and ACE05 datasets.},
  archive      = {J_NEUCOM},
  author       = {Zheng Chen and Changyu Guo},
  doi          = {10.1016/j.neucom.2022.04.059},
  journal      = {Neurocomputing},
  pages        = {182-191},
  shortjournal = {Neurocomputing},
  title        = {A pattern-first pipeline approach for entity and relation extraction},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TIPCB: A simple but effective part-based convolutional
baseline for text-based person search. <em>NEUCOM</em>, <em>494</em>,
171–181. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-based person search is a sub-task in the field of image retrieval , which aims to retrieve target person images according to a given textual description. The significant feature gap between two modalities makes this task very challenging. Many existing methods attempt to utilize local alignment to address this problem in the fine-grained level. However, most relevant methods introduce additional models or complicated training and evaluation strategies, which are hard to use in realistic scenarios. In order to facilitate the practical application, we propose a simple but effective baseline for text-based person search named TIPCB (i.e., T ext- I mage P art-based C onvolutional B aseline). Firstly, a novel dual-path local alignment network structure is proposed to extract visual and textual local representations, in which images are segmented horizontally and texts are aligned adaptively. Then, we propose a multi-stage cross-modal matching strategy, which eliminates the modality gap from three feature levels, including low level, local level and global level. Extensive experiments are conducted on the widely-used benchmark datasets (CUHK-PEDES and ICFG-PEDES) and verify that our method outperforms all the existing methods. Our code has been released in https://github.com/OrangeYHChen/TIPCB .},
  archive      = {J_NEUCOM},
  author       = {Yuhao Chen and Guoqing Zhang and Yujiang Lu and Zhenxing Wang and Yuhui Zheng},
  doi          = {10.1016/j.neucom.2022.04.081},
  journal      = {Neurocomputing},
  pages        = {171-181},
  shortjournal = {Neurocomputing},
  title        = {TIPCB: A simple but effective part-based convolutional baseline for text-based person search},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dimension decoupling attention mechanism for time series
prediction. <em>NEUCOM</em>, <em>494</em>, 160–170. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spatial-temporal sequence prediction task is a challenge for neural networks , as it requires capturing temporal and spatial changes simultaneously. Recent researches focus on the modification of the ConvLSTM internal elements, which improves the prediction ability to some extent but introduces a large number of parameters. We observe that although the result generated by the row ConvLSTM is not very accurate in position and have a blurry appearance, it contains enough elements required to reconstruct the prediction. The motivation is to further refine these feature maps. Therefore, we propose a multi-attention LSTM (MA-LSTM) based on dimensional decoupling attention to alleviate the problems of the existing ConvLSTM-based methods, including inaccurate positions prediction and blurry generated results. The proposed model includes the Dimensionality Decoupling Module (D2M) and the Channel Attention Module (CAM). D2M compresses dimensions to transfer motion features over time that squeezes the features by dimensions and calculates the motion distribution of each dimension. CAM maintains the predicted texture information, which integrates latent information between channels and weights of the effective channels. Through the coordination of multiple modes, the model has long-term predictive capability and the accuracy of the prediction results has been improved. Experimental results show that using a smaller number of parameters, the proposed method can obtain competitive results but less inference time compared with the state-of-the-art (SOTA) methods.},
  archive      = {J_NEUCOM},
  author       = {Jie Yan and Guihe Qin and Minghui Sun and Yanhua Liang and Zhonghan Zhang},
  doi          = {10.1016/j.neucom.2022.04.063},
  journal      = {Neurocomputing},
  pages        = {160-170},
  shortjournal = {Neurocomputing},
  title        = {Dimension decoupling attention mechanism for time series prediction},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation of underwater image enhancement algorithms based
on retinex and its implementation on embedded systems. <em>NEUCOM</em>,
<em>494</em>, 148–159. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The improvement of underwater imaging has advanced significantly due to its contribution to marine engineering and underwater exploration. This fact has been reflected in recent years with the proposal of numerous algorithms that improve the quality of underwater images. A benchmarking of three algorithms based on the Retinex models implemented on five high-performance embedded systems is presented herein. These algorithms are the Single Scale Retinex Model (SSR), Multi-Scale Retinex Model (MSR), and the Multi-Scale Retinex Model with Color Restoration (MSRCR). These algorithms perform the histogram equalization to distribute pixels, reduce the predominant color, perform color and contrast correction, and achieve an automatic white balance to improve illumination. This paper employs five edge devices such as Beagle Board, Odroid-XU4, Raspberry Pi 4, Jetson Nano, and Jetson TX2 to enhance underwater images and benchmark their performance. Four quality metrics without a reference image such as UIQM, UCIQUE, BRISQUE and Entropy are used to evaluate the quality of the enhanced underwater images. The MSRCR algorithm achieves the best quality results when it is implemented on Jetson TX2 embedded system. It has a difference of 0.46 s in the processing time of 147 × × 196 pixels images concerning a high-performance personal computer (PC). Implementing these algorithms on embedded systems offers an excellent cost-benefit ratio versus a traditional PC, considering image quality metrics, precision, accuracy, energy consumption, price, lightweight, size, portability, and reliability. These findings hold great promise for unmanned and self-propelled underwater vehicles with artificial vision for exploration.},
  archive      = {J_NEUCOM},
  author       = {O.A. Aguirre-Castro and E.E. García-Guerrero and O.R. López-Bonilla and E. Tlelo-Cuautle and D. López-Mancilla and J.R. Cárdenas-Valdez and J.E. Olguín-Tiznado and E. Inzunza-González},
  doi          = {10.1016/j.neucom.2022.04.074},
  journal      = {Neurocomputing},
  pages        = {148-159},
  shortjournal = {Neurocomputing},
  title        = {Evaluation of underwater image enhancement algorithms based on retinex and its implementation on embedded systems},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Light weight object detector based on composite attention
residual network and boundary location loss. <em>NEUCOM</em>,
<em>494</em>, 132–147. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The object detector based on deep learning has received extensive attention, but the high computational cost has become an obstacle to its large-scale application. It is a great challenge for object detection to further reduce the hardware requirements on the premise of ensuring high detection accuracy. We propose a one-stage lightweight object detector and a new regression loss. In this method, ResNet is improved and combined with attention mechanism to ensure the maximum integrity of feature information with fewer parameters; The multi-scale feature fusion network is improved to reduce the reasoning complexity of the structure. In addition, the bounding box regression loss is improved, and the specific position of the bounding box is adjusted by considering the balance of multiple factors in the regression process. The experimental results show that: 1) the combination of most detectors and improved loss can further improve the performance of detectors; 2) As a whole, our improved network and loss can give consideration to both speed and accuracy on Pascal VOC and COCO; 3) in the addition of other new training tricks such as DropBlock and Mosaic, we can achieve better overall performance on the coco test development set, 38.42 AP (average accuracy) at 40.3 FPS.},
  archive      = {J_NEUCOM},
  author       = {Zehao Xiao and Enzeng Dong and Jigang Tong and Lin Zhu and Zenghui Wang},
  doi          = {10.1016/j.neucom.2022.04.090},
  journal      = {Neurocomputing},
  pages        = {132-147},
  shortjournal = {Neurocomputing},
  title        = {Light weight object detector based on composite attention residual network and boundary location loss},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive empirical review of modern voice activity
detection approaches for movies and TV shows. <em>NEUCOM</em>,
<em>494</em>, 116–131. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robust and language agnostic Voice Activity Detection (VAD) is crucial for Digital Entertainment Content (DEC). Primary examples of DEC include movies and TV series. Some ways in which VAD systems are used for DEC creation include augmenting subtitle creation, subtitle drift detection and correction, and audio diarisation. Majority of the previous work on VAD focuses on scenarios that: (a) have minimal background noise, and (b) where the audio content is delivered in English language. However, movies and TV shows can: (a) have substantial amounts of non-voice background signal ( e.g. musical score and environmental sounds), and (b) are released worldwide in a variety of languages. This makes most of the previous standard VAD approaches not readily applicable for DEC related applications. Furthermore, there does not exist a comprehensive analysis of Deep Neural Network’s (DNN) performance for the task of VAD applied to DEC. In this work, we present a thorough survey on DNN based VADs on DEC data in terms of their accuracy, Area Under Curve (AUC), noise sensitivity, and language agnostic behaviour . For our analysis we use 1100 proprietary DEC videos spanning 450 h of content in 9 languages and 5 + genres, making our study the largest of its kind ever published. The key findings of our analysis are: (a) even high quality timed-text or subtitle 2 files contain significant levels of label-noise (up to 15\%). Despite high label noise, deep networks are robust and are able to retain high AUCs ( ∼ ∼ 0.94). (b) Using larger labelled dataset can substantially increase neural VAD model’s True Positive Rate (TPR) with up to 1.3\% and 18\% relative improvement over current state-of-the-art methods in Hebbar et al. (2019) and Chaudhuri et al. (2018) respectively. This effect is more pronounced in noisy environments such as music and environmental sounds. This insight is particularly instructive while prioritizing domain specific labelled data acquisition versus exploring model structure and complexity. (c) Currently available sequence based neural models show similar levels of competence in terms of their language agnostic behaviour for VAD at high Signal-to-Noise Ratios (SNRs) and for clean speech, (d) Deep models exhibit varied performance across different SNRs with CLDNN (Zazo et al., 2016) being the most robust, and (e) models with comparatively larger number of parameters ( ∼ ∼ 2 M) are less robust to input noise as opposed to models having smaller number of parameters ( ∼ ∼ 0.5 M).},
  archive      = {J_NEUCOM},
  author       = {Mayank Sharma and Sandeep Joshi and Tamojit Chatterjee and Raffay Hamid},
  doi          = {10.1016/j.neucom.2022.04.084},
  journal      = {Neurocomputing},
  pages        = {116-131},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive empirical review of modern voice activity detection approaches for movies and TV shows},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Task-aware adaptive attention learning for few-shot semantic
segmentation. <em>NEUCOM</em>, <em>494</em>, 104–115. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot semantic segmentation is a newly developing and challenging computer vision task which aims to predict pixel-wise segmentation on the novel categories where only a few annotated samples are supplied. Because of the scarcity of the annotated novel class samples, the main obstacle of this issue is the diversity of objects in the support set and query set. This paper proposes a novel network aiming to bridge the gap by exploring the correlation between the support feature and the query feature. Specifically, a task-aware adaptive attention module(TAAM) is introduced to extract the task-specific information from the current input and integrates it into the feature representations both in channel dimension and spatial dimension for adaptive reinforcement. Besides, an additional prediction refinement module(RPM) is attached to further optimize the predictions to present more details of objects. Furthermore, through a non-parameter aggregation operation, the proposed network is easy to generalize to k-shot segmentation without developing specific architectures. Extensive experiments on three benchmarks demonstrate that our method exceeds previous state-of-the-arts with a sizable margin, verifying the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Binjie Mao and Lingfeng Wang and Shiming Xiang and Chunhong Pan},
  doi          = {10.1016/j.neucom.2022.04.089},
  journal      = {Neurocomputing},
  pages        = {104-115},
  shortjournal = {Neurocomputing},
  title        = {Task-aware adaptive attention learning for few-shot semantic segmentation},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A backpropagation with gradient accumulation algorithm
capable of tolerating memristor non-idealities for training memristive
neural networks. <em>NEUCOM</em>, <em>494</em>, 89–103. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memristive neural network (MNN) has emerged as a new computing architecture with high speed and low power consumption, but its hardware implementation is hampered mainly by the device non-idealities of memristors. Here, we propose a backpropagation with gradient accumulation (BP-GA) algorithm which can effectively tolerate the memristor non-idealities. We first show that a memristor-based single-layer perceptron trained with BP-GA achieves high image recognition accuracies (&gt;85\% on the MNIST dataset) with a wide range of learning rates (0.01–50), large nonlinearities (&gt;6), a small number of conductance states (even down to 3 states), a broad spectrum of ON/OFF ratios (across 3 orders of magnitude), and large noises (up to 40\%). The origin for such good robustness against the learning rate and memristor non-idealities is then investigated and revealed to be associated with the operation mechanism of BP-GA. In this algorithm, the weights can keep increasing in magnitude due to the gradient accumulation and therefore become movable even at a small learning rate (or a large ON/OFF ratio equivalently). Moreover, the weights corresponding to the foreground and background of the input image are appropriately moved to the positive and negative boundaries of the weight range, respectively, thus allowing the learning of the image features using only a small number of conductance states. These boundary weights are trapped there without significant oscillation under the effects of accumulated gradients, resulting in immunity to large nonlinearity and noise. Therefore, BP-GA enables the MNN to be insensitive to the learning rate and robust against the memristor non-idealities. The performance of BP-GA is further evaluated on the memristor-based multilayer perceptron (on the MNIST dataset) and convolutional neural network (on the Cifar-10 dataset). For both MNNs, BP-GA exhibits relatively high accuracies and good tolerance against memristor non-idealities, demonstrating its applicability to complex networks and problems. This study provides a viable approach at the algorithm level for addressing some important hardware implementation issues of MNNs using realistic memristors.},
  archive      = {J_NEUCOM},
  author       = {Shuai Dong and Yihong Chen and Zhen Fan and Kaihui Chen and Minghui Qin and Min Zeng and Xubing Lu and Guofu Zhou and Xingsen Gao and Jun-Ming Liu},
  doi          = {10.1016/j.neucom.2022.04.008},
  journal      = {Neurocomputing},
  pages        = {89-103},
  shortjournal = {Neurocomputing},
  title        = {A backpropagation with gradient accumulation algorithm capable of tolerating memristor non-idealities for training memristive neural networks},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven predictive maintenance strategy considering the
uncertainty in remaining useful life prediction. <em>NEUCOM</em>,
<em>494</em>, 79–88. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining Useful Life (RUL) prediction and maintenance decision-making are two key tasks within the framework of Prognostics and Health Management (PHM) of system. However, existing works are performing the two tasks separately and hierarchically. Besides, the uncertainty in RUL prediction caused by cognitive level and measurement capabilities has not aroused wide concern and this may reduce the credibility of point prediction. To address these issues and finally ensure the safe and reliable operation of the system, this paper proposes a novel data-driven predictive maintenance strategy. The proposed strategy is a complete process from implementing the RUL prediction with uncertainty to making maintenance decision. Considering the prediction aspect, a Local Uncertainty Estimation (LUE) model with Bidirectional Long-Short Term Memory (Bi-LSTM) is proposed to characterize the uncertainty in RUL prediction. Regarding the post-prediction aspect, the Maintenance Cost Rate (MCR), namely maintenance cost per unit operational time, function is constructed by linking the constructed RUL distribution with maintenance-related costs. Oriented towards the economic requirements of operation management, the time for taking maintenance activities can be determined by optimizing the MCR function. The whole proposition is validated on a case study of the aero-engine health monitoring. The comparison with recent publications and the corresponding analysis results indicate that the proposed method is a promising tool in predictive maintenance applications, which can reduce system maintenance costs.},
  archive      = {J_NEUCOM},
  author       = {Chuang Chen and Jiantao Shi and Ningyun Lu and Zheng Hong Zhu and Bin Jiang},
  doi          = {10.1016/j.neucom.2022.04.055},
  journal      = {Neurocomputing},
  pages        = {79-88},
  shortjournal = {Neurocomputing},
  title        = {Data-driven predictive maintenance strategy considering the uncertainty in remaining useful life prediction},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Delving into the representation learning of deep hashing.
<em>NEUCOM</em>, <em>494</em>, 67–78. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Searching for the nearest neighbor is a fundamental problem in the computer vision field, and deep hashing has become one of the most representative and widely used methods, which learns to generate compact binary codes for visual data. In this paper, we first delve into the representation learning of deep hashing and surprisingly find that deep hashing could be a double-edged sword, i.e. , deep hashing can accelerate the query speed and decrease the storage cost in the nearest neighbor search progress, but it greatly sacrifices the discriminability of deep representations especially with extremely short target code lengths. To solve this problem, we propose a two-step deep hashing learning framework. The first step focuses on learning deep discriminative representations with metric learning. Subsequently, the learning framework concentrates on simultaneously learning compact binary codes and preserving representations learned in the former step from being sacrificed. Extensive experiments on two general image datasets and four challenging image datasets validate the effectiveness of our proposed learning framework. Moreover, the side effect of deep hashing is successfully mitigated with our learning framework.},
  archive      = {J_NEUCOM},
  author       = {Quan Cui and Zhao-Min Chen and Osamu Yoshie},
  doi          = {10.1016/j.neucom.2022.04.082},
  journal      = {Neurocomputing},
  pages        = {67-78},
  shortjournal = {Neurocomputing},
  title        = {Delving into the representation learning of deep hashing},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain adaptation with a shrinkable discrepancy strategy for
cross-domain sentiment classification. <em>NEUCOM</em>, <em>494</em>,
56–66. (<a href="https://doi.org/10.1016/j.neucom.2022.04.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain sentiment classification (CDSC) is used to predict the sentiment polarity of a text in an unlabeled target domain by analyzing the reviews in the labeled source domain. Domain adaptive approaches have become the preferred solution in recent years to the unsupervised domain migration problem. Among them, adversarial learning aligns the sample distribution of the two domains through domain confusion to transfer sentiment across domains. However, traditional adversarial learning often roughly measures domain discrepancy. Although scholars have attempted to adjust the decision boundary of different categories to eliminate the domain shift, such as maximum classifier discrepancy model, there are still two problems with this approach. First, it ignores the intra-domain structure, which causes the samples distributed on the decision boundary to be easily misclassified. Second, it only realizes coarse-grained sentiment migration and lacks a refined evaluation of the transferable information in the inter-domain, which causes a negative transfer. To solve these problems, we propose domain adaptation with a shrinkable discrepancy strategy (DA-SDS) for the task of CDSC. Specifically, we propose to shrink the category subspace in the intra-domain while building the decision boundary of classifiers, which reduces the misclassification by clustering samples to the category center. We also propose to measure the weighted domain discrepancy in the inter-domain, which mitigates the negative transfer through the refined assessment of domain discrepancy. Extensive evaluations showed that DA-SDS outperformed state-of-the-art methods on the Amazon Review dataset.},
  archive      = {J_NEUCOM},
  author       = {Yanping Fu and Yun Liu},
  doi          = {10.1016/j.neucom.2022.04.092},
  journal      = {Neurocomputing},
  pages        = {56-66},
  shortjournal = {Neurocomputing},
  title        = {Domain adaptation with a shrinkable discrepancy strategy for cross-domain sentiment classification},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-object tracking in traffic environments: A systematic
literature review. <em>NEUCOM</em>, <em>494</em>, 43–55. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of computer vision techniques to detect objects in images has grown in recent years. These techniques are especially useful to automatically extract and analyze information from an image or a sequence of them. One of the problems addressed by computer vision is multi-object tracking over frames sequences. To know the path and direction of objects can be crucial for some areas like traffic control and supervision; by doing that the system can be able to reduce traffic jams or redirect vehicles over less condensed areas. These algorithms include several aspects to have in mind in order to start a new development or research in this area, for instance, is important to review the current state-of-the art techniques, the hardware requirements, the main evaluation metrics, the commonly used datasets, among others. Therefore, the objective of this research is to present a systematic literature review which analyzes the recent works developed in the area of multi-object tracking in traffic environments. This paper reviews the techniques, hardware, datasets, metrics, and open lines of research in this area.},
  archive      = {J_NEUCOM},
  author       = {Diego M. Jiménez-Bravo and Álvaro Lozano Murciego and André Sales Mendes and Héctor Sánchez San Blás and Javier Bajo},
  doi          = {10.1016/j.neucom.2022.04.087},
  journal      = {Neurocomputing},
  pages        = {43-55},
  shortjournal = {Neurocomputing},
  title        = {Multi-object tracking in traffic environments: A systematic literature review},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SI-news: Integrating social information for news
recommendation with attention-based graph convolutional network.
<em>NEUCOM</em>, <em>494</em>, 33–42. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-quality news recommendation heavily relies on accurate and timely representations of news documents and user interests. Social information, which usually contains the most recent information about the activities of users and their friends, naturally reflects the dynamics and diversities of user interests. However, existing news recommendation approaches often overlook these dynamic items, and thus lead to suboptimal performance. In this paper, we propose a novel approach by embedding users’ interests from their social information by attentional graph convolutional network (GCN). We also improve news representations by jointly optimizing the titles and contents of news via attention mechanisms . Extensive experiments on three benchmark datasets show that our approach effectively improves news recommendation performance compared with state-of-the-art baselines. We also evaluate our model on a real-world dataset and the results demonstrate the superior performance of the proposed techniques in industry-level applications.},
  archive      = {J_NEUCOM},
  author       = {Peng Zhu and Dawei Cheng and Siqiang Luo and Fangzhou Yang and Yifeng Luo and Weining Qian and Aoying Zhou},
  doi          = {10.1016/j.neucom.2022.04.073},
  journal      = {Neurocomputing},
  pages        = {33-42},
  shortjournal = {Neurocomputing},
  title        = {SI-news: Integrating social information for news recommendation with attention-based graph convolutional network},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022e). MSL3D: 3D object detection from monocular, stereo and point
cloud for autonomous driving. <em>NEUCOM</em>, <em>494</em>, 23–32. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel deep architecture by combining multiple sensors for 3D object detection, named MSL3D. While recently LiDAR-Camera methods introduce additional semantic cues, working with fewer false detections, there is still a performance gap compared LiDAR-only methods. We argue that this gap is caused for two reasons: 1) the 3D spherical receptive fields of the set abstraction of the point clouds are not aligned with the 2D pixel-level receptive fields of the image. 2) the premature introduction of image information makes it is difficult to apply data augmentation both LiDAR and image synchronously. For the first problem, we extend 3D set abstraction to a 2D set abstraction that can transform the 2D image features to the 3D sphere to unify the receptive field of multi-modal data. For the second problem, we design a novel two-stage 3D detection framework that employs the LiDAR-only backbone in the first stage to estimate high-recall and high-quality proposals and then integrates the image and point clouds information for box refinement and confidence prediction. Besides, we add two auxiliary networks to effectively learn image features and point cloud features when using different multi-modal data augmentation strategies synchronously. Moreover, we design a consistency-structure generator using stereo images to determine whether any of a point in the 3D space belongs to the contour of the object, thereby supplementing the sparse point cloud information. Extensive experiments on the popular KITTI 3D objects detection dataset show that our proposed MSL3D achieves better performance comparing with other LiDAR-Only or LiDAR-Camera fusion approaches.},
  archive      = {J_NEUCOM},
  author       = {Wenyu Chen and Peixuan Li and Huaici Zhao},
  doi          = {10.1016/j.neucom.2022.04.075},
  journal      = {Neurocomputing},
  pages        = {23-32},
  shortjournal = {Neurocomputing},
  title        = {MSL3D: 3D object detection from monocular, stereo and point cloud for autonomous driving},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Path-aware multi-hop graph towards improving graph learning.
<em>NEUCOM</em>, <em>494</em>, 13–22. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have achieved state-of-the-art performance in graph-related tasks. Most of them pass messages between direct neighbors and the deeper GNNs can theoretically capture the more global neighborhood information. However, they often suffer from over-smoothing problems when the GNNs’ depth deepens. To eliminate this limitation, we propose a path-aware multi-hop graph framework with hop-level attention (HAPG), which has a larger receptive field than GNNs with the same depth. HAPG generates some multi-path multi-hop graphs by converting the original graph to achieve message passing between multi-hop neighbors in a single layer. HAPG aggregates one-hop and multi-hop neighbors by stacking the original graph and the generated graphs into GNNs. The node embeddings are obtained by combining the multiple outputs of the GNNs with the help of hop-level attention. Comparative experiments with various existing GNNs are conducted on three benchmark datasets, and results show that the HAPG is an effective way for improving these models. Specifically, for semi-supervised node classification tasks, the proposed HAPG-GAT and HAPG-AGNN have achieved state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Rui Duan and Chungang Yan and Junli Wang and Changjun Jiang},
  doi          = {10.1016/j.neucom.2022.04.085},
  journal      = {Neurocomputing},
  pages        = {13-22},
  shortjournal = {Neurocomputing},
  title        = {Path-aware multi-hop graph towards improving graph learning},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Part-facial relational and modality-style attention networks
for heterogeneous face recognition. <em>NEUCOM</em>, <em>494</em>, 1–12.
(<a href="https://doi.org/10.1016/j.neucom.2022.04.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of heterogeneous face recognition (HFR) is to match face images of the same person from different modalities. Most HFR methods bridge the cross-modality variations with feature alignment by global feature representation learning , but ignore the content information of local features and modality-style information of face image for each modality, which limits the performance for HFR. The content information of local features not only contains the invariance of modality face features, but also can improve the stability of global face features, i.e. , local features such as eyes, nose and mouth are steady and invariant. With this motivation, we propose a cross-modality dual-constraint (CMDC) approach that includes the part-facial relational attention network (PRAN) and modality-style attention network (MSAN). First, PRAN is designed to estimate the intrinsic structural relationships of local content features on each modality. It can extract discriminative local face features by capturing correlations within the face space of individual modality , and strengthen representations by contextual relationships across modalities. Secondly, we design the MSAN to capture the modality-style information for each modality, and then reduce the inter-modality differences by minimizing the distance of two modality-style features. Thirdly, to alleviate cross-modality variances and enhance intra-class compactness and inter-class divisibility, we propose the cross-modality dual-constrained loss (DCLoss) in the CMDC approach, which adds a global constraint to each sample distribution in the embedding space. Meanwhile, on the basis of focusing on modality-style information, DCLoss emphasizes the significance of category information. Extensive experiments on four datasets demonstrate the superior performance of our approach over the existing state-of-the-art. The code is available at https://github.com/JianYu777/CMDC.},
  archive      = {J_NEUCOM},
  author       = {Jian Yu and Yujian Feng and Ruonan Li and Yang Gao},
  doi          = {10.1016/j.neucom.2022.04.093},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {Part-facial relational and modality-style attention networks for heterogeneous face recognition},
  volume       = {494},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A gradient-type noise-tolerant finite-time neural network
for convex optimization. <em>NEUCOM</em>, <em>493</em>, 647–656. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of powerful methods for solving optimization problems , the gradient-type neural network has attracted the attention of many scholars. Up to now, there are few studies on finite-time convergence and the ability of noise tolerance of gradient-type networks. Motivated by the superior performance of various activation functions and advantages of gradient-type networks for solving constrained optimization , this paper aims to introduce a suitable activation function in a gradient-type neural network to solve convex optimization . It is shown that the state solution of the network converges to an optimal solution of the original convex optimization and the convergence time is finite under mild conditions. The capability of the network to suppress bounded noises is also analyzed theoretically. Superior to existing models for constrained optimization , the resulting network model not only has fast convergence but also can tolerate additive noises. Some numerical results are reported, including the results for smooth and nonsmooth problems, to show that the presented network is effective for convex constrained problems in the absence and presence of additive noises.},
  archive      = {J_NEUCOM},
  author       = {Dan Wang and Xin-Wei Liu},
  doi          = {10.1016/j.neucom.2022.01.018},
  journal      = {Neurocomputing},
  pages        = {647-656},
  shortjournal = {Neurocomputing},
  title        = {A gradient-type noise-tolerant finite-time neural network for convex optimization},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Review the state-of-the-art technologies of semantic
segmentation based on deep learning. <em>NEUCOM</em>, <em>493</em>,
626–646. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of semantic segmentation is to segment the input image according to semantic information and predict the semantic category of each pixel from a given label set. With the gradual intellectualization of modern life, more and more applications need to infer relevant semantic information from images for subsequent processing, such as augmented reality , autonomous driving , video surveillance, etc. This paper reviews the state-of-the-art technologies of semantic segmentation based on deep learning . Because semantic segmentation requires a large number of pixel-level annotations, in order to reduce the fine-grained requirements of annotation and reduce the economic and time cost of manual annotation, this paper studies the works on weakly-supervised semantic segmentation. In order to enhance the generalization ability and robustness of the segmentation model , this paper investigates the works on domain adaptation in semantic segmentation. Many types of sensors are usually equipped in some practical applications, such as autonomous driving and medical image analysis. In order to mine the association between multi-modal data and improve the accuracy of the segmentation model , this paper investigates the works based on multi-modal data fusion semantic segmentation. The real-time performance of the model needs to be considered in practical application. This paper analyzes the key factors affecting the real-time performance of the segmentation model and investigates the works on real-time semantic segmentation. Finally, this paper summarizes the challenges and promising research directions of semantic segmentation tasks based on deep learning .},
  archive      = {J_NEUCOM},
  author       = {Yujian Mo and Yan Wu and Xinneng Yang and Feilin Liu and Yujun Liao},
  doi          = {10.1016/j.neucom.2022.01.005},
  journal      = {Neurocomputing},
  pages        = {626-646},
  shortjournal = {Neurocomputing},
  title        = {Review the state-of-the-art technologies of semantic segmentation based on deep learning},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Learning graph normalization for graph neural networks.
<em>NEUCOM</em>, <em>493</em>, 613–625. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have emerged as a useful paradigm to process graph-structured data. Usually, GNNs are stacked to multiple layers and node representations in each layer are computed through propagating and aggregating the neighboring node features. To effectively train a GNN with multiple layers, normalization techniques are necessary. Though existing normalization techniques have achieved good results in helping GNNs training, but they seldom consider the structure information of the graph. In this paper, we propose two graph-aware normalization techniques, namely adjacency-wise normalization and graph-wise normalization, which fully take into account the structure information of the graph. Furthermore, we propose a novel approach, termed Attentive Graph Normalization (AGN), which learns a weighted combination of multiple graph-aware normalization methods, aiming to automatically select the optimal combination of multiple normalization methods for a specific task. We conduct extensive experiments on eleven benchmark datasets, including three single-graph and eight multiple-graph datasets, and the experimental results provide a comprehensive evaluation on the effectiveness of our proposals.},
  archive      = {J_NEUCOM},
  author       = {Yihao Chen and Xin Tang and Xianbiao Qi and Chun-Guang Li and Rong Xiao},
  doi          = {10.1016/j.neucom.2022.01.003},
  journal      = {Neurocomputing},
  pages        = {613-625},
  shortjournal = {Neurocomputing},
  title        = {Learning graph normalization for graph neural networks},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stronger separation of analog neuron hierarchy by
deterministic context-free languages. <em>NEUCOM</em>, <em>493</em>,
605–612. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computational power of discrete-time recurrent neural networks (NNs) with the saturated-linear activation function depends on the descriptive complexity of their weight parameters encoding the NN program. In order to study the power of increasing analogicity in NNs between integer (finite automata) and arbitrary rational weights (Turing machines), we have established the analog neuron hierarchy 0ANNs ⊂ ⊂ 1ANNs ⊂ ⊂ 2ANNs ⊆ ⊆ 3ANNs where α α ANN is a binary-state NN that is extended with α ⩾ 0 α⩾0 extra analog-state neurons with rational weights. In our previous work, we have compared it to the traditional Chomsky hierarchy and separated its first two levels. The separation 1ANNs ⫋ ⫋ 2ANNs has been witnessed by the non-regular deterministic context-free language (DCFL) L # = { 0 n 1 n | n ⩾ 1 } L#={0n1n|n⩾1} which cannot be recognized by any 1ANN even with real weights, while any DCFL is accepted by a 2ANN with rational weights. In this paper, we strengthen this separation by showing that any non-regular DCFL (DFCL’) cannot be recognized by 1ANNs with real weights, which means DCFL’s ⊂ ⊂ (2ANNs \ \ 1ANNs), implying 1ANNs ∩ ∩ DCFLs = 0ANNs. For this purpose, we show that any 1ANN that would recognize a DFCL’ can be augmented to a larger 1ANN that would recognize L # L# , which does not exists.},
  archive      = {J_NEUCOM},
  author       = {Jiří Šíma},
  doi          = {10.1016/j.neucom.2021.12.107},
  journal      = {Neurocomputing},
  pages        = {605-612},
  shortjournal = {Neurocomputing},
  title        = {Stronger separation of analog neuron hierarchy by deterministic context-free languages},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Probabilistic online self-distillation. <em>NEUCOM</em>,
<em>493</em>, 592–604. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deploying state-of-the-art deep learning models on devices with limited computational power imposes certain computation and storage restrictions. Knowledge Distillation , i.e. training compact models by transferring knowledge from more powerful models, constitutes a promising route to address this issue that has been followed during the recent years. A limitation of conventional knowledge distillation is that it is a long-lasting, computationally and memory demanding process, since it requires multiple stages of training process. To this end, a novel online probabilistic self-distillation method, namely Probabilistic Online Self-Distillation (POSD), aiming to improve the performance of any deep neural model in an online manner, is proposed in this paper. We argue that considering a classification problem, apart from the explicit concepts expressed with the hard labels, there are also implicit concepts expressed with the so-called latent labels . These implicit concepts reflect similarities among data, regardless of the classes. Then, our goal is to maximize the Mutual Information between the data samples and the latent labels. In this way, we are able to derive additional knowledge from the model itself, without the need of building multiple identical models or using multiple models to teach each other, like existing online distillation methods, rendering the POSD method more efficient. The experimental evaluation on six datasets validates that the proposed method improves the classification performance.},
  archive      = {J_NEUCOM},
  author       = {Maria Tzelepi and Nikolaos Passalis and Anastasios Tefas},
  doi          = {10.1016/j.neucom.2021.12.101},
  journal      = {Neurocomputing},
  pages        = {592-604},
  shortjournal = {Neurocomputing},
  title        = {Probabilistic online self-distillation},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimator-based iterative deviation-free residual generator
for fault detection under random access protocol. <em>NEUCOM</em>,
<em>493</em>, 583–591. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an estimator-based iterative deviation-free residual generator (IDRG) for linear discrete-time stochastic systems . The communication between intelligent nodes and the remote estimator is realized by adopting a shared network. With the purpose of random access protocol (RAP) is utilized to schedule the data transmission process, according to which only one node at one instant is selected to get access to the communication network. The aim of the addressed problem is to detect the occurrence and disappearance of the faulty signal via utilizing the designed estimator. By solving an optimization problem subject to the deviation-free constraint, a novel batch estimator is firstly designed with finite response. Then, the IDRG is developed by extracting the residual signal out of the proposed estimator. By adopting the norm of the residual as the evaluation function, the Chebyshev inequalities are used to obtain the lower and upper stochastic thresholds. Finally, an illustrative example is given to demonstrate that the designed IDRG can detect the occurrence and disappearance of the faulty signals in a short transient stage, and is capable of reducing the false alarm rate in comparison to the benchmark Kalman filter residual generator (KFRG).},
  archive      = {J_NEUCOM},
  author       = {Ye Zhao and Xiao He and Lifeng Ma and Hongjian Liu},
  doi          = {10.1016/j.neucom.2021.12.100},
  journal      = {Neurocomputing},
  pages        = {583-591},
  shortjournal = {Neurocomputing},
  title        = {Estimator-based iterative deviation-free residual generator for fault detection under random access protocol},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ASSP: An adaptive sample statistics-based pooling for
full-reference image quality assessment. <em>NEUCOM</em>, <em>493</em>,
568–582. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most full-reference image quality assessment (IQA) models first compute local quality scores and then pool them into an overall score. In this paper, we develop an innovative pooling strategy based on sample statistics to adaptively make the IQA more consistent with human visual assessment. The innovation of this work is threefold. First, we identify that standard sample statistics and robust sample statistics could provide complementary information about the degree of degradation in distorted images. Second, an effective IQA metric is proposed by adaptively integrating robust sample statistics and standard sample statistics via excess kurtosis . Third, instead of using the statistics directly, we adjust them by taking into account the global change of image gradients to avoid exaggerating the degradation degree. Experiments conducted on five well-known IQA databases demonstrate the effectiveness of the proposed pooling strategy in terms of high prediction accuracy and monotonicity.},
  archive      = {J_NEUCOM},
  author       = {Yurong Ling and Fei Zhou and Kun Guo and Jing-Hao Xue},
  doi          = {10.1016/j.neucom.2021.12.098},
  journal      = {Neurocomputing},
  pages        = {568-582},
  shortjournal = {Neurocomputing},
  title        = {ASSP: An adaptive sample statistics-based pooling for full-reference image quality assessment},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A wearable-HAR oriented sensory data generation method
based on spatio-temporal reinforced conditional GANs. <em>NEUCOM</em>,
<em>493</em>, 548–567. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition based on wearable sensors plays an essential role in promoting many practical applications, such as healthcare, motion monitoring, medical examination, anomaly detection and human-computer interaction. It’s worth noting that longer temporal sensory sequences could reflect the characteristics of different daily activities more accurately. However, existing GANs-based time series generation methods could only synthesize uniaxial, multivariate or multidimensional sensor data over a relatively short span of time. These shorter synthetic time series could not effectively represent at least one complete daily activity cycle. To synthesize longer and more realistic multi-axial sensor data, this paper proposes a new customized GANs-based sensory data synthesizing method, which is dedicated to wearable activity recognition tasks, named Conditional SensoryGANs. Firstly, the elaborately designed MultiScale MultiDimensional (MSMD) spatiotemporal function module endows the proposed Conditional SensoryGANs with the capability of synthesizing longer sensory sequences, which could better characterize different behaviors with periodicity. Secondly, benefited from the well-designed Time-Frequency Enhancement (TFE) functional module , Conditional SensoryGANs could more accurately capture each axis’s spatiotemporal property and spatial correlation between different axes to improve the fidelity of synthetic sensor data. Thirdly, Conditional SensoryGANs could synthesize verisimilar wearable sensor data of the specified quantity and category under a unified framework with the embedded condition’s refined control. Qualitative visual evaluations demonstrate that the proposed method has more excellent capability for synthesizing verisimilar wearable multi-axial sensor data than the state-of-the-art GAN-based sensor data generation methods. Quantitative experiments also prove that it could achieve better results than off-the-shelf GANs-based time series methods for synthesizing wearable multi-axial sensor data. Meanwhile, empirical results demonstrate that synthetic sensor data from Conditional SensoryGANs can achieve comparatively approximate usability in the field of wearable human activity recognition than the real sensor data.},
  archive      = {J_NEUCOM},
  author       = {Jiwei Wang and Yiqiang Chen and Yang Gu},
  doi          = {10.1016/j.neucom.2021.12.097},
  journal      = {Neurocomputing},
  pages        = {548-567},
  shortjournal = {Neurocomputing},
  title        = {A wearable-HAR oriented sensory data generation method based on spatio-temporal reinforced conditional GANs},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sparse-view cone beam CT reconstruction using dual CNNs in
projection domain and image domain. <em>NEUCOM</em>, <em>493</em>,
536–547. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cone beam computed tomography (CBCT) is used extensively in image-guided surgery and radiotherapy, but it induces ionizing radiation to the patients. Sparse-view CBCT is a main method to lower the radiation dose; however, it introduces streak artifacts in the reconstructed images. We develop a dual convolutional neural network architecture (DualCNN) to eliminate streak artifacts from sparse-view CBCT images. In the first part, we develop an interpolation CNN in the projection domain to restore the full-view projections from sparse-view projections. The restored full-view projections are then input to the Feldkamp–Davis–Kress algorithm for reconstructing the CBCT images. In the second part, we develop an image domain CNN to further improve the quality of the CBCT images. DualCNN is evaluated using real CBCT X-ray projection data of walnuts. Experimental results show that, DualCNN reconstructs good CT images with only a quarter number of full-view projections, and it achieves significantly higher performance than other representative methods in terms of qualitative and quantitative evaluations . DualCNN achieves a mean root-mean-square error of 0.0369, a mean peak-signal-to-noise ratio of 26.93 dB and a mean structural similarity of 0.732 in 3800 reconstructed images. Therefore, our DualCNN can significantly lower the CBCT radiation dose while maintaining good quality of reconstructed images.},
  archive      = {J_NEUCOM},
  author       = {Lianying Chao and Zhiwei Wang and Haobo Zhang and Wenting Xu and Peng Zhang and Qiang Li},
  doi          = {10.1016/j.neucom.2021.12.096},
  journal      = {Neurocomputing},
  pages        = {536-547},
  shortjournal = {Neurocomputing},
  title        = {Sparse-view cone beam CT reconstruction using dual CNNs in projection domain and image domain},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GAN-based anomaly detection: A review. <em>NEUCOM</em>,
<em>493</em>, 497–535. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised learning algorithms have shown limited use in the field of anomaly detection due to the unpredictability and difficulty in acquiring abnormal samples. In recent years, unsupervised or semi-supervised anomaly-detection algorithms have become more widely used in anomaly-detection tasks. As a form of unsupervised learning algorithm, generative adversarial networks (GAN/GANs) have been widely used in anomaly detection because GAN can make abnormal inferences using adversarial learning of the representation of samples. To provide inspiration for the research of GAN-based anomaly detection, this review reconsiders the concept of anomaly, provides three criteria for discussing the anomaly detection task, and discusses the current challenges of anomaly detection. For the existing works, this review focuses on the theoretical and technological evolution, theoretical basis, applicable tasks, and practical application of GAN-based anomaly detection. This review also addresses the current internal and external outstanding issues encountered by GAN-based anomaly detection and predicts and analyzes several future research directions in detail. This review summarizes more than 330 references related to GAN-based anomaly detection and provides detailed technical information for researchers who are interested in GANs and want to apply them to anomaly-detection tasks.},
  archive      = {J_NEUCOM},
  author       = {Xuan Xia and Xizhou Pan and Nan Li and Xing He and Lin Ma and Xiaoguang Zhang and Ning Ding},
  doi          = {10.1016/j.neucom.2021.12.093},
  journal      = {Neurocomputing},
  pages        = {497-535},
  shortjournal = {Neurocomputing},
  title        = {GAN-based anomaly detection: A review},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quality enhancement of compressed screen content video by
cross-frame information fusion. <em>NEUCOM</em>, <em>493</em>, 486–496.
(<a href="https://doi.org/10.1016/j.neucom.2021.12.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the rise of various online learning platforms and game live broadcast industries, screen content video, a special type of video, is gradually emerging, and its traffic on the Internet is also increasing. Therefore, how to effectively enhance the quality of the screen content video has become an urgent problem to be solved. There exist a few successful compressed video enhancement algorithms. However, since there are a large number of areas with similar colors in the compressed screen content video, the traditional algorithms based on optical flow and deformable convolution cannot align the screen content video frames well. Specifically, for screen content videos containing animations and games, we propose a screen content video quality enhancement network based on the cross-fusion of multi-frame information. It includes a feature extraction module, a feature fusion module, an edge detail recovery module, and a reconstruction module. Our main contribution is the alignment-free quality enhancement framework based on cross-frame information fusion instead of traditional alignment based approaches. Through our experiments, the best results have been achieved on 13 screen content videos containing animations and games compressed by the SCC branch of HEVC/H.265.},
  archive      = {J_NEUCOM},
  author       = {Jiawang Huang and Jinzhong Cui and Mao Ye and Shuai Li and Yu Zhao},
  doi          = {10.1016/j.neucom.2021.12.092},
  journal      = {Neurocomputing},
  pages        = {486-496},
  shortjournal = {Neurocomputing},
  title        = {Quality enhancement of compressed screen content video by cross-frame information fusion},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive fuzzy command filtering control for nonlinear MIMO
systems with full state constraints and unknown control direction.
<em>NEUCOM</em>, <em>493</em>, 474–485. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the command-filter-based adaptive control strategy is proposed for a class of unknown nonlinear multiple input multiple output (MIMO) systems with full state constraints and unknown control direction, whose unknown nonlinear function is approximated by the fuzzy logic system (FLS). First, the fuzzy logic system (FLS) act as the universal approximator of the unknown nonlinear function and the command-filtered backstepping control method is utilized to handle the difficulty induced by the explosion of differentiation, as well as the compensating signals are designed to make up for the command filter error. Besides, the appropriate barrier Lyapunov function and the Nussbaum-type functions are employed to deal with the constraints violation and the unknown direction control gains, respectively. It is proved that the practical tracking performance of the system can be achieved with the designed protocols and all signals in the closed-loop system are semiglobal uniformly ultimately bounded. Finally, the simulation example is performed to verify the effectiveness of the proposed control strategy.},
  archive      = {J_NEUCOM},
  author       = {Yuhao Zhou and Xin Wang},
  doi          = {10.1016/j.neucom.2021.12.091},
  journal      = {Neurocomputing},
  pages        = {474-485},
  shortjournal = {Neurocomputing},
  title        = {Adaptive fuzzy command filtering control for nonlinear MIMO systems with full state constraints and unknown control direction},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Similarity-based domain adaptation network. <em>NEUCOM</em>,
<em>493</em>, 462–473. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation utilizes labeled source domains to solve classification problems in the unlabeled target domain. Previous domain adaptation methods consider global domain adaptation while neglecting class-wise information, thus leading to poor transfer performance. In recent years, many researchers studied class-wise domain adaptation, the focus of which is to accurately align the distribution of different domains. However, these methods cannot distinguish samples with different similarities during domain adaptation, which results in the inaccurate matching of different domains. Therefore, this paper proposes a Similarity-Based Adaptation Network (SBAN), which optimizes Similarity-Based Domain Discrepancy (SBDD) that models similarity-based intra-domain and inter-domain discrepancies, and proposes an alternating update strategy to train the SBAN. Specifically, we assign different weights to samples with different similarities, and minimize the similarity-based inter-domain discrepancy to make similar samples dominate the distribution alignment across domains while alleviating the effect of dissimilar samples, and minimize the similarity-based intra-domain discrepancy to align dissimilar samples with similar samples within the same domain to learn more discriminative representations. Extensive experiments on four widely used benchmark datasets show that SBAN performs better than several latest domain adaptation methods.},
  archive      = {J_NEUCOM},
  author       = {Meixin Peng and Zhanshan Li and Xin Juan},
  doi          = {10.1016/j.neucom.2021.12.089},
  journal      = {Neurocomputing},
  pages        = {462-473},
  shortjournal = {Neurocomputing},
  title        = {Similarity-based domain adaptation network},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymptotic and finite-time synchronization of
fractional-order multiplex networks with time delays by adaptive and
impulsive control. <em>NEUCOM</em>, <em>493</em>, 445–461. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we analyze the asymptotic synchronization of fractional-order multiplex networks with time delays via adaptive control , where intra-layer and inter-layer transmission delays are taken into consideration. By introducing a new fractional-order Halanay-type inequality and utilizing graph-theoretic method and Lyapunov method, we formulate some sufficient conditions to ensure the asymptotic synchronization of fractional-order multiplex networks with time delays . Furthermore, in the case that there is no delay in intra-layer and inter-layer transmissions, we investigate the finite-time synchronization of fractional-order multiplex networks by impulsive control. Meanwhile, the upper bound of the settling time for finite-time synchronization is reckoned. In addition, the results herein are applied to coupled Chua’s circuits on fractional-order multiplex networks with time delays. Finally, some numerical simulations are carried out to demonstrate the effectiveness of the developed results.},
  archive      = {J_NEUCOM},
  author       = {Tianjiao Luo and Qi Wang and Qilong Jia and Yao Xu},
  doi          = {10.1016/j.neucom.2021.12.087},
  journal      = {Neurocomputing},
  pages        = {445-461},
  shortjournal = {Neurocomputing},
  title        = {Asymptotic and finite-time synchronization of fractional-order multiplex networks with time delays by adaptive and impulsive control},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Accelerating spiking neural networks using quantum
algorithm with high success probability and high calculation accuracy.
<em>NEUCOM</em>, <em>493</em>, 435–444. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) are a kind of neuromorphic computing which meticulously imitates the operations of biological nervous systems. Thus, the SNN is seen as a promising approach to further improve the level of intelligence that the legacy artificial neural networks achieved. In a spiking neuron of an SNN, it is a key step with the highest computing complexity to find out the moment when the output stimuli occur. Classic computer (i.e., electrical computer) based acceleration cannot reduce the computational complexity of the operations in the spiking neurons. As a result, the SNN suffers from scaling and deeper emulation problems. Considering these, in this paper, we propose a quantum algorithm to reduce the complexity of the key steps in the SNN and use this algorithm to build a quantum spiking neuron network (QSNN). More specifically, first, we give mathematical proof that the problem of finding the output stimuli is approximately equal to the problem of calculating the unsigned vector inner products, which can transfer to a quantum operation. Second, we design a scalable quantum circuit of QSNN for data of any dimension and evaluate its basic success probability and calculation accuracy. Third, to improve the QSNN performance, we propose a method to improve the minimum success probability to 99.8\%, by repeatedly performing the quantum circuit only 11 times. Fourth, we prove that the computational complexity of the QSNN is a log-polynomial relationship with the data dimension, which is much lower than that of the linear complexity of the classic SNN. Finally, we apply the QSNN to solve classification tasks on two real-world datasets, i.e., MNIST and fashion MNIST which both have two noise levels (i.e., no noise and 50\% of the noise). The experiment results show that in addition to the acceleration, QSNN and SNN have equal classification accuracy, which suggests the feasibility and robustness of the QSNN.},
  archive      = {J_NEUCOM},
  author       = {Yanhu Chen and Cen Wang and Hongxiang Guo and Xiong Gao and Jian Wu},
  doi          = {10.1016/j.neucom.2022.02.004},
  journal      = {Neurocomputing},
  pages        = {435-444},
  shortjournal = {Neurocomputing},
  title        = {Accelerating spiking neural networks using quantum algorithm with high success probability and high calculation accuracy},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Examining and mitigating gender bias in text emotion
detection task. <em>NEUCOM</em>, <em>493</em>, 422–434. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gender bias is an important problem that affects models of natural language, and the propagation of such biases could be harmful. Much research focuses on gender biases in word embeddings , and there are also some works on gender biases in subsequent tasks. However, very limited prior work has been done on gender issues in emotion detection tasks. In this paper, we investigate the effect of gender in text emotion detection. Existing methods for gender biases require gender balanced and gender-swapping data, and might influence the performance of the target task due to removing more information related to sensitive attributes. We present different solutions to measuring and mitigating gender bias in emotion detection. To measure gender bias, we first prepare datasets annotated with emotional classes and gender information. Then, we compare the performance of emotion recognition models from gender balanced samples, and also analyze gender prediction results from emotion related data. Our experiment results show that there exists gender bias in emotion detection: the models trained on the female data often achieve better results than the male models, and the female models and the male models report the opposite trends on the recognition of some emotions. We also attempt to mitigate gender bias by developing various approaches including products of experts, introducing weights and variants of focal loss, as well as adversarial training . Compared to other debiasing methods, adversarial trainings represent tpr reduction approximately 0.02–0.03 while simultaneously less harming performance by below 1.0 points on our prepared datasets. Further, we show that efficient parameters can lead to further improvements.},
  archive      = {J_NEUCOM},
  author       = {Odbal and Guanhong Zhang and Sophia Ananiadou},
  doi          = {10.1016/j.neucom.2022.04.057},
  journal      = {Neurocomputing},
  pages        = {422-434},
  shortjournal = {Neurocomputing},
  title        = {Examining and mitigating gender bias in text emotion detection task},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Event-triggered based practical fixed-time consensus for
chained-form multi-agent systems with dynamic disturbances.
<em>NEUCOM</em>, <em>493</em>, 414–421. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the practical fixed-time event-triggered consensus problem of multi-agent nonholonomic systems with dynamic disturbances. The continuous communications can be avoided in the update of controller. By converting the nonholonomic chained systems into two subsystems, a switching control algorithm was proposed to deal with the coupling problem in systems. Compared with the event-triggered fixed-time consensus problem of first-order or second-order linear systems, the research of nonholonomic chained systems is more challenging due to the inherent nonlinearity of these systems. Moreover, the convergence time of fixed-time consensus problem is independent of initial states, which is more practical than finite-time consensus problem. Furthermore, it is proved that there is no Zeno behavior under the fixed-time event-triggered consensus control strategies. The effectiveness of the proposed control algorithms is verified by numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Dengyu Liang and Chaoli Wang and Zongyu Zuo and Xuan Cai},
  doi          = {10.1016/j.neucom.2022.04.048},
  journal      = {Neurocomputing},
  pages        = {414-421},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered based practical fixed-time consensus for chained-form multi-agent systems with dynamic disturbances},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Medical image segmentation with 3D convolutional neural
networks: A survey. <em>NEUCOM</em>, <em>493</em>, 397–413. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-aided medical image analysis plays a significant role in assisting medical practitioners for expert clinical diagnosis and deciding the optimal treatment plan. At present, convolutional neural networks (CNNs) are the preferred choice for medical image analysis. In addition, with the rapid advancements in three-dimensional (3D) imaging systems and the availability of excellent hardware and software support to process large volumes of data, 3D deep learning methods are gaining popularity in medical image analysis. Here, we present an extensive review of the recently proposed 3D deep learning methods for medical image segmentation . Furthermore, the research gaps and future directions in 3D medical image segmentation are discussed.},
  archive      = {J_NEUCOM},
  author       = {S. Niyas and S.J. Pawan and M. Anand Kumar and Jeny Rajan},
  doi          = {10.1016/j.neucom.2022.04.065},
  journal      = {Neurocomputing},
  pages        = {397-413},
  shortjournal = {Neurocomputing},
  title        = {Medical image segmentation with 3D convolutional neural networks: A survey},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). H∞ state estimation for t-s fuzzy reaction-diffusion delayed
neural networks with randomly occurring gain uncertainties and
semi-markov jump parameters. <em>NEUCOM</em>, <em>493</em>, 385–396. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the H ∞ H∞ state estimation issue for Takagi-Sugeno (T-S) fuzzy reaction-diffusion delayed neural networks (RDNNs) with randomly occurring gain uncertainties and semi-Markov jump parameters (sMJP). The considered gain perturbations are assumed to occur in a random manner and are modeled by a random variable with the Bernoulli distribution . Furthermore, different from the existing T-S fuzzy neural networks (NNs), as the first attempt, the reaction-diffusion phenomenon, the T-S fuzzy rules, and the sMJP are taken into account in the unified framework, which makes the proposed models more applicable. By utilizing the Lyapunov functional method and introducing a suitable free weight matrix, sufficient critered to guarantee the exponential stability and H ∞ H∞ performance of estimation error. In order to improve the tolerance of the proposed estimator to gain variations, a fuzzy resilient estimator design scheme is presented with the aid of some decoupling techniques. Finally, two numerical simulations verify the effectiveness and superiority of the proposed scheme.},
  archive      = {J_NEUCOM},
  author       = {Yamin Liu and Fang Fang and Jianping Zhou and Yajuan Liu},
  doi          = {10.1016/j.neucom.2022.04.060},
  journal      = {Neurocomputing},
  pages        = {385-396},
  shortjournal = {Neurocomputing},
  title        = {H∞ state estimation for T-S fuzzy reaction-diffusion delayed neural networks with randomly occurring gain uncertainties and semi-markov jump parameters},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Low personality-sensitive feature learning for radar-based
gesture recognition. <em>NEUCOM</em>, <em>493</em>, 373–384. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radar-based sensing of gestures has gained tremendous attention with the recent advancements in radar technologies. However, evident discrepancies exist in the gesture samples due to hand flexibility and individual habits. It is challenging for traditional methods to identify the gestures from unknown data sources. Cross-person (Cross-scenario) recognition refers to a recognition where the training and test samples are from different people (scenarios), respectively. To explore how the recognition performance is affected by the individual habits, the reasons are analyzed and visualized through the experiments. On this basis, HandNet is targeted proposed for the low personality-sensitive feature learning and it has two main contributions. First, a Stepped Data Augmentation (SDA) is proposed to reduce the sample interferences by non-coherent accumulating, and capture the inter-frame dependencies. Second, a Focus on Generalization loss (FoG loss) is proposed to highlight the generalized feature learning by res tricting the distances of inter-source features. Extensive experiments demonstrate that HandNet effectively reduces the classifier’s sensitivity to the personalized habits, and outperforms the existing state-of-the-art methods on the cross-person and cross-scenario gesture recognition . To the best of our knowledge, it is the first time to dedicate to addressing the radar-based gesture recognition with low personal sensitivity, which is more suitable for practical scenarios.},
  archive      = {J_NEUCOM},
  author       = {Liying Wang and Zongyong Cui and Yiming Pi and Changjie Cao and Zongjie Cao},
  doi          = {10.1016/j.neucom.2022.04.035},
  journal      = {Neurocomputing},
  pages        = {373-384},
  shortjournal = {Neurocomputing},
  title        = {Low personality-sensitive feature learning for radar-based gesture recognition},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Enhance prototypical networks with hybrid attention and
confusing loss function for few-shot relation classification.
<em>NEUCOM</em>, <em>493</em>, 362–372. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation classification (RC) is a fundamental task to building knowledge graphs and describing semantic formalization. It aims to classify a relation between the head and the tail entities in a sentence. The existing RC method mainly adopts the distant supervision (DS) scheme. However, DS still has the problem of long-tail and suffers from data sparsity . Recently, few-shot learning (FSL) has attracted people’s attention. It solves the long-tail problem by learning from few-shot samples. The prototypical networks have a better effect on FSL, which classifies a relation by distance. However, the prototypical networks and their related variants did not consider the critical role of entity words. In addition, not all sentences in support set equally contributed to classifying relations. Furthermore, an entity pair in a sentence may have true and confusing relations, which is difficult for the RC model to distinguish them. A new context encoder BERT_FE is proposed to address those problems, which uses the BERT model as pre-training and fuses the information of head and tail entities by entity word-level attention (WLA). At the same time, the sentence-level attention (SLA) is proposed to give more weight to sentences of the support set similar to the query instance and improve the classification accuracy . A confusing loss function (CLF) is designed to enhance the model’s ability to distinguish between true and confusing relations. The experiment results demonstrate that our proposed model (HACLF) is better than several baseline models .},
  archive      = {J_NEUCOM},
  author       = {Yibing Li and Zuchang Ma and Lisheng Gao and Yichen Wu and Fei Xie and Xiaoye Ren},
  doi          = {10.1016/j.neucom.2022.04.067},
  journal      = {Neurocomputing},
  pages        = {362-372},
  shortjournal = {Neurocomputing},
  title        = {Enhance prototypical networks with hybrid attention and confusing loss function for few-shot relation classification},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A motion blur QR code identification algorithm based on
feature extracting and improved adaptive thresholding. <em>NEUCOM</em>,
<em>493</em>, 351–361. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion blur can easily affect the quality of images. For example, Quick Response (QR) code is hard to be identified with severe motion blur caused by camera shaking or object moving. In this paper, a motion blur QR code identification algorithm based on feature extraction and improved adaptive thresholding is proposed. First, this work designs a feature extraction framework using a deep convolutional network for motion deblurring. The framework consists of a basic end-to-end network for feature extraction, an encoder-decoder structure for increasing training feasibility and several ResBlocks for producing large receptive fields. Then an improved adaptive thresholding method is used to avoid influence caused by uneven illumination. Finally, the proposed algorithm is compared with several recent methods on a dataset including QR code images influenced by both motion blur and uneven illumination. Experimental results demonstrate that the processing time and identification accuracy of the proposed algorithm are improved in executing motion blur QR code identification missions compared with other competing methods.},
  archive      = {J_NEUCOM},
  author       = {Junnian Li and Dong Zhang and MengChu Zhou and Zhengcai Cao},
  doi          = {10.1016/j.neucom.2022.04.041},
  journal      = {Neurocomputing},
  pages        = {351-361},
  shortjournal = {Neurocomputing},
  title        = {A motion blur QR code identification algorithm based on feature extracting and improved adaptive thresholding},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multitask learning for emotion and personality traits
detection. <em>NEUCOM</em>, <em>493</em>, 340–350. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning-based automated personality traits detection has received a lot of attention, especially now, due to the massive digital footprints of an individual. Moreover, many researchers have demonstrated that there is a strong link between personality traits and emotions. In this paper, we build on the known correlation between personality traits and emotional behaviors and propose a novel transferring based multitask learning framework that simultaneously predicts both of them. We also empirically evaluate and discuss different information-sharing mechanisms between the two tasks. To ensure the high quality of the learning process, we adopt a model-agnostic meta-learning-like framework for model optimization. Our computationally efficient multitask learning model achieves the state-of-the-art performance across multiple famous personality and emotion datasets, even outperforming language model-based models.},
  archive      = {J_NEUCOM},
  author       = {Yang Li and Amirmohammad Kazemeini and Yash Mehta and Erik Cambria},
  doi          = {10.1016/j.neucom.2022.04.049},
  journal      = {Neurocomputing},
  pages        = {340-350},
  shortjournal = {Neurocomputing},
  title        = {Multitask learning for emotion and personality traits detection},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CIRNet: An improved RGBT tracking via cross-modality
interaction and re-identification. <em>NEUCOM</em>, <em>493</em>,
327–339. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGBT tracking is receiving more and more attention because of its huge tracking potential in an all-weather environment. RGB and thermal source data contain different levels of information about the object. Utilizing the complementary advantage of different levels of information can effectively improve the tracking performance. Existing work focuses on the extraction and fusion of multi-modal features. Although these methods effectively deploy the fusion of information among multiple modalities, they ignore the potential value of multi-level shared clues in different modalities. In addition, these works cannot provide effective candidate boxes after tracking drift, resulting in limited tracker performance. In this paper, we propose a cross-modality interaction and re-identification network that performs multi-level modality-shared, modality-specific and object probability prediction learning. We designed two feature extraction sub-networks, namely, a multi-level modality-shared fusion network and modality complementary sub-network. Specifically, the two sub-networks extract and fuse multi-level modality shared information and modality specific information, respectively. To optimize tracking drift, object-aware branches that predict the object-centered state are designed. Our object-aware branching is simple, neat and efficient. Moreover, to achieve the visual tracking real-time requirement, we designed the object regression branch that does not require repeated region suggestion input. By extensive experiments and comparisons with state-of-the-art trackers on the RGBT tracking benchmark dataset, our tracker achieves leading performance and essentially real-time tracking speeds. Tracking drift caused by occlusion, fast motion and camera moving is significantly optimized.},
  archive      = {J_NEUCOM},
  author       = {Weidai Xia and Dongming Zhou and Jinde Cao and Yanyu Liu and Ruichao Hou},
  doi          = {10.1016/j.neucom.2022.04.017},
  journal      = {Neurocomputing},
  pages        = {327-339},
  shortjournal = {Neurocomputing},
  title        = {CIRNet: An improved RGBT tracking via cross-modality interaction and re-identification},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-scale receptive field fusion network for lightweight
image super-resolution. <em>NEUCOM</em>, <em>493</em>, 314–326. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the rapid development of deep learning , quantities of convolutional neural network (CNN) based methods are applied to the field of single image super-resolution (SISR), which have excellent performance compared with traditional ones. However, these methods have a large amount of calculation and memory consumption, limiting their application in edge devices. To address this problem, we propose a more lightweight multi-scale receptive field fusion network (MRFN) for fast and accurate SISR. Specifically, we first propose a multi-scale receptive field fusion block to fuse different scales of spatial information and enlarge the overall receptive field simultaneously. Secondly, based on the non-local sparse attention, we introduce a hash-learnable cheap non-local attention to capture long-range dependencies with much fewer parameters and calculations. Moreover, channel attention is also very important for SISR, we further combine directional second-order information and spatial coordinate information into it to enhance its capability, which is called second-order coordinate attention. The cooperation of these components leads to the success of our MRFN. Extensive experimental results show that our method achieves a better trade-off against other state-of-the-art methods in terms of SISR performance and model complexity.},
  archive      = {J_NEUCOM},
  author       = {Jing Luo and Lin Zhao and Li Zhu and Wenbing Tao},
  doi          = {10.1016/j.neucom.2022.04.038},
  journal      = {Neurocomputing},
  pages        = {314-326},
  shortjournal = {Neurocomputing},
  title        = {Multi-scale receptive field fusion network for lightweight image super-resolution},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sampled-data observer based event-triggered leader-follower
consensus for uncertain nonlinear multi-agent systems☆. <em>NEUCOM</em>,
<em>493</em>, 305–313. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the event-triggered output feedback consensus problem for feedforward nonlinear multi-agent systems with a directed topology graph . To avoid continuous monitoring and communication among agents, the periodic sampled-based output information is adopted to construct the observer. The observer-based controller for every agent updates under a newly designed triggering mechanism, which relies on its output and the relative output information of its neighbour agents at sampling points. With the designed event-triggered control protocol, the leader-follower consensus is achieved and the Zeno behavior is excluded effectively. Moreover, the sampling period and state delay of the considered system can be arbitrary positive numbers. Finally, the consensus result is extended to a class of feedforward multi-agent systems with the system nonlinearities satisfying the increment ratio of an unbounded time-varying function. A simulation example with two cases is given to demonstrate the proposed event-triggered control protocols.},
  archive      = {J_NEUCOM},
  author       = {Yanjie Chang and Xianfu Zhang and Qingrong Liu and Xiandong Chen},
  doi          = {10.1016/j.neucom.2022.04.071},
  journal      = {Neurocomputing},
  pages        = {305-313},
  shortjournal = {Neurocomputing},
  title        = {Sampled-data observer based event-triggered leader-follower consensus for uncertain nonlinear multi-agent systems☆},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Swin transformer for fast MRI. <em>NEUCOM</em>,
<em>493</em>, 281–304. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) is an important non-invasive clinical tool that can produce high-resolution and reproducible images. However, a long scanning time is required for high-quality MR images, which leads to exhaustion and discomfort of patients, inducing more artefacts due to voluntary movements of the patients and involuntary physiological movements. To accelerate the scanning process, methods by k -space undersampling and deep learning based reconstruction have been popularised. This work introduced SwinMR, a novel Swin transformer based method for fast MRI reconstruction. The whole network consisted of an input module (IM), a feature extraction module (FEM) and an output module (OM). The IM and OM were 2D convolutional layers and the FEM was composed of a cascaded of residual Swin transformer blocks (RSTBs) and 2D convolutional layers. The RSTB consisted of a series of Swin transformer layers (STLs). The shifted windows multi-head self-attention (W-MSA/SW-MSA) of STL was performed in shifted windows rather than the multi-head self-attention (MSA) of the original transformer in the whole image space. A novel multi-channel loss was proposed by using the sensitivity maps, which was proved to reserve more textures and details. We performed a series of comparative studies and ablation studies in the Calgary-Campinas public brain MR dataset and conducted a downstream segmentation experiment in the Multi-modal Brain Tumour Segmentation Challenge 2017 dataset. The results demonstrate our SwinMR achieved high-quality reconstruction compared with other benchmark methods, and it shows great robustness with different undersampling masks, under noise interruption and on different datasets. The code is publicly available at https://github.com/ayanglab/SwinMR .},
  archive      = {J_NEUCOM},
  author       = {Jiahao Huang and Yingying Fang and Yinzhe Wu and Huanjun Wu and Zhifan Gao and Yang Li and Javier Del Ser and Jun Xia and Guang Yang},
  doi          = {10.1016/j.neucom.2022.04.051},
  journal      = {Neurocomputing},
  pages        = {281-304},
  shortjournal = {Neurocomputing},
  title        = {Swin transformer for fast MRI},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Pair-wise aspect and opinion terms extraction as graph
parsing via a novel mutually-aware interaction mechanism.
<em>NEUCOM</em>, <em>493</em>, 268–280. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pair-wise aspect and opinion term extraction (PAOTE) task aims to extract aspect terms and opinion terms from reviews in the form of opinion pairs, which provides a global profile for reviews of goods or users. Up-to-date studies ignore the interaction between term detection and term pairing, which may be crucial for the PAOTE task. Other studies use syntactic dependency structures to enhance their models, which cannot better provide task-specific structural information. In this work, we design an aspect-to-opinion graph and transform PAOTE into a graph parsing task. To exploit the interaction between term detection and pairing, we propose a novel mutually-aware interaction network (MAIN), which interactively updates the representations for term detection and pairing via graph sampling and convolution. Further, the word-word graph learned during training can be iteratively refined and gradually approaches the aspect-to-opinion graph. Experimental results on four benchmark datasets show that our proposed method significantly outperforms strong baselines with state-of-the-art performance and achieves a maximum increase of 2.01 points on the F1 metric. Further analysis demonstrates the advance of the aspect-to-opinion graph and the effectiveness of the mutually-aware interaction mechanism.},
  archive      = {J_NEUCOM},
  author       = {Yijiang Liu and Fei Li and Hao Fei and Donghong Ji},
  doi          = {10.1016/j.neucom.2022.04.064},
  journal      = {Neurocomputing},
  pages        = {268-280},
  shortjournal = {Neurocomputing},
  title        = {Pair-wise aspect and opinion terms extraction as graph parsing via a novel mutually-aware interaction mechanism},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SAR-DRDNet: A SAR image despeckling network with detail
recovery. <em>NEUCOM</em>, <em>493</em>, 253–267. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic aperture radar (SAR) image is affected by inherent speckle, greatly hindering its interpretation and subsequent applications. In SAR images despeckling tasks, it is still challenging to remove speckle while preserving spatial details. Traditional methods generally require a complicated design of relationships between the speckled and noise-free SAR images. The growing popularity of deep learning algorithms exhibits great potential in resolving this limitation. However, the existing deep learning-based despeckling methods need further improvement in speckle suppression and details preservation. Therefore, we propose an end-to-end SAR images despeckling residual network with detail recovery, named SAR-DRDNet, which is mainly composed of non-local blocks (NLBs) and detail recovery blocks (DRBs). NLB takes full advantage of the global information of the SAR image to suppress speckle. DRB is further employed to recover lost details in the process of NLBs, taking into account the multi-scale contextual information of pixels and has a larger receptive field without reducing the resolution of feature maps. We validate the proposed SAR-DRDNet on the simulated and real SAR data. Both quantitative and qualitative comparisons demonstrate the superiority of the proposed SAR-DRDNet over the many mainstream methods, evidenced by its capability to achieve a great balance between speckle suppression and textural details preservation.},
  archive      = {J_NEUCOM},
  author       = {Wenfu Wu and Xiao Huang and Zhenfeng Shao and Jiahua Teng and Deren Li},
  doi          = {10.1016/j.neucom.2022.04.066},
  journal      = {Neurocomputing},
  pages        = {253-267},
  shortjournal = {Neurocomputing},
  title        = {SAR-DRDNet: A SAR image despeckling network with detail recovery},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Continuous and discrete zeroing neural network for a class
of multilayer dynamic system. <em>NEUCOM</em>, <em>493</em>, 244–252.
(<a href="https://doi.org/10.1016/j.neucom.2022.04.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilayer dynamic system is widely used in industry and other fields. Different from common systems, multilayer dynamic system has complex structure leading to challenges for research. In this paper, we study zeroing neural network(ZNN) models for a class of multilayer dynamic system(MLDS). In the case of continuous time, continuous ZNN models for continuous MLDS (MLDS-linear-ZNN, MLDS-nonlinear-ZNN and MLDS-noise-tolerant-ZNN) are proposed based on ZNN design method with theoretical analysis. In the discrete case concurrently, discrete ZNN models (MLDS-linear- m DZNN, MLDS-nonlinear- m DZNN and MLDS-noise-tolerant- m DZNN) with m -step ZeaD formula, a new Zhang et al. discretization formula presented in previous paper, are put forward and corresponding discrete algorithms are obtained. Finally, numerical experiments are carried out to verify the superiority and maneuverability of ZNN models for MLDS proposed in this paper.},
  archive      = {J_NEUCOM},
  author       = {Yuting Xue and Jitao Sun and Ying Qian},
  doi          = {10.1016/j.neucom.2022.04.056},
  journal      = {Neurocomputing},
  pages        = {244-252},
  shortjournal = {Neurocomputing},
  title        = {Continuous and discrete zeroing neural network for a class of multilayer dynamic system},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards learning trustworthily, automatically, and with
guarantees on graphs: An overview. <em>NEUCOM</em>, <em>493</em>,
217–243. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing digitization and datification of all aspects of people’s daily life, and the consequent growth in the use of personal data, are increasingly challenging the current development and adoption of Machine Learning (ML). First, the sheer complexity and amount of data available in these applications strongly demands for ML algorithms that can be trained directly on complex structures, which can be naturally described by graphs. In fact, graphs inherently capture information about entities, their attributes, and relationships between them. Directly applying ML to graphs relieves domain experts and data scientists from the challenging and time-consuming problem of designing a suitable vector-based data representation used by classical ML techniques . Second, ML algorithms should not only be designed to achieve high technical and functional standards; as the automated decisions provided by these algorithms can have a relevant impact on people’s lives, their behavior has to be aligned with the values and principles of individuals and society. This demands for designing automated algorithms that we, as humans, can trust, fulfilling the requirements of fairness, robustness, privacy, and explainability. Third, designing effective ML algorithms requires skills and expertise developed at different levels. This substantially hinders the democratization and widespread availability of such technology for society at large, which in turn demands for improving the level of automatization and systematization of their design process, while also providing guarantees on their performance. For this reason, this paper provides an overview of the current works focused towards learning trustworthily, automatically, and with guarantees on graphs.},
  archive      = {J_NEUCOM},
  author       = {Luca Oneto and Nicoló Navarin and Battista Biggio and Federico Errica and Alessio Micheli and Franco Scarselli and Monica Bianchini and Luca Demetrio and Pietro Bongini and Armando Tacchella and Alessandro Sperduti},
  doi          = {10.1016/j.neucom.2022.04.072},
  journal      = {Neurocomputing},
  pages        = {217-243},
  shortjournal = {Neurocomputing},
  title        = {Towards learning trustworthily, automatically, and with guarantees on graphs: An overview},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ASS-GAN: Asymmetric semi-supervised GAN for breast
ultrasound image segmentation. <em>NEUCOM</em>, <em>493</em>, 204–216.
(<a href="https://doi.org/10.1016/j.neucom.2022.04.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasound imaging is considered to be one of the important methods for diagnosing breast cancers, and lesion segmentation is an essential step in automatic computer-aided ultrasonic diagnosis. However, the high cost of ultrasound image labeling and the small amount of data in a single dataset hinder the progress of breast ultrasound (BUS) image segmentation algorithms. In this paper, we propose a novel asymmetric semi-supervised GAN (ASSGAN), which employs two generators and a discriminator for adversarial learning. The two generators can supervise each other, i.e. , they can generate reliable segmentation predicted masks as guidance for each other without labels. Therefore, the unlabeled cases can be used to effectively promote model training. To verify the proposed method, we compared it with fully supervised and semi-supervised methods on three public BUS datasets (DBUI, OASBUI, SPDBUI) and one dataset (SDBUI) that we collected. DBUI, OASBUI, SPDBUI and SDBUI contain 647, 200, 320 and 1805 cases respectively. The experimental results show that the proposed method has excellent performance under the condition of having a small number of labeled images. Compared with fully supervised methods, our method is higher by 4.16\% ∼ 13.94\% 4.16\%∼13.94\% in IoU .},
  archive      = {J_NEUCOM},
  author       = {Donghai Zhai and Bijie Hu and Xun Gong and Haipeng Zou and Jun Luo},
  doi          = {10.1016/j.neucom.2022.04.021},
  journal      = {Neurocomputing},
  pages        = {204-216},
  shortjournal = {Neurocomputing},
  title        = {ASS-GAN: Asymmetric semi-supervised GAN for breast ultrasound image segmentation},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new method to build the adaptive k-nearest neighbors
similarity graph matrix for spectral clustering. <em>NEUCOM</em>,
<em>493</em>, 191–203. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In spectral clustering (SC), the clustering result highly depends on the similarity graph matrix. The k-nearest neighbors graph is a popular method to build the similarity graph matrix with a sparse structure for better graph cutting. However, many current methods require that the parameter k is specified by the user, and specifying an appropriate k for an unknown data set is often a difficult task. In this paper, we propose a new method for building the adaptive k-nearest neighbors similarity graph (AKNNG). The AKNNG specifies different k values for different data points to obtain a better graph structure. Specifically, it sets a maximum number of the nearest neighbors k max kmax and assigns a different k value ( k ⩽ k max k⩽kmax ) for each data point. The k value is adjusted automatically by cutting some weak connections from each data point according to the m powers transform of the similarity graph. The experimental results on Spiral, Multi-clusters, Yale and Coil20 datasets have shown that when setting k max = 20 kmax=20 , the new method has improved the clustering accuracies of these four datasets over 4\%, 6\%, 4\%, 5\%, respectively, in comparison with those by the existing methods. The new method can also reduce the sensitiveness of the number of nearest neighbors, and build the similarity graph with less time.},
  archive      = {J_NEUCOM},
  author       = {Yongda Cai and Joshua Zhexue Huang and Jianfei Yin},
  doi          = {10.1016/j.neucom.2022.04.030},
  journal      = {Neurocomputing},
  pages        = {191-203},
  shortjournal = {Neurocomputing},
  title        = {A new method to build the adaptive k-nearest neighbors similarity graph matrix for spectral clustering},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Motion cues guided feature aggregation and enhancement for
video object segmentation. <em>NEUCOM</em>, <em>493</em>, 176–190. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video object segmentation (VOS) aims to separate unknown target objects from various given video sequences. Although many recent successful methods boosted the performance of VOS, especially those using deep convolution neural networks (CNNs), it is still difficult to aggregate deep features as well as motion cues effectively, which can be important to associate valid information of adjacent frames in video sequences. To tackle this problem, we propose a simple yet effective feature optimization method for VOS based on motion information. To achieve this, we construct a two-branch deep network and use computed motion cues (i.e., optical flow) to jointly optimize global and local interframe correlation information. Additionally, a clustering-based feature enhancement module is proposed to further fuse motion information and enhance the feature saliency of the target area. Optimized feature maps show a significant performance improvement in the final VOS tasks , especially those with rapid target movement. Experiments on the DAVIS16, DAVIS17, YouTube-Objects and YouTube-VOS datasets demonstrate that our simple feature aggregation and enhancement method for VOS improves segmentation accuracy effectively and gains an impressive result compared to many state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xuejun Li and Wenming Zheng and Yuan Zong},
  doi          = {10.1016/j.neucom.2022.03.064},
  journal      = {Neurocomputing},
  pages        = {176-190},
  shortjournal = {Neurocomputing},
  title        = {Motion cues guided feature aggregation and enhancement for video object segmentation},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Session-based recommendation with temporal convolutional
network to balance numerical gaps. <em>NEUCOM</em>, <em>493</em>,
166–175. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A session-based recommendation system recommends the next possible item for users by learning the click session sequences of anonymous users. Considering the session data used is anonymous and few background information is available, it is very challenging to solve these problems. Recently, although the session-based recommendation systems based on neural network have achieved gratifying results, there are still two problems in the existing methods: (1) The value of each dimension in the embedded layer result is a non-zero mean distribution and the numerical gaps are very large. Such numerical gaps will increase the variance of the gradient, hindering the parameter optimization, and thus leading to the final prediction results inaccurate; (2) The previous models cannot effectively learn the long-term dependency information and capture the dependencies between non-adjacent items in the session sequence. To solve the above problems, we propose a Session-based Recommendation with Temporal Convolutional Network to Balance Numerical Gaps model. Specifically, we first normalize the embedded layer results, then constrain the embedded results in the unit hypersphere to reduce their impact on gradient calculation, and finally use Temporal Convolution Network (TCN) complements the multi-layer self-attention network to learn the session sequence.The TCN can obtain large enough receptive fields to fully learn session representation and the short-range item dependence that is missing due to the distraction of attention distribution by the self-attention mechanism, and the self-attention method capture the one-to-one interaction of each item, and obtain the long-term dependence of the item. We have conducted a large number of experiments on three real-world datasets. The results show that, in most cases, our proposed method outperforms the state-of-the-arts methods.},
  archive      = {J_NEUCOM},
  author       = {Weinan Li and Jin Gou and Zongwen Fan},
  doi          = {10.1016/j.neucom.2022.04.069},
  journal      = {Neurocomputing},
  pages        = {166-175},
  shortjournal = {Neurocomputing},
  title        = {Session-based recommendation with temporal convolutional network to balance numerical gaps},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysing deep reinforcement learning agents trained with
domain randomisation. <em>NEUCOM</em>, <em>493</em>, 143–165. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) has the potential to train robots to perform complex tasks in the real world without requiring accurate models of the robot or its environment. However, agents trained with these algorithms typically lack the explainability of more traditional control methods . In this work, we use a combination of out-of-distribution generalisation tests and post hoc interpretability methods in order to understand what strategies DRL-trained agents use to perform a reaching task. To do so, we train agents under different conditions, using comparison to better interpret both quantitative and qualitative results; this allows us to not only provide local explanations, but also broad categorisations of behaviour . A key aim of our work is to understand how agents trained with visual domain randomisation (DR)—a technique which allows agents to generalise from simulation-based-training to the real world—differ from agents trained without. Our results show that the primary outcome of DR is more robust, entangled representations, accompanied by greater spatial structure in convolutional filters . Furthermore, even with an improved saliency method introduced in this work, we show that qualitative studies may not always correspond with quantitative measures, necessitating the combination of inspection tools in order to provide sufficient insights into the behaviour of trained agents. We conclude with recommendations for applying interpretability methods to DRL agents.},
  archive      = {J_NEUCOM},
  author       = {Tianhong Dai and Kai Arulkumaran and Tamara Gerbert and Samyakh Tukra and Feryal Behbahani and Anil Anthony Bharath},
  doi          = {10.1016/j.neucom.2022.04.005},
  journal      = {Neurocomputing},
  pages        = {143-165},
  shortjournal = {Neurocomputing},
  title        = {Analysing deep reinforcement learning agents trained with domain randomisation},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive quantitative control for robust h∞ synchronization
between multiplex neural networks under stochastic cyber attacks.
<em>NEUCOM</em>, <em>493</em>, 129–142. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, to resist stochastic cyber attacks and suppress the influence of the exogenous disturbance in synchronization of multiplex neural networks , an adaptive quantization control strategy is proposed. To overcome uncertainties and represent constraints in communication, an adaptive quantitative controller is designed, which is used to arrive outer synchronized behavior with an H ∞ H∞ performance between the multiplex neural networks under stochastic cyber attacks and exogenous disturbance. The node of the multiplex networks is neural networks which is named neural sub-networks. It is assumed that the neural sub-networks in the multiplex networks with delay topology are coupled by nonlinear functions . Based on Lyapunov stability method, the conditions for the multiplex networks to achieve synchronization with an H ∞ H∞ performance are presented. Finally, numerical example illustrates the effective of the theoretical framework.},
  archive      = {J_NEUCOM},
  author       = {Fei Tan and Shengyuan Xu and Yongmin Li and Yuming Chu and Zhengqiang Zhang},
  doi          = {10.1016/j.neucom.2022.04.054},
  journal      = {Neurocomputing},
  pages        = {129-142},
  shortjournal = {Neurocomputing},
  title        = {Adaptive quantitative control for robust h∞ synchronization between multiplex neural networks under stochastic cyber attacks},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Facial expressions recognition with multi-region divided
attention networks for smart education cloud applications.
<em>NEUCOM</em>, <em>493</em>, 119–128. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the electronic devices and wireless network are seen everywhere, generating a massive amount of online surveillance video data that can be applied to recognize facial expressions to sustain the smart education cloud deployment. However, research highlights of existing Facial Expression Recognition (FER) methods mainly focus on the global or local facial expression separately, but pay less attention to the co-operation relationships among them. To relieve the problem, this paper has proposed a Multi-region Attention Transformation Framework (MATF) to blend the global and local facial details for expression recognition. The proposed framework is structured with a multi-region attention transformation network and a pseudo label generation module. The former is used to fuse the rough global feature and local detail information, which divides the original facial image into multi-region sub-blocks for multi-region expression association. Specifically, it includes the facial local segmentation network , the attention transformation network and the feature weight allocation mechanism for facial expression feature extraction. The pseudo label generation strategy is proposed to enhance the performance of multi-region facial expression integration with a semi-supervised way. Further, a unified training strategy is exploited to optimize the proposed framework to ensure a high FER accuracy. Experiments have been conducted on several public FER datasets (RAF-DB, FERPlus, CAER-S) and results indicate that the proposed method outperforms existing algorithms by 3\%–8\% in accuracy. Based on the multi-region divided attention network learned by the proposed framework, the algorithm for recognizing the expressions can achieve a time complexity as low as O(n), which can be deployed in the mobile electronic devices like the FaceReader series smart facial expression analysis sever. In addition, our facial expression recognition algorithm can be also deployed into the smart education cloud for E-learning.},
  archive      = {J_NEUCOM},
  author       = {Yifei Guo and Jian Huang and Mingfu Xiong and Zhongyuan Wang and Xinrong Hu and Jihong Wang and Mohammad Hijji},
  doi          = {10.1016/j.neucom.2022.04.052},
  journal      = {Neurocomputing},
  pages        = {119-128},
  shortjournal = {Neurocomputing},
  title        = {Facial expressions recognition with multi-region divided attention networks for smart education cloud applications},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A dual attention model based on probabilistically mask for
3D human motion prediction. <em>NEUCOM</em>, <em>493</em>, 106–118. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous work based on attention and Graph Convolutional Network (GCN) have been shown impressive performance in 3D human motion prediction. We believe that 3D human motion prediction problem can be explained as a modeling task of understanding and synthesizing human poses based on learning sub-sequences of historical moments. However, existing methods fail to model the observation that human motion can be learned from historical state. In this paper, we propose a dual attention architecture, optimizing the utilization of historical sequences in two aspects. First, we introduce the local pre-attention based on temporal autocorrelation inside each sub-sequence for the current and historical sub-sequences. Specifically, our research uses the dependence of each moment and its several historical moments to access and capture past information selectively, generating reasonable historical time sub-sequence representation, which is a kind of generative sampling model matching with scores. Then, the current and historical sub-sequences are embedded into global attention to obtain the historical information that contributes the most to the observed sub-sequence. On the other hand, instead of using simple GCN with over-smoothing problem, We extend GCN to a multi-layer residual graph structure. The 3D mean per joint position error (MPJPE) and the mean angle error (MAE) experiments on the datasets of Human3.6 M and 3DPW prove that our model can obtain more accurate prediction results than previous methods. Our code is available at https://github.com/lishuangshuang2022/DANet.},
  archive      = {J_NEUCOM},
  author       = {Wenming Cao and Shuangshuang Li and Jianqi Zhong},
  doi          = {10.1016/j.neucom.2022.04.047},
  journal      = {Neurocomputing},
  pages        = {106-118},
  shortjournal = {Neurocomputing},
  title        = {A dual attention model based on probabilistically mask for 3D human motion prediction},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-layer multi-kernel neural network for determining
associations between non-coding RNAs and diseases. <em>NEUCOM</em>,
<em>493</em>, 91–105. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identification of associations between non-coding RNAs and diseases plays an important role in the study of pathogenesis, which has been a hot topic in recent research. However, traditional methods are time-consuming to detect the associations between non-coding RNAs and diseases. Recently, associations of non-coding RNAs and diseases can be regarded as bipartite network. In this paper, we propose a novel deep multiple kernel learning method, called the multi-layer multi-kernel deep neural network (MLMKDNN). First, many feature matrices are built by multiple features of non-coding RNAs and diseases. Then, these feature matrices are mapped into kernel space and fused by deep neural network . Finally, combine two fused output of MLMKDNN as the predicted values. Three types of non-coding RNAs (miRNA, circRNA and lncRNA) are used to test the performance of MLMKDNN. Compared with other existing methods, our proposed model has high Area Under Precision Recall (AUPR) value on three types of datasets. Experimental results confirm that our method is an effective predictive tool. It provides a framework that can also be applied to the link prediction of other bipartite networks.},
  archive      = {J_NEUCOM},
  author       = {Chengwei Ai and Hongpeng Yang and Yijie Ding and Jijun Tang and Fei Guo},
  doi          = {10.1016/j.neucom.2022.04.068},
  journal      = {Neurocomputing},
  pages        = {91-105},
  shortjournal = {Neurocomputing},
  title        = {A multi-layer multi-kernel neural network for determining associations between non-coding RNAs and diseases},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-source collaborative enhanced for remote sensing
images semantic segmentation. <em>NEUCOM</em>, <em>493</em>, 76–90. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing images semantic segmentation is a difficult instance of image understanding. Due to the regional variability and uncertainty of real-world ground cover features, the semantic segmentation of remote sensing images becomes a challenging task. In this paper, we propose an end-to-end multi-source remote sensing image semantic segmentation network (MCENet) aiming at the problems of intra-class inconsistency and inter-class indistinguishability in remote sensing images. Firstly, we design a collaborative enhanced fusion module to mine complementary characteristics of multi-source remote sensing images. Among them, the collaborative fusion module is used to solve the problem of intra-class difference, and the enhanced aggregation module is used to solve the problem of inter-class similarity. Secondly, a multi-scale decoder is proposed to improve the robustness of the model for small targets and large-scale changes by learning scale invariance features. Experimental results show that our method achieved 2.2\% and 1.11\% mean intersection over union (mIoU) score improvements compared with other methods on the US3D and ISPRS Potsdam data sets, respectively. In addition, the method proposed in this paper also has strong competitiveness in terms of parameter quantity and inference speed.},
  archive      = {J_NEUCOM},
  author       = {Jiaqi Zhao and Di Zhang and Boyu Shi and Yong Zhou and Jingyang Chen and Rui Yao and Yong Xue},
  doi          = {10.1016/j.neucom.2022.04.045},
  journal      = {Neurocomputing},
  pages        = {76-90},
  shortjournal = {Neurocomputing},
  title        = {Multi-source collaborative enhanced for remote sensing images semantic segmentation},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Perturb more, trap more: Understanding behaviors of graph
neural networks. <em>NEUCOM</em>, <em>493</em>, 59–75. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While graph neural networks (GNNs) have shown great potential in various graph-related tasks, their lack of transparency has hindered our understanding of how they arrive at their predictions. The fidelity to the local decision boundary of the original model, indicating how well the explainer fits the original model around the instance to be explained, is neglected by existing GNN explainers. In this paper, we first propose a novel post hoc framework based on local fidelity for any trained GNNs, called TraP2 , which can generate a high-fidelity explanation. Considering that both the relevant graph structure and important features inside each node must be highlighted, a three-layer architecture in TraP2 is designed: i) the interpretation domain is defined by the Tra nslation layer in advance; ii) the local predictive behaviors of the GNNs being explained are probed and monitored by the P erturbation layer, in which multiple perturbations for graph structure and feature level are conducted in the interpretation domain; and iii) highly faithful explanations are generated by fitting the local decision boundary of GNNs being explained through the P araphrase layer. We evaluated TraP2 on several benchmark datasets under the four metrics of accuracy, area under receiver operating characteristic curve, fidelity, and contrastivity, and the results prove that it significantly outperforms state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Chaojie Ji and Ruxin Wang and Hongyan Wu},
  doi          = {10.1016/j.neucom.2022.04.070},
  journal      = {Neurocomputing},
  pages        = {59-75},
  shortjournal = {Neurocomputing},
  title        = {Perturb more, trap more: Understanding behaviors of graph neural networks},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive deep learning for network intrusion detection by
risk analysis. <em>NEUCOM</em>, <em>493</em>, 46–58. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With increasing connectedness, network intrusion has become a critical security concern for modern information systems. The state-of-the-art performance of Network Intrusion Detection (NID) has been achieved by deep learning . Unfortunately, NID remains very challenging, and deep models may still mislabel many activities in real networks. Therefore, there is a need for risk analysis , which aims to know which activities may be mislabeled and why. In this paper, we propose a novel solution of interpretable risk analysis for NID that can rank the activities by their mislabeling risk. Built upon the existing framework of LearnRisk, it first extracts interpretable risk features and then trains a risk model by a learning-to-rank objective. It constructs risk features based on domain knowledge of network intrusion as well as statistical characteristics of activities. Furthermore, we demonstrate how to leverage risk analysis to improve prediction accuracy of deep models. Specifically, we present an adaptive training approach for NID that can effectively fine-tune a deep model towards a particular workload by minimizing its misprediction risk. Finally, we empirically evaluate the performance of the proposed solutions on real benchmark data. Our extensive experiments have shown that the proposed solution of risk analysis can identify mislabeled activities with considerably higher accuracy than the existing alternatives, and the proposed solution of adaptive training can effectively improve the performance of deep models by considerable margins in both offline and online settings.},
  archive      = {J_NEUCOM},
  author       = {Lijun Zhang and Xingyu Lu and Zhaoqiang Chen and Tianwei Liu and Qun Chen and Zhanhuai Li},
  doi          = {10.1016/j.neucom.2022.04.061},
  journal      = {Neurocomputing},
  pages        = {46-58},
  shortjournal = {Neurocomputing},
  title        = {Adaptive deep learning for network intrusion detection by risk analysis},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Synthetic data generation for tabular health records: A
systematic review. <em>NEUCOM</em>, <em>493</em>, 28–45. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic data generation (SDG) research has been ongoing for some time with promising results in different application domains, including healthcare, biometrics and energy consumption. The need for a robust SDG solution to capitalise on advances in Big Data and AI technology has never been greater to enable access to useful data while ensuring reasonable privacy protections. This paper presents a systematic review from the last 5 years (2016–2021) to analyse and report on recent approaches in synthetic tabular data generation (STDG) with a focus on the healthcare application context to preserve patient privacy, paying special attention to the contribution of Generative Adversarial Networks (GAN). In total 34 publications have been retrieved and analysed. A classification of approaches has been proposed and the performance of GAN-based approaches has been extensively analysed. From the systematic review it has been concluded that there is no universal method or metric to evaluate and benchmark the performance of various approaches and that further research is needed to improve the generalisability of GANs to find a model that works optimally across tabular healthcare data.},
  archive      = {J_NEUCOM},
  author       = {Mikel Hernandez and Gorka Epelde and Ane Alberdi and Rodrigo Cilla and Debbie Rankin},
  doi          = {10.1016/j.neucom.2022.04.053},
  journal      = {Neurocomputing},
  pages        = {28-45},
  shortjournal = {Neurocomputing},
  title        = {Synthetic data generation for tabular health records: A systematic review},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NLFFTNet: A non-local feature fusion transformer network for
multi-scale object detection. <em>NEUCOM</em>, <em>493</em>, 15–27. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent object detection studies attempt to implement multi-scale feature fusion through complicated hierarchical structures. However, the existing feature fusion methods only focus on the interaction between the same local positions and fail to describe the long-distance dependencies of features. In this study, a novel non-local feature fused transformer convolutional network is proposed for object detection. This model can focus on global semantic information by calculating the attention of different positions to capture the long-distance dependency. Meanwhile, a dynamic data augment method called configurable mix-splicing is introduced to solve the problem of data imbalance between different classes. The experimental results indicate that attributed to the feature fusion and data augment method, our model achieves better performance than state-of-the-art models on two authoritative public datasets.},
  archive      = {J_NEUCOM},
  author       = {Kai Zeng and Qian Ma and Jiawen Wu and Sijia Xiang and Tao Shen and Lei Zhang},
  doi          = {10.1016/j.neucom.2022.04.062},
  journal      = {Neurocomputing},
  pages        = {15-27},
  shortjournal = {Neurocomputing},
  title        = {NLFFTNet: A non-local feature fusion transformer network for multi-scale object detection},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online author name disambiguation in evolving digital
library. <em>NEUCOM</em>, <em>493</em>, 1–14. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Name ambiguity is a prevalent problem in digital library domain where mapping of bibliographic records to authors is a major issue. The unprecedented growth of the bibliographic records and absence of unique identifiers are further exacerbating the problem. Specifically, name ambiguity affects various bibliometric analysis tasks that include record management as well as scientific assessment of the authors thereby necessitating the name disambiguation. The name disambiguation task is to assign the records, possibly with the ambiguous authorship, to corresponding authors. While existing techniques are good at extracting abstract features from set of records with a common author name that can be subsequently used for clustering the records based on unique author identities, however, such techniques usually perform poorly in disambiguating isolated individual record entries that arrive continuously. Disambiguation of only newly arrived records, rather than the whole records of the digital library is challenging, however, computationally rewarding and thus, not only preferable but becoming the necessity due to tremendous growth in the number of bibliographic records with the time, which is likely to continue. In this regard, we propose an online author name disambiguation approach for evolving digital library. Our approach involves representation learning of records in an online manner in evolving (academic networks) digital library using dynamic graph embedding and clustering of latent representation of records. We show the use of our online name disambiguation method in batch setting (for static or initial records of digital library) and incremental setting (for new records of digital library). Significant improvement, over existing state-of-the-art methods in terms of various evaluation metrics , has been observed which indicates the effectiveness of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {K.M. Pooja and Samrat Mondal and Joydeep Chandra},
  doi          = {10.1016/j.neucom.2021.07.104},
  journal      = {Neurocomputing},
  pages        = {1-14},
  shortjournal = {Neurocomputing},
  title        = {Online author name disambiguation in evolving digital library},
  volume       = {493},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Goal representation adaptive critic design for discrete-time
uncertain systems subjected to input constraints: The event-triggered
case. <em>NEUCOM</em>, <em>492</em>, 676–688. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the event-triggered near-optimal control issue is studied for the input-constrained uncertain system with the input-to-state stability (ISS) attribute. In the proposed approach, we design a near-optimal controller and an adaptive event-triggered mechanism (ETM) to optimize the cost function and reduce the redundant computational consumption. Toward this end, the robust control problem of the uncertain system is first converted into the near-optimal control issue for the nominal system via the designed cost function. Then, for reducing the redundant computational consumption for uncertain systems, the adaptive ETM is distinguishingly devised for the matched uncertainty. Subsequently, a sufficient condition is offered to ensure the asymptotical stability for the discrete-time uncertain system with the ISS attribute under the event-triggered controller. To further improve the control performance for the closed-loop systems, the goal representation adaptive critic design approach is proposed in the event-triggered context with non-periodic weight updating rules for neural networks are designed for the controlled system. Moreover, the corresponding convergence of the proposed control approach is considered. Finally, the effectiveness of the suggested approach is demonstrated by two simulation cases.},
  archive      = {J_NEUCOM},
  author       = {Shangwei Zhao and Jingcheng Wang and Hongyuan Wang and Haotian Xu},
  doi          = {10.1016/j.neucom.2021.12.057},
  journal      = {Neurocomputing},
  pages        = {676-688},
  shortjournal = {Neurocomputing},
  title        = {Goal representation adaptive critic design for discrete-time uncertain systems subjected to input constraints: The event-triggered case},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Oscillatory source tensor discriminant analysis (OSTDA): A
regularized tensor pipeline for SSVEP-based BCI systems.
<em>NEUCOM</em>, <em>492</em>, 664–675. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Periodic signals called Steady-State Visual Evoked Potentials (SSVEP) are elicited in the brain by flickering stimuli. They are usually detected by means of regression techniques that need relatively long trial lengths to provide feedback and/or sufficient number of calibration trials to be reliably estimated in the context of brain-computer interface (BCI). Thus, for BCI systems designed to operate with SSVEP signals, reliability is achieved at the expense of speed or extra recording time. Furthermore, regardless of the trial length, calibration free regression-based methods have been shown to suffer from significant performance drops when cognitive perturbations are present affecting the attention to the flickering stimuli. In this study we present a novel technique called Oscillatory Source Tensor Discriminant Analysis (OSTDA) that extracts oscillatory sources and classifies them using the newly developed tensor-based discriminant analysis with shrinkage. The proposed approach is robust for small sample size settings where only a few calibration trials are available. Besides, it works well with both low- and high-number-of-channel settings, using trials as short as one second. OSTDA performs similarly or significantly better than other three benchmarked state-of-the-art techniques under different experimental settings, including those with cognitive disturbances (i.e. four datasets with control, listening, speaking and thinking conditions). Overall, in this paper we show that OSTDA is the only pipeline among all the studied ones that can achieve optimal results in all analyzed conditions.},
  archive      = {J_NEUCOM},
  author       = {Tania Jorajuría and Mina Jamshidi Idaji and Zafer İşcan and Marisol Gómez and Vadim V. Nikulin and Carmen Vidaurre},
  doi          = {10.1016/j.neucom.2021.07.103},
  journal      = {Neurocomputing},
  pages        = {664-675},
  shortjournal = {Neurocomputing},
  title        = {Oscillatory source tensor discriminant analysis (OSTDA): A regularized tensor pipeline for SSVEP-based BCI systems},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vision-based neural formation tracking control of multiple
autonomous vehicles with visibility and performance constraints.
<em>NEUCOM</em>, <em>492</em>, 651–663. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Limited sensing capability is one of features of onboard vision sensors. This paper addresses the formation tracking control problem for multiple nonholonomic autonomous vehicles with modeling uncertainties under limited sensing capabilities. Within the leader–follower formation control framework, the desired formation geometry of the vehicular team can be achieved by controlling the relative distance and angle between each pair of leader–follower vehicles. Each vehicle in the group is equipped with limited field-of-view onboard vision sensors to measure only the relative distance and angle with respect to its leader. For this scenario, each vehicle must remain within the visibility region relative to the leader in order to maintain the connectivity of the multi-vehicle system over time, while avoiding the possible collision with its leader. By incorporating the prescribed performance control methodology into the formation control design, the boundedness of the closed-loop system signals as well as the predefined performance indexes are achieved, where the neural networks (NNs) are employed to compensate for the uncertain dynamics. Visibility maintenance and collision avoidance between the leaders and followers are also proven mathematically. The proposed control strategy is decentralized in the sense that each vehicle uses only local relative information with respect to its leader to calculate its own control signals, as well as robust with respect to modeling uncertainties. Simulations and experiments on Pioneer-3AT robots are conducted to demonstrate the effectiveness of the proposed control strategy.},
  archive      = {J_NEUCOM},
  author       = {Shude He and Rourou Xu and Zhijia Zhao and Tao Zou},
  doi          = {10.1016/j.neucom.2021.12.056},
  journal      = {Neurocomputing},
  pages        = {651-663},
  shortjournal = {Neurocomputing},
  title        = {Vision-based neural formation tracking control of multiple autonomous vehicles with visibility and performance constraints},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-type spectral spatial feature for hyperspectral image
classification. <em>NEUCOM</em>, <em>492</em>, 637–650. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, many methods have been proposed to capture intra-spectrum features for the hyperspectral image classification task. However, most of these methods ignore inter-spectra information. In consideration of this, we propose a novel 3-D Inter-Spectra Difference Feature (ISDF) descriptor, which models the relationship between adjacent spectra using the difference between a center pixel and each of its spectral-adjacent spatial-neighbor pixels. Moreover, to increase the completeness of ISDF, the Neighbor Spectral Difference Feature (NSDF) guided by local spatial information is proposed as a supplement to the insufficient description of intra-spectrum information. At last, the Multi-type Spectral Spatial Feature (MSSF) is constructed by fusing ISDF, NSDF, and a global spatial texture feature. Experimental results on three public hyperspectral image datasets demonstrate that our proposed MSSF is effective and can outperform eight representative hyperspectral image classification methods.},
  archive      = {J_NEUCOM},
  author       = {Yuan Yuan and Mingxin Jin},
  doi          = {10.1016/j.neucom.2021.12.055},
  journal      = {Neurocomputing},
  pages        = {637-650},
  shortjournal = {Neurocomputing},
  title        = {Multi-type spectral spatial feature for hyperspectral image classification},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forward-reverse adaptive graph convolutional networks for
skeleton-based action recognition. <em>NEUCOM</em>, <em>492</em>,
624–636. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the latest research based on skeleton data, the graph convolutional networks (GCN) based methods have achieved excellent performance on action recognition tasks. Existing GCN-based methods commonly adopt the strategy of fusing the data flow of joints and bones to obtain better results. However, these approaches ignore the reversibility of the skeleton data in the temporal dimension. Compared with the forward sequences input, which can achieve better results in certain actions through the end-to-end networks, the reverse skeleton data has excellent discrimination and richer information for some specific actions. In this work, we propose the novel forward-reverse adaptive graph convolutional networks (FR-AGCN) for skeleton-based action recognition. The sequences of joints and bones, as well as their reverse information, are modeled in the multi-stream networks at the same time. By extracting the features of forward and reverse deep information and performing multi-stream fusion, this strategy can significantly improve the recognition accuracy. Extensive experiments on two large-scale datasets NTU 60 &amp; 120 show that the performance of our strategies has exciting advantages. On the latest dataset UAV-Human, the proposed FR-AGCN outperforms other state-of-the-art (SOTA) methods. Concretely, compared with 4s Shift-GCN, one of the most advanced models, FR-AGCN obtains significant improvements of +6.0\% on CSv1 benchmark and +2.46\% on CSv2 benchmark.},
  archive      = {J_NEUCOM},
  author       = {Zesheng Hu and Zihao Pan and Qiang Wang and Lei Yu and Shumin Fei},
  doi          = {10.1016/j.neucom.2021.12.054},
  journal      = {Neurocomputing},
  pages        = {624-636},
  shortjournal = {Neurocomputing},
  title        = {Forward-reverse adaptive graph convolutional networks for skeleton-based action recognition},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scale attentive network for scene recognition.
<em>NEUCOM</em>, <em>492</em>, 612–623. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene recognition aims at classifying a scene image to one of the predefined scene categories by comprehending the entire image. The complex composition of scenery images makes scene recognition a challenging task. However, most state-of-the-art visual recognition methods are developed on general-purpose datasets and omit the uniqueness of scene data. In this work, we propose an efficient Scale Attentive (SA) Module to address the predicament of scene recognition, which streamlines the scale-aware attention learning pipeline to assist the feature re-calibration and refinement process. By integrating SA Module into ResNet-50, we obtain a boost of Top-1 accuracy by 1.83\% on the benchmark scene dataset with only 0.12\% additional parameters and 0.24\% additional FLOPs. Moreover, comprehensive experiments show that our method achieves better performance compared with the state-of-the-art attention and multi-scale methods in a computationally efficient manner.},
  archive      = {J_NEUCOM},
  author       = {Xiaohui Yuan and Zhinan Qiao and Abolfazl Meyarian},
  doi          = {10.1016/j.neucom.2021.12.053},
  journal      = {Neurocomputing},
  pages        = {612-623},
  shortjournal = {Neurocomputing},
  title        = {Scale attentive network for scene recognition},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-hierarchy feature extraction and multi-step cost
aggregation for stereo matching. <em>NEUCOM</em>, <em>492</em>, 601–611.
(<a href="https://doi.org/10.1016/j.neucom.2021.12.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with the traditional hand-crafted feature based methods, learning-based stereo matching methods have made great progress in matching accuracy. However, current CNN-based stereo matching methods usually require a lot of time and memory consumption. It is very difficult to achieve the good balance between disparity estimation accuracy and inference speed that is significant to the application in real scenarios. To this end, we propose a accurate and fast stereo matching network (named MMNet), which contains two key modules of M ulti-hierarchy feature extraction and M ulti-step cost aggregation. In order to achieve a good trade-off between better disparity estimation and faster inference speed, a lightweight multi-hierarchy feature extractor is first proposed. This module obtains reliable feature information of different scales through three stable scale hierarchy branches, and outputs multi-step feature flows containing multi-scale fusion information at each step of the highest scale hierarchy branch. Moreover, we also propose a multi-step cost aggregation scheme, which uses shallow features to guide cost aggregation for ensuring a better aggregation effect with a small number of 3D convolutions. The experimental results on SceneFlow, KITTI 2012 and KITTI 2015 datasets show that our proposed network achieves extremely competitive disparity estimation accuracy with fast inference speed.},
  archive      = {J_NEUCOM},
  author       = {Aixin Chong and Hui Yin and Yanting Liu and Jin Wan and Zhihao Liu and Ming Han},
  doi          = {10.1016/j.neucom.2021.12.052},
  journal      = {Neurocomputing},
  pages        = {601-611},
  shortjournal = {Neurocomputing},
  title        = {Multi-hierarchy feature extraction and multi-step cost aggregation for stereo matching},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022d). An efficient spatial–temporal model based on gated linear
units for trajectory prediction. <em>NEUCOM</em>, <em>492</em>, 593–600.
(<a href="https://doi.org/10.1016/j.neucom.2021.12.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory prediction is a crucial and challenging task in many domains (e.g., autonomous driving and robot navigation). First, high-quality trajectory prediction methods need to capture the human–human interactions and human-scene interactions effectively to avoid collisions with moving agents and static obstacles. Moreover, it is indispensable for the approaches to be efficient and lightweight to reduce computing costs and economize public resources. To address these challenges, we propose a model with a Spatial–Temporal module and a heatmap module based on gated linear units. In the Spatial–Temporal module, an adaptive Graph Convolutional Network was proposed to capture the human–human interactions, which combines physical features with graph convolutional networks to speculate the agents’ implicit relationships. As for the human-scene interaction, we encode the sequential local heatmap around each agent in the heatmap module. The model includes two gated linear units to capture the correlations of the agent’s motion and dynamic changing trend of the surrounding scene , respectively. Compared with previous methods, our method is more lightweight and efficient with a smaller parameter size and shorter inference time. Meanwhile, our model achieves better experimental results on two publicly available datasets (ETH and UCY) and predicts more socially reasonable trajectories.},
  archive      = {J_NEUCOM},
  author       = {Shaohua Liu and Yisu Wang and Jingkai Sun and Tianlu Mao},
  doi          = {10.1016/j.neucom.2021.12.051},
  journal      = {Neurocomputing},
  pages        = {593-600},
  shortjournal = {Neurocomputing},
  title        = {An efficient Spatial–Temporal model based on gated linear units for trajectory prediction},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Exploiting reliable pseudo-labels for unsupervised domain
adaptive person re-identification. <em>NEUCOM</em>, <em>492</em>,
581–592. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification, getting impressive performance under the single-domain setting, often suffers huge performance drop when deploying to the unseen target domain owing to domain gap. Current research mainly focuses on unsupervised domain adaptation to alleviate the domain gap, and the methods by clustering the target-domain samples have achieved significant results. However, some inaccurate pseudo-labels, i.e., noisy pseudo-labels, may be generated on clustering, which will seriously affect the performance of the model. In order to solve the above problem, we propose a novel unsupervised domain adaptive person re-identification method by exploiting reliable pseudo-labels (RPL) from two aspects, i.e., adaptive dynamic clustering (ADC) and cross-camera similarity evaluation (CCSE). Specifically, firstly, for the methods based on the density-based clustering algorithm , we propose the adaptive dynamic clustering which calculates the clustering radius adaptively and dynamically to obtain more reasonable clustering results in the iterative optimization of the model. Next, for noisy pseudo-labels caused by small inter-class variations under the same camera, we propose the cross-camera similarity evaluation to filter out these noises to further improve the discrimination of the model. Extensive experiments on three publicly available large-scale datasets show that the proposed method can achieve state-of-the-art performance on unsupervised domain adaptation person re-identification.},
  archive      = {J_NEUCOM},
  author       = {Pengfei Zhao and Lei Huang and Wenfeng Zhang and Xiaojing Li and Zhiqiang Wei},
  doi          = {10.1016/j.neucom.2021.12.050},
  journal      = {Neurocomputing},
  pages        = {581-592},
  shortjournal = {Neurocomputing},
  title        = {Exploiting reliable pseudo-labels for unsupervised domain adaptive person re-identification},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-target regression via non-linear output structure
learning. <em>NEUCOM</em>, <em>492</em>, 572–580. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of simultaneously predicting multiple real-valued outputs using a shared set of input variables is known as multi-target regression and has attracted considerable interest in the past couple of years. The dominant approach in the literature for multi-target regression is to capture the dependencies between the outputs through a linear model and express it as an output mixing matrix. This modelling formalism, however, is too simplistic in real-world problems where the output variables are related to one another in a more complex and non-linear fashion. To address this problem, in this study, we propose a structural modelling approach where the correlations between output variables are modelled using a non-linear approach. In particular, we pose the multi-target regression problem as one of vector-valued composition function learning in the reproducing kernel Hilbert space and propose a non-linear structure learning approach to capture the relationship between the outputs via an output kernel. By virtue of using a non-linear output kernel function , the proposed approach can better discover non-linear dependencies among targets for improved prediction performance. An extensive evaluation conducted on different databases reveals the benefits of the proposed multi-target regression technique against the baseline and the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Shervin Rahimzadeh Arashloo and Josef Kittler},
  doi          = {10.1016/j.neucom.2021.12.048},
  journal      = {Neurocomputing},
  pages        = {572-580},
  shortjournal = {Neurocomputing},
  title        = {Multi-target regression via non-linear output structure learning},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-person multi-camera tracking for live stream videos
based on improved motion model and matching cascade. <em>NEUCOM</em>,
<em>492</em>, 561–571. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple live videos are streamed to the security room in the video surveillance system of a museum, shopping mall, plaza, etc. For public safety and crowd research, multi-person tracking is essential in these small-scale distributed multi-camera systems. This paper presents a multi-person multi-camera tracking framework for live stream videos. It is compatible with both overlapping and non-overlapping views. Since the tracking framework cannot consistently achieve real-time performance, live stream videos are probably sub-sampled. This sub-sampled issue will enlarge the error of every tracked person’s predicted bounding box at each frame. A time-based motion model studying the precise time intervals among sub-sampled frames is proposed. Besides, cameras have different orientations and exposures, resulting in false matches when tracked pedestrians cross the camera boundaries. When a tracked person is out of a camera’s view, its motion model will fail, and its tracking identity will probably switch when reentering the same camera. An improved multi-person matching cascade scheme is proposed to solve these problems. It can increase the accuracy of inter-camera person re-identification (Re-ID) by taking advantage of association priorities. Experiments are implemented with the EPFL dataset and live stream videos. Results show that the proposed method has robust performances in different situations.},
  archive      = {J_NEUCOM},
  author       = {Yundong Guo and Zhenyu Liu and Hao Luo and Huijie Pu and Jianrong Tan},
  doi          = {10.1016/j.neucom.2021.12.047},
  journal      = {Neurocomputing},
  pages        = {561-571},
  shortjournal = {Neurocomputing},
  title        = {Multi-person multi-camera tracking for live stream videos based on improved motion model and matching cascade},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Single image dehazing based on pixel-wise transmission
estimation with estimated radiance patches. <em>NEUCOM</em>,
<em>492</em>, 545–560. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images acquired outdoors can be affected by atmospheric conditions, such as fog and haze, and image dehazing is used to restore scene radiance in hazy images. In image dehazing, atmospheric light and transmission estimation are essential; transmission estimation is an essential step. In particular, the dark channel prior (DCP) is widely used for the transmission estimation. When using DCP-based methods, an initial transmission map is obtained through a morphological operation based on the assumption that the scene transmission in a local area is constant. However, the depth discontinuity problem cannot be avoided, and outliers are produced in the process of refining the initial transmission map. In addition, the estimation accuracy varies depending on the scene configuration due to the limitations of DCP-based methods, which simply estimate the transmission based on pixel intensity . To overcome these problems, we propose the pixel-wise transmission estimation method with estimated radiance patches (PTERP) for image dehazing. We first approximate the transmission range in the pixel location using the transmission map obtained using DCP. A patch is then set around each pixel, and several estimated radiance patches are obtained using each value belonging to the transmission range. The transmission value in the corresponding pixel location is determined using the information from the estimated radiance patches. The transmission map is then obtained by estimating the transmission value for each pixel in the entire image. With this approach, scene radiance can be restored using the determined transmission map. We performed experiments using various images, and the results demonstrated that proposed PTERP outperformed the conventional methods both quantitatively and qualitatively.},
  archive      = {J_NEUCOM},
  author       = {Soonyoung Hong and Moon Gi Kang},
  doi          = {10.1016/j.neucom.2021.12.046},
  journal      = {Neurocomputing},
  pages        = {545-560},
  shortjournal = {Neurocomputing},
  title        = {Single image dehazing based on pixel-wise transmission estimation with estimated radiance patches},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3D md-unet: A novel model of multi-dataset collaboration for
medical image segmentation. <em>NEUCOM</em>, <em>492</em>, 530–544. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation is widely used in the medical field. Convolutional neural network has become more diverse and effective in recent years. However, at present, most networks are designed for a single dataset (i.e., a single organ or target). The designed network is only suitable for a single dataset, and its accuracy is very different (especially small-size image datasets). In response to this problem, a collaborative network can be designed to simultaneously extract the specific and common features of a multi-dataset (i.e., multiple organs or targets). The network can be used for multi-dataset segmentation and help to balance the segmentation performance of different datasets, especially to improve the accuracy of small-size image datasets. By exploring the adapters modified by the convolution kernels, the adaptive weight update strategy and the network branched structure, the paper proposes a multi-dataset collaborative image segmentation network, called Md-Unet, which integrates a shared-specific adapter (SSA), an asymmetric similarity loss function with the proposed adaptive weight update strategy, and a dual-branch. Experimental results showed that compared with the baseline 3D U 2 Net, the accuracy of the module using the SSA was improved by 3.7\%, using several loss functions with the proposed adaptive weight update strategy was improved by 0.64\%–30.63\%, and using dual-branch integrated architecture was improved by 17.47\%. Moreover, Md-Unet had a significant improvement on small-size image datasets compared with single-dataset models.},
  archive      = {J_NEUCOM},
  author       = {Manying Lin and Qingling Cai and Jun Zhou},
  doi          = {10.1016/j.neucom.2021.12.045},
  journal      = {Neurocomputing},
  pages        = {530-544},
  shortjournal = {Neurocomputing},
  title        = {3D md-unet: A novel model of multi-dataset collaboration for medical image segmentation},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BERT gated multi-window attention network for relation
extraction. <em>NEUCOM</em>, <em>492</em>, 516–529. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity relation extraction aims to identify the semantic relation between entity pairs in a sentence and is an important technical support for downstream tasks such as question answering systems and semantic searching. Existing relation extraction models mainly rely on neural networks to extract the semantic information of sentences, ignoring the critical role of important phrase information in relation extraction. For this problem, this paper proposes a relation extraction model based on BERT gated multi-window attention network (BERT-GMAN). The model first uses BERT to extract the semantic representation features of the sentence and its constraint information. Secondly, it constructs the key phrases extraction network to obtain multi-granularity phrase information and uses element-wise max pooling to select key phrases features. Thirdly, it adopts classification feature perception network to further filter and globally perceive key phrase feature to form the overall features of relation classification. Finally, it combines with Softmax classifier to perform relation extraction. The experimental results on the Semeval-2010 Task 8 dataset show that the performance of the model in this paper is further improved compared with the existing methods, and the F1-score reaches 90.25\%.},
  archive      = {J_NEUCOM},
  author       = {Shiao Xu and Shuihua Sun and Zhiyuan Zhang and Fan Xu and Jianhua Liu},
  doi          = {10.1016/j.neucom.2021.12.044},
  journal      = {Neurocomputing},
  pages        = {516-529},
  shortjournal = {Neurocomputing},
  title        = {BERT gated multi-window attention network for relation extraction},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prior preference learning from experts: Designing a reward
with active inference. <em>NEUCOM</em>, <em>492</em>, 508–515. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active inference may be defined as Bayesian modeling of a brain with a biologically plausible model of the agent. Its primary idea relies on the free energy principle and the prior preference of the agent. An agent will choose an action that leads to its prior preference for a future observation. In this paper, we claim that active inference can be interpreted using reinforcement learning (RL) algorithms and find a theoretical connection between them. We extend the concept of expected free energy (EFE), which is a core quantity in active inference, and claim that EFE can be treated as a negative value function. Motivated by the concept of prior preference and a theoretical connection, we propose a simple but novel method for learning a prior preference from experts. This illustrates that the problem with inverse RL can be approached with a new perspective of active inference. Experimental results of prior preference learning show the possibility of active inference with EFE-based rewards and its application to an inverse RL problem.},
  archive      = {J_NEUCOM},
  author       = {Jin Young Shin and Cheolhyeong Kim and Hyung Ju Hwang},
  doi          = {10.1016/j.neucom.2021.12.042},
  journal      = {Neurocomputing},
  pages        = {508-515},
  shortjournal = {Neurocomputing},
  title        = {Prior preference learning from experts: Designing a reward with active inference},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interaction augmented transformer with decoupled decoding
for video captioning. <em>NEUCOM</em>, <em>492</em>, 496–507. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based architectures achieve competitive performances in video captioning. However, their applicability still has many issues: (1) Existing methods only consider the correlation of query and key modalities when calculating the attention weights, and ignore their interaction with other modalities. (2) Deep stacked cross-modal encoding blocks make the different modalities assimilative and lose their preliminary discriminative properties. (3) The decoder usually employs the output of the last encoding block, which is not a comprehensive representation. Based on these concerns, we propose a novel method called Interaction Augmented Transformer (IAT) with discriminative encoding and decoupled decoding for video captioning. Concretely, by concatenating “[CLS]” tokens to multimodal features, we perform reconstructive contrastive constraints for the encoded results. Based on the conclusive information carried by these tokens, we first introduce the global-gated interaction into multi-head attention, where the conclusive information mentioned above is transformed into multiple interaction augmented functions. Additionally, the dot-product operation is replaced by the tucker-fused operation to better capture the query-to-key correlation. Furthermore, we employ fine-grained layer-wise decoding for multi-layer multi-modal features from the encoder with decoupled strategy. We conduct extensive quantitative, qualitative, and ablation experiments on the benchmark datasets and the experimental results show that IAT outperforms the state-of-the-art methods under most of the metrics.},
  archive      = {J_NEUCOM},
  author       = {Tao Jin and Zhou Zhao and Peng Wang and Jun Yu and Fei Wu},
  doi          = {10.1016/j.neucom.2022.03.065},
  journal      = {Neurocomputing},
  pages        = {496-507},
  shortjournal = {Neurocomputing},
  title        = {Interaction augmented transformer with decoupled decoding for video captioning},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Reliable state estimation for neural networks with TOD
protocol and mixed compensation. <em>NEUCOM</em>, <em>492</em>, 488–495.
(<a href="https://doi.org/10.1016/j.neucom.2022.03.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the reliable state estimation issue for discrete-time neural networks with the try-once-discard (TOD) scheduling protocol and mixed compensation strategy. For the phenomenon of medium access constraint, the measurement transmitted from sensors to the estimator is subjected to the TOD scheduling protocol. The mixed compensation is proposed to flexibly compensate those missing measurements caused by the TOD protocol. By using a novel polytopic uncertain model, a reliable state estimator is designed, where the gain matrix is determined by two vertex matrices. Then sufficient conditions are established, which ensure the error system meets the stochastic stability and the l 2 l2 - l ∞ l∞ performance. Finally, an illustrative example shows the validity of the proposed reliable state estimator .},
  archive      = {J_NEUCOM},
  author       = {Hui Chen and Yao Li and Chang Liu and Ming Lin and Hongxia Rao},
  doi          = {10.1016/j.neucom.2022.03.058},
  journal      = {Neurocomputing},
  pages        = {488-495},
  shortjournal = {Neurocomputing},
  title        = {Reliable state estimation for neural networks with TOD protocol and mixed compensation},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cascaded geometric feature modulation network for point
cloud processing. <em>NEUCOM</em>, <em>492</em>, 474–487. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud analysis is a critical technology in the field of 3D vision, such as autonomous driving and robot navigation . Utilizing the inherent geometric properties embedded in 3D point cloud data remains a great challenge. In this paper, a cascaded geometric feature modulation network is proposed to explore the shared geometric patterns of 3D point clouds from local to global. The contribution of this paper is threefold. First, we design a local geometric feature modulation (GFM) block that learns a pointwise transformation according to the surrounding semantic context of each point. Second, based on the dense connection of multiple GFM blocks, we design a novel global fusion mechanism to ensure the preservation of valuable structural information. Finally, we propose a novel spatial distribution consistency loss to remedy the situation of irrational sampling. Benefitting from the proposed loss function, our network enjoys better convergence performance at the same time. Extensive experimental results on different tasks of point cloud processing demonstrate the superiority and robustness of our proposed network.},
  archive      = {J_NEUCOM},
  author       = {Fengda Hao and Rui Song and JiaoJiao Li and Kailang Cao and Yunsong Li},
  doi          = {10.1016/j.neucom.2022.04.007},
  journal      = {Neurocomputing},
  pages        = {474-487},
  shortjournal = {Neurocomputing},
  title        = {Cascaded geometric feature modulation network for point cloud processing},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scale-aware network with modality-awareness for RGB-d indoor
semantic segmentation. <em>NEUCOM</em>, <em>492</em>, 464–473. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on indoor semantic segmentation based on RGB-D images. Semantic segmentation is a pixel-level classification task that has made steady progress based on fully convolutional networks (FCNs). However, we find there is still room for improvements in the following three aspects. The first is related to multi-scale feature extraction. Recent state-of-the-art works forcibly concatenate multi-scale feature representations extracted by spatial pyramid pooling, dilated convolution or other architectures, regardless of the spatial extent for each pixel. The second is regarding RGB-D modal fusion. Most successful methods treat RGB and depth as two separate modalities and force them to be joined together regardless of their different contributions to the final prediction. The final aspect is about the modeling ability of extracted features. Due to the “local grid” defined by the receptive field, the learned feature representation lacks the ability to model spatial dependencies. In addition to these modules, we design a depth estimation module to encourage the RGB network to extract more effective features. To solve the above challenges, we propose four modules to address them: scale-aware module, modality-aware module, attention module and depth estimation module. Extensive experiments on the NYU-Depth v2 and SUN RGB-D datasets demonstrate that our method is effective against RGB-D indoor semantic segmentation.},
  archive      = {J_NEUCOM},
  author       = {Feng Zhou and Yu-Kun Lai and Paul L. Rosin and Fengquan Zhang and Yong Hu},
  doi          = {10.1016/j.neucom.2022.04.025},
  journal      = {Neurocomputing},
  pages        = {464-473},
  shortjournal = {Neurocomputing},
  title        = {Scale-aware network with modality-awareness for RGB-D indoor semantic segmentation},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Complete quadruple extraction using a two-stage neural
model for aspect-based sentiment analysis. <em>NEUCOM</em>,
<em>492</em>, 452–463. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) is a fine-grained task which aims to identify the emotional polarity of a specific aspect in a text or sentence. Aspect term extraction (ATE), opinion term extraction (OTE) and aspect polarity classification (APC) are three main subtasks of the ABSA task. Nowadays, researchers mainly focus on a single task or a joint task composed of these three subtasks, and such investigation on the sentiment analysis is not sufficient. In this paper, we firstly introduce a complete aspect sentiment analysis task, called Aspect Sentiment Quadruple Extraction, which also includes the category detection beside ATE, OTE and APC. Then we propose a two-stage neural network model composed of several modules, including BiLSTM, simple gated self-attention and position encoding for this joint task. In the first stage, the proposed model extracts aspect and opinion terms as well as their categories and polarities. Moreover, the second stage mainly includes a relation classifier to validate the aspect-opinion pairs and then finalizes the complete quadruple extraction. The experimental results, evaluated on a benchmark dataset of Chinese product reviews, show that our proposed model outperforms other baseline methods and achieves the start-of-art performance.},
  archive      = {J_NEUCOM},
  author       = {Hua Zhang and Zeqi Chen and Bi Chen and Biao Hu and Mian Li and Cheng Yang and Bo Jiang},
  doi          = {10.1016/j.neucom.2022.04.027},
  journal      = {Neurocomputing},
  pages        = {452-463},
  shortjournal = {Neurocomputing},
  title        = {Complete quadruple extraction using a two-stage neural model for aspect-based sentiment analysis},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HYPER2: Hyperbolic embedding for hyper-relational link
prediction. <em>NEUCOM</em>, <em>492</em>, 440–451. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) Embedding has been broadly studied in recent years. However, less light is shed on the ubiquitous hyper-relational KGs. Most existing hyper-relational KG embedding methods decompose n-ary facts into smaller tuples, undermining the structure of n-ary facts. Moreover, these models always suffer from low expressiveness and high complexity. In this work, to tackle the indecomposability issue, we represent n-ary fact as a hyperedge , keeping the integrity of fact and maintaining the vital role that primary triple plays. To address the expressiveness and complexity issue, we propose HYPER 2 where we generalize hyperbolic Poincaré embedding from binary to arbitrary arity data, and we design an information aggregation module to capture the interaction between entities within and beyond triple. Extensive experiments demonstrate HYPER 2 is superior to its translational and deep analogues, improving MRR and other metrics by a large margin with relatively few dimensions. Moreover, we study the side effect of literals, and we theoretically and experimentally compare the computational complexity of HYPER 2 against several best-performing baselines. HYPER 2 is much quicker than its counterparts.},
  archive      = {J_NEUCOM},
  author       = {Shiyao Yan and Zequn Zhang and Xian Sun and Guangluan Xu and Li Jin and Shuchao Li},
  doi          = {10.1016/j.neucom.2022.04.026},
  journal      = {Neurocomputing},
  pages        = {440-451},
  shortjournal = {Neurocomputing},
  title        = {HYPER2: Hyperbolic embedding for hyper-relational link prediction},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Synthesized rain images for deraining algorithms.
<em>NEUCOM</em>, <em>492</em>, 421–439. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since most of the rainy scene datasets used for training single image rain removal (SIRR) algorithms are constructed by blending artificial rain streaks with source images, it is difficult for a machine trained with such datasets to understand the patterns of real or realistic rain streaks. So, several studies have been attempted to build a real rainy scene dataset. However, since collecting real rainy scenes itself requires significant costs, the real rainy scene datasets provided by some studies cover only very limited rainy environment(s). This paper presents a new approach to synthesize realistic rainy scenes using GAN, which is a world-first attempt as far as we know. The proposed method builds a representation space to which rain streaks of multiple styles are smoothly mapped by learning the distributions of various rain datasets. The representation space allows control over the generated rain streaks. Also, the proposed method can synthesize multiple rainy scenes per clean (source) scene simultaneously, thereby a synthesized rain image dataset (SyRa) (Dataset can be found here: https://github.com/jaewoong1/SyRa-Synthesized_Rain_dataset ) consisting of 11 K clean images and 55 K rainy images was constructed. Finally, this paper provides benchmarking results of several SIRR methods trained with SyRa. This result will be very useful for developing SIRR algorithms that can cope well with the actual rain environment.},
  archive      = {J_NEUCOM},
  author       = {Jaewoong Choi and Dae Ha Kim and Sanghyuk Lee and Sang Hyuk Lee and Byung Cheol Song},
  doi          = {10.1016/j.neucom.2022.04.034},
  journal      = {Neurocomputing},
  pages        = {421-439},
  shortjournal = {Neurocomputing},
  title        = {Synthesized rain images for deraining algorithms},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Identifying common driver modules by equilibrating coverage
and mutual exclusivity across pan-cancer data. <em>NEUCOM</em>,
<em>492</em>, 408–420. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is of significance to identify common driver modules from pan-cancer data to interpret heterogeneity of cancer, and the accumulated omic data have made it into reality. In this paper, the pan-cancer common driver module identification problem is formulated, which takes the frequency difference among various cancers into account. For solving this problem, a K -nearest neighbors based imputation algorithm KNNImp is firstly devised to infer the variation values for some potential significant missing genes. Secondly, a harmonic mean of coverage and mutual exclusivity based random walk algorithm HMCEwalk is proposed. It weights the integrated PPI network with the harmonic mean of gene coverage scores and mutual exclusion scores among various cancer types, and extracts modules through a random walk process . Experiments were implemented on both simulated data and real biological data. The experimental results on simulated data indicate that given two types of cancers, the HMCEwalk algorithm has a stronger tendency to identify a set of modules which not only mutate in a large proportion of samples of these cancers, but have close proportion of mutated samples for each cancer. The experimental results on biological data show that the presented imputation algorithm does play roles in regaining some important cancer related genes . In comparison with two state-of-the-art identification methods MEXCOwalk and DriveWays, the presented one exhibits competitive performance in most instances in terms of revealing the known cancer genes , producing modules having satisfied coverage and mutual exclusivity for each cancer. Many detected modules engage in the known cancer-related biological pathways. In addition, the presented method does recognize many cancer-associated genes omitted by methods MEXCOwalk and DriveWays.},
  archive      = {J_NEUCOM},
  author       = {Jingli Wu and Cong Wu and Gaoshi Li},
  doi          = {10.1016/j.neucom.2022.04.050},
  journal      = {Neurocomputing},
  pages        = {408-420},
  shortjournal = {Neurocomputing},
  title        = {Identifying common driver modules by equilibrating coverage and mutual exclusivity across pan-cancer data},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Video object segmentation based on multi-level target models
and feature integration. <em>NEUCOM</em>, <em>492</em>, 396–407. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video object segmentation (VOS) is a highly challenging task with wide prospects of applications. Many complex situations of target objects such as tiny-sizes, deformations, occlusions, etc., influence segmentation accuracy adversely. To solve these problems, we propose an effective video object segmentation method based on multi-level target models and feature integration (MTMFI-VOS). The multi-level target models focus on more crucial details of target appearances and can get finer segmentation results even on tiny objects. The feature integration module integrates temporal information adaptively and can capture dynamic changes of the target objects. Extensive experiments are conducted on VOS benchmarks: DAVIS-16 validation set, DAVIS-17 validation set, and DAVIS-17 test-dev set. Compared with the state-of-the-art algorithms, our method achieves competitive accuracy and meets the demand of the real-time speed. Codes and trained models are available in https://github.com/gbc-sid/MTMFI-VOS .},
  archive      = {J_NEUCOM},
  author       = {Bocong Gao and Yuqian Zhao and Fan Zhang and Biao Luo and Chunhua Yang},
  doi          = {10.1016/j.neucom.2022.04.042},
  journal      = {Neurocomputing},
  pages        = {396-407},
  shortjournal = {Neurocomputing},
  title        = {Video object segmentation based on multi-level target models and feature integration},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive multiple kernel fusion model using
spatial-statistical information for high resolution SAR image
classification. <em>NEUCOM</em>, <em>492</em>, 382–395. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current high-resolution (HR) synthetic aperture radar (SAR) image classification is confronted with the challenges of the complex spatial patterns and highly variable backscattering of objects. Data-based methods, such as convolutional neural networks (CNNs), can well extract spatial features but ignore valuable statistical knowledge of SAR data. Model-based methods can utilize the non-stationary and non-Gaussian statistical properties of SAR images, while they fail to encode the local spatial patterns. In this paper, an adaptive multiple kernel fusion model with superpixel regularization (AMKFM-SPR) is proposed for HR SAR image classification, which combines the advantages of both deep spatial features and multiscale statistical properties to improve classification accuracy . For the deep spatial features, multilayer features are extracted by using the pre-trained CNN model. Then, a hybrid pooling strategy is designed to encode the feature maps into more distinguishable features from the perspective of spatial structure and local statistics. For the scattering statistical features, the Gabor magnitudes of HR SAR data are modeled by the log-normal distribution and projected into the cumulative distribution function space. Further, the covariance matrix is calculated for mapped multivariate data to build global statistical features. For the feature fusion , multiple kernels are constructed to describe the spatial and statistical information. An improved centered kernel alignment (ICKA) scheme is utilized to adaptively determine the kernel weights and effectively exploit the complementarity among different features. Next, the fusion kernel is fed into a support vector machine to produce the initial classification map. Finally, to compensate for the limitations of the patch-based classification way, superpixel regularization (SPR) is performed on the class probability map to enhance label consistency and refine the spatial detail . Experiments on three real HR SAR images show the superiority of the proposed method over other related algorithms.},
  archive      = {J_NEUCOM},
  author       = {Wenkai Liang and Yan Wu and Ming Li and Yice Cao},
  doi          = {10.1016/j.neucom.2022.03.062},
  journal      = {Neurocomputing},
  pages        = {382-395},
  shortjournal = {Neurocomputing},
  title        = {Adaptive multiple kernel fusion model using spatial-statistical information for high resolution SAR image classification},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RGBT tracking based on cooperative low-rank graph model.
<em>NEUCOM</em>, <em>492</em>, 370–381. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing graph-based RGBT tracking methods mainly focus on assigning a weight to each local image patch to suppress background influence in target bounding box, but the influences of background clutter might limit the improvement of tracking performance. To solve this problem, we propose a new algorithm, called cooperative low-rank graph model, to suppress background clutter. Specifically, the proposed feature decomposition module decomposes input dual-modal features into low-rank components and sparse noisy components, which could be used collaboratively by regularizing graph learning by combining modal weights. Besides, to avoid SVD (Singular Value Decomposition) operations we have designed an efficient solver based on ADMM (Alternating Direction Methods of Multipliers), which could factorize the low-rank matrix into two low-dimensional submatrices. Extensive experiments on four RGBT tracking benchmark data sets show that our method performs favorably against other state-of-the-art tracking algorithms, and achieves more robust tracking performance.},
  archive      = {J_NEUCOM},
  author       = {Longfeng Shen and Xiaoxiao Wang and Lei Liu and Bin Hou and Yulei Jian and Jin Tang and Bin Luo},
  doi          = {10.1016/j.neucom.2022.04.032},
  journal      = {Neurocomputing},
  pages        = {370-381},
  shortjournal = {Neurocomputing},
  title        = {RGBT tracking based on cooperative low-rank graph model},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel alzheimer’s disease detection approach using
GAN-based brain slice image enhancement. <em>NEUCOM</em>, <em>492</em>,
353–369. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the prevalence and the enormous societal consequence on health of Alzheimer’s disease (AD), diagnosis of AD and its prodromal form, mild cognitive impairment (MCI) is essential for patient care, and has been a research hotspot in recent years. Existing studies have applied machine learning methods to perform AD early diagnosis by analyzing various biomarkers. However, the difficulty in extracting the low-dimensional high-level brain features that accurately reflect main AD-related variations of anatomical brain structures becomes a bottleneck of the diagnosis performance in most of the existing researches. To overcome this bottleneck, this paper proposes a novel three-component adversarial network-based AD detection method (brain slice generative adversarial network for Alzheimer’s disease detection, BSGAN-ADD) to predict the disease category. BSGAN-ADD combines generative adversarial network (GAN)-based brain slice image enhancement and deep convolutional neural network (CNN)-based AD detection. In BSGAN-ADD, under the restriction of the discriminator , the generator learns to integrate the disease category feedbacks from classifier into 2D-brain slice image reconstruction process for image enhancement in the training phase. In the prediction phase , the stacked CNN layers in the generator are used to extract high-level brain features from category-enhanced 2D-brain slice images. And the classifier receives the extracted brain features to output the posterior probabilities of diseased states (Normal, AD and MCI). Experimental results on two real-world datasets (Alzheimer’s disease neuroimaging initiative, ANDI, Open Access Series of Imaging Studies OASIS) demonstrate that the new feature extraction process used in BSGAN-ADD can extract more representative high-level brain features to achieve a significant diagnosis performance gain compared with several typical methods.},
  archive      = {J_NEUCOM},
  author       = {Tian Bai and Mingyu Du and Lin Zhang and Lei Ren and Li Ruan and Yuan Yang and Guanghao Qian and Zihao Meng and Li Zhao and M. Jamal Deen},
  doi          = {10.1016/j.neucom.2022.04.012},
  journal      = {Neurocomputing},
  pages        = {353-369},
  shortjournal = {Neurocomputing},
  title        = {A novel alzheimer’s disease detection approach using GAN-based brain slice image enhancement},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CT image quality enhancement via a dual-channel neural
network with jointing denoising and super-resolution. <em>NEUCOM</em>,
<em>492</em>, 343–352. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, computed tomography (CT) has been widely used in various clinical diagnosis. Given potential health risks bring by the X-ray radiation, the major objective of the current research is to achieve high-quality CT imaging while reducing X-ray radiation. However, most existing studies on low-dose CT image super-resolution reconstruction do not focus on the interaction between the denoising task and the super-resolution task. In this paper, we propose a dual-channel joint learning framework to accurately reconstruct high-resolution CT images from low-resolution CT images. Unlike the previous cascaded models which directly combine the denoising network and the super-resolution network, our method can process the denoising reconstruction and the super-resolution reconstruction in parallel. Additionally, we design a filter gate module that can filter features from the denoising branch and highlight important features which can benefit the super-resolution task. We evaluate the performance of our method in medical image enhancement by testing on the 2016 Low-Dose CT Grand Challenge dataset and the piglet dataset. The experimental results show that the proposed network is superior to other state-of-the-art methods in terms of both peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM). We also demonstrate that our method can better remove noise and recover details. Furthermore, the method achieves competitive results not only for super-resolution reconstruction of low-dose CT, but also for super-resolution reconstruction of sparse-view CT.},
  archive      = {J_NEUCOM},
  author       = {Hongyu Hou and Qunchao Jin and Guixu Zhang and Zhi Li},
  doi          = {10.1016/j.neucom.2022.04.040},
  journal      = {Neurocomputing},
  pages        = {343-352},
  shortjournal = {Neurocomputing},
  title        = {CT image quality enhancement via a dual-channel neural network with jointing denoising and super-resolution},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022d). Improving robustness for pose estimation via stable heatmap
regression. <em>NEUCOM</em>, <em>492</em>, 322–342. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods have achieved excellent performance in pose estimation, but the lack of robustness causes the keypoints to change drastically between similar images. In view of this problem, a stable heatmap regression method is proposed to alleviate network vulnerability to small perturbations. We utilize the correlation between different rows and columns in a heatmap to alleviate the multi-peaks problem, and design a highly differentiated heatmap regression to make a keypoint discriminative from surrounding points. A maximum stability training loss is used to simplify the optimization difficulty when minimizing the prediction gap of two similar images. The proposed method achieves a significant advance in robustness over state-of-the-art approaches on four benchmark datasets and maintains high performance.},
  archive      = {J_NEUCOM},
  author       = {Yumeng Zhang and Li Chen and Yufeng Liu and Xiaoyan Guo and Wen Zheng and Junhai Yong},
  doi          = {10.1016/j.neucom.2022.04.046},
  journal      = {Neurocomputing},
  pages        = {322-342},
  shortjournal = {Neurocomputing},
  title        = {Improving robustness for pose estimation via stable heatmap regression},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed leader-following formation control for multiple
nonholonomic mobile robots via bioinspired neurodynamic approach.
<em>NEUCOM</em>, <em>492</em>, 308–321. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the distributed leader-following formation control problem for multiple nonholonomic wheeled mobile robots via a bioinspired neurodynamic approach. To do this, first, we develop a distributed estimator for each follower robot which uses its own information and the information of its neighboring robots to estimate the leader’s states. Second, a formation tracking control law is proposed for each follower robot based on the estimated states of the leader using the backstepping technique. Then, a bioinspired neurodynamics-based backstepping controller is designed to solve the impractical velocity jumps problem. Furthermore, Lyapunov function-based approach is utilized to derive sufficient conditions which guarantee asymptotic stability of the multiple mobile robot system . Finally, simulation results are presented to illustrate the effectiveness of the proposed controllers.},
  archive      = {J_NEUCOM},
  author       = {Sathishkumar Moorthy and Young Hoon Joo},
  doi          = {10.1016/j.neucom.2022.04.001},
  journal      = {Neurocomputing},
  pages        = {308-321},
  shortjournal = {Neurocomputing},
  title        = {Distributed leader-following formation control for multiple nonholonomic mobile robots via bioinspired neurodynamic approach},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adversarial attack and defense technologies in natural
language processing: A survey. <em>NEUCOM</em>, <em>492</em>, 278–307.
(<a href="https://doi.org/10.1016/j.neucom.2022.04.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the adversarial attack and defense technology has made remarkable achievements and has been widely applied in the computer vision field, promoting its rapid development in other fields, primarily the natural language processing domain. However, discrete semantic texts bring additional restrictions and challenges to successfully implementing adversarial attacks and defenses. This survey systematically summarizes the current progress of adversarial techniques in the natural language processing field. We first briefly introduce the textual adversarial example’s particularity, vectorization, and evaluation metrics. More importantly, we categorize textual adversarial attacks according to the combination of semantic granularity and example generation strategy. Next, we present commonly used datasets and adversarial attack applications in diverse natural language processing tasks. Besides, we classify defense strategies as passive and active methods considering both input data and victim models. Finally, we present several challenging issues and future research directions in this domain.},
  archive      = {J_NEUCOM},
  author       = {Shilin Qiu and Qihe Liu and Shijie Zhou and Wen Huang},
  doi          = {10.1016/j.neucom.2022.04.020},
  journal      = {Neurocomputing},
  pages        = {278-307},
  shortjournal = {Neurocomputing},
  title        = {Adversarial attack and defense technologies in natural language processing: A survey},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient dual semantic preserving hashing for
cross-modal retrieval. <em>NEUCOM</em>, <em>492</em>, 264–277. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hashing methods have recently received widespread attention due to their flexibility and effectiveness for cross-modal retrieval tasks. However, most existing cross-modal hashing methods have some challenging problems, in particular, effective exploitation of semantic information and learning discriminative hash codes. To address these challenges, we propose an efficient Dual Semantic Preserving Hashing (DSPH) method, which first leverages matrix factorization to obtain low-level latent semantic representations of different modalities and remove redundant information. To enhance the discriminative capability of hash codes, we preserve the high-level pairwise semantics and the learned low-level latent semantics into the unified hash codes. Finally, DSPH adopts discrete optimization strategy to learn the hash codes directly. Experimental results on three benchmark datasets demonstrate that the proposed DSPH method outperforms many state-of-the-art cross-modal hashing methods in terms of retrieval accuracy , especially when dealing with short hash code.},
  archive      = {J_NEUCOM},
  author       = {Yun Liu and Shujuan Ji and Qiang Fu and Dickson K.W. Chiu and Maoguo Gong},
  doi          = {10.1016/j.neucom.2022.04.011},
  journal      = {Neurocomputing},
  pages        = {264-277},
  shortjournal = {Neurocomputing},
  title        = {An efficient dual semantic preserving hashing for cross-modal retrieval},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A systematic literature review of speech emotion recognition
approaches. <em>NEUCOM</em>, <em>492</em>, 245–263. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays emotion recognition from speech (SER) is a demanding research area for researchers because of its wide real-life applications. There are many challenges for SER systems such as the availability of suitable emotional databases, identification of the relevant feature vector, and suitable classifiers. This paper critically analysed the literature on SER in terms of speech databases, speech features, traditional machine learning (ML) classifiers and DL approaches along with the areas for future directions. In recent years, there is a growing interest of researchers to use deep learning (DL) approaches for SER and get improvement in recognition rate. The focus of this review is on DL approaches for SER. A total of 152 papers have been reviewed from years 2000–2021. We have identified frequently used speech databases and related accuracies achieved using DL approaches. The motivations and limitations of DL approaches for SER are also summarized.},
  archive      = {J_NEUCOM},
  author       = {Youddha Beer Singh and Shivani Goel},
  doi          = {10.1016/j.neucom.2022.04.028},
  journal      = {Neurocomputing},
  pages        = {245-263},
  shortjournal = {Neurocomputing},
  title        = {A systematic literature review of speech emotion recognition approaches},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mix-VAEs: A novel multisensor information fusion model for
intelligent fault diagnosis. <em>NEUCOM</em>, <em>492</em>, 234–244. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multisensor information are usually required to recognize the health condition of machinery by domain experts, since redundancy and complementarity of multisensor information can enhance robustness of fault diagnosis. However, the mainstream approaches of intelligent fault diagnosis based on deep neural networks only focus on applications of single sensor. In this paper, a novel intelligent fault diagnosis model using mixture of Gaussians (MoGs) and variational auto-encoders (VAEs), named Mix-VAEs, is proposed to leverage redundancy and complementarity of multisensor information. The proposed Mix-VAEs mainly contains two modules. First, feature extracting module is constructed by several parallel and independent VAEs which are used to learn data representation from multisensor data respectively, and their latent variable distributions extracted by VAEs are used for fusion. Second, in multisensor information fusion module, a novel fusion method is proposed where latent variable distributions are combined to form MoGs, and the fused features are obtained in a sampling manner from MoGs. The performance of the proposed model is verified through two datasets consisting of multisensor data. Experimental results demonstrate the robustness of the proposed model in two scenarios, sensor failure and local signal missing, while also showing the better performance than other fusion models.},
  archive      = {J_NEUCOM},
  author       = {Cunjun Wang and Cun Xin and Zili Xu and Manqing Qin and Mengfu He},
  doi          = {10.1016/j.neucom.2022.04.044},
  journal      = {Neurocomputing},
  pages        = {234-244},
  shortjournal = {Neurocomputing},
  title        = {Mix-VAEs: A novel multisensor information fusion model for intelligent fault diagnosis},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IMSiam: IoU-aware matching-adaptive siamese network for
object tracking. <em>NEUCOM</em>, <em>492</em>, 222–233. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully convolutional Siamese networks have shown their advantages in the visual object tracking task. However, most existing Siamese-based trackers still suffer from poor matching information and a low correlation between the classification score and bounding box estimation. To address these issues, we propose an IoU-aware Matching-adaptive Siamese network (IMSiam) for visual tracking in this paper. Specifically, a matching-adaptive network is proposed, which integrates multiple types of encoded feature maps and adaptively sample matching information to simultaneously perform target classification and bounding box regression. And we introduce an IoU-aware head to equip the Siamese detector with the capacity of IoU prediction for each regressed box, which then penalizes the classification score to obtain a more confident target region. Benefiting from the adaptive matching information and IoU-based classification outputs, the model can localize the target more accurately while avoiding the redundant search of scale penalty factor during tracking. Experimental results on OTB2013, OTB2015, VOT2018, VOT2019, LaSOT, and Got10k datasets demonstrate that the proposed tracker performs favorably against state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Ke Tan and Ting-Bing Xu and Zhenzhong Wei},
  doi          = {10.1016/j.neucom.2022.04.003},
  journal      = {Neurocomputing},
  pages        = {222-233},
  shortjournal = {Neurocomputing},
  title        = {IMSiam: IoU-aware matching-adaptive siamese network for object tracking},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Span-based dual-decoder framework for aspect sentiment
triplet extraction. <em>NEUCOM</em>, <em>492</em>, 211–221. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect sentiment triplet extraction (ASTE) aims to extract aspects from review sentences along with their corresponding opinions and sentiments to form opinion triplets. Since each factor within a sentiment triplet could be a single word or a phrase, defining and implementing the span-level features for this span-level task is critical and challenging. However, prior works typically formulate the ASTE task as a sequence tagging problem and address it with token-level models, limiting the extraction performances of long entities and suffering from cascading errors due to sequential decoding. Although some methods have enumerated all possible spans as input, they fail to explicitly build the interaction among the potential triplets and semantic information within the sentence explicitly. To address these problems, we propose a span-based joint training framework, where each potential entity is represented as an independent span and sentiment polarity is classified by using the corresponding independent span representations. Specifically, we design two different transformer-based decoders to extract the aspects and their corresponding opinions, respectively. Those decoders utilize multiple multi-head attention mechanisms to model the associations among the spans and the semantic information between the spans and the sentences. To verify the effectiveness of our approach, we conduct extensive experiments on four benchmark datasets. The experimental results demonstrate that our proposed method significantly outperforms existing state-of-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yuqi Chen and Zequn Zhang and Guangyao Zhou and Xian Sun and Keming Chen},
  doi          = {10.1016/j.neucom.2022.04.022},
  journal      = {Neurocomputing},
  pages        = {211-221},
  shortjournal = {Neurocomputing},
  title        = {Span-based dual-decoder framework for aspect sentiment triplet extraction},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prescribed performance control with input indicator for
robot system based on spectral normalized neural networks.
<em>NEUCOM</em>, <em>492</em>, 201–210. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a real robot system, it is not easy to use the deep neural networks to approximate the unknown nonlinear dynamics online due to limited computing resources, meanwhile the saturation of the motor also makes it difficult for the system to achieve the desired control effect. In this paper, a method combining spectral normalized deep neural networks and prescribed performance controller with saturated indicator is proposed to solve the problems of insufficient computing resources and input saturation in practical robot system control. Firstly, a low computational cost offline learning spectral normalized deep neural network with rectified linear unit activation is applied in nonlinear dynamics identification to reduce the learning computation burden. The unknown nonlinear dynamics of the robot system including Coriolis force and friction dynamics can be approximated well with good generalization ability by spectral normalized deep neural networks, and the boundedness of the approximation error can be guaranteed by the Lipschitz constraint. Subsequently, a prescribed performance controller with a saturation indicator is also introduced to improve the transient performance of the robot system and eliminate the influence of input saturation. Besides, the closed-loop stability is also proved via the Lyapunov approach. The simulation and experiment results show that the proposed method can achieve good tracking performance and better generalization capability.},
  archive      = {J_NEUCOM},
  author       = {Ning Han and Xuemei Ren and Chao Zhang and Dongdong Zheng},
  doi          = {10.1016/j.neucom.2022.04.039},
  journal      = {Neurocomputing},
  pages        = {201-210},
  shortjournal = {Neurocomputing},
  title        = {Prescribed performance control with input indicator for robot system based on spectral normalized neural networks},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generating diverse chinese poetry from images via
unsupervised method. <em>NEUCOM</em>, <em>492</em>, 188–200. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic poetry generation represents a typical exhibition of artificial intelligence creativity, and the cross-modal generation methods reveal a promising direction for improvement. Although previous methods have made some progress, they still suffer from the following challenges: (1) lack of annotated multimodal Chinese poetry datasets; (2) insufficient diversity of generated poetry; (3) inadequate semantic consistency between images and poems. In this paper, we propose a novel Unsupervised Image to Poetry Model (UI2P) with a newly designed generative adversarial network to address the above issues. Specifically, the unsupervised learning framework eliminates the dependence on annotated multimodal poetry datasets. We present a contrastive learning approach to optimize the diversity of generated poems. Furthermore, a consistency strategy is developed, including constructing a modern-classical concept dictionary to ensure semantic coherence between poems and images. Extensive experiments are conducted on the CCPC dataset, and the results with both automatic and manual evaluations demonstrate the superiority of our model compared with several state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Jiangnan Wang and Haisheng Li and Chunlei Wu and Faming Gong and Leiquan Wang},
  doi          = {10.1016/j.neucom.2022.04.024},
  journal      = {Neurocomputing},
  pages        = {188-200},
  shortjournal = {Neurocomputing},
  title        = {Generating diverse chinese poetry from images via unsupervised method},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EmoSeC: Emotion recognition from scene context.
<em>NEUCOM</em>, <em>492</em>, 174–187. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context provides additional information to determine the actual emotional state of a person as part of a scene. Existing works on emotion recognition in context focused only on the features extracted from the entire image and the target’s body. In this work, we propose a comprehensive multi-cue based emotion recognition framework that incorporates the context, using a hybrid architecture comprised of four separate deep convolutional neural networks and a novel feature fusion mechanism. Each deep network presented in our proposed approach effectively learns the emotion-related features from the facial, body pose, non-target subject and entire image, individually. Experiments on Emotic, an in-painted and a newly constructed EmoSec datasets show that our proposed emotion recognition framework is promising when compared to existing methods in terms of accurately classifying emotions. Comparison with the state-of-the-art deep networks and off-the-shelf fusion techniques demonstrates that our network showed an improved performance. Furthermore, the performance evaluation of our proposed approach on all three datasets confirms that the contextual information influences the emotional state of a human.},
  archive      = {J_NEUCOM},
  author       = {Selvarajah Thuseethan and Sutharshan Rajasegarar and John Yearwood},
  doi          = {10.1016/j.neucom.2022.04.019},
  journal      = {Neurocomputing},
  pages        = {174-187},
  shortjournal = {Neurocomputing},
  title        = {EmoSeC: Emotion recognition from scene context},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pattern-based autonomous smooth switching control for
constrained flexible joint manipulator. <em>NEUCOM</em>, <em>492</em>,
162–173. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes a pattern-based control scheme for a class of flexible joint manipulators with unknown dynamics and position constraints. The scheme consists of two phases: (i) online controller adjustment and task pattern identification ; (ii) offline pattern recognition and controller calling. In phase (i) , the constraint position vectors are transformed into unconstrained variables by using a transformation function. Subsequently, a set of static neural learning controllers are constructed for different reference patterns by employing experience weights obtained from stable adaptive neural control. Moreover, a dynamic estimator is developed to identify different reference patterns. The identified patterns are stored by constant NNs , thereby constructing a trained pattern library by combining with their corresponding static neural learning controllers. In phase (ii) , the dynamic residual system is designed to recognize a tested pattern by comparing the size of residual error between the tested pattern and trained patterns. To avoid misjudgment, a novel recognition strategy is proposed by pre-recognition and recognition phases. When the tested pattern is recognized, the relevant experience-based controller strategy is recalled by an autonomous smooth switching technology. The proposed pattern-based control scheme has some advantages including accurate pattern recognition ability, small controller chattering, and highly autonomous control. Simulation studies on a 2-link flexible joint manipulator are implemented to show these advantages of the proposed scheme.},
  archive      = {J_NEUCOM},
  author       = {Haotian Shi and Min Wang and Cong Wang},
  doi          = {10.1016/j.neucom.2022.04.031},
  journal      = {Neurocomputing},
  pages        = {162-173},
  shortjournal = {Neurocomputing},
  title        = {Pattern-based autonomous smooth switching control for constrained flexible joint manipulator},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TRAT: Tracking by attention using spatio-temporal features.
<em>NEUCOM</em>, <em>492</em>, 150–161. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust object tracking requires knowledge of tracked objects’ appearance, motion and their evolution over time. Although motion provides distinctive and complementary information especially for fast moving objects, most of the recent tracking architectures primarily focus on the objects’ appearance information. In this paper, we propose a two-stream deep neural network tracker that uses both spatial and temporal features. Our architecture is developed over ATOM tracker and contains two backbones: (i) 2D-CNN network to capture appearance features and (ii) 3D-CNN network to capture motion features. The features returned by the two networks are then fused with attention based Feature Aggregation Module (FAM). Since the whole architecture is unified, it can be trained end-to-end. The experimental results show that the proposed tracker TRAT (TRacking by ATtention) achieves the state-of-the-art performance on most of the benchmarks and it significantly outperforms the baseline ATOM tracker. The source code and pretrained models can be found at https://github.com/Hasan4825/TRAT.},
  archive      = {J_NEUCOM},
  author       = {Hasan Saribas and Hakan Cevikalp and Okan Köpüklü and Bedirhan Uzun},
  doi          = {10.1016/j.neucom.2022.04.043},
  journal      = {Neurocomputing},
  pages        = {150-161},
  shortjournal = {Neurocomputing},
  title        = {TRAT: Tracking by attention using spatio-temporal features},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022e). Transformer with peak suppression and knowledge guidance
for fine-grained image recognition. <em>NEUCOM</em>, <em>492</em>,
137–149. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained image recognition is challenging because discriminative clues are usually fragmented, whether from a single image or multiple images. Despite their significant improvements, the majority of existing methods still focus on the most discriminative parts from a single image, ignoring informative details in other regions and lacking consideration of clues from other associated images. In this paper, we analyze the difficulties of fine-grained image recognition from a new perspective and propose a transformer architecture with the peak suppression module and knowledge guidance module, which respects the diversification of discriminative features in a single image and the aggregation of discriminative clues among multiple images. Specifically, the peak suppression module first utilizes a linear projection to convert the input image into sequential tokens. It then blocks the token based on the attention response generated by the transformer encoder. This module penalizes the attention to the most discriminative parts in the feature learning process, therefore, enhancing the information exploitation of the neglected regions. The knowledge guidance module compares the image-based representation generated from the peak suppression module with the learnable knowledge embedding set to obtain the knowledge response coefficients. Afterwards, it formalizes the knowledge learning as a classification problem using response coefficients as the classification scores. Knowledge embeddings and image-based representations are updated during training simultaneously so that the knowledge embedding includes a large number of discriminative clues for different images of the same category. Finally, we incorporate the acquired knowledge embeddings into the image-based representations as comprehensive representations, leading to significantly higher recognition performance. Extensive evaluations on the six popular datasets demonstrate the advantage of the proposed method in performance. The source code and models will be available online after the acceptance of the paper.},
  archive      = {J_NEUCOM},
  author       = {Xinda Liu and Lili Wang and Xiaoguang Han},
  doi          = {10.1016/j.neucom.2022.04.037},
  journal      = {Neurocomputing},
  pages        = {137-149},
  shortjournal = {Neurocomputing},
  title        = {Transformer with peak suppression and knowledge guidance for fine-grained image recognition},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel distributed detection framework for quality-related
faults in industrial plant-wide processes. <em>NEUCOM</em>,
<em>492</em>, 126–136. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality-related fault detection is crucial for improving system reliability, reducing production costs and ensuring product quality, which has been an emerging area of practical interest. An industrial plant-wide process contains several interactive subprocesses and large number of variables, which makes traditional centralized monitoring methods face severe challenges. In this context, a new distributed detection framework for quality-related faults is designed, which will provide a reasonable solution to increase the monitoring reliability and economic efficiency for industrial plant-wide processes. To be specific, the main innovations are: (1) a performance-based process decomposition method is proposed combined mechanical knowledge with affinity propagation (AP) clustering algorithm , which will be helpful to find the common variables between subprocesses; (2) a new dynamic mixed kernel partial least squares (DMKPLS) model with information interaction is built for local monitoring; (3) Bayesian inference is implemented to establish statistical indicators for monitoring the plant-wide process. Furthermore, Tennessee Eastman (TE) process is adopted to verify the fault detection performance of the proposed framework.},
  archive      = {J_NEUCOM},
  author       = {Liang Ma and Mengwei Wang and Jie Dong and Kaixiang Peng},
  doi          = {10.1016/j.neucom.2022.04.014},
  journal      = {Neurocomputing},
  pages        = {126-136},
  shortjournal = {Neurocomputing},
  title        = {A novel distributed detection framework for quality-related faults in industrial plant-wide processes},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Manifold biomedical text sentence embedding.
<em>NEUCOM</em>, <em>492</em>, 117–125. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pretrained distributed sentence embeddings have been proven to be useful in various biomedical text tasks. However, the current research on biomedical text sentence embeddings is mainly based on Euclidean space. The geometric structure of sentences and the relations with the representations of sentence context contribute to more accurate representations of sentence semantics and still need further investigation. To address this issue, in this study, we propose a manifold biomedical text sentence embedding model. To learn biomedical text sentence embedding in the manifold space, we develop an efficient optimization algorithm with neighbourhood preserving embedding based on manifold optimization. We conducted experiments on two tasks of biomedical text classification and clustering, and the experimental results outperformed the state-of-the-art baseline models .},
  archive      = {J_NEUCOM},
  author       = {Bolin Wang and Yuanyuan Sun and Yonghe Chu and Hongfei Lin and Di Zhao and Liang Yang and Chen Shen and Zhihao Yang and Jian Wang},
  doi          = {10.1016/j.neucom.2022.04.009},
  journal      = {Neurocomputing},
  pages        = {117-125},
  shortjournal = {Neurocomputing},
  title        = {Manifold biomedical text sentence embedding},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Elliptical convolution kernel: More real visual field.
<em>NEUCOM</em>, <em>492</em>, 107–116. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most common convolutional neural networks (CNNs) adopt square convolution kernels because the computer can quickly process the square matrix data. However, the shape of the visual field observed by the human visual system is not a square or a rectangle but rather a low-curvature quasi-corrected ellipse. Based on this view, we consider using elliptical convolution kernels to perform convolution operations . According to the natural characteristics of the human visual system, in this oval receptive field, the imaging sharpness of the central area is higher than that of the marginal area of the ellipse. We gradually convert the rectangular convolution kernels into elliptical convolution kernels by adopting an ellipse correction matrix, of which the weights and shape are fixed and pre-calculated. The ellipse correction matrix performs matrix multiplication with the original rectangular convolution kernels without increasing extra computational cost and parameters. The square convolution kernels in the existing CNNs can be easily replaced with elliptical convolution kernels. We have conducted lots of image classification and object detection experiments on some standard datasets, and the experiment results show that the elliptical convolution kernel we proposed is more effective than the currently popular square convolution kernel.},
  archive      = {J_NEUCOM},
  author       = {Hui Chen and Hao Mao and Yuancheng Li},
  doi          = {10.1016/j.neucom.2022.04.033},
  journal      = {Neurocomputing},
  pages        = {107-116},
  shortjournal = {Neurocomputing},
  title        = {Elliptical convolution kernel: More real visual field},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis of clustering methods for crop type mapping using
satellite imagery. <em>NEUCOM</em>, <em>492</em>, 91–106. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the current challenges in population growth and scarceness of food, new technologies are emerging. Remote sensing in general and satellite imagery more specifically are part of these technologies which can help provide accurate monitoring and classification of cultivars. Part of the increase in the use of these technologies has to do with the ongoing increment on the spatial–temporal resolution together with the free availability of some of these services. Typically time series are used as a pre-processing technique and combined with supervised learning techniques in order to build models for crop type identification in remote images. However, these models suffer from the lack of labelled data sets needed to train them. Unsupervised classification can overcome this limitation but has been less frequently used in this research field. This paper proposes to test and analyse the performance of several unsupervised clustering algorithms towards crop type identification on remote images. In this manner combinations of clustering algorithms and distance measures, a key element in the behaviour of these algorithms, are studied using an experimental design with more than twenty datasets built from the combinations of five crops and more than 45000 parcels. Results highlight better clustering methods and distance measures to create accurate and novel crop mapping models for remote sensing images.},
  archive      = {J_NEUCOM},
  author       = {Antonio J. Rivera and María D. Pérez-Godoy and David Elizondo and Lipika Deka and María J. del Jesus},
  doi          = {10.1016/j.neucom.2022.04.002},
  journal      = {Neurocomputing},
  pages        = {91-106},
  shortjournal = {Neurocomputing},
  title        = {Analysis of clustering methods for crop type mapping using satellite imagery},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correlation filters based on spatial-temporal gaussion scale
mixture modelling for visual tracking. <em>NEUCOM</em>, <em>492</em>,
76–90. (<a href="https://doi.org/10.1016/j.neucom.2022.04.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correlation Filters (CFs) have shown outstanding performance in tracking, but are subject to unwanted boundary effects. Spatial regularization (SR) is widely used as an efficient method to alleviate the boundary effects. However, spatial regularization is almost handcrafted and fixed during tracking process, which cannot handle the diversity of objects and the complexity of motion. Furthermore, the rich spatio-temporal correlations among multiple targets of interest cannot be fully exploited. Herein, we propose a spatio-temporal Gaussian scale mixture model (ST-GSM) for correlation-filter-based visual tracking. In our Gaussian scale mixture (GSM) model, each correlation filter coefficient is decomposed into the product of a positive scalar multiplier with sparsity and a Gaussian random variable . The reliable components of the Gaussian random variable can be adaptively selected based on the positive multipliers, aiming at alleviating the notorious boundary effects. To exploit the temporal consistency between adjacent frames, nonzero-means GSM models are developed to characterize the temporal correlations. Specifically, the filter coefficient obtained in the previous frame is used as the mean prior for the current frame. The spatial correlations among filter coefficients have been considered in the structured GSM model, thereby further improving the tracking performance. Experimental results show that the proposed model can significantly improve the performance of CF-based trackers.},
  archive      = {J_NEUCOM},
  author       = {Yuan Cao and Guangming Shi and Weisheng Dong and Tianzhu Zhang and Jinjian Wu and Xuemei Xie and Xin Li},
  doi          = {10.1016/j.neucom.2022.04.013},
  journal      = {Neurocomputing},
  pages        = {76-90},
  shortjournal = {Neurocomputing},
  title        = {Correlation filters based on spatial-temporal gaussion scale mixture modelling for visual tracking},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodal high-order relational network for
vision-and-language tasks. <em>NEUCOM</em>, <em>492</em>, 62–75. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-and-language tasks require the understanding and learning of visual semantic relations , language syntactic relations and mutual relations between these two modalities. Existing methods only focus on intra-modality low-order relations by simply combining pairwise features while ignoring the intra-modality high-order relations and the sophisticated correlations between visual and textual relations. We thus propose the multimodal high-order relational network (MORN) to simultaneously capture the intra-modality high-order relations and the sophisticated correlations between visual and textual relations. The MORN model consists of three modules. A coarse-to-fine visual relation encoder first captures the fully-connected relations between all visual objects, and then refines the local relations between neighbor objects. Moreover, a textual relation encoder is used to capture the syntactic relations between text words. Finally, a relational multimodal transformer is designed to align the multimodal representations and model sophisticated correlations between textual and visual relations. Our proposed approach shows state-of-the-art performance on two vision-and-language tasks, including visual question answering (VQA) and visual grounding (VG).},
  archive      = {J_NEUCOM},
  author       = {Hao Pan and Jun Huang},
  doi          = {10.1016/j.neucom.2022.03.071},
  journal      = {Neurocomputing},
  pages        = {62-75},
  shortjournal = {Neurocomputing},
  title        = {Multimodal high-order relational network for vision-and-language tasks},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Label-aware graph representation learning for multi-label
image classification. <em>NEUCOM</em>, <em>492</em>, 50–61. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label image classification (MLIC) is a quintessential but challenging issue in the field of Computer Vision. Since the label co-occurrence is a crucial component of MLIC, previous existing approaches resort to the label co-occurrence for either modeling label correlations or modeling visual feature relationships. However, these methods ignore either the feature interaction or the label characteristics in MLIC. In this paper, we propose a label-aware graph representation learning (LGR) for MLIC that can explore the label interaction via a graph neural network built on the label co-occurrence and mine the feature correlations via another graph neural network also based on the label co-occurrence. Moreover, to decouple semantic visual features, current approaches resort to the word embedding guided semantic decoupling methods. However, the word embedding cannot clearly represent the label semantic information of MLIC. Hence, we reconstruct the semantic decoupling method by using the graph label representation. Extensive experiments on three benchmark datasets well demonstrate that our proposed framework can significantly achieve the state-of-the-art performance. In addition, a series of ablative studies further demonstrate the positive impacts of our proposed model.},
  archive      = {J_NEUCOM},
  author       = {Yilu Chen and Changzhong Zou and Jianli Chen},
  doi          = {10.1016/j.neucom.2022.04.004},
  journal      = {Neurocomputing},
  pages        = {50-61},
  shortjournal = {Neurocomputing},
  title        = {Label-aware graph representation learning for multi-label image classification},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scale-aware attention network for weakly supervised semantic
segmentation. <em>NEUCOM</em>, <em>492</em>, 34–49. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised semantic segmentation (WSSS) using image-level labels greatly alleviates the burden of obtaining large amounts of pixel-wise annotations. To create pseudo segmentation labels , most WSSS algorithms rely on the local response regions in the class activation maps (CAMs). However, such activation maps only focus on the local discriminative parts of the object, because the classification network does not require the entire object to optimize the objective function. To enhance the network’s ability to focus more on non-discriminative parts of the object and generate high-quality pseudo-masks, the Scale-aware Attention Network (SAN) is proposed. Specifically, a pyramidal attention module is introduced to propagate discriminative information to adjacent object regions by adaptively selecting contextual features from the convolutional pyramid with varied filter scales. A multi-scale prediction fusion structure with a joint loss is proposed to make better use of the complementary information of localization maps in different scales. The dense and integral localization maps are obtained in the inference stage by weighted fusion of the multi-scale predictions, which are then used to train segmentation models . This novel SAN has demonstrated its effectiveness in a series of experiments. It has achieved a state-of-the-art result of 71.9\% mIoU on the PASCAL VOC 2012 segmentation test set compared with other approaches under the same level of supervision.},
  archive      = {J_NEUCOM},
  author       = {Zhiyuan Cao and Yufei Gao and Jiacai Zhang},
  doi          = {10.1016/j.neucom.2022.04.006},
  journal      = {Neurocomputing},
  pages        = {34-49},
  shortjournal = {Neurocomputing},
  title        = {Scale-aware attention network for weakly supervised semantic segmentation},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Some remarks on activation function design in complex
extreme learning using schwarz lemma. <em>NEUCOM</em>, <em>492</em>,
23–33. (<a href="https://doi.org/10.1016/j.neucom.2022.04.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Processing of complex valued data has become a challenge issue in classification problems where artificial neural networks are used as the classifier. This issue particularly arises in design of complex valued activation functions . To address this problem, a complex valued activation function which is obtained by using Schwarz lemma is proposed in this study and a complex-valued extreme learning classifier is utilized to analyse its classification performance. Accordingly, three inequalities have been presented first by considering the different versions of the boundary Schwarz lemma for N α Nα class and then, the proposed activation function has been obtained by performing extremal analyses of these inequalities. During simulations, complex extreme learning machine has been used to compare the classification performances of the proposed and other frequently-used activation functions. In classification step, three multi-class and four binary-class datasets have been utilized. In addition, proposed activation function has been considered for two exemplary function approximation problems. According to simulation results, proposed activation function outperforms other activation functions in term of classification accuracy for all considered datasets. It has also been observed that the proposed activation function gives a lower root mean square error than other trigonometric functions in function approximation problem.},
  archive      = {J_NEUCOM},
  author       = {Bülent Nafi Örnek and Salih Berkan Aydemir and Timur Düzenli and Bilal Özak},
  doi          = {10.1016/j.neucom.2022.04.010},
  journal      = {Neurocomputing},
  pages        = {23-33},
  shortjournal = {Neurocomputing},
  title        = {Some remarks on activation function design in complex extreme learning using schwarz lemma},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stability analysis of delayed neural networks: An auxiliary
matrix-based technique. <em>NEUCOM</em>, <em>492</em>, 16–22. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper revisits the problem of stability analysis for delayed neural networks (DNNs). By introducing a set of auxiliary vectors and slack matrices, an auxiliary matrix-based integral inequality (AMBII) is presented. The auxiliary matrix is composed of auxiliary vectors, slack matrix and time-varying delay. It can make a trade off between conservatism and complexity. By using AMBII, a less conservative stability criterion is obtained for DNNs in terms of linear matrix inequalities (LMIs). The effectiveness of the stability condition can be demonstrated by illustrating a numerical example.},
  archive      = {J_NEUCOM},
  author       = {Yufeng Tian and Zhanshan Wang},
  doi          = {10.1016/j.neucom.2022.04.036},
  journal      = {Neurocomputing},
  pages        = {16-22},
  shortjournal = {Neurocomputing},
  title        = {Stability analysis of delayed neural networks: An auxiliary matrix-based technique},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visually aligned sound generation via sound-producing motion
parsing. <em>NEUCOM</em>, <em>492</em>, 1–15. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of generating natural sounds from videos is still challenging because the generated sounds should be highly temporal-wise aligned with visual motions. To reach this goal, the model needs to extract the discriminative visual motions correlated to the corresponding sound. In this paper, we propose a novel method of sound-producing motion parsing to explore the discriminative temporal visual embedding, which can distinguish the sound-producing motion from still to facilitate the mapping from visual motion to the corresponding sound. In the proposed method, we first extract the time-redundant visual embedding in a sliding temporal window through video frames to better distinguish the transient visual motion from complex background information. Subsequently, a series of temporal regulators are performed to capture the various tempo-scales of visual motions, and then a cross-modal temporal aligner is introduced to align the visual and sound embeddings in finer temporal scale. Finally, the visual embedding is affined and upsampled to ensure that the generated sound is consistent with real one in the resolution scale. Furthermore in order to make the model more interpretable, we leverage the gradient flowing into the bottleneck layer to produce a coarse temporal activation map, highlighting the important temporal cues in the visual embedding for the sound prediction. To evaluate the effectiveness of our approach, we conduct several experiments on the generated sounds. Extensive evaluation results demonstrate that the proposed method can improve the temporal-wise alignment significantly and obtain the competitive results in sound quality as well. Code will be released here.},
  archive      = {J_NEUCOM},
  author       = {Xin Ma and Wei Zhong and Long Ye and Qin Zhang},
  doi          = {10.1016/j.neucom.2022.04.018},
  journal      = {Neurocomputing},
  pages        = {1-15},
  shortjournal = {Neurocomputing},
  title        = {Visually aligned sound generation via sound-producing motion parsing},
  volume       = {492},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lyapunov stable learning laws for multilayer recurrent
neural networks. <em>NEUCOM</em>, <em>491</em>, 644–657. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to develop stable learning laws (in the sense of Lyapunov) for a general class of multilayer recurrent neural network (RNN) non-parametric identifier. The application of control Lyapunov functions in the discrete-time domain ensures the ultimate boundedness for the identification error enforcing it to reach a boundary set related to the power of parametric uncertainties and the modeling error. This work presents a general algorithm to design RNNs with n n layers: one input layer, n - 2 n-2 hidden layers, and one output layer. Numerical simulations support the theoretical results showing the advantages of increasing the number of layers in an RNN structure. A first example identifies the unknown states of the Van Der Pol oscillator. Then, a second example demonstrates the behavior of an RNN in a third-order system with high nonlinear dynamics describing an ozonation system of a single contaminant. For both cases, the application of the developed learning laws succeeds in estimating the uncertain dynamics. Moreover, the numerical simulations show how the identification error decreases as the number of layers increases.},
  archive      = {J_NEUCOM},
  author       = {Alejandro Guarneros-Sandoval and Mariana Ballesteros and Ivan Salgado and Julia Rodríguez-Santillán and Isaac Chairez},
  doi          = {10.1016/j.neucom.2021.12.041},
  journal      = {Neurocomputing},
  pages        = {644-657},
  shortjournal = {Neurocomputing},
  title        = {Lyapunov stable learning laws for multilayer recurrent neural networks},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards collaborative appearance and semantic adaptation for
medical image segmentation. <em>NEUCOM</em>, <em>491</em>, 633–643. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new unsupervised domain adaptation framework, named as Collaborative Appearance and Semantic Adaptation (CASA) , for addressing the medical domain mismatch problem. Domain adaptation techniques have become one of the hot topics, especially when applying the established deep neural network into new domains in the medical analysis, i.e., semantic segmentation of medical lesions. To achieve unsupervised domain adaptation , our designed CASA framework could preserve synergistic fusion of adaptation knowledge from the perspectives of appearance and semantic. To be specific, we transform the appearance of medical lesions across domains via a C haracterization T ransfer M odule (CTM), which can mitigate the appearance divergence of medical lesions across domains. Meanwhile, a R epresentation T ransfer M odule (RTM) is proposed via incorporating with a conditional generative adversarial network , which could transform features of source lesions to target-like feature, and further narrow the domain-wise distribution gap of underlying semantic knowledge . To the end, a challenging application of medical image segmentation is used to extensively validate the effectiveness of our proposed CASA framework. Various experiment results show its superior performance by a significant margin when comparing to the state-of-the-art domain adaptation methods.},
  archive      = {J_NEUCOM},
  author       = {Qiang Wang and Yingkui Du and Huijie Fan and Chi Ma},
  doi          = {10.1016/j.neucom.2021.12.040},
  journal      = {Neurocomputing},
  pages        = {633-643},
  shortjournal = {Neurocomputing},
  title        = {Towards collaborative appearance and semantic adaptation for medical image segmentation},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Real-time cooperative kinematic control for multiple robots
in distributed scenarios with dynamic neural networks. <em>NEUCOM</em>,
<em>491</em>, 621–632. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates the real-time cooperative kinematic control for multiple robots in distributed scenarios. The information interaction among robots is described as a directed topology in which each robotic manipulator is connected to specified nodes. Besides, a performance index of minimum joint velocity norm is introduced to regulate the robots’ motion. Combining with the performance index and integrating the related constraints, a control scheme is developed to guide the behavior of robots with an error feedback term leveraged to improve the real-time execution accuracy of tasks. Moreover, considering that the involved parameters are time-dependent, a dynamic neural-network-assisted solver is constructed to solve the control scheme online. In the end, simulations and illustrative experiments on the virtual robot experiment platform (V-REP) are conducted by a set of UR5 robots to execute tasks in a switchable directed topology, where the corresponding results demonstrate the effectiveness of the proposed scheme.},
  archive      = {J_NEUCOM},
  author       = {Mei Liu and Jiazheng Zhang and Mingsheng Shang},
  doi          = {10.1016/j.neucom.2021.12.038},
  journal      = {Neurocomputing},
  pages        = {621-632},
  shortjournal = {Neurocomputing},
  title        = {Real-time cooperative kinematic control for multiple robots in distributed scenarios with dynamic neural networks},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A heuristic-driven uncertainty based ensemble framework for
fake news detection in tweets and news articles. <em>NEUCOM</em>,
<em>491</em>, 607–620. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significance of social media has increased manifold in the past few decades as it helps people from even the most remote corners of the world to stay connected. With the advent of technology, digital media has become more relevant and widely used than ever before and along with this, there has been a resurgence in the circulation of fake news and tweets that demand immediate attention. In this paper, we describe a novel Fake News Detection system that automatically identifies whether a news item is “real” or “fake”, as an extension of our work in the CONSTRAINT COVID-19 Fake News Detection in English challenge. We have used an ensemble model consisting of pre-trained models followed by a statistical feature fusion network, along with a novel heuristic algorithm by incorporating various attributes present in news items or tweets like source, username handles, URL domains and authors as statistical feature. Our proposed framework have also quantified reliable predictive uncertainty along with proper class output confidence level for the classification task . We have evaluated our results on the COVID-19 Fake News dataset and FakeNewsNet dataset to show the effectiveness of the proposed algorithm on detecting fake news in short news content as well as in news articles. We obtained a best F1-score of 0.9892 on the COVID-19 dataset, and an F1-score of 0.9156 on the FakeNewsNet dataset.},
  archive      = {J_NEUCOM},
  author       = {Sourya Dipta Das and Ayan Basak and Saikat Dutta},
  doi          = {10.1016/j.neucom.2021.12.037},
  journal      = {Neurocomputing},
  pages        = {607-620},
  shortjournal = {Neurocomputing},
  title        = {A heuristic-driven uncertainty based ensemble framework for fake news detection in tweets and news articles},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-source temporal knowledge graph embedding for edge
computing enabled internet of vehicles. <em>NEUCOM</em>, <em>491</em>,
597–606. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing furnishes communicational and computational mediators such as edge nodes (ENs) between vehicles and cloud platforms, accelerating interactive services such as route arrangement and congestion warning for the Internet of Vehicles (IoV). Implemented with the knowledge graph (KG), EN is further enabled to represent the structural relations between multi-source entities (e.g., vehicles and roads) for information reasoning tasks such as traffic flow prediction . However, due to the spatial precision dissimilarity, discontinuity, and relevance of the multi-source data, plus underestimating temporal consecutiveness in traditional rules, establishing KGs for ENs remains a challenge. Given this challenge, a temporal knowledge graph empowered reasoning model named TKGERM is developed. Firstly, confluent data for each EN are initiated by logical smoothing and filtering with multi-source data. Then, the temporal KGs are constructed by extending KG triples into temporal quadruples using timestamp information in the complex vector representation space. Furthermore, with the relative temporal information of past events, logical rules are explored by the temporal KG for traffic information reasoning. Finally, the time performance and effectiveness of TKGERM are evaluated by implementing a series of experiments on real-world data collected from the Bureau of Transportation in Guangdong, China.},
  archive      = {J_NEUCOM},
  author       = {Haoyang Shi and Yulan Zhang and Zhanyang Xu and Xiaolong Xu and Lianyong Qi},
  doi          = {10.1016/j.neucom.2021.12.036},
  journal      = {Neurocomputing},
  pages        = {597-606},
  shortjournal = {Neurocomputing},
  title        = {Multi-source temporal knowledge graph embedding for edge computing enabled internet of vehicles},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensembles of probabilistic LSTM predictors and correctors
for bearing prognostics using industrial standards. <em>NEUCOM</em>,
<em>491</em>, 575–596. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic prediction of the remaining useful life (RUL) of bearings is critically important, especially in an industrial setting where unplanned maintenance needs, unscheduled equipment downtime, or catastrophic failures can cost a company millions of dollars and threaten worker safety. Current research in the field of bearing prognostics clearly shows the advantage of a deep learning-based solution, but the reliability of purely data-driven predictions is questionable in harsh industrial environments with varying operational conditions. To make this work industrially relevant, we adopt ISO guidelines to determine bearing failure thresholds (specifically ISO 10816), which are defined in the velocity domain, while considering characteristic bearing fault frequencies defined by the geometry of each bearing. We propose a two-stage Long Short-Term Memory (LSTM) model ensemble which includes: (1) a predictor step to forecast and (2) a corrector step to offset the RUL prediction. Each LSTM model within the ensemble is customized to include a Gaussian layer that captures the aleatoric uncertainty in the forecasted parameter, and the ensemble of all the individual LSTM models provides the epistemic uncertainty in the RUL prediction. We demonstrate the implementation of the proposed model on the publicly available Xi&#39;an Jiaotong University and Changxing Sumyoung Technology Co., Ltd. (XJTU-SY) bearing dataset and establish the superiority of the model, both in terms of accuracy as well as uncertainty quantification, when compared against other commonly used techniques in the field of bearing prognostics. The ensemble model tends to explore multiple functional/forecast modes providing better uncertainty estimates when compared to Bayesian counterparts.},
  archive      = {J_NEUCOM},
  author       = {Venkat P. Nemani and Hao Lu and Adam Thelen and Chao Hu and Andrew T. Zimmerman},
  doi          = {10.1016/j.neucom.2021.12.035},
  journal      = {Neurocomputing},
  pages        = {575-596},
  shortjournal = {Neurocomputing},
  title        = {Ensembles of probabilistic LSTM predictors and correctors for bearing prognostics using industrial standards},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Learning adversarial point-wise domain alignment for stereo
matching. <em>NEUCOM</em>, <em>491</em>, 564–574. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The state-of-the-art stereo matching models trained on synthetic datasets have difficulty in generalizing to real-world datasets. One major reason is that illumination and texture in the real world are hard to be simulated, resulting in big differences between synthetic and real-world data. In this study, instead of narrowing the image-level appearance difference, we focus on aligning both data domains in feature space in an unsupervised manner and propose an end-to-end domain alignment stereo network (DAStereo). A domain alignment module (DAM) is introduced by learning a point-wise linear transformation . We demonstrate that DAM can maintain sufficient alignment capacity with fewer parameters than the globally nonlinear mapping . To explicitly promote the point-wise domain alignment, adversarial learning is further introduced using a cost volume discriminator in a hybrid training manner. Experimental results show that DAStereo outperforms the state-of-the-art unsupervised and adaptive methods and even achieves comparable performance to some supervised methods.},
  archive      = {J_NEUCOM},
  author       = {Chenghao Zhang and Gaofeng Meng and Richard Yi Da Xu and Shiming Xiang and Chunhong Pan},
  doi          = {10.1016/j.neucom.2021.12.034},
  journal      = {Neurocomputing},
  pages        = {564-574},
  shortjournal = {Neurocomputing},
  title        = {Learning adversarial point-wise domain alignment for stereo matching},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Meta graph transformer: A novel framework for
spatial–temporal traffic prediction. <em>NEUCOM</em>, <em>491</em>,
544–563. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic prediction is critical for enhancing the performance of intelligent transportation systems . The key challenge to this task is how to properly model the complex dynamics of traffic while respecting and exploiting both spatial and temporal heterogeneity in data. This paper proposes a novel framework called Meta Graph Transformer (MGT) to address this problem. The MGT framework is a generalization of the original transformer, which is used to model vector sequences in natural language processing . Specifically, MGT has an encoder-decoder architecture. The encoder is responsible for encoding historical traffic data into intermediate representations, while the decoder predicts future traffic states autoregressively. The main building blocks of MGT are three types of attention layers named Temporal Self-Attention (TSA), Spatial Self-Attention (SSA), and Temporal Encoder-Decoder Attention (TEDA), respectively. They all have a multi-head structure. TSAs and SSAs are employed by both the encoder and decoder to capture temporal and spatial correlations . TEDAs are employed by the decoder, allowing every position in the decoder to attend all positions in the input sequence temporally. By leveraging multiple graphs, SSA can conduct sparse spatial attention with various inductive biases. To facilitate the model’s awareness of temporal and spatial conditions, Spatial–Temporal Embeddings (STEs) are learned from external attributes, which are composed of temporal attributes (e.g. sequential order, time of day) and spatial attributes (e.g. Laplacian eigenmaps). These embeddings are then utilized by all the attention layers via meta-learning, hence endowing these layers with Spatial–Temporal Heterogeneity-Aware (STHA) properties. Experiments on three real-world traffic datasets demonstrate the superiority of our model over several state-of-the-art methods. Our code and data are available at ( http://github.com/lonicera-yx/MGT ).},
  archive      = {J_NEUCOM},
  author       = {Xue Ye and Shen Fang and Fang Sun and Chunxia Zhang and Shiming Xiang},
  doi          = {10.1016/j.neucom.2021.12.033},
  journal      = {Neurocomputing},
  pages        = {544-563},
  shortjournal = {Neurocomputing},
  title        = {Meta graph transformer: A novel framework for Spatial–Temporal traffic prediction},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning edge-preserved image stitching from multi-scale
deep homography. <em>NEUCOM</em>, <em>491</em>, 533–543. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image stitching is a classical and challenging technique in computer vision, which aims to generate an image with a wide field of view. The traditional methods heavily depend on feature detection and require the feature points to be dense and evenly distributed in the image, leading to poor robustness in low-texture scenes. Learning methods are rarely studied due to the unavailability of ground truth stitched results, showing unreliable performance on real-world datasets. In this paper, we propose an image stitching learning framework, which consists of a multi-scale deep homography module and an edge-preserved deformation module. First, we design a multi-scale deep homography module to estimate the accurate homography progressively from coarse to fine. After that, an edge-preserved deformation module is designed to learn the deformation rules of image stitching from edge to content, generating the stitched image with artifacts eliminated. Besides, the proposed supervised learning framework can stitch images of arbitrary resolutions and demonstrate good generalization capability in real-world images. Experiments show that our superiority to the existing homography solutions and image stitching algorithms.},
  archive      = {J_NEUCOM},
  author       = {Lang Nie and Chunyu Lin and Kang Liao and Yao Zhao},
  doi          = {10.1016/j.neucom.2021.12.032},
  journal      = {Neurocomputing},
  pages        = {533-543},
  shortjournal = {Neurocomputing},
  title        = {Learning edge-preserved image stitching from multi-scale deep homography},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AHDet: A dynamic coarse-to-fine gaze strategy for active
object detection. <em>NEUCOM</em>, <em>491</em>, 522–532. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the work setting of deep learning , most of the neural networks employed for visual object detection in recent years are based on bounding box regression. The performance of active detectors through multi-step decision-making is limited by the rough model design. However, from the perspective of cognitive science, the recognition in the human visual system is a decision process from coarse to fine. Based on the theory of “see the forest first, then the trees”, this paper proposes a dynamic coarse-to-fine gaze strategy for active object detection, named AHDet, which takes the key points as the realization carrier of the coarse-to-fine concept. The detection process is divided into two steps, AIM and HIT. In the step of AIM, the positioning and prior bounding boxes for objects are given by detecting the center points, referring to the first glance. In the step of HIT, bounding boxes are dynamically adjusted to obtain compact bounding boxes with the help of the corner points, referring to the careful observation. With the design of the two-step coarse-to-fine gaze process, AHDet outperforms traditional approaches. A series of experiments performed on MS-COCO and PASCAL VOC dataset demonstrate the advantages of AHDet.},
  archive      = {J_NEUCOM},
  author       = {Nuo Xu and Chunlei Huo and Xin Zhang and Chunhong Pan},
  doi          = {10.1016/j.neucom.2021.12.030},
  journal      = {Neurocomputing},
  pages        = {522-532},
  shortjournal = {Neurocomputing},
  title        = {AHDet: A dynamic coarse-to-fine gaze strategy for active object detection},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Strategies for time series forecasting with generalized
regression neural networks. <em>NEUCOM</em>, <em>491</em>, 509–521. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses how to forecast time series using generalized regression neural networks. The main goal is to take advantage of their inherent properties to generate fast, highly accurate forecasts. To this end, the key modeling decisions involved in forecasting with generalized regression neural networks are described. To deal with every modeling decision, several strategies are proposed. Each strategy is analyzed in terms of forecast accuracy and computational time. Apart from the modeling decisions, any successful time series forecasting methodology has to be able to capture the seasonal and trend patterns found in a time series. In this regard, some clever techniques to cope with these patterns are also suggested. The proposed methodology is able to forecast time series in an automatic way. Additionally, the paper introduces a publicly available R package that incorporates the best presented modeling approaches and transformations to forecast time series with generalized regression neural networks.},
  archive      = {J_NEUCOM},
  author       = {Francisco Martínez and Francisco Charte and María Pilar Frías and Ana María Martínez-Rodríguez},
  doi          = {10.1016/j.neucom.2021.12.028},
  journal      = {Neurocomputing},
  pages        = {509-521},
  shortjournal = {Neurocomputing},
  title        = {Strategies for time series forecasting with generalized regression neural networks},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Trustworthiness neural networks in distributed computing and
artificial intelligence. <em>NEUCOM</em>, <em>491</em>, 507–508. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Fernando De la Prieta and Juan M. Corchado Rodríguez},
  doi          = {10.1016/j.neucom.2021.11.058},
  journal      = {Neurocomputing},
  pages        = {507-508},
  shortjournal = {Neurocomputing},
  title        = {Trustworthiness neural networks in distributed computing and artificial intelligence},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enabling automation and edge intelligence over resource
constraint IoT devices for smart home. <em>NEUCOM</em>, <em>491</em>,
494–506. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart home applications are pervasive and have gained popularity due to the overwhelming use of Internet of Things (IoT). The revolution in IoT technologies made homes more convenient, efficient and perhaps more secure. The need to advance smart home technology is necessary at this stage as IoT is abundantly used in automation industry. However, most of the proposed solutions are lacking in certain key areas of the system i.e., high interoperability, data independence, privacy, and optimization in general. The use of machine learning algorithms requires high-end hardware and are usually deployed on servers, where computation is convenient, but at the cost of bandwidth. However, more recently edge AI enabled systems are being proposed to shift the computation burden from the server side to the client side enabling smart devices. In this paper, we take advantage of the edge AI enabled technology to propose a fully featured cohesive system for smart home based on IoT and edge computing . The proposed system makes use of industry standards adopted for fog computing as well as providing robust responses from connected IoT sensors in a typical smart home. The proposed system employs edge devices as a computational platform in terms of reducing energy costs and provides security, while remotely controlling all appliances behind a secure gateway . A case study of human fall detection is evaluated by a custom lightweight deep neural network architecture implemented over the edge device of the proposed framework. The case study was validated using the Le2i dataset. During the training, the early stopping threshold was achieved with 98\% accuracy for training set and 94\% for validation set. The model size of the network was 6.4 MB which is significantly lower than other networks with similar performance.},
  archive      = {J_NEUCOM},
  author       = {Mansoor Nasir and Khan Muhammad and Amin Ullah and Jamil Ahmad and Sung Wook Baik and Muhammad Sajjad},
  doi          = {10.1016/j.neucom.2021.04.138},
  journal      = {Neurocomputing},
  pages        = {494-506},
  shortjournal = {Neurocomputing},
  title        = {Enabling automation and edge intelligence over resource constraint IoT devices for smart home},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Deep dictionary learning: Algorithm, theory and
application. <em>NEUCOM</em>, <em>491</em>, 492–493. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Zhao Zhang ( Guest editors of the special issue ) and Meng Wang and Sheng Li and Zheng Zhang},
  doi          = {10.1016/j.neucom.2020.11.071},
  journal      = {Neurocomputing},
  pages        = {492-493},
  shortjournal = {Neurocomputing},
  title        = {Editorial: deep dictionary learning: algorithm, theory and application},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Human visual saliency and artificial neural
attention in deep learning. <em>NEUCOM</em>, <em>491</em>, 489–491. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Wenguan Wang (Guest editors of the special issue) and Ming-Ming Cheng and Haibin Ling and Fatih Porikli},
  doi          = {10.1016/j.neucom.2020.08.066},
  journal      = {Neurocomputing},
  pages        = {489-491},
  shortjournal = {Neurocomputing},
  title        = {Editorial: Human visual saliency and artificial neural attention in deep learning},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structure optimization of prior-knowledge-guided neural
networks. <em>NEUCOM</em>, <em>491</em>, 464–488. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prior-knowledge use in neural networks , for example, knowledge of a physical system, allows network training to be tailored to specific problems. Literature shows that prior-knowledge in neural network training enhances predictive performance . Research to date focuses on parametric optimization rather than structure optimization. We present a new framework to optimize the structure of a neural network using prior-knowledge. This is achieved through optimizing the number of hidden units via a line search and cross-validation using the empirical error to eliminate data-set/model-structure application dependency for prior-knowledge guided neural networks. In addition to using the prior-knowledge in the model training step, we propose utilizing the prior errors as part of the cross-validation performance index to improve generalization. Results demonstrate that the proposed training framework enhances the model’s prediction accuracy and prior-knowledge consistency for convex data sets with a unique minimum and non-convex multi-modal data sets. The presented results yield a new understanding of physics-guided neural networks in terms of their structural and parametric optimization.},
  archive      = {J_NEUCOM},
  author       = {Mohamed Atwya and George Panoutsos},
  doi          = {10.1016/j.neucom.2022.03.008},
  journal      = {Neurocomputing},
  pages        = {464-488},
  shortjournal = {Neurocomputing},
  title        = {Structure optimization of prior-knowledge-guided neural networks},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of machine learning approaches in animal behaviour.
<em>NEUCOM</em>, <em>491</em>, 442–463. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Animal activity recognition is an important topic that facilitates understanding of animal behavior that is useful for analyzing and classifying their wellbeing. Research studies have been reporting the use of animal activity as an effective indicator of their health state. This survey focuses on recent advancements in machine intelligence utilizing wearable devices for sheep activity recognition. We summarise existing works focusing on various types of sensors used in agricultural sheep activity recognition. Furthermore, data segmentation methods used in each study, followed by the potential recommendations on window size and sample rate selection are addressed in detail. Finally, we present the features being identified as significant along with an overview of machine learning algorithms used in the domain of sheep activity recognition using accelerometer data.},
  archive      = {J_NEUCOM},
  author       = {Natasa Kleanthous and Abir Jaafar Hussain and Wasiq Khan and Jennifer Sneddon and Ahmed Al-Shamma&#39;a and Panos Liatsis},
  doi          = {10.1016/j.neucom.2021.10.126},
  journal      = {Neurocomputing},
  pages        = {442-463},
  shortjournal = {Neurocomputing},
  title        = {A survey of machine learning approaches in animal behaviour},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heuristics and metaheuristics for biological network
alignment: A review. <em>NEUCOM</em>, <em>491</em>, 426–441. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the emergence of big-data and high-throughput biological analyses, massive biological data have been generated and accessed, and many heuristic and metaheuristic algorithms have been proposed for further analysis and extraction of the potential knowledge of those data. Biological network alignment (BNA) aligns proteins between species to maximally conserve biological and topological structures of proteins. The studies of BNAs are essential for uncovering conserved protein interactions of biological networks with functional homology and understanding the evolutionary process across species. In this paper, we give a comprehensive review for the works in BNAs from a novel taxonomy: heuristic and metaheuristic BNAs. Moreover, we give some comparative analyses of the alignment models, real data sets , evaluation metrics and experimental results in these works. Finally, we provide some conclusions and give some possible future directions for BNAs.},
  archive      = {J_NEUCOM},
  author       = {Lijia Ma and Zengyang Shao and Lingling Li and Jiaxiang Huang and Shiqiang Wang and Qiuzhen Lin and Jianqiang Li and Maoguo Gong and Asoke K. Nandi},
  doi          = {10.1016/j.neucom.2021.08.156},
  journal      = {Neurocomputing},
  pages        = {426-441},
  shortjournal = {Neurocomputing},
  title        = {Heuristics and metaheuristics for biological network alignment: A review},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FCMNet: Frequency-aware cross-modality attention networks
for RGB-d salient object detection. <em>NEUCOM</em>, <em>491</em>,
414–425. (<a
href="https://doi.org/10.1016/j.neucom.2022.04.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D saliency detection aims to comprehensively use RGB images and depth maps to detect object saliency. This field still faces two challenges: 1) how to extract representative multimodal features and 2) how to effectively fuse them. Most of the previous methods in this field equally treat RGB and depth information as two modalities, while not considering the difference in the frequency domain of the two modalities, and may lose some complementary information. In this paper, we introduce the frequency channel attention mechanism into the fusion process. First, we design a frequency-aware cross-modality attention (FACMA) module to interweave adequate channel features and select representative features. In the FACMA module, we also propose a spatial frequency channel attention (SFCA) module to introduce more complementary information in different channels. Second, we develop a weighted cross-modality fusion (WCMF) module to adaptively fuse multimodality features by learning the content-dependent weight maps. Comprehensive experiments on several benchmark datasets demonstrate that the proposed framework outperforms seventeen state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xiao Jin and Chunle Guo and Zhen He and Jing Xu and Yongwei Wang and Yuting Su},
  doi          = {10.1016/j.neucom.2022.04.015},
  journal      = {Neurocomputing},
  pages        = {414-425},
  shortjournal = {Neurocomputing},
  title        = {FCMNet: Frequency-aware cross-modality attention networks for RGB-D salient object detection},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online human action detection and anticipation in videos: A
survey. <em>NEUCOM</em>, <em>491</em>, 395–413. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To meet the demand for powerful models for practical applications in real time, the focus of research on human actions has shifted from offline detection to online and real-time understanding, such as driver-assistance systems, surveillance analysis, and robot services. In recent years, with the development of video recording acquisition technology and deep learning , online action analysis has made significant progress. However, there is a lack of comprehensive online surveys for online human action detection. In this survey, we discuss two hot real-time concerns: online action detection and action anticipation. Online action/activity detection aims to determine whether an action is currently taking place and what kind of action it is in untrimmed videos. Action anticipation aims to anticipate human actions under limited observation of videos. Online action detection and anticipation require accuracy and low latency of detection when the video is partly observed. We present a comprehensive study that includes the definition, taxonomy, comparison of state-of-the-art techniques, datasets, metrics, challenges, and future directions. We hope that it will provide readers with a detailed understanding of the topic and inspiration for new research directions.},
  archive      = {J_NEUCOM},
  author       = {Xuejiao Hu and Jingzhao Dai and Ming Li and Chenglei Peng and Yang Li and Sidan Du},
  doi          = {10.1016/j.neucom.2022.03.069},
  journal      = {Neurocomputing},
  pages        = {395-413},
  shortjournal = {Neurocomputing},
  title        = {Online human action detection and anticipation in videos: A survey},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NN adaptive optimal tracking control for a class of
uncertain nonstrict feedback nonlinear systems. <em>NEUCOM</em>,
<em>491</em>, 382–394. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel reinforcement learning-based adaptive optimal controller is proposed to obtain the desired tracking performance for a class of nonlinear nonstrict feedback systems with uncertain dynamics in this paper. The main feature is that the proposed control scheme can handle the control problem that traditional reinforcement learning-based algorithm cannot deal with. To achieve the optimal control of the high-order system, the virtual and the actual control of the system are optimized by using reinforcement learning method. Radial basis function neural networks are employed to approximate the uncertain system dynamics, the optimal cost function and the optimal control law, respectively. According to Lyapunov stability theorem, it is proved that all the error signals in the closed-loop systems are semi-globally uniformly ultimately bounded (SGUUB) while the desired tracking control performance can be obtained. Simulation results are given to illustrate the effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Liang’en Yuan and Tieshan Li and Shaocheng Tong and Yang Xiao and Xiaoyang Gao},
  doi          = {10.1016/j.neucom.2022.03.049},
  journal      = {Neurocomputing},
  pages        = {382-394},
  shortjournal = {Neurocomputing},
  title        = {NN adaptive optimal tracking control for a class of uncertain nonstrict feedback nonlinear systems},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Learning meta-adversarial features via multi-stage
adaptation network for robust visual object tracking. <em>NEUCOM</em>,
<em>491</em>, 365–381. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual tracking is a crucial research topic in computer vision, which aims to locate any object as precisely as possible over a sequence of image frames. However, the existing trackers often suffer from the object drifting problem due to the difficulty of adapting to complex environments. In this paper, we propose a novel multi-stage adaptation network (MAN), including the meta-adaptation, feature adaptation, and location adaptation sub-networks, to improve the adaptability and robustness of tracking. Specifically, the meta-adaptation sub-network takes advantage of meta-learning to enhance the generalization ability for the new tracking sequence. The feature adaptation sub-network exploits an adversarial attention mask module and a multi-level and multi-scale meta-classifier module for improving the robustness and discriminative ability. Moreover, the location adaptation sub-network can refine the tracking location to avoid the drifting problem. The three sub-networks can benefit from each other and are strategically integrated in a whole framework. Extensive experimental results demonstrate that the proposed tracker outperforms the state-of-the-art methods on several challenging datasets, including OTB50, OTB2013, OTB100, UAV123, UAV20L, NfS, LaSOT, VOT2016, and VOT2018.},
  archive      = {J_NEUCOM},
  author       = {Si Chen and Libo Wang and Zhen Wang and Yan Yan and Da-Han Wang and Shunzhi Zhu},
  doi          = {10.1016/j.neucom.2022.03.031},
  journal      = {Neurocomputing},
  pages        = {365-381},
  shortjournal = {Neurocomputing},
  title        = {Learning meta-adversarial features via multi-stage adaptation network for robust visual object tracking},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-supervised label distribution learning with
co-regularization. <em>NEUCOM</em>, <em>491</em>, 353–364. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label Distribution Learning (LDL) is a machine learning paradigm which is recently proposed to deal with the more ambiguity label. This paradigm assigns the distribution-level label to an instance so that it can exploit the relative importance of every candidate labels to a particular instance. Previous studies always concentrate on the methods under strong supervision, which requires a large number of tagged training data. In real-world applications, it is usually difficult to collect numerical precise labels owing to the large costs in labor and time spent on the label annotation. To this end, this paper proposes a novel algorithm named S emi- S upervised L abel D istribution L earning with Co -regularization ( S 2 S2 LDL-CO). To benefit from all available information, ensemble of two different models is utilized to deal with the labeled and unlabeled data , respectively. More specifically, the co-regularization framework is adopted to combine these two different models, which can process both the labeled and unlabeled data with good robustness and consistency. What’s more, manifold regularization and l 2 , 1 l2,1 -norm are also added into the objective function, which can fully exploit the implicit information in instances. Finally, the well-designed objective function is optimized by an Alternating Direction of Method of Multipliers (ADMM) algorithm. Experimental results tested on thirteen benchmark datasets illustrate its effectiveness over several state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xinyuan Liu and Jihua Zhu and Qinghai Zheng and Zhiqiang Tian and Zhongyu Li},
  doi          = {10.1016/j.neucom.2022.03.041},
  journal      = {Neurocomputing},
  pages        = {353-364},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised label distribution learning with co-regularization},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning-based pose prediction for visual servoing of
robotic manipulators using image similarity. <em>NEUCOM</em>,
<em>491</em>, 343–352. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy of pose prediction is crucial in learning-based visual servoing. Motivated by the fact that the more similar observed images are, the closer the camera poses, we propose a joint training strategy with a two-part loss function in this paper. One part is the least absolute deviation (L1) loss function, which is defined by the error between the predicted pose and the pose label. The other is the mean similarity image measurement loss function (MSIM), which is related to the image’s brightness, contrast, and structure similarity and is determined by the differences between the input image and the image corresponding to the predicted pose. Meanwhile, a data generator based on spherical projection is created to generate data uniformly for training a CNN model, and position-based visual servoing (PBVS) is designed for a robotic manipulator after pose prediction. A numeric simulation and real experiments are conducted in a virtual environment and with a UR3 manipulator. The results show that the proposed method can realize more accurate pose prediction and is robust to occlusion disturbance, and PBVS is achieved by using monocular images.},
  archive      = {J_NEUCOM},
  author       = {Yaozhen He and Jian Gao and Yimin Chen},
  doi          = {10.1016/j.neucom.2022.03.045},
  journal      = {Neurocomputing},
  pages        = {343-352},
  shortjournal = {Neurocomputing},
  title        = {Deep learning-based pose prediction for visual servoing of robotic manipulators using image similarity},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EvoSTGAT: Evolving spatiotemporal graph attention networks
for pedestrian trajectory prediction. <em>NEUCOM</em>, <em>491</em>,
333–342. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting pedestrian trajectory is an essential task in many applications. While previous studies based on graphs seek to model spatiotemporal information among pedestrian interactions, most of them neglect the recursive and continuous relations between neighboring time points. In this paper, we propose an evolving spatiotemporal graph attention network to predict future trajectories of pedestrians. This model considers the evolving relations of social interactions between contiguous time points and uses coordinates. The interaction is modeled by an evolving and dynamic attention mechanism. The social influence of each pedestrians of current frame is evolved from that of last frame and will be utilized to generate the social influence of next frame. The proposed model was tested on two challenging datasets and the experimental results prove the strength of the model.},
  archive      = {J_NEUCOM},
  author       = {Haowen Tang and Ping Wei and Jiapeng Li and Nanning Zheng},
  doi          = {10.1016/j.neucom.2022.03.051},
  journal      = {Neurocomputing},
  pages        = {333-342},
  shortjournal = {Neurocomputing},
  title        = {EvoSTGAT: Evolving spatiotemporal graph attention networks for pedestrian trajectory prediction},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting chaotic time series and replicating chaotic
attractors based on two novel echo state network models.
<em>NEUCOM</em>, <em>491</em>, 321–332. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network is the inevitable outcome of the rapid development of artificial intelligence . Based on the idea of homotopy and combined activation function , two novel echo state network (ESN) models are proposed. Compared with several activation functions commonly used in the neural network, the proposed models provide intuitive but effective approaches to chaotic forecasting, and the prediction accuracy is higher. Secondly, for the Mackey-Glass (MG) time series and Rössler attractor, the prediction errors and prediction step sizes of the two novel models are superior to many pre-existing ESN models, which demonstrates the merit of the proposed models. Moreover, several parameters play key roles in network training, such as spectral radius , sparse degree etc., and their effects on network performance are analyzed. Notably, it is also investigated that the trained network can replicate Rössler chaotic attractor well. At the end of the results, the parameters of the proposed models are optimized, and the relatively optimized parameters are obtained after a large number of data experiments.},
  archive      = {J_NEUCOM},
  author       = {Yuting Li and Yong Li},
  doi          = {10.1016/j.neucom.2022.03.054},
  journal      = {Neurocomputing},
  pages        = {321-332},
  shortjournal = {Neurocomputing},
  title        = {Predicting chaotic time series and replicating chaotic attractors based on two novel echo state network models},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of deep nonnegative matrix factorization.
<em>NEUCOM</em>, <em>491</em>, 305–320. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Nonnegative Matrix Factorization (Deep NMF) is an effective strategy for feature extraction in recent years. By decomposing the matrix recurrently on account of the NMF algorithms, we obtain a hierarchical neural network structure as well as exploring more interpretable representations of the data. This paper mainly focuses on some theoretical researches with respect to Deep NMF, where the basic models, optimization methods, properties together with its extensions and generalizations are included systematically. We partition the Deep NMF algorithms into five categories: Deep NMF, Constrained Deep NMF, Generalized Deep NMF, Multi-View Deep Matrix Factorization (MF), the association between deep neural network (DNN) and NMF. Besides, we investigate the clustering performance of Deep NMF Algorithms on some face databases. Then the design principles, major steps, relationships, application domains and evolution of Deep NMF methods are comprehensively analyzed. Moreover, some open problems of Deep NMF are discussed.},
  archive      = {J_NEUCOM},
  author       = {Wen-Sheng Chen and Qianwen Zeng and Binbin Pan},
  doi          = {10.1016/j.neucom.2021.08.152},
  journal      = {Neurocomputing},
  pages        = {305-320},
  shortjournal = {Neurocomputing},
  title        = {A survey of deep nonnegative matrix factorization},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Elastic gradient boosting decision tree with adaptive
iterations for concept drift adaptation. <em>NEUCOM</em>, <em>491</em>,
288–304. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an excellent ensemble algorithm, Gradient Boosting Decision Tree (GBDT) has been tested extensively with static data. However, real-world applications often involve dynamic data streams, which suffer from concept drift problems where the data distribution changes overtime. The performance of GBDT model is degraded when applied to predict data streams with concept drift. Although incremental learning can help to alleviate such degrading, finding a perfect learning rate (i.e., the iteration in GBDT) that suits all time periods with all their different drift severity levels can be difficult. In this paper, we convert the issue of determining an optimal learning rate into the issue of choosing the best adaptive iterations when tuning GBDT. We theoretically prove that drift severity is closely related to the convergence rate of model. Accordingly, we propose a novel drift adaptation method, called adaptive iterations (AdIter), that automatically chooses the number of iterations for different drift severities to improve the prediction accuracy for data streams under concept drift. In a series of comprehensive tests with seven state-of-the-art drift adaptation methods on both synthetic and real-world data, AdIter yielded superior accuracy levels.},
  archive      = {J_NEUCOM},
  author       = {Kun Wang and Jie Lu and Anjin Liu and Yiliao Song and Li Xiong and Guangquan Zhang},
  doi          = {10.1016/j.neucom.2022.03.038},
  journal      = {Neurocomputing},
  pages        = {288-304},
  shortjournal = {Neurocomputing},
  title        = {Elastic gradient boosting decision tree with adaptive iterations for concept drift adaptation},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive event-triggered control of markovian jump complex
dynamic networks with actuator faults. <em>NEUCOM</em>, <em>491</em>,
273–287. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adaptive event-triggered control of Markovian jump complex dynamic networks (MJCDN) with actuator faults is studied in this paper. A new adaptive fault-tolerant control method is introduced to prove that the synchronization error is asymptotically convergent. Compared with traditional event-triggered strategies, a more general adaptive event-triggered control scheme for MJCDN is proposed to reduce network traffic load more effectively. This paper not only considers the synchronization of MJCDN with actuator faults and time-varying delay but also studies the H ∞ H∞ disturbance attenuation performance of MJCDN with random disturbance and actuator faults under adaptive event-triggered controller with appropriate adaptive laws. The Zeno behavior is ruled out effectively in these two different situations. In the end, two simulation examples are provided to illustrate the validity and rationality of the proposed methods about the adaptive event-triggered control of MJCDN with actuator faults.},
  archive      = {J_NEUCOM},
  author       = {Meng Hou and Deyou Liu and Yuechao Ma},
  doi          = {10.1016/j.neucom.2022.03.067},
  journal      = {Neurocomputing},
  pages        = {273-287},
  shortjournal = {Neurocomputing},
  title        = {Adaptive event-triggered control of markovian jump complex dynamic networks with actuator faults},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient time series anomaly detection by multiresolution
self-supervised discriminative network. <em>NEUCOM</em>, <em>491</em>,
261–272. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection aims to identify abnormal subsequences in time series that are markedly different from the temporal behaviors of the entire sequence. Although previous density-based or proximity-based anomaly detection methods are usually used for anomaly detection, they are still suffering from high computational costs due to the need of traversing the whole training dataset during testing. Recently, reconstruction-based deep learning methods are popular for time series anomaly detection. However, they may not work well because their objective is to recover all information appeared in time series, including high-frequency noises. In this paper, we propose a simple yet efficient method called M ultiresolution S elf- S upervised D iscriminative Net work (MS 2 D-Net) for efficient time series anomaly detection. Specifically, the MS 2 D-Net includes a multiresolution downsampling module, a feature extraction module, and a self-supervised discrimination module. The multiresolution downsampling module generates some multiresolution samples by downsampling the original time series with different sampling rates and creates different pseudo-labels representing multi-scale behaviors in time series. Then, in the feature extraction module, a shallow convolution network is used to extract temporal dynamics in time series at multiple resolutions. Finally, the self-supervised discrimination module uses the pseudo-labels obtained from the multiresolution downsampling module as the self-supervised information to help separate anomalies from the normal time series samples. Experimental results show that the proposed MS 2 D-Net can outperform recent strong deep learning baselines on 18 benchmarks for time series anomaly detection with a much lower computational cost.},
  archive      = {J_NEUCOM},
  author       = {Desen Huang and Lifeng Shen and Zhongzhong Yu and Zhenjing Zheng and Min Huang and Qianli Ma},
  doi          = {10.1016/j.neucom.2022.03.048},
  journal      = {Neurocomputing},
  pages        = {261-272},
  shortjournal = {Neurocomputing},
  title        = {Efficient time series anomaly detection by multiresolution self-supervised discriminative network},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distance regularization energy terms in level set image
segment model: A survey. <em>NEUCOM</em>, <em>491</em>, 244–260. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The level set is a classical image segmentation model. In order to achieve its stable evolution, the level set function should be a signed distance function (SDF). However, due to the common appearance of irregularities, it must periodically be initialized in order to remain a SDF near the zero level set. Distance regularization terms have been used to maintain the stable evolution of the level set function . We provide a survey of the various distance regularization potential functions. Firstly, we summarize many kinds of distance regularization potential functions studied in the literature. We then divide them into five classes according to the type of potential function. Secondly, we analyze the properties of every class of potential functions and their diffusion rate functions. Finally, to demonstrate the effectiveness of the distance regularization potential functions, we apply them with a region based level set energy functional for image segmentation . Experimental analyses are conducted to compare the segmentation performance of various distance regularization potential functions when combined with the classical Chan Vese model.},
  archive      = {J_NEUCOM},
  author       = {Le Zou and Thomas Weise and Qian-Jing Huan and Zhi-Ze Wu and Liang-Tu Song and Xiao-Feng Wang},
  doi          = {10.1016/j.neucom.2021.09.080},
  journal      = {Neurocomputing},
  pages        = {244-260},
  shortjournal = {Neurocomputing},
  title        = {Distance regularization energy terms in level set image segment model: A survey},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Brain MR images segmentation using 3D CNN with features
recalibration mechanism for segmented CT generation. <em>NEUCOM</em>,
<em>491</em>, 232–243. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of MR (magnetic resonance) images is a simple approach to create Pseudo CT images which are useful for many medical imaging analysis applications. One of the main challenges of this process is the bone segmentation of brain MR images. Deep convolutional neural networks (CNNs) have been widely and efficiently applied to perform MR images segmentation . The aim of this work is to propose a novel excitation-based CNN by recalibrating the network features adaptively to enhance the bone segmentation by segmenting the brain MR images into three tissue classes: bone, soft tissue, and air. The proposed method combines two types of features excitation mechanisms namely: (1) spatial squeeze and channel excitation block (cSE) and (2) channel squeeze and spatial excitation block (sSE). The two blocks are combined sequentially and integrated seamlessly into a 3D convolutional encoder decoder network. The novelty of this work emerges in the combination of the two excitation blocks sequentially to improve the segmentation performance and reduce the model complexity. The proposed approach is evaluated through a comparison with computed tomography (CT) images as ground truth and validated with other methods in the literature that applied deep CNN approaches to perform MR image segmentation for PET attenuation correction. Brain MR and CT datasets which consist of 50 patients are used to evaluate the proposed method. The segmentation performance of the three brain classes is evaluated using precision, recall, dice similarity coefficient (DSC), and Jaccard index. The presented method improves the bone tissue segmentation compared to the baseline model and other methods in the literature where the DSC is improved from 0.6278 ± ± 0.0006 to 0.6437 ± ± 0.0006 with an improvement percentage of 2.53\% for bone class. The proposed excitation-based segmentation network architecture demonstrates promising and competitive results compared with other methods in the literature and reduces the model complexity thanks to the sequential combination of the two excitation blocks.},
  archive      = {J_NEUCOM},
  author       = {Imene Mecheter and Maysam Abbod and Habib Zaidi and Abbes Amira},
  doi          = {10.1016/j.neucom.2022.03.039},
  journal      = {Neurocomputing},
  pages        = {232-243},
  shortjournal = {Neurocomputing},
  title        = {Brain MR images segmentation using 3D CNN with features recalibration mechanism for segmented CT generation},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual-semantic graph neural network with pose-position
attentive learning for group activity recognition. <em>NEUCOM</em>,
<em>491</em>, 217–231. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video-based group activities typically contain interactive contexts among diverse visual modalities between multiple persons, and semantic relationships between individual actions. Nevertheless, majority of the existing methods for recognizing group activity either captures the relationships among different persons by utilizing a solely RGB modality or neglect to exploit the label hierarchies between individual actions and the group activity. To tackle these issues, we propose a visual-semantic graph neural network, with pose-position attentive learning (VSGNN-PAL), for group activity recognition. Specifically, we first extract the individual-level appearance and motion representations from RGB and optical-flow inputs, to build a bi-modal visual graph. Two attentive aggregators are further proposed to integrate both the pose and position information to measure the relevance scores between persons, and dynamically refine the representation of each visual node from both modality-specific and cross-modal perspectives. To model a semantic hierarchy from a label space, we construct a semantic graph based on the linguistic embeddings of individual actions and group activity labels. We further employ a bi-directional mapping learning scheme, to integrate the label-relation-aware semantic context into the visual representations. Besides, a global reasoning module is introduced to progressively generate the group-level representations with the scene description maintained. Furthermore, we formulate a semantic-preserving loss, to maintain the consistency between the learned high-level representations and the semantics of the ground-truth labels. Experimental results on three group activity benchmarks demonstrate that the proposed method achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Tianshan Liu and Rui Zhao and Kin-Man Lam and Jun Kong},
  doi          = {10.1016/j.neucom.2022.03.066},
  journal      = {Neurocomputing},
  pages        = {217-231},
  shortjournal = {Neurocomputing},
  title        = {Visual-semantic graph neural network with pose-position attentive learning for group activity recognition},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CS-AF: A cost-sensitive multi-classifier active fusion
framework for skin lesion classification. <em>NEUCOM</em>, <em>491</em>,
206–216. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have achieved the state-of-the-art performance in skin lesion analysis. Compared with single CNN classifier, combining the results of multiple classifiers via fusion approaches shows to be more effective and robust. Since the skin lesion datasets are usually limited and statistically biased, while designing an effective fusion approach, it is important to consider not only the performance of each classifier on the training/validation dataset, but also the relative discriminative power (e.g., confidence) of each classifier regarding an individual sample in the testing phase, which calls for an active fusion approach. Furthermore, in skin lesion analysis, the data of certain classes (e.g., the benign lesions) is usually abundant which makes them an over-represented majority, while the data of some other classes (e.g., the cancerous lesions) is deficient which makes them an underrepresented minority. It is more crucial to precisely identify the samples from an underrepresented (i.e., in terms of the amount of data) but more important minority class (e.g., cancerous skin lesions). In other words, misclassifying a more severe skin lesion to a benign or less severe skin lesion should have relative more cost (e.g., money, time and even lives). To address such challenges, we present CS-AF, a cost-sensitive multi-classifier active fusion framework for skin lesion classification. In the experimental evaluation, we prepared 96 base classifiers (of 12 CNN architectures) on the ISIC Challenge 2019 research dataset. Our experimental results show that our framework consistently outperforms both the static and the active fusion competitors in terms of the accuracy and total costs.},
  archive      = {J_NEUCOM},
  author       = {Di Zhuang and Keyu Chen and J. Morris Chang},
  doi          = {10.1016/j.neucom.2022.03.042},
  journal      = {Neurocomputing},
  pages        = {206-216},
  shortjournal = {Neurocomputing},
  title        = {CS-AF: A cost-sensitive multi-classifier active fusion framework for skin lesion classification},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel ZNN model for fast synchronisation of chaos systems
with external disturbances. <em>NEUCOM</em>, <em>491</em>, 197–205. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {External disturbances are always inevitable in complex application scenarios, especially in synchronizing chaotic systems. This paper proposes a noise-restraint zeroing neural network (NRZNN) model to expedite the synchronisation of chaotic systems under external disturbances. Its associative controller is then evolved to suppress the interference of external noise. Theoretical analysis shows that the NRZNN model and its associated controller have inherent robustness. For comparison, the conventional zeroing neural network (CZNN) approach is utilized for the synchronisation of chaotic systems. Numerical comparison results validate the efficiency of the NRZNN model for synchronising chaotic systems under the constant noise disturbance. Moreover, through additional tests, it is found that the proposed NRZNN model can also suppress time-dependent noise during the synchronization of chaotic systems. Finally, the effect on the convergence performance is further investigated by adjusting the values of design parameters.},
  archive      = {J_NEUCOM},
  author       = {Lin Xiao and Ping Liu and Yongjun He and Lei Jia and Juan Tao},
  doi          = {10.1016/j.neucom.2022.03.053},
  journal      = {Neurocomputing},
  pages        = {197-205},
  shortjournal = {Neurocomputing},
  title        = {A novel ZNN model for fast synchronisation of chaos systems with external disturbances},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). SLAN: Similarity-aware aggregation network for embedding
out-of-knowledge-graph entities. <em>NEUCOM</em>, <em>491</em>, 186–196.
(<a href="https://doi.org/10.1016/j.neucom.2022.03.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding acts as a pivotal role in predicting the missing information in knowledge graphs (KGs). Due to the evolving nature of real-world KGs, one requires the ability to make predictions for newly emerging entities besides those already observed at training time. Current studies have made great efforts to develop a neighborhood aggregator and embed out-of-knowledge-graph (OOKG) entities inductively, with less focus on exploiting the similarity between the existing and newly emerging entities. Attaching importance to such similarity helps facilitate semantic transfer. In this work, we propose a similarity-aware aggregation network for embedding out-of-knowledge-graph entities. Motivated by the fact that similar entities are likely to occur in common graph context, we skillfully design a similarity-aware function, which measures the distance of each entity pair based on the contextual gap. Moreover, we aggregate the neighborhood surrounding the target entity and its similarity information by query-specific attention weights, which are optimized during the learning process. Extensive experiments on knowledge graph completion task show that our method achieves substantial improvements over baselines.},
  archive      = {J_NEUCOM},
  author       = {Mingda Li and Zhengya Sun and Wensheng Zhang},
  doi          = {10.1016/j.neucom.2022.03.063},
  journal      = {Neurocomputing},
  pages        = {186-196},
  shortjournal = {Neurocomputing},
  title        = {SLAN: Similarity-aware aggregation network for embedding out-of-knowledge-graph entities},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved DV-hop algorithm for wireless sensor networks
based on neural dynamics. <em>NEUCOM</em>, <em>491</em>, 172–185. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among the localization algorithms of wireless sensor networks (WSNs), the distance vector-hop (DV-Hop) algorithm has been widely concerned thanks to its simplicity, low hardware requirements, and easy implementation. However, the localization accuracy of the DV-Hop algorithm declines greatly when the sensor nodes are unevenly distributed. To improve the accuracy of the DV-Hop algorithm, we propose an improved DV-Hop algorithm based on neural dynamics (ND-DV-Hop). First, the fluctuant range of distance errors between the unknown nodes and the anchor nodes is computed via error analysis. Then, the traditional localization model is transformed into an algebraic equation in which the distances and coordinates change with time. Besides, a neural dynamics (ND) algorithm is used to solve the equation and obtain the solution with the residual errors eliminated. Theoretical analyses are provided to verify the convergence and anti-noise performance of the ND-DV-Hop algorithm. Finally, numerical simulations are carried out to confirm the superiority, efficiency, robustness, and accuracy of the proposed algorithm for dealing with WSNs localization problems .},
  archive      = {J_NEUCOM},
  author       = {Jingping Liu and Mei Liu and Xiujuan Du and Predrag S. Stanimirovi and Long Jin},
  doi          = {10.1016/j.neucom.2022.03.050},
  journal      = {Neurocomputing},
  pages        = {172-185},
  shortjournal = {Neurocomputing},
  title        = {An improved DV-hop algorithm for wireless sensor networks based on neural dynamics},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated design of CNN architecture based on efficient
evolutionary search. <em>NEUCOM</em>, <em>491</em>, 160–171. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary Neural Architecture Search (ENAS) is a promising method for the automated design of deep network architecture , which has attracted extensive attention in the field of automated machine learning . However, the existing ENAS methods often need a lot of computing resources to design CNN architecture automatically. In order to achieve efficient and automated design of CNNs, this paper focuses on two aspects to improve efficiency. On the one hand, efficient CNN-based building blocks are introduced to ensure the effectiveness of the generated architectures and a triplet attention mechanism is incorporated into the architectures to further improve the classification performance. On the other hand, a random forest-based performance predictor is used in the fitness evaluation to reduce the amount of computation required to train each individual from scratch. Experimental results show that the proposed algorithm can significantly reduce the computational resources required and achieve competitive classification performance on the CIFAR dataset. Also, the architecture designed for the traffic sign recognition task exceeds the accuracy of manual expert design.},
  archive      = {J_NEUCOM},
  author       = {Yirong Xie and Hong Chen and Yongjie Ma and Yang Xu},
  doi          = {10.1016/j.neucom.2022.03.046},
  journal      = {Neurocomputing},
  pages        = {160-171},
  shortjournal = {Neurocomputing},
  title        = {Automated design of CNN architecture based on efficient evolutionary search},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stable learning laws design for long short-term memory
identifier for uncertain discrete systems via control lyapunov
functions. <em>NEUCOM</em>, <em>491</em>, 144–159. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a method for designing stable learning laws of Long Short-Term Memory (LSTM) networks working as a non-parametric identifier of nonlinear systems with uncertain models. The strategy applies the concept of stability for discrete-time systems in the sense of Lyapunov to prove that origin is a practical stable equilibrium point for the identification error. The laws consider a general class of sigmoidal functions placed at the different gates of a LSTM structure (long and short memory). The design of the learning laws uses a matrix inequality framework to obtain the rate gains associated with the evolution of the weights. Numerical results show the designed learning laws for the non-parametric identifier based on a LSTM approximation tested on two classes of nonlinear systems: the first one describes the ozone-based degradation of organic contaminants, and the second one represents the dynamics of a Van Der Poll oscillator. The LSTM identifier is compared against a classical Lyapunov-based recurrent neural network . This comparison demonstrates how the proposed algorithm approximates the trajectories of both systems with a smaller mean squared error, which serves as an indicator of the benefits obtained with these new learning laws.},
  archive      = {J_NEUCOM},
  author       = {Alejandro Guarneros-Sandoval and Mariana Ballesteros and Ivan Salgado and Isaac Chairez},
  doi          = {10.1016/j.neucom.2022.03.070},
  journal      = {Neurocomputing},
  pages        = {144-159},
  shortjournal = {Neurocomputing},
  title        = {Stable learning laws design for long short-term memory identifier for uncertain discrete systems via control lyapunov functions},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning feature-rich integrated comprehensive context
networks for automated fundus retinal vessel analysis. <em>NEUCOM</em>,
<em>491</em>, 132–143. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the computer-aided diagnosis of ophthalmic diseases, the automatic segmentation of retinal vessels is the most basic and critical step. The semantic segmentation networks proposed in recent years have been improving in performance, but suffer from the drawbacks of oversized models and excessive number of parameters. In this work, we focus on designing a lightweight and efficient comprehensive contextual network (CC-Net) to segment retinal vessels more accurately. The CC-Net is a U-shaped encoder-decoder structure that integrates the multi-scale pooling module and the channel fusion module. The multi-scale pooling module is specifically designed to compensate for the loss of spatial information caused by continuous pooling operations. The channel fusion module was constructed in order to allow adaptive recalibration of channel feature responses to highlight the most discriminative feature channels. To objectively validate the proposed method, we performed extensive qualitative and quantitative analyses based on three publicly available fundus datasets, CHASE_DB1, STARE, and DRIVE. The contrast-limited adaptive histogram equalization (CLAHE) method was used to enhance the contrast of the original images in the experiments without using any data augmentation strategy. The results show that the proposed CC-Net has excellent segmentation performance with a model parameter count of only 0.26 M. In addition, we use cross-training to evaluate the robustness of the method and demonstrate its strong generalization ability in the cell membrane segmentation task .},
  archive      = {J_NEUCOM},
  author       = {Dongxu Yang and Hongdong Zhao and Tiecheng Han},
  doi          = {10.1016/j.neucom.2022.03.061},
  journal      = {Neurocomputing},
  pages        = {132-143},
  shortjournal = {Neurocomputing},
  title        = {Learning feature-rich integrated comprehensive context networks for automated fundus retinal vessel analysis},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning in indoor visible light positioning
systems: A review. <em>NEUCOM</em>, <em>491</em>, 117–131. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing a wireless indoor positioning system with high accuracy, reliability, and reasonable cost has been the focus of many researchers. Recent studies have shown that visible-light-based positioning (VLP) systems have better positioning accuracy than radio-frequency-based systems. A notable highlight of those research articles is their combination of VLP and machine learning (ML) to improve the positioning performance in both two-dimensional and three-dimensional spaces. In this paper, in addition to describing VLP systems and well-known positioning algorithms , we analyze, evaluate, and summarize the ML techniques that have been applied recently. We break these into four categories: supervised learning, unsupervised learning , reinforcement, and deep learning . We also provide deep discussion of articles published during the past five years in terms of their proposed algorithm, space (2D/3D), experimental method (simulation/experiment), positioning accuracy, type of collected data, type of optical receiver , and number of transmitters.},
  archive      = {J_NEUCOM},
  author       = {Huy Q. Tran and Cheolkeun Ha},
  doi          = {10.1016/j.neucom.2021.10.123},
  journal      = {Neurocomputing},
  pages        = {117-131},
  shortjournal = {Neurocomputing},
  title        = {Machine learning in indoor visible light positioning systems: A review},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Indirect adaptive control of multi-input-multi-output
nonlinear singularly perturbed systems with model uncertainties.
<em>NEUCOM</em>, <em>491</em>, 104–116. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, two indirect adaptive control schemes for a class of multi-input-multi-output nonlinear singularly perturbed systems with partially unknown models and parameters are presented. Firstly, the original system dynamic equation is reformulated into a new form with identity control gain matrices, and a new multi-time-scale singularity-free neural network is employed to represent the new dynamic equation. Subsequently, an online identification scheme is proposed to update neural network weights where a set of auxiliary weight error vectors are used such that better convergence property can be achieved. Based on identification results, a singularity-free singular perturbation controller is developed to control the unknown nonlinear system . By using the singularity-free neural network and singular perturbation technique, the complexity in controller design for a singularly perturbed system is reduced, and the potential singularity problem is avoided. Moreover, a singularity-free dynamic surface control scheme is also proposed, and the “explosion of complexity” issue is relieved. Compared to conventional direct adaptive dynamic surface control schemes which use gradient-like updating laws and tracking errors to train the neural networks, the singularity-free dynamic surface controller is designed indirectly and the neural networks are updated using the identification errors. Therefore, better identification and control performance is achieved, and the potential singularity problem is also circumvented. The stability of the closed-loop system is rigorously proved via the Lyapunov approach, and the effectiveness of proposed identification and control schemes is demonstrated by simulations.},
  archive      = {J_NEUCOM},
  author       = {Dong-Dong Zheng and Kai Guo and Yongping Pan and Haoyong Yu},
  doi          = {10.1016/j.neucom.2022.03.044},
  journal      = {Neurocomputing},
  pages        = {104-116},
  shortjournal = {Neurocomputing},
  title        = {Indirect adaptive control of multi-input-multi-output nonlinear singularly perturbed systems with model uncertainties},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive one-pass passive-aggressive radial basis function
for classification problems. <em>NEUCOM</em>, <em>491</em>, 91–103. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel adaptive one-pass Passive-Aggressive Radial Basis Function (APARBF) for classification problems. The APARBF uses elliptic Gaussian neurons followed by a Softmax layer and cross-entropy loss function. This network tries to overcome the elasticity-plasticity dilemma by using the Passive-Aggressive (PA) algorithm and adapting the hidden layer structure. The weight updates have to be plastic to acquire the most information from each sample and at the same time need to be elastic to retrain the information from the past instances. Inspired by PA, a novel update formula for cross-entropy loss minimization has been derived. The adaptive design of the network lets it start with zero hidden neurons and grow or shrink according to the data. For kernel parameters , the adaptive structure determines the correct number of hidden neurons and updates recursively each neuron’s center and covariance matrix . To evaluate our network, we perform two series of experiments. The first experiments compare the proposed APARBF with other recently developed one-pass algorithms (i.e., OVIG, OBHT, SCW, AROW , OGD , and PA). The subsequent experiments include comparing the proposed algorithm with some online adaptive structures such as FGAP-RBF, C-Mantec, McNN , and PBL-McNN, based on their mean classification error and the number of hidden neurons. Wilcoxon sign rank test and Friedman test clearly show the superiority of the proposed network’s results compared with its competitors in one-pass classification problems.},
  archive      = {J_NEUCOM},
  author       = {Maedeh Kafiyan-Safari and Modjtaba Rouhani},
  doi          = {10.1016/j.neucom.2022.03.047},
  journal      = {Neurocomputing},
  pages        = {91-103},
  shortjournal = {Neurocomputing},
  title        = {Adaptive one-pass passive-aggressive radial basis function for classification problems},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MEANet: Multi-modal edge-aware network for light field
salient object detection. <em>NEUCOM</em>, <em>491</em>, 78–90. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abundant light field cues have been demonstrated helpful to boost performance of salient object detection (SOD) in challenging scenarios. However, the majority of existing deep light field SOD models focus on exploring spatial interrelations across focal slices and seldom consider boundary accuracy of salient objects, which inevitability limits the detection performance. Meanwhile, in addition to focal stacks, several other data forms/modalities can be derived simultaneously from the light field. Therefore existing UNet-like strategies widely adopted for a single modality may not be very suitable for this task. To address these issues, we propose a novel multi-modal edge-aware network for light field SOD, named MEANet. MEANet has two innovative components elaborately designed for this task, i . e ., the cross-modal compensation (CMC) module and the multi-modal edge supervision (MES) module. CMC utilizes the attention mechanism to explore cross-modal complementarities and overcome the information loss of focal stack cues, whereas MES generates explicit object edges and edge features in order to progressively refine regional features to achieve edge-aware detection. Comprehensive evaluations on four benchmark datasets show that MEANet outperforms state-of-the-art light field and RGB-D/RGB SOD models, generating saliency maps with fine-grained accurate object boundaries effectively from multiple data inputs. The code and models are publicly available at https://github.com/jiangyao-scu/MEANet .},
  archive      = {J_NEUCOM},
  author       = {Yao Jiang and Wenbo Zhang and Keren Fu and Qijun Zhao},
  doi          = {10.1016/j.neucom.2022.03.056},
  journal      = {Neurocomputing},
  pages        = {78-90},
  shortjournal = {Neurocomputing},
  title        = {MEANet: Multi-modal edge-aware network for light field salient object detection},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Autoencoder-driven spiral representation learning for
gravitational wave surrogate modelling. <em>NEUCOM</em>, <em>491</em>,
67–77. (<a href="https://doi.org/10.1016/j.neucom.2022.03.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, artificial neural networks have been gaining momentum in the field of gravitational wave astronomy, for example in surrogate modelling of computationally expensive waveform models for binary black hole inspiral and merger. Surrogate modelling yields fast and accurate approximations of gravitational waves and neural networks have been used in the final step of interpolating the coefficients of the surrogate model for arbitrary waveforms outside the training sample. We investigate the existence of underlying structures in the empirical interpolation coefficients using autoencoders . We demonstrate that when the coefficient space is compressed to only two dimensions, a spiral structure appears, wherein the spiral angle is linearly related to the mass ratio. Based on this finding, we design a spiral module with learnable parameters, that is used as the first layer in a neural network, which learns to map the input space to the coefficients. The spiral module is evaluated on multiple neural network architectures and consistently achieves better speed-accuracy trade-off than baseline models . A thorough experimental study is conducted and the final result is a surrogate model which can evaluate millions of input parameters in a single forward pass in under 1 ms on a desktop GPU, while the mismatch between the corresponding generated waveforms and the ground-truth waveforms is better than the compared baseline methods . We anticipate the existence of analogous underlying structures and corresponding computational gains also in the case of spinning black hole binaries.},
  archive      = {J_NEUCOM},
  author       = {Paraskevi Nousi and Styliani-Christina Fragkouli and Nikolaos Passalis and Panagiotis Iosif and Theocharis Apostolatos and George Pappas and Nikolaos Stergioulas and Anastasios Tefas},
  doi          = {10.1016/j.neucom.2022.03.052},
  journal      = {Neurocomputing},
  pages        = {67-77},
  shortjournal = {Neurocomputing},
  title        = {Autoencoder-driven spiral representation learning for gravitational wave surrogate modelling},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Meta hyperbolic networks for zero-shot learning.
<em>NEUCOM</em>, <em>491</em>, 57–66. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-Shot Learning (ZSL) aims at generalizing the classification experience from seen classes to unseen classes with auxiliary side information, among which word vectors of class names and class attributes are popular ones. While word vectors technique is more practical for large datasets, its performance is usually slightly worse than that of attributes since it requires no human annotations. In this paper, we focus on the utilization of word vectors in ZSL by exploiting their hierarchical knowledge for large dataset and propose Meta Hyperbolic Networks (MHN). Specifically, we present Poincaré Graph Convolutional Networks (P-GCN), which transforms the word vectors into a Poincaré ball, and then encodes them with Poincaré Graph Convolutional layers . During training, the image classifiers from Convolutional Neural Networks (CNN) and P-GCN weights are aligned to ensure an accurate mapping between them. Moreover, we further develop a short-term memory episode learning on it to relieve the model’s inherent bias towards seen classes. Extensive experiments on the popular ImageNet dataset show the competitive performance for both ZSL and generalized ZSL.},
  archive      = {J_NEUCOM},
  author       = {Yan Xu and Lifu Mu and Zhong Ji and Xiyao Liu and Jungong Han},
  doi          = {10.1016/j.neucom.2022.03.040},
  journal      = {Neurocomputing},
  pages        = {57-66},
  shortjournal = {Neurocomputing},
  title        = {Meta hyperbolic networks for zero-shot learning},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structural target-aware model for thermal infrared tracking.
<em>NEUCOM</em>, <em>491</em>, 44–56. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal InfraRed (TIR) target trackers are easy to be interfered by similar objects, while susceptible to the influence of the target occlusion. To solve these problems, we propose a structural target-aware model (STAMT) for the thermal infrared target tracking tasks. Specifically, the proposed STAMT tracker can learn a target-aware model, which can add more attention to the target area to accurately identify the target from similar objects. In addition, considering the situation that the target is partially occluded in the tracking process, a structural weight model is proposed to locate the target through the unoccluded reliable target part. Ablation studies show the effectiveness of each component in the proposed tracker. Without bells and whistles, the experimental results demonstrate that our STAMT tracker performs favorably against state-of-the-art trackers on PTB-TIR and LSOTB-TIR datasets.},
  archive      = {J_NEUCOM},
  author       = {Di Yuan and Xiu Shu and Qiao Liu and Zhenyu He},
  doi          = {10.1016/j.neucom.2022.03.055},
  journal      = {Neurocomputing},
  pages        = {44-56},
  shortjournal = {Neurocomputing},
  title        = {Structural target-aware model for thermal infrared tracking},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving projected fuzzy k-means clustering via robust
learning. <em>NEUCOM</em>, <em>491</em>, 34–43. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy K-Means clustering has been an attractive research area for many multimedia tasks. Due to the interference of the noise and outliers, the performance of fuzzy K-Means clustering has been limited. In this paper, a projected fuzzy K-Means clustering method, referred to as Robust Projected Fuzzy K-Means (RPFKM) is proposed as a response to such a challenge. RPFKM improves fuzzy K-Means clustering in three perspectives. First, unlike existing fuzzy K-Means algorithms where the clustering process is conducted in the original space, RPFKM learns the fuzzy membership relationship between samples and prototypes in the low-dimensional space to eliminate the influence of the noise and irrelevant features. Second, it employs the ℓ 21 ℓ21 norm to reduce the contribution of outliers to the learning of prototypes. Third, it also considers the sensitivity of fuzzy clustering to the number of reduced dimensions, and the reconstruction term is introduced to hold the main energy of the original data. Furthermore, an iterative re-weighted algorithm is developed to solve the proposed method. The evaluation results of our proposed method and the state-of-the-art methods on real-world and synthetic data sets show the effectiveness and efficiency of our approach.},
  archive      = {J_NEUCOM},
  author       = {Xiaowei Zhao and Feiping Nie and Rong Wang and Xuelong Li},
  doi          = {10.1016/j.neucom.2022.03.043},
  journal      = {Neurocomputing},
  pages        = {34-43},
  shortjournal = {Neurocomputing},
  title        = {Improving projected fuzzy K-means clustering via robust learning},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finite-time stabilization of memristive neural networks via
two-phase method. <em>NEUCOM</em>, <em>491</em>, 24–33. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The finite-time stability and stabilization issues of memristive neural networks with time delays are studied via two-phase method, based on impulsive control and state feedback control. Different from classical control design, the control scheme here consists of two phases, i. e. the state can reach the inner of the unit ball exponentially from any initial condition in the first phase, and the then it can arrive at zero equilibrium from the inner of the unit ball in a finite-time. By using different Lyapunov function in two phases, both the finite-time stability criteria based on algebra inequality and the settling time dependent on the initial condition are obtained simultaneously. Compare with the finite-time control strategy in the literature, the finite-time stability and finite-time controller for stabilization of memristive neural networks are used in the second phase only, rather than the whole control process. In addition, the pinning control based on our novel control scheme is designed to obtain the finite-time stabilization of memristive neural networks.},
  archive      = {J_NEUCOM},
  author       = {Tianhu Yu and Huamin Wang and Jinde Cao and Changfeng Xue},
  doi          = {10.1016/j.neucom.2022.03.059},
  journal      = {Neurocomputing},
  pages        = {24-33},
  shortjournal = {Neurocomputing},
  title        = {Finite-time stabilization of memristive neural networks via two-phase method},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-scale semantic attention representation for
multi-label image recognition with graph networks. <em>NEUCOM</em>,
<em>491</em>, 14–23. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label image recognition is a basic and challenging task in computer vision and multimedia fields. Graph Convolutional Networks (GCNs) are often used to learn the multi-label semantic features and multi-label dependency. Although the label semantic features in GCNs can learn the global image visual representation well, they are rarely used on the local image regions. Therefore, we try to use GCNs to learn global and local features at the same time, and make a balance between them. In this paper, we give a multi-scale semantic attention model MS-SGA-GCN including three main modules (i.e., MS, SGA and GCN) for multi-label image recognition. The Multi-Scale module (MS) utilizes feature maps of different sizes to obtain global features and have strong generalization capabilities. Semantic Guide Attention module (SGA) applies the label embeddings learned by GCNs to guide the generation of the cross-modality class-specific attention maps, which can discover the locations of semantically related regions for each label. Experiments show that our model on two datasets MS-COCO and PASCAL VOC2007 separately achieves the classification accuracy by 83.4\% 83.4\% and 94.2\% 94.2\% , which has a competitive advantage over other mainstream models.},
  archive      = {J_NEUCOM},
  author       = {Jun Liang and Feiteng Xu and Songsen Yu},
  doi          = {10.1016/j.neucom.2022.03.057},
  journal      = {Neurocomputing},
  pages        = {14-23},
  shortjournal = {Neurocomputing},
  title        = {A multi-scale semantic attention representation for multi-label image recognition with graph networks},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). DPG-net: Densely progressive-growing network for point
cloud completion. <em>NEUCOM</em>, <em>491</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a Densely Progressive-growing Network (DPG-Net) for 3D point cloud completion based on the Generative Adversarial Network (GAN). It aims to learn useful features from incomplete 3D objects to infer the complete geometric shape. Most methods usually acquire global features directly from the incomplete point cloud. However, the global feature often loses local information from the input point cloud. To solve this problem, we design a novel network named DPG-Net for point cloud completion by proposing a multi-resolution dense contextual feature mechanism, a progressive growth process, and combining the adversarial process. Firstly, we study a Multi-resolution Densely Contextual Encoder to infer the potential features with local information of the partial point cloud. The encoder can obtain the global information of the point cloud while fusing the local structure details. Secondly, we propose a Progressive Growth Decoder, which can make full use of global information, to gradually refine local areas and generate a complete shape. In addition, the discriminator is used to control the network for a realistic point cloud. Our model composed of the above modules can extract the features from incomplete point clouds, and then generate detailed complete point clouds. The performance (chamfer distance) of the proposed method is better than other methods on different datasets. The experiment proves the effectiveness of our method on point cloud completion.},
  archive      = {J_NEUCOM},
  author       = {Jun Li and Shangwei Guo and Xiantong Meng and ZhengChao Lai and Shaokun Han},
  doi          = {10.1016/j.neucom.2022.03.060},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {DPG-net: Densely progressive-growing network for point cloud completion},
  volume       = {491},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human-related anomalous event detection via spatial-temporal
graph convolutional autoencoder with embedded long short-term memory
network. <em>NEUCOM</em>, <em>490</em>, 482–494. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic detection of human-related anomalous events in surveillance videos is challenging, owing to unclear definition of anomalies and insufficiency of training data. Generally, the irregular human motion patterns can be regarded as human-related abnormal events. Therefore, we propose a novel method to operate directly on sequences of human skeleton graphs for discovering the normal patterns of human motion . The sequence of skeleton graphs is decomposed into two sub-components: global movement and local posture sequences. The global component is utilized to compute local component. The local component sequences are then input to our network for capturing normal spatial-temporal motion patterns of human skeleton. Our network is established on a Spatial-temporal Graph Convolutional Autoencoder (ST-GCAE) and embedded with Long Short-Term Memory (LSTM) network in hidden layers for exploring the temporal cues, which is thus called Spatial-temporal Graph Convolutional Autoencoder with Embedded Long Short-Term Memory Network (STGCAE-LSTM). Different from traditional autoencoder, STGCAE-LSTM owns a single-encoder-dual-decoder architecture, which is capable of reconstructing the input and predicting the unseen future simultaneously. Then, samples that deviate from normal patterns are detected as anomalies with fusion of reconstruction and prediction errors. Experimental results on four challenging datasets demonstrate advantages of our method over other state-of-the-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Nanjun Li and Faliang Chang and Chunsheng Liu},
  doi          = {10.1016/j.neucom.2021.12.023},
  journal      = {Neurocomputing},
  pages        = {482-494},
  shortjournal = {Neurocomputing},
  title        = {Human-related anomalous event detection via spatial-temporal graph convolutional autoencoder with embedded long short-term memory network},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tackling cyber-aggression: Identification and fine-grained
categorization of aggressive texts on social media using weighted
ensemble of transformers. <em>NEUCOM</em>, <em>490</em>, 462–481. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pervasiveness of aggressive content in social media has become a serious concern for government organizations and tech companies because of its pernicious societal effects. In recent years, social media has been repeatedly used as a tool to incite communal aggression, spread distorted propaganda, damage social harmony and demean the identity of individuals or a community in the public spaces. Therefore, restraining the proliferation of aggressive content and detecting them has become an urgent duty. Studies of the identification of aggressive content have mostly been done for English and other high-resource languages. Automatic systems developed for those languages can not accurately identify detrimental contents written in regional languages like Bengali. To compensate this insufficiency, this work presents a novel Bengali aggressive text dataset (called ‘BAD’) with two-level annotation. In level-A, 14158 texts are labeled as either aggressive or non-aggressive. While in level-B, 6807 aggressive texts are categorized into religious, political, verbal and gendered aggression classes each having 2217, 2085, 2043 and 462 texts respectively. This paper proposes a weighted ensemble technique including m-BERT, distil-BERT, Bangla-BERT and XLM-R as the base classifiers to identify and classify the aggressive texts in Bengali. The proposed model can readdress the softmax probabilities of the participating classifiers depending on their primary outcomes. This weighting technique has enabled the model to outdo the simple average ensemble and all other machine learning (ML), deep learning (DL) baselines. It has acquired the highest weighted f 1 f1 -score of 93.43\% in the identification task and 93.11\% in the categorization task. Dataset developed as the part of this work is available at https://github.com/BAD-Bangla-Aggressive-Text-Dataset},
  archive      = {J_NEUCOM},
  author       = {Omar Sharif and Mohammed Moshiul Hoque},
  doi          = {10.1016/j.neucom.2021.12.022},
  journal      = {Neurocomputing},
  pages        = {462-481},
  shortjournal = {Neurocomputing},
  title        = {Tackling cyber-aggression: Identification and fine-grained categorization of aggressive texts on social media using weighted ensemble of transformers},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3SHACC: Three stages hybrid agglomerative constrained
clustering. <em>NEUCOM</em>, <em>490</em>, 441–461. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally within the unsupervised learning paradigm, hierarchical and partitional clustering techniques have been shown to produce better results when provided with partial information, leading to a renewed attention towards this topic. Constrained clustering is a semi-supervised learning problem that combines classic clustering techniques with background knowledge given in the form of a set of constraints. In this paper, we propose to incorporate constraints into the clustering process in three phases: the first phase is devoted to quantify constraint relevance and to learn a metric matrix according to such relevance, a second phase computing similarities between instances by means of the reconstruction coefficient and pairwise distances, and a third stage performing agglomerative hierarchical clustering with a reward-style stepped affinity function favoring merges satisfying the higher possible number of constraints. Experimental results, supported by Bayesian statistical testing, show a consistent improvement in favor of our proposal over previous approaches to the constrained clustering problem.},
  archive      = {J_NEUCOM},
  author       = {Germán González-Almagro and Juan Luis Suárez and Julián Luengo and José-Ramón Cano and Salvador García},
  doi          = {10.1016/j.neucom.2021.12.018},
  journal      = {Neurocomputing},
  pages        = {441-461},
  shortjournal = {Neurocomputing},
  title        = {3SHACC: Three stages hybrid agglomerative constrained clustering},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive neural network state constrained fault-tolerant
control for a class of pure-feedback systems with actuator faults.
<em>NEUCOM</em>, <em>490</em>, 431–440. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive neural network (NN) constrained fault-tolerant control (FTC) method is proposed for a class of nonlinear pure feedback systems with actuator faults and state constraints. By designing a fault-tolerant compensation controller and a new asymmetric time-varying tangent Barrier Lyapunov function (ATVTBLF), the problem of time-varying asymmetric state constraints caused by actuator failure is solved. The actuator takes into account both loss of effectiveness and bias fault. Different from the existing asymmetric BLF, the new BLF solves the problem of asymmetry under tangent constraints and expands the application range of the asymmetric constraint. NN is used to approximate the unknown items generated in the process of designing fault-tolerant controllers. Based on the Lyapunov stability analysis, it is proved that all signals in the closed-loop system are semi-globally uniformly ultimately bounded (SGUUB), and all states do not violate the bounds. Finally, the simulation example verifies the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Lei Ma and Zhanshan Wang and Changlai Wang},
  doi          = {10.1016/j.neucom.2021.12.017},
  journal      = {Neurocomputing},
  pages        = {431-440},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural network state constrained fault-tolerant control for a class of pure-feedback systems with actuator faults},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generating adversarial examples via enhancing latent spatial
features of benign traffic and preserving malicious functions.
<em>NEUCOM</em>, <em>490</em>, 413–430. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Well-crafted adversarial examples can easily deceive neural network models into producing misclassified results while contributing to evaluating and improving the performance and robustness of the classification model . However, most adversarial examples generation methods still have the following drawbacks: (1) the original samples ignore the distribution regularity of benign samples and directly add noise, so the generated adversarial examples have significant differences in latent spatial distribution with benign samples, which makes them difficult to escape detection; (2) the discriminant features of the adversarial examples are directly modified, which causes their malicious patterns to change or malicious functions to be unattainable. In this paper, a novel malicious traffic adversarial examples generation method, NIDSFM, is proposed. Through NIDSFM, the feature space of the traffic samples is reconstructed to avoid interference with the malicious functions of the generated adversarial examples by isolating the discriminant features. By using the ability of the flow-based model to represent the latent space distribution, the distribution of adversarial examples is modeled around the benign samples, then fine-tuned based on generative adversarial networks (GAN) with additional latent spatial noise so that the distribution of generated adversarial examples is similar to benign samples. Extensive experiments were conducted on multiple datasets (NSL-KDD, UNSW-NB15, CIC-DDoS2019) and compared with various adversarial examples generation methods. The experimental results show that the proposed method leads to a significant reduction in the detection rate of multiple NIDSs and is competitive in escaping NIDS detection.},
  archive      = {J_NEUCOM},
  author       = {Rongqian Zhang and Senlin Luo and Limin Pan and Jingwei Hao and Ji Zhang},
  doi          = {10.1016/j.neucom.2021.12.015},
  journal      = {Neurocomputing},
  pages        = {413-430},
  shortjournal = {Neurocomputing},
  title        = {Generating adversarial examples via enhancing latent spatial features of benign traffic and preserving malicious functions},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards densely clustered tiny pest detection in the wild
environment. <em>NEUCOM</em>, <em>490</em>, 400–412. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our life is populated with many small-size objects, such as human in aerial images and tiny pests in agriculture. Current generic and small object detection methods are only focus on tackling their sizes rather than distribution. Considering this limitation, we state a Densely Clustered Tiny (DCT) object detection problem using a novel metric Object Density Level (ODL) to measure the object distribution in an image. The DCT problem allows varied densely distributed objects in the real-world captured images. In dealing with the DCT problem, we select two kinds of aphids that usually gather into cliques in the real-world agricultural environment, and build an aphid dataset APHID-4K in our task. Accompanying the DCT task, we propose a novel DCT detection network (DCTDet) to address this challenge. Specifically, a Cluster Region Proposal Network (ClusRPN) is trained to select appropriate densely distributed object cluster regions from images. These candidates are classified into different groups according to their density. A Density Merging and Partition module (DMP) merges and partitions them respectively and finally outputs cluster regions with uniform size and density to a subsequent Local Detector Group (LDG). In addition, we also use Composited Cluster data Generation (CCG) to present a large-scale dataset for ClusRPN optimization for robust training procedure and theoretically analyze their effects in detail. Experiments on APHID-4K and another clustered small object detection dataset VisDrone show that our DCTDet achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Jianming Du and Liu Liu and Rui Li and Lin Jiao and Chengjun Xie and Rujing Wang},
  doi          = {10.1016/j.neucom.2021.12.012},
  journal      = {Neurocomputing},
  pages        = {400-412},
  shortjournal = {Neurocomputing},
  title        = {Towards densely clustered tiny pest detection in the wild environment},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A distributed deep reinforcement learning method for traffic
light control. <em>NEUCOM</em>, <em>490</em>, 390–399. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a distributed deep reinforcement learning algorithm for the traffic light control problem, which consists of local learning and global consensus. Firstly, the reinforcement learning environment for the traffic light control problem is built by defining the three key elements of state, action, and reward. Then, the CNN-based deep Q-network is designed to process the quantized traffic state information to obtain the state-action values. After locally optimizing the deep Q-networks of multiple traffic light agents based on their experience samples, the consensus algorithm is subsequently applied to globally update these agents that are connected over a decentralized communication topology. In this way, the distributed learning agents learn from their neighbors’ experience to optimize the modeling process without actually sharing experience data samples. Lastly, homogeneous and heterogeneous traffic flow patterns on different intersections are simulated in SUMO to verify the superiority of the proposed distributed deep Q-networks, with the comparison to the fixed-time strategy, local learning and centralized learning algorithms. The simulation study demonstrates that the distributed learning algorithm without a central server shows comparable performance with centralized learning, which is much better than fixed-time strategy and the local learning method in both homogeneous and heterogeneous traffic scenarios.},
  archive      = {J_NEUCOM},
  author       = {Bo Liu and Zhengtao Ding},
  doi          = {10.1016/j.neucom.2021.11.106},
  journal      = {Neurocomputing},
  pages        = {390-399},
  shortjournal = {Neurocomputing},
  title        = {A distributed deep reinforcement learning method for traffic light control},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Realizing balanced object detection through prior location
scale information and repulsive loss. <em>NEUCOM</em>, <em>490</em>,
380–389. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is one significant field of computer vision. The imbalance problem exerts negative effects on achieving satisfactory performance. We reveal two sources of imbalance in existing object detection methods. Correspondingly, we propose our methods in terms of the model architecture and optimization target. Different from general object detection benchmarks, the location distribution of objects with different sizes is unbalanced in many practical applications. In addition, the representation information of different categories of objects is unbalanced. In this paper, we propose a location scale equilibrium module to utilize the prior location scale information and generate more balanced feature maps. More appropriate feature maps are selected and merged for different locations. After merging, feature maps become more consistent in terms of representation content, exerting positive effects on the following classification and regression tasks. For the imbalance caused by similar objects, we propose the repulsive loss to strengthen the punishment. Our method will not treat all categories of objects equally since we take the imbalance between them into consideration. With the enhanced supervision, the training will pay more attention to similar objects. Our proposed model is evaluated on the VisDrone benchmark and UAVDT benchmark. Sufficient experiments are conducted. Our model achieves the highest precision on most evaluation metrics , outperforming the other strong models.},
  archive      = {J_NEUCOM},
  author       = {Zelong Kong and Yongquan Chen and Xinping Guan and Xinyi Le},
  doi          = {10.1016/j.neucom.2021.11.105},
  journal      = {Neurocomputing},
  pages        = {380-389},
  shortjournal = {Neurocomputing},
  title        = {Realizing balanced object detection through prior location scale information and repulsive loss},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven event-triggered control for switched systems
based on neural network disturbance compensation. <em>NEUCOM</em>,
<em>490</em>, 370–379. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates data-driven event-triggered tracking control for switched systems with dual unreliable communication links. Consider modeling constraints with unknown dynamics, a data-driven model-free adaptive control (MFAC) method which relies on system input and output data is adopted. To reduce system resource consumption caused by continuous calculation of control execution, an event-triggering scheme is applied. A radial basis function (RBF) neural network is constructed to approximate the unknown disturbance. Accordingly, the disturbance estimation and triggered system data are respectively transmitted through dual network channels, which are vulnerable to malicious denial-of-service (DoS) attacks. Then, a data dependent anti-attack mechanism and an event-triggered MFAC with disturbance compensation are proposed, respectively. Moreover, in view of the stability analysis of the MFAC switched systems , by introducing Lyapunov functional and average dwell time technique, a set of novel sufficient conditions is derived for ensuring the boundedness of tracking error. Finally, simulation examples verify the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yiwen Qi and Xiujuan Zhao and Jie Huang},
  doi          = {10.1016/j.neucom.2021.11.103},
  journal      = {Neurocomputing},
  pages        = {370-379},
  shortjournal = {Neurocomputing},
  title        = {Data-driven event-triggered control for switched systems based on neural network disturbance compensation},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Unsupervised visual feature learning based on similarity
guidance. <em>NEUCOM</em>, <em>490</em>, 358–369. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of a large amount of image data and the impracticality of annotating each sample, coupled with various changes in the target class, such as lighting, posture, etc., make the performance of feature learning disappointing on unlabeled datasets. Lack of attention to hard sample pairs in network modeling and one-sided consideration of similarity measurement in the process of merging have exacerbated the huge performance gap between supervised and unsupervised feature expression. In order to alleviate these problems, we propose an unsupervised network that gradually optimizes feature expression under the guidance of similarity. It employs the deep network to train high-dimensional features and small-scale merge to generate high-quality labels to alternately execute the two steps. Feature learning is guided by gradually generating high-quality labels, thereby narrowing the huge gap between unsupervised learning and supervised learning. The proposed method has been evaluated on both general datasets and the datasets for person re-identification (person re-ID) with superior performance in comparison with existing state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xiaoqiang Chen and Zhihao Jin and Qicong Wang and Wenming Yang and Qingmin Liao and Hongying Meng},
  doi          = {10.1016/j.neucom.2021.11.102},
  journal      = {Neurocomputing},
  pages        = {358-369},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised visual feature learning based on similarity guidance},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HFNet: Hierarchical feedback network with multilevel atrous
spatial pyramid pooling for RGB-d saliency detection. <em>NEUCOM</em>,
<em>490</em>, 347–357. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiscale features have received considerable attention for improving saliency detection . However, existing methods only perform decoding at multiple scales without exploring feature refinement. We propose a hierarchical feedback network (HFNet) with multilevel atrous spatial pyramid pooling (MASPP) to refine multiscale features for RGB-D saliency detection . The improved MASPP for adaptive refinement is applied to hierarchical network modules to obtain multiscale information. Then, the detailed multiscale information is used for decoding based on a channel attention mechanism with joint information guidance, and the output is fed to the next stage through reverse attention. This iterative refinement reuses feature information and predicts more precise saliency maps with detailed information. Experimental results on seven benchmark datasets show the effectiveness of the proposed HFNet, and ablation studies confirm the effectiveness and superiority of applying its different strategies.},
  archive      = {J_NEUCOM},
  author       = {Wujie Zhou and Chang Liu and Jingsheng Lei and Lu Yu and Ting Luo},
  doi          = {10.1016/j.neucom.2021.11.100},
  journal      = {Neurocomputing},
  pages        = {347-357},
  shortjournal = {Neurocomputing},
  title        = {HFNet: Hierarchical feedback network with multilevel atrous spatial pyramid pooling for RGB-D saliency detection},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A spatiotemporal multi-feature extraction framework for
opinion mining. <em>NEUCOM</em>, <em>490</em>, 337–346. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Internet technology and the explosive growth of digital text, opinion mining has become one of the important research hotspots in the field of natural language processing (NLP). In recent years, neural network based deep learning algorithms have been applied in the field of opinion mining . Considering the relation between temporal and spatial dimensions of text data and the characteristics of natural language itself, traditional deep learning algorithms cannot be comprehensive in the processing of fully feature extraction. In this paper, we propose a new deep learning framework for opinion mining, which includes a temporal feature extraction layer that consists of two layers of bidirectional simple recurrent unit (Bi-SRU) networks extracting features at the word and grammar levels; a semantic feature extraction layer that mainly contains a multi-head attention module; a spatial feature extraction layer with dilated convolution that is used to extract opinion preference features. The Internet movie database (IMDb) is used to verify the performance of the proposed framework. The experiment results show that the proposed framework can effectively improve the classification accuracy , whose performance is better than that of the compared algorithms.},
  archive      = {J_NEUCOM},
  author       = {Tiankuo Li and Hongji Xu and Zhi Liu and Zheng Dong and Qiang Liu and Juan Li and Shidi Fan and Xiaojie Sun},
  doi          = {10.1016/j.neucom.2021.11.098},
  journal      = {Neurocomputing},
  pages        = {337-346},
  shortjournal = {Neurocomputing},
  title        = {A spatiotemporal multi-feature extraction framework for opinion mining},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A consecutive hybrid spiking-convolutional (CHSC) neural
controller for sequential decision making in robots. <em>NEUCOM</em>,
<em>490</em>, 319–336. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a Consecutive Hybrid Spiking-Convolutional (CHSC) neural controller is proposed by integrating Convolutional Neural Networks (CNNs) and Spiking Neural Networks (SNNs). The proposed controller is mainly developed around an image-based control strategy. For this purpose, the CNN processes the input images and detects objects. The Neuronal Data Transfer Interface (NDTI) algorithm receives information from CNN, calculates the position of the objects, and expands the SNN based on the input data. Finally, the SNN generates the proper motor commands according to the detected object. The applicability of the proposed controller in responding to the different situations was shown. The expansion of the network (i.e., creating new neurons and connections during training) is also examined. The CHSC made SNNs grow upon learning of interaction with new objects. The adaptability of the method is also evaluated. The results reveal that the SNN could adapt itself to changes in the environment without any supervisor. This characteristics allows the robot to forget the learned policies and learn new ones without changing the controller’s whole structure. Each learned policy has its address in the SNN. Unlike the second-generation networks (e.g., Perceptron), change in an feature of the object only alters the synaptic connections associated with that object, so a small change in the environment does not affect the entire network. The method is verified experimentally using a two degrees-of-freedom robotic arm.},
  archive      = {J_NEUCOM},
  author       = {Vahid Azimirad and Mohammad Tayefe Ramezanlou and Saleh Valizadeh Sotubadi and Farrokh Janabi-Sharifi},
  doi          = {10.1016/j.neucom.2021.11.097},
  journal      = {Neurocomputing},
  pages        = {319-336},
  shortjournal = {Neurocomputing},
  title        = {A consecutive hybrid spiking-convolutional (CHSC) neural controller for sequential decision making in robots},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Defining and detecting toxicity on social media: Context and
knowledge are key. <em>NEUCOM</em>, <em>490</em>, 312–318. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online platforms have become an increasingly prominent means of communication. Despite the obvious benefits to the expanded distribution of content, the last decade has resulted in disturbing toxic communication, such as cyberbullying and harassment. Nevertheless, detecting online toxicity is challenging due to its multi-dimensional, context sensitive nature. As exposure to online toxicity can have serious social consequences, reliable models and algorithms are required for detecting and analyzing such communication across the vast and growing space of social media. In this paper, we draw on psychological and social theory to define toxicity. Then, we provide an approach that identifies multiple dimensions of toxicity and incorporates explicit knowledge in a statistical learning algorithm to resolve ambiguity across such dimensions.},
  archive      = {J_NEUCOM},
  author       = {Amit Sheth and Valerie L. Shalin and Ugur Kursuncu},
  doi          = {10.1016/j.neucom.2021.11.095},
  journal      = {Neurocomputing},
  pages        = {312-318},
  shortjournal = {Neurocomputing},
  title        = {Defining and detecting toxicity on social media: Context and knowledge are key},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel end-to-end model for steering behavior prediction of
autonomous ego-vehicles using spatial and temporal attention mechanism.
<em>NEUCOM</em>, <em>490</em>, 295–311. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, autonomous vehicles have attracted many researchers from academia and industry. Their efforts include object detection and tracking in the fields of computer vision, probabilistic-fusion and decision-making algorithms, etc. But most current methods that directly map from image pixels to steering behavior are not able to generate accurate results, especially under scenarios such as light and weather change drastically; this is largely due to the fact that these methods ignore the temporal relationship between frames. In this paper, we propose a novel end-to-end deep learning framework based on temporal and spatial attention mechanism , which aims to solve the problem of inaccurate vehicle steering angle prediction in complex environments and the difficulty of model interpretation. First, we use video sequence and historical steering angle sequence as inputs to the model, instead of just using a single frame as input. Second, we design a temporal attention mechanism to capture the long- and short-term memory in input visual information, and a spatial attention mechanism to capture key objects in the image and obtain their position information. This is achieved by inserting carefully-designed SE-Net, ConvLSTM and CNN layers into the appropriate layers of the network framework. Finally, we demonstrate the feasibility of the proposed model with public Comma2k19 , with comparison to current advanced methods. Experimental results show that compared with state-of-the-art methods, the average absolute error ( MAE ) values of our model on the training set and testing set are reduced by 10.2\% and 6.3\%, respectively, and has more accurate steering prediction performance. In addition, we explain the trigger mechanism of steering behavior prediction by visualizing the spatial attention map and temporal attention score on Comma2k19 and Udacity datasets, which further demonstrates that the proposed model can learn human-like driving behavior.},
  archive      = {J_NEUCOM},
  author       = {Lei Han and Lei Wu and Fujian Liang and Hao Cao and Dabing Luo and Zutao Zhang and Zexi Hua},
  doi          = {10.1016/j.neucom.2021.11.093},
  journal      = {Neurocomputing},
  pages        = {295-311},
  shortjournal = {Neurocomputing},
  title        = {A novel end-to-end model for steering behavior prediction of autonomous ego-vehicles using spatial and temporal attention mechanism},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RACP: A network with attention corrected prototype for
few-shot speaker recognition using indefinite distance metric.
<em>NEUCOM</em>, <em>490</em>, 283–294. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot speaker recognition task is to identify speakers from limited support samples. We argue that query samples and support samples are both informative for classification. To help Prototypical Networks capture information from query samples, this paper proposes the relation-based indefinite distance metric attentive correction prototype network (RACP). Since the mean prototype deviates from the ideal prototype, we calculate attention scores for each query sample to customize the attention prototype. Then, to compensate for the missed query samples information, the prototype is further refined by correction data that is constructed by combining query samples with the global class attention score. Later, the indefinite distance metric of Relation Networks is introduced on Prototypical Networks, and the relation scores between the sample prototypes and the query samples are calculated for final prediction. Compare with existing methods, RACP can consider both query samples and support samples instead of ignoring the query ones. We compare RACP with strong baselines (e.g. GMM-SVM, MAML, Prototypical Networks, Res32, and VGG11). Ablation study and generalizability study of different scenarios are also conducted on different datasets. Results show that RACP achieves better performance and generalization ability.},
  archive      = {J_NEUCOM},
  author       = {Xingmei Wang and Jiaxiang Meng and Bin Wen and Fuzhao Xue},
  doi          = {10.1016/j.neucom.2021.11.092},
  journal      = {Neurocomputing},
  pages        = {283-294},
  shortjournal = {Neurocomputing},
  title        = {RACP: A network with attention corrected prototype for few-shot speaker recognition using indefinite distance metric},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Event-triggered adaptive neural control for uncertain
nonstrict-feedback nonlinear systems with full-state constraints and
unknown actuator failures. <em>NEUCOM</em>, <em>490</em>, 269–282. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates an adaptive asymptotic tracking controller for uncertain nonstrict-feedback nonlinear systems(NFNSs) with full-state constraints and unknown actuator failures. By constructing a class of new switched high-order barrier Lyapunov functions(BLFs) candidates to the backstepping design, the asymptotic tracking performance can be guaranteed, all states do not violate constraints. The neural networks(NNs) is used to handle the difficulties caused by the unknown nonlinearities, the event-triggered control law based on relative threshold method for reducing the communication load between the controller and actuator. The control scheme guarantees that all closed-loop signals of the system are bounded and the tracking error asymptotically approaches a pre-defined bound, no matter whether the actuators operate in normal or faulty modes and the number of actuator failures can be infinite. Finally, simulation results including numerical simulation and practical application simulation verify the feasibility of the control scheme.},
  archive      = {J_NEUCOM},
  author       = {Xinming Liao and Zhi Liu and C.L. Philip Chen and Yun Zhang and Zongze Wu},
  doi          = {10.1016/j.neucom.2021.11.090},
  journal      = {Neurocomputing},
  pages        = {269-282},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered adaptive neural control for uncertain nonstrict-feedback nonlinear systems with full-state constraints and unknown actuator failures},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SRAI-LSTM: A social relation attention-based
interaction-aware LSTM for human trajectory prediction. <em>NEUCOM</em>,
<em>490</em>, 258–268. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian trajectory prediction is one of the important research topics in the field of computer vision and a key technology of autonomous driving system. Walking in groups is a common social behavior in which pedestrians pay more attention to the movements of their companions while walking. Motivated by this idea, we propose a Social Relation Attention-based Interaction-aware LSTM (SRAI-LSTM) to model this social behavior for trajectory prediction. We design a social relation encoder module to capture social relation feature between pedestrians through their relative positions. Afterwards, the social relation features are adopted to acquire social relation attentions among pedestrians. Social interaction modeling is achieved by utilizing social relation attentions to aggregate motion features from neighbor pedestrians. Experimental results on two public pedestrian trajectory datasets (ETH and UCY) demonstrate that our proposed model achieves superior performances compared with state-of-the-art methods on ADE and FDE metrics.},
  archive      = {J_NEUCOM},
  author       = {Yusheng Peng and Gaofeng Zhang and Jun Shi and Benzhu Xu and Liping Zheng},
  doi          = {10.1016/j.neucom.2021.11.089},
  journal      = {Neurocomputing},
  pages        = {258-268},
  shortjournal = {Neurocomputing},
  title        = {SRAI-LSTM: A social relation attention-based interaction-aware LSTM for human trajectory prediction},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Attentive encoder-decoder networks for crowd counting.
<em>NEUCOM</em>, <em>490</em>, 246–257. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting that aims to estimate the crowd density has recently made significant progress but remains an unsolved problem due to several challenges. In this paper, we propose an Attentive Encoder-Decoder Network (AEDNet) to overcome the notorious scale-variation problem in crowd counting. Our major contributions can be summarized in three aspects. First, we design an Attentive Feature Refinement (AFR) block in the encoder to adaptively extract multi-scale features. AFR compares the spatial information in different scales through the attention mechanism and then adaptively assign importance weights to each point, which highlights the distinctive roles in multi-scale feature extraction. Second, we develop a Separable Non-local Fusion (SNF) block in the decoder with the self-attention mechanism to aggregate multi-scale features from different layers, which not only achieves the sufficient feature fusion by capturing long-range dependencies, but also vastly reduces the computation cost compared to the original non-local operation. Third, we propose a Regional MSE (R-MSE) loss to tackle the pixel-isolation problems in regular MSE loss . To demonstrate the effectiveness of the proposed AEDNet, we conduct extensive experiments on four widely-used crowd counting datasets, and our AEDNet consistently achieves the state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Xuhui Liu and Yutao Hu and Baochang Zhang and Xiantong Zhen and Xiaoyan Luo and Xianbin Cao},
  doi          = {10.1016/j.neucom.2021.11.087},
  journal      = {Neurocomputing},
  pages        = {246-257},
  shortjournal = {Neurocomputing},
  title        = {Attentive encoder-decoder networks for crowd counting},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-variate time series clustering approach based on
intermediate fusion: A case study in air pollution data imputation.
<em>NEUCOM</em>, <em>490</em>, 229–245. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate Time Series Clustering (MVTS) is an essential task, especially for large and complex dataset, but it has received limited attention in the literature. We are motivated by a real-world problem: the need to cluster air pollution data to produce plausible imputations for missing measurements for some pollutants. Our main focus will be on the UK air quality assessments, the study uses data collected from automatic monitoring stations during four-year period (2015–2018). In this work, we propose a MVTS clustering method followed by an imputation methods for the whole Time Series (TS). We compare two approaches to cluster the stations: univariate TS clustering using Shape-Based Distance (SBD) for individual pollutants, and MVTS clustering using the fused similarity that combines the SBD for all the pollutants. We run a k-means algorithm to produce clusters with each approach on the same dataset. Our analysis shows that using MVTS clustering produces the best clusters as measured by various quality indexes and by the imputations they help to reduce the error average between imputed and real values based on the Root Mean Squared Error (RMSE) and its standard deviation (Std).},
  archive      = {J_NEUCOM},
  author       = {Wedad Alahamade and Iain Lake and Claire E. Reeves and Beatriz De La Iglesia},
  doi          = {10.1016/j.neucom.2021.09.079},
  journal      = {Neurocomputing},
  pages        = {229-245},
  shortjournal = {Neurocomputing},
  title        = {A multi-variate time series clustering approach based on intermediate fusion: A case study in air pollution data imputation},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Guest editorial: Special issue on neural networks-based
reinforcement learning control of autonomous systems. <em>NEUCOM</em>,
<em>490</em>, 226–228. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks-based reinforcement learning control (NRLC) of autonomous systems is an active field due to its theoretical challenges and crucial applications. Note that there exist numerous difficulties in enhancing the intelligence and reliability of autonomous systems since autonomous and reliable techniques of guidance, navigation and control functionals are extremely involved in face of sophisticated and hazardous environments. In this context, high-intelligence reliable control technologies, especially based on neural networks tools, of autonomous systems are persistently pursued in trajectory tracking, path following, waypoints guidance, cooperative formation, etc. In addition, massive nonlinearities, sensor fault diagnosis, actuator failures tolerance, environment abnormalities, civil requirements and national security issues have led to strong demands for the NRLC technologies in autonomous systems. Reinforcement learning, inspired by learning mechanisms observed in mammals, is concerned with how agent and actor ought to take actions to optimize a cost of its long-term interactions with the environment, and is gradually becoming the focus of learning control for autonomous systems. The autonomous systems inevitably suffer from actuator faults, component failures, insecurity factors, complex uncertainties, such that neural networks induced intelligence in autonomous control, fault tolerant control, network communication and signal progressing becomes dramatically significant. To be specific, by combining with neural networks and reinforcement learning, advances in the NRLC technologies of autonomous systems are exclusively pursued in this special issue.},
  archive      = {J_NEUCOM},
  author       = {Hamid Reza Karimi ( Managing Guest Editor ) and Ning Wang and Xu Jin and Ali Zemouche},
  doi          = {10.1016/j.neucom.2021.11.086},
  journal      = {Neurocomputing},
  pages        = {226-228},
  shortjournal = {Neurocomputing},
  title        = {Guest editorial: Special issue on neural networks-based reinforcement learning control of autonomous systems},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling long-term video semantic distribution for temporal
action proposal generation. <em>NEUCOM</em>, <em>490</em>, 217–225. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video temporal segmentation plays a vital role in video analysis since many higher-level computer vision tasks rely on it. Some recent efforts have been dedicated to generating temporal action proposals for long and untrimmed videos, which requires methods to generate accurate boundaries for video semantics. In this paper, we propose a novel and efficient Temporal Distribution Network (TDN), to model the long-term distribution of video semantic units (video dictionary). Firstly, we encode the semantics and context relations of video segments with a boundary-specified video embedding method. Then based on temporal convolutional layers , we design a Temporal Distribution Network (TDN) enumerating all the possible temporal locations in one pass and generating proposals that have high action confidence scores by capturing the long-term distributions of video semantics. We validate our method on temporal action proposal generation tasks and action detection tasks. Experimental results on two benchmark datasets, THUMOS14 and ActivityNet-1.3, show that the proposed method can significantly outperform the state-of-the-art approaches. Our model could obtain high-quality action proposals with a much faster speed.},
  archive      = {J_NEUCOM},
  author       = {Tingting Han and Sicheng Zhao and Xiaoshuai Sun and Jun Yu},
  doi          = {10.1016/j.neucom.2021.11.085},
  journal      = {Neurocomputing},
  pages        = {217-225},
  shortjournal = {Neurocomputing},
  title        = {Modeling long-term video semantic distribution for temporal action proposal generation},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generating self-attention activation maps for visual
interpretations of convolutional neural networks. <em>NEUCOM</em>,
<em>490</em>, 206–216. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, many interpretable methods based on class activation maps (CAMs) have served as an important judging basis for the predictions of convolutional neural networks (CNNs). However, these methods still suffer from the problems of gradient noise, weight distortion, and perturbation deviation. In this work, we present self-attention class activation map (SA-CAM) and shed light on how it uses the self-attention mechanism to refine the existing CAM methods. In addition to generating basic activation feature maps, SA-CAM adds an attention skip connection as a regularization item for each feature map which further refines the focus area of an underlying CNN model. By introducing an attention branch and constructing a new attention operator, SA-CAM greatly alleviates the limitations of the CAM methods. The experimental results on the ImageNet dataset show that SA-CAM can not only generate highly accurate and intuitive interpretation but also have robust stability in adversarial comparison with the state-of-the-art CAM methods.},
  archive      = {J_NEUCOM},
  author       = {Yu Liang and Maozhen Li and Changjun Jiang},
  doi          = {10.1016/j.neucom.2021.11.084},
  journal      = {Neurocomputing},
  pages        = {206-216},
  shortjournal = {Neurocomputing},
  title        = {Generating self-attention activation maps for visual interpretations of convolutional neural networks},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finite-time adaptive neural command filtered control for
pure-feedback time-varying constrained nonlinear systems with actuator
faults. <em>NEUCOM</em>, <em>490</em>, 193–205. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, finite-time adaptive control (FTAC) is investigated for non-affine uncertain constrained nonlinear systems with actuator faults . The state constraints are dealt with by using nonlinear mapping (NM), and an auxiliary dynamical signal is used to handle the unknown dynamic uncertainties of the system. Based on the converted system, a FTAC strategy is designed via command filtered backstepping method. By introducing the compensation signals and adding them into the whole Lyapunov function , and with the help of the defined compact set in stability analysis, it is strictly proved that all signals are semi-globally practical finite-time stable (SGPFS) and all the states are within the specified open set. Simulation results verify the effectiveness of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Ziwen Wu and Tianping Zhang and Xiaonan Xia and Yang Yi},
  doi          = {10.1016/j.neucom.2021.11.083},
  journal      = {Neurocomputing},
  pages        = {193-205},
  shortjournal = {Neurocomputing},
  title        = {Finite-time adaptive neural command filtered control for pure-feedback time-varying constrained nonlinear systems with actuator faults},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LRP-net: A lightweight recursive pyramid network for single
image deraining. <em>NEUCOM</em>, <em>490</em>, 181–192. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single image deraining, as a low-level computer vision task , has been drawn extensive attention in recent years. Rain streaks can degrade subjective visibility quality, meanwhile, bring significant difficulties to subsequent high-level computer vision tasks such as object detection. Nowadays, deep-learning based methods, specifically Convolutional Neural Networks (CNN) based ones are adopted to remove the rain streaks and become the state-of-the-art. However, existing popular deep-networks have complicated branches and numerous layers, which strengthen the ability of removing rain streaks and result in high memory and computational cost inevitably. This restricts many applications in real-time and limited computation resource scene, especially on mobile or edge devices. To handle this issue, this paper proposes a novel Lightweight Recursive Pyramid network (LRP-Net) with a small number of parameters for single image deraining. To begin with, we propose a novel Lightweight Pyramid Deraining (LPD) block which consists of a multi-scale pyramid convolution for sufficient feature extraction and a pointwise convolution for feature fusion . Meanwhile, we also design a novel group convolution strategy in LPD for the sake of remarkable parameter reduction. Secondly, we combine a recursive deraining mechanism, a critical component that serves as a feature fusion iterator to construct our LRPNet a powerful and lightweight multi-stage model. In the benefit of the combination between the LPD block and recursive mechanism, the total number of parameters in LRP-Net is only 130 k, which is nearly a 40- reduction compared with the latest state-of-the-art models. The extensive experiments demonstrate the superiority of LRP-Net in both quantitative assessments and visual quality.},
  archive      = {J_NEUCOM},
  author       = {Bi Xiaojun and Chen Zheng and Yue Jianyu and Wang Haibo},
  doi          = {10.1016/j.neucom.2022.03.035},
  journal      = {Neurocomputing},
  pages        = {181-192},
  shortjournal = {Neurocomputing},
  title        = {LRP-net: A lightweight recursive pyramid network for single image deraining},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-efficient image captioning of fine art paintings via
virtual-real semantic alignment training. <em>NEUCOM</em>, <em>490</em>,
163–180. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The image captioning of fine art paintings aims at generating a sentence to describe the painting content. Compared with photographic images, there are few annotated data of clear and precise content descriptions for paintings. Besides, painting images usually have abstract expressions, making it hard to extract their representative features. In this paper, we propose a virtual-real semantic alignment training process to address these challenges in painting captioning. To provide sufficient training data, we generate a virtual painting captioning dataset by applying style transfer to a large-scale photographic image captioning dataset and maintaining their annotations. To tackle the difficulty of abstract expressions, we employ a semantic alignment loss between photographic image features and virtual painting features to guide the training of the painting feature extractor. We evaluate our method in two data-hungry scenarios where only a few or no annotated painting data for training. According to the evaluation results on a public painting captioning dataset and our annotated painting captioning dataset, our model achieves significant improvements and higher data efficiency than the baselines in the two data-hungry scenarios on all datasets.},
  archive      = {J_NEUCOM},
  author       = {Yue Lu and Chao Guo and Xingyuan Dai and Fei-Yue Wang},
  doi          = {10.1016/j.neucom.2022.01.068},
  journal      = {Neurocomputing},
  pages        = {163-180},
  shortjournal = {Neurocomputing},
  title        = {Data-efficient image captioning of fine art paintings via virtual-real semantic alignment training},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Firefly algorithm and learning-based geographical task
scheduling for operational cost minimization in distributed green data
centers. <em>NEUCOM</em>, <em>490</em>, 146–162. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green Data Centers (GDCs) are more and more deployed world-wide. They integrate many renewable sources to provide clean power and decrease their operating cost. GDCs are typically deployed over multiple locations where renewable energy availability, bandwidth prices and grid electricity cost have high geographical diversity. This paper focuses on delay-bounded applications in distributed GDCs (DGDCs) and performs cost and energy-effective scheduling of multiple heterogeneous applications verifying delay bound constraints of different tasks. DGDCs’ operational cost minimization problem is formulated and successfully optimized using an innovative modified Firefly Algorithm (mFA). Real-life data trace-driven experiments are conducted to evaluate the effectiveness of the proposed mFA in solving this problem. High performance task scheduling results are obtained. The operational cost of each GDC is minimized, the utilization of solar and wind renewable energy from the different geographical locations is maximized while delay bound constraints of all tasks are strictly met. Compared to Bat Algorithm , Simulated-annealing Bat Algorithm and basic firefly algorithm, mFA can produce a schedule that outperforms its peers’ drastically in terms of operational cost of DGDCs. Moreover, mFA finds more rapidly both global or local optima than its peers. It succeeds to meet all equality and inequality constraints at all time slots while its peers may sometimes fail to find satisfactory solutions at some particular time slots.},
  archive      = {J_NEUCOM},
  author       = {Ahmed Chiheb Ammari and Wael Labidi and Faisal Mnif and Haitao Yuan and MengChu Zhou and Mohamed Sarrab},
  doi          = {10.1016/j.neucom.2022.01.052},
  journal      = {Neurocomputing},
  pages        = {146-162},
  shortjournal = {Neurocomputing},
  title        = {Firefly algorithm and learning-based geographical task scheduling for operational cost minimization in distributed green data centers},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-modal interactive attention and dual progressive
decoding network for RGB-d/t salient object detection. <em>NEUCOM</em>,
<em>490</em>, 132–145. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-based salient object detection (SOD) algorithms have shown good ability to segment salient objects from images, but the performance is still unsatisfactory when dealing with challenging scenes such as ambiguous object contours , low color contrasts between foreground and background. To overcome this problem, RGB-D or RGB-T SOD has been studied. However, they are currently usually treated as separate visual tasks. And most of them directly extract and fuse raw features from backbones. In this paper, we explore the potential commonalities between the two tasks and propose a novel end-to-end unified framework that can be used for both RGB-D and RGB-T SOD. The framework consists of three key components: multi-modal interactive attention (MIA) unit, joint attention guided cross-modal decoding (JAGCD) module, and multi-level feature progressive decoding (MFPD) module. Specifically, MIA units effectively capture rich multi-layered context features from each modality feature, which serve as a bridge between feature encoding and cross-modal decoding. Moreover, the proposed JAGCD and MFPD modules progressively integrate complementary features from multi-source features and different level of fusion features , respectively. To demonstrate the effectiveness of the proposed approach, we conduct comprehensive experiments not only on RGB-D but also on RGB-T saliency detection benchmark. Experimental results show that our approach outperforms other state-of-the-art methods and has good generalization. Moreover, the proposed framework can provide a potential solution for cross-modal complementary tasks. The code will be available at https://github.com/Liangyh18/MIA_DPD.},
  archive      = {J_NEUCOM},
  author       = {Yanhua Liang and Guihe Qin and Minghui Sun and Jun Qin and Jie Yan and Zhonghan Zhang},
  doi          = {10.1016/j.neucom.2022.03.029},
  journal      = {Neurocomputing},
  pages        = {132-145},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal interactive attention and dual progressive decoding network for RGB-D/T salient object detection},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Global exponential stability of neutral-type
cohen–grossberg neural networks with multiple time-varying neutral and
discrete delays. <em>NEUCOM</em>, <em>490</em>, 124–131. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the global exponential stability of neutral-type Cohen–Grossberg neural networks (NTCGNNs) with multiple time-varying discrete and neutral delays. Since the system model can not be expressed in the form of a vector–matrix,some methods and techniques for stability analysis of the vector–matrix models will not be available. First, a novel criterion is proposed to ensure the existence and uniqueness of equilibrium point (EP) of the NTCGNNs under consideration. Then, with the purpose of ensuring the global exponential stability of the unique EP, a new Lyapunov–Krasovskii functional is constructed to obtain novel stability criteria. Several representative numerical examples are used to demonstrate the applicability of the obtained stability conditions, and its advantages over the existing ones.},
  archive      = {J_NEUCOM},
  author       = {Zhongjie Zhang and Xian Zhang and Tingting Yu},
  doi          = {10.1016/j.neucom.2022.03.068},
  journal      = {Neurocomputing},
  pages        = {124-131},
  shortjournal = {Neurocomputing},
  title        = {Global exponential stability of neutral-type Cohen–Grossberg neural networks with multiple time-varying neutral and discrete delays},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Robust dual-graph regularized and minimum redundancy based
on self-representation for semi-supervised feature selection.
<em>NEUCOM</em>, <em>490</em>, 104–123. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial labeled data is ubiquitous in the big data era. Selecting informative features, and avoiding redundant and noise features is an important task for constructing robust learning models. The inherent characteristics of samples and features need to be surveyed simultaneously. In this study, a feature selection method for partial labeled data based on dual-graph regularized is proposed. Self-representation can well mine the relation between features. Then, the self-representation is combined with the framework of sparse learning to well embody the character of data and an adaptive redundancy regularization term based on self-representation is designed to minimize the redundancy between features. In the self-representation based regularization term , the relation between features is updated dynamically during the iteration so as to capture the inherent relation between features more accurately. The manifold structure in both feature space and data space are considered jointly. Moreover, the L 2 , p - norm L2,p-norm is imposed on the feature self-representation regularization term, self-representation coefficient matrix , and feature selection matrix, respectively. These constrains aim to enhance its robustness to outliers, and select the representative features with discriminative and low redundancy. The convex ( p = 1 p=1 ) and non-convex ( 0 0&amp;lt;p&amp;lt;1 ) are involved in the proposed method. Then, a unified solution for the proposed method is investigated and its convergence is proved. Experimental results on public data sets show that the proposed method is effective for classification tasks when compared with some feature selection methods.},
  archive      = {J_NEUCOM},
  author       = {Hao Chen and Hongmei Chen and Weiyi Li and Tianrui Li and Chuan Luo and Jihong Wan},
  doi          = {10.1016/j.neucom.2022.03.004},
  journal      = {Neurocomputing},
  pages        = {104-123},
  shortjournal = {Neurocomputing},
  title        = {Robust dual-graph regularized and minimum redundancy based on self-representation for semi-supervised feature selection},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Generating images from audio under semantic consistency.
<em>NEUCOM</em>, <em>490</em>, 93–103. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating the data of an absent modality based on existing modal information is valuable for realizing audio-visual intermodal information complementarity. However, existing audio-visual generation methods require strict timing synchronization between the data of two modalities, which is very time-consuming and expensive. In this paper, considering the extensive audio-visual semantic associations , we propose a semantic consistency audio-to-image generative adversarial network (SCAIGAN) to generate visual images with the corresponding semantics directly from audio spectrograms. Particularly, in our model, three mechanisms are exploited. First, a self-attention mechanism is added to the encoder to better capture the global features and geometric structure of the high-dimensional characteristics of the data. Second, the projection mechanism is used in a discriminator to constrain the generator in such a way that a type of cross-modal-based self-supervision under semantic consistency can be embedded. Finally, self-modulation batch normalization is applied to the generator to accelerate the convergence and improve the quality of the generated images. Experiments demonstrate that our model can generate clear visual images with diversity on both instrument and face datasets and can achieve better classification accuracy than the other state-of-the-art methods. Our code will be made publicly available at https://github.com/PengchengZhao1001/AV-Correlation.},
  archive      = {J_NEUCOM},
  author       = {Pengcheng Zhao and Yanxiang Chen and Lulu Zhao and Guang Wu and Xi Zhou},
  doi          = {10.1016/j.neucom.2022.03.015},
  journal      = {Neurocomputing},
  pages        = {93-103},
  shortjournal = {Neurocomputing},
  title        = {Generating images from audio under semantic consistency},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An overview on twin support vector regression.
<em>NEUCOM</em>, <em>490</em>, 80–92. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twin support vector regression (TSVR) is a useful extension of traditional support vector regression (SVR). As a new regression model, the basic idea of TSVR is generating a pair of nonparallel functions on both sides of the training data points , such that the ε ε -insensitive upper and lower bounds of the regression function can be determined. Owing to its excellent learning ability, TSVR has become a research hotspot in the field of machine learning . With the deepening of such research, scholars have found that TSVR also has certain limitations, and thus various improved models have been proposed. This review aims to report the recent developments in twin support vector regression. First, the basic concepts and basic models of TSVR are introduced. Second, the improved algorithms and applications of TSVR in recent years are summarized, and the advantages and disadvantages of its representative algorithms are analyzed and compared with the experiments. Finally, we discuss the research conducted on TSVR.},
  archive      = {J_NEUCOM},
  author       = {Huajuan Huang and Xiuxi Wei and Yongquan Zhou},
  doi          = {10.1016/j.neucom.2021.10.125},
  journal      = {Neurocomputing},
  pages        = {80-92},
  shortjournal = {Neurocomputing},
  title        = {An overview on twin support vector regression},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Corrigendum to “partner learning: A comprehensive knowledge
transfer for vehicle re-identification” [neurocomputing 480 (2022)
89–98/NEUCOM-d-21-03435R1]. <em>NEUCOM</em>, <em>490</em>, 79. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Wen Qian and Zhiqun He and Chen Chen and Silong Peng},
  doi          = {10.1016/j.neucom.2022.03.037},
  journal      = {Neurocomputing},
  pages        = {79},
  shortjournal = {Neurocomputing},
  title        = {Corrigendum to “Partner learning: A comprehensive knowledge transfer for vehicle re-identification” [Neurocomputing 480 (2022) 89–98/NEUCOM-D-21-03435R1]},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian sparse factor analysis with kernelized
observations. <em>NEUCOM</em>, <em>490</em>, 66–78. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view problems can benefit from latent representations since they find low-dimensional projections that fairly capture the correlations among the multiple views that characterise the data. On the other hand, high-dimensionality and non-linear issues are traditionally handled by kernel methods , inducing a (non)-linear function between the latent projection and the data itself. However, they usually come with exposition to overfitting. Here, we combine Bayesian factor analysis with what we refer to as kernelized observations, in which the proposed model focuses on reconstructing not the data itself, but its relationship with other data points measured by a kernel function . In turn, we extend previous Bayesian FA formulations to be able to model non-linear data relationships by means of kernelized data representations and, at the same time, include additional facilities to obtain compact kernel representations by means of an automatic selection of Bayesian Relevance Vectors (RVs), feature relevance analysis and, even, obtain an automatic multiple kernel learning approach. Besides, this is flexibly included into a modular framework where we can easily adapt the model capabilities to the data needs and, even, combine them with previous FA functionalities such as heterogeneous data representations or semi-supervised learning. Using several public databases, we demonstrate the potential of the approach (and its extensions) w.r.t. common multi-view learning models such as kernel canonical correlation analysis, heterogeneous incomplete – variational autoenconder or manifold relevance determination, where the proposed model shows its ability to outperform the baselines while indistinctly combining model extensions.},
  archive      = {J_NEUCOM},
  author       = {Carlos Sevilla-Salcedo and Alejandro Guerrero-López and Pablo M. Olmos and Vanessa Gómez-Verdejo},
  doi          = {10.1016/j.neucom.2022.03.024},
  journal      = {Neurocomputing},
  pages        = {66-78},
  shortjournal = {Neurocomputing},
  title        = {Bayesian sparse factor analysis with kernelized observations},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review on varying-parameter convergence differential
neural network. <em>NEUCOM</em>, <em>490</em>, 54–65. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the nature of actual dynamics systems with time-varying parameters, varying-parameter convergence differential neural network (termed as VP-CDNN) has been put forward and played a crucial role in obtaining the real-time solution of algebraic equations and optimization problems . Plenty of fruitful literatures report that such a neural network breaks the bottlenecks of the conventional algorithms and presents superior convergence performance and strong anti-noise capability in the time-varying problem solving. This paper presents an overall review about VP-CDNN in different mathematical problems solving such as time-varying quadratic-programming equation, time-varying Sylvester equation, nonlinear and nonconvex equation and so on. Besides its extension forms such as anti-noise VP-CDNN, finite-time VP-CDNN, fuzzy VP-CDNN and discrete-time VP-CDNN are briefly introduced in mathematical problems solving. Additionally, the applications of VP-CDNN in robot motion planning, unmanned aerial vehicles , venture investment and other applications are illustrated for practical implementation. The conclusion summarizes the superiority of VP-CDNN and indicates several future research direction.},
  archive      = {J_NEUCOM},
  author       = {Zhijun Zhang and Xianzhi Deng and Lunan Zheng},
  doi          = {10.1016/j.neucom.2022.03.026},
  journal      = {Neurocomputing},
  pages        = {54-65},
  shortjournal = {Neurocomputing},
  title        = {A review on varying-parameter convergence differential neural network},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Liver, kidney and spleen segmentation from CT scans and MRI
with deep learning: A survey. <em>NEUCOM</em>, <em>490</em>, 30–53. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning approaches for automatic segmentation of organs from CT scans and MRI are providing promising results, leading towards a revolution in the radiologists’ workflow. Precise delineations of abdominal organs boundaries reveal fundamental for a variety of purposes: surgical planning, volumetric estimation (e.g. Total Kidney Volume – TKV – assessment in Autosomal Dominant Polycystic Kidney Disease – ADPKD), diagnosis and monitoring of pathologies. Fundamental imaging techniques exploited for these tasks are Computed Tomography (CT) and Magnetic Resonance Imaging (MRI), which enable clinicians to perform 3D analyses of all Regions of Interests (ROIs). In the realm of existing methods for segmentation and classification of these zones, Convolutional Neural Networks (CNNs) are emerging as the reference approach. In the last five years an enormous research effort has been done about the possibility of applying CNNs in Medical Imaging , resulting in more than 8000 documents on Scopus and more than 80000 results on Google Scholar. The high accuracy provided by those systems cannot be denied as motivation of all obtained results, though there are still problems to be addressed with. In this survey, major article databases, as Scopus, for instance, were systematically investigated for different kinds of Deep Learning approaches in segmentation of abdominal organs with a particular focus on liver, kidney and spleen. In this work, approaches are accurately classified, both by relevance of each organ (for instance, segmentation of liver has specific properties, if compared to other organs) and by type of computational approach, as well as the architecture of the employed network. For this purpose, a case study of segmentation for each of these organs is presented.},
  archive      = {J_NEUCOM},
  author       = {Nicola Altini and Berardino Prencipe and Giacomo Donato Cascarano and Antonio Brunetti and Gioacchino Brunetti and Vito Triggiani and Leonarda Carnimeo and Francescomaria Marino and Andrea Guerriero and Laura Villani and Arnaldo Scardapane and Vitoantonio Bevilacqua},
  doi          = {10.1016/j.neucom.2021.08.157},
  journal      = {Neurocomputing},
  pages        = {30-53},
  shortjournal = {Neurocomputing},
  title        = {Liver, kidney and spleen segmentation from CT scans and MRI with deep learning: A survey},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). When multi-view classification meets ensemble learning.
<em>NEUCOM</em>, <em>490</em>, 17–29. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the coming of big data era, multi-view data represented by multiple features have been involved in many terms, such as machine learning , data mining and computer vision and so on. Due to the complex structure hidden in data, how to utilize the complementary and correlative information among multiple view features to improve classification performance is a challenging task. Moreover, the another challenging task is how to assign an appropriate weight for each classifier on the basis of its performance. To solve above problems, we proposed a supervised multi-view classification method based on Least Square Regression (LSR) and Ensemble Learning . To be specific, all samples for each view firstly can be classified by using Multi-class Support Vector Machine (MSVM); Then, to evaluate the classification results of different views for each sample, the optimal weight of each sample classification result is learned; Furthermore, considering the view difference with different classification quality, the view weights are assigned adaptively; Finally, we adopt the decision function values to determine the final classification results . Extensive experimental results show that the proposed method outperforms most state-of-the-art multi-view classification methods.},
  archive      = {J_NEUCOM},
  author       = {Shaojun Shi and Feiping Nie and Rong Wang and Xuelong Li},
  doi          = {10.1016/j.neucom.2022.02.052},
  journal      = {Neurocomputing},
  pages        = {17-29},
  shortjournal = {Neurocomputing},
  title        = {When multi-view classification meets ensemble learning},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Efficient depthwise separable convolution accelerator for
classification and UAV object detection. <em>NEUCOM</em>, <em>490</em>,
1–16. (<a href="https://doi.org/10.1016/j.neucom.2022.02.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depthwise separable convolutions (DSC) have been widely deployed in lightweight convolutional neural networks due to high efficiency. But the acceleration performance of the Graphics Processing Unit for DSC was not as well as in theory. In this paper, some approaches were proposed for accelerating DSC based on Field-Programmable Gate Array (FPGA). For the preceding layers, S2C (spatial to channel) was proposed to accelerate computing and improve the utilization rate of computational resources and bandwidth. An efficient SharePE was proposed to accelerate the DSC, which can improve the efficiency of the computing resource. The regulable parallelism approach was proposed to compute efficiently the different pointwise convolutional layers . P2D&amp;D2P approach is proposed to reduce the external memory access. For the entire accelerating system, the pre-load workflow was proposed to reduce the waiting time of the accelerator between two images. We demonstrated our approaches on the SkyNet using the Ultra96V2 development board. Results indicated that our proposed accelerator obtained 80.030 frames per second and 0.072 Joule per image for UAV object detection, which achieved the state-of-the-art results for SkyNet. Besides, the MobileNetV2 model was implemented on a larger XC7Z100 FPGA, and the results showed our accelerator classified each picture from ImageNet in 2.69 ms. Code is available at https://github.com/AILearnerLi/DAC-SDC-2020-SEUer.},
  archive      = {J_NEUCOM},
  author       = {Guoqing Li and Jingwei Zhang and Meng Zhang and Ruixia Wu and Xinye Cao and Wenzhao Liu},
  doi          = {10.1016/j.neucom.2022.02.071},
  journal      = {Neurocomputing},
  pages        = {1-16},
  shortjournal = {Neurocomputing},
  title        = {Efficient depthwise separable convolution accelerator for classification and UAV object detection},
  volume       = {490},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparing subject-to-subject transfer learning methods in
surface electromyogram-based motion recognition with shallow and deep
classifiers. <em>NEUCOM</em>, <em>489</em>, 599–612. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface electromyogram (sEMG)-based human-computer interface (HCI) is an effective tool for detecting human movements. Because sEMG-based motion recognition usually requires prolonged data measurements from the user (target), transfer learning reusing pre-measured (source) data from other users and pre-trained classifiers can be applied to sEMG data to reduce the measurement time. However, little knowledge is available regarding the combination of transfer learning methods and classifiers in sEMG data applications. Thus, we investigated the classification accuracy of data- and parameter-space-based transfer learning with shallow or deep classifiers in cross-subject sEMG classification. The dataset contains eight classes of forearm motions recorded from 25 volunteer participants. We used a support vector machine (SVM) as a shallow classifier as well as a deep neural network architecture, referred to as an artificial neural network (ANN), as a deep classifier. In addition, we used style transfer mapping (STM) as a data-space-based transfer learning method and fine-tuning (FT) as a parameter-space-based transfer learning method. Consequently, the classification accuracy of the ANN was higher than that of the SVM, regardless of the combinational use of transfer learning. STM and FT significantly improved the classification accuracy compared with non-transfer cases regardless of the classifier (note that FT can only be used with the ANN). In particular, the combined use of FT and the ANN yielded the best accuracy. These findings suggest that parameter-space-based transfer learning and deep classifiers are suitable for cross-subject sEMG classification. The combined use of parameter-space-based transfer learning and deep classifiers can effectively reduce the data measurement time of sEMG-based HCI applications.},
  archive      = {J_NEUCOM},
  author       = {Takayuki Hoshino and Suguru Kanoga and Masashi Tsubaki and Atsushi Aoyama},
  doi          = {10.1016/j.neucom.2021.12.081},
  journal      = {Neurocomputing},
  pages        = {599-612},
  shortjournal = {Neurocomputing},
  title        = {Comparing subject-to-subject transfer learning methods in surface electromyogram-based motion recognition with shallow and deep classifiers},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization algorithms in wireless monitoring networks: A
survey. <em>NEUCOM</em>, <em>489</em>, 584–598. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless network has emancipated people from the bondage of wired network and enhanced the quality of human life. However, there remain a few areas pertaining to wireless network that require attention, such as network congestion , low communication reliability and security. With the increasing scale and extended applications of Internet of Things (IoT), there is a growing demand for reliability, stability and security within the network. Wireless network monitoring is an effective system put in place which involves distributed sniffers that capture the transmitted data of wireless users, facilitating status analysis, fault diagnosis and resource management of the network system. Due to the limited number of sniffers, optimization of hardware configuration and channel assignment of sniffers is paramount, which can significantly improve the amount of captured data and the monitoring quality of the wireless network. Primarily, the concept, classification and characteristics of wireless network monitoring are introduced. Secondarily, the application of optimization algorithms in wireless network monitoring, particularly the channel selection algorithms during the data collection process and the channels and time-slot scheduling algorithms during the data aggregation process are summarized. Finally, the challenges faced when building a wireless network monitoring are discussed and to conclude prospects aimed towards the development of this research field are put forward.},
  archive      = {J_NEUCOM},
  author       = {Na Xia and Cong Wang and Huaizhen Peng and Zhongqiu Zhao and Yuqing Chen and Peipei Wang and Huazheng Du and Sheng Ding and Yongtang Yu},
  doi          = {10.1016/j.neucom.2021.12.072},
  journal      = {Neurocomputing},
  pages        = {584-598},
  shortjournal = {Neurocomputing},
  title        = {Optimization algorithms in wireless monitoring networks: A survey},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). JSENet: A deep convolutional neural network for joint image
super-resolution and enhancement. <em>NEUCOM</em>, <em>489</em>,
570–583. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Super-resolution (SR) and image enhancement (IE) are two common and important tasks in image processing . Due to poor equipment, illumination, and photographic skills, many low-resolution and low-quality (in terms of color, and contrasts) photos are captured in our daily life. To make the photos more visually pleasing, we usually enlarge and retouch them in two separate steps. In this paper, we propose a new Joint Image Super-resolution and Enhancement Network (JSENet), which is arguably the first end-to-end method based on deep learning for joint SR and IE. Compared with simply conducting these two tasks in parallel or sequentially, JSENet employs the bilateral learning framework to integrate the two tasks together seamlessly. Meanwhile, two lightweight modules are designed for restoring details and generating color transformation coefficients respectively, which ensures that our JSENet can be deployed in real-world applications. Extensive experiments are conducted to demonstrate that JSENet outperforms the state-of-the-art SR-IE methods.},
  archive      = {J_NEUCOM},
  author       = {Kejie Lyu and Sicheng Pan and Yingming Li and Zhongfei Zhang},
  doi          = {10.1016/j.neucom.2021.12.071},
  journal      = {Neurocomputing},
  pages        = {570-583},
  shortjournal = {Neurocomputing},
  title        = {JSENet: A deep convolutional neural network for joint image super-resolution and enhancement},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PD control for passivity of coupled reaction-diffusion
neural networks with multiple state couplings or spatial diffusion
couplings. <em>NEUCOM</em>, <em>489</em>, 558–569. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the passivity for coupled reaction-diffusion neural networks with multiple state couplings (CRDNNMSCs) or spatial diffusion couplings (CRDNNMSDCs) by employing the proportional-derivative (PD) control method . Firstly, a PD control strategy is presented for the sake of ensuring the passivity of CRDNNMSCs, and a synchronization condition is also given by utilizing the output-strict passivity of CRDNNMSCs. In addition, some corresponding conditions for guaranteeing the passivity and synchronization of CRDNNMSDCs are also developed in virtue of PD controller. Lastly, the correctness of the obtained passivity and synchronization criteria for the proposed models is verified by two numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Rong-Guo Liang and Jin-Liang Wang},
  doi          = {10.1016/j.neucom.2021.12.070},
  journal      = {Neurocomputing},
  pages        = {558-569},
  shortjournal = {Neurocomputing},
  title        = {PD control for passivity of coupled reaction-diffusion neural networks with multiple state couplings or spatial diffusion couplings},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). On self-adaptive stochastic ranking in decomposition
many-objective evolutionary optimization. <em>NEUCOM</em>, <em>489</em>,
547–557. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multi-objective optimization problems have attracted increasingly attention in the evolutionary computing community. Now a lot of efforts have been devoted to this direction. For example, the proposed Pareto-dominated, decomposition-based and indicator-based methods have improved the scalability of multi-objective evolutionary algorithms (MOEAs). However, with the increase of the number of objectives, the portion of non-dominated individuals in the population is too large, and the distinguishability of individuals in the objective space decreases, which will affect the selection of elite solutions, thereby losing the balance of convergence and diversity. In this paper, a self-adaptive stochastic ranking method (SSR) is proposed to adaptively balance the convergence and diversity in high-dimensional space according to the state of the population. It has been embedded into the MOEA/D framework to form a novel multi-objective optimization algorithm, named MOEA/D-SSR. In addition, an improved shift-based density estimation strategy (ISDE) is adopted to enhance the convergence and diversity. Compared with the existing MOEAs on benchmark suite DTLZ and WFG with up to 10 objectives, the performance of the our algorithm has been verified. Experimental results show that the proposed algorithm is competitive compared with the most advanced MOEAs.},
  archive      = {J_NEUCOM},
  author       = {Li Li and Guangpeng Li and Liang Chang},
  doi          = {10.1016/j.neucom.2021.12.069},
  journal      = {Neurocomputing},
  pages        = {547-557},
  shortjournal = {Neurocomputing},
  title        = {On self-adaptive stochastic ranking in decomposition many-objective evolutionary optimization},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prior embedding multi-degradations super resolution network.
<em>NEUCOM</em>, <em>489</em>, 534–546. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, multi-degradations super-resolution (MDSR) has gradually received wide attention for its ability to deal with multiple degradations including blur, noise in a low-resolution (LR) image. Deep neural networks based MDSR methods have gained rapid development by utilizing the degradation prior. Though achieving promising results, most existing MDSR models fail to fully utilize the degradation prior and efficiently reconstruct high-resolution (HR) image by simple concatenation and iterative operations. This paper proposes an end-to-end MDSR approach to effectively extract features from the degradation prior and embed the degradation features into image features via the degradation feature extraction module and the prior embedding module. In addition, the axis attention mechanism and the pixel attention mechanism are proposed to augment the representation power of image features. Extensive experiments demonstrate that our approach can simultaneously solve different degradations and produce state-of-the-art results on standard benchmark datasets, with advantages in terms of quantitative metrics, visual quality, and reconstruction efficiency.},
  archive      = {J_NEUCOM},
  author       = {Chenxi Ma and Weimin Tan and Bo Yan and Shili Zhou},
  doi          = {10.1016/j.neucom.2021.12.066},
  journal      = {Neurocomputing},
  pages        = {534-546},
  shortjournal = {Neurocomputing},
  title        = {Prior embedding multi-degradations super resolution network},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HSAN-capsule: A novel text classification model.
<em>NEUCOM</em>, <em>489</em>, 521–533. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most text classification methods fail to fully consider the important role of the hierarchical structure of the text in determining the text category, and cannot well extract enough text sequence information. To address this problem, a novel model based on hierarchical self-attention mechanism capsule network was proposed for text classification , which was composed of two components, i.e., the hierarchical self-attention network and capsule network. First input the text data processed by word embedding into the hierarchical self-attention network for feature extraction, model the text from the two levels of words and sentences to extract the hierarchical features of the text; then the results are passed into the capsule network in order to refine the relationship between the part of the text and the whole, and further extract richer text semantic information. The experimental results on 5 text classification datasets show that compared with other baseline models , the model in this paper has achieved better classification results .},
  archive      = {J_NEUCOM},
  author       = {Yan Cheng and Haifeng Zou and Huan Sun and Haomai Chen and Yingying Cai and Meng Li and Qinyi Du},
  doi          = {10.1016/j.neucom.2021.12.064},
  journal      = {Neurocomputing},
  pages        = {521-533},
  shortjournal = {Neurocomputing},
  title        = {HSAN-capsule: A novel text classification model},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive neural control for mobile manipulator systems based
on adaptive state observer. <em>NEUCOM</em>, <em>489</em>, 504–520. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study processes the adaptive robust control problem in a task space for a mobile manipulator with uncertain dynamics and external disturbances based on radial basis function neural networks(RBFNN) and a nonlinear state observer. Owing to the high nonlinearity, strong coupling, and unknown uncertainty characteristics of the mobile manipulators, their control poses a considerable challenge. An adaptive robust control strategy for nonlinear mobile robot systems with unknown uncertainties and disturbances based on the RBFNN and state observer is proposed in the operating space. First, a feedforward-feedback virtual speed generator is developed based on the feedforward control and backstepping method to implement virtual speed tracking control in the operation space to make the positional error asymptotically stable. Then, a model-independent RBFNN based adaptive robust controller (ARBFNNC) with the state observer is proposed, which converts the virtual speed input into the control torque of the actual mobile manipulator to achieve precise position tracking in the task space, and theoretical analysis performed through Lyapunov stability theory shows the global asymptotic stability of a system under the control of the proposed method. Finally, simulation results confirm the effectiveness of the proposed control method in position regulation and tracking control of the nonlinear mobile manipulator.},
  archive      = {J_NEUCOM},
  author       = {Yukun Zheng and Yixiang Liu and Rui Song and Xin Ma and Yibin Li},
  doi          = {10.1016/j.neucom.2021.12.062},
  journal      = {Neurocomputing},
  pages        = {504-520},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural control for mobile manipulator systems based on adaptive state observer},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human pose estimation for mitigating false negatives in
weapon detection in video-surveillance. <em>NEUCOM</em>, <em>489</em>,
488–503. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying CNN-based object detection models to the task of weapon detection in video-surveillance is still producing a high number of false negatives . In this context, most existing works focus on one type of weapons, mainly firearms, and improve the detection using different pre- and post-processing strategies. One interesting approach that has not been explored in depth yet is the exploitation of the human pose information for improving weapon detection. This paper proposes a top-down methodology that first determines the hand regions guided by the human pose estimation then analyzes those regions using a weapon detection model. For an optimal localization of each hand region, we defined a new factor, called Adaptive pose factor , that takes into account the distance of the body from the camera. Our experiments show that this top-down Weapon Detection over Pose Estimation (WeDePE) methodology is more robust than the alternative bottom-up approach and state-of-the art detection models in both indoor and outdoor video-surveillance scenarios.},
  archive      = {J_NEUCOM},
  author       = {Alberto Lamas and Siham Tabik and Antonio Cano Montes and Francisco Pérez-Hernández and Jorge García and Roberto Olmos and Francisco Herrera},
  doi          = {10.1016/j.neucom.2021.12.059},
  journal      = {Neurocomputing},
  pages        = {488-503},
  shortjournal = {Neurocomputing},
  title        = {Human pose estimation for mitigating false negatives in weapon detection in video-surveillance},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed machine learning, optimization and applications.
<em>NEUCOM</em>, <em>489</em>, 486–487. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Qingshan Liu and Zhigang Zeng and Yaochu Jin},
  doi          = {10.1016/j.neucom.2021.12.058},
  journal      = {Neurocomputing},
  pages        = {486-487},
  shortjournal = {Neurocomputing},
  title        = {Distributed machine learning, optimization and applications},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of regression and classification techniques for
analysis of common and rare variants and gene-environmental factors.
<em>NEUCOM</em>, <em>489</em>, 466–485. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical techniques incorporated with machine-learning algorithms in unison with gene-environment interaction are giving unparalleled understanding of complex diseases. Accurate analysis and intricate capturing of common, rare, and low MAF (Minor Allele Frequency) variants alongside gene-environmental interaction is pivotal whilst concluding reliable and accurate classification of complex diseases. Various complex diseases including genres of diabetes Type 1 and Type 2 alongside the vastly under-researched Lada (Latent Autoimmune Diabetes in Adults) diabetes require further investigation alongside significant machine learning research to gain a deeper understanding of the disease complexities. Despite existing efforts, an ideal combination of statistical techniques with optimal machine-learning algorithms that can accurately capture and model the gene-environment interaction is lacking. Intentionally exploring future and simultaneously exploiting modern-day computational methods in genomic analysis, this paper profoundly investigates both the future and present interaction of statistical analysis techniques and machine-learning algorithms and Ensembles with gene-environmental factors. In this context, this paper firstly presents a conceptual understanding of genomic conventions; secondly, conducts potential future machine learning algorithms alongside an extensive analysis of a range of classification, regression and Ensemble techniques along with exhibiting their imperative relationship and roles in investigating and classifying common, rare variants and a wide array of gene-environmental factors; and thirdly, utilisation of statistical techniques in Genome Wide Association Studies is scrutinised whilst analysing common, rare and MAF variants. As an important contribution, this paper identifies efficient machine-learning algorithms alongside Ensemble models and future potential analysis techniques and exhibits their inherent characteristics that can enhance the reliability and accuracy of the gene-environment classification analysis .},
  archive      = {J_NEUCOM},
  author       = {Anthony Miller and John Panneerselvam and Lu Liu},
  doi          = {10.1016/j.neucom.2021.08.150},
  journal      = {Neurocomputing},
  pages        = {466-485},
  shortjournal = {Neurocomputing},
  title        = {A review of regression and classification techniques for analysis of common and rare variants and gene-environmental factors},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on epistemic (model) uncertainty in supervised
learning: Recent advances and applications. <em>NEUCOM</em>,
<em>489</em>, 449–465. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying the uncertainty of supervised learning models plays an important role in making more reliable predictions. Epistemic uncertainty, which usually is due to insufficient knowledge about the model, can be reduced by collecting more data or refining the learning models. Over the last few years, scholars have proposed many epistemic uncertainty handling techniques which can be roughly grouped into two categories, i.e., Bayesian and ensemble. This paper provides a comprehensive review of epistemic uncertainty learning techniques in supervised learning over the last five years. As such, we, first, decompose the epistemic uncertainty into bias and variance terms. Then, a hierarchical categorization of epistemic uncertainty learning techniques along with their representative models is introduced. In addition, several applications such as computer vision (CV) and natural language processing (NLP) are presented, followed by a discussion on research gaps and possible future research directions.},
  archive      = {J_NEUCOM},
  author       = {Xinlei Zhou and Han Liu and Farhad Pourpanah and Tieyong Zeng and Xizhao Wang},
  doi          = {10.1016/j.neucom.2021.10.119},
  journal      = {Neurocomputing},
  pages        = {449-465},
  shortjournal = {Neurocomputing},
  title        = {A survey on epistemic (model) uncertainty in supervised learning: Recent advances and applications},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep domain adaptation via joint transfer networks.
<em>NEUCOM</em>, <em>489</em>, 441–448. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation aims to transfer the enrich label knowledge from a large-scale labeled tasks to new ones with no labeled data. In the real-world scenario, the domain discrepancy of feature distributions between different tasks (domains) is usually uncontrollable, which is dramatically motivated to match the feature distributions in the face of the domain discrepancy is completely divergence. Under the condition that target task (domain) annotations are unknown, how to successfully adapt the trained classified from source to the target of interest still remains an open issue. In this paper, a unified domain adaptation method is proposed, Joint Transfer Networks (JTN), which jointly generates domain transferable features across two different domains and a double weighting scheme is able to learn more meaningful and transferable features. Additionally, we also exploit the pseudo-labeled target data to generate discriminative features in the target domain, which further boosts the adaptation performance. Finally, after a thorough evaluation of proposed method utilizing several benchmark datasets of varying difficulty. JTN yielded the state-of-the-art performance and outperformed baseline approaches for various domain adaptation tasks.},
  archive      = {J_NEUCOM},
  author       = {Changchun Zhang and Qingjie Zhao and Heng Wu},
  doi          = {10.1016/j.neucom.2022.03.028},
  journal      = {Neurocomputing},
  pages        = {441-448},
  shortjournal = {Neurocomputing},
  title        = {Deep domain adaptation via joint transfer networks},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Treeago: Tree-structure aggregation and optimization for
graph neural network. <em>NEUCOM</em>, <em>489</em>, 429–440. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Networks (GCNs) have achieved much success in various graph learning tasks. However, as the number of layers increases, the smoothing of GCNs will over-mix the neighbors’ information, leading output towards space with low expressivity. It is known as the over-smoothing issue. Although several works have refined deep GCNs by optimizing network structure, receptive field, and topology, the over-smoothing issue cannot be completely avoided. In this paper, we propose a recurrent neural network framework for learning graph representation while avoiding over-smoothing effectively, which is the tree-structure aggregation and optimization framework named Treeago. Treeago firstly transforms the irregularly distributed graph into sequential trees. Then, Treeago adopts Tree-LSTM with attention to aggregate important neighbors’ feature information to the graph representation . Tree-LSTM with attention can prevent the mixing of noise neighbors’ information to avoid the over-smoothing issue. Finally, Treeago uses an edge pruning optimization framework based on reinforcement learning to enhance the model’s performance further. Experimental results on multiple real-world datasets show that Treeago effectively avoids over-smoothing and yields state-of-the-art results.},
  archive      = {J_NEUCOM},
  author       = {Ensen Wu and Hongyan Cui and Zunming Chen and Roy E. Welsch},
  doi          = {10.1016/j.neucom.2022.03.021},
  journal      = {Neurocomputing},
  pages        = {429-440},
  shortjournal = {Neurocomputing},
  title        = {Treeago: Tree-structure aggregation and optimization for graph neural network},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Applications of fractional calculus in computer vision: A
survey. <em>NEUCOM</em>, <em>489</em>, 407–428. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fractional calculus is an abstract idea exploring interpretations of differentiation having non-integer order. For a very long time, it was considered as a topic of mere theoretical interest. However, the introduction of several useful definitions of fractional derivatives has extended its domain to applications. Supported by computational power and algorithmic representations, fractional calculus has emerged as a multifarious domain. It has been found that the fractional derivatives are capable of incorporating memory into the system and thus suitable to improve the performance of locality-aware tasks such as image processing and computer vision in general. This article presents an extensive survey of fractional-order derivative-based techniques that are used in computer vision. It briefly introduces the basics and presents applications of the fractional calculus in six different domains viz . edge detection, optical flow, image segmentation , image de-noising, image recognition, and object detection. The fractional derivatives ensure noise resilience and can preserve both high and low-frequency components of an image. The relative similarity of neighboring pixels can get affected by an error, noise, or non–homogeneous illumination in an image. In that case, the fractional differentiation can model special similarities and help compensate for the issue suitably. The fractional derivatives can be evaluated for discontinuous functions, which help estimate discontinuous optical flow. The order of the differentiation also provides an additional degree of freedom in the optimization process. This study shows the successful implementations of fractional calculus in computer vision and contributes to bringing out challenges and future scopes.},
  archive      = {J_NEUCOM},
  author       = {Sugandha Arora and Trilok Mathur and Shivi Agarwal and Kamlesh Tiwari and Phalguni Gupta},
  doi          = {10.1016/j.neucom.2021.10.122},
  journal      = {Neurocomputing},
  pages        = {407-428},
  shortjournal = {Neurocomputing},
  title        = {Applications of fractional calculus in computer vision: A survey},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on dendritic neuron model: Mechanisms, algorithms
and practical applications. <em>NEUCOM</em>, <em>489</em>, 390–406. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on dendrites has been conducted for decades, providing valuable information for the development of dendritic computation. Creating an ideal neuron model is crucial for computer science and may also provide robust guidance for understanding our brain’s underlying mechanisms and principles. This paper aims to review the related studies regarding a newly emerging, non-spiking and biologically inspired model, the dendritic neuron model (DNM). By mimicking the biological phenomena of neurons in vivo, the DNM incorporates a neural pruning scheme to eliminate superfluous synapses and dendrites, simplifying its architecture and forming unique neuron morphology for a specific task. Furthermore, the simplified structure can be transformed into logic circuits consisting of the comparators and logic AND, OR and NOT gates, without sacrificing model accuracy. The rapidity of binary operations in hardware implementation gives the DNM a distinct advantage to handle high-speed data streams. The advent of the big data era has led to an exponential explosion in the amount and variety of available information. The appealing properties of the DNM lead us to believe that it is worthy of more attention and that it might be a promising data mining technique . This article presents an in-depth analysis of the pruning and transformation mechanisms and a comprehensive review of the learning algorithms and real-world applications of the DNM. It also presents an empirical comparison of the optimization performance of different algorithms. Finally, we outline some critical issues and future works of the DNM. All the source code of DNM is available at http://www.dnm.net.cn/ .},
  archive      = {J_NEUCOM},
  author       = {Junkai Ji and Cheng Tang and Jiajun Zhao and Zheng Tang and Yuki Todo},
  doi          = {10.1016/j.neucom.2021.08.153},
  journal      = {Neurocomputing},
  pages        = {390-406},
  shortjournal = {Neurocomputing},
  title        = {A survey on dendritic neuron model: Mechanisms, algorithms and practical applications},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive dense pyramid network for object detection in UAV
imagery. <em>NEUCOM</em>, <em>489</em>, 377–389. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in Unmanned Aerial Vehicle (UAV) imagery has a wide variety of applications in both military and civilian fields. As UAV images are usually captured from flexible perspectives, with multiple altitudes, containing objects in various sizes and scales, such characteristics bring huge challenges to the object detection task. To address this issue, we develop a novel Adaptive Dense Pyramid Network (ADPN) that integrates congested scene analysis , aiming to incorporate the object distribution information into the object detection workflow without introducing additional annotations. We also design a creative Pyramid Density Module (PDM) for adaptive density prediction. The proposed ADPN incorporates the PDM and Object Detection Module (ODM) in a parallel manner to facilitate the feature alignment between density information and instance recognition. Our method can be applied to existing detection algorithms , and experimental results demonstrate the effectiveness and robustness of ADPN, and ADPN is able to improve detection accuracy on challenging datasets.},
  archive      = {J_NEUCOM},
  author       = {Ruiqian Zhang and Zhenfeng Shao and Xiao Huang and Jiaming Wang and Yufeng Wang and Deren Li},
  doi          = {10.1016/j.neucom.2022.03.033},
  journal      = {Neurocomputing},
  pages        = {377-389},
  shortjournal = {Neurocomputing},
  title        = {Adaptive dense pyramid network for object detection in UAV imagery},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Study on fast speed fractional order gradient descent
method and its application in neural networks. <em>NEUCOM</em>,
<em>489</em>, 366–376. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a novel fractional order gradient descent method for the quadratic loss function . Based on Riemann-Liouville definition, a more practical fractional order gradient descent method with variable initial value is proposed to ensure convergence to the actual extremum. On this basis, the random weight particle swarm optimization algorithm is introduced to select the appropriate initial value, which not only accelerates the convergence speed, but also enhances the global convergence ability of the algorithm. To avoid complicated problems of the chain rule in fractional calculus, the parameters of output layers is trained by the new designed method, while the parameters of hidden layers still use the conventional method. By selecting proper hyper-parameters, the proposed method shows faster convergence speed than others. Finally, numerical examples are given to verify that the proposed algorithm has fast convergence speed and high accuracy under a adequate large number of independent runs.},
  archive      = {J_NEUCOM},
  author       = {Yong Wang and Yuli He and Zhiguang Zhu},
  doi          = {10.1016/j.neucom.2022.02.034},
  journal      = {Neurocomputing},
  pages        = {366-376},
  shortjournal = {Neurocomputing},
  title        = {Study on fast speed fractional order gradient descent method and its application in neural networks},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3D human motion prediction: A survey. <em>NEUCOM</em>,
<em>489</em>, 345–365. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D human motion prediction, predicting future poses from a given sequence, is an issue of great significance and challenge in computer vision and machine intelligence , which can help machines in understanding human behaviors . Due to the increasing development and understanding of Deep Neural Networks (DNNs) and the availability of large-scale human motion datasets, the human motion prediction has been remarkably advanced with a surge of interest among academia and industrial community. In this context, a comprehensive survey on 3D human motion prediction is conducted for the purpose of retrospecting and analyzing relevant works from existing released literature. In addition, a pertinent taxonomy is constructed to categorize these existing approaches for 3D human motion prediction. In this survey, relevant methods are categorized into three categories: human pose representation , network structure design , and prediction target . We systematically review all relevant journal and conference papers in the field of human motion prediction since 2015, which are presented in detail based on proposed categorizations in this survey. Furthermore, the outline for the public benchmark datasets, evaluation criteria, and performance comparisons are respectively presented in this paper. The limitations of the state-of-the-art methods are discussed as well, hoping for paving the way for future explorations.},
  archive      = {J_NEUCOM},
  author       = {Kedi Lyu and Haipeng Chen and Zhenguang Liu and Beiqi Zhang and Ruili Wang},
  doi          = {10.1016/j.neucom.2022.02.045},
  journal      = {Neurocomputing},
  pages        = {345-365},
  shortjournal = {Neurocomputing},
  title        = {3D human motion prediction: A survey},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ABL-TC: A lightweight design for network traffic
classification empowered by deep learning. <em>NEUCOM</em>,
<em>489</em>, 333–344. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network traffic classification is an increasingly significant prerequisite for network management. An accurate traffic classifier can contribute to traffic engineering, traffic intrusion detection and user behavior analysis. Recently, deep learning (DL) has attracted considerable attention for traffic classification due to its excellent learning ability without the need for handcrafted feature engineering or privacy invasion. However, most DL-based traffic classification solutions mainly focus on improving the identification performance, with no regard for the computational and memory burden caused by a large model size or data redundancy . Motivated by the above gaps, we elaborate on the preprocessing of raw traffic data and investigate a lightweight traffic classifier. Specifically, we design a preprocessing approach to convert raw traffic data into available datasets for deep learning based traffic classifiers, which tailors raw traffic data as training datasets by resolving its structure and content and pruning redundant information. Thanks to its ability to focus on key information, attention mechanism is introduced to design an attention-based long short-term memory (LSTM) model for traffic classification, termed the ABL-TC. ABL-TC can effectively identify global dependencies between the input and the output with a limited number of important raw features, which can contribute to learning key information to identify various traffic types. Extensive experiments on real-world public datasets show that the ABL-TC outperforms state-of-the-art approaches in terms of various metrics for recognizing traffic categories while remaining competitive in terms of time and memory efficiency.},
  archive      = {J_NEUCOM},
  author       = {Wenting Wei and Huaxi Gu and Wenshuai Deng and Zhe Xiao and Xinming Ren},
  doi          = {10.1016/j.neucom.2022.03.007},
  journal      = {Neurocomputing},
  pages        = {333-344},
  shortjournal = {Neurocomputing},
  title        = {ABL-TC: A lightweight design for network traffic classification empowered by deep learning},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SuperCoder: Program learning under noisy conditions from
superposition of states. <em>NEUCOM</em>, <em>489</em>, 323–332. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method of program learning in a Domain Specific Language (DSL) which is based on gradient descent with no direct search. The first component of our method is a probabilistic representation of the DSL variables. At each timestep in the program sequence, different DSL functions are applied on the DSL variables with a certain probability, leading to different possible outcomes. Rather than handling all these outputs separately, whose number grows exponentially with each timestep, we collect them into a superposition of variables which captures the information in a single, but fuzzy, state. This state is to be contrasted at the final timestep with the ground-truth output, through a loss function. The second component of our method is an attention-based recurrent neural network , which provides an appropriate initialization point for the gradient descent that optimizes the probabilistic representation. The method we have developed surpasses the state-of-the-art for synthesising long programs and is able to learn programs under noise.},
  archive      = {J_NEUCOM},
  author       = {Ali Davody and Mahmoud Safari and Răzvan V. Florian},
  doi          = {10.1016/j.neucom.2022.03.011},
  journal      = {Neurocomputing},
  pages        = {323-332},
  shortjournal = {Neurocomputing},
  title        = {SuperCoder: Program learning under noisy conditions from superposition of states},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A differential evolution with adaptive neighborhood mutation
and local search for multi-modal optimization. <em>NEUCOM</em>,
<em>489</em>, 309–322. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive neighborhood mutation based memetic differential evolution is proposed for multimodal optimization. In the proposed method, an adaptive neighborhood mutation (ANM) strategy is devised to allow the individuals to conduct a diverse search at the early stage of evolution and then gradually switch to an intensive search at the later stage of evolution. Further, the ANM is devised such that encouraging promising individuals for exploitation while unpromising individuals for exploration during evolution to appropriate search the multimodal space. In addition, an adaptive Gaussian based local search strategy, which considers the difference between the offspring and their paired individuals with successful replacements, is developed to appropriately improve promising individuals during evolution. The proposed method has been extensively accessed on a suite of twenty multimodal benchmark functions and the performance of which is compared with sixteen related multimodal algorithms. The results clearly demonstrate the superiority of proposed method as well as the merit of devised strategies.},
  archive      = {J_NEUCOM},
  author       = {Mengmeng Sheng and Shengyong Chen and Weibo Liu and Jiafa Mao and Xiaohui Liu},
  doi          = {10.1016/j.neucom.2022.03.013},
  journal      = {Neurocomputing},
  pages        = {309-322},
  shortjournal = {Neurocomputing},
  title        = {A differential evolution with adaptive neighborhood mutation and local search for multi-modal optimization},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Groundwater level prediction using machine learning models:
A comprehensive review. <em>NEUCOM</em>, <em>489</em>, 271–308. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing accurate soft computing methods for groundwater level (GWL) forecasting is essential for enhancing the planning and management of water resources. Over the past two decades, significant progress has been made in GWL prediction using machine learning (ML) models. Several review articles have been published, reporting the advances in this field up to 2018. However, the existing review articles do not cover several aspects of GWL simulations using ML, which are significant for scientists and practitioners working in hydrology and water resource management. The current review article aims to provide a clear understanding of the state-of-the-art ML models implemented for GWL modeling and the milestones achieved in this domain. The review includes all of the types of ML models employed for GWL modeling from 2008 to 2020 (138 articles) and summarizes the details of the reviewed papers, including the types of models, data span, time scale, input and output parameters, performance criteria used, and the best models identified. Furthermore, recommendations for possible future research directions to improve the accuracy of GWL prediction models and enhance the related knowledge are outlined.},
  archive      = {J_NEUCOM},
  author       = {Hai Tao and Mohammed Majeed Hameed and Haydar Abdulameer Marhoon and Mohammad Zounemat-Kermani and Salim Heddam and Sungwon Kim and Sadeq Oleiwi Sulaiman and Mou Leong Tan and Zulfaqar Sa’adi and Ali Danandeh Mehr and Mohammed Falah Allawi and S.I. Abba and Jasni Mohamad Zain and Mayadah W. Falah and Mehdi Jamei and Neeraj Dhanraj Bokde and Maryam Bayatvarkeshi and Mustafa Al-Mukhtar and Suraj Kumar Bhagat and Tiyasha Tiyasha and Khaled Mohamed Khedher and Nadhir Al-Ansari and Shamsuddin Shahid and Zaher Mundher Yaseen},
  doi          = {10.1016/j.neucom.2022.03.014},
  journal      = {Neurocomputing},
  pages        = {271-308},
  shortjournal = {Neurocomputing},
  title        = {Groundwater level prediction using machine learning models: A comprehensive review},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning-based perception systems for autonomous
driving: A comprehensive survey. <em>NEUCOM</em>, <em>489</em>, 255–270.
(<a href="https://doi.org/10.1016/j.neucom.2021.08.155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of society and the economy, autonomous driving techniques are widely applied in many areas, such as autonomous vehicles, autonomous drones, and robotics. As a dominating technique, deep learning has become more and more popular for 2-D and 3-D object detection. Numerous deep learning-based methods have been proposed to solve various vision issues. To further help with the development of unmanned systems, this paper presents a comprehensive survey of the recent processes from the past five years for 3-D object detection, road detection , traffic sign detection, and traffic light detection and classification. To summarize and analyze previous works in detail, this paper only focuses on deep learning-based object detection tasks in autonomous driving that take place when the input is a point cloud or image(s). It also presents comparative results for insight comparison and inspiring future researches.},
  archive      = {J_NEUCOM},
  author       = {Li-Hua Wen and Kang-Hyun Jo},
  doi          = {10.1016/j.neucom.2021.08.155},
  journal      = {Neurocomputing},
  pages        = {255-270},
  shortjournal = {Neurocomputing},
  title        = {Deep learning-based perception systems for autonomous driving: A comprehensive survey},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transfer learning for medical images analyses: A survey.
<em>NEUCOM</em>, <em>489</em>, 230–254. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of deep learning has brought great change to the community of computer science and also revitalized numerous fields where traditional machine learning methods failed to make breakthroughs. Benefitted from the development of deep learning, analysis of medical images, which used to be a challenging yet exhausting task carried out manually by physicians, has experienced fast development as well. However, training deep learning models in these systems for analysis from scratch can be quite challenging. The small-scale data can’t guarantee the performance of the developed systems, while large-scale data is usually unavailable due to expensive costs in the process of collection and storage. To allow a fast transition from one domain to another for reuse, experts and researchers have extensively delved transfer learning , which turns out to be an efficient and low-cost learning technique. In this paper, we will present a comprehensive survey of transfer learning on medical image analysis. The imaging modalities include but not limits to Computed Tomography (CT), Ultrasound (US), and Magnetic Resonance Imaging (MRI). The subjects covered in this paper include the brain, breast, lung, kidney, etc. Besides, this survey provides systematic knowledge about deep learning and transfer learning for beginners. Readers with different backgrounds can easily catch up with the interdisciplinary knowledge and new trends of transfer learning via this survey.},
  archive      = {J_NEUCOM},
  author       = {Xiang Yu and Jian Wang and Qing-Qi Hong and Raja Teku and Shui-Hua Wang and Yu-Dong Zhang},
  doi          = {10.1016/j.neucom.2021.08.159},
  journal      = {Neurocomputing},
  pages        = {230-254},
  shortjournal = {Neurocomputing},
  title        = {Transfer learning for medical images analyses: A survey},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of artificial immune algorithms for multi-objective
optimization. <em>NEUCOM</em>, <em>489</em>, 211–229. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective immune algorithm (MOIA) is a heuristic algorithm based on artificial immune system model. Due to its characteristics of antibody clonal selection , automatic antigen recognition and immune memory in the immune system, artificial immune algorithm has become a research hotspot in the field of multi-objective optimization after the evolutionary algorithms . In this paper, most MOIAs can be classified into three main categories according to the type of problem solving, i.e., they are mostly designed to solve multi-objective optimization problems (MOPs), dynamic MOPs, and constrained MOPs. In this paper, a comprehensive survey is presented to summarize most existing MOIAs, in which their corresponding characteristics, principles and theoretical analyses are discussed in details. Moreover, the performance of MOIAs on solving various kinds of MOPs and many-objective optimization problems is also studied in our experimental comparisons. Finally, a brief conclusion is given to summarize the current drawbacks, challenges, and some future directions for MOIAs.},
  archive      = {J_NEUCOM},
  author       = {Lingjie Li and Qiuzhen Lin and Zhong Ming},
  doi          = {10.1016/j.neucom.2021.08.154},
  journal      = {Neurocomputing},
  pages        = {211-229},
  shortjournal = {Neurocomputing},
  title        = {A survey of artificial immune algorithms for multi-objective optimization},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Echo state network with logistic mapping and bias dropout
for time series prediction. <em>NEUCOM</em>, <em>489</em>, 196–210. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An echo state network (ESN) is a special structure of a recurrent neural network in which the recurrent neurons are randomly connected. ESN models that have achieved high accuracy on time series prediction tasks can be utilized as time series prediction models in many fields. Nevertheless, in most ESN models, the input weights are irregularly generated and the reservoir layer units are generally redundant, which cannot guarantee that the ESN models will always be optimal for a given task. In this paper, a novel ESN model that combines logistic mapping (LM) and bias dropout (BD) algorithms is proposed to optimize the irregular input weight matrix and generate a superior and simpler reservoir. Initially, the initial input weight matrix of ESN is replaced by an LM input weight matrix that is generated by the recurrent LM algorithm . Meanwhile, the reservoir, which can convert the input space into a high-dimensional feature space, is formed by the input signals and the LM input weight matrix. Then, the units with low activation values that are determined by a reservoir dropout probability are discarded through the BD algorithm. The dropout probability is determined by the contributions of the reservoir units to the training performance. Three multivariable benchmark tasks and four univariate real-world time series tasks indicate that the proposed LM-BD-ESN model is effective in reducing the testing time, reservoir size, and model complexity while improving the performance of the traditional ESN.},
  archive      = {J_NEUCOM},
  author       = {Heshan Wang and Yuxi Liu and Peng Lu and Yong Luo and Dongshu Wang and Xiangyang Xu},
  doi          = {10.1016/j.neucom.2022.03.018},
  journal      = {Neurocomputing},
  pages        = {196-210},
  shortjournal = {Neurocomputing},
  title        = {Echo state network with logistic mapping and bias dropout for time series prediction},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Few-shot image classification with composite rotation based
self-supervised auxiliary task. <em>NEUCOM</em>, <em>489</em>, 179–195.
(<a href="https://doi.org/10.1016/j.neucom.2022.02.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-life problem settings have classes of data with very few examples for training. Deep learning networks do not perform well for such few-shot classes. In order to perform well in this setting, the networks should learn to extract highly discriminative and generic features. In this paper, we propose to use a composite rotation based self-supervised auxiliary task to improve the representation learning of the network so that it can extract such discriminative features . Our proposed composite rotation based auxiliary task rotates the image at two levels, i.e., it rotates patches inside the image (inner rotation) and also rotates the whole image (outer rotation), and assigns one out of 16 rotation classes to the transformed image. We jointly train the network on the main image classification task and the composite rotation based auxiliary task. This helps the network to learn to extract more generic and discriminative features , which in turn helps to improve its few-shot classification performance. Additionally, during the few-shot testing phase, we consolidate the predictions for images obtained by applying different composite rotation transformations to the same query image to improve the final prediction further. We perform experiments on several few-shot benchmark datasets and empirically show the efficacy of our method for various problem settings. We experimentally show that our method improves the performance of deep learning models on the few-shot classification, fine-grained few-shot classification, cross-domain few-shot classification, and transductive few-shot classification settings. We also experimentally show that models trained using our approach perform better than the baseline even when the query examples in the episode are not aligned with the support examples in the episode. We perform extensive ablation experiments to validate the different components of our approach. We also analyze the effect of our approach on the ability of the network to focus on the discriminative regions of the image.},
  archive      = {J_NEUCOM},
  author       = {Pratik Mazumder and Pravendra Singh and Vinay P. Namboodiri},
  doi          = {10.1016/j.neucom.2022.02.044},
  journal      = {Neurocomputing},
  pages        = {179-195},
  shortjournal = {Neurocomputing},
  title        = {Few-shot image classification with composite rotation based self-supervised auxiliary task},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient convolutional networks learning through irregular
convolutional kernels. <em>NEUCOM</em>, <em>489</em>, 167–178. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As deep neural networks are increasingly used in applications suited for low-power devices, a fundamental dilemma emerges: the trend is to develop models to use the increasing amount of data, resulting in memory-intensive models; however, low-power devices have very limited memory and cannot store large models. Parameters pruning is critical for deep model deployment on low-power devices. Existing efforts mainly focus on designing highly efficient structures or pruning redundant connections in networks. They are typically sensitive to the tasks or rely on dedicated and expensive hashing storage strategies. In this work, we introduce a novel approach to achieve a lightweight model from the perspective of reconstructing the structure of convolution kernels for efficient storage. Our approach transforms a traditional square convolution kernel into line segments, and automatically learns a proper strategy for equipping these line segments to model diverse features. Experimental results show that our approach can significantly reduce the number of parameters (pruned 69\% on DenseNet-40) and calculation costs (pruned 59\% on DenseNet-40) while maintaining acceptable performance (only lose less than 2\% accuracy).},
  archive      = {J_NEUCOM},
  author       = {Weiyu Guo and Jiabin Ma and Yidong Ouyang and Liang Wang and Yongzhen Huang},
  doi          = {10.1016/j.neucom.2022.02.065},
  journal      = {Neurocomputing},
  pages        = {167-178},
  shortjournal = {Neurocomputing},
  title        = {Efficient convolutional networks learning through irregular convolutional kernels},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human-behavior learning: A new complementary learning
perspective for optimal decision making controllers. <em>NEUCOM</em>,
<em>489</em>, 157–166. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reviews an almost new method for the design of optimal decision making controllers named as Human-Behavior learning. This new paradigm is inspired by the complementary learning that different areas of the human brain have to improve learning and experience transference. It is shown that independent and well identified sources of knowledge can enhance learning and facilitate the design of the optimal decision making controller. This interaction is modelled as a Markov Decision Process defined by a tuple of actions, cognitions, and emotions sets. Existing methods of both control and reinforcement learning theories are reviewed and connected to complete the behavior learning picture for a class of linear systems.},
  archive      = {J_NEUCOM},
  author       = {Adolfo Perrusquía},
  doi          = {10.1016/j.neucom.2022.03.036},
  journal      = {Neurocomputing},
  pages        = {157-166},
  shortjournal = {Neurocomputing},
  title        = {Human-behavior learning: A new complementary learning perspective for optimal decision making controllers},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Designing efficient convolutional neural network structure:
A survey. <em>NEUCOM</em>, <em>489</em>, 139–156. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a powerful machine learning method, deep learning has attracted the attention of numerous researchers. While exploring a high-performance neural network model, the floating-point operations of a neural network model are also increasing. In recent years, many researchers have noticed that efficiency is also one of important indicators to measure the property of neural network models. Obviously, the efficient neural network model is more helpful to deploy on mobile and embedded devices. Therefore, the efficient neural network model becomes a hot research spot. In this paper, we review the methods related to the structural design of efficient convolution neural networks in recent years. According to the characteristics of these methods, we divide them into three kinds of methods: model pruning, efficient architecture, and neural architecture search. Detailed analyses of each method are presented to demonstrate their advantages and disadvantages. Then, we comprehensively compare them in detail and propose many suggestions about the design of the efficient convolution neural network model structure. Inspired by these suggestions, we built a new efficient neural network model, SharedNet. And the SharedNet obtains the best accuracy of manually-designed efficient CNN models on the ImageNet dataset.},
  archive      = {J_NEUCOM},
  author       = {Jian-Xun Mi and Jie Feng and Ke-Yang Huang},
  doi          = {10.1016/j.neucom.2021.08.158},
  journal      = {Neurocomputing},
  pages        = {139-156},
  shortjournal = {Neurocomputing},
  title        = {Designing efficient convolutional neural network structure: A survey},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-resolution optical flow and frame-recurrent network for
video super-resolution and deblurring. <em>NEUCOM</em>, <em>489</em>,
128–138. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last years, advances in deep learning have brought huge developments to the studying of super-resolution reconstruction. However, most super-resolution methods only deal with simply down-sampled sharp images, which may lose efficacy when encountering severe blur. The severe motion blur caused by the rapid movement of an object or the large shake of the lens is common in video captured by cameras. However, existing super-resolution algorithms often bring a large amount of artifacts and are difficult to achieve satisfactory results when reconstructing such blurred video sequences. In this paper, a novel convolutional neural network is proposed that jointly processes video super-resolution (SR) and deblurring (DB) to deal with severe motion blur and recover sharp high-resolution (HR) frames. In particular, a pyramid optical flow module is introduced to estimate the sharp latent image in the blurred frame and generate HR optical flow in a coarse-to-fine way. Then, the frame-recurrent is used to warp the previous SR frame to achieve motion compensation and make full use of the previous sharp features and temporal information to help restoration of the subsequent frames. Next, to further overcome the destruction caused by motion blur in the final reconstruction, a parallel-fusion module was designed to extract and fuse the SR and DB features, finally reconstructing the output frame. Experimental results obtained in this study confirm that, compared with other advanced SR algorithms, the proposed method is both effective and efficient in dealing with videos that contain real motion blur.},
  archive      = {J_NEUCOM},
  author       = {Ning Fang and Zongqian Zhan},
  doi          = {10.1016/j.neucom.2022.02.067},
  journal      = {Neurocomputing},
  pages        = {128-138},
  shortjournal = {Neurocomputing},
  title        = {High-resolution optical flow and frame-recurrent network for video super-resolution and deblurring},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Penalty based robust learning with noisy labels.
<em>NEUCOM</em>, <em>489</em>, 112–127. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In general, deep neural network is vulnerable to noisy labels also known as erroneous labels. As a main solution to mitigate this problem, sample selection techniques have been actively studied. However, if the labels are dominantly corrupted by some classes (these noisy samples are called dominant noisy labeled samples), the network also learns dominant noisy labeled samples rapidly via content-aware optimization. This can cause memorization (reduce generalization) in the deep neural network. In this study, we propose a compelling criteria to penalize dominant-noisy-labeled samples intensively through class-wise penalty labels. By averaging prediction confidences for the each observed label, we obtain suitable penalty labels that have high values if the labels are largely corrupted by some classes. Additionally, to enhance the accuracy of penalty labels, temporal ensembling and weight are exploited. Experiments were performed using benchmarks (CIFAR-10, CIFAR-100, Tiny-ImageNet) and real-world datasets (ANIMAL-10 N, Clothing1M) to evaluate the proposed criteria in various scenarios with different noise rates. Using the proposed sample selection, the learning process of the network becomes significantly robust to noisy labels compared to existing methods in several noise types. Moreover, the proposed criteria can be easily combined with the algorithms of loss correction and hybrid categories through a simple modification to improve learning performance.},
  archive      = {J_NEUCOM},
  author       = {Kyeongbo Kong and Junggi Lee and Youngchul Kwak and Young-Rae Cho and Seong-Eun Kim and Woo-Jin Song},
  doi          = {10.1016/j.neucom.2022.02.030},
  journal      = {Neurocomputing},
  pages        = {112-127},
  shortjournal = {Neurocomputing},
  title        = {Penalty based robust learning with noisy labels},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel image super-resolution algorithm based on
multi-scale dense recursive fusion network. <em>NEUCOM</em>,
<em>489</em>, 98–111. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing maturity of convolution neural network (CNN) technology, the image super-resolution reconstruction (SR) method based on CNN is booming and has achieved many remarkable results. Undoubtedly, SR has become the mainstream direction of image reconstruction technology. However, most of the existing SR methods improve the reconstruction performance by increasing the depth of networks, which also increases the number of parameters, number of network computations, and difficulty of training network. To solve the performance complexity dilemma in SR, this paper proposes a network called a multi-scale dense recursive fusion network (MSDRFN). The network is composed of three parts: initial feature extraction module, multi-scale dense fusion group module and recursive reconstruction module. In detail, rough features are first extracted through a shallow feature extraction module, and then are inputted into multi-scale dense fusion blocks (MSDFBs) group. Each MSDFB makes full use of image features in convolution kernels of different sizes to obtain different hierarchical features, and further these output features are inputted into the channel attention mechanism to learn their corresponding weights. All MSDFBs outputs will be restored to high resolution images via the recursive reconstruction module. In addition, the network supplements the information loss with residual learning, which is embodied in one long-jump connection and several short-jump connections. The proposed network is mainly trained in the Pytorch deep learning framework. In comparison experiments on benchmark datasets, the proposed method outperformed the most advanced convolutional methods.},
  archive      = {J_NEUCOM},
  author       = {Xiang Lv and Changzhong Wang and Xiaodong Fan and Qiangkui Leng and Xiaoli Jiang},
  doi          = {10.1016/j.neucom.2022.02.042},
  journal      = {Neurocomputing},
  pages        = {98-111},
  shortjournal = {Neurocomputing},
  title        = {A novel image super-resolution algorithm based on multi-scale dense recursive fusion network},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A modified projection neural network with fixed-time
convergence. <em>NEUCOM</em>, <em>489</em>, 90–97. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a modified projection neural network (PNN) with fixed-time convergence to solve the nonlinear projection equations. Under the assumptions of Lipschitz continuity and strict monotonicity, the existence of the solution and the stability in the Lyapunov sense of the proposed modified PNN are proved, which guarantee the convergence in fixed time. The convergence time of the proposed PNN has an upper bound which is independent ofarbitrary initial conditions. Compared with other existing PNN,the presented modified PNN can also solve the non-smooth, nonlinear, and constrained convex optimization problems . In the final step, the numerical simulations demonstrate that the presented modified PNN has a faster convergence rate and gets a more precise solution than the existing methods.},
  archive      = {J_NEUCOM},
  author       = {Dengzhou Hu and Xing He and Xingxing Ju},
  doi          = {10.1016/j.neucom.2022.03.023},
  journal      = {Neurocomputing},
  pages        = {90-97},
  shortjournal = {Neurocomputing},
  title        = {A modified projection neural network with fixed-time convergence},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). WheatNet: A lightweight convolutional neural network for
high-throughput image-based wheat head detection and counting.
<em>NEUCOM</em>, <em>489</em>, 78–89. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a globally recognized plant breeding organization, manually recorded field observation data is crucial for plant breeding decision making. However, certain phenotypic traits such as plant color, height, kernel counts, etc. can only be recorded during a specific time-window of a crop’s growth cycle. Due to labor-intensive requirements, only a small subset of possible field observations are recorded each season. To help mitigate this data collection bottleneck in wheat breeding, we propose a novel deep learning framework to accurately and efficiently count wheat heads to aid in the gathering of real-time data for decision making. We call our model WheatNet and show that our approach is robust and accurate for a wide range of environmental conditions of the wheat field. WheatNet uses a truncated MobileNetV2 as a lightweight backbone feature extractor which merges feature maps with different scales to counter image scale variations. Then, extracted multi-scale features go to two parallel sub-networks for simultaneous density-based counting and localization tasks. The proposed method uses only point-level annotations for both counting and localization which is less labor-intensive compared to box-level annotations. Our proposed method achieves an MAE and RMSE of 3.85 and 5.19 in our wheat head counting task, respectively, while having significantly fewer parameters when compared to other state-of-the-art methods. Our experiments and comparisons with other state-of-the-art methods demonstrate the superiority and effectiveness of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Saeed Khaki and Nima Safaei and Hieu Pham and Lizhi Wang},
  doi          = {10.1016/j.neucom.2022.03.017},
  journal      = {Neurocomputing},
  pages        = {78-89},
  shortjournal = {Neurocomputing},
  title        = {WheatNet: A lightweight convolutional neural network for high-throughput image-based wheat head detection and counting},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data augmentation guided knowledge distillation for
environmental sound classification. <em>NEUCOM</em>, <em>489</em>,
59–77. (<a href="https://doi.org/10.1016/j.neucom.2022.03.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environmental sound classification (ESC) is an increasingly relevant field of research in recent years but has high computational overhead in its classification of environmental sounds. Knowledge distillation (KD) is a prominent technique to develop a lightweight deep model by distilling knowledge from a heavyweight model into a less computationally complex model. Generally, conventional KD techniques require manual setting of a temperature parameter to explore the similarity among the classes. Herein, we propose a novel data augmentation technique that creates an augmented data instance by blending hidden features of a data sample from one class with a style information (mean and standard values) of a data sample from another class. We have designed a new loss function to accomplish Knowledge Distillation that minimizes Kullback–Leibler (KL) divergence loss between class probabilities obtained from the teacher and student networks while classifying the augmented data sample. Furthermore, the proposed KD technique rids the process of a temperature parameter that needs to be set manually by the traditional vanilla KD technique. Our experiments on two benchmark ESC datasets i.e., the ESC-10 and DCASE 2019 Task-1(A) dataset demonstrate comparable performance of the student network to state-of-the-art techniques. Moreover, the student model is explainable and clearly explains why a signal is classified into a specific class.},
  archive      = {J_NEUCOM},
  author       = {Achyut Mani Tripathi and Konark Paul},
  doi          = {10.1016/j.neucom.2022.03.025},
  journal      = {Neurocomputing},
  pages        = {59-77},
  shortjournal = {Neurocomputing},
  title        = {Data augmentation guided knowledge distillation for environmental sound classification},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A method for support neuron selection in NMLI.
<em>NEUCOM</em>, <em>489</em>, 52–58. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By simulating the neural mechanism of cognition, NMLI (Neural Model with Lateral Interaction) was recently proposed for learning tasks. It can realize both supervised and unsupervised learning while achieving outstanding results on few-shot learning. Obeying Hebbian rules and the one-to-one correspondence between elementary neurons and samples, the number of inter-level connections in NMLI is consistent with the number of training samples. This forming mechanism, however, would result in huge computation when the training set is large. Inspired by the fact that neurons in the human brain are sparsely connected, as well as the related cognition phenomena, we propose a method for support neuron selection in NMLI. We first evaluate the validity of the inter-level connections. Based on the evaluation, only a few parts of elementary neurons are selected as support neurons, corresponding to the typical and special samples in the training set. Then, by considering only the support neurons, NMLI can form spares inter-level connections. In this way, the computational efficiency and the biological reasonability of the model are significantly improved. In addition, the proposed method adjusts neuronal connections according to prediction error, implying that back-propagation (BP) mechanism can be realized by synaptic plasticity . Experiments show that the proposed method reduced the test time of NMLI while maintaining accuracy. Furthermore, it shows the potential to improve the efficiency of other neural models.},
  archive      = {J_NEUCOM},
  author       = {Ziyan Qin and Jigen Peng and Deqaun Jin},
  doi          = {10.1016/j.neucom.2022.03.030},
  journal      = {Neurocomputing},
  pages        = {52-58},
  shortjournal = {Neurocomputing},
  title        = {A method for support neuron selection in NMLI},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Video super-resolution with inverse recurrent net and hybrid
local fusion. <em>NEUCOM</em>, <em>489</em>, 40–51. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video super-resolution converts low-resolution videos to sharp high-resolution ones. In order to make better use of temporal information in video super-resolution, we design inverse recurrent net and hybrid local fusion. We concatenate the original low-resolution input sequence and its inverse sequence repeatedly. The new sequence is viewed as a combination of different stages, and is processed sequentially by using orent net. The outputs of the last two stages in opposite directions are fused to generate the final images. Our inverse recurrent net can extract more bidirectional temporal information in the input sequence, without adding parameter to the corresponding unidirectional recurrent net. We also propose a hybrid local fusion method which uses parallel fusion and cascade fusion for incorporating sliding-window-based methods into our inverse recurrent net. Extensive experimental results demonstrate the effectiveness of the proposed inverse recurrent net and hybrid local fusion, in terms of visual quality and quantitative evaluations . The code will be released at https://github.com/5ofwind .},
  archive      = {J_NEUCOM},
  author       = {Dingyi Li and Zengfu Wang and Jian Yang},
  doi          = {10.1016/j.neucom.2022.03.019},
  journal      = {Neurocomputing},
  pages        = {40-51},
  shortjournal = {Neurocomputing},
  title        = {Video super-resolution with inverse recurrent net and hybrid local fusion},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis methods of coronary artery intravascular images: A
review. <em>NEUCOM</em>, <em>489</em>, 27–39. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronary artery disease is among one of the diseases human suffer most. Intravascular coronary arterial image analysis consists of denoising , segmentation, detection, and three-dimensional reconstruction, having a significant meaning for auxiliary diagnosis and treatment of coronary artery disease. Intravascular ultrasound (IVUS) and intravascular optical coherence tomography (IVOCT) are the two most commonly applied intravascular coronary arterial imaging techniques. Based on these fundamental imaging techniques, in recent years, many advanced technologies from traditional machine learning algorithms to deep learning methods were employed in the analysis of intravascular coronary arterial images and made huge progress in this field. In this survey, we reviewed more than one hundred papers published in top journals or conferences such as Neural Networks and MICCAI. These papers proposed approaches or schemes for the intravascular coronary arterial image analysis, including lumen border segmentation, atherosclerotic plaque characterization, media-adventitia segmentation, stent strut detection, and three-dimensional reconstruction. Our survey began with introducing coronary artery intravascular imaging techniques, essential neural networks, and deep learning and then presented an across-the-board review of methods, applications, and trends of intravascular image analysis. This survey is more comprehensive than other articles not only for its scope and reference number but also for discussing the future direction in this field. Compared to other review papers in this field, this article could assist beginners in constructing a basic knowledge frame of coronary artery intravascular image analysis methods and brought state-of-the-art progress in this field to fellow researchers. We hope this paper could benefit either the beginners for coronary arterial image analysis or experienced researchers.},
  archive      = {J_NEUCOM},
  author       = {Chenxi Huang and Jian Wang and Qiang Xie and Yu-Dong Zhang},
  doi          = {10.1016/j.neucom.2021.10.124},
  journal      = {Neurocomputing},
  pages        = {27-39},
  shortjournal = {Neurocomputing},
  title        = {Analysis methods of coronary artery intravascular images: A review},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). WITHDRAWN: Semi-supervised segmentation of echocardiography
videos via noise-resilient spatiotemporal semantic calibration and
fusion. <em>NEUCOM</em>, <em>489</em>, 18–26. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Publisher regrets that this article is an accidental duplication of an article that has already been published in Medical Image Analysis, 78 (2022) 102397, https://doi.org/10.1016/j.media.2022.102397 . The duplicate article has therefore been withdrawn. The full Elsevier Policy on Article Withdrawal can be found at ( https://www.elsevier.com/about/our-business/policies/article-withdrawal ).},
  archive      = {J_NEUCOM},
  author       = {Huisi Wu and Jiasheng Liu and Fangyan Xiao and Zhenkun Wen and Lan Cheng and Jing Qin},
  doi          = {10.1016/j.neucom.2022.03.022},
  journal      = {Neurocomputing},
  pages        = {18-26},
  shortjournal = {Neurocomputing},
  title        = {WITHDRAWN: Semi-supervised segmentation of echocardiography videos via noise-resilient spatiotemporal semantic calibration and fusion},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Aspect-based sentiment analysis with component focusing
multi-head co-attention networks. <em>NEUCOM</em>, <em>489</em>, 9–17.
(<a href="https://doi.org/10.1016/j.neucom.2022.03.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User-generated content based on customer opinions and experience has become a rich source of valuable information for enterprises. The purpose of aspect-based sentiment analysis is to predict the sentiment polarity of specific targets from user-generated content. This study proposes a component focusing multi-head co-attention network model which contains three modules: extended context, component focusing, and multi-headed co-attention, designed to improve upon problems encountered in the past. The extended context module improves the ability of bidirectional encoder representations from transformers to handle aspect-based sentiment analysis tasks, and the component focusing module improves the weighting of adjectives and adverbs, to alleviate the problem of average pooling , which treats every word as an equally important term. The multi-head co-attention network is applied to learn the important words in a multi-word target before acquiring the context representation and performs the attention mechanism on the sequence data. The performance of the proposed model is evaluated in extensive experiments on publicly available datasets. The results show that the performance of the proposed model is better than that of the recent state-of-the-art models.},
  archive      = {J_NEUCOM},
  author       = {Li-Chen Cheng and Yen-Liang Chen and Yuan-Yu Liao},
  doi          = {10.1016/j.neucom.2022.03.027},
  journal      = {Neurocomputing},
  pages        = {9-17},
  shortjournal = {Neurocomputing},
  title        = {Aspect-based sentiment analysis with component focusing multi-head co-attention networks},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ideal kernel tuning: Fast and scalable selection of the
radial basis kernel spread for support vector classification.
<em>NEUCOM</em>, <em>489</em>, 1–8. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A simple and fast method, named ideal kernel tuning, is proposed to select the radial basis kernel spread of the support vector machine for classification. The spread is selected directly from data, without any training nor test, in order to bring the kernel matrix nearer to the ideal kernel matrix, with values one for patterns of the same class and zero otherwise. To avoid scaling with the training set size, the kernel matrix is calculated for a small set of class prototypes. The selected spread can be used also for multi-class classification problems considering the two most populated classes. Compared to other 5 popular tuning algorithms , the proposed approach is a smart and efficient strategy whose performance is very near to the state-of-the-art, is 2–4 orders of magnitude faster and requires very little memory, scales better with the dataset size both in time and memory, and is able to classify medium-size datasets up to 70,000 training patterns, where other methods fail.},
  archive      = {J_NEUCOM},
  author       = {Ziad Akram-Ali-Hammouri and Manuel Fernández-Delgado and Audi Albtoush and Eva Cernadas and Senén Barro},
  doi          = {10.1016/j.neucom.2022.03.034},
  journal      = {Neurocomputing},
  pages        = {1-8},
  shortjournal = {Neurocomputing},
  title        = {Ideal kernel tuning: Fast and scalable selection of the radial basis kernel spread for support vector classification},
  volume       = {489},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generating training images with different angles by GAN for
improving grocery product image recognition. <em>NEUCOM</em>,
<em>488</em>, 694–705. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image recognition based on deep learning methods has gained remarkable achievements by feeding with abundant training data. Unfortunately, collecting a tremendous amount of annotated images is time-consuming and expensive, especially in grocery product recognition tasks. It is challenging to recognise grocery products accurately when the deep learning model is trained with insufficient data. This paper proposes multi-angle Generative Adversarial Networks (MAGAN), which can generate realistic training images with different angles for data augmentation . Mutual information is employed in the novel GAN to achieve the learning of angles in an unsupervised manner . This paper aims to create training images containing grocery products from different angles, thus improving grocery product recognition accuracy. We first enlarge the fruit dataset by using MAGAN and the state-of-the-art GAN variants. Then, we compare the top-1 accuracy results from CNN classifiers trained with different data augmentation methods. Finally, our experiments demonstrate that the MAGAN exceeds the existing GANs for grocery product recognition tasks, obtaining a significant increase in the accuracy.},
  archive      = {J_NEUCOM},
  author       = {Yuchen Wei and Shuxiang Xu and Byeong Kang and Sabera Hoque},
  doi          = {10.1016/j.neucom.2021.11.080},
  journal      = {Neurocomputing},
  pages        = {694-705},
  shortjournal = {Neurocomputing},
  title        = {Generating training images with different angles by GAN for improving grocery product image recognition},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Delay-induced periodic oscillation for fractional-order
neural networks with mixed delays. <em>NEUCOM</em>, <em>488</em>,
681–693. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is mainly devoted to the investigation on the stability and Hopf bifurcation of fractional-order neural networks with mixed delays. Applying a suitable substitution of variable, a novel equivalent fractional-order neural networks concerning single delay is set up. By analyzing the corresponding characteristic equation of the involved fractional-order delayed neural networks and choosing the time delay as bifurcation parameter , we derive a new sufficient condition to guarantee the stability behavior and the appearance of Hopf bifurcation for the considered fractional-order delayed neural networks. The study reveals that the time delay is a key factor which has a vital impact on stability and Hopf bifurcation of neural networks. The obtained results of this work can be effectively applied to design neural networks. The numerical simulations and bifurcation diagrams are displayed to verify the rationality of the analytical results.},
  archive      = {J_NEUCOM},
  author       = {Changjin Xu and Wei Zhang and Zixin Liu and Lingyun Yao},
  doi          = {10.1016/j.neucom.2021.11.079},
  journal      = {Neurocomputing},
  pages        = {681-693},
  shortjournal = {Neurocomputing},
  title        = {Delay-induced periodic oscillation for fractional-order neural networks with mixed delays},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Off-policy algorithm based hierarchical optimal control for
completely unknown dynamic systems. <em>NEUCOM</em>, <em>488</em>,
669–680. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an online reinforcement learning(RL) for solving Stackelberg games with completely unknown dynamic systems. To deal with the hierarchical optimal control problem , the key is to find the solution of a two-level optimal control with the leader’s optimal problem being constrained. Firstly, the leader–follower coupled Hamiltonian-Jacobi(HJ) equations subject to the follower’s costate equation is derived. Secondly, an off-policy scheme is designed following the policy iteration(PI) algorithm based on model. The improved off-policy algorithm is given for obtaining the solution to the leader–follower coupled HJ equations. The algorithm is built without requiring any knowledge of the dynamic system, and the leader–follower optimal control policies are directly constructed by the extracted data. Meanwhile, the existence of the Stackelberg equilibrium is demonstrated. Lastly, NNs for each player are built, and NN learning is accomplished online with Kronecker product technique and vectorization , which simples the NN form and could decrease computation burden. Simulation examples are presented to demonstrate the proposed learning algorithm.},
  archive      = {J_NEUCOM},
  author       = {Xiaohong Cui and Jiayu Chen and Binrui Wang and Suan Xu},
  doi          = {10.1016/j.neucom.2021.11.077},
  journal      = {Neurocomputing},
  pages        = {669-680},
  shortjournal = {Neurocomputing},
  title        = {Off-policy algorithm based hierarchical optimal control for completely unknown dynamic systems},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generative adversarial network based cerebrovascular
segmentation for time-of-flight magnetic resonance angiography image.
<em>NEUCOM</em>, <em>488</em>, 657–668. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate segmentation of cerebral vessels from time-of-flight magnetic resonance angiography (TOF-MRA) data is crucial for the diagnosis and treatment of cerebrovascular diseases . However, cerebrovascular segmentation remains challenging due to the tiny and complex structure of the vessels. This paper proposed a GAN-based deep-based method that maps the TOF-MRA data to 3D cerebral vessels. To improve the capability of feature expression, the proposed network integrates squeeze-and-excite blocks into a Vnet structure to extract and accumulate features at different scales. In addition, we introduce adversarial loss for network training, which can help the model to learn the distribution of the cerebral vessels. Besides, we introduce island number and minimum diameter to evaluate the spatial consistency and recognized minimal vessel of the cerebrovascular segmentation results. The proposed method is validated on 102 TOF-MRA cases with manually annotated labels. The experimental results indicate that our method can identify more tiny cerebral vessels meanwhile maintaining the spatial consistency of the cerebral vessel structure. Besides, our GAN-based cerebrovascular segmentation method reaches an average dice similar coefficient of 89.89\% 89.89\% , outperforming other state-of-the-art segmentation methods.},
  archive      = {J_NEUCOM},
  author       = {Zan Chen and Lei Xie and Yukai Chen and Qingrun Zeng and Qichuan ZhuGe and Jiakai Shen and Caiyun Wen and Yuanjing Feng},
  doi          = {10.1016/j.neucom.2021.11.075},
  journal      = {Neurocomputing},
  pages        = {657-668},
  shortjournal = {Neurocomputing},
  title        = {Generative adversarial network based cerebrovascular segmentation for time-of-flight magnetic resonance angiography image},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Advertising impression resource allocation strategy with
multi-level budget constraint DQN in real-time bidding. <em>NEUCOM</em>,
<em>488</em>, 647–656. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to allocate advertising impressions under budget constraint is one of the leading research issues in Real-Time Bidding (RTB). Traditional methods are mostly grounded on ‘the highest bidder rule’ to optimize revenues of AD Exchange (ADX), which causes Demand Side Platforms (DSPs) to over-consume budget in the early stage and eventually lead to bad revenue of all trading parties. In addition, the long auction sequence in large-scale RTB environments may also bring challenges to existing algorithms. To those problems, we propose a Multi-Level Budget Constraint DQN (MLBC-DQN) framework, which divides the long sequence in RTB environment into several short sequence environments with different budgets’ level and use a deep Q network (DQN) to learn optimal strategy for environments of each level. The final strategy to interact with the original RTB environment of MLBC-DQN is weighted by strategies of all DQNs mentioned above. By weighing various strategies from different perspectives, an MLBC-DQN agent can quickly learn effective strategies to overcome the over-consume budget problem. We evaluate MLBC-DQN in two datasets comparing with traditional allocation strategies and DQN . Results show that the MLBC-DQN can achieve higher revenues of DSPs without prejudice to the income of ADX, and promote the marketing effect of advertising resources.},
  archive      = {J_NEUCOM},
  author       = {Chengwei Zhang and Kangjie Zheng and Yu Tian and Wanli Xue and Tianpei Yang and Dou An and Yongqi Pi and Rong Chen},
  doi          = {10.1016/j.neucom.2021.11.072},
  journal      = {Neurocomputing},
  pages        = {647-656},
  shortjournal = {Neurocomputing},
  title        = {Advertising impression resource allocation strategy with multi-level budget constraint DQN in real-time bidding},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-supervised learning of monocular depth using quantized
networks. <em>NEUCOM</em>, <em>488</em>, 634–646. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning monocular depth in a self-supervised manner is desirable for numerous applications ranging from autonomous driving , robotics to augmented reality . However, the current challenges lie in the problems of scale ambiguity, dynamic scene and hardware limitations. To this end, a self-supervised approach is proposed in this work for monocular depth learning and estimation. Specifically, we first introduce a self-supervised depth learning framework that learns a part of the camera intrinsics and the stereo extrinsics, which ensures the absoluteness of the predicted depth while achieving enhanced performance (i.e., lower error between the predicted depth and the ground-truth) on depth estimation. Besides, we further improve the accuracy and the efficiency (i.e., shorter inference time and lower weight/activation footprints) via a specially-designed network that exploits multi-scale context across multi-level feature maps. In addition, we propose a quantization scheme for our depth estimation networks. The scheme allows the network inference to be carried out using INT4-INT8 arithmetic while keeping a high performance on depth estimation. Extensive experiments on KITTI and Make3D datasets demonstrate that our approach substantially boosts the performance compared to the existing state-of-the-art methods on monocular depth estimation.},
  archive      = {J_NEUCOM},
  author       = {Keyu Lu and Chengyi Zeng and Yonghu Zeng},
  doi          = {10.1016/j.neucom.2021.11.071},
  journal      = {Neurocomputing},
  pages        = {634-646},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised learning of monocular depth using quantized networks},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fault detection and diagnosis with a novel source-aware
autoencoder and deep residual neural network. <em>NEUCOM</em>,
<em>488</em>, 618–633. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capability of deep learning (DL) techniques for dealing with non-linear, dynamic and correlated data has paved the way for DL-based fault detection and diagnosis (FDD). Among them, autoencoders (AEs) have shown their potential to serve as the fault detection network. However, misclassifying faulty samples that share similar patterns to normal samples is a common drawback of AEs. In this work, a source-aware autoencoder (SAAE) is proposed as an extension of AEs to incorporate faulty samples in the training stage. In SAAE, flexibility in tuning recall and precision trade-off, ability to detect unseen faults and applicability in imbalanced data sets are achieved. Bidirectional long short-term memory (BiLSTM) with skip connections SAAE is designed as the structure of the fault detection network. Further, a deep network with BiLSTM and residual neural network (ResNet) is proposed for the subsequent fault diagnosis step to avoid randomness imposed by the order of the input features. A framework for combining fault detection and fault diagnosis networks is also presented without the assumption of having a perfect fault detection network. A comprehensive comparison among relevant existing techniques in the literature and SAAE-ResNet is also conducted on the Tennessee-Eastman process, which shows the superiority of the proposed FDD method.},
  archive      = {J_NEUCOM},
  author       = {Nima Amini and Qinqin Zhu},
  doi          = {10.1016/j.neucom.2021.11.067},
  journal      = {Neurocomputing},
  pages        = {618-633},
  shortjournal = {Neurocomputing},
  title        = {Fault detection and diagnosis with a novel source-aware autoencoder and deep residual neural network},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Does aggression lead to hate? Detecting and reasoning
offensive traits in hinglish code-mixed texts. <em>NEUCOM</em>,
<em>488</em>, 598–617. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aggression is a prominent trait of human beings that can affect social harmony in a negative way. The hate mongers misuse the freedom of speech in social media platforms to flood with their venomous comments in many forms. Identifying different traits of online offense is thus inevitable and the need of the hour. Existing studies usually handle one or two offense traits at a time, mainly due to the lack of a combined annotated dataset and a scientific study that provides insights into the relationship among the traits. In this paper, we study the relationship among five offense traits – aggression , hate , sarcasm , humor , and stance in Hinglish (Hindi-English) social media code-mixed texts. We employ various state-of-the-art deep learning systems at different morphological granularities for the classification across five offense traits. Our evaluation of the unified framework suggests ∼ 90\% ∼90\% performance across all major traits. Furthermore, we propose a novel notion of causal importance score to quantify the effect of different abusive keywords and the overall context on the offensiveness of the texts.},
  archive      = {J_NEUCOM},
  author       = {Ayan Sengupta and Sourabh Kumar Bhattacharjee and Md. Shad Akhtar and Tanmoy Chakraborty},
  doi          = {10.1016/j.neucom.2021.11.053},
  journal      = {Neurocomputing},
  pages        = {598-617},
  shortjournal = {Neurocomputing},
  title        = {Does aggression lead to hate? detecting and reasoning offensive traits in hinglish code-mixed texts},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A buffered online transfer learning algorithm with
multi-layer network. <em>NEUCOM</em>, <em>488</em>, 581–597. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online transfer learning (OTL) has attracted much attention in recent years. It is designed to handle the transfer learning tasks, where the data of the target domain isn’t available in advance but may arrive in an online manner, which may be a more realistic scenario in practice. However, there typically are two limitations of existing OTL algorithms. 1) Existing OTL algorithms are based on shallow online learning models (SOLMs), e.g., linear or kernel models. Due to this limitation of SOLMs they cannot effectively learn complex nonlinear functions in complicated application and the OTL algorithms based on SOLMs cannot either. 2) Existing algorithms only utilize the latest arrived instance to adjust the model. In this way, the previously arrived instances are not utilized. It may be better to utilize the previously arrived instances as well. In this paper, to overcome the abovementioned two limitations, a buffered online transfer learning (BOTL) algorithm is proposed. In the proposed BOTL algorithm, the learner is designed as a deep learning model , referred to as Online Hedge Neural Network (OHNN). In order to enable the OHNN to be effectively learned in an online manner, we propose a buffered online learning framework that utilizes several previously arrived instances to assist learning. Further, to enhance the performance of the OHNN, a model learned in the source domain is transferred to the target domain. The regret bound of the proposed BOTL algorithm is analyzed theoretically. Experimental results on realistic datasets illustrate that the proposed BOTL algorithm can achieve lower mistake rate than the algorithms compared.},
  archive      = {J_NEUCOM},
  author       = {Zhongfeng Kang and Bo Yang and Mads Nielsen and Lihui Deng and Shantian Yang},
  doi          = {10.1016/j.neucom.2021.11.066},
  journal      = {Neurocomputing},
  pages        = {581-597},
  shortjournal = {Neurocomputing},
  title        = {A buffered online transfer learning algorithm with multi-layer network},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint neighborhood preserving and projected clustering for
feature extraction. <em>NEUCOM</em>, <em>488</em>, 572–580. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood reconstruction is proved effective for dimensionality reduction because of the preservation of manifold structure. Conventional neighborhood preserving embedding (NPE) method first learns the affinity relationship or reconstruction relationship in the original space, and then learns the projection matrix to preserve the learned local information in low-dimensional space. However, the pre-learned manifold information may be inaccurate due to the noises and irrelevant features in real-world data. The performance of dimensionality reduction would be influenced as well. Besides, NPE and its variants only aim to preserve the local reconstruction relationship but ignore the fuzzy membership relationship between samples and cluster prototypes . To address these issues, we propose an adaptive neighborhood preserving discriminant projection model, where sparse reconstruction coefficients are updated in the process of dimensionality reduction to eliminate the influence of noises and irrelevant features. Meanwhile, we also learn the fuzzy membership relationships between data points and cluster prototypes to gather the samples belonging to the same class together in low-dimensional space. Neighborhood reconstruction learning and clustering are seamlessly connected in the learned subspace. To solve this model, an iterative algorithm is developed. The experimental results of recognition accuracy show the superiorities of the proposed methods over the state-of-the-arts.},
  archive      = {J_NEUCOM},
  author       = {Jing An and Xiaowei Zhao and Mei Shi and Xiaoxia Liu and Jun Guo},
  doi          = {10.1016/j.neucom.2021.11.065},
  journal      = {Neurocomputing},
  pages        = {572-580},
  shortjournal = {Neurocomputing},
  title        = {Joint neighborhood preserving and projected clustering for feature extraction},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning based trust- and tag-aware recommender
system. <em>NEUCOM</em>, <em>488</em>, 557–571. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are popular tools used in many applications, such as e-commerce, e-learning, and social networks to help users select their desired items. Collaborative filtering is a widely used recommendation technique that employs previous ratings of users to predict their future interests. Lack of sufficient ratings often reduces the performance of collaborative filtering recommendation methods. Additional side resources, such as trust relationships and tag information can be employed to enhance the recommendation accuracy. However, trust and tag data are often heavily sparse as users mainly provide insufficient information about these side resources. Moreover, such additional resources have generally large dimensions which result in increasing the computational complexity of recommendation models in calculating similarity values. To cope with these problems, a new recommendation model is proposed that utilizes deep neural networks to model the representation of trust relationships and tag information. To this end, a sparse autoencoder is used to extract latent features from user-user trust relationships and user-tag matrices. Then, the extracted latent features are utilized to calculate similarity values between users, which are then used to form the nearest neighbors of the target user and predict unseen items. The proposed method can tackle the data sparsity problem and reduce the computational complexity of recommender systems as the extracted latent features have smaller dimensions in comparison to the original data. Experimental results on two benchmark datasets reveal the effectiveness of the proposed method and show its outperformance over state-of-the-art recommender systems.},
  archive      = {J_NEUCOM},
  author       = {Sajad Ahmadian and Milad Ahmadian and Mahdi Jalili},
  doi          = {10.1016/j.neucom.2021.11.064},
  journal      = {Neurocomputing},
  pages        = {557-571},
  shortjournal = {Neurocomputing},
  title        = {A deep learning based trust- and tag-aware recommender system},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RANet: A relation-aware network for two-view correspondence
learning. <em>NEUCOM</em>, <em>488</em>, 547–556. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding true correspondences from a set of putative correspondences is a basic task in computer vision. Recent advances have demonstrated that Multi Layer Perceptrons (MLPs) can handle the unordered correspondence learning problem by training a deep classifier. However, MLPs ignore the relationship between correspondences, such as geometric information , spatial information and inlier distribution information, which will lead to difficulties in modeling complex global context. To solve this issue, we propose a Relation-Aware Network (RANet), by capturing rich global information from channel and spatial dimensions, to establish reliable correspondences for feature matching. Specifically, we firstly present a Global Context Attention block by a two-branch attention structure to cooperate with MLPs for contextual information extraction. Then, we design a Relation-Aware Filter block by further exploring the channel and spatial relationship information with different connection manners. Finally, we combine two blocks to obtain an enhanced basic block with strong feature representation capacity due to the acquisition of global contextual information. Our experiments have been conducted over both indoor and outdoor datasets on the tasks of outlier removal and camera pose estimation, which demonstrate the superiority of our network that achieves the best performance compared with the state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Guorong Lin and Xin Liu and Fangfang Lin and Guobao Xiao and Jiayi Ma},
  doi          = {10.1016/j.neucom.2021.11.063},
  journal      = {Neurocomputing},
  pages        = {547-556},
  shortjournal = {Neurocomputing},
  title        = {RANet: A relation-aware network for two-view correspondence learning},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An upper bound on the variance of scalar multilayer
perceptrons for log-concave distributions. <em>NEUCOM</em>,
<em>488</em>, 540–546. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we give an upper bound on the variance of scalar multilayer perceptrons . The distribution of the input is assumed to be the class of log-concave distributions, which includes the well-known Gaussian distribution. The activation functions of the scalar multilayer perceptrons are assumed to be differentiable and Lipschitz continuous.},
  archive      = {J_NEUCOM},
  author       = {Aydin Sarraf and Saeed Khalili},
  doi          = {10.1016/j.neucom.2021.11.062},
  journal      = {Neurocomputing},
  pages        = {540-546},
  shortjournal = {Neurocomputing},
  title        = {An upper bound on the variance of scalar multilayer perceptrons for log-concave distributions},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). VMAT dose prediction in radiotherapy by using progressive
refinement UNet. <em>NEUCOM</em>, <em>488</em>, 528–539. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of dose distribution in volumetric modulated arc therapy (VMAT) plays a curial role in radiotherapy. Accurate VMAT dose prediction for prostate cancer is always a great challenge because of the complexity of the VMAT dose distributions and the low contrast of the organs and tissues in the male pelvic CT images. In this paper, a novel progressive refinement UNet (PRUNet) with rank loss is proposed to address the aforementioned problem. On the one hand, the proposed PRUNet extends the traditional UNet with a novel progressive refinement module to generate more realistic dose distributions. The progressive refinement module generates multiple dose predictions with different resolutions in one forward pass and refines the dose prediction with predicted details at finer levels from lower resolution to higher resolution. On the other hand, it turns out that the dosimetric metrics are sensitive to the order relation among the dose values in dose distributions. A new rank loss function is proposed to optimize the similarity between the order relations among the dose values in dose predictions and that in real dose distributions. The proposed PRUNet is trained in a multi-task framework to jointly learn the dose distribution and the order relation among dose values. To evaluate the performance of the proposed PRUNet, the VMAT dose distributions and anatomical information of 64 prostate cancer patients are collected. The proposed model generates more accurate dose distributions with better quantitative dosimetric metrics than the state of the art UNet models do.},
  archive      = {J_NEUCOM},
  author       = {Jianyong Wang and Junjie Hu and Ying Song and Qiang Wang and Xiaozhi Zhang and Sen Bai and Zhang Yi},
  doi          = {10.1016/j.neucom.2021.11.061},
  journal      = {Neurocomputing},
  pages        = {528-539},
  shortjournal = {Neurocomputing},
  title        = {VMAT dose prediction in radiotherapy by using progressive refinement UNet},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Guided filter random walk and improved spiking cortical
model based image fusion method in NSST domain. <em>NEUCOM</em>,
<em>488</em>, 509–527. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image fusion has become a hot issue in the field of information processing . In this paper, a novel image fusion method based on guided filter random walk and improved spiking cortical model (ISCM) in non-subsampled shearlet transform (NSST) is presented. The core process is composed of three steps. Firstly, the source images to be fused are decomposed into the low-frequency parts and high-frequency parts via NSST. Then, two models including guided filter and random walk are combined to complete the fusion of low-frequency sub-images. As for the fusion of the high-frequency parts, the traditional spiking cortical model is improved to be ISCM to capture and fuse the details information of the source images. Finally, the fused image can be obtained by inverse NSST. In order to verify the effectiveness of the proposed method, lots of datasets with different categories are selected as the source images to conduct the simulation experiments. Experimental results demonstrate that the proposed method own obvious superiorities over the representative ones in terms of both subjective visual performance and objective evaluation data.},
  archive      = {J_NEUCOM},
  author       = {Weiwei Kong and Qiguang Miao and Yang Lei and Cong Ren},
  doi          = {10.1016/j.neucom.2021.11.060},
  journal      = {Neurocomputing},
  pages        = {509-527},
  shortjournal = {Neurocomputing},
  title        = {Guided filter random walk and improved spiking cortical model based image fusion method in NSST domain},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on data integration for multi-omics sample
clustering. <em>NEUCOM</em>, <em>488</em>, 494–508. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the current high availability of omics, data-driven biology has greatly expanded, and several papers have reviewed state-of-the-art technologies. Nowadays, two main types of investigation are available for a multi-omics dataset: extraction of relevant features for a meaningful biological interpretation and clustering of the samples. In the latter case, a few reviews refer to some outdated or no longer available methods, whereas others lack the description of relevant clustering metrics to compare the main approaches. This work provides a general overview of the major techniques in this area, divided into four groups: graph, dimensionality reduction, statistical and neural-based. Besides, eight tools have been tested both on a synthetic and a real biological dataset. An extensive performance comparison has been provided using four clustering evaluation scores: Peak Signal-to-Noise Ratio (PSNR), Davies-Bouldin(DB) index, Silhouette value and the harmonic mean of cluster purity and efficiency. The best results were obtained by using the dimensionality reduction, either explicitly or implicitly, as in the neural architecture.},
  archive      = {J_NEUCOM},
  author       = {Marta Lovino and Vincenzo Randazzo and Gabriele Ciravegna and Pietro Barbiero and Elisa Ficarra and Giansalvo Cirrincione},
  doi          = {10.1016/j.neucom.2021.11.094},
  journal      = {Neurocomputing},
  pages        = {494-508},
  shortjournal = {Neurocomputing},
  title        = {A survey on data integration for multi-omics sample clustering},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). An overview of edge and object contour detection.
<em>NEUCOM</em>, <em>488</em>, 470–493. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In computer vision, edge and object contour detection is essential for higher-level vision tasks, such as shape matching, visual salience, image segmentation , and object recognition. It has attracted much attention during the past several decades, and many excellent methods have been proposed. In this paper, we make a comprehensive introduction to representative edge and object contour detection methods in the past two decades. Based on the development of these methods, we mainly classify them into two categories: traditional methods and learning-based methods. We further divide traditional methods into local pattern methods, edge grouping methods, active contour models , and bio-inspired methods. Further, we divide learning-based methods into classical learning-based methods and deep learning-based methods. At the same time, we introduce the most popular benchmarks and evaluation measures and quantitatively compare the performances of these promising methods. Moreover, we discuss current challenges in edge and object contour detection and suggest some future trends to bridge gaps with human vision. We believe that this overview will benefit newcomers and promote the development of edge and object contour detection.},
  archive      = {J_NEUCOM},
  author       = {Daipeng Yang and Bo Peng and Zaid Al-Huda and Asad Malik and Donghai Zhai},
  doi          = {10.1016/j.neucom.2022.02.079},
  journal      = {Neurocomputing},
  pages        = {470-493},
  shortjournal = {Neurocomputing},
  title        = {An overview of edge and object contour detection},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparison and ensemble of 2D and 3D approaches for COVID-19
detection in CT images. <em>NEUCOM</em>, <em>488</em>, 457–469. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting COVID-19 in computed tomography (CT) or radiography images has been proposed as a supplement to the RT-PCR test. We compare slice-based (2D) and volume-based (3D) approaches to this problem and propose a deep learning ensemble, called IST-CovNet, combining the best 2D and 3D systems with novel preprocessing and attention modules and the use of a bidirectional Long Short-Term Memory model for combining slice-level decisions. The proposed ensemble obtains 90.80\% accuracy and 0.95 AUC score overall on the newly collected IST-C dataset in detecting COVID-19 among normal controls and other types of lung pathologies; and 93.69\% accuracy and 0.99 AUC score on the publicly available MosMedData dataset that consists of COVID-19 scans and normal controls only. The system also obtains state-of-art results (90.16\% accuracy and 0.94 AUC) on the COVID-CT-MD dataset which is only used for testing. The system is deployed at Istanbul University Cerrahpaşa School of Medicine where it is used to automatically screen CT scans of patients, while waiting for RT-PCR tests or radiologist evaluation.},
  archive      = {J_NEUCOM},
  author       = {Sara Atito Ali Ahmed and Mehmet Can Yavuz and Mehmet Umut Şen and Fatih Gülşen and Onur Tutar and Bora Korkmazer and Cesur Samancı and Sabri Şirolu and Rauf Hamid and Ali Ergun Eryürekli and Toghrul Mammadov and Berrin Yanikoglu},
  doi          = {10.1016/j.neucom.2022.02.018},
  journal      = {Neurocomputing},
  pages        = {457-469},
  shortjournal = {Neurocomputing},
  title        = {Comparison and ensemble of 2D and 3D approaches for COVID-19 detection in CT images},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Discrete-time future nonlinear neural optimization with
equality constraint based on ten-instant ZTD formula. <em>NEUCOM</em>,
<em>488</em>, 444–456. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to facilitate practical applications, discrete-time future nonlinear neural optimization with equality constraint (DFNNOEC) is investigated. First, starting from the continuous time-varying nonlinear neural optimization with equality constraint (CTNNOEC), continuous time-varying ZNN (CTZNN) models are derived by using Zhang neural network (ZNN) method. Then, a new ten-instant Zhang time discretization (TZTD) formula with high precision is presented to develop discrete algorithms for solving DFNNOEC problem in real time. Subsequently, two ten-instant discrete-time future ZNN (TDFZNN) algorithms are developed by utilizing TZTD formula to discretize CTZNN models. In addition, theoretical analyses expound the validity of TDFZNN algorithms. Finally, experiments of a numerical example and computer simulations on UR5 manipulator are carried out to confirm the effectiveness and superiority of TDFZNN algorithms. At the same time, computer simulation and physical experiment on Kinova Jaco2 manipulator further substantiate the practicability of TDFZNN algorithms.},
  archive      = {J_NEUCOM},
  author       = {Keqi Wang and Tundong Liu and Yunong Zhang and Ning Tan},
  doi          = {10.1016/j.neucom.2022.03.010},
  journal      = {Neurocomputing},
  pages        = {444-456},
  shortjournal = {Neurocomputing},
  title        = {Discrete-time future nonlinear neural optimization with equality constraint based on ten-instant ZTD formula},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-hop interactive attention based classification network
for expert recommendation. <em>NEUCOM</em>, <em>488</em>, 436–443. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community question answering (CQA) is a popular platform where users can ask questions or solve the questions proposed by other users. The expert recommendation aims at providing high-quality answers for the newly proposed questions in time, which is the key to a successful CQA. Questions in CQA usually consist of two parts, a subject which describes the main point, and a body which gives the details of the question. In previous studies, researchers usually ignore the differences between the subject and the body and concatenate them as a whole. In this paper, we propose a multi-hop interactive attention based classification network (MIACN) to recommend experts for newly proposed questions. In our model, the subject and the body are seen as two separate parts. A multi-hop attention is used to capture the multiple latent interactions among the two parts. Then, a high-level representation of the question is generated from the interactions. Experiment results on two real-world datasets demonstrate the effectiveness of our model.},
  archive      = {J_NEUCOM},
  author       = {Lingfei Qian and Jian Wang and Hongfei Lin and Liang Yang and Yu Zhang},
  doi          = {10.1016/j.neucom.2022.02.033},
  journal      = {Neurocomputing},
  pages        = {436-443},
  shortjournal = {Neurocomputing},
  title        = {Multi-hop interactive attention based classification network for expert recommendation},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Relation-based global-partial feature learning network for
video-based person re-identification. <em>NEUCOM</em>, <em>488</em>,
424–435. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video-based person re-identification (Re-ID) aims to match the same pedestrian from the video sequences captured by non-overlapping cameras. It is the key to fully extracting abundant spatial and temporal information from the video frames in video-based Re-ID. In this paper, a novel Relation-Based Global-Partial Feature Learning framework is proposed to explore discriminative spatiotemporal features with the help of the global and partial relationship between frames. Specifically, we propose a Relation-Based Global Feature Learning Module (RGL) to obtain global references for generating features correlation maps between frames in the video sequence and determine the importance of frame-level features. As the supplementary of the global relation-based features, a Relation-Based Partial Feature Learning Module (RPL) is also proposed to obtain the relationship between partial features of the same spatial position in different frames to enhance the frame-level partial representation. Moreover, we design a multi-level training scheme to deeply supervise our model. Extensive experiments are conducted on three public video-based person Re-ID datasets, and the results indicate that our framework achieves state-of-the-art performance on three benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Fan Yang and Xiangtong Wang and Xuan Zhu and Binbin Liang and Wei Li},
  doi          = {10.1016/j.neucom.2022.03.032},
  journal      = {Neurocomputing},
  pages        = {424-435},
  shortjournal = {Neurocomputing},
  title        = {Relation-based global-partial feature learning network for video-based person re-identification},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Document-level event argument linking as machine reading
comprehension. <em>NEUCOM</em>, <em>488</em>, 414–423. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level event argument linking aims to find global event arguments to fill an event’s semantic role, which is a challenging task owing to the appearance of long contexts and the issue of data sparsity . In this paper, we study a new formulation to address the above challenges in document-level EAL, by explicitly framing the task as a machine reading comprehension (MRC) problem. In this formulation, argument extraction is viewed as a question answering procedure. To better transfer each semantic role into a question, we propose a back-translation based query generation method, which can effectively generate well-formed questions without adopting huge human effort. Moreover, to better capture the non-local dependencies between triggers and arguments, we devise a dependency-guided question answering process, which can explore the underlying structure of the document to boost learning. The extensive experiments on a benchmark have justified the effectiveness of our approach. Particularity, our approach achieves substantially improvement over previous methods, leading to +5.7\% in F1 in the full argument linking setting. Moreover, our approach is particular data-efficient and demonstrates superior performance in the data-low scenario with limited training data.},
  archive      = {J_NEUCOM},
  author       = {Jian Liu and Yufeng Chen and Jinan Xu},
  doi          = {10.1016/j.neucom.2022.03.016},
  journal      = {Neurocomputing},
  pages        = {414-423},
  shortjournal = {Neurocomputing},
  title        = {Document-level event argument linking as machine reading comprehension},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent development on intelligent computing.
<em>NEUCOM</em>, <em>488</em>, 412–413. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The articles appearing in this special issue on Recent Development on Intelligent Computing are extended versions of the papers presented at the 2020 Sixteenth International Conference on Intelligent Computing (ICIC2020) held on October 2–5, 2020, in Bari, Italy. All the papers included here have been thoroughly reviewed and revised with the support of many reviewers under the Elsevier Editorial System (EES). 19 papers representing less than five percent of all eligible papers accepted at the ICIC2020 are selected for inclusion in this special issue. The selected papers are organized into the following three sections.},
  archive      = {J_NEUCOM},
  author       = {De-Shuang Huang ( Guest Editor )},
  doi          = {10.1016/j.neucom.2022.01.097},
  journal      = {Neurocomputing},
  pages        = {412-413},
  shortjournal = {Neurocomputing},
  title        = {Recent development on intelligent computing},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fine tuning attribute weighted naive bayes. <em>NEUCOM</em>,
<em>488</em>, 402–411. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Naive Bayes (NB) is one of the top 10 data mining algorithms due to its simplicity, efficiency and efficacy. However, both the unrealistic attribute conditional independence assumption and the unreliable conditional probability estimation limit its performance. Of numerous improved approaches, attribute weighting only focuses on alleviating the unrealistic attribute conditional independence assumption, while fine tuning devotes all the efforts to finding a more reliable conditional probability estimation. In this study, we argue that both of them are equally important to enhance the performance of NB and propose a novel model called fine tuned attribute weighted NB (FTAWNB) by combining fine tuning with attribute weighting into a uniform framework. In FTAWNB, we first exploit correlation-based attribute weighting to initialize the conditional probabilities, then for each misclassified training instance, the conditional probabilities are fine tuned iteratively to make them more reliable, and the fine tuning process will stop once the training classification accuracy no longer improves. Extensive experimental results show that FTAWNB significantly outperforms all the other existing state-of-the-art competitors.},
  archive      = {J_NEUCOM},
  author       = {Huan Zhang and Liangxiao Jiang},
  doi          = {10.1016/j.neucom.2022.03.020},
  journal      = {Neurocomputing},
  pages        = {402-411},
  shortjournal = {Neurocomputing},
  title        = {Fine tuning attribute weighted naive bayes},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discrete-time ZNN-based noise-handling ten-instant algorithm
solving yang-baxter-like matrix equation with disturbances.
<em>NEUCOM</em>, <em>488</em>, 391–401. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-variant Yang-Baxter-like matrix equation (YBLME) with the disturbances of noises is the hotspot in various scientific disciplines. The existing research, either can not handle the noise, or rely on the build-in numerical algorithm provided by MATLAB. Therefore, it is necessary to further study the digital-computer discrete solution of this problem. In this paper, the authors propose a noise-handling ten-instant discrete solution for the time-variant YBLME. By defining the matrix-form error function, Zhang neural network (ZNN) is exploited to design the continuous-time noise-handling ZNN model. For potential digital hardware (i.e., digital computer) realization, a discrete-time ZNN-based noise-handling ten-instant (DTZNH10i) algorithm, which is capable of handling three types of noises, is proposed on the basis of a Zhang time discretization (ZTD) formula. The convergence and precision of the proposed DTZNH10i algorithm are investigated and discussed. Theoretical analyses show the correctness and effectiveness of the proposed algorithm. The paper offers three examples of time-variant YBLME with disturbances of constant, linear, and bounded random noises to illustrate the efficacy and convergence of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Dongqing Wu and Yunong Zhang},
  doi          = {10.1016/j.neucom.2022.02.068},
  journal      = {Neurocomputing},
  pages        = {391-401},
  shortjournal = {Neurocomputing},
  title        = {Discrete-time ZNN-based noise-handling ten-instant algorithm solving yang-baxter-like matrix equation with disturbances},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning soft threshold for sparse reparameterization using
gradual projection operators. <em>NEUCOM</em>, <em>488</em>, 381–390.
(<a href="https://doi.org/10.1016/j.neucom.2022.03.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have achieved great success in the field of computer vision in recent years. While being high-precision, the characteristic of over-parameterization impedes DNNs from being applied to lightweight devices. To obtain parameter-efficient networks, a large body of work based on uniform sparsity or heuristic non-uniform sparsity techniques has been explored. However, these sparsity techniques offer limited improvement in inference speed (FLOPs) and prediction accuracy. To make further progress, we propose a novel gradual projection operators (GPO) to learn the soft threshold for sparse reparameterization . GPO approaches the soft-threshold operator with a family of projection operators, which progressively reduces the gradient of weights to be pruned during training, to gently learn the pruning thresholds. Experiments on ImageNet show that ResNet-50 with the proposed training algorithm achieves 76.52\% top-1 validation accuracy at the sparsity 81.62\%, which has merely a 0.5\% accuracy gap to its dense counterpart. Additionally, the non-uniform budgets learned by GPO can reduce the FLOPs by up to 10\% compared to the state-of-the-arts, which is superior to the popular heuristics methods , thus yielding an effective mechanism for sparse reparameterization . 1},
  archive      = {J_NEUCOM},
  author       = {Xiaodong Wang and Xianxian Zeng and Yun Zhang and Dong Li and Weijun Yang},
  doi          = {10.1016/j.neucom.2022.03.009},
  journal      = {Neurocomputing},
  pages        = {381-390},
  shortjournal = {Neurocomputing},
  title        = {Learning soft threshold for sparse reparameterization using gradual projection operators},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SFNet: A slow feature extraction network for parallel linear
and nonlinear dynamic process monitoring. <em>NEUCOM</em>, <em>488</em>,
359–380. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a typical industrial process, there may exist both linear and nonlinear relationships among process variables. Besides, the existence of process dynamics poses challenges to process monitoring. Some monitoring methods have been developed for dynamic processes. However, purely linear or nonlinear methods can hardly tackle the hybrid linear and nonlinear relationships among process variables. In this work, a novel unsupervised neural network model, named slow feature network (SFNet), is proposed to monitor dynamic processes. In SFNet, a linear mapping module and a transform gate structure are constructed to realize the parallel extraction of linear and nonlinear characteristics. Moreover, slow constraints on features are designed to capture the velocity characteristics while retaining variability information so that the process dynamic behavior can be directly observed. Various statistics are developed to monitor the process status from both variability and velocity as well as both linear and nonlinear perspectives. Thus, monitoring results corresponding to different statistical information reflect different process behavior and fault characteristics with meaningful interpretations. One numerical example and two real industrial examples are adopted to validate the proposed method. For these experimental examples, the proposed SFNet method achieves an average false alarm rate of 5.17\% (min 0.8\%, max 8.08\%), an average detection accuracy of 87.5\% (min 50.2\%, max 100\%), and an average precision of 98.6\% (min 96.3\%, max 100\%), outperforming counterpart methods in the literature.},
  archive      = {J_NEUCOM},
  author       = {Pengyu Song and Chunhui Zhao and Biao Huang},
  doi          = {10.1016/j.neucom.2022.03.012},
  journal      = {Neurocomputing},
  pages        = {359-380},
  shortjournal = {Neurocomputing},
  title        = {SFNet: A slow feature extraction network for parallel linear and nonlinear dynamic process monitoring},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contour-guided saliency detection with long-range
interactions. <em>NEUCOM</em>, <em>488</em>, 345–358. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The guided search theory suggests that global sources of scenes are important for robust visual processing. In this study, we use an eye-tracking experiment to verify that contours play a crucial role in guiding visual attention. Moreover, the experimental data show that subjects pay more attention to the closed regions of line drawings, which are usually related to the dominant objects in the corresponding scenes. In addition, human attention is also guided by scene structure. Inspired by these findings, we designed two long-range selective pooling (LRSP) modules of convolutional neural networks to improve saliency detection by integrating long-range features. The proposed LRSP modules (including regional pooling and layout pooling modules) are inspired by the long-range interactions in the biological visual cortexes and are beneficial for capturing long-range information guided by contours. Extensive experiments show that the proposed method achieves comparable results to state-of-the-art methods, but with a more lightweight network structure. Moreover, benefiting from the contour guidance, the proposed model with long-range interactions demonstrates higher robustness and generalization in the saliency detection task compared with other methods.},
  archive      = {J_NEUCOM},
  author       = {Peng Peng and Kai-Fu Yang and Si-Qin Liang and Yong-Jie Li},
  doi          = {10.1016/j.neucom.2022.03.006},
  journal      = {Neurocomputing},
  pages        = {345-358},
  shortjournal = {Neurocomputing},
  title        = {Contour-guided saliency detection with long-range interactions},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ridge regression with adaptive additive rectangles and other
piecewise functional templates. <em>NEUCOM</em>, <em>488</em>, 328–344.
(<a href="https://doi.org/10.1016/j.neucom.2022.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a penalization algorithm for functional linear regression models, where the coefficient function β β is shrunk towards a data-driven shape template γ γ . To the best of our knowledge, we employ the nonzero centered L 2 L2 penalty in a novel manner, as the center of the penalty γ γ is also optimized while being constrained to belong to a class of piecewise functions Γ Γ , by restricting its basis expansion. This indirect penalization allows the user to control the overall shape of β β , by imposing his prior knowledge on γ γ through the definition of Γ Γ , without limiting the flexibility of the estimated model. In particular, we focus on the case where γ γ is expressed as a sum of q rectangles that are adaptively positioned with respect to the regression error. As the problem of finding the optimal knot placement of a piecewise function is nonconvex, we also propose a novel parametrization that allows to reduce the number of variables in the global optimization scheme, resulting in a fitting algorithm that alternates between approximating a suitable template and solving a convex ridge-like problem. The predictive power and interpretability of our method is shown on multiple simulations and two real world case studies.},
  archive      = {J_NEUCOM},
  author       = {Edoardo Belli and Simone Vantini},
  doi          = {10.1016/j.neucom.2022.03.003},
  journal      = {Neurocomputing},
  pages        = {328-344},
  shortjournal = {Neurocomputing},
  title        = {Ridge regression with adaptive additive rectangles and other piecewise functional templates},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A reliable solder joint inspection method based on a
light-weight point cloud network and modulated loss. <em>NEUCOM</em>,
<em>488</em>, 315–327. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-speed and high-reliability automated quality inspection is widely demanded in the electronics industry. Recently, deep learning theory combined with many non-destructive technologies shows superior performance for inspecting failed soldering. In this paper, a reliable point cloud learning based method is implemented for high-speed solder joint shape defect detection. First, a light-weight neural network named Solder PointNet (SPNet) is proposed. With local group attention mechanisms , SPNet avoids adverse effects of outliers in the scanning point cloud and finds favorable critical point feature adaptively. Then, a modulated loss is designed to ensure reliable low false detection rate. By adjusting the weights of cross-entropy loss, the predictive distribution of defective samples is guided to a smaller range, thereby setting an appropriate threshold to efficiently separate the predictive distribution . Furthermore, the proposed method is further trained and evaluated on the self built solder joint dataset DHU-PAD1000 of point cloud data. Comparison experiments are carried out on the built dataset , and the results show that SPNet achieves higher accuracy with fewer parameters, considerable speed advantage, and more reliable automated detection.},
  archive      = {J_NEUCOM},
  author       = {Haijian Li and Kuangrong Hao and Bing Wei and Xue-song Tang and Qiming Hu},
  doi          = {10.1016/j.neucom.2022.02.077},
  journal      = {Neurocomputing},
  pages        = {315-327},
  shortjournal = {Neurocomputing},
  title        = {A reliable solder joint inspection method based on a light-weight point cloud network and modulated loss},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature adaptation-based multipeak-redetection spatial-aware
correlation filter for object tracking. <em>NEUCOM</em>, <em>488</em>,
299–314. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual tracking has always been an important research topic in the field of computer vision. During tracking, cluttered backgrounds, deformations, and occasional occlusion inevitably cause unpredictable appearance changes in the target, making the task very challenging. Traditional methods often tackle this problem using fixed central region constraints, simple combinations of features and independent classifiers. However, existing constraints are not very accurate; the simple mechanism of combining features lacks descriptive robustness, and the independent classifiers require complex additional training. Therefore, in this paper, we propose a correlation filter tracker called the feature adaptation-based multipeak-redetection spatial-aware correlation filter (FMCF) to accurately track targets that often change in appearance. In this tracker, the correlation filter has a dynamic spatial constraint that effectively reduces the response of the filter to the cluttered background area. To address target deformation, a new feature adaptation-based training method is designed, and the final response is a combination of the correlation filter and an independent statistical color model. Finally, a multipeak-redetection scheme, which can find the missing targets within multiple peaks of the final response map, is proposed to handle occlusion . In particular, the statistical color model is employed in the spatial-aware filter construction, the final response calculation, and the multipeak-redetection procedure to improve the robustness of the tracker, because of its ability to generate pixel-level color probabilities. Extensive experimental results on public tracking datasets prove that our proposed tracker can perform better than state-of-the-art trackers. Moreover, compared to the baseline tracker, the precision rate and success rate of FMCF are increased by 6.5\% and 4.8\% on the OTB100 benchmark and by 12.7\% and 8.2\% on the TC128 benchmark, respectively.},
  archive      = {J_NEUCOM},
  author       = {Wanli Xing and Hong Zhang and Hao Chen and Yifan Yang and Ding Yuan},
  doi          = {10.1016/j.neucom.2022.02.072},
  journal      = {Neurocomputing},
  pages        = {299-314},
  shortjournal = {Neurocomputing},
  title        = {Feature adaptation-based multipeak-redetection spatial-aware correlation filter for object tracking},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Action-dependent bidirectional contrastive predictive coding
for neural belief representations. <em>NEUCOM</em>, <em>488</em>,
284–298. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key to solving the complex, partially observable Markov decision process (POMDP) with high-dimensional observations lies in explicit belief representations. However, the existing methods generally adopted the black-box model for shaping beliefs, which is inefficient and lacks interpretability. Due to this reason, the action-dependent bidirectional contrastive predictive coding (BCPC|Action) is proposed in this paper, in which the observation features are extracted efficiently through self-supervised contrastive learning. Owing to the bottleneck belief constraints in the bidirectional model, the upper bound of prediction errors is effectively reduced. Besides, the forward prediction is optimized by the guidance of an easier trainable backward prediction; thus, the bidirectional match regularization (BMR) could be derived for stabilizing the training process. More importantly, the interpretability of the learned belief representation is thoroughly explored based on the gradient truncation. Simulation results verify the effectiveness of the presented method; apart from achieving highly accurate belief tracking, the state uncertainties could be characterized reasonably, which provides a guarantee for solving the POMDP optimal policy for downstream tasks.},
  archive      = {J_NEUCOM},
  author       = {Jianfeng Liu and Lifan Sun and Jiexin Pu and Yongyi Yan},
  doi          = {10.1016/j.neucom.2022.02.066},
  journal      = {Neurocomputing},
  pages        = {284-298},
  shortjournal = {Neurocomputing},
  title        = {Action-dependent bidirectional contrastive predictive coding for neural belief representations},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EvoDCNN: An evolutionary deep convolutional neural network
for image classification. <em>NEUCOM</em>, <em>488</em>, 271–283. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing Deep Convolutional Neural Networks (DCNNs) for image classification is a complicated task that needs considerable effort and knowledge. By employing an evolutionary computation approach, one can automatically generate the network models. However, the Neuroevolution is computationally expensive, and in some cases it needs hundreds of GPU days for training. Therefore, there is a need to find optimum Neuroevolutionary models with minimum computation to deal with this problem. In this paper, by utilising a Genetic Algorithm (GA), we introduce EvoDCNN, as a block-based evolutionary model for developing an evolutionary deep convolutional network for image classification. Such that by using the proposed fixed-length encoding model, we can generate variable-length networks with high accuracy while using less computation. The proposed model by utilising a straightforward evolutionary framework is able to establish small networks with high classification accuracy. Eight datasets: CIFAR10, MNIST, and six versions of EMNIST, that include balanced and unbalanced datasets, are used for evaluation of the proposed model. We did a comprehensive evaluation where we compared the results with many previous works, and outperformed the previous state-of-the-art accuracy for classification of five of the datasets.},
  archive      = {J_NEUCOM},
  author       = {Tahereh Hassanzadeh and Daryl Essam and Ruhul Sarker},
  doi          = {10.1016/j.neucom.2022.02.003},
  journal      = {Neurocomputing},
  pages        = {271-283},
  shortjournal = {Neurocomputing},
  title        = {EvoDCNN: An evolutionary deep convolutional neural network for image classification},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis of the electronic integrate and fire neuron model.
<em>NEUCOM</em>, <em>488</em>, 261–270. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nano-scale devices are thought to intervene in natural life for a variety of responsibilities. For understanding the intrinsic communication of such nano-scale devices, software and hardware modalities have been introduced. Some of these models are of neuro-spike communication systems which employ spiking neuron circuits. In this study, the previously designed electronic integrate and fire circuit inspired by Hodgkin Huxley membrane model is analyzed and interrelated to the Izhikevich’s systematic integrate and fire model. The generated action potentials with this model are very similar to the ones generated by real biophysical neurons which are thought as the inter-neuronal ionic transporters of information. The superiority of the analyzed model to the existing models is that it can show pulse trains whose characteristics are almost similar to those produced by nerve cells. The analytical, hardware and simulation results have shown that the model has the potential of employment in the smart nano-scale systems and medical treatment strategies.},
  archive      = {J_NEUCOM},
  author       = {Ibrahim Isik and Mehmet Emin Tagluk},
  doi          = {10.1016/j.neucom.2022.02.064},
  journal      = {Neurocomputing},
  pages        = {261-270},
  shortjournal = {Neurocomputing},
  title        = {Analysis of the electronic integrate and fire neuron model},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Semi-supervised learning based on intra-view heterogeneity
and inter-view compatibility for image classification. <em>NEUCOM</em>,
<em>488</em>, 248–260. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve high value of classification results by using a limited number of training samples, designing a multi-view semi-supervised classification model is extremely urgent. Moreover, considering that graph learning can fully capture the complex data structure information, we propose a graph-based multi-view semi-supervised classification approach named as Semi-supervised Classification based on Intra-view Heterogeneity and Inter-view Compatibility (SSC_IHIC). Specifically, the similarity between two samples can be measured based on the Euclidean distance . Considering that heterogeneity exists in intra-view sub-features, hence, the weights are learned adaptively. Besides, based on the inter-view compatibility, the consensus similarity graph is constructed on which the labels are propagated. To verify the effectiveness, the proposed approach is conducted on four data sets including MSRC-v1, Handwritten (HW), Cal101-7 and Cal101-20. From the experimental results, we can see that the classification performance about proposed method outperforms the single view classification methods and the state-of-the-art multi-view classification methods.},
  archive      = {J_NEUCOM},
  author       = {Shaojun Shi and Feiping Nie and Rong Wang and Xuelong Li},
  doi          = {10.1016/j.neucom.2022.02.026},
  journal      = {Neurocomputing},
  pages        = {248-260},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised learning based on intra-view heterogeneity and inter-view compatibility for image classification},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive survey on robust image watermarking.
<em>NEUCOM</em>, <em>488</em>, 226–247. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development and popularity of the Internet, multimedia security has become a general essential concern. Especially, as manipulation of digital images gets much easier, the challenges it brings to authentication certification are increasing. As part of the solution, digital watermarking has made significant contributions to image content security and has attracted increasing attention. In this paper, we present a comprehensive review on digital image watermarking methods that were published in recent years illustrating the conventional schemes in different domains. We provide an overview of geometric invariant techniques and emerging watermarking methods for novel medias, such as depth image based rendering (DIBR), high dynamic range (HDR), screen content images (SCIs), and point cloud model. Particularly, as deep learning has achieved a great success in the field of image processing, and has also successfully been used in the field of digital watermarking, learning-based watermarking methods using various neural networks are summarized according to the utilization of neural networks in the single stage training (SST) and double stage training (DST). Finally, we provide an analysis and summary on those methods, and suggest some future research directions.},
  archive      = {J_NEUCOM},
  author       = {Wenbo Wan and Jun Wang and Yunming Zhang and Jing Li and Hui Yu and Jiande Sun},
  doi          = {10.1016/j.neucom.2022.02.083},
  journal      = {Neurocomputing},
  pages        = {226-247},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive survey on robust image watermarking},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). One-shot video graph generation for explainable action
reasoning. <em>NEUCOM</em>, <em>488</em>, 212–225. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action analysis is a critical yet challenging task for understanding diverse video content. Recently, to enable explainable reasoning of video actions, a spatio-temporal video graph structure was proposed to represent the video state changes at the semantic level. However, its requirement of tedious manual annotation of all the video frames is a serious limitation. Obviously, this approach would have a tremendously expanded applicability if the video graph generation process can be automated. In this paper, a One-Shot Video Graph (OSVG) generation approach is proposed for more effective explainable action reasoning, which only requires a one-time annotation of the objects in the starting frame of the video. We first estimate the predefined relevant objects across the temporal dimension by employing a proposed one-shot target-aware tracking strategy. This helps obtain the object locations and links objects simultaneously across all video frames. Then, the scene graph of each video frame can be constructed by an attribute detector and a relationship detector based on the estimated object locations. In addition, to further enhance the reasoning accuracy of performed actions, a video graph smoothing mechanism is designed with a fully-connected Conditional Random Field (CRF). By sequentially examining every state transition (including attributes and relationships) of the smoothed video graph, the actions occurring can be recognized using pre-defined rules. Experiments on the CAD-120++ dataset and a newly collected NTU RGBD++ dataset have verified that the proposed OSVG is able to outperform other state-of-the-art video action reasoning strategies on both state recognition and action recognition accuracy.},
  archive      = {J_NEUCOM},
  author       = {Yamin Han and Tao Zhuo and Peng Zhang and Wei Huang and Yufei Zha and Yanning Zhang and Mohan Kankanhalli},
  doi          = {10.1016/j.neucom.2022.02.069},
  journal      = {Neurocomputing},
  pages        = {212-225},
  shortjournal = {Neurocomputing},
  title        = {One-shot video graph generation for explainable action reasoning},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new training approach for deep learning in EEG biometrics
using triplet loss and EMG-driven additive data augmentation.
<em>NEUCOM</em>, <em>488</em>, 194–211. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the major challenges facing Electroencephalogram (EEG) in biometric systems is the high time-variability of the brainwaves, especially across different sessions. Electrical muscle activity, or Electromyogram (EMG), is considered one of the main noise sources that affect EEG repeatability due to the widely overlapping spectra. In this paper, we introduce a new training approach for deep learning to learn time-permanent and subject-unique embeddings towards an EEG biometric system. The proposed neural network is trained to minimize the triplet loss from EEG frames that are boosted with EMG-driven additive data augmentation . The EMG-like noise is synthetically generated and added to the original EEG batches during training, i.e. online augmentation, to reduce the memory usage specifically in large-scale EEG datasets. This framework is evaluated on a multi-session database that was collected specifically for EEG biometric evaluation under auditory stimulation and relaxation protocols from over 50 users. Adopting this approach showed significantly improved performance over brain-computer interface techniques and conventional deep learning schemes that use cross-entropy loss where a 6–20\% improvement in the Correct Recognition Rate (CRR) and 3–7\% decrease in the Equal Error Rate (EER) were achieved under cross-session setup. Besides, replicating session nuisance with the proposed framework demonstrated enhanced session-invariant EEG embeddings compared to adversarial learning methods with an average of 7.5\% CRR improvements. Finally, our proposed training procedure attained a consistent performance on a longitudinal assessment setup where the time gap between enrollment and testing is almost 1 year. Under this setup, a CRR up to 99.8\% and EER as low as 1.24\% were achieved over a subset of 12 subjects. The achieved results demonstrate the effectiveness of the proposed training framework in improving the time-permanence of the EEG biometric traits under different protocols and testing scenarios.},
  archive      = {J_NEUCOM},
  author       = {Sherif Nagib Abbas Seha and Dimitrios Hatzinakos},
  doi          = {10.1016/j.neucom.2022.02.084},
  journal      = {Neurocomputing},
  pages        = {194-211},
  shortjournal = {Neurocomputing},
  title        = {A new training approach for deep learning in EEG biometrics using triplet loss and EMG-driven additive data augmentation},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic sleep staging method of EEG signal based on
transfer learning and fusion network. <em>NEUCOM</em>, <em>488</em>,
183–193. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic sleep staging technology is a current research hotspot in brain-computer interfaces, freeing sleep specialists from the time-consuming task of manually diagnosing sleep. It performs complex sleep staging tasks by characterising sleep waves. Current research cannot fully interpret the meaning of EEG signals due to drawbacks such as high signal-to-noise ratio and insufficiency of EEG signals, and weak interpretability of depth models. In this research, we proposed an automatic sleep staging network of EEG signal based on transfer learning and integration of single-channel and multi-channel features. In Epoch processing block (EPB) stage and sequence processing block (SPB) stage, the frequency information and long-term features were extracted from the raw EEG and time-frequency data. Beside that, the transfer learning strategy was still adopted to overcome the data-variability and data-inefficiency issues and enable transferring knowledge from a large dataset to a small cohort. And then, the learning results of the two neural networks were fused adaptively and classified by using LightGBM. Lastly, we used the public dataset sleep-edf expanded to evaluate the performance of the system. The overall highest accuracy rate obtained on the sleep-edf expanded sleep-cassette (sc) subset was 87.84\%, on the basis of not relying on massive training data, the accuracy rate is 1.57\%-6.73\% higher than other methods in the same experimental environment.},
  archive      = {J_NEUCOM},
  author       = {Hai Wang and Hongbo Guo and Kan Zhang and Ling Gao and Jie Zheng},
  doi          = {10.1016/j.neucom.2022.02.049},
  journal      = {Neurocomputing},
  pages        = {183-193},
  shortjournal = {Neurocomputing},
  title        = {Automatic sleep staging method of EEG signal based on transfer learning and fusion network},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent fault diagnosis based on sample weighted joint
adversarial network. <em>NEUCOM</em>, <em>488</em>, 168–182. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, adversarial-based deep domain adaptation (DDA) has attracted increasing attention in transferable fault diagnosis. However, most of the existing methods mainly focus on the elimination of global distribution discrepancies, and neglect the exploration of category-specific distribution characteristics, resulting in unsatisfactory diagnostic results in complex scenarios. To avoid this drawback, a novel sample weighted joint adversarial network (SWJAN) is proposed in this paper, which exploits the category information to enhance the joint domain adaptability of adversarial learning. Specifically, in SWJAN, the generated feature vector for domain recognition is decomposed into a feature matrix according to the label probability, so that the category distribution of the feature space can be captured and aligned. As a result, not only the traditional domain-wise adaptation, but also the class-wise feature matching can be emphasized simultaneously. Moreover, since it is risky to adapt the distribution on low-confidence data, the weight of each sample is dynamically adjusted according to the classification uncertainty, so as to control the influence of ambiguous data on adversarial learning and suppress negative transfer near the decision boundary. Experimental analysis, including cross-domain fault diagnosis of the gearbox and rolling bearing, verifies the practicability and superiority of SWJAN in engineering applications.},
  archive      = {J_NEUCOM},
  author       = {Minqiang Deng and Aidong Deng and Yaowei Shi and Yang Liu and Meng Xu},
  doi          = {10.1016/j.neucom.2022.03.005},
  journal      = {Neurocomputing},
  pages        = {168-182},
  shortjournal = {Neurocomputing},
  title        = {Intelligent fault diagnosis based on sample weighted joint adversarial network},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RefFaceNet: Reference-based face image generation from line
art drawings. <em>NEUCOM</em>, <em>488</em>, 154–167. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexible artistic creation of painting using deep neural networks has attracted lots of attention recently. Existing image-to-image translation approaches show powerful capabilities in producing photos between various domains. However, little attention has been paid to reference - based and line-based tasks simultaneously. In this paper, we introduce a novel network, RefFaceNet, to synthesize face portraits by utilizing reference face photos and line art drawings that only consist of the outlines of principal facial components. Our model can provide those people who have no experience in painting with the freedom to create. We utilize two separate encoders to focus on learning better feature representations for the line domain and the reference domain. An Attention-based Face Transfer Module composed of several sub-modules is built to capture the spatial correspondence between the two types of features. To construct a more robust encoding ability for our generator, we first learn a direct mapping from the line drawings to their ground truth color images and then take some distortions on the reference examples. With the assistance of optimal transport, we further propose to keep Spatial Distortion Consistency between the reference pictures in different geometric shapes by aligning features in high-dimensional space. A series of experiments have been conducted, and the results demonstrate the superiority of our method in generating more pleasing images compared with state-of-the-art models.},
  archive      = {J_NEUCOM},
  author       = {Shukai Wu and Weiming Liu and Qingqin Wang and Sanyuan Zhang and Zhenjie Hong and Shuchang Xu},
  doi          = {10.1016/j.neucom.2022.02.075},
  journal      = {Neurocomputing},
  pages        = {154-167},
  shortjournal = {Neurocomputing},
  title        = {RefFaceNet: Reference-based face image generation from line art drawings},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Partial-neurons-based state estimation for artificial neural
networks under constrained bit rate: The finite-time case.
<em>NEUCOM</em>, <em>488</em>, 144–153. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the partial-neuron-based finite-time state estimation problem for a class of artificial neural networks with time-varying delays. Measurements information from only a small fractional of the artificial neurons are applied to the state estimation process. The data transmission from the sensor to estimator is implemented via a bit-rate constrained communication channel, and a data encoding–decoding scheme is developed to convert the original analog sensor measurements into certain digital codewords with fewer occupations of the network bandwidth . With the help of the Lyapunov stability theory , sufficient conditions are presented to guarantee the finite-time boundedness of the estimation error and the estimator gain matrix is parameterized in terms of the solution to certain matrix inequalities. Finally, a numerical example is provided to further confirm the effectiveness of the proposed state estimation scheme.},
  archive      = {J_NEUCOM},
  author       = {Licheng Wang and Di Zhao and Yu-Ang Wang and Derui Ding and Hongjian Liu},
  doi          = {10.1016/j.neucom.2022.03.001},
  journal      = {Neurocomputing},
  pages        = {144-153},
  shortjournal = {Neurocomputing},
  title        = {Partial-neurons-based state estimation for artificial neural networks under constrained bit rate: The finite-time case},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Bipartite consensus for a class of nonlinear multi-agent
systems under switching topologies: A disturbance observer-based
approach. <em>NEUCOM</em>, <em>488</em>, 130–143. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the leader-following bipartite consensus for a class of nonlinear multi-agent systems (MASs) subject to exogenous disturbances under directed fixed and switching topologies , respectively. Firstly, two new output feedback control protocols involving signs of link weights are introduced based on relative output measurements of neighboring agents. In order to estimate the disturbances produced by an exogenous system, a disturbance observer-based approach is developed. Then, sufficient conditions for leader-following bipartite consensus with directed fixed topologies are derived. Furthermore, by assuming that each switching topology contains a directed spanning tree, it is proved that the leader-following bipartite consensus can be realized with the designed output feedback control protocol if the dwell time is larger than a non-negative threshold. Finally, numerical simulations inspired by a real-world DC motors are provided to illustrate the effectiveness of the proposed controllers.},
  archive      = {J_NEUCOM},
  author       = {Qiang Wang and Wangli He and Lorenzo Zino and Dayu Tan and Weimin Zhong},
  doi          = {10.1016/j.neucom.2022.02.081},
  journal      = {Neurocomputing},
  pages        = {130-143},
  shortjournal = {Neurocomputing},
  title        = {Bipartite consensus for a class of nonlinear multi-agent systems under switching topologies: A disturbance observer-based approach},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gain-scheduled state estimation for discrete-time complex
networks under bit-rate constraints. <em>NEUCOM</em>, <em>488</em>,
120–129. (<a
href="https://doi.org/10.1016/j.neucom.2022.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the gain-scheduled state estimation issue is investigated for a kind of complex networks subject to randomly occurring nonlinearities under bit-rate constraints. An array of random variables is introduced to govern the nonlinearities whose occurring probability is a time-varying but bounded value with known upper and lower bounds. A bit-rate constraint model is established and an encoding–decoding mechanism is proposed, under which an upper bound of the decoding error is acquired. The primary purpose of the issue considered in this paper is to design a gain-scheduled state estimator to obtain an estimate of the network state with an acceptable accuracy according to available output measurements. By means of the stochastic analysis and Lyapunov stability theory , a sufficient condition is provided such that the estimation error dynamics achieve the exponentially mean-square ultimate boundedness. The required estimator gain matrix is parameterized by solving a series of matrix inequalities. A numerical simulation is exploited to show the usefulness of the obtained gain-scheduled state estimator.},
  archive      = {J_NEUCOM},
  author       = {Licheng Wang and Di Zhao and Yuhan Zhang and Derui Ding and Xiaojian Yi},
  doi          = {10.1016/j.neucom.2022.03.002},
  journal      = {Neurocomputing},
  pages        = {120-129},
  shortjournal = {Neurocomputing},
  title        = {Gain-scheduled state estimation for discrete-time complex networks under bit-rate constraints},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FG-CF: Friends-aware graph collaborative filtering for POI
recommendation. <em>NEUCOM</em>, <em>488</em>, 107–119. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering approach greatly promotes the development and application of personalized recommendation. In location-based social networks (LBSNs), the sparsity of check-in data is one of the main obstacles for traditional Point-of-Interest (POI) recommendation models. Graph convolutional network (GCN) is an efficient tool to overcome this kind of problems, which enhances the representational ability of embeddings by capture high-order connectivity of users and POIs. In real applications, social tie is a crucial factor for POI recommendation that ignored in most current graph-based methods. Moreover, most message aggregation functions fail to capture contextual information. To address these problems, a novel framework named Friends-aware Graph Collaborative Filtering (FG-CF) is proposed in this paper, which incorporates social information into a user-POI graph. Firstly, a user-POI correlation matrix is estimated by check-in data and social links, and then, user embedding is updated according to the user-POI correlation matrix . Secondly, interaction messages are constructed in a novel way by integrating nodes’ ego embeddings, neighbors’ embeddings and social embeddings. Thirdly, by aggregating previous state embeddings and non-linear combination of neighbor messages with interaction messages, a new message aggregation function is present to update user and POI embeddings. Fourthly, we concatenate embeddings from each additional interaction layer to get the final embeddings, and inner product is used to compute the preference score of a user to a targeted POI. Finally, extensive experiments on two large-scale LBSN datasets demonstrate the superiority of our model over several state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Zhuo Cai and Guan Yuan and Shaojie Qiao and Song Qu and Yanmei Zhang and Rui Bing},
  doi          = {10.1016/j.neucom.2022.02.070},
  journal      = {Neurocomputing},
  pages        = {107-119},
  shortjournal = {Neurocomputing},
  title        = {FG-CF: Friends-aware graph collaborative filtering for POI recommendation},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-supervised 3D human pose estimation from video.
<em>NEUCOM</em>, <em>488</em>, 97–106. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To accurately estimate 3D human pose from monocular camera images, a large amount of 3D annotated data is required. However, obtaining 3D annotated data outside the laboratory is not easy. In the absence of such data, weakly-supervised methods that rely on multi-view cameras during training and single-view cameras during inference have been proposed. These methods either use multi-view networks or classical triangulation to train the 3D human pose estimator. This study shows that these two paradigms can collaborate to further improve performance. The available unlabeled uncalibrated multi-view inputs are used to obtain pseudo-3D labels employing classical triangulation. A pose estimator is trained with these pseudo-3D labels and with multi-view re-projection loss. This loss enforces the 3D poses estimated from different views to be consistent and improves the performance. Therefore, our method relaxes the constraints (calibrated cameras, 2D/3D annotations), only requires multi-view videos for training, and is therefore convenient for in-the-wild settings. The proposed method outperforms previous works on two challenging datasets, Human3.6 M and MPI-INF-3DHP. Codes and pretrained models will be publicly available.},
  archive      = {J_NEUCOM},
  author       = {Mohsen Gholami and Ahmad Rezaei and Helge Rhodin and Rabab Ward and Z. Jane Wang},
  doi          = {10.1016/j.neucom.2022.02.076},
  journal      = {Neurocomputing},
  pages        = {97-106},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised 3D human pose estimation from video},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodal graph neural network for video procedural
captioning. <em>NEUCOM</em>, <em>488</em>, 88–96. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video procedural captioning aims to generate detailed descriptive captions for all steps in a long instructional video. The peculiarity of this problem is the procedural dependency between the events to generate consistent captions among the video. However, existing video (dense) captioning methods only consider intra-event or sequential inter-event context and are hard to model the non-sequential context dependency between events. In this paper, inspired by the recent success of graph neural networks in capturing the relations for structured data, we propose a novel M ultimodal G raph N eural N etwork ( MGNN ) for dense video procedural captioning in capturing the procedural structure between events. Specifically, we construct temporal sequential graph and semantic non-sequential graph for a multimodal heterogeneous graph. Moreover, we adopt the graph neural network to enhance the visual and text features, and fuse both features for further caption generation. Extensive experiments demonstrate the proposed MGNN is effective in generating coherent captions on both the Youcook2 and Activitynet Captions benchmark.},
  archive      = {J_NEUCOM},
  author       = {Lei Ji and Rongcheng Tu and Kevin Lin and Lijuan Wang and Nan Duan},
  doi          = {10.1016/j.neucom.2022.02.062},
  journal      = {Neurocomputing},
  pages        = {88-96},
  shortjournal = {Neurocomputing},
  title        = {Multimodal graph neural network for video procedural captioning},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Point-to-point consensus tracking control for unknown
nonlinear multi-agent systems using data-driven iterative learning.
<em>NEUCOM</em>, <em>488</em>, 78–87. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the point-to-point consensus tracking control for a class of nonlinear multi-agent systems with completely unknown dynamics, where the consensus is concerned with some given desired points instead of the entire desired trajectory . It is assumed that the multi-agent system executes repetitive coordination tasks in a finite time interval and the iterative learning control is also utilized to design a consensus protocol with learning ability. To deal with the unknown nonlinear agent’s dynamic, the relationship between agent’s output at these given points and agent’s control input is first derived and then a data-based model referring to the agent’s dynamic is established by utilizing the iteration-domain dynamical linearization technique. Then, a data-driven iterative learning protocol is developed by optimizing two performance indexes, which contains a control input updated algorithm, a parameter estimation algorithm and a reset algorithm. The results show that the proposed design can achieve the point-to-point consensus tracking task only by using the I/O data of the agent. Finally, simulation examples are provided to verify the effectiveness of the proposed protocol.},
  archive      = {J_NEUCOM},
  author       = {Yanling Yin and Xuhui Bu and Panpan Zhu and Wei Qian},
  doi          = {10.1016/j.neucom.2022.02.074},
  journal      = {Neurocomputing},
  pages        = {78-87},
  shortjournal = {Neurocomputing},
  title        = {Point-to-point consensus tracking control for unknown nonlinear multi-agent systems using data-driven iterative learning},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-task joint training model for machine reading
comprehension. <em>NEUCOM</em>, <em>488</em>, 66–77. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine reading comprehension is an important topic in natural language processing . However, the redundancy of text and the diversity of answer types are neglected in existing machine reading comprehension. To tackle these issues, a multi-task joint training scheme is proposed for the multi-type answer machine reading comprehension task. In this scheme, a feature-based paragraph extraction mechanism is first designed in the training stage to extract various text features from answers and sentences. For efficiency, the redundancy of the text is greatly reduced, while the effective information of the text is retained. And then, a reading comprehension module is optimized by enhancing the representation of the pre-trained language model , as well as an answer type classification module is optimized through the capsule network. Finally, a multi-task joint training model is designed to simultaneous obtaining answer text and answer type. Experiments are conducted to evaluate the proposed approach with two open datasets, CJRC and Natural Questions, and demonstrate that our model is efficient and promising, in terms of both the reading comprehension and answer classification tasks . In particular, our model won the best method that is winner of the first prize in the CAIL-2020 machine reading comprehension contest.},
  archive      = {J_NEUCOM},
  author       = {Fangfang Li and Youran Shan and Xingliang Mao and Xingkai Ren and Xiyao Liu and Shichao Zhang},
  doi          = {10.1016/j.neucom.2022.02.082},
  journal      = {Neurocomputing},
  pages        = {66-77},
  shortjournal = {Neurocomputing},
  title        = {Multi-task joint training model for machine reading comprehension},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). You should know more: Learning external knowledge for visual
dialog. <em>NEUCOM</em>, <em>488</em>, 54–65. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual dialog is a task that two agents complete a multi-round conversation based on an image, a caption, and dialog histories . Despite the recent progress, existing methods still undergo degradation on the condition of complex scenarios. Handling these scenarios depends on logical reasoning that requires commonsense priors. In this paper, we propose a novel visual dialog pipeline named Structured Knowledge-Aware Network (SKANet), consisting of an Image Knowledge-Aware Module and a Caption Knowledge-Aware Module. Specifically, the Image and Caption Knowledge-Aware Modules construct commonsense knowledge graphs from ConceptNet. We apply SKANet to two sub-tasks: the conventional visual dialog and a goal-oriented visual dialog named ‘image guessing’. For the conventional visual dialog, the SKANet is combined with an additional Multi-Modality Fusion Module, which is designed to explore the visual content and the textual context about the dialog history. For the goal-oriented visual dialog, we directly apply the Image and Caption Knowledge-Aware Modules to two agents, respectively. Experimental results on VisDial v0.9 and VisDial v1.0 datasets show that our proposed method effectively outperforms comparative methods on both sub-tasks.},
  archive      = {J_NEUCOM},
  author       = {Lei Zhao and Haonan Zhang and Xiangpeng Li and Sen Yang and Yuanfeng Song},
  doi          = {10.1016/j.neucom.2021.10.121},
  journal      = {Neurocomputing},
  pages        = {54-65},
  shortjournal = {Neurocomputing},
  title        = {You should know more: Learning external knowledge for visual dialog},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge interaction enhanced sequential modeling for
interpretable learner knowledge diagnosis in intelligent tutoring
systems. <em>NEUCOM</em>, <em>488</em>, 36–53. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the fundamental tasks when providing personalized tutoring services to learners in online learning systems, such as intelligent tutoring systems and massive open online courses, is the learner knowledge diagnosis (LKD). LKD obtains the learner knowledge proficiency on skills by modeling their learning performance. Learners’ knowledge construction process is not static, but evolves overtime; hence, the evolution of learners’ knowledge proficiency must be dynamically traced. Moreover, considering the wide usage of online learning systems by large numbers of learners, the LKD task also needs to meet the requirements of large-scale assessment and interpretability to explain the diagnosed results. The existing models are either designed for static scenarios or find it difficult to explain the causality between learner performance and knowledge proficiency, as well as the item characteristics. To solve these issues, we propose herein a novel model, called the knowledge interaction-enhanced dynamic LKD (KIEDLKD), to develop learner performance, and hence, dynamically diagnose and trace the evolution of each learner’s knowledge proficiency during the exercising activities. We first propose a dynamic LKD framework by unifying the strength of the memory capacity of the key-value memory network to enhance the representation of the knowledge state during learner performance modeling and the interpretability of the Item Response Theory (IRT) to explain the learner performance in terms of knowledge proficiency and item characteristics (i.e., item difficulty and discrimination). In this framework, we diagnose and trace each learner’s knowledge proficiency on each knowledge concept (KC) over time and store them into an auxiliary memory using the key-value memory network. We further infer their general proficiencies and the IRT-based item characteristics using another neural network . Moreover, we propose the knowledge interaction concept among KCs and incorporate it into the LKD procedure to further exploit the long-term dependencies in the exercising sequences, thereby devising the KIEDLKD model. We also incorporate the learner-oriented cognitive item difficulty into our model, based on each learner’s exercising history, to adaptively model the item difficulty. Based on these factors, our KIEDLKD model can not only output the learners’ knowledge proficiency in a multi-granularity manner but also output the item characteristics, making it possible to interpret the learner performances in terms of their current knowledge states and item characteristics. Extensive experiments are conducted from six perspectives on five real-world datasets to test our model.The results of learner performance prediction demonstrate the superiority of our model on the LKD task. It can also automatically discover the underlying interaction between each pair of latent KCs, and the underlying concepts for each exercise. The ablation study verifies the contributions of each component in our model. Moreover, it can depict the evolution of learner knowledge proficiency in a multi-granularity manner and provide additional information for skill domain analysis, which enables the interpretability of our model.},
  archive      = {J_NEUCOM},
  author       = {Wenbin Gan and Yuan Sun and Yi Sun},
  doi          = {10.1016/j.neucom.2022.02.080},
  journal      = {Neurocomputing},
  pages        = {36-53},
  shortjournal = {Neurocomputing},
  title        = {Knowledge interaction enhanced sequential modeling for interpretable learner knowledge diagnosis in intelligent tutoring systems},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain-aware multi-modality fusion network for generalized
zero-shot learning. <em>NEUCOM</em>, <em>488</em>, 23–35. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized zero-shot learning (GZSL) is a challenging problem which aims to recognize images from both seen and unseen classes. Existing research suffers from the bias problem, which means that the model tends to misclassify an unseen sample to seen classes. Moreover, recent methods mainly focus on using a single semantic representation for knowledge transfer (e.g., attributes). Although some try to utilize multiple information, they only use simple concatenation or transformations and the performance is limited. To solve GZSL problem, we propose a two-step method aimed at overcoming these two challenges progressively. Firstly, a local neighborhood based gating model is designed to leverage both the distribution of original data space and a learned latent space for domain detection. The model is used to separate seen and unseen samples, and then decompose GZSL into a conventional zero-shot learning (ZSL) problem and a supervised classification problem. Then, we design a graph convolutional network (GCN) based model for fusing multiple semantic modalities to promote the solution of the decomposed ZSL problem. By using one primary modality as input and another for construction of node relationships, our model is able to fuse multiple information effectively and helps to learn more discriminative visual classifiers. We test our method, local neighborhood based domain aware and GCN based multi-modality fusion network (LND-GMF) on five benchmark datasets. The results show that our method out-performs state-of-the-art methods with a large margin.},
  archive      = {J_NEUCOM},
  author       = {Jia Wang and Xiao Wang and Han Zhang},
  doi          = {10.1016/j.neucom.2022.02.056},
  journal      = {Neurocomputing},
  pages        = {23-35},
  shortjournal = {Neurocomputing},
  title        = {Domain-aware multi-modality fusion network for generalized zero-shot learning},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive neural network decentralized fault-tolerant control
for nonlinear interconnected fractional-order systems. <em>NEUCOM</em>,
<em>488</em>, 14–22. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the neural network (NN) decentralized observer-based fault-tolerant control (FTC) design problem on the nonlinear interconnected fractional-order systems. The considered fractional-order systems have the non strict-feedback form and are subject to immeasurable states and intermittent actuator faults . Neural networks (NN) are employed to identify the unknown dynamics, and a NN decentralized observer is formulated to estimate unknown states. By constructing appropriate Lyapunov functions and using the backstepping dynamic surface control (DSC) technique, a NN observer-based decentralized FTC method is developed. It is proved that the developed NN decentralized FTC scheme can guarantee that the controlled interconnected fractional-order system is stable and the track errors can be made smaller. Finally, a practical simulated example is provided to check the validity of the NN decentralized FTC algorithm.},
  archive      = {J_NEUCOM},
  author       = {Xiaomei Li and Yongliang Zhan and Shaocheng Tong},
  doi          = {10.1016/j.neucom.2022.02.078},
  journal      = {Neurocomputing},
  pages        = {14-22},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural network decentralized fault-tolerant control for nonlinear interconnected fractional-order systems},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning task-specific discriminative embeddings for
few-shot image classification. <em>NEUCOM</em>, <em>488</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, few-shot learning has attracted more and more attention. Generally, the fine-tuning-based few-shot learning framework contains two stages: i) In the pre-training stage, using base data to train the feature extractor; ii) In the meta-testing stage, using a well-trained feature extractor to extract embedding features of novel data and designing a base learner to predict the labels. Due to the diverse categories of base and novel data, it is challenging for the feature extractor trained in the pre-training stage to adapt to novel data, which will result in an embedding-mismatch problem. This paper proposes Task-specific Discriminative Embeddings for Few-shot Learning (TDE-FSL) to solve the embedding-mismatch problem. Specifically, we embed the dictionary learning method into the few-shot learning framework to map the feature embeddings to a more discriminative subspace to adapt to the specific task. Moreover, we extend the self-training framework to our approach to fully utilize the unlabeled data . Finally, we evaluate the TDE-FSL on five benchmark image datasets, such as mini-Imagenet, tiered-Imagenet, CIFAR-FS, FC100, and CUB dataset. The experimental results show that the performance of our proposed TDE-FSL achieves a significant improvement.},
  archive      = {J_NEUCOM},
  author       = {Lei Xing and Shuai Shao and Weifeng Liu and Anxun Han and Xiangshuai Pan and Bao-Di Liu},
  doi          = {10.1016/j.neucom.2022.02.073},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {Learning task-specific discriminative embeddings for few-shot image classification},
  volume       = {488},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel method for distributed optimization with globally
coupled constraints based on multi-agent systems. <em>NEUCOM</em>,
<em>487</em>, 289–299. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A continuous-time distributed algorithm based on multi-agent systems is proposed to solve the convex nonsmooth optimization with globally coupled constraints in this paper. Firstly, the relationship of equivalence between the equilibrium and the optimal solution of the system is proved by using the properties of projection operator and saddle point. In addition, the stability of the algorithm is analyzed by means of Lie derivative and set-valued LaSalle’s invariance principle. In particular, the trajectory of the proposed algorithm from any initial point can converge to the global optimal solution . Finally, the effectiveness of the designed algorithm is verified by numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Yiyang Ge and Xuehui Mei and Haijun Jiang and Jianlong Qiu and Zhiyong Yu},
  doi          = {10.1016/j.neucom.2021.11.014},
  journal      = {Neurocomputing},
  pages        = {289-299},
  shortjournal = {Neurocomputing},
  title        = {A novel method for distributed optimization with globally coupled constraints based on multi-agent systems},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two discrete ZNN models for solving time-varying augmented
complex sylvester equation. <em>NEUCOM</em>, <em>487</em>, 280–288. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on practical applications of the complex-valued Sylvester equation and the effectiveness of zeroing neural network (ZNN) in solving time-varying problems, two discrete nonlinear and noise-tolerant ZNN (DNN-TZNN) models are proposed to solve the time-varying augmented complex Sylvester (TACS) equation by using the Adams-Bashforth formula to discretize the continuous nonlinear and noise-tolerant ZNN (CNN-TZNN) model. The presented DNN-TZNN models are divided into two types: DNN-TZNK and DNN-TZNU models, according to whether the derivative information is known or not in the CNN-TZNN design formula. Compared with the continuous ZNN methods, the proposed DNN-TZNN models are more innovative, and compared with other discrete ZNN methods, the convergence speed of the DNN-TZNN models is much faster and more accurate. Through the theoretical analysis, the superior convergence and strong robustness of the DNN-TZNN models are guaranteed. At last, the simulative experiments not only verify the correctness of the theoretical analysis but also demonstrate the availability of the DNN-TZNN models in solving the TACS problem.},
  archive      = {J_NEUCOM},
  author       = {Lin Xiao and Wenqian Huang and Lei Jia and Xiaopeng Li},
  doi          = {10.1016/j.neucom.2021.11.012},
  journal      = {Neurocomputing},
  pages        = {280-288},
  shortjournal = {Neurocomputing},
  title        = {Two discrete ZNN models for solving time-varying augmented complex sylvester equation},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). M2N: Mutual constraint network for multi-level unsupervised
domain adaptation. <em>NEUCOM</em>, <em>487</em>, 269–279. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) algorithms aim to transfer the knowledge learned from the labeled source domain to the unlabeled target domain. To tackle this issue, domain-alignment models based on different representation space levels were used to extract knowledge relevant to the ultimate task. Although they achieved remarkable performance, domain shift that poses an evident challenge for adapting the model trained on one domain to another one was ignored. Pseudo labels learning for UDA is therefore proposed to reduce the impact of domain shifts. However, the inevitable label noise severely weakens the model’s capability of feature representations. Inspired by recent studies on deep learning with noisy labels, we propose a Mutual Constraint Network for multi-level UDA (M2N), to mitigate the effects of noisy pseudo labels and learn better feature representation from different space levels. Extensive experimental results on Digits, Office-31, and VisDA-2017, show that our methods can achieve new state-of-the-art performance on three benchmark tasks and improve significantly over prior single-level UDA.},
  archive      = {J_NEUCOM},
  author       = {Xinhui Liu and Wei Xi and Gairui Bai and Ziwei Wang and Zhilin Liu and Jizhong Zhao},
  doi          = {10.1016/j.neucom.2021.11.011},
  journal      = {Neurocomputing},
  pages        = {269-279},
  shortjournal = {Neurocomputing},
  title        = {M2N: Mutual constraint network for multi-level unsupervised domain adaptation},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constructing infinite deep neural networks with flexible
expressiveness while training. <em>NEUCOM</em>, <em>487</em>, 257–268.
(<a href="https://doi.org/10.1016/j.neucom.2021.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The depth of the deep neural network (DNN) refers to the number of hidden layers between the input and output layers of an artificial neural network. It usually indicates a certain degree of complexity of the computational cost (parameters and floating point operations per second) and expressiveness once the network structure is settled. In this study, we experimentally investigate the effectiveness of using neural ordinary differential equations (NODEs) as a component to provide further depth in a continuous way to relatively shallower networks rather than stacking more layers (discrete depth), which achieved an improvement with fewer parameters. Experiments are conducted on classic DNNs , the residual networks. Moreover, we construct infinite deep neural networks with flexible complexity based on NODEs, enabling the system to adjust its complexity during training. On a better hidden-space provided by adaptive step DNNs, adaptive step ResNet with NODE (ResODE) is managed to achieve better performances in terms of convergence and accuracy than standard networks, and the improvements are widely observed in popular benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Zhengbo Luo and Zitang Sun and Weilian Zhou and Zizhang Wu and Sei-ichiro Kamata},
  doi          = {10.1016/j.neucom.2021.11.010},
  journal      = {Neurocomputing},
  pages        = {257-268},
  shortjournal = {Neurocomputing},
  title        = {Constructing infinite deep neural networks with flexible expressiveness while training},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HPGCN: Hierarchical poselet-guided graph convolutional
network for 3D pose estimation. <em>NEUCOM</em>, <em>487</em>, 243–256.
(<a href="https://doi.org/10.1016/j.neucom.2021.11.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D pose estimation remains a challenging task since human poses exhibit high ambiguity and multi-granularity. Traditional graph convolution networks (GCNs) accomplish the task by modeling all skeletons as an entire graph, and are unable to fuse combinable part-based features. By observing that human movements occur due to part of human body (i.e. related skeletons and body components, known as the poselet) and those poselets contribute to each movement in a hierarchical fashion, we propose a hierarchical poselet-guided graph convolutional network (HPGCN) for 3D pose estimation from 2D poses. HPGCN sets five primitives of human body as basic poselets, and constitutes high-level poselets according to the kinematic configuration of human body. Moreover, HPGCN forms a fundamental unit by using a diagonally dominant graph convolution layer and a non-local layer, which corporately capture the multi-granular feature of human poses from local to global perspective. Finally HPGCN designs a geometric constraint loss function with constraints on lengths and directions of bone vectors, which help produce reasonable pose regression. We verify the effectiveness of HPGCN on three public 3D human pose benchmarks. Experimental results show that HPGCN outperforms several state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yongpeng Wu and Dehui Kong and Shaofan Wang and Jinghua Li and Baocai Yin},
  doi          = {10.1016/j.neucom.2021.11.007},
  journal      = {Neurocomputing},
  pages        = {243-256},
  shortjournal = {Neurocomputing},
  title        = {HPGCN: Hierarchical poselet-guided graph convolutional network for 3D pose estimation},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint adaptive transfer learning network for cross-domain
fault diagnosis based on multi-layer feature fusion. <em>NEUCOM</em>,
<em>487</em>, 228–242. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional intelligent fault diagnosis models are required to be trained and tested under an identical probability distribution. However, the shift in data distributions is inevitable due to changes in environmental and operational conditions, which results in diagnostic performance degradation . Currently, transfer learning has been successfully applied to learn a discriminative diagnosis model in the presence of a shift. But conventional transfer learning approaches encounter obstacles without adequately considering the feature interactivity and transferable ability at different layers. In this study, a joint adaptive transfer learning framework based on multi-layer feature fusion for reliable cross-domain diagnosis is presented to address these issues. Firstly, the multilinear map is employed to implement a novel multi-layer feature fusion . This fusion is key to realizing a substantial improvement of feature representation capability and effectively embedding joint distribution of multi-layer features. Furthermore, a novel joint adaptive transfer learning (JATL) framework is devised to facilitate reliable cross-domain adaption by making utmost use of cross-domain-invariant features with a small amount of data. Experiments with different transfer scenarios on two benchmark datasets have been conducted, and experimental results demonstrate the superiority of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Yimin Jiang and Tangbin Xia and Dong Wang and Kaigan Zhang and Lifeng Xi},
  doi          = {10.1016/j.neucom.2021.11.005},
  journal      = {Neurocomputing},
  pages        = {228-242},
  shortjournal = {Neurocomputing},
  title        = {Joint adaptive transfer learning network for cross-domain fault diagnosis based on multi-layer feature fusion},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New discrete-time zeroing neural network for solving
time-variant underdetermined nonlinear systems under bound constraint.
<em>NEUCOM</em>, <em>487</em>, 214–227. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many industrial applications result in the constrained underdetermined nonlinear system (UNS) that needs to be solved. The existing solutions are reported to the constrained UNS with time-invariant coefficients, and they may not perform well for the time-variant case. In this paper, we attempt to address the above limitation by providing a new discrete-time zeroing neural network (DTZNN) for solving the time-variant UNS (TVUNS) under bound constraint . Specifically, the bound-constrained TVUNS (BC-TVUNS) is first transformed into a mixed nonlinear system by introducing a nonnegative variable. Then, a continuous-time ZNN (CTZNN) model is established to solve such a mixed system as well as the BC-TVUNS. By employing a special difference formula to discretize the CTZNN model, the new DTZNN model is thus proposed to obtain the solution of the BC-TVUNS. Theoretical analysis and comparative numerical results are presented to validate the effectiveness of the proposed DTZNN model over the previous DTZNN models. The DTZNN application potential is further indicated on the basis of the simulations on a dual-arm redundant robot using the proposed model.},
  archive      = {J_NEUCOM},
  author       = {Shaobin Huang and Zhisheng Ma and Shihang Yu and Yang Han},
  doi          = {10.1016/j.neucom.2021.11.004},
  journal      = {Neurocomputing},
  pages        = {214-227},
  shortjournal = {Neurocomputing},
  title        = {New discrete-time zeroing neural network for solving time-variant underdetermined nonlinear systems under bound constraint},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel parameters correction and multivariable decision
tree method for edge computing enabled HGR system. <em>NEUCOM</em>,
<em>487</em>, 203–213. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of cloud computing , Internet of things and artificial intelligence , human–computer interaction (HCI) is playing an increasingly important role in the daily life. As an important component of HCI, hand gesture recognition (HGR) system is usually combined with edge computing server, utilizing machine learning , including neural network , decision tree , integrated learning, to achieve low latency and high reliability service. High precision HGR with low computational complexity is prerequisite for the commercialization of gesture recognition . Therefore, this paper proposed a high-precision parameter correction algorithm based on the established scattered-point model and the outlier detection scheme, and a recognition algorithm with multivariable decision tree is then presented for the dynamic hand gestures. The experimental results show that the proposed algorithms can improve the recognition accuracy and effectively reduce the running time, which is conducive to algorithm transplantation and model deployment in edge servers.},
  archive      = {J_NEUCOM},
  author       = {Wei He and Yong Wang and Mu Zhou and Bang Wang},
  doi          = {10.1016/j.neucom.2021.08.147},
  journal      = {Neurocomputing},
  pages        = {203-213},
  shortjournal = {Neurocomputing},
  title        = {A novel parameters correction and multivariable decision tree method for edge computing enabled HGR system},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge distillation based on decision boundary instances
generated by DBI-GAN. <em>NEUCOM</em>, <em>487</em>, 190–202. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new model-free knowledge distillation scheme. We attempt on distilling the knowledge about the decision-making process and design a novel generative adversarial network, named as DBI-GAN, to generate instances located on the decision boundary of the teacher network. By depicting the decision-making process of the teacher network with the decision boundary instances, it is possible for us to transfer such knowledge to a student network. Based on the decision boundary instances, a new knowledge distillation scheme is proposed. In our scheme, we focus on the student network’s “weak-points region”, where wrong decisions are made. We locate these weak-points regions by evaluate the student network using confusion matrix. Then, a specific dataset, which consists of the original train data and synthesized DBIs that located in the weak-points regions, is constructed for knowledge transferring. With the constructed sample set, the student network is then optimized with a new KD loss function. We evaluate the effectiveness of proposed scheme on banchmark datasets and state-of-the-art performance is achieved.},
  archive      = {J_NEUCOM},
  author       = {Ziqi Zhu and Xi Liu and Chunhua Deng and Jing Liu and Jixin Zou},
  doi          = {10.1016/j.neucom.2021.10.097},
  journal      = {Neurocomputing},
  pages        = {190-202},
  shortjournal = {Neurocomputing},
  title        = {Knowledge distillation based on decision boundary instances generated by DBI-GAN},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Meta-learning for compressed language model: A multiple
choice question answering study. <em>NEUCOM</em>, <em>487</em>, 181–189.
(<a href="https://doi.org/10.1016/j.neucom.2021.01.148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model compression is a promising approach for reducing the model size of pretrained-language-models (PLMs) on low resource edge devices and applications. Unfortunately, the compression process always accompanies a cost of performance degradation , especially for the low resource downstream tasks, i.e., multiple-choice question answering. To address the degradation issue of model compression on PLMs, we proposed an end-to-end reptile (ETER) meta-learning approach to improving the performance of PLMs on the low resource multiple-choice question answering task. Specifically, our ETER improves the traditional two-stage meta-learning to an end-to-end manner, integrating the target finetuning stage into the meta training stage. To strengthen the generic meta-learning, ETER employs two-level meta-task construction from instance-level and domain-level to enrich its task generalization. What is more, ETER optimizes meta-learning by parameter constraints to reduce its parameter learning space. Experiments demonstrate that ETER significantly improved the performance of compressed PLMs and achieved large superiority over the baselines on different datasets.},
  archive      = {J_NEUCOM},
  author       = {Ming Yan and Yi Pan},
  doi          = {10.1016/j.neucom.2021.01.148},
  journal      = {Neurocomputing},
  pages        = {181-189},
  shortjournal = {Neurocomputing},
  title        = {Meta-learning for compressed language model: A multiple choice question answering study},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Conv-inheritance: A hardware-efficient method to compress
convolutional neural networks for edge applications. <em>NEUCOM</em>,
<em>487</em>, 172–180. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) have won tremendous success in various applications, such as image recognition and natural language processing . Due to the computing-intensive and memory-intensive features of CNN models, it is challenging to deploy them on devices with limited resources and tight power budgets. To address this limitation, pruning, quantization, weights sharing, and other methods have been proposed as efficient solutions to compress CNN models. However, these works usually do not optimize the hardware design when compressing the CNNs. In this paper, we introduce Conv-Inheritance, a hardware-efficient compression method for CNNs by reducing the number of convolution operations to simultaneously reduce the inference time and hardware computing resources on chip of CNN edge devices. We also develop an extended version, called adaptive Conv-Inheritance, to further improve the inference performance by considering the similarity between pixels. We applied our Conv-Inheritance method to compressing various CNN models and performed extensive experiments on different image datasets. Experimental results demonstrate that Conv-Inheritance is both hardware-efficient and time-efficient on edge devices. Besides, Conv-Inheritance is a plug-and-play compression method for CNNs, and we can run Conv-Inheritance on top of other compression methods without any conflicts.},
  archive      = {J_NEUCOM},
  author       = {Yang Yang and Chao Wang and Lei Gong and Min Wu and Xuehai Zhou},
  doi          = {10.1016/j.neucom.2021.02.106},
  journal      = {Neurocomputing},
  pages        = {172-180},
  shortjournal = {Neurocomputing},
  title        = {Conv-inheritance: A hardware-efficient method to compress convolutional neural networks for edge applications},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Jointly attention network for crowd counting.
<em>NEUCOM</em>, <em>487</em>, 157–171. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, crowd counting has shown great practical value in public safety and related fields. Most leading algorithms exploit CNN to generate density maps and have improved the estimation accuracy. However, the counting models still suffer from the challenge of huge scale variations. In order to mitigate this issue, we propose a novel approach named Jointly Attention Network (JANet) for Crowd Counting. It is composed of two major schemes: the Multi-order Scale Attention (MSA) module and the Multi-pooling Relational Channel Attention (MRCA) module. The MSA module explores meaningful high-order statistics and helps the backbone network obtain more discriminative features with rich scale information in an explicit manner. The MRCA module compactly represents the global scope relations and accounts the interdependence among all channel-wise nodes, which is complementary to MSA module. Meanwhile, the Distributed Combinatorial Loss (DCL) is designed to achieve the distributed supervision on intermediate layers at each level. Finally, we conduct extensive studies on multiple crowd counting datasets, the ShanghaiTech, the UCF-QNRF, the JHU-CROWD++, the NWPU-Crowd. The experimental results indicate that our proposed method has achieved superior performance.},
  archive      = {J_NEUCOM},
  author       = {Yuqiang He and Yinfeng Xia and Yizhen Wang and Baoqun Yin},
  doi          = {10.1016/j.neucom.2022.02.060},
  journal      = {Neurocomputing},
  pages        = {157-171},
  shortjournal = {Neurocomputing},
  title        = {Jointly attention network for crowd counting},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Synchronization and control for directly coupled
reaction-diffusion neural networks with multiple weights and hybrid
coupling. <em>NEUCOM</em>, <em>487</em>, 144–156. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the synchronization and pinning control problems of directly coupled reaction-diffusion neural networks (RDNNs). The model in this article has the following advantages: 1. the network can be directly coupled; 2. there are multiple coupling matrices to represent different communication channels; 3. the spatial information of RDNNs is also utilized for synchronization along with state information, which is called the hybrid coupling. Since different coupling matrices have different normalized left eigenvectors (NLEVec) corresponding to their zero eigenvalue, the design of Lyapunov functions , which heavily depends on NLEVec, will be prevented. In virtue of the weighted combination of NLEVec for multiple coupling matrices, we demonstrate that if the Chebyshev distance among these NLEVec is less than an allowable bound, then several synchronization and pinning control criteria with sufficiently large coupling strengths can be derived. In addition, the issue of adaptive coupling strengths is also addressed. Some numerical examples are finally simulated to illustrate the effectiveness of acquired results.},
  archive      = {J_NEUCOM},
  author       = {Shanrong Lin and Xiwei Liu},
  doi          = {10.1016/j.neucom.2022.02.061},
  journal      = {Neurocomputing},
  pages        = {144-156},
  shortjournal = {Neurocomputing},
  title        = {Synchronization and control for directly coupled reaction-diffusion neural networks with multiple weights and hybrid coupling},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Accelerated gradient-free neural network training by
multi-convex alternating optimization. <em>NEUCOM</em>, <em>487</em>,
130–143. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, even though Stochastic Gradient Descent (SGD) and its variants are well-known for training neural networks , it suffers from limitations such as the lack of theoretical guarantees, vanishing gradients, and excessive sensitivity to input. To overcome these drawbacks, alternating minimization methods have attracted fast-increasing attention recently. As an emerging and open domain, however, several new challenges need to be addressed, including 1) Convergence properties are sensitive to penalty parameters, and 2) Slow theoretical convergence rate. We, therefore, propose a novel monotonous Deep Learning Alternating Minimization (mDLAM) algorithm to deal with these two challenges. Our innovative inequality-constrained formulation infinitely approximates the original problem with non-convex equality constraints, enabling our convergence proof of the proposed mDLAM algorithm regardless of the choice of hyperparameters. Our mDLAM algorithm is shown to achieve a fast linear convergence by the Nesterov acceleration technique. Extensive experiments on multiple benchmark datasets demonstrate the convergence, effectiveness, and efficiency of the proposed mDLAM algorithm.},
  archive      = {J_NEUCOM},
  author       = {Junxiang Wang and Hongyi Li and Liang Zhao},
  doi          = {10.1016/j.neucom.2022.02.039},
  journal      = {Neurocomputing},
  pages        = {130-143},
  shortjournal = {Neurocomputing},
  title        = {Accelerated gradient-free neural network training by multi-convex alternating optimization},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generative models with kernel distance in data space.
<em>NEUCOM</em>, <em>487</em>, 119–129. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models dealing with modeling a joint data distribution are generally autoencoder, or GAN based. Both have pros and cons, generating blurry images or being unstable in training. We propose a new generative model resembling a classical GAN transforming Gaussian noise into data space without adversarial optimization. Training of the proposed model is a two-step procedure. First, we train an autoencoder-based architecture to model a data manifold. Second, we use the Latent Trick to map Gaussian noise into the autoencoder’s latent space. The resulting Latent Cramer-Wold (LCW) generator achieves competitive generative scores. Elimination of adversarial training and replacing the discriminator with kernel methods results in a stable training procedure that is not prone to mode collapse. We also show that the introduced Latent Trick can improve the generative capabilities of other latent-based models. We validate the model on standard benchmarks and compare it to different approaches.},
  archive      = {J_NEUCOM},
  author       = {Szymon Knop and Marcin Mazur and Przemysław Spurek and Jacek Tabor and Igor Podolak},
  doi          = {10.1016/j.neucom.2022.02.053},
  journal      = {Neurocomputing},
  pages        = {119-129},
  shortjournal = {Neurocomputing},
  title        = {Generative models with kernel distance in data space},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Suboptimal linear quadratic tracking control for multi-agent
systems. <em>NEUCOM</em>, <em>487</em>, 110–118. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the distributed linear quadratic tracking control problem for multi-agent leader–follower systems. Considering that only few followers can access the state information of the leader owing to the limited communication range, a novel distributed control law is designed to make followers convergent to the leader by introducing appropriate interconnections among the followers. Besides the tracking consensus of the leader–follower systems, the designed control law also enables the associated cost to be less than a given tolerance for any initial states of the leader and the followers. The implementation of the designed distributed control law can be executed by solving a single Riccati equation , requiring no global information of the communication topology. Two examples are finally provided to demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Shuo Yuan and Chengpu Yu and Ping Wang},
  doi          = {10.1016/j.neucom.2022.02.057},
  journal      = {Neurocomputing},
  pages        = {110-118},
  shortjournal = {Neurocomputing},
  title        = {Suboptimal linear quadratic tracking control for multi-agent systems},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Degree aware based adversarial graph convolutional networks
for entity alignment in heterogeneous knowledge graph. <em>NEUCOM</em>,
<em>487</em>, 99–109. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity alignment, as the vital technique for knowledge graph construction and integration, aims to match entities that refer to the same real-world identity in different knowledge graphs (KGs). Recently, much effort has been devoted to embedding-based methods for entity alignment. For most of such methods, the entity with a high degree is hard to be aligned with its equivalent counterpart with a low degree. This degree difference between equivalent entities poses a great challenge for entity alignment. To solve this problem, a novel entity alignment framework that integrates a graph convolutional network (GCN) based embedding initializer and a degree aware generative adversarial network is proposed. In particular, the embedding initializer utilizes a GCN with highway gates to generate the preliminary embedding of entities based on their topological characteristics in the KGs. By alleviating the relevance between embeddings and degree features, the degree aware GAN mitigates the impact of degree difference and generates the final degree level irrelevant alignment result. To quantify the heterogeneity between the KGs, an evaluation metric called heterogeneity entropy of degree (HED) that represents the degree difference is defined in this paper. Based on HED, the impact of KG heterogeneity on the performance of the proposed DAGCN model is investigated based on WK3l-15k and DBP15k datasets. The experimental results show that the proposed degree aware adversarial graph convolutional network (DAGCN) outperforms other state-of-the-art methods over all metrics, especially when the HED is large.},
  archive      = {J_NEUCOM},
  author       = {Hanchen Wang and Yining Wang and Jianfeng Li and Tao Luo},
  doi          = {10.1016/j.neucom.2022.02.002},
  journal      = {Neurocomputing},
  pages        = {99-109},
  shortjournal = {Neurocomputing},
  title        = {Degree aware based adversarial graph convolutional networks for entity alignment in heterogeneous knowledge graph},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Online association by continuous-discrete appearance
similarity measurement for multi-object tracking. <em>NEUCOM</em>,
<em>487</em>, 86–98. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Appearance similarity is of great importance for the association between objects and candidates. Recurrent models and similarity vector are two ways widely used by trackers for calculating similarities between objects and candidates. Recurrent models, like Long Short Term Memory network (LSTM), are capable of modeling the continuous change of object’s appearance in trajectory. But it is prone to identity (ID) switch when only employ recurrent models as appearance model. The similarity vector way is able to maintain correct IDs for objects when they reappear. But association fails easily when the object is partially occluded and similarity vector is used as the only appearance model. To obtain more accurate and robust appearance similarity, in this paper, we propose an online association by continuous-discrete appearance similarity measurement, OA-CDASM, for multi-object tracking. For continuous perspective, the concept of “smoothness” is proposed to explicitly model and use the continuous and smooth change of object’s appearance in trajectory. For discrete perspective, similarity vector is employed. By taking both continuous smoothness and discrete similarity vector into consideration, we can get the continuous-discrete appearance similarity measurement, CDASM, and further perform online association based on CDASM. Experimental results on three public benchmarks demonstrate the effectiveness of our work.},
  archive      = {J_NEUCOM},
  author       = {Hongli Li and Yongsheng Dong and Xuelong Li},
  doi          = {10.1016/j.neucom.2022.02.055},
  journal      = {Neurocomputing},
  pages        = {86-98},
  shortjournal = {Neurocomputing},
  title        = {Online association by continuous-discrete appearance similarity measurement for multi-object tracking},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view unsupervised feature selection with tensor
low-rank minimization. <em>NEUCOM</em>, <em>487</em>, 75–85. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To describe objects more comprehensively and accurately, multi-view learning has attracted considerable attention. Recently, graph embedding based multi-view feature selection methods have been proposed and shown efficient in many real applications. The existing methods generally construct one common graph matrix to exploit the local structure of multi-view data via the linear weight fusion or learning one common graph matrix across all views. However, since all views share the identical graph structure, this emphasizes the consistency too much, resulting in restricting the diversity among different views. In this paper, a tensor low-rank constrained graph embedding method is proposed for multi-view unsupervised feature selection. To embody the view-specific information of each view, our model constructs the graph structure for each corresponding view, respectively. To capture the consistency across views, a tensor low-rank regularization constraint is imposed on the tensor data formed by these graph matrices. An efficient optimization algorithm with theoretical convergence guarantee is designed to solve the proposed method. Extensive experimental results validate that the proposed method outperforms some state-of-the-art methods. The code of our model can be found at https://www.researchgate.net/publication/353902948_demoTLR .},
  archive      = {J_NEUCOM},
  author       = {Haoliang Yuan and Junyu Li and Yong Liang and Yuan Yan Tang},
  doi          = {10.1016/j.neucom.2022.02.005},
  journal      = {Neurocomputing},
  pages        = {75-85},
  shortjournal = {Neurocomputing},
  title        = {Multi-view unsupervised feature selection with tensor low-rank minimization},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spherical perspective on learning with normalization layers.
<em>NEUCOM</em>, <em>487</em>, 66–74. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Normalization Layers (NLs) are widely used in modern deep-learning architectures. Despite their apparent simplicity, their effect on optimization is not yet fully understood. This paper introduces a spherical framework to study the optimization of neural networks with NLs from a geometric perspective. Concretely, the radial invariance of groups of parameters, such as filters for convolutional neural networks , allows to translate the optimization steps on the L 2 L2 unit hypersphere. This formulation and the associated geometric interpretation shed new light on the training dynamics. Firstly, the first effective learning rate expression of Adam is derived. Then the demonstration that, in the presence of NLs, performing Stochastic Gradient Descent (SGD) alone is actually equivalent to a variant of Adam constrained to the unit hypersphere, stems from the framework. Finally, this analysis outlines phenomena that previous variants of Adam act on and their importance in the optimization process are experimentally validated.},
  archive      = {J_NEUCOM},
  author       = {Simon Roburin and Yann de Mont-Marin and Andrei Bursuc and Renaud Marlet and Patrick Pérez and Mathieu Aubry},
  doi          = {10.1016/j.neucom.2022.02.021},
  journal      = {Neurocomputing},
  pages        = {66-74},
  shortjournal = {Neurocomputing},
  title        = {Spherical perspective on learning with normalization layers},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of deep learning approaches to image restoration.
<em>NEUCOM</em>, <em>487</em>, 46–65. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an extensive review on deep learning methods for image restoration tasks. Deep learning techniques , led by convolutional neural networks , have received a great deal of attention in almost all areas of image processing , especially in image classification . However, image restoration is a fundamental and challenging topic and plays significant roles in image processing , understanding and representation. It typically addresses image deblurring, denoising , dehazing and super-resolution. There are substantial differences in the approaches and mechanisms in deep learning methods for image restoration. Discriminative learning based methods are able to deal with issues of learning a restoration mapping function effectively, while optimisation models based methods can further enhance the performance with certain learning constraints. In this paper, we offer a comparative study of deep learning techniques in image denoising , deblurring, dehazing, and super-resolution, and summarise the principles involved in these tasks from various supervised deep network architectures , residual or skip connection and receptive field to unsupervised autoencoder mechanisms. Image quality criteria are also reviewed and their roles in image restoration are assessed. Based on our analysis, we further present an efficient network for deblurring and a couple of multi-objective training functions for super-resolution restoration tasks. The proposed methods are compared extensively with the state-of-the-art methods with both quantitative and qualitative analyses. Finally, we point out potential challenges and directions for future research.},
  archive      = {J_NEUCOM},
  author       = {Jingwen Su and Boyan Xu and Hujun Yin},
  doi          = {10.1016/j.neucom.2022.02.046},
  journal      = {Neurocomputing},
  pages        = {46-65},
  shortjournal = {Neurocomputing},
  title        = {A survey of deep learning approaches to image restoration},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new label ordering method in classifier chains based on
imprecise probabilities. <em>NEUCOM</em>, <em>487</em>, 34–45. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Multi-Label Classification (MLC), Classifier Chains (CC) are considered simple and effective methods to exploit correlations between labels. A CC considers a binary classifier per label, in which the previous labels, according to an established order, are used as additional features. The label order strongly influences the performance of the CC, and there is no way to determine the optimal order so far. In this work, a new label ordering method based on label correlations is proposed. It uses a non-parametric model based on imprecise probabilities to estimate the correlations between pairs of labels. Then, it employs a greedy procedure that, to insert the labels in the chain, considers the correlations among the candidate labels and the ones already inserted, as well as the correlations between the candidate labels and the ones non-inserted yet. We argue that our proposal presents some advantages over the label ordering methods in CC developed so far based on label correlations. It is also shown that our proposal achieves better experimental results than the label ordering methods proposed so far that use label correlations in CC.},
  archive      = {J_NEUCOM},
  author       = {Serafín. Moral-García and Javier G. Castellano and Carlos J. Mantas and Joaquín Abellán},
  doi          = {10.1016/j.neucom.2022.02.048},
  journal      = {Neurocomputing},
  pages        = {34-45},
  shortjournal = {Neurocomputing},
  title        = {A new label ordering method in classifier chains based on imprecise probabilities},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hierarchical scheme for remaining useful life prediction
with long short-term memory networks. <em>NEUCOM</em>, <em>487</em>,
22–33. (<a href="https://doi.org/10.1016/j.neucom.2022.02.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining useful life (RUL) prediction is essential in prognostics and health management (PHM) applications, where data-driven approaches employ the tendency of the degradation process using operating data of complex systems, and have attracted more and more attention. With the idea that forecasting the time period before the equipment reaches the critical degradation stage (e.g., failure, fault, etc.), RUL prediction is usually formed as an optimization problem (in particular, a regression problem between the inputs–real-time measurements and the outputs–the RUL predictions). This work formulates the RUL prediction as a bi-level optimization problem, (i) the lower level is intended to forecast the time-series in the near future, and (ii) the upper level is to predict the RULs by integrating the available measurements up-to-date and the predicted ones by the lower-level prediction. To tackle the hierarchical optimization problem, a bi-level deep learning scheme is proposed for the machine RUL prediction, where long short-term memory (LSTM) networks are applied as of the unique characteristics in processing time-series and extracting recursive and non-recursive features among them. Case studies using PHM08 data challenge data set, 4 data sets in C-MAPSS package and 1 data set in the new CMAPSS dataset are implemented, to validate the proposed framework. The results show that the presented method outperforms the state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Tao Song and Chao Liu and Rui Wu and Yunfeng Jin and Dongxiang Jiang},
  doi          = {10.1016/j.neucom.2022.02.032},
  journal      = {Neurocomputing},
  pages        = {22-33},
  shortjournal = {Neurocomputing},
  title        = {A hierarchical scheme for remaining useful life prediction with long short-term memory networks},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mitigating domain mismatch in face recognition using style
matching. <em>NEUCOM</em>, <em>487</em>, 9–21. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite outstanding performance on public benchmarks, face recognition still suffers due to domain mismatch between training (source) and testing (target) data. Furthermore, these domains are not shared classes, which complicates domain adaptation . Since this is also a fine-grained classification problem which does not strictly follow the low-density separation principle, conventional domain adaptation approaches do not resolve these problems. In this paper, we formulate domain mismatch in face recognition as a style mismatch problem for which we propose two methods. First, we design a domain discriminator with human-level judgment to mine target-like images in the training data to mitigate the domain gap. Second, we extract style representations in low-level feature maps of the backbone model, and match the style distributions of the two domains to find a common style representation. Evaluations on verification and open-set and closed-set identification protocols show that both methods yield good improvements, and that performance is more robust if they are combined. Our approach is competitive with related work, and its effectiveness is verified in a practical application.},
  archive      = {J_NEUCOM},
  author       = {Chun-Hsien Lin and Bing-Fei Wu},
  doi          = {10.1016/j.neucom.2022.02.009},
  journal      = {Neurocomputing},
  pages        = {9-21},
  shortjournal = {Neurocomputing},
  title        = {Mitigating domain mismatch in face recognition using style matching},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SGD-rα: A real-time α-suffix averaging method for SGD with
biased gradient estimates. <em>NEUCOM</em>, <em>487</em>, 1–8. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient descent (SGD) is a simple and efficient method for solving large-scale stochastic optimization problems in machine learning . It has been shown that the convergence rate of SGD can be improved by α α -suffix averaging technique, abbreviated as SGD- α α . Classic analysis usually requires the assumption of unbiased gradient estimates, which is not suitable for many practical applications of SGD- α α such as non-independently and identically distributed (non-i.i.d.) scenarios. Another limitation is that SGD- α α needs to store all iterates in memory and thus cannot be implemented on-the-fly. To address the issues, we employ rounding technique to propose a real-time version of SGD- α α (named SGD- r α rα ), which can iteratively calculate the α α -suffix averaging and has the same convergence rate as that of SGD- α α . In particular, SGD- r α rα with biased gradient estimates can obtain sublinear convergence rate for strongly convex objectives. Numerical experiments on the benchmark datasets have shown the characteristics of SGD- r α rα and corroborated the theoretical results. The implementation of SGD- r α rα is available at: https://github.com/xudp100/SGD-ra .},
  archive      = {J_NEUCOM},
  author       = {Jianqi Luo and Jinlan Liu and Dongpo Xu and Huisheng Zhang},
  doi          = {10.1016/j.neucom.2022.02.063},
  journal      = {Neurocomputing},
  pages        = {1-8},
  shortjournal = {Neurocomputing},
  title        = {SGD-rα: A real-time α-suffix averaging method for SGD with biased gradient estimates},
  volume       = {487},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards hour-level crime prediction: A neural attentive
framework with spatial–temporal-categorical fusion. <em>NEUCOM</em>,
<em>486</em>, 286–297. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most complex social problems around the world, crime may bring the risk of dying or losing property to the public if not handled properly. Crime prediction which aims at predicting crime incidents before they happen is of great importance to fight against crime. Previous studies are concerned primarily with day-level crime prediction and have certain limitations on modeling complex spatial–temporal-categorical dependency contained in the criminal activities as well as utilizing external factors to facilitate the forecast. In this paper, we develop a novel Neural Attentive framework for Hour-level Crime prediction (NAHC) to cope with these challenges. Specifically, we first adopt the priori knowledge-based data enhancement strategy to alleviate the zero-inflated issue raised in hour-level settings. Then, multi-graph convolutional networks are applied to capture spatial dependency from different aspects. After that, we integrate gated recurrent units with a temporal attention mechanism to jointly address temporal dependency and capture time-sensitive external factors. A categorical attention mechanism is proposed for dealing with categorical dependency and finally a fully connected network is utilized to generate the final prediction results. Extensive experiments on two real-world crime datasets demonstrate the effectiveness of our framework over the state-of-the-art comparing methods.},
  archive      = {J_NEUCOM},
  author       = {Weichao Liang and Youquan Wang and Haicheng Tao and Jie Cao},
  doi          = {10.1016/j.neucom.2021.11.052},
  journal      = {Neurocomputing},
  pages        = {286-297},
  shortjournal = {Neurocomputing},
  title        = {Towards hour-level crime prediction: A neural attentive framework with spatial–temporal-categorical fusion},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Co-attention dictionary network for weakly-supervised
semantic segmentation. <em>NEUCOM</em>, <em>486</em>, 272–285. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose the co-attention dictionary network (CODNet) for weakly-supervised semantic segmentation using only image-level class labels. The CODNet model exploits extra semantic information by jointly leveraging a pair of samples with common semantics through co-attention rather than processing them independently. The inter-sample similarities of spatially distributed deep features are computed to merge reference features through non-local connections. To discover similar patterns regardless of appearance variations, we propose to extract image representations by equipping the neural networks with dictionary learning which provides the universal basis elements for different images. Based on the CODNet model, we propose a multi-reference class activation map (MR-CAM) algorithm which generates semantic segmentation masks for a target image by jointly merging semantic cues from multiple reference images. Experimental results on the PASCAL VOC 2012 and MSCOCO benchmark datasets for weakly-supervised semantic segmentation show that the proposed algorithm performs favorably against the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Weitao Wan and Jiansheng Chen and Ming-Hsuan Yang and Huimin Ma},
  doi          = {10.1016/j.neucom.2021.11.046},
  journal      = {Neurocomputing},
  pages        = {272-285},
  shortjournal = {Neurocomputing},
  title        = {Co-attention dictionary network for weakly-supervised semantic segmentation},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DCNN based human activity recognition framework with depth
vision guiding. <em>NEUCOM</em>, <em>486</em>, 261–271. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The smartphone-based human activity recognition (HAR) provides abundant healthcare guidance for telemedicine and clinic treatment. The continually increasing daily activities cause many difficulties for recognition and labeling. Although multimodal data fusion and artificial intelligence (AI) techniques can solve these problems, big data collection and labeling are still heavy. This paper proposes a remarkable depth data-guided framework based on smartphones for complex HAR and automatic labeling. The hardware platform is utilized to collect information of depth vision from the Microsoft Kinect camera and Inertial Measurement Unit (IMU) signals from the smartphone simultaneously. This framework consists of five clustering layers and deep learning (DL) based classification model to identify 12 complex daily activities. The results show that the hierarchical k-medoids (Hk-medoids) algorithm obtains the labels with high accuracy ( 93.89\% 93.89\% ). Furthermore, the performance evaluation of the DCNN model is evaluated better by comparing it with other machine learning (ML) and DL methods.},
  archive      = {J_NEUCOM},
  author       = {Wen Qi and Ning Wang and Hang Su and Andrea Aliverti},
  doi          = {10.1016/j.neucom.2021.11.044},
  journal      = {Neurocomputing},
  pages        = {261-271},
  shortjournal = {Neurocomputing},
  title        = {DCNN based human activity recognition framework with depth vision guiding},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Sensor network based distributed state estimation for
maneuvering target with guaranteed performances. <em>NEUCOM</em>,
<em>486</em>, 250–260. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a sensor network information fusion based distributed state estimation algorithm for tracking non-cooperative maneuvering target . In order to lower the communication burden and energy consumption, an event-triggered mechanism is introduced. The distributed state estimation algorithm for maneuvering target tracking is designed by two stages, namely, local filtering stage and consensus fusion stage. The algorithm proposed in this paper can be used to obtain the high accurate state estimation of the target by introducing a multiple suboptimal fading factor even when the target makes big maneuvering. Moreover, a contribution factor is designed in the information fusion stage to improve the accuracy of maneuvering target state estimation and reduce the consensus iteration times . Besides, the stochastic boundedness of the event-triggered distributed estimation algorithm is proved by introducing a stochastic process . Finally, Monte Carlo numerical simulation example is designed to illustrate the effectiveness of the algorithm.},
  archive      = {J_NEUCOM},
  author       = {Zheng Zhang and Xiwang Dong and Liang Han and Qingdong Li and Zhang Ren},
  doi          = {10.1016/j.neucom.2021.11.042},
  journal      = {Neurocomputing},
  pages        = {250-260},
  shortjournal = {Neurocomputing},
  title        = {Sensor network based distributed state estimation for maneuvering target with guaranteed performances},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatial-wise and channel-wise feature uncertainty for
occluded person re-identification. <em>NEUCOM</em>, <em>486</em>,
237–249. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occluded person re-identification is a challenging task since the available data often suffers from information incompleteness and spatial misalignment. Most state-of-the-art occluded models rely on the external model to provide additional semantic information. However, for the time being, external models, such as the human parsing model and the pose estimation model cannot provide accurate semantic information under a complex occlusion environment and may introduce errors to the Re-ID model instead. In this paper, we propose an occluded person Re-ID model that mines the latent recognizable information of the person image itself, without the help of external models. Feature/Data uncertainty can reduce the influence of noisy samples in datasets and has been discussed in person Re-ID and face recognition, we extend the uncertainty to the micro feature level, and propose the spatial-wise and channel-wise feature uncertainty to constantly refine the features in the spatial domain and the channel domain respectively during feature construction by weakening the influence of noise features. Extensive experiments on the occluded datasets and holistic datasets have proved the effectiveness of our proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Yuxuan Shi and Weiyi Tian and Hefei Ling and Zongyi Li and Ping Li},
  doi          = {10.1016/j.neucom.2021.11.038},
  journal      = {Neurocomputing},
  pages        = {237-249},
  shortjournal = {Neurocomputing},
  title        = {Spatial-wise and channel-wise feature uncertainty for occluded person re-identification},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on cooperative control strategies for DC
microgrids. <em>NEUCOM</em>, <em>486</em>, 225–236. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed generators have been widely used in modern power systems, and microgrids are becoming a key concept for the integration of multiple distributed generators and clusters of loads with great efficiency and high system reliability. In a microgrid, the control strategy is one of the most important issues. Various control schemes have been proposed to achieve the cooperation of distributed generators in a microgrid. This paper surveys cooperative control strategies for multiple distributed generators in DC microgrids. The three popular coordinated control strategies are presented: decentralized control, centralized control, and distributed control. The advantages and drawbacks of the control strategies are compared. Some intelligent control methods such as fuzzy logic control and neural network approaches are also briefly introduced in the context of microgrids. Further research trends and challenges in this area are also discussed.},
  archive      = {J_NEUCOM},
  author       = {Duy-Long Nguyen and Hong-Hee Lee},
  doi          = {10.1016/j.neucom.2021.11.036},
  journal      = {Neurocomputing},
  pages        = {225-236},
  shortjournal = {Neurocomputing},
  title        = {A survey on cooperative control strategies for DC microgrids},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep discrete cross-modal hashing with multiple supervision.
<em>NEUCOM</em>, <em>486</em>, 215–224. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep hashing has been widely used for large-scale cross-modal retrieval benefited from the low storage cost and fast search speed. However, most existing deep supervised methods only preserve the instance-pairwise relationship supervised by the semantic similarity matrix , which always inufficient heterogeneous correlation. Thus, we propose the Deep Discrete Cross-Modal Hashing with Multiple Supervision ( DDCH ms DDCHms ) to further enhance the semantic consistency of heterogeneous modalities. It improves the performance of semantic information retrieval with the joint supervision of instance-pairwise, instance-labeled and class-wise similarities. Specifically, we firstly utilize the instance-pairwise similarity matrix to supervise the learning process of heterogeneous networks and it keeps the pairwise correlation from the perspective of instance-instance. Specially, we design a semantic network to fully exploit the semantic information implicated in labels, which is also used to supervise multi-modal networks on instance-label level. Furthermore, we propose the class-wise hash codes to cooperate with the intrinsic label matrix as the prototypes, and it guides the hash learning and further ensures the precision and compactness of the learned hash codes. In addition, we design different discrete optimization strategies to optimize the class-wise hash codes and unified hash codes, respectively. That avoids the optimization errors and ensures the high-quality of learned hash codes. Experiments on three popular datasets indicate that our method outperforms other state-of-the-art methods in terms of cross-modal retrieval.},
  archive      = {J_NEUCOM},
  author       = {En Yu and Jianhua Ma and Jiande Sun and Xiaojun Chang and Huaxiang Zhang and Alexander G. Hauptmann},
  doi          = {10.1016/j.neucom.2021.11.035},
  journal      = {Neurocomputing},
  pages        = {215-224},
  shortjournal = {Neurocomputing},
  title        = {Deep discrete cross-modal hashing with multiple supervision},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Noise/fault aware regularization for incremental learning in
extreme learning machines. <em>NEUCOM</em>, <em>486</em>, 200–214. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates noise/fault tolerant incremental algorithms for the extreme learning machine (ELM) concept. Existing incremental ELM algorithms can be classified into two approaches: non-recomputation and recomputation. This paper first formulates a noise/fault aware objective function for nonlinear regression problems. Instead of developing noise/fault aware algorithms for the two computational approaches in a one-by-one manner, this paper uses two representative incremental algorithms, namely incremental ELM (I-ELM) and error minimized ELM (EM-ELM), to develop two noise/fault aware incremental algorithms. The proposed algorithms are called generalized I-ELM (GI-ELM) and generalized EM-ELM (GEM-ELM). The GI-ELM adds k hidden nodes into the existing network at each incremental step without recomputing the existing weights. To have a fair comparison, we consider a modified version of I-ELM as a comparison algorithm. The simulation demonstrates that the noise/fault tolerance of the proposed GI-ELM is better than that of the modified I-ELM. In the GEM-ELM, k hidden nodes are added into the existing network at each incremental step. Meanwhile, all output weights are recomputed based on a recursive formula. We also consider a modified version of EM-ELM as a comparison algorithm. The simulation demonstrates that the noise/fault tolerance of the proposed GEM-ELM is better than that of the modified EM-ELM. Moreover, we demonstrate that the multiple set concept can further enhance the performance of the two proposed algorithms. Following our research results, one can make some non-noise/fault tolerant incremental algorithms to be noise/fault tolerant.},
  archive      = {J_NEUCOM},
  author       = {Hiu-Tung Wong and Ho-Chun Leung and Chi-Sing Leung and Eric Wong},
  doi          = {10.1016/j.neucom.2021.11.026},
  journal      = {Neurocomputing},
  pages        = {200-214},
  shortjournal = {Neurocomputing},
  title        = {Noise/fault aware regularization for incremental learning in extreme learning machines},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A neural architecture generator for efficient search space.
<em>NEUCOM</em>, <em>486</em>, 189–199. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) has made significant progress in recent years. However, the existing methods usually search architectures in a small-scale, well-designed architecture space, discover only one architecture in a single search, and hardly rework, which severely limits their potential. In this paper, we propose a novel neural architecture generator (NAG) that can efficiently sample architectures in a large-scale architecture space. Like a generative adversarial network (GAN), our model consists of two components: (1) a generator that can generate directed acyclic graphs (DAGs) as cells or blocks of neural architectures and (2) a discriminator that can estimate the probability that a DAG comes from cells of real architectures rather than the generator. Furthermore, we employ a random search with NAG (RS-NAG) to discover the optimal architecture according to the customized requirements. Experimental results show that the NAG can generate diverse architectures with our customized requirements multiple times after one adversary training. Furthermore, compared with the existing methods, our RS-NAG achieves the competitive results with 2.50\% and 25.5\% top-1 accuracies on two benchmark datasets – CIFAR-10 and ImageNet.},
  archive      = {J_NEUCOM},
  author       = {Kun Jing and Jungang Xu and Zhen Zhang},
  doi          = {10.1016/j.neucom.2021.10.118},
  journal      = {Neurocomputing},
  pages        = {189-199},
  shortjournal = {Neurocomputing},
  title        = {A neural architecture generator for efficient search space},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on mutual information based medical image
registration algorithms. <em>NEUCOM</em>, <em>486</em>, 174–188. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of aligning one image, in the coordinate system of another is called registration. Image registration is vital in the medical domain and is used for diagnosis, therapy planning, and treatment of diseases. Due to its huge applicability and importance, medical image registration has emerged to be a separate domain of research. Beginning from the invasive landmark based registration, innumerable algorithms have been proposed to register two images of the human physiology. However, a breakthrough in the literature occurred when an information theory based measure, mutual information was used to register two images. Since then a large number of new algorithms have developed, which use mutual information for fully automatic registration of medical images. This paper is a survey of these algorithms. Beginning from its development, it discusses about some of the major works done on mutual information based image registration. Some comparative studies with other algorithms have also been discussed. The paper ends with a discussion of the developments in medical image registration algorithms post mutual information, which primarily include deep neural network (DNN) based algorithms.},
  archive      = {J_NEUCOM},
  author       = {Debapriya Sengupta and Phalguni Gupta and Arindam Biswas},
  doi          = {10.1016/j.neucom.2021.11.023},
  journal      = {Neurocomputing},
  pages        = {174-188},
  shortjournal = {Neurocomputing},
  title        = {A survey on mutual information based medical image registration algorithms},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Measure-pseudo almost periodic dynamical behaviors for BAM
neural networks with d operator and hybrid time-varying delays.
<em>NEUCOM</em>, <em>486</em>, 160–173. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we are interested in a class of Bi-directional associative memory neural networks (BAMNNs) with hybrid time-varying delays and D operator. We establish some sufficient conditions to guarantee the existence and global exponential stability of measure-pseudo almost periodic solutions of the considered BAMNNs, using contraction mapping principle, exponential dichotomy theory, differential inequality techniques, and the properties of the measure-pseudo almost periodic functions. A numerical example along with a graphical illustration are presented to support the effectiveness and feasibility of the obtained results. The results in this paper are original and complement the previous outcomes.},
  archive      = {J_NEUCOM},
  author       = {Moez Ayachi},
  doi          = {10.1016/j.neucom.2021.11.020},
  journal      = {Neurocomputing},
  pages        = {160-173},
  shortjournal = {Neurocomputing},
  title        = {Measure-pseudo almost periodic dynamical behaviors for BAM neural networks with d operator and hybrid time-varying delays},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data multiplexed and hardware reused architecture for deep
neural network accelerator. <em>NEUCOM</em>, <em>486</em>, 147–159. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite many decades of research on high-performance Deep Neural Network (DNN) accelerators, their massive computational demand still requires resource-efficient, optimized and parallel architecture for computational acceleration. Contemporary hardware implementations of DNNs face the burden of excess area requirement due to resource-intensive elements such as multipliers and non-linear Activation Functions (AFs). This paper proposes DNN with reused hardware-costly AF by multiplexing data using shift-register. The on-chip quantized log 2 log2 based memory addressing with an optimized technique is used to access input features, weights, and biases. This way the external memory bandwidth requirement is reduced and dynamically adjusted for DNNs. Further, high-throughput and resource-efficient memory elements for sigmoid activation function are extracted using the Taylor series and its order expansion have been tuned for better test accuracy. The performance is validated and compared with previous works for the MNIST dataset. Besides, the digital design of AF is synthesized at 45 nm nm technology node and physical parameters are compared with previous works. The proposed hardware reused architecture is verified for neural network 16:16:10:4 using 8-bit dynamic fixed-point arithmetic and implemented on Xilinx Zynq xc7z010clg400 SoC using 100 MHz clock. The implemented architecture uses 25\% less hardware resources and consumes 12\% less power without performance loss, compared to other state-of-the-art implementations, as lower hardware resources and power consumption are especially important for increasingly important edge computing solutions.},
  archive      = {J_NEUCOM},
  author       = {Gopal Raut and Anton Biasizzo and Narendra Dhakad and Neha Gupta and Gregor Papa and Santosh Kumar Vishvakarma},
  doi          = {10.1016/j.neucom.2021.11.018},
  journal      = {Neurocomputing},
  pages        = {147-159},
  shortjournal = {Neurocomputing},
  title        = {Data multiplexed and hardware reused architecture for deep neural network accelerator},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Multimodal medical image segmentation using multi-scale
context-aware network. <em>NEUCOM</em>, <em>486</em>, 135–146. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal medical image segmentation with different imaging devices is a key but challenging task in medical image visual analysis and reasoning. Recently, U-Net based networks achieved considerable success in semantic segmentation of medical image. However, U-Net utilizes a skip-connection to connect two symmetric encoder and decoder layers. Although the single granularity information of the encoder layer is preserved through skip connection, the rich multi-scale spatial information is ignored, which greatly affects its performance in the segmentation task. In this paper, a multi-scale context-aware network (CA-Net) for multimodal medical image segmentation is proposed, which captures rich context information with dense skip connection and assigns distinct weights to different channels. CA-Net consists of four key components, namely encoder module, multi-scale context fusion (MCF) module, decoder module, and dense skip connection module. The proposed MCF module extracts multi-scale spatial information through a spatial context fusion (SCF) block, and learn to balance channel-wise features through a Squeeze-and-Excitation (SE) block. Extensive experiments demonstrate that our model achieves state-of-the-art performance on three benchmark datasets of different modalities, including skin lesion segmentation in dermoscopy, lung segmentation in CT images, and blood vessel segmentation in retina images.},
  archive      = {J_NEUCOM},
  author       = {Xue Wang and Zhanshan Li and Yongping Huang and Yingying Jiao},
  doi          = {10.1016/j.neucom.2021.11.017},
  journal      = {Neurocomputing},
  pages        = {135-146},
  shortjournal = {Neurocomputing},
  title        = {Multimodal medical image segmentation using multi-scale context-aware network},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive multi-task learning for cross domain and modal
person re-identification. <em>NEUCOM</em>, <em>486</em>, 123–134. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (re-ID) aims at matching a person-of-interest across various non-overlap cameras with distinguished visual appearance variances. Pre-existing research methods mainly employ deep neural models to train large-scale person re-ID datasets, achieving good performance. However, these methods are primarily deployed only on visual data, which can be easily influenced by the environment variances (e.g., viewpoints, poses, and illuminations). In this paper, we propose an adaptive multi-task learning (MTL) scheme for cross domain and modal person re-ID. It can effectively utilize the visual and language information from multiple datasets for improving learning performance. Comprehensive experiments are also conducted on the widely-used person re-ID datasets, i.e., Market-1501 and DukeMTMC-reID, validating the effectiveness of the proposed method. It can model the domain difference and the relationship between the vision and language modalities and achieve state-of-the-art performance. The source code of our proposed method will be available at https://github.com/emdata-ailab/Multitask_Learning_ReID .},
  archive      = {J_NEUCOM},
  author       = {Shiyang Yan and Jianan Zhao and Lin Xu},
  doi          = {10.1016/j.neucom.2021.11.016},
  journal      = {Neurocomputing},
  pages        = {123-134},
  shortjournal = {Neurocomputing},
  title        = {Adaptive multi-task learning for cross domain and modal person re-identification},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive synchronization of fractional-order complex-valued
coupled neural networks via direct error method. <em>NEUCOM</em>,
<em>486</em>, 114–122. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, without dividing the fractional-order complex-valued coupled neural networks (FCVCNNs) into two real-valued systems, the problem of synchronization is investigated for FCVCNNs with time-varying coupling strength. To achieve synchronization, by updating coupling strength, two feasible adaptive protocols are designed, 1) a fractional-order adaptive strategy depending on global information; 2) a fractional-order adaptive law relying on the local information based on the connected dominating set theory. Additionally, instead of making the weighted average technique or the solution of the isolated node equation as synchronization reference value, direct error method is adopted to realize synchronization, which offers a flexible way in analysis of FCVCNNs. At last, a numerical simulation is provided to illustrate the validity of theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Bibo Zheng and Zhanshan Wang},
  doi          = {10.1016/j.neucom.2021.11.015},
  journal      = {Neurocomputing},
  pages        = {114-122},
  shortjournal = {Neurocomputing},
  title        = {Adaptive synchronization of fractional-order complex-valued coupled neural networks via direct error method},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The devil is in the face: Exploiting harmonious
representations for facial expression recognition. <em>NEUCOM</em>,
<em>486</em>, 104–113. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the recent effort from computer vision community, facial expression recognition (FER) remains a largely unsolved problem. This is because the appearance of people’s face undergoes dramatic changes due to changes in view angle, pose, illumination plus ambiguous facial expressions and low-quality facial images. In this work, we show the advantage of feature representation learning by dynamically graph message propagating subject to FER discriminative learning constraints and minimizing the distance of expression-agnostic transformed instance feature pairs. Specifically, we formulate a novel Harmonious Representation Learning (HRL) model for joint learning of landmark-guided graph message propagation, and spatially invariant feature learning using only generic matching metrics. Extensive comparative evaluations demonstrate the superiority of our proposed approach for FER over a variety of state-of-the-art methods on three major benchmark datasets including SFEW 2.0, RAF-DB, and CK+.},
  archive      = {J_NEUCOM},
  author       = {Jiayi Han and Liang Du and Xiaoqing Ye and Li Zhang and Jianfeng Feng},
  doi          = {10.1016/j.neucom.2022.02.054},
  journal      = {Neurocomputing},
  pages        = {104-113},
  shortjournal = {Neurocomputing},
  title        = {The devil is in the face: Exploiting harmonious representations for facial expression recognition},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Close-set camera style distribution alignment for single
camera person re-identification. <em>NEUCOM</em>, <em>486</em>, 93–103.
(<a href="https://doi.org/10.1016/j.neucom.2022.02.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of person re-identification (ReID) is to find the same person under different cameras and the basic difficulty lies in the need for large amounts of cross-camera pedestrian annotations. In reality, annotating cross-camera pedestrians is time-consuming especially in large-scale surveillance camera networks. This paper focuses on addressing the ReID problem under single-camera training (SCT) setting, where each person of the training set only appears in one camera. Due to the lack of cross-camera pedestrian annotations, it is difficult to effectively eliminate the camera style interference by narrowing the distance between the image features of the same person. To address this problem, we propose a close-set camera style distribution alignment (C 2 SDA) framework for SCT ReID . In order to reduce the camera-style interference from both instance- and distribution-levels simultaneously, we first design an instance-distribution camera style alignment module that directly aligns the feature distribution of input images under each camera and then trains the model at instance level with the aligned features. Secondly, we further design an augment close-set camera style distribution module that transforms the camera feature distribution alignment problem from open-set into close-set one, which preserving the discriminative ability of features during the alignment process. Experimental results verify that our framework can significantly improve the ReID performance under SCT setting and surpass the current SOTA methods. The source code is available at https://github.com/HongweiZhang97/CCSDA .},
  archive      = {J_NEUCOM},
  author       = {Guoqing Zhang and Hongwei Zhang and Yuhao Chen and Yuhui Zheng},
  doi          = {10.1016/j.neucom.2022.02.051},
  journal      = {Neurocomputing},
  pages        = {93-103},
  shortjournal = {Neurocomputing},
  title        = {Close-set camera style distribution alignment for single camera person re-identification},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Supervised outlier detection for classification and
regression. <em>NEUCOM</em>, <em>486</em>, 77–92. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection , i.e., the task of detecting points that are markedly different from the data sample, is an important challenge in machine learning . When a model is built, these special points can skew the model training and result in less accurate predictions. Due to this fact, it is important to identify and remove them before building any supervised model and this is often the first step when dealing with a machine learning problem. Nowadays, there exists a very large number of outlier detector algorithms that provide good results, but their main drawbacks are their unsupervised nature together with the hyperparameters that must be properly set for obtaining good performance. In this work, a new supervised outlier estimator is proposed. This is done by pipelining an outlier detector with a following a supervised model, in such a way that the targets of the later supervise how all the hyperparameters involved in the outlier detector are optimally selected. This pipeline-based approach makes it very easy to combine different outlier detectors with different classifiers and regressors. In the experiments done, nine relevant outlier detectors have been combined with three regressors over eight regression problems as well as with two classifiers over another eight binary and multi-class classification problems. The usefulness of the proposal as an objective and automatic way to optimally determine detector hyperparameters has been proven and the effectiveness of the nine outlier detectors has also been analyzed and compared.},
  archive      = {J_NEUCOM},
  author       = {Ángela Fernández and Juan Bella and José R. Dorronsoro},
  doi          = {10.1016/j.neucom.2022.02.047},
  journal      = {Neurocomputing},
  pages        = {77-92},
  shortjournal = {Neurocomputing},
  title        = {Supervised outlier detection for classification and regression},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-directional rain streak removal based on infimal
convolution of oscillation TGV. <em>NEUCOM</em>, <em>486</em>, 61–76.
(<a href="https://doi.org/10.1016/j.neucom.2022.02.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image deraining is essential in both image processing and computer vision. However it is still challenging to remove rain streaks, due to the fact that they are complex and usually have multiple directions. In this paper, we propose a novel infimal convolution type functional based model to remove multi-directional rain streaks. Specifically, we employ total generalized variation (TGV) to represent the rain-free background and m -fold infimal convolution of oscillation TGV ( ICTGV m osci ICTGVmosci ) to capture the rain streaks with m different directions. The existence of solutions to the proposed model is proved. We also design an algorithm using the classical first-order Primal–Dual method for solving the proposed model. Numerical experiments on both synthetic and real images demonstrate that the proposed model outperforms the state-of-the-art methods quantitatively and qualitatively.},
  archive      = {J_NEUCOM},
  author       = {Yanan Gu and Yiming Gao and Hairong Liu and Dong Wang},
  doi          = {10.1016/j.neucom.2022.02.059},
  journal      = {Neurocomputing},
  pages        = {61-76},
  shortjournal = {Neurocomputing},
  title        = {Multi-directional rain streak removal based on infimal convolution of oscillation TGV},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ASPCNet: Deep adaptive spatial pattern capsule network for
hyperspectral image classification. <em>NEUCOM</em>, <em>486</em>,
47–60. (<a href="https://doi.org/10.1016/j.neucom.2022.02.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous studies have shown the great potential of capsule networks for the spatial contextual feature extraction from hyperspectral images (HSIs). However, the sampling locations of the convolutional kernels of capsules are fixed and cannot be adaptively changed according to the inconsistent semantic information of HSIs. Based on this observation, this paper proposes an adaptive spatial pattern capsule network (ASPCNet) architecture by developing an adaptive spatial pattern (ASP) unit, that can rotate the sampling location of convolutional kernels on the basis of an enlarged receptive field. Note that this unit can learn more discriminative representations of HSIs with fewer parameters. Specifically, two cascaded ASP-based convolution operations (ASPConvs) are applied to input images to learn relatively high-level semantic features , transmitting hierarchical structures among capsules more accurately than the use of the most fundamental features. Furthermore, the semantic features are fed into ASP-based conv-capsule operations (ASPCaps) to explore the shapes of objects among the capsules in an adaptive manner, further exploring the potential of capsule networks. Finally, the class labels of image patches centered on test samples can be determined according to the fully connected capsule layer. Experiments on three public datasets demonstrate that ASPCNet can yield competitive performance with higher accuracies than state-of-the-art methods. For the convenience of follow-up research and engineering applications, we packaged the algorithm into an arbitrary plug-in module and released it at https://github.com/Cimy-wang.},
  archive      = {J_NEUCOM},
  author       = {Jinping Wang and Xiaojun Tan and Jianhuang Lai and Jun Li},
  doi          = {10.1016/j.neucom.2022.02.058},
  journal      = {Neurocomputing},
  pages        = {47-60},
  shortjournal = {Neurocomputing},
  title        = {ASPCNet: Deep adaptive spatial pattern capsule network for hyperspectral image classification},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design of stabilized fuzzy relation-based neural networks
driven to ensemble neurons/layers and multi-optimization.
<em>NEUCOM</em>, <em>486</em>, 27–46. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a design methodology based on fuzzy relation-based neural networks for stabilized network structure is introduced to cope with over-fitting as well as multi-collinearity problems which generally appear in conventional fuzzy neural networks . The design method of the proposed self-organizing network structure provides an efficient solution to construct the stabilized Fuzzy Relation-based Neural Networks (FRNN) through a synergy of multi-techniques such as ensemble neurons/layers, L2-norm regularization , compromise technique, and multi-optimization, in order to generate the structure of the multi-layered self-organizing network designed with the aid of the learning as well as novel structural design. The overall network structure is realized with the aid of parallel network structure with newly added layers as well as effective node selection method through the combination technique of both a sum of squared coefficients (SSC) and performance index (PI) as a node selection criterion for each layer in FRNN. Ensemble neurons consist of the current inputs and the original inputs, and they serve to reduce the bias of the proposed FRNN by maintaining the information of the original inputs. Also, ensemble layers stand for the combination of the current layer and the front layer, and they play a role for control the variance of the model by taking into account the output of the previous layers. The least square error estimation (LSE)-based learning method with L2-norm regularization is used for constructing the stabilized network architecture , and their ensuring design methodologies result in alleviating the overfitting phenomenon and also enhancing the generalization ability . For the performance enhancement of FRNN directly affected by some parameters such as the number of input variables, collocation of the specific subset of input variables, the number of membership functions per each variable, and the order of polynomial in the consequent parts of the fuzzy rules, multi-particle swarm optimization (MPSO) is exploited for the effectively structural as well as parametric optimization of the proposed networks. That is, the multi-optimization helps achieve a compromise between the better generation performance and the alleviated over-fitting leading to the stabilization of the proposed multi-layered self-organizing network structure realized with the aid of synergistic multi-techniques and ensemble structures such as a) L2-norm regularization-based LSE learning, b) combination technique for effective node selection through the combination of SSC and PI, and c) a novel parallel network structure including newly added layers and node selection method. The performance of the proposed network structure is quantified by comprehensive experiments and comparative analysis.},
  archive      = {J_NEUCOM},
  author       = {Zheng Wang and Sung-Kwun Oh and Witold Pedrycz and Eun-Hu Kim and Zunwei Fu},
  doi          = {10.1016/j.neucom.2022.02.036},
  journal      = {Neurocomputing},
  pages        = {27-46},
  shortjournal = {Neurocomputing},
  title        = {Design of stabilized fuzzy relation-based neural networks driven to ensemble neurons/layers and multi-optimization},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). BTN: Neuroanatomical aligning between visual object
tracking in deep neural network and smooth pursuit in brain.
<em>NEUCOM</em>, <em>486</em>, 16–26. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by neuroanatomy , deep neural networks (DNNs) have recently developed from shallow network structures to exceedingly deep structures, providing excellent visual tracking results. However, standard DNNs usually do not easily connect with brain areas on account of their excessive network depth and absent biological constraints, such as recurrent connections. We propose a brain-like tracking network (BTN) with four neuroanatomically mapped regions and recurrence, guided by the brain-like tracking score (BTS), a novel benchmark to measure the model similarity of the human smooth pursuit pathway. In addition, we propose that the middle temporal (MT) and medial superior temporal (MST) areas in the cerebral cortex are equivalent to the designed network structure on the basis of the continuous motion perception of the tracking pathway, and indicate that the metrics between the neuroanatomical similarity in the cerebral cortex and visual tracking of the DNN are compatible. Despite having significant tracking performance on the Tracking-Gump dataset, the BTN has achieved a high BTS. In summary, this research builds a BTN, a brain-like and recurrent DNN, as the first model of the cortical pathway of smooth pursuit.},
  archive      = {J_NEUCOM},
  author       = {Haidong Wang and Zhiyong Li and Ke Nai and Jin Yuan and Shutao Li and Xianghua Li},
  doi          = {10.1016/j.neucom.2022.02.031},
  journal      = {Neurocomputing},
  pages        = {16-26},
  shortjournal = {Neurocomputing},
  title        = {BTN: Neuroanatomical aligning between visual object tracking in deep neural network and smooth pursuit in brain},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Collaborative and adversarial deep transfer auto-encoder for
intelligent fault diagnosis. <em>NEUCOM</em>, <em>486</em>, 1–15. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep transfer learning provides an advanced analytical tool for intelligent fault diagnosis to learn shared fault knowledge in industrial scenarios whereby datasets are collected from different operating conditions. The majority of previous approaches consist in minimizing the domain discrepancy at the domain level, but they may cause erroneous mappings for local category features. Recently, to prioritize the feature discriminability , several adversarial learning approaches with bi-classifier have been developed by using the classification disagreement. However, they suffer from a restricted representation of the classification disagreement, and may fail to align category-level features when domain gaps are large. To address these weaknesses, we proposed a Collaborative and Adversarial Deep Transfer model based on a convolutional Auto-encoder (CADTA) for intelligent fault diagnosis . Specifically, by leveraging a couple of multi-task classifiers, a joint subspace feature discrimination method involving duplex adversarial learning is proposed to promote the category-level feature discriminability . Then, a collaborative transfer scheme is built to integrate the domain similarity learning and the joint subspace feature discrimination hierarchically into a convolutional Auto-encoder, in which the domain similarity learning is achieved by adapting the intermediate feature representations in terms of high-order moments. For the sake of efficient model training, a stage-wise adversarial training process is presented correspondingly. Extensive experiments of diverse transfer tasks based on two rolling bearing datasets and three transfer fault diagnosis cases demonstrate that CADTA outperforms the existing state-of-the-art deep transfer learning methods.},
  archive      = {J_NEUCOM},
  author       = {Yulin Ma and Jun Yang and Lei Li},
  doi          = {10.1016/j.neucom.2022.02.050},
  journal      = {Neurocomputing},
  pages        = {1-15},
  shortjournal = {Neurocomputing},
  title        = {Collaborative and adversarial deep transfer auto-encoder for intelligent fault diagnosis},
  volume       = {486},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bringing AI to edge: From deep learning’s perspective.
<em>NEUCOM</em>, <em>485</em>, 297–320. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing and artificial intelligence (AI), especially deep learning algorithms , are gradually intersecting to build the novel system, namely edge intelligence . However, the development of edge intelligence systems encounters several challenges, and one of these challenges is the computational gap between computation-intensive deep learning algorithms and less-capable edge systems. Due to the computational gap, many edge intelligence systems cannot meet the expected performance requirements. To bridge the gap, a plethora of new techniques and optimization methods were proposed in the past years: lightweight deep learning models , network compression, and efficient neural architecture search. Although some reviews or surveys have partially covered this large body of literature, we lack a systematic and comprehensive review to discuss all aspects of these deep learning techniques which are critical for edge intelligence implementation. As various and diverse methods, applicable to edge systems, are proposed, a holistic review would enable edge computing engineers and the community to understand the state-of-the-art deep learning techniques that are instrumental for edge intelligence and to facilitate the development of edge intelligence systems. This paper surveys the representative and latest deep learning techniques that are useful for edge intelligence systems, including hand-crafted models, model compression , hardware-aware neural architecture search, and adaptive deep learning models . Finally, based on observations and simple experiments we conducted, we discuss some future directions.},
  archive      = {J_NEUCOM},
  author       = {Di Liu and Hao Kong and Xiangzhong Luo and Weichen Liu and Ravi Subramaniam},
  doi          = {10.1016/j.neucom.2021.04.141},
  journal      = {Neurocomputing},
  pages        = {297-320},
  shortjournal = {Neurocomputing},
  title        = {Bringing AI to edge: From deep learning’s perspective},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive offloading and scheduling algorithm for big data
based mobile edge computing. <em>NEUCOM</em>, <em>485</em>, 285–296. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data will cause the system for business public opinion to be overburdened, and dynamic changes in computing resources will cause tasks to be delayed. To end the situation, this study assigns non-fixed execution time to each task node based on the task soft deadline and task constraints and solves the problem of difficult task scheduling caused by task dependency constraints. Aiming at the problem of task delay caused by dynamic changes of computing resources, this paper proposes an adaptive offloading and scheduling algorithm for dependent tasks in the mobile edge computing environment. This study takes the economic efficiency analysis system as an example and uses the resource allocation management algorithm based on linked lists and edge servers to study the communication resource allocation management of the economic efficiency analysis system. In addition, this study designs experiments to perform performance analysis of the algorithm proposed by this study. The research results show that the proposed algorithm has an obvious effect.},
  archive      = {J_NEUCOM},
  author       = {Xiaoping Zhu and Yi Xiao},
  doi          = {10.1016/j.neucom.2021.03.141},
  journal      = {Neurocomputing},
  pages        = {285-296},
  shortjournal = {Neurocomputing},
  title        = {Adaptive offloading and scheduling algorithm for big data based mobile edge computing},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Edge-aided control dynamics for information diffusion in
social internet of things. <em>NEUCOM</em>, <em>485</em>, 274–284. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information diffusion in social Internet of Things (SIoT) brings convenience to life, but it also faces challenges. The explosive growth of information exceeds the computing capability of the network, making it difficult to control. Motivated by the challenge, a novel control strategy for information diffusion is proposed in SIoT, which is based on the advantages of edge computing with low latency, high energy efficiency and timely feedback. Furthermore, graph neural networks (GNNs) is combined with ordinary differential equation systems (ODEs) to model edge-aided control dynamics, describing high-dimensionality and complicated interactions. Theoretical analysis and comparative simulation results show that the proposed edge-aided control strategy can dominate information diffusion within the target scope at the lowest cost.},
  archive      = {J_NEUCOM},
  author       = {Yinxue Yi and Zufan Zhang and Laurence T. Yang and Xiaokang Wang and Chenquan Gan},
  doi          = {10.1016/j.neucom.2021.03.140},
  journal      = {Neurocomputing},
  pages        = {274-284},
  shortjournal = {Neurocomputing},
  title        = {Edge-aided control dynamics for information diffusion in social internet of things},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neurocomputing for internet of things: Object recognition
and detection strategy. <em>NEUCOM</em>, <em>485</em>, 263–273. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern and new integrated technologies have changed the traditional systems by using more advanced machine learning , artificial intelligence methods, new generation standards, and smart and intelligent devices. The new integrated networks like the Internet of Things (IoT) and 5G standards offer various benefits and services. However, these networks have suffered from multiple object detection, localization, and classification issues. Conventional Neural Networks (CNN) and their variants have been adopted for object detection, classification, and localization in IoT networks to create autonomous devices to make decisions and perform tasks without human intervention and helpful to learn in-depth features. Motivated by these facts, this paper investigates existing object detection and recognition techniques by using CNN models used in IoT networks. This paper presents a Conventional Neural Networks for 5G-Enabled Internet of Things Network (CNN-5GIoT) model for moving and static objects in IoT networks after a detailed comparison. The proposed model is evaluated with existing models to check the accuracy of real-time tracking. The proposed model is more efficient for real-time object detection and recognition than conventional methods.},
  archive      = {J_NEUCOM},
  author       = {Kashif Naseer Qureshi and Omprakash Kaiwartya and Gwanggil Jeon and Francesco Piccialli},
  doi          = {10.1016/j.neucom.2021.04.140},
  journal      = {Neurocomputing},
  pages        = {263-273},
  shortjournal = {Neurocomputing},
  title        = {Neurocomputing for internet of things: Object recognition and detection strategy},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A flexible free-space detection system based on stereo
vision. <em>NEUCOM</em>, <em>485</em>, 252–262. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Free-space detection is considered as one of the most important tasks in intelligent vehicle, which remains the essential requirement for obstacle detection and path planning . As a part of Internet of Things , vehicle-based device produces a large amount of data requiring to be processed in real-time. Therefore, this study proposes a fast free-space detection system with a mobile platform based stereo vision . The current system processes the image-based perception signal in terminal equipment, which avoids lots of data transmissions between cloud and vehicle. In terms of flexibility and robustness, a fast spare disparity matching algorithm is suggested to be real-timely processed in a low-power mobile platform. Based on the spare disparity map, the current work improves the u-disparity space algorithm as the u-log-disparity space with the aim to detect the free-space for significantly lowering the running time. Besides, we also provide a complete system design including hardware and software. The experiments demonstrate that our system is precise and robust under complex real-time driving environment.},
  archive      = {J_NEUCOM},
  author       = {Qiwei Xie and Ranran Liu and Zhao Sun and Shanshan Pei and Feng Cui},
  doi          = {10.1016/j.neucom.2021.05.115},
  journal      = {Neurocomputing},
  pages        = {252-262},
  shortjournal = {Neurocomputing},
  title        = {A flexible free-space detection system based on stereo vision},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contrastive adversarial knowledge distillation for deep
model compression in time-series regression tasks. <em>NEUCOM</em>,
<em>485</em>, 242–251. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) attempts to compress a deep teacher model into a shallow student model by letting the student mimic the teacher’s outputs. However, conventional KD approaches can have the following shortcomings. First, existing KD approaches align the global distribution between teacher and student models and overlook the fine-grained features. Second, most of existing approaches focus on classification tasks and require the architecture of teacher and student models to be similar. To address these limitations, we propose a contrastive adversarial knowledge distillation called CAKD for time series regression tasks where the student and teacher are using different architectures. Specifically, we first propose adversarial adaptation to automatically align the feature distribution between student and teacher networks respectively. Yet, adversarial adaptation can only align the global feature distribution without considering the fine-grained features. To mitigate this issue, we employ a novel contrastive loss for instance-wise alignment between the student and teacher. Particularly, we maximize similarity between teacher and student features that originate from the same sample. Lastly, a KD loss is used to for the knowledge distillation where the teacher and student have two different architectures. We used a turbofan engine dataset that consists of four sub-datasets to evaluate the model performance. The results show that the proposed CAKD method consistently outperforms state-of-the-art methods in terms of two different metrics.},
  archive      = {J_NEUCOM},
  author       = {Qing Xu and Zhenghua Chen and Mohamed Ragab and Chao Wang and Min Wu and Xiaoli Li},
  doi          = {10.1016/j.neucom.2021.04.139},
  journal      = {Neurocomputing},
  pages        = {242-251},
  shortjournal = {Neurocomputing},
  title        = {Contrastive adversarial knowledge distillation for deep model compression in time-series regression tasks},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Concrete crack segmentation based on UAV-enabled edge
computing. <em>NEUCOM</em>, <em>485</em>, 233–241. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the rapid development of UAV technology has greatly improved the efficiency of the detection of concrete bridge cracks. With the increase in the number of bridge inspection UAVs, the number of tasks handled by cloud services has increased linearly, resulting in increased computational pressure on cloud services. In order to reduce the computational load of cloud servers, we proposed a crack segmentation network based on UAV-enabled edge computing . However, due to the limitation of computational capability of edge computing and the strength inhomogeneity and background complexity of cracks, crack detection is still a challenging task. Thus, we proposed an effective concrete crack segmentation network based on UAV-enabled edge computing, the network used feature map fusion to fuse different levels of feature map information into lower-level features for crack detection. The atrous spatial pyramid pooling network was used to increase the low-resolution feature map receptive field information for cracks and to enhance the detection accuracy for cracks of different scales. In addition, loss functions for crack datasets were proposed to solve the problem of imbalance due to positive and negative samples in the concrete crack images. Experiments demonstrated that the proposed methods are better than the state-of-the-art edge detection and semantic segmentation methods in terms of accuracy and generality.},
  archive      = {J_NEUCOM},
  author       = {Jianxi Yang and Hao Li and Junzhi Zou and Shixin Jiang and Ren Li and Xinlong Liu},
  doi          = {10.1016/j.neucom.2021.03.139},
  journal      = {Neurocomputing},
  pages        = {233-241},
  shortjournal = {Neurocomputing},
  title        = {Concrete crack segmentation based on UAV-enabled edge computing},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EdgeShare: A blockchain-based edge data-sharing framework
for industrial internet of things. <em>NEUCOM</em>, <em>485</em>,
219–232. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial Internet of Things (IIoT) is facing significant scalability and security challenges in sharing massive device data across heterogeneous network domains. Traditional cloud-based sharing solutions for IIoT applications that are getting closer to devices are uneconomical and inefficient because of their centralized architecture. We propose a blockchain-based data-sharing framework called EdgeShare for edge data-sharing services among heterogeneous network domains by introducing a two-layer overlay network topology and an edge computing paradigm that can dramatically alleviate system pressure and reduce communication delays to improve data-sharing efficiency. Under such framework, a novel smart contract is designed to construct access control strategies with dissimilar granularities to achieve different levels of data access control in an undeniable and automated manner. All IIoT data-sharing activities are recorded in a blockchain for secured transaction logging and auditing. We implement an EdgeShare prototype and conduct extensive experiments and analyses to evaluate the feasibility of our proposals. In contrast with centralized sharing methods, results demonstrate that the proposed framework can effectively improve the reliability, efficiency, and security of massive data sharing while introducing reasonable and acceptable overheads.},
  archive      = {J_NEUCOM},
  author       = {Lei Yang and Wanrong Zou and Jianggan Wang and Zi Tang},
  doi          = {10.1016/j.neucom.2021.01.147},
  journal      = {Neurocomputing},
  pages        = {219-232},
  shortjournal = {Neurocomputing},
  title        = {EdgeShare: A blockchain-based edge data-sharing framework for industrial internet of things},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep anomaly detection in packet payload. <em>NEUCOM</em>,
<em>485</em>, 205–218. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the wide deployment of edge devices, a variety of emerging applications have been deployed at the edge of network. To guarantee the safe and efficient operations of the edge applications, especially the extensive web applications, it is important and challenging to detect packet payload anomalies, which can be expressed as a number of specific strings that may cause attacks. Although some approaches have achieved remarkable progress, they are with limited applications since these approaches are dependent on in-depth expert knowledge, e.g., signatures describing anomalies or communication protocol at the application level. Moreover, they might fail to detect the payload anomalies that may have long-term dependency relationships at the edge of network. To overcome these limitations and adaptively detect anomalies from packet payloads, we propose a deep learning based framework which does not rely on any in-depth expert knowledge and is capable of detecting anomalies that have long-term dependency relationships . The proposed framework consists of two parts. First, a novel block sequence construction method is proposed to obtain a valid expression of a payload. The block sequence could encapsulate both the high-dimension information and the underlying sequential information which facilitate the anomaly detection . Secondly, we design a detection model to learn two different dependency relationships within the block sequence, which is based on Long Short-Term Memory (LSTM), Convolutional Neural Networks (CNN) and Multi-head Self Attention Mechanism . Furthermore, we cast the anomaly detection as a classification problem and employ a classifier with attention mechanism to integrate information and detect anomalies . Extensive experimental results on three public datasets indicate that our model could achieve a higher detection rate, while keeping a lower false positive rate compared with two traditional machine learning methods and three state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Jiaxin Liu and Xucheng Song and Yingjie Zhou and Xi Peng and Yanru Zhang and Pei Liu and Dapeng Wu and Ce Zhu},
  doi          = {10.1016/j.neucom.2021.01.146},
  journal      = {Neurocomputing},
  pages        = {205-218},
  shortjournal = {Neurocomputing},
  title        = {Deep anomaly detection in packet payload},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Neural architecture tuning with policy adaptation.
<em>NEUCOM</em>, <em>485</em>, 196–204. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) is to automatically design task-specific neural architectures, whose performance has already surpassed those of many manually designed neural networks . Existing NAS techniques focus on searching for the neural architecture and training the optimal network weights from the scratch. Nevertheless, it could be essential to study how to tune a given neural architecture instead of producing a completely new neural architecture in some scenarios, which may lead to a more optimal solution by combining human experience and the advantages of the machine’s automatic searching. This paper proposes to learn to tune the architectures at hand to achieve better performance. The proposed Neural Architecture Tuning (NAT) algorithm trains a deep Q-network to tune neural architectures given a random architecture so that we can achieve better performance on a reduced space. We then apply adversarial autoencoder to make the learned policy be generalized to a different searching space in real-world applications. The proposed algorithm is evaluated on the NAS-Bench-101 dataset. The results indicate that our NAT framework can achieve state-of-the-art performance on the NAS-Bench-101 benchmark, and the learned policy can be adapted to a different search space while maintaining the performance.},
  archive      = {J_NEUCOM},
  author       = {Yanxi Li and Minjing Dong and Yixing Xu and Yunhe Wang and Chang Xu},
  doi          = {10.1016/j.neucom.2021.10.095},
  journal      = {Neurocomputing},
  pages        = {196-204},
  shortjournal = {Neurocomputing},
  title        = {Neural architecture tuning with policy adaptation},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An ensemble of random decision trees with local differential
privacy in edge computing. <em>NEUCOM</em>, <em>485</em>, 181–195. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing is an emerging computing paradigm , which offers a great opportunity to implement data mining-based services and applications for a large number of devices and sensors in Internet of Things . However, the new paradigm is faced with security and privacy challenges due to the diversity and the limited capability of edge components. In particular, data privacy is one of the most concerned problems for all the participants. In this paper, we propose a framework of privacy-preserving data mining based on private random decision trees in edge computing, which not only gives the strong privacy guarantee, but also provides a certain amount of data utility. Firstly, we design a preservation framework to implement private random decision trees satisfying local differential privacy . Secondly, we present the concrete implementations of algorithms and the corresponding task that each participant needs to undertake. Thirdly, we analyze the key factors to influence privacy and utility, including the allocation of data and privacy budget. Fourthly, we give the improved algorithms to further increase the utility with strong privacy preservation . Finally, extensive experiments demonstrate the good performance of our designed framework.},
  archive      = {J_NEUCOM},
  author       = {Xiaotong Wu and Lianyong Qi and Jiaquan Gao and Genlin Ji and Xiaolong Xu},
  doi          = {10.1016/j.neucom.2021.01.145},
  journal      = {Neurocomputing},
  pages        = {181-195},
  shortjournal = {Neurocomputing},
  title        = {An ensemble of random decision trees with local differential privacy in edge computing},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An LSTM-based distributed scheme for data transmission
reduction of IoT systems. <em>NEUCOM</em>, <em>485</em>, 166–180. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growth of the number of connected devices in Internet of Things (IoT) systems causes a huge increase in network traffic. Thus, there is a significant demand for systems that can predict the measurements of the distributed IoT-based applications to mitigate the increasing network traffic. Existing methods utilized a distributed scheme, i.e., dual prediction schemes (DPS), to achieve this task. The idea of this scheme is based on deploying a predictive model on the data sources (i.e., sensors) and the fusion center in a distributive manner. The state-of-the-art results can be simply reached using predictive models, e.g., adaptive filters. Deep learning-based approaches are not well utilized to address this problem. In this context, we proposed a distributed scheme utilizing fog and edge computing technologies. The proposed DPS includes an LSTM predictive model to reduce the data transmission instances of connected IoT devices ; it is called LSTM-DPS. In addition, we proposed an updating mechanism that updates the LSTM model according to a set of tracking parameters that observes the model behavior during the deployment due to the changes of data properties through time. The proposed updating mechanism guarantees that the deployed LSTM model is identical at the data source and fusion center. The LSTM-DPS is evaluated using two real datasets. The obtained results show that the LSTM-DPS outperforms state-of-the-art methods in terms of communication reduction ratios.},
  archive      = {J_NEUCOM},
  author       = {Ahmed Fathalla and Kenli Li and Ahmad Salah and Marwa F. Mohamed},
  doi          = {10.1016/j.neucom.2021.02.105},
  journal      = {Neurocomputing},
  pages        = {166-180},
  shortjournal = {Neurocomputing},
  title        = {An LSTM-based distributed scheme for data transmission reduction of IoT systems},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). LCSED: A low complexity CNN based SED model for IoT
devices. <em>NEUCOM</em>, <em>485</em>, 155–165. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sound event detection (SED) has been widely applied in different applications such as smart home, video surveillance, environmental monitoring. The SED models which are based on neural network (NN) have attracted lots of attention due to its high detection accuracy. However, the existing NN-based SED models have high computational complexity in terms of both the number of parameters and the number of multiply accumulates (MACs) operations which leads to significant processing time, power consumption, and memory storage, making it unsuitable for the Internet of Things (IoT) devices with constrained power consumption and resource. To address the above issue, a low complexity SED model (named LCSED ) with a hybrid convolution scheme and a lightweight dual-attention scheme is proposed to reduce the number of parameters and MACs operations while maintaining high detection accuracy. The proposed LCSED model is evaluated on the DCASE2017 task4 public dataset. Compared with several state-of-the-art methods, the computational complexity is significantly reduced (up to 48.8 times and 2.50 times for parameters and MACs operations respectively) while maintaining high detection accuracy. The proposed LCSED model is suitable for sound event detection in power &amp; resource constrained IoT devices.},
  archive      = {J_NEUCOM},
  author       = {Mingxue Yang and Lujie Peng and Li Liu and Yujiang Wang and Zhenyuan Zhang and Zhengxi Yuan and Jun Zhou},
  doi          = {10.1016/j.neucom.2021.02.104},
  journal      = {Neurocomputing},
  pages        = {155-165},
  shortjournal = {Neurocomputing},
  title        = {LCSED: A low complexity CNN based SED model for IoT devices},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A two-phase half-async method for heterogeneity-aware
federated learning. <em>NEUCOM</em>, <em>485</em>, 134–154. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a distributed machine learning paradigm that allows training models on decentralized data over large-scale edge/mobile devices without collecting raw data. However, existing methods are still far from efficient and stable under extreme statistical and environmental heterogeneity. In this work, we propose FedHA ( Fed erated H eterogeineity A wareness), a novel half-async algorithm which simultaneously incorporates the merits of asynchronous and synchronous methods. It separates the training into two phases by estimating the consistency of optimization directions of collected local models. It applies different strategies to facilitate fast and stable training, namely model selection, adaptive local epoch, and heterogeneity weighted aggregation in these phases. We provide theoretical convergence and communication guarantees on both convex and non-convex problems without introducing extra assumptions. In the first phase (the consistent phase), the convergence rate of FedHA is O 1 e T O1eT , which is faster than existing methods while reducing communication. In the second phase (inconsistent phase), FedHA retains the best-known results in convergence ( O 1 T O1T ) and communication ( ∊ O 1 ∊ O1∊ ). We validate our proposed algorithm on different tasks with both IID (Independently and Identically Distributed) and non-IID data, and results show that our algorithm is efficient, stable, and flexible under the twofold heterogeneity using the proposed strategies.},
  archive      = {J_NEUCOM},
  author       = {Tianyi Ma and Bingcheng Mao and Ming Chen},
  doi          = {10.1016/j.neucom.2021.08.146},
  journal      = {Neurocomputing},
  pages        = {134-154},
  shortjournal = {Neurocomputing},
  title        = {A two-phase half-async method for heterogeneity-aware federated learning},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MemTorch: An open-source simulation framework for memristive
deep learning systems. <em>NEUCOM</em>, <em>485</em>, 124–133. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memristive devices have shown great promise to facilitate the acceleration and improve the power efficiency of Deep Learning (DL) systems. Crossbar architectures constructed using these Resistive Random-Access Memory (RRAM) devices can be used to efficiently implement various in-memory computing operations, such as Multiply Accumulate (MAC) and unrolled-convolutions, which are used extensively in Deep Neural Networks (DNNs) and Convolutional Neural Networks (CNNs). However, memristive devices face concerns of aging and non-idealities, which limit the accuracy, reliability, and robustness of Memristive Deep Learning Systems (MDLSs), that should be considered prior to circuit-level realization. This Original Software Publication(OSP) presents MemTorch , an open-source 1 framework for customized large-scale memristive Deep Learning (DL) simulations, with a refined focus on the co-simulation of device non-idealities. MemTorch also facilitates co-modelling of key crossbar peripheral circuitry. MemTorch adopts a modernized software engineering methodology and integrates directly with the well-known PyTorch Machine Learning (ML) library.},
  archive      = {J_NEUCOM},
  author       = {Corey Lammie and Wei Xiang and Bernabé Linares-Barranco and Mostafa Rahimi Azghadi},
  doi          = {10.1016/j.neucom.2022.02.043},
  journal      = {Neurocomputing},
  pages        = {124-133},
  shortjournal = {Neurocomputing},
  title        = {MemTorch: An open-source simulation framework for memristive deep learning systems},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sparse-attentive meta temporal point process for clinical
decision support. <em>NEUCOM</em>, <em>485</em>, 114–123. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the study of clinical decision-making, prediction of future clinical events of patients has become an important task, especially for variant disease predictions. In previous studies, the disease prediction problems are considered as binary classification based on the patients’ electronic health records (EHRs), which lack the capacity to predict multiple types of diseases. In this paper, we propose a method which can predict both the patients’ disease types among various candidate diseases and patients’ next hospital visit time. The next hospital visit time is crucial for medical experts in making decisions, because it reflects the onset time information of disease and provides sufficient information on the severity of the disease. Our proposed method is implemented based on the point process framework, which utilizes meta-learning to gain the prior knowledge of the individual patient’s clinical data with context information, adopts sparse-attention to determine the importance of past major clinical events, and simulates the intensity of clinical events through Hawkes process to predict the types of diseases diagnosed by the doctor and patient’ next hospital visit time. The experimental data are extracted from the public datasets: Multiparameter Intelligent Monitoring in Intensive Care (MIMIC-II) and Medical Information Mart for Intensive Care (MIMIC-III). Compared with the baseline time series models , our proposed method has achieved superior results, with a higher F1-score (66.67\%) and a lower root-mean-square error (RMSE) (6.69) on the test set, which proves the effectiveness of the proposed method. We further study the self-attention mechanism based on Transformer and sparse-attention methods to demonstrate the validity of our model. Our proposed method provides empirical evidence of its ability in facilitating the decision-making process of clinicians, which can be potentially utilized as effective clinical decision support tools to better improve the quality of medical services and reduce medical errors.},
  archive      = {J_NEUCOM},
  author       = {Yajun Ru and Xihe Qiu and Xiaoyu Tan and Bin Chen and Yongbin Gao and Yaochu Jin},
  doi          = {10.1016/j.neucom.2022.02.028},
  journal      = {Neurocomputing},
  pages        = {114-123},
  shortjournal = {Neurocomputing},
  title        = {Sparse-attentive meta temporal point process for clinical decision support},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving generation diversity via syntax-controlled
paraphrasing. <em>NEUCOM</em>, <em>485</em>, 103–113. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the neural-based Seq2Seq model pushes the state-of-the-art in text generation, recent work has turned to controlling attributes of the text such models generate, where syntax-controlled text generation can be applied for the paraphrase generation task, i.e., given an input sentence and a syntactic control to generate a paraphrase. The main challenge is how to generate sentences that follow the given syntax while maintaining semantics during the decoding process. Previous approaches using constituency parse trees as syntactic control can achieve better performance, but still suffer from the problems of inaccurate utilization of syntactic information and original semantics loss. To this end, we propose a S yntax A ttention- G uided P araphrase (SAGP) generation model that can utilize the previously generated text to accurately select a syntactic node from the given constituency parse tree to guide the generation of paraphrases. The automatic and manual evaluation results on the public datasets of syntactically controlled paraphrase generation task show that SAGP achieves state-of-the-art results in both syntactic controllability and semantic consistency . In order to improve the semantic consistency , we further propose a coarse-grained syntactic control definition method, which first removes the part-of-speech node and then extracts higher-level subtrees as control, so that meaningful paraphrases can be generated within a loose constraint. The experimental results on the same evaluation set show that the coarse-grained syntactic control can significantly improve semantic consistency.},
  archive      = {J_NEUCOM},
  author       = {Erguang Yang and Mingtong Liu and Deyi Xiong and Yujie Zhang and Yao Meng and Jinan Xu and Yufeng Chen},
  doi          = {10.1016/j.neucom.2022.02.020},
  journal      = {Neurocomputing},
  pages        = {103-113},
  shortjournal = {Neurocomputing},
  title        = {Improving generation diversity via syntax-controlled paraphrasing},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finite-time synchronization of the drive-response networks
by event-triggered aperiodic intermittent control. <em>NEUCOM</em>,
<em>485</em>, 89–102. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the finite-time synchronization problem of complex networks with time-varying delays is investigated by event-triggered intermittent control. By mean of introducing the event-triggered control (ETC) mechanism and the aperiodic intermittent control (AIC) scheme, an event-triggered intermittent control (ETIC) synthesis for complex networks with time-varying delays is proposed, which is more in line with the actual situation. An modified lemma is derived without predeg intermittent instants. This lemma lead to the existence of the finite-time ETIC. And based on this lemma with the proposed ETIC scheme and the finite-time stability theory, sufficient conditions are presented to guarantee the achievement of finite-time synchronization for all change to time-varying delays complex networks and eliminate the Zeno behavior . Finally, numerical examples are given to verify the effectiveness of the theoretical results and the practicability of the proposed control method .},
  archive      = {J_NEUCOM},
  author       = {Zeyu Ruan and Yuanyuan Li and Junhao Hu and Jun Mei and Dan Xia},
  doi          = {10.1016/j.neucom.2022.02.037},
  journal      = {Neurocomputing},
  pages        = {89-102},
  shortjournal = {Neurocomputing},
  title        = {Finite-time synchronization of the drive-response networks by event-triggered aperiodic intermittent control},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A single-layer asymmetric RNN with low hardware complexity
for solving linear equations. <em>NEUCOM</em>, <em>485</em>, 74–88. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A single layer neural network for the solution of linear equations is presented. The proposed circuit is based on the standard Hopfield model albeit with the added flexibility that the interconnection weight matrix need not be symmetric. This results in an asymmetric Hopfield neural network capable of solving linear equations . PSPICE simulation results are given which verify the theoretical predictions. A simple technique to incorporate re-configurability into the circuit for setting the different weights of the interconnection is also included. Experimental results for circuits set up to solve small problems further confirm the operation of the proposed circuit.},
  archive      = {J_NEUCOM},
  author       = {Mohammad Samar Ansari},
  doi          = {10.1016/j.neucom.2022.01.033},
  journal      = {Neurocomputing},
  pages        = {74-88},
  shortjournal = {Neurocomputing},
  title        = {A single-layer asymmetric RNN with low hardware complexity for solving linear equations},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sparse and low-dimensional representation with maximum
entropy adaptive graph for feature selection. <em>NEUCOM</em>,
<em>485</em>, 57–73. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional feature selection algorithms usually explore the relationship between data and cluster structure in a single space, so the internal relationship obtained is not very rich, and it is not enough to select more valuable features. To solve the above problems, in order to fully mine the intrinsic correlation information in different spaces, so that the relationship between data, features and clustering structure can be explored at the same time, this paper proposes a feature selection method based on sparse and low-dimensional representation with maximum entropy adaptive graph (SLMEA). Firstly, the SLMEA combines the sparse transform representation with pseudo-label matrix learning to optimize, and uses the pseudo-label matrix to guide the learning of sparse low-dimensional space. It can not only explore the relationship between data and pseudo-labels in data space, but also mine the association between features and pseudo-labels in feature space, so as to select more discriminative features. Secondly, based on the maximum entropy theory, the similarity matrix is constructed adaptively, so that the two different manifold structures corresponding to sparse transform representation and pseudo label matrix learning can be adaptively learned and retained in the iterative process. In addition, in order to ensure the sparsity of the transformation matrix, the constraint of ℓ 2 , 1 / 2 ℓ2,1/2 -norm is applied to the matrix, which can better deal with the redundant features and obtain more sparse solutions. Finally, the SLMEA uses an alternate iterative update method to optimize the objective function, and carries out extensive experiments on eight mainstream datasets. Compared with seven state-of-the-art algorithms, SLMEA can have higher clustering accuracy and normalized mutual information.},
  archive      = {J_NEUCOM},
  author       = {Ronghua Shang and Xinlei Zhang and Jie Feng and Yangyang Li and Licheng Jiao},
  doi          = {10.1016/j.neucom.2022.02.038},
  journal      = {Neurocomputing},
  pages        = {57-73},
  shortjournal = {Neurocomputing},
  title        = {Sparse and low-dimensional representation with maximum entropy adaptive graph for feature selection},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SILP-autoencoder for face de-occlusion. <em>NEUCOM</em>,
<em>485</em>, 47–56. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing faces with partial occlusion is a challenging problem in many real-world applications. Although various methods have been proposed to deal with the facial image de-occlusion tasks, most of them only concern the local features of occluded images, obviously ignoring the global facial expressions and structural prior information. In this paper, we propose a novel end-to-end SILP-Autoencoder to effectively restore partial occluded faces. To improve the recovery quality and occlusion removal robustness, our framework mainly consists of two components, Laplacian prior subnetwork , and left-and-right symmetric match module (LR-match module), which preserve the global facial expression features and fully make use of the symmetrical characteristics of facial regions and structures respectively. Based on the above characteristics, a composite loss function is designed to achieve end-to-end training of the entire network. Extensive experiments on the face expression datasets with various shaded areas suggest that our approach achieves superior performance against the state-of-the-art methods. In particular, our method is more useful for facial detail recovery and distortion expression suppression.},
  archive      = {J_NEUCOM},
  author       = {Dengdi Sun and Wandong Xie and Zhuanlian Ding and Jin Tang},
  doi          = {10.1016/j.neucom.2022.02.035},
  journal      = {Neurocomputing},
  pages        = {47-56},
  shortjournal = {Neurocomputing},
  title        = {SILP-autoencoder for face de-occlusion},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-modal trained artificial intelligence solution to
triage chest x-ray for COVID-19 using pristine ground-truth, versus
radiologists. <em>NEUCOM</em>, <em>485</em>, 36–46. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The front-line imaging modalities computed tomography (CT) and X-ray play important roles for triaging COVID patients. Thoracic CT has been accepted to have higher sensitivity than a chest X-ray for COVID diagnosis. Considering the limited access to resources (both hardware and trained personnel) and issues related to decontamination, CT may not be ideal for triaging suspected subjects. Artificial intelligence (AI) assisted X-ray based application for triaging and monitoring require experienced radiologists to identify COVID patients in a timely manner with the additional ability to delineate and quantify the disease region is seen as a promising solution for widespread clinical use. Our proposed solution differs from existing solutions presented by industry and academic communities. We demonstrate a functional AI model to triage by classifying and segmenting a single chest X-ray image, while the AI model is trained using both X-ray and CT data. We report on how such a multi-modal training process improves the solution compared to single modality (X-ray only) training. The multi-modal solution increases the AUC (area under the receiver operating characteristic curve) from 0.89 to 0.93 for a binary classification between COVID-19 and non-COVID-19 cases. It also positively impacts the Dice coefficient (0.59 to 0.62) for localizing the COVID-19 pathology. To compare the performance of experienced readers to the AI model, a reader study is also conducted. The AI model showed good consistency with respect to radiologists. The DICE score between two radiologists on the COVID group was 0.53 while the AI had a DICE value of 0.52 and 0.55 when compared to the segmentation done by the two radiologists separately. From a classification perspective, the AUCs of two readers was 0.87 and 0.81 while the AUC of the AI is 0.93 based on the reader study dataset. We also conducted a generalization study by comparing our method to the-state-art methods on independent datasets. The results show better performance from the proposed method. Leveraging multi-modal information for the development benefits the single-modal inferencing.},
  archive      = {J_NEUCOM},
  author       = {Tao Tan and Bipul Das and Ravi Soni and Mate Fejes and Hongxu Yang and Sohan Ranjan and Daniel Attila Szabo and Vikram Melapudi and K.S. Shriram and Utkarsh Agrawal and Laszlo Rusko and Zita Herczeg and Barbara Darazs and Pal Tegzes and Lehel Ferenczi and Rakesh Mullick and Gopal Avinash},
  doi          = {10.1016/j.neucom.2022.02.040},
  journal      = {Neurocomputing},
  pages        = {36-46},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal trained artificial intelligence solution to triage chest X-ray for COVID-19 using pristine ground-truth, versus radiologists},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimating scale-free dynamic effective connectivity
networks from fMRI using group-wise spatial–temporal regularizations.
<em>NEUCOM</em>, <em>485</em>, 22–35. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating dynamic effective connectivity (dEC) networks is crucial to understand the time-varying directional interconnections among brain regions. It is now widely understood that brain networks have the property of being scale-free. However, this property has seldom been considered and is often inadequately preserved using conventional dEC estimation methods. As a result, important hubs and network graphical characteristics cannot be accurately obtained. In this work, we develop a new method to use a group-wise penalty together with spatial sparsity and temporal smoothness regularizations (namely Group-wise Spatial–Temporal Regularizations, GSTR) for the inference of scale-free dEC networks from functional magnetic resonance imaging (fMRI). The method employs a time-varying vector autoregressive (VAR) model, where the model coefficients can be formed as adjacency matrices of the dEC networks. Meanwhile, the proposed group-wise regularization is able to preserve the connectivities of potential hubs in scale-free networks by grouping them as an entire set. To deal with the complexity of optimization with multiple regularizations , we propose an effective algorithm based on the augmented Lagrangian multiplier . The accuracy of the GSTR method is validated using a variety of synthetic datasets with the scale-free property. Furthermore, we apply the GSTR method to an open fMRI dataset recorded from a block design visual task-related experiment containing 255 healthy participants to estimate visual-induced dEC networks and find GSTR can achieve reasonable and interpretable dEC estimates. Results from both synthetic and real-world datasets suggest that the proposed GSTR method could serve as a powerful analytical tool to accurately infer scale-free dEC patterns.},
  archive      = {J_NEUCOM},
  author       = {Li Zhang and Gan Huang and Zhen Liang and Linling Li and Zhiguo Zhang},
  doi          = {10.1016/j.neucom.2022.02.041},
  journal      = {Neurocomputing},
  pages        = {22-35},
  shortjournal = {Neurocomputing},
  title        = {Estimating scale-free dynamic effective connectivity networks from fMRI using group-wise spatial–temporal regularizations},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Motif-based memory networks for complex-factoid question
answering. <em>NEUCOM</em>, <em>485</em>, 12–21. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge-based question answering (KBQA) is an interesting but challenging task in the field of natural language processing . And in recent years, there is increasing interest in introducing deep learning models for answering complex-factoid questions, which associate with multiple facts and require multi-hop inference. However, the complex-factoid question answering mainly faces two challenges: (1) multiple entities are involved in these questions, which bring multiple initial states for knowledge reasoning; (2) a number of complex-factoid questions require the intersection of multiple related sub-paths in knowledge bases, which demands repeated explorations of path reasoning, matching and assembling. To address the above challenges, we propose a motif-based Memory Network for answering complex-factoid questions, which introduces motifs as the basic constituents for semantic representation , and meanwhile includes a specific-designed memory network for knowledge reasoning and matching. Extensive experiments on real datasets demonstrate that our model significantly outperforms the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Zhifeng Hao and Junhao Chen and Wen Wen and Biao Wu and Ruichu Cai},
  doi          = {10.1016/j.neucom.2022.02.008},
  journal      = {Neurocomputing},
  pages        = {12-21},
  shortjournal = {Neurocomputing},
  title        = {Motif-based memory networks for complex-factoid question answering},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-step image dehazing with intra-domain and inter-domain
adaptation. <em>NEUCOM</em>, <em>485</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intra-domain and inter-domain gaps are widely presented in image processing tasks due to data distribution differences. In the field of image dehazing, particular previous works have paid attention to the inter-domain gap between the synthetic domain and the real domain. However, those methods only establish the connection from the real domain to the synthetic domain without considering the significant distribution shift within the synthetic domain (intra-domain gap). In this work, we propose a Two-Step Dehazing Network (TSDN) with an intra-domain adaptation and a constrained inter-domain adaptation. First, we subdivide the distributions within the synthetic domain into subsets and mine the optimal subset (easy samples) by loss-based supervision. To alleviate the intra-domain gap of the synthetic domain, we propose an intra-domain adaptation to align distributions of other subsets to the optimal subset by adversarial learning. Finally, we conduct the constrained inter-domain adaptation from the real domain to the optimal subset of the synthetic domain, alleviating the domain shift between domains as well as the distribution shift within the real domain. Extensive experimental results demonstrate that our framework performs favorably against the state-of-the-art algorithms both on the synthetic datasets and the real datasets.},
  archive      = {J_NEUCOM},
  author       = {Xin Yi and Bo Ma and Yulin Zhang and Longyao Liu and JiaHao Wu},
  doi          = {10.1016/j.neucom.2022.02.019},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {Two-step image dehazing with intra-domain and inter-domain adaptation},
  volume       = {485},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic learning for object detection. <em>NEUCOM</em>,
<em>484</em>, 260–272. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To alleviate the burden of manual image annotation, we propose an automatic learning method to enable object detection. This method mainly consists of the following three aspects: (1) a novel synthetic data generation strategy, which can automatically generate large-scale synthetic data with bounding-box annotations using only semantic concepts of target categories; (2) self-training paradigm combined with synthetic data generation strategy, which mines more information from the unannotated real data through iterative training to improve the performance of the object detector; (3) a simple and effective pseudo box filtering method, which can purify the quality of pseudo boxes during training. Without using any annotations (i.e., image-level annotations and bounding-box annotations) from the PASCAL VOC dataset, our proposed method can obtain 59.3\% 59.3\% and 55.1\% 55.1\% mAP on PASCAL VOC 2007 and PASCAL VOC 2012, respectively. We also demonstrate the effectiveness of our method on several datasets, including CUB-200–2011, FGVC Aircraft, Stanford Cars, Bird-Aircraft-Car-Dog, and CBCL StreetScenes.},
  archive      = {J_NEUCOM},
  author       = {Xiang Zhang and Chao Zhao and Hangzai Luo and Wanqing Zhao and Sheng Zhong and Lei Tang and Jinye Peng and Jianping Fan},
  doi          = {10.1016/j.neucom.2022.02.012},
  journal      = {Neurocomputing},
  pages        = {260-272},
  shortjournal = {Neurocomputing},
  title        = {Automatic learning for object detection},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classifying cybergrooming for child online protection using
hybrid machine learning model. <em>NEUCOM</em>, <em>484</em>, 250–259.
(<a href="https://doi.org/10.1016/j.neucom.2021.08.148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper shows a computational model that classifies Cybergrooming attacks in the context of COP (child online protection) using Natural Language Processing (NLP) and Convolutional Neural Networks (CNN). The model predicts a high number of false positives , therefore low precision and F-score, but a high accuracy. In this issue, where the number of messages in the context of grooming are so low compared to the number of conversations and messages from other contexts, it can be concluded that is a very consistent and useful result as it captures a high number of true positives , considering that the classifier works for messages. Performing the training of machine learning algorithms with neural networks, semantic analysis and NLP, allows approximate representation of knowledge contributing to discovery of pseudo-intelligent information in these environments and reducing human intervention for characterization of underlying abnormal behavior and detecting messages that potentially represent these attacks.},
  archive      = {J_NEUCOM},
  author       = {Gustavo Isaza and Fabián Muñoz and Luis Castillo and Felipe Buitrago},
  doi          = {10.1016/j.neucom.2021.08.148},
  journal      = {Neurocomputing},
  pages        = {250-259},
  shortjournal = {Neurocomputing},
  title        = {Classifying cybergrooming for child online protection using hybrid machine learning model},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A predictive and user-centric approach to machine learning
in data streaming scenarios. <em>NEUCOM</em>, <em>484</em>, 238–249. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning has emerged in the last years as the main solution to many of nowadays’ data-based decision problems. However, while new and more powerful algorithms and the increasing availability of computational resources contributed to a widespread use of Machine Learning, significant challenges still remain. Two of the most significant nowadays are the need to explain a model’s predictions, and the significant costs of training and re-training models, especially with large datasets or in streaming scenarios. In this paper we address both issues by proposing an approach we deem predictive and user-centric. It is predictive in the sense that it estimates the benefit of re-training a model with new data, and it is user-centric in the sense that it implements an explainable interface that produces interpretable explanations that accompany predictions. The former allows to reduce necessary resources (e.g. time, costs) spent on re-training models when no improvements are expected, while the latter allows for human users to have additional information to support decision-making. We validate the proposed approach with a group of public datasets and present a real application scenario.},
  archive      = {J_NEUCOM},
  author       = {Davide Carneiro and Miguel Guimarães and Fábio Silva and Paulo Novais},
  doi          = {10.1016/j.neucom.2021.07.100},
  journal      = {Neurocomputing},
  pages        = {238-249},
  shortjournal = {Neurocomputing},
  title        = {A predictive and user-centric approach to machine learning in data streaming scenarios},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Boosting biomedical document classification through the use
of domain entity recognizers and semantic ontologies for document
representation: The case of gluten bibliome. <em>NEUCOM</em>,
<em>484</em>, 223–237. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing number of scientific research documents published keeps growing at an unprecedented rate, making it increasingly difficult to access practical information within a target domain. This situation is motivating a growing interest in applying text mining techniques for the automatic processing of text resources to structure the information that helps researchers to find information of interest and infer knowledge of practical use. However, the automatic processing of research documents requires the previous existence of large, manually annotated text corpora to develop robust and accurate text mining processing methods and machine learning models. In this context, semi-automatic extraction techniques based on structured data and state-of-the-art biomedical tools appear to have significant potential to enhance curator productivity and reduce the costs of document curation. In this line, this work proposes a semi-automatic machine learning workflow and a NER + Ontology boosting technique for the automatic classification of biomedical literature. The practical relevance of the proposed approach has been proven in the curation of 4,115 gluten-related documents extracted from PubMed and contrasted against the word embedding alternative. Comparing the results of the experiments, the proposed NER + Ontology technique is an effective alternative to other state-of-the-art document representation techniques to process the existing biomedical literature.},
  archive      = {J_NEUCOM},
  author       = {Martín Pérez-Pérez and Tânia Ferreira and Anália Lourenço and Gilberto Igrejas and Florentino Fdez-Riverola},
  doi          = {10.1016/j.neucom.2021.10.100},
  journal      = {Neurocomputing},
  pages        = {223-237},
  shortjournal = {Neurocomputing},
  title        = {Boosting biomedical document classification through the use of domain entity recognizers and semantic ontologies for document representation: The case of gluten bibliome},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised characterization of lessons according to
temporal patterns of teacher talk via topic modeling. <em>NEUCOM</em>,
<em>484</em>, 211–222. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classroom observation is an essential component to improve the quality of teaching and develop educational research. Nonetheless, traditional observation procedures involve previously trained observers, rendering them expensive and time-consuming. Thus, there is a need for a tool which enables to analyze multiple lessons in short time, represent those lessons consistently, and describe them according to the teaching strategies used over time to give teachers timely and continuous feedback. In this work, we propose two unsupervised approaches to represent the evolution of lessons based on topic modeling: textbook- and BERT-based. This way, we can improve the generalization capability of these tools and avoid the need of previously annotated data. Subsequently, we collapsed the derived topics into two super-topics to ease interpretability , and clustered the time series they define to characterize them according to the teaching strategies used. We applied our methodology to 195 science lessons revealing three patterns related to different strategies. Lastly, we compare the two approaches using different metrics for clustering assessment and discuss their benefits and detriments. We expect these models can become useful tools for teachers to obtain an automated and objective representation of their lessons, but also to other stakeholders who want to analyze teaching practices at a large scale.},
  archive      = {J_NEUCOM},
  author       = {Matías Altamirano and Pablo Uribe and Danner Schlotterbeck and Abelino Jiménez and Roberto Araya and Johan van der Molen Moris and Daniela Caballero},
  doi          = {10.1016/j.neucom.2021.09.078},
  journal      = {Neurocomputing},
  pages        = {211-222},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised characterization of lessons according to temporal patterns of teacher talk via topic modeling},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Charging stations and mobility data generators for
agent-based simulations. <em>NEUCOM</em>, <em>484</em>, 196–210. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current traffic congestion and the resulting carbon emissions are two of the main problems threatening the sustainability of modern cities. The challenges facing today’s cities focus primarily on the optimization of traffic flow and the transition to electric vehicles. The latter aspect implies the need for an adequate deployment of the infrastructure of charging stations. The inherent complexity in today’s cities and the difficulty in implementing new policies whose benefits are difficult to measure and predict has led in recent years to consider the enormous potential of simulation tools and in particular of the agent-based simulation (ABS). ABS allows the specification of complex models that reflect the complexity and dynamism of urban mobility. Current technology in ABS has evolved and matured sufficiently to provide very sophisticated tools but lacking facilities for a flexible and realistic generation of input data in the execution of the experiments. In line with this, this paper introduces two configurable generators that automatize the creation of experiments in agent-based simulations. The generators have been developed with the SimFleet simulation tool enhancing the simulation of realistic movements and location of vehicles, passengers and other users of the urban traffic system within a city. The generators proved to be useful for comparing different distributions of locations as well as different agent movement behaviors based on real city data.},
  archive      = {J_NEUCOM},
  author       = {Pasqual Martí and Jaume Jordán and Javier Palanca and Vicente Julian},
  doi          = {10.1016/j.neucom.2021.06.098},
  journal      = {Neurocomputing},
  pages        = {196-210},
  shortjournal = {Neurocomputing},
  title        = {Charging stations and mobility data generators for agent-based simulations},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Secure data exchange in industrial internet of things.
<em>NEUCOM</em>, <em>484</em>, 183–195. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of the Industrial Internet of Things (IoT) is widespread, working as an enabler to implement large, scalable, reliable, and secure industrial environments. Although existing deployments do not meet security standards and have limited resources for each component which leads to several security breaches , such as trust between components, partner factories, or remote-control. These security failures can lead to critical outcomes, from theft of production information to forced production stoppages, accidents, including physical and others. The combination of blockchain-based solutions with IIoT environments is gaining momentum due to their resilience and security properties. However, chain-structured classic blockchain solutions are very resource-intensive and are not suitable for power-constrained IoT devices . To mitigate the mentioned security concerns, a secure architecture is proposed using a structured asynchronous blockchain DAG (Directed Acyclic Graph) that simultaneously provides security and transaction efficiency for the solution. The solution was modelled with special details in the use cases and sequence diagrams . Security concerns were integrated from the start, and a threat model was created using the STRIDE approach to test the security of the proposed solution. As a result, a flexible solution was been developed that significantly reduces the attack vectors in IIoT environments. The proposed architecture is versatile and flexible, is supported by an extensive security assessment, which allows it to be deployed in a variety of customizable industrial environments and scenarios, as well as to include future hardware and software extensions.},
  archive      = {J_NEUCOM},
  author       = {Anna Sukiasyan and Hasmik Badikyan and Tiago Pedrosa and Paulo Leitao},
  doi          = {10.1016/j.neucom.2021.07.101},
  journal      = {Neurocomputing},
  pages        = {183-195},
  shortjournal = {Neurocomputing},
  title        = {Secure data exchange in industrial internet of things},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ProPythia: A python package for protein classification based
on machine and deep learning. <em>NEUCOM</em>, <em>484</em>, 172–182.
(<a href="https://doi.org/10.1016/j.neucom.2021.07.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of protein data mining has been growing rapidly in the last years. To characterize proteins and determine their function from their amino acid sequences are challenging and long-standing problems, where Bioinformatics and Machine Learning have an emergent role. A myriad of machine and deep learning algorithms have been applied in these tasks with exciting results. However, tools and platforms to calculate protein features and perform both Machine Learning (ML) and Deep Learning (DL) pipelines, taking as inputs protein sequences, are still lacking and have their limitations in terms of performance, user-friendliness and restricted domains of application. Here, to address these limitations, we propose ProPythia, a generic and modular Python package that allows to easily deploy ML and DL approaches for a plethora of problems in protein sequence analysis and classification. It facilitates the implementation, comparison and validation of the major tasks in ML or DL pipelines including modules to read and alter sequences, calculate protein features, preprocess datasets, execute feature selection and dimensionality reduction, perform clustering and manifold analysis, as well as to train and optimize ML/DL models and use them to make predictions. ProPythia has an adaptable modular architecture being a versatile and easy-to-use tool, which will be useful to transform protein data in valuable knowledge even for people not familiarized with ML code. This platform was tested in several applications comparing with results from literature. Here, we illustrate its applicability in two cases studies: the prediction of antimicrobial peptides and the prediction of enzymes Enzyme commission (EC) numbers. Furthermore, we assess the performance of the different descriptors on four different protein classification challenges. Its source code and documentation, including an user guide and case studies are freely available at https://github.com/BioSystemsUM/propythia.},
  archive      = {J_NEUCOM},
  author       = {Ana Marta Sequeira and Diana Lousa and Miguel Rocha},
  doi          = {10.1016/j.neucom.2021.07.102},
  journal      = {Neurocomputing},
  pages        = {172-182},
  shortjournal = {Neurocomputing},
  title        = {ProPythia: A python package for protein classification based on machine and deep learning},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A computational propagation model for malware based on the
SIR classic model. <em>NEUCOM</em>, <em>484</em>, 161–171. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main goal of this work is to reformulate the compartmental and deterministic global SIR Kermack-McKendrick model in terms of stochastic and individual-based techniques. Specifically, the novel model proposed is based on the use of a probabilistic cellular automaton . Specific local transition functionsendowed with appropriate epidemiological coefficients are considered with the aim to replicate the simulation results obtained from the global and continuous approach. Moreover, this new model exhibits important improvements with respect to the original Kermack-McKendrick model: different contact topologies can be considered (not only complete networks but also small-world networks and scale-free networks) and also specific and differentiating characteristics of the devices (resistance to infection, number of adjacent infectious nodes, detection and removal coefficients, etc.) and the specimen of malware (virulence) are taken into account. A comparison between both models is introduced by showing that scale-free networks accelerate the propagation process.},
  archive      = {J_NEUCOM},
  author       = {A. Martín del Rey and R. Casado Vara and S. Rodríguez González},
  doi          = {10.1016/j.neucom.2021.08.149},
  journal      = {Neurocomputing},
  pages        = {161-171},
  shortjournal = {Neurocomputing},
  title        = {A computational propagation model for malware based on the SIR classic model},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis of reliable deployment of TDOA local positioning
architectures. <em>NEUCOM</em>, <em>484</em>, 149–160. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local Positioning Systems (LPS) are supposing an attractive research topic over the last few years. LPS are ad-hoc deployments of wireless sensor networks for particularly adapt to the environment characteristics in harsh environments. Among LPS, those based on temporal measurements stand out for their trade-off among accuracy, robustness and costs. But, regardless the LPS architecture considered, an optimization of the sensor distribution is required for achieving competitive results. Recent studies have shown that under optimized node distributions, time-based LPS cumulate the bigger error bounds due to synchronization errors. Consequently, asynchronous architectures such as Asynchronous Time Difference of Arrival (A-TDOA) have been recently proposed. However, the A-TDOA architecture supposes the concentration of the time measurement in a single clock of a coordinator sensor making this architecture less versatile. In this paper, we present an optimization methodology for overcoming the drawbacks of the A-TDOA architecture in nominal and failure conditions with regards to the synchronous TDOA. Results show that this optimization strategy allows the reduction of the uncertainties in the target location by 79\% and 89.5\% and the enhancement of the convergence properties by 86\% and 33\% of the A-TDOA architecture with regards to the TDOA synchronous architecture in two different application scenarios. In addition, maximum convergence points are more easily found in the A-TDOA in both configurations concluding the benefits of this architecture in LPS high-demanded applications.},
  archive      = {J_NEUCOM},
  author       = {Javier Díez-González and Rubén Álvarez and Paula Verde and Rubén Ferrero-Guillén and Hilde Perez},
  doi          = {10.1016/j.neucom.2021.12.074},
  journal      = {Neurocomputing},
  pages        = {149-160},
  shortjournal = {Neurocomputing},
  title        = {Analysis of reliable deployment of TDOA local positioning architectures},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sliding mode based fault-tolerant control of hypersonic
reentry vehicle using composite learning. <em>NEUCOM</em>, <em>484</em>,
142–148. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A sliding mode based fault-tolerant control method using neural learning is studied for hypersonic reentry vehicle (HRV) in this paper. Based on the non-singular second-order terminal sliding mode, the composite neural learning is adopted to deal with the system uncertainties caused by the additive faults. The main point is to construct the prediction error to evaluate the performance of intelligent approximation . Meanwhile, a disturbance observer is employed to estimate the unknown disturbance while the actuator multiplicative fault is compensated with an adaptive law. The simulation of HRV is conducted to verify the effectiveness of the proposed fault-tolerant control scheme.},
  archive      = {J_NEUCOM},
  author       = {Yuan Zhang and Yingxin Shou and Pengchao Zhang and Weixin Han},
  doi          = {10.1016/j.neucom.2021.10.084},
  journal      = {Neurocomputing},
  pages        = {142-148},
  shortjournal = {Neurocomputing},
  title        = {Sliding mode based fault-tolerant control of hypersonic reentry vehicle using composite learning},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive dynamic programming for nonaffine nonlinear optimal
control problem with state constraints. <em>NEUCOM</em>, <em>484</em>,
128–141. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a constrained adaptive dynamic programming (CADP) algorithm to solve general nonlinear nonaffine optimal control problems with known dynamics. Unlike previous ADP algorithms, it can directly deal with problems with state constraints. Firstly, a constrained generalized policy iteration (CGPI) framework is developed to handle state constraints by transforming the traditional policy improvement process into a constrained policy optimization problem . Next, we propose an actor-critic variant of CGPI, called CADP, in which both policy and value functions are approximated by multi-layer neural networks to directly map the system states to control inputs and value function, respectively. CADP linearizes the constrained optimization problem locally into a quadratically constrained linear programming problem , and then obtains the optimal update of the policy network by solving its dual problem. A trust region constraint is added to prevent excessive policy update, thus ensuring linearization accuracy. We determine the feasibility of the policy optimization problem by calculating the minimum trust region boundary and update the policy using two recovery rules when infeasible. The vehicle control problem in the path-tracking task is used to demonstrate the effectiveness of this proposed method.},
  archive      = {J_NEUCOM},
  author       = {Jingliang Duan and Zhengyu Liu and Shengbo Eben Li and Qi Sun and Zhenzhong Jia and Bo Cheng},
  doi          = {10.1016/j.neucom.2021.04.134},
  journal      = {Neurocomputing},
  pages        = {128-141},
  shortjournal = {Neurocomputing},
  title        = {Adaptive dynamic programming for nonaffine nonlinear optimal control problem with state constraints},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Drag coefficient modeling of heterogeneous connected
platooning vehicles via BP neural network and PSO algorithm.
<em>NEUCOM</em>, <em>484</em>, 117–127. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operation of connected platooning vehicles (CPVs) with V2V and V2I techniques has the potential to decrease the overall aerodynamic drag and reduce fuel consumption. One of the key technologies for CPVs is the spacing control which is heavily dependent on the drag force. However, the existing studies on drag coefficient of CPVs seldom pay attention to heterogeneous platoon, and most analysis only consider the effect of vehicle spacing and ignore key information such as cross-sectional area of adjacent vehicles . In addition, most research only focuses on qualitative research, without concluding a quick formula for calculating vehicle drag coefficient in a platoon. In this work, we investigate the modeling and estimation of drag coefficient in terms of the inter-vehicle distances, the platoon configurations, and the cross-sectional area of the adjacent vehicles . We calculate the drag coefficients for ten categories of vehicles with different inter-vehicle distances via numerical analysis in the software FLUENT. According to hundreds of the analysis results, we propose a model to estimate the drag correction factor online. A hybrid algorithm combining the BP neural network (BPNN) and particle swarm optimization (PSO) is employed to optimize the parameters in the model. The model is validated via three kinds of regression evaluation indexes and additional simulation tests with different platooning configurations and different types of vehicles. In terms of the comparison results, the developed model is effective to estimate the drag coefficients of CPVs.},
  archive      = {J_NEUCOM},
  author       = {Qianyue Luo and Jiaxing Li and Hui Zhang},
  doi          = {10.1016/j.neucom.2020.12.136},
  journal      = {Neurocomputing},
  pages        = {117-127},
  shortjournal = {Neurocomputing},
  title        = {Drag coefficient modeling of heterogeneous connected platooning vehicles via BP neural network and PSO algorithm},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Fault-tolerant adaptive tracking control of euler-lagrange
systems – an echo state network approach driven by reinforcement
learning. <em>NEUCOM</em>, <em>484</em>, 109–116. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) has enjoyed considerable success in application to nonlinear systems . However, very few RL-based works that explicitly address the control problem of MIMO nonlinear systems with subject to actuator failures. In this work, we develop a fault-tolerant adaptive tracking control method fused with an echo state network (ESN) driven by reinforcement learning for Euler-Lagrange systems subject to actuation faults. The proposed control includes an associative search network (ASN), a control gain network (CGN), and an adaptive critic network (ACN), with ASN to estimate the unknown items of the control system, CGN to deal with the time-varying and unknown control gains matrix, and ACN to generate the reinforcement signal, all together ensuring stable tracking and accommodate modeling uncertainties and actuation failures. Different from traditional reinforcement learning controllers that utilizes radial basis function neural networks (RBFNN) or fuzzy systems, the proposed one adopts an echo state network , a paradigm of recurrent neural networks , to implement the ASN, ACN and CGN, resulting in enhanced learning capabilities and stronger robustness against external uncertainties and disturbances, thus better control performance.},
  archive      = {J_NEUCOM},
  author       = {Qing Chen and Yaochu Jin and Yongduan Song},
  doi          = {10.1016/j.neucom.2021.10.083},
  journal      = {Neurocomputing},
  pages        = {109-116},
  shortjournal = {Neurocomputing},
  title        = {Fault-tolerant adaptive tracking control of euler-lagrange systems – an echo state network approach driven by reinforcement learning},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Deep reinforcement learning based active disturbance
rejection control for ship course control. <em>NEUCOM</em>,
<em>484</em>, 99–108. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The linear active disturbance rejection control (LADRC) has been applied in many control practices and achieved satisfactory results. However, the controller with fixed parameters cannot achieve the optimal control performance for the controlled plant. In order to optimize the control effort of LADRC with online parameter adjustment, a deep reinforcement learning algorithm, the deep deterministic policy gradient (DDPG), is applied to enhance the LADRC in this paper for the ship course control and to obtain the optimized parameters of LADRC in different conditions. Specifically, the proposed strategy adopts the deep neural network to adjust the control parameters according to the measured states. This makes the proposed method applicable to the nonlinear control systems with high dimensional continuous states and actions. In addition, the stability of the closed-loop system is analyzed based on the Lyapunov method. In simulations, comparisons with Q-learning based LADRC and conventional LADRC controllers are also presented. Simulation results are provided to demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Huayang Qin and Panlong Tan and Zengqiang Chen and Mingwei Sun and Qinglin Sun},
  doi          = {10.1016/j.neucom.2021.06.096},
  journal      = {Neurocomputing},
  pages        = {99-108},
  shortjournal = {Neurocomputing},
  title        = {Deep reinforcement learning based active disturbance rejection control for ship course control},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed adaptive neural network constraint containment
control for the benthic autonomous underwater vehicles. <em>NEUCOM</em>,
<em>484</em>, 89–98. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple Autonomous Underwater Vehicles (AUV) can complete complex ocean exploration missions cooperatively. This paper proposes a containment control algorithm under time-varying constraints by using a neural network for control of multiple benthic AUVs which are called the Ocean Bottom Flying Node (OBFN) systems. The multiple OBFNs in the presence of nonlinear model uncertainties are under the directed topology. First, we define the auxiliary variable and low-order filter. The anti-windup saturation auxiliary system is constructed in presence of the input saturation. Further, the adaptive law and neural network are designed to compensate environmental disturbances and systems model uncertainties, respectively. Moreover, in order to ensure the control performance of OBFN, an exponential boundary constraint is imposed which could constrain the system error convergent rates and bounds. Lyapunov stability theorem and graph theory are used to prove that the multiple OBFN systems are uniformly ultimately bounded. Finally, simulation results for multiple OBFNs illustrate the effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Yanchao Sun and Yutong Du and Hongde Qin},
  doi          = {10.1016/j.neucom.2021.03.137},
  journal      = {Neurocomputing},
  pages        = {89-98},
  shortjournal = {Neurocomputing},
  title        = {Distributed adaptive neural network constraint containment control for the benthic autonomous underwater vehicles},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reinforcement learning using expectation maximization based
guided policy search for stochastic dynamics. <em>NEUCOM</em>,
<em>484</em>, 79–88. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Guided policy search algorithms have been proven to work with incredible accuracy not only for controlling complicated dynamical systems , but also in learning optimal policies from exploration of various unseen instances. This paper deals with a trajectory optimization problem for an unknown dynamical system subject to measurement noise using expectation maximization and extends it to learning (optimal) policies which have less stochasticity in trajectories because of the higher exploitation efficiency. Theoretical and empirical evidence of learned optimal policies for the new approach is depicted in comparison to some well known baselines which are evaluated on an autonomous system with widely used performance metrics.},
  archive      = {J_NEUCOM},
  author       = {Prakash Mallick and Zhiyiong Chen and Mohsen Zamani},
  doi          = {10.1016/j.neucom.2021.01.142},
  journal      = {Neurocomputing},
  pages        = {79-88},
  shortjournal = {Neurocomputing},
  title        = {Reinforcement learning using expectation maximization based guided policy search for stochastic dynamics},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural network-based reinforcement learning control for
combined spacecraft attitude tracking maneuvers. <em>NEUCOM</em>,
<em>484</em>, 67–78. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel reinforcement learning-based attitude tracking control strategy for combined spacecraft takeover maneuvers with completely unknown dynamics. One major issue in the context of combined spacecraft attitude takeover control is that the accurate dynamic model is highly nonlinear, complex and costly to identify online, which makes it impractical for control design. To address this issue, we take the advantage of the Q-learning algorithm to acquire the control strategy directly from system input/output measurement data in a model-free manner, and thus the online inertia parameter identification procedure is avoided. More specifically, first, the attitude tracking is formulated as a regulation problem by introducing an argumented system, where the system dynamic model is still required in control design. Then, in order to achieve a model-free control strategy, an online policy-iteration (PI) Q-learning procedure is derived to solve the Bellman optimality equation by utilizing the generated measurement data. In theoretical analysis, it is proved that the iteration sequences of Q value function and control strategy can converge to the optimal ones. In addition, rigorous proof of the stability and monotonicity guarantees of the proposed control strategy are also provided. Furthermore, for the purpose of online implementation, off-policy learning scheme is employed to find the optimal Q value function approximator with neural network structure after data-collection phase. Numerical simulations are exhibited to validate the effectiveness of the proposed strategy.},
  archive      = {J_NEUCOM},
  author       = {Yuhan Liu and Guangfu Ma and Yueyong Lyu and Pengyu Wang},
  doi          = {10.1016/j.neucom.2021.07.099},
  journal      = {Neurocomputing},
  pages        = {67-78},
  shortjournal = {Neurocomputing},
  title        = {Neural network-based reinforcement learning control for combined spacecraft attitude tracking maneuvers},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A spatially enhanced network with camera-lidar fusion for 3D
semantic segmentation. <em>NEUCOM</em>, <em>484</em>, 59–66. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In autonomous vehicle technology, environmental perception is a very important part of the whole system. The robustness and accuracy of the perception determine the performance of the whole system. Compared with the camera, lidar can generate point cloud data which can provide accurate 3D information better. At present, more researches focus on environmental perception through point cloud. However, the point cloud has the characteristics of sparsity , unordered and non-uniform distribution, its processing method is also different from the general image-based method. In this paper, we proposed a method of semantic segmentation of point cloud which is realized by convolutional neural network . Through spherical mapping, the scattered point cloud is transformed into 2D spherical map with dense and uniform distribution, which is convenient for the processing of the network. To reduce the loss of point information, the spatial position, reflection intensity information and angle value of point are preserved during spherical mapping. Our work includes a lightweight convolutional neural network that fuses point cloud and image information. In addition, a spatial module is added to supplement the loss of spatial information and improve the performance of segmentation. Finally, a series of comparative experiments and performance evaluation are carried out, which show that the proposed method is not only much better than the original structure, but also better than another image and lidar fusion network in the segmentation of each category.},
  archive      = {J_NEUCOM},
  author       = {Chao Ye and Huihui Pan and Xinghu Yu and Huijun Gao},
  doi          = {10.1016/j.neucom.2020.12.135},
  journal      = {Neurocomputing},
  pages        = {59-66},
  shortjournal = {Neurocomputing},
  title        = {A spatially enhanced network with camera-lidar fusion for 3D semantic segmentation},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decentralized optimal large scale multi-player
pursuit-evasion strategies: A mean field game approach with
reinforcement learning. <em>NEUCOM</em>, <em>484</em>, 46–58. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the intelligent design for the pursuit-evasion game with large scale multi-pursuer and multi-evader has been investigated. Due to the vast number of agents, the notorious ”Curse of Dimensionality” can seriously challenge the traditional design in multi-player pursuit-evasion game, especially under harsh environment with limited communication resource to support information exchange among multi-players. To address this intractable challenge, the emerging Mean Field Games (MFG) theory has been utilized to solve the optimal pursuit-evasion strategies based on a new form of probability density function (PDF) instead of detailed information from all the other players/agents. As such, not only the information exchange is reduced, but also the computation dimension for the optimal strategy derivation is decreased. Specifically, the MFG has been integrated into the pursuit-evasion game to generate a hierarchical structure where the pursuers and the evaders form two mean field groups separately. To online solve the mean field equations, i.e., two coupled partial differential equations , the actor-critic reinforcement learning mechanism is adopted and further extended to a novel actor-critic-mass-opponent (ACMO) approach. In ACMO, the actor neural network estimates the optimal control, the critic neural network approximates the optimal cost function, the mass neural network learns the agent’s group PDF, and the opponent neural network predicts the opponents’ average states in the form of PDF that causes maximum cost for the agent’s group. The Lyapunov theory is utilized to provide the convergence analysis for all neural networks and the stability analysis for the closed-loop system. Eventually, a series of numerical simulations are conducted to demonstrate the effectiveness of the developed scheme.},
  archive      = {J_NEUCOM},
  author       = {Zejian Zhou and Hao Xu},
  doi          = {10.1016/j.neucom.2021.01.141},
  journal      = {Neurocomputing},
  pages        = {46-58},
  shortjournal = {Neurocomputing},
  title        = {Decentralized optimal large scale multi-player pursuit-evasion strategies: A mean field game approach with reinforcement learning},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simultaneous estimation of joint angle and interaction force
towards sEMG-driven human-robot interaction during constrained tasks.
<em>NEUCOM</em>, <em>484</em>, 38–45. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human has excellent motor capability and performance in conducting various manipulation tasks. During some tasks such as tightening/loosening a screw with a screwdriver, the motion is accompanied by force exertion to the environment (that is, constrained motion). To obtain natural human-robot interaction (HRI) as human interacts/collaborates with the environment, decoding the human’s movement intention in a way of motion and interaction force is meaningful for robots to carry out such constrained tasks. This paper proposes a long shortterm memory (LSTM) -based decoding method for the simultaneous estimation of human motion and interactive force from muscle activities represented by surface electromyography (sEMG) signals. The sEMG recorded from the muscles of forearm is used to decode human’s movement intention. In order to extract smooth features from non-stationary sEMG signals, Bayesian filter is applied instead of traditional time-domain feature extraction method. From the real-time experiments on eight subjects, the LSTM-based decoding method represents high accuracy of motion estimation (91.7\%) and force estimation (96.1\%) despite of the existence of muscle coupling and non-stationary mapping between muscle activities and motion/interaction force during such constrained tasks. It indicates that the estimated motion and interaction force can be further applied for HRI in accomplishing constrained tasks.},
  archive      = {J_NEUCOM},
  author       = {Qin Zhang and Li Fang and Qining Zhang and Caihua Xiong},
  doi          = {10.1016/j.neucom.2021.05.113},
  journal      = {Neurocomputing},
  pages        = {38-45},
  shortjournal = {Neurocomputing},
  title        = {Simultaneous estimation of joint angle and interaction force towards sEMG-driven human-robot interaction during constrained tasks},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Reinforcement learning-based finite-time tracking control
of an unknown unmanned surface vehicle with input constraints.
<em>NEUCOM</em>, <em>484</em>, 26–37. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, subject to completely unknown system dynamics and input constraints, a reinforcement learning-based finite-time trajectory tracking control (RLFTC) scheme is innovatively created for an unmanned surface vehicle (USV) by combining actor-critic reinforcement learning (RL) mechanism with finite-time control technique. Unlike previous RL-based tracking which requires infinite-time convergence thereby rather sensitive to complex unknowns, an actor-critic finite-time control structure is created by employing adaptive neural network identifiers to recursively update actor and critic, such that learning-based robustness can be sufficiently enhanced. Moreover, deduced from the Bellman error formulation, the proposed RLFTC is directly optimized in a finite-time manner. Theoretical analysis eventually shows that the proposed RLFTC scheme can ensure semi-global practical finite-time stability (SGPFS) for a closed-loop USV system and tracking errors converge to an arbitrarily small neighborhood of the origin in a finite time, subject to optimal cost. Both mathematical simulation and virtual-reality experiments demonstrate remarkable effectiveness and superiority of the proposed RLFTC scheme.},
  archive      = {J_NEUCOM},
  author       = {Ning Wang and Ying Gao and Chen Yang and Xuefeng Zhang},
  doi          = {10.1016/j.neucom.2021.04.133},
  journal      = {Neurocomputing},
  pages        = {26-37},
  shortjournal = {Neurocomputing},
  title        = {Reinforcement learning-based finite-time tracking control of an unknown unmanned surface vehicle with input constraints},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning-based online optimal sliding-mode control for space
circumnavigation missions with input constraints and mismatched
uncertainties. <em>NEUCOM</em>, <em>484</em>, 13–25. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A learning-based online optimal sliding-mode control strategy is developed for space circumnavigation missions subject to input constraints, and the mismatched uncertainties caused by measurement uncertainties are also considered in this infinite-horizon optimal control problem . The logarithmic hyperbolic cosine function is used to design the optimal value function to overcome the weakness that the derivative of the adaptive weight of neural network (NN) changes too fast when the value of the sliding-mode function is too large, and another suitable nonquadratic function is used to incorporate input constraints into the optimal control framework. To approximate the Hamiton-Jacobi-Bellman equation corresponding to the novel optimal value function, an actor-critic (AC) architecture is introduced with NNs, and a finite-time disturbance observer (FTDO) is employed to estimate the mismatched uncertainties in the plant. The simulation results verify the effectiveness of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Hanlin Dong and Xuebo Yang},
  doi          = {10.1016/j.neucom.2021.04.132},
  journal      = {Neurocomputing},
  pages        = {13-25},
  shortjournal = {Neurocomputing},
  title        = {Learning-based online optimal sliding-mode control for space circumnavigation missions with input constraints and mismatched uncertainties},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust adaptive neural network control for dynamic
positioning of marine vessels with prescribed performance under model
uncertainties and input saturation. <em>NEUCOM</em>, <em>484</em>, 1–12.
(<a href="https://doi.org/10.1016/j.neucom.2021.03.136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a dedicated robust adaptive neural network control (RANNC) scheme for dynamic positioning (DP) of marine vessels with a prescribed performance under model uncertainties, external disturbances and input saturation. To guarantee that the transient performance is always within the prescribed performance constraints, a novel error transfer function is firstly proposed to transfer the original dynamic positioning system with the constrained error behavior into an equivalent unconstrained one. Next, the RANNC scheme is developed with the backstepping technique, and the method of command filter is introduced to avoid the ”dimension disaster” problem. Considering the ship’s inertial matrix and damping matrix are not constant in practice, the adaptive control technique and RBF neural networks are adopted to design the model adaptive controller, which only requires the actuator matrix rather than a completely accurate model. Moreover, minimal learning parameter technique is introduced to minimize the computational burden triggered by weight update of neural networks. Finally, comparison simulation results are provided to illustrate the performance of the proposed RANNC scheme.},
  archive      = {J_NEUCOM},
  author       = {Jinjiang Li and Xianbo Xiang and Shaolong Yang},
  doi          = {10.1016/j.neucom.2021.03.136},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {Robust adaptive neural network control for dynamic positioning of marine vessels with prescribed performance under model uncertainties and input saturation},
  volume       = {484},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Energy-efficient VM opening algorithms for real-time
workflows in heterogeneous clouds. <em>NEUCOM</em>, <em>483</em>,
501–514. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimizing energy consumption is a critical challenge for real-time workflows, particularly in heterogeneous cloud computing systems . State-of-the-art algorithms aim to minimize the energy consumed for processing such applications by choosing virtual machines (VMs) to shut down from all opened VMs (i.e., VM merging). However, such VM merging through an “on-to-close” approach usually incurs high computational complexity . This paper proposes an energy-efficient VM opening (EEVO) algorithm that is capable of choosing VMs to turn on from all closed VMs while satisfying the real-time constraint of applications. Considering that there are slacks that can be eliminated or reduced between adjacently scheduled tasks after using the EEVO algorithm, a dynamic scaling down EEVO algorithm (DEEVO) is further proposed. DEEVO is implemented by scaling down the frequency of VMs executing each task based on the dynamic voltage and frequency scaling (DVFS) technique. Experimental results demonstrate that, with the above-mentioned improvements, DEEVO achieves lower energy consumption for real-time workflows than state-of-the-art algorithms do. In addition, DEEVO outperforms state-of-the-art algorithms in the computational efficiency of accomplishing task scheduling .},
  archive      = {J_NEUCOM},
  author       = {Saiqin Long and Xin Dai and Tingrui Pei and Jiasheng Cao and Hiroo Sekiya and Young-June Choi},
  doi          = {10.1016/j.neucom.2021.08.145},
  journal      = {Neurocomputing},
  pages        = {501-514},
  shortjournal = {Neurocomputing},
  title        = {Energy-efficient VM opening algorithms for real-time workflows in heterogeneous clouds},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DFSNet: Dividing-fuse deep neural networks with searching
strategy for distributed DNN architecture. <em>NEUCOM</em>,
<em>483</em>, 488–500. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The overwhelming parameters and computation consumption of deep neural networks limit their applicability to a single computing node with poor computing power, such as edge and mobile devices . Most previous works leverage model pruning and compression strategies to reduce DNN parameters for resource-constrained devices. However, most model compression methods may suffer from accuracy loss. Recently, we find that combine many weak computing nodes as a distributed system to run large and sophisticated DNN models is a promising solution for the issue. However, it is essential for the distributed system to design distributed DNN models and inference schemes, one of the great challenges of distributed system is how to design an efficient distributed DNN model for data parallelism and model parallelism , and communication overhead is also another critical performance bottleneck for distributed DNN model. Therefore, in this article, we propose DFSNet framework ( D ividing- F use neural Net work with S earching Strategy) for distributed DNN architecture. Firstly, the DFSNet framework includes a joint ”dividing-fusing” method to convert regular DNN models into distributed models that are friendly for distributed systems. This method divides the conventional DNN model in the channel dimension, and sets a few special layers to fuse feature-map information from different channel groups for accuracy improvement. Since the fusion layers are sparse in the network, they do not increase too much extra inference time and communication overhead on the distributed nodes, but they can maintain the accuracy of distributed neural networks significantly. Secondly, considering the architecture of distributed computing nodes, we propose a parallel fusion topology to improve the utilization of different computing nodes. Lastly, the popular weight-sharing neural architecture search (NAS) technique is leveraged to search the position of fusion layers in the distributed DNN model for high accuracy and finally generate an efficient distributed DNN model. Compared with the original network, our converted distributed DNN achieves better performance (e.g. 1.88\% precision boosting in ResNet56 on CIFAR-100 dataset, and 1.25\% precision improving in MobileNetV2 on ImageNet dataset). In addition, most layers of DNN have been divided into different distributed nodes on channel dimension, which is particularly suitable for distributed DNN architecture with very low communication overhead.},
  archive      = {J_NEUCOM},
  author       = {Wenxuan Hou and Longjun Liu and Haonan Zhang and Hongbin Sun and Nanning Zheng},
  doi          = {10.1016/j.neucom.2021.08.144},
  journal      = {Neurocomputing},
  pages        = {488-500},
  shortjournal = {Neurocomputing},
  title        = {DFSNet: Dividing-fuse deep neural networks with searching strategy for distributed DNN architecture},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EventGraD: Event-triggered communication in parallel machine
learning. <em>NEUCOM</em>, <em>483</em>, 474–487. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication in parallel systems imposes significant overhead which often turns out to be a bottleneck in parallel machine learning . To relieve some of this overhead, in this paper, we present EventGraD - an algorithm with event-triggered communication for stochastic gradient descent in parallel machine learning . The main idea of this algorithm is to modify the requirement of communication at every iteration in standard implementations of stochastic gradient descent in parallel machine learning to communicating only when necessary at certain iterations. We provide theoretical analysis of convergence of our proposed algorithm. We also implement the proposed algorithm for data-parallel training of a popular residual neural network used for training the CIFAR-10 dataset and show that EventGraD can reduce the communication load by up to 60\% while retaining the same level of accuracy. In addition, EventGraD can be combined with other approaches such as Top-K sparsification to decrease communication further while maintaining accuracy.},
  archive      = {J_NEUCOM},
  author       = {Soumyadip Ghosh and Bernardo Aquino and Vijay Gupta},
  doi          = {10.1016/j.neucom.2021.08.143},
  journal      = {Neurocomputing},
  pages        = {474-487},
  shortjournal = {Neurocomputing},
  title        = {EventGraD: Event-triggered communication in parallel machine learning},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Laparoscopic image enhancement based on distributed retinex
optimization with refined information fusion. <em>NEUCOM</em>,
<em>483</em>, 460–473. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With intrinsic non-uniform illumination variations in laparoscopic images, such images often suffer from insufficient lighting and low visibility. This in turn may cause incorrect targeting, surgical risk, and extended operating time during laparoscopic surgery. Although various methods for nature image enhancement have been proposed in past decades, surgical laparoscopic image enhancement still needs improving due to issues including naturalness, blurred texture, color cast, and extensive computational time. To address these problems, this paper proposes a laparoscopic image enhancement method, based on distributed retinex optimization with refined information fusion. The proposed method minimizes a distributed optimization model with l 2 l2 -norm regularization terms , resulting in a low computational complexity . By integrating the refined image information into the optimization process, our method significantly enhances dark regions while preserving naturalness and texture structures. Experimental results show that our optimization algorithm is more effective than conventional enhancement algorithms in terms of vision augmentation, performance index, and computation time.},
  archive      = {J_NEUCOM},
  author       = {Wenyao Xia and Elvis Chen and Stephen Pautler and Terry Peters},
  doi          = {10.1016/j.neucom.2021.08.142},
  journal      = {Neurocomputing},
  pages        = {460-473},
  shortjournal = {Neurocomputing},
  title        = {Laparoscopic image enhancement based on distributed retinex optimization with refined information fusion},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of distributed optimization: Problems, models and
algorithms. <em>NEUCOM</em>, <em>483</em>, 446–459. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of big data and artificial intelligence , distributed optimization has emerged as an indispensable tool for solving large-scale problems. In particular, the multi-agent system based on distributed information processing can be elaborately designed for distributed optimization , in which the agents collaboratively minimize a global objective function made up of a sum of local objective cost functions subject to some local and/or global constraints. Inspired by the applications involving resource allocation, machine learning , power systems, sensor networks and cloud computing , a variety of distributed optimization models and algorithms have been investigated and developed. The optimization models include unconstrained and constrained problems in continuous and discontinuous systems with undirected and directed communication topology graphs . The constraints include bounded constraint, separable and inseparable equality and inequality constraints . Meanwhile, in distributed algorithms, every agent executes its local computation and updating on basis of its own data information and that exchanging with its neighboring agents by means of the underlying communication networks, in order to deal with the optimization problems in a distributed way. This paper is designed to provide a comprehensive overview of extant distributed models and algorithms for distributed optimization.},
  archive      = {J_NEUCOM},
  author       = {Yanling Zheng and Qingshan Liu},
  doi          = {10.1016/j.neucom.2021.06.097},
  journal      = {Neurocomputing},
  pages        = {446-459},
  shortjournal = {Neurocomputing},
  title        = {A review of distributed optimization: Problems, models and algorithms},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FedSim: Similarity guided model aggregation for federated
learning. <em>NEUCOM</em>, <em>483</em>, 432–445. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a distributed machine learning approach in which clients contribute to learning a global model in a privacy preserved manner. Effective aggregation of client models is essential to create a generalised global model. To what extent a client is generalisable and contributing to this aggregation can be ascertained by analysing inter-client relationships. We use similarity between clients to model such relationships. We explore how similarity knowledge can be inferred from comparing client gradients, instead of inferring similarity on the basis of client data which violates the privacy-preserving constraint in FL. The similarity-guided FedSim algorithm, introduced in this paper, decomposes FL aggregation into local and global steps. Clients with similar gradients are clustered to provide local aggregations, which thereafter can be globally aggregated to ensure better coverage whilst reducing variance. Our comparative study also investigates the applicability of FedSim in both real-world datasets and on synthetic datasets where statistical heterogeneity can be controlled and studied systematically. A comparative study of FedSim with state-of-the-art FL baselines, FedAvg and FedProx, clearly shows significant performance gains. Our findings confirm that by exploiting latent inter-client similarities, FedSim’s performance is significantly better and more stable compared to both these baselines.},
  archive      = {J_NEUCOM},
  author       = {Chamath Palihawadana and Nirmalie Wiratunga and Anjana Wijekoon and Harsha Kalutarage},
  doi          = {10.1016/j.neucom.2021.08.141},
  journal      = {Neurocomputing},
  pages        = {432-445},
  shortjournal = {Neurocomputing},
  title        = {FedSim: Similarity guided model aggregation for federated learning},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finite-iteration learning tracking of multi-agent systems
via the distributed optimization method. <em>NEUCOM</em>, <em>483</em>,
423–431. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the finite-iteration tracking issue of multi-agent systems is investigated with the distributed optimization method. Since the infinite-iteration strategy is unrealistic, the finite-iteration approach is adopted to study the problem. Moreover, the tracking performance is undesired for the traditional iterative learning schemes. Then optimization technique is used to cover the drawback. The tracking error is regarded as the optimization objective, and the consensus tracking issue is considered as the distributed optimization problem. An appropriate learning control strategy is designed on the basis of the gradient of the tracking error. Further, the optimization issue can be solved by means of the finite-iteration approach, and the learning algorithm can improve the tracking performance. Theoretical results are proposed by using the norm estimation and some inequalities skills. At last, a numerical simulation is given to illustrate the effectiveness of the main results.},
  archive      = {J_NEUCOM},
  author       = {Zijian Luo and Wenjun Xiong and Chi Huang},
  doi          = {10.1016/j.neucom.2021.08.140},
  journal      = {Neurocomputing},
  pages        = {423-431},
  shortjournal = {Neurocomputing},
  title        = {Finite-iteration learning tracking of multi-agent systems via the distributed optimization method},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A collective neurodynamic approach for solving distributed
system optimum dynamic traffic assignment problems. <em>NEUCOM</em>,
<em>483</em>, 411–422. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the traditional system optimum dynamic traffic assignment (SO-DTA) problem is solved by distributed multi-agent dynamics. The goal of SO-DTA is to optimally control the route choice of each user to minimize the total travel time by all users over the assignment time period. It is beneficial for reducing the congestion of the traffic network with time-varying demand. Different from the traditional SO-DTA which is formulated and solved in a centralized scheme, we aim at solving it from a multi-agent perspective in a communication network. Based on the cell transmission model, two connector-based relaxed SO-DTA models are provided in a multi-agent system framework for the traffic network with a single destination and multiple destinations, respectively. In the provided models, each cell connector is treated as an agent, which could exchange information with its adjacent connectors to accomplish the system optimization objective. Then, a collective neurodynamic system equipped with the proposed distributed protocol is used to solve general network optimization problems including the above SO-DTA models as special cases. The convergence analysis is further given for the proposed algorithm. Numerical studies over various traffic networks are presented to show the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Xinli Shi and Xiangping Xu and Jinde Cao},
  doi          = {10.1016/j.neucom.2021.08.139},
  journal      = {Neurocomputing},
  pages        = {411-422},
  shortjournal = {Neurocomputing},
  title        = {A collective neurodynamic approach for solving distributed system optimum dynamic traffic assignment problems},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust supervised discrete hashing. <em>NEUCOM</em>,
<em>483</em>, 398–410. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we proposed a more robust supervised hashing framework based on the Cauchy loss function and Supervised Discrete Hashing (SDH) called Robust Supervised Discrete Hashing (RSDH), which can learn a robust subspace consisted of binary codes. The Cauchy loss is used to measure the error between the label matrix and the product of the decomposed matrices. RSDH can not only reduce the outliers and noise of the hashing codes, but also achieve the more satisfactory retrieval effect. Image retrieval experiments demonstrate that RSDH performs better than the other hashing methods .},
  archive      = {J_NEUCOM},
  author       = {Yao Xiao and Wei Zhang and Xiangguang Dai and Xiangqin Dai and Nian Zhang},
  doi          = {10.1016/j.neucom.2021.09.077},
  journal      = {Neurocomputing},
  pages        = {398-410},
  shortjournal = {Neurocomputing},
  title        = {Robust supervised discrete hashing},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Streamlining advanced taxi assignment strategies based on
legal analysis. <em>NEUCOM</em>, <em>483</em>, 386–397. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years many novel applications have appeared that promote the provision of services and activities in a collaborative manner. The key idea behind such systems is to take advantage of idle or underused capacities of existing resources, in order to provide improved services that assist people in their daily tasks, with additional functionality, enhanced efficiency, and/or reduced cost. Particularly in the domain of urban transportation, many researchers have put forward novel ideas, which are then implemented and evaluated through prototypes that usually draw upon AI methods and tools. However, such proposals also bring up multiple non-technical issues that need to be identified and addressed adequately if such systems are ever meant to be applied to the real world. While, in practice, legal and ethical aspects related to such AI-based systems are seldomly considered in the beginning of the research and development process, we argue that they not only restrict design decisions, but can also help guiding them. In this manuscript, we set out from a prototype of a taxi coordination service that mediates between individual (and autonomous) taxis and potential customers. After representing key aspects of its operation in a semi-structured manner, we analyse its viability from the viewpoint of current legal restrictions and constraints, so as to identify additional non-functional requirements as well as options to address them. Then, we go one step ahead, and actually modify the existing prototype to incorporate the previously identified recommendations. Performing experiments with this improved system helps us identify the most adequate option among several legally admissible alternatives.},
  archive      = {J_NEUCOM},
  author       = {Holger Billhardt and José-Antonio Santos and Alberto Fernández and Mar Moreno and Sascha Ossowski and José A. Rodríguez},
  doi          = {10.1016/j.neucom.2021.10.085},
  journal      = {Neurocomputing},
  pages        = {386-397},
  shortjournal = {Neurocomputing},
  title        = {Streamlining advanced taxi assignment strategies based on legal analysis},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-tumorous facial pigmentation classification based on
multi-view convolutional neural network with attention mechanism.
<em>NEUCOM</em>, <em>483</em>, 370–385. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosis of non-tumorous facial pigmentation is an important and difficult issue in the field of dermatology (For example, chloasma and freckles are too similar to distinguish, but they often appear at the same time). In this paper, different from other studies, we used images with nine different forms (views) to comprehensively diagnose these diseases for the first time. In detail, firstly, we collected and published the first multi-view non-tumorous facial pigmentation (MVNFP) dataset provided as the benchmark for classification and segmentation problems: MVNFP, where each face consists of 9 images: 1) Standard Image, 2) Polarization Image, 3) Oil Secretion Image, 4) Sunshine Damage Image, 5) Pigmentation Image, 6) Physiological Aging Image, 7) Sensitive Image, 8) Brown Image, 9) Pigmentation Trend Image. MVNFP has a total of 10,719 images, 5 categories which brings great convenience for the follow-up research. Secondly, to make full use of the informations behind these images described from different views, we use multi-view convolutional neural network to diagnose these indistinguishable diseases. In addition, we introduced the attention mechanisms , and at the same time deeply studied the many influencing factors of multi-view non-tumorous facial pigmentation diagnosis. All experimental results show our method has achieved state-of-the-art results on the MVNFP dataset. Code and MVNFP dataset are released at: https://github.com/sunshiding/MVNFP.git .},
  archive      = {J_NEUCOM},
  author       = {Yingjie Tian and Shiding Sun and Zhiquan Qi and Ying Liu and Zeyuan Wang},
  doi          = {10.1016/j.neucom.2022.01.011},
  journal      = {Neurocomputing},
  pages        = {370-385},
  shortjournal = {Neurocomputing},
  title        = {Non-tumorous facial pigmentation classification based on multi-view convolutional neural network with attention mechanism},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new neuro-optimal nonlinear tracking control method via
integral reinforcement learning with applications to nuclear systems.
<em>NEUCOM</em>, <em>483</em>, 361–369. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new infinite horizon optimal tracking control method for continuous-time nonlinear systems is given using an actor-critic structure. This present integral reinforcement learning (IRL) method is a novelty method in adaptive dynamic programming (ADP) algorithms and an online policy iteration algorithm. For the optimal tracking problem, the cost function is defined by tracking errors. Consequently, the goal is to minimize tracking errors toward desired trajectories . Since it is hard to solve the Hamilton-Jacobi-Bellman (HJB) equation for continuous-time nonlinear systems control problems, leveraging the actor-critic architecture with neural networks (NNs) to approximate the tracking error performance index and error control law is necessary. Instead of using conventional neural networks , we employ higher-order polynomials in the whole actor-critic architecture. Finally, we apply this new neuro-optimal tracking method to the 2500MW pressurized water reactor (PWR) nuclear power plant, and simulation results are given to demonstrate the effectiveness of the developed method.},
  archive      = {J_NEUCOM},
  author       = {Weifeng Zhong and Mengxuan Wang and Qinglai Wei and Jingwei Lu},
  doi          = {10.1016/j.neucom.2022.01.034},
  journal      = {Neurocomputing},
  pages        = {361-369},
  shortjournal = {Neurocomputing},
  title        = {A new neuro-optimal nonlinear tracking control method via integral reinforcement learning with applications to nuclear systems},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data representation via refined discriminant analysis and
common class structure. <em>NEUCOM</em>, <em>483</em>, 348–360. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main goal of discriminant embedding is to extract features that form a compact and informative representation of the original feature set. In this paper, we propose an improved hybrid method aimed at extracting linear features for supervised multiclass classification . We implement a unifying criterion that is able to preserve the benefits of robust sparse linear discrimination along with inter-class sparsity . The expected transformation involves two forms of discrimination, namely: common class or group sparsity in addition to robust discriminant analysis with feature ranking. For the purpose of solving the proposed criterion, an iterative alternating minimization framework is used to evaluate the linear transformation and orthogonal matrix. The presented scheme is generic enough that it can be used to consolidate and tune several linear embedding methods. In the light of experiments conducted on various image datasets with different types, the suggested scheme was able to outperform other methods in most cases.},
  archive      = {J_NEUCOM},
  author       = {F. Dornaika and A. Khoder and W. Khoder},
  doi          = {10.1016/j.neucom.2021.12.068},
  journal      = {Neurocomputing},
  pages        = {348-360},
  shortjournal = {Neurocomputing},
  title        = {Data representation via refined discriminant analysis and common class structure},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Online multi-object tracking with unsupervised
re-identification learning and occlusion estimation. <em>NEUCOM</em>,
<em>483</em>, 333–347. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occlusion between different objects is a typical challenge in Multi-Object Tracking (MOT), which often leads to inferior tracking results due to the missing detected objects. The common practice in multi-object tracking is re-identifying the missed objects after their reappearance. Though tracking performance can be boosted by the re-identification, the annotation of identity is required to train the model. In addition, such practice of re-identification still can not track those highly occluded objects when they are missed by the detector. In this paper, we focus on online multi-object tracking and design two novel modules, the unsupervised re-identification learning module and the occlusion estimation module, to handle these problems. Specifically, the proposed unsupervised re-identification learning module does not require any (pseudo) identity information nor suffer from the scalability issue. The proposed occlusion estimation module tries to predict the locations where occlusions happen, which are used to estimate the positions of missed objects by the detector. Our study shows that, when applied to state-of-the-art MOT methods, the proposed unsupervised re-identification learning is comparable to supervised re-identification learning, and the tracking performance is further improved by the proposed occlusion estimation module.},
  archive      = {J_NEUCOM},
  author       = {Qiankun Liu and Dongdong Chen and Qi Chu and Lu Yuan and Bin Liu and Lei Zhang and Nenghai Yu},
  doi          = {10.1016/j.neucom.2022.01.008},
  journal      = {Neurocomputing},
  pages        = {333-347},
  shortjournal = {Neurocomputing},
  title        = {Online multi-object tracking with unsupervised re-identification learning and occlusion estimation},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Event-triggered impulsive control design for synchronization
of inertial neural networks with time delays. <em>NEUCOM</em>,
<em>483</em>, 322–332. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the synchronization problem of inertial neural networks (INNs) with time delays by virtue of event-triggered (E-T) impulsive control, in which a Lyapunov function based E-T mechanism is used to determine impulsive instants. The synchronization analysis of INNs through E-T impulsive control technique unlike time-triggered impulsive control, which would be activated when certain well-designed conditions exist, E-T impulsive control is only allowed when certain well-defined events occur. Besides that, control input is only required at triggered instants and also no control input is required for two triggered instants in a sequence. Considering the E-T mechanism, the synchronization analysis of the INNs is discussed by reduced and non-reduced order approaches and constructing the suitable Lyapunov functionals. Finally, two simulation results are provided to illustrate the efficacy of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {S. Shanmugasundaram and K. Udhayakumar and D. Gunasekaran and R. Rakkiyappan},
  doi          = {10.1016/j.neucom.2022.02.023},
  journal      = {Neurocomputing},
  pages        = {322-332},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered impulsive control design for synchronization of inertial neural networks with time delays},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RUFP: Reinitializing unimportant filters for soft pruning.
<em>NEUCOM</em>, <em>483</em>, 311–321. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network pruning has become a popular method to reduce the storage and computational complexity of deep neural networks . In order to minimize the performance loss, soft pruning retains a large model capacity by setting unimportant weights to zero and allowing them to be updated. However, these weights are difficult to reactivate due to the small amplitude and frequent resets. In this paper, we propose a novel method, termed RUFP, to reinitialize unimportant filters according to the most important one, which not only gives these filters a chance to be reactivated, but also introduces more filter forms that may win the initialization lottery. By gradually increasing the reinitialization ratio and decreasing the reassigned values of factors in the batch normalization layer, soft pruning is achieved. Benefiting from the large model capacity and multiple reinitializations, the compressed model after fine-tuning achieves superior performance. Extensive experiments demonstrate the effectiveness of this method in improving the accuracy of the pruned model. The accuracy of ResNet-56 on CIFAR-10 is improved from 93.05\% to 93.17\% while reducing 57.7\% calculations and 58.8\% parameters. Compared with the traditional soft pruning method and other state-of-the-art methods, our RUFP obtains outstanding performance at various compression levels .},
  archive      = {J_NEUCOM},
  author       = {Ke Zhang and Guangzhe Liu and Meibo Lv},
  doi          = {10.1016/j.neucom.2022.02.024},
  journal      = {Neurocomputing},
  pages        = {311-321},
  shortjournal = {Neurocomputing},
  title        = {RUFP: Reinitializing unimportant filters for soft pruning},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deterministic policy optimization with clipped value
expansion and long-horizon planning. <em>NEUCOM</em>, <em>483</em>,
299–310. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based reinforcement learning (MBRL) approaches have demonstrated great potential in handling complex tasks with high sample efficiency. However, MBRL struggles with asymptotic performance compared to model-free reinforcement learning (MFRL). In this paper, we present a long-horizon policy optimization method, namely model-based deterministic policy gradient (MBDPG), for efficient exploitation of the learned dynamics model through multi-step gradient information. First, we approximate the dynamics of the environment with a parameterized linear combination of an ensemble of Gaussian distributions. Moreover, the dynamics model is equipped with a memory module and trained on a multi-step prediction task to reduce cumulative error. Second, successful experience is used to guide the policy at the early stage of training to avoid ineffective exploration. Third, a clipped double value network is expanded in the learned dynamics to reduce overestimation bias. Finally, we present a deterministic policy gradient approach in the model that backpropagates multi-step gradient along the imagined trajectories. Our method shows higher sampling efficiency than the state-of-the-art MFRL methods while maintaining better convergence performance and time efficiency compared to the SOAT MBRL.},
  archive      = {J_NEUCOM},
  author       = {Shiqing Gao and Haibo Shi and Fang Wang and Zijian Wang and Siyu Zhang and Yunxia Li and Yaoru Sun},
  doi          = {10.1016/j.neucom.2022.02.022},
  journal      = {Neurocomputing},
  pages        = {299-310},
  shortjournal = {Neurocomputing},
  title        = {Deterministic policy optimization with clipped value expansion and long-horizon planning},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A quantile fusion methodology for deep forecasting.
<em>NEUCOM</em>, <em>483</em>, 286–298. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning for forecasting has elicited excitement. Previous deep forecasting methods were usually designed for specific datasets and might hardly generalize well on other datasets. This paper discloses that besides designing a specific deep architecture, if we deploy the loss function more intelligently, we can construct an accurate and robust deep forecasting model. We frame this research from four aspects. First, we propose to transform a hidden layer as quantile layer to generate quantiles as robust distribution representation. Second, we introduce an effective crossing loss which can reduce the frequency of quantile crossing. Third, we investigate the performance of two learning modes, i.e., end-to-end v.s. two-stage, and conclude end-to-end is more advisable for the proposed methodology. Fourth, we incorporate the quantile layer into AutoEncoder to build quantile fusion-based AutoEncoder that achieves lower reconstruction error. We performed rigorous studies and evaluations on eight open UCI datasets using RMSE and MAE metrics. The experimental results substantiate its significance of accuracy and robustness. Our methodology is generic and can be applied to general forecasting problems such as time-series modeling and spatio-temporal prediction.},
  archive      = {J_NEUCOM},
  author       = {Bin Wang and Jie Lu and Tianrui Li and Zheng Yan and Guangquan Zhang},
  doi          = {10.1016/j.neucom.2022.02.029},
  journal      = {Neurocomputing},
  pages        = {286-298},
  shortjournal = {Neurocomputing},
  title        = {A quantile fusion methodology for deep forecasting},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Stability analysis of delayed neural network based on the
convex method and the non-convex method. <em>NEUCOM</em>, <em>483</em>,
275–285. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the asymptotic stability of neural network with time-varying delay. A new Lyapunov–Krasovskii functional (LKF) is constructed with some non-integral delay-product functional terms. Some parameter matrices in the LKF are not required to be positive definite. The convex method and the non-convex method are proposed to deal with the square of the time-varying delay appearing in the derivative of the LKF, respectively. Two less conservative delay-dependent stability criteria in the form of linear matrix inequalities (LMIs) are established. Finally, two widely used numerical examples are given to illustrate the validity and superiority of the obtained stability criteria.},
  archive      = {J_NEUCOM},
  author       = {Xiaofang Hu and Xinge Liu and Meilan Tang},
  doi          = {10.1016/j.neucom.2022.02.015},
  journal      = {Neurocomputing},
  pages        = {275-285},
  shortjournal = {Neurocomputing},
  title        = {Stability analysis of delayed neural network based on the convex method and the non-convex method},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). JAC-net: Joint learning with adaptive exploration and
concise attention for unsupervised domain adaptive person
re-identification. <em>NEUCOM</em>, <em>483</em>, 262–274. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing unsupervised domain adaptive (UDA) methods of person re-identification (re-ID) often use clustering to generate and optimize pseudo-labels. However, the pseudo-labels generated in this way contain noise, which is gradually amplified during the iterative process, leading to a lower recognition accuracy than for supervised methods. This paper proposes Joint Learning with Adaptive Exploration and Concise Attention Network (JAC-Net), which uses two identical networks to optimize person re-ID in an unlabeled target domain. Based on the pseudo-labels generated by clustering, JAC-Net optimizes the training network by combining a joint learning network (JLN) with a concise attention module (CAM). Inspired by the teacher-student network, JLN uses two identical networks to share knowledge for network learning, and also applies adaptive exploration learning strategies to automatically assign weights to the two identical networks and to balance the impact of the knowledge from the two networks. As a parameter-free attention module, a CAM is added to the feature map extracted in specific layers of ResNet50 without changing the high-order semantic features . Extensive experiments on the Market-1501, DukeMTMC-reID and MSMT17 datasets show that JAC-Net achieves well performance and reaches a similar level of supervised learning.},
  archive      = {J_NEUCOM},
  author       = {Yingchun Guo and Fang Feng and Xiaoke Hao and Xi Chen},
  doi          = {10.1016/j.neucom.2022.02.010},
  journal      = {Neurocomputing},
  pages        = {262-274},
  shortjournal = {Neurocomputing},
  title        = {JAC-net: Joint learning with adaptive exploration and concise attention for unsupervised domain adaptive person re-identification},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint semantics and data-driven path representation for
knowledge graph reasoning. <em>NEUCOM</em>, <em>483</em>, 249–261. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reasoning on a large-scale knowledge graph (KG) is of great importance for KG applications like question answering. The path-based reasoning models can leverage much information over paths other than pure triples in the KG but face several challenges. Firstly, all the existing path-based methods are data-driven, lacking explainability, namely how the path representations and the reasoning results are obtained with human-understandable explanations. Besides, some approaches either consider only relational paths or ignore the heterogeneity between entities and relations both in paths, which cannot capture the rich semantics of paths well. To address the above challenges, in this work, we propose a novel joint semantics and data-driven path representation that balances explainability and generalization in the framework of KG embedding. Specifically, we inject horn rules to obtain the condensed paths through a transparent and explainable path composition procedure. The entity converter is designed to transform entities along paths into the representations in the semantic level similar to relations for reducing the heterogeneity between entities and relations. The KGs, both with and without type information, are considered. Our proposed model is evaluated on two classes of tasks: link prediction and path query answering. The experimental results show that our model obtains significant performance gains over several state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Guanglin Niu and Bo Li and Yongfei Zhang and Yongpan Sheng and Chuan Shi and Jingyang Li and Shiliang Pu},
  doi          = {10.1016/j.neucom.2022.02.011},
  journal      = {Neurocomputing},
  pages        = {249-261},
  shortjournal = {Neurocomputing},
  title        = {Joint semantics and data-driven path representation for knowledge graph reasoning},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Foreground-guided textural-focused person re-identification.
<em>NEUCOM</em>, <em>483</em>, 235–248. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (Re-ID) is challenging in computer vision. It is crucial to strengthen discriminative features and suppress irrelevant ones for high-performance. Existing Re-ID approaches have won significant progress by attention mechanisms or introducing key-point/part priors. However, these methods suffer the high cost of building models. Besides, potential feature false alarm problems may happen due to background interference and inaccurate priors. Moreover, they usually ignore the degradation of texture clues which are identity sensitive. In this paper, we propose the Foreground-Guided Textural-Focused Network (FTN) to address these problems. Specifically, our FTN is an end-to-end Re-ID framework, which consists of a Semantic Encoder (S-Enc), a Compact Foreground Attention (CFA) module, and a Texture-Focused Decoder (TF-Dec). First, based on CFA and 2D Gaussian kernel , a coarse foreground-guided learning strategy is developed to suppress the feature false alarms at the source. Its core idea lies in constructing foreground guidance, which forces S-Enc to pay more attention to person instance-level features. Second, the TF-Dec is designed as a lightweight reconstruction task. It is trained via a novel gradient loss, and further forces S-Enc to maintain texture-wise details. Our method is computationally efficient as TF-Dec is abandoned in the inference phase. Extensive experiments are conducted on three large-scale Re-ID datasets Market1501, CUHK03, MSMT17, and two other occluded datasets. The results indicate that FTN achieves superior performance against the state-of-the-art methods, e.g., Rank-1 of 96.2\% and 59.0\% on Market1501 and Occluded-Duke respectively.},
  archive      = {J_NEUCOM},
  author       = {Donghaisheng Liu and Shoudong Han and Yang Chen and Chenfei Xia and Jun Zhao},
  doi          = {10.1016/j.neucom.2022.02.014},
  journal      = {Neurocomputing},
  pages        = {235-248},
  shortjournal = {Neurocomputing},
  title        = {Foreground-guided textural-focused person re-identification},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Privacy-preserving and verifiable deep learning inference
based on secret sharing. <em>NEUCOM</em>, <em>483</em>, 221–234. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning inference, providing the model utilization of deep learning, is usually deployed as a cloud-based framework for the resource-constrained client. However, the existing cloud-based frameworks suffer from severe information leakage or lead to significant increase of communication cost. In this work, we address the problem of privacy-preserving deep learning inference in a way that both the privacy of the input data and the model parameters can be protected with low communication and computational costs. Additionally, the user can verify the correctness of results with small overhead, which is very important for critical application. Specifically, by designing secure sub-protocols, we introduce a new layer to collaboratively perform the secure computations involved in the inference. With the cooperation of the secret sharing, we inject the verifiable data into the input, enabling us to check the correctness of the returned inference results. Theoretical analyses and extensive experimental results over MNIST and CIFAR10 datasets are provided to validate the superiority of our proposed privacy-preserving and verifiable deep learning inference (PVDLI) framework.},
  archive      = {J_NEUCOM},
  author       = {Jia Duan and Jiantao Zhou and Yuanman Li and Caishi Huang},
  doi          = {10.1016/j.neucom.2022.01.061},
  journal      = {Neurocomputing},
  pages        = {221-234},
  shortjournal = {Neurocomputing},
  title        = {Privacy-preserving and verifiable deep learning inference based on secret sharing},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Modeling context appearance changes for person
re-identification via IPES-GCN. <em>NEUCOM</em>, <em>483</em>, 210–220.
(<a href="https://doi.org/10.1016/j.neucom.2022.02.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the previous person re-identification works focus on learning discriminative features for individuals, and retrieve a query person only based on pair-wise individual feature similarities, ignoring context relationships among gallery images. Consequently, it is hard to re-identify a query person when large appearance changes occur. To address this problem, we propose the IPES-GCN model to exploit context relationships across gallery images. In the IPES-GCN, we first construct an Individual Pivot Expansion Subgraph (IPES) to enrich the context representation of each individual. By taking high-order nearest neighbors of each individual into account, we can model more positive appearance changes into the representation. Then GCN is employed to explicitly model various appearance changes contained in the IPES into a graph embedding for each enriched individual. Finally, the graph embeddings are utilized to re-rank the gallery images. Experiments on the Market1501, DukeMTMC and MSMT17 datasets show that the proposed method has strong generalization and can yield favorable results to the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Chuang Liu and Hua Yang and Ji Zhu and Qin Zhou and Shibao Zheng},
  doi          = {10.1016/j.neucom.2022.02.001},
  journal      = {Neurocomputing},
  pages        = {210-220},
  shortjournal = {Neurocomputing},
  title        = {Modeling context appearance changes for person re-identification via IPES-GCN},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). L0 structure-prior assisted blur-intensity aware efficient
video deblurring. <em>NEUCOM</em>, <em>483</em>, 195–209. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a L 0 L0 Structure-Prior Assisted Blur-intensity Aware method for efficient video deblurring. To efficiently generate sharp frames, we utilize separate streams to estimate content and structure information, both two streams effectively extract features under dedicated constraints using light-weight architecture. In content estimation, to better extract features from frames with non-uniform blur distribution, we introduce a blur-intensity detection module to generate a blur-intensity mask. The mask reflects region-wise blur degrees similar to an attention map and provides preliminary information to the content decoder. For structure estimation, to generate frames with less structural distortion, we utilize L 0 L0 smoothed frames as supervision to estimate structure information. A pyramid module with a deformable convolution layer in the last scale is designed in this stream. The estimated content and structure information are then merged with the frame synthesis module to generate perceptually favorable frames. Experiments demonstrate that our method could achieve favorable results on both synthetic and real-world datasets in terms of objective metrics and perceptual quality , with fewer input frames and less time-consuming.},
  archive      = {J_NEUCOM},
  author       = {Chen Li and Li Song and Rong Xie and Wenjun Zhang},
  doi          = {10.1016/j.neucom.2022.02.013},
  journal      = {Neurocomputing},
  pages        = {195-209},
  shortjournal = {Neurocomputing},
  title        = {L0 structure-prior assisted blur-intensity aware efficient video deblurring},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Triple-discriminator generative adversarial network for
infrared and visible image fusion. <em>NEUCOM</em>, <em>483</em>,
183–194. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We aim to address the challenging task of infrared and visible image fusion. The existed fusion methods cannot achieve the balance of clear boundaries and rich details. In this paper, we propose a novel fusion model using a triple-discriminator generative adversarial network, which can achieve the balance. The difference image obtained by image subtraction can highlight the difference information, extract image details, and obtain the target outlines in some scenes. Therefore, besides the visible discriminator and infrared discriminator, a new difference image discriminator is added to retain the difference between infrared and visible images, thereby improving the contrast of infrared targets and keeping the texture details in visible images. Multi-level features extracted by the discriminators are used for information measurement, and as a result, deriving perceptual fusion weights for adaptive fusion. SSIM loss function and target edge-enhancement loss are also introduced to improve the quality of the fused image. Compared with existing state-of-the-art fusion methods on public datasets, it is demonstrated that our model has a better performance on quantitative metrics and qualitative effects.},
  archive      = {J_NEUCOM},
  author       = {Anyang Song and Huixian Duan and Haodong Pei and Lei Ding},
  doi          = {10.1016/j.neucom.2022.02.025},
  journal      = {Neurocomputing},
  pages        = {183-194},
  shortjournal = {Neurocomputing},
  title        = {Triple-discriminator generative adversarial network for infrared and visible image fusion},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A weight initialization method based on neural network with
asymmetric activation function. <em>NEUCOM</em>, <em>483</em>, 171–182.
(<a href="https://doi.org/10.1016/j.neucom.2022.01.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weight initialization of neural networks has an important influence on the learning process, and the selection of initial weights is related to the activation interval of the activation function . It is proposed that an improved and extended weight initialization method for neural network with asymmetric activation function as an extension of the linear interval tolerance method (LIT), called ‘GLIT’ (generalized LIT), which is more suitable for higher-dimensional inputs. The purpose is to expand the selection range of the activation function so that the input falls in the unsaturated region, so as to improve the performance of the network. Then, a tolerance solution theorem based upon neural network system is given and proved. Furthermore, the algorithm is given about determining the initial weight interval. The validity of the theorem and algorithm is verified by numerical experiments. The input could fall into any preset interval in the sense of probability under the GLIT method. In another sense, the GLIT method could provide a theoretical basis for the further study of neural networks.},
  archive      = {J_NEUCOM},
  author       = {Jingjing Liu and Yefeng Liu and Qichun Zhang},
  doi          = {10.1016/j.neucom.2022.01.088},
  journal      = {Neurocomputing},
  pages        = {171-182},
  shortjournal = {Neurocomputing},
  title        = {A weight initialization method based on neural network with asymmetric activation function},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SiamSMDFFF: Siamese network tracker based on
shallow-middle-deep three-level feature fusion and clustering-based
adaptive rectangular window filtering. <em>NEUCOM</em>, <em>483</em>,
160–170. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of machine vision, target trackers based on Siamese networks have demonstrated excellent performance in balancing speed and accuracy compared to traditional methods. Traditional trackers usually use only the deep features extracted from the last convolutional neural network (CNN) layer, which contain semantic information, to complete the similarity matching. In addition, a cosine window is usually used to filter the score map, which leads to the limited suppression effect of the tracker on the interference of the objects similar to the target and the poor robustness of the tracker. In this paper, a Siamese network tracker named SiamSMDFFF, which combines shallow-middle-deep feature fusion with a clustering-based adaptive rectangular window filter, is proposed. SiamSMDFFF uses the features to fuse at the feature level to obtain the complementary feature maps and then uses the score maps calculated from the complementary feature maps via correlation to fuse at the score level and obtain the final score maps. Then, the peak points in the score map are used as the initial clustering centers to complete the clustering, and the distance between the clustering center and the farthest clustering point is calculated. Finally, the distance is used to control the change in the size of the rectangular window to filter the score map in order to overcome the negative impact of the similar targets interfering in the tracking process and improve the robustness of the tracker. The experimental results demonstrate that SiamSMDFFF is significantly improved in several aspects compared to the conventional tracker.},
  archive      = {J_NEUCOM},
  author       = {Yuan Luo and Hang Xiao and Junxiong Ou and Xu Chen},
  doi          = {10.1016/j.neucom.2022.02.027},
  journal      = {Neurocomputing},
  pages        = {160-170},
  shortjournal = {Neurocomputing},
  title        = {SiamSMDFFF: Siamese network tracker based on shallow-middle-deep three-level feature fusion and clustering-based adaptive rectangular window filtering},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Image-text bidirectional learning network based cross-modal
retrieval. <em>NEUCOM</em>, <em>483</em>, 148–159. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of cross-modal retrieval has attracted significant attention in the cross-media retrieval community. One key challenge of cross-modal retrieval is to eliminate the heterogeneous gap between different patterns. The existing numerous cross-modal retrieval approaches tend to jointly construct a common subspace, while these methods fail to consider mutual influence between modalities sufficiently during the whole training process. In this paper, we propose a novel image-text B idirectional L earning N etwork (BLN) based cross-modal retrieval method . The method constructs a common representation space and directly measures the similarity of heterogeneous data . More specifically, a multi-layer supervision network is proposed to learn the cross-modal relevance of the generated representations. Moreover, a bidirectional crisscross loss function is proposed to preserve the modal invariance with the bidirectional learning strategy in the common representation space. The loss functions of discriminant consistency and the bidirectional crisscross loss are integrated into an objective function which aims to minimize the intra-class distance and maximize the inter-class distance. Comprehensive experimental results on four widely-used databases show that the proposed method is effective and superior to the existing cross-modal retrieval methods.},
  archive      = {J_NEUCOM},
  author       = {Zhuoyi Li and Huibin Lu and Hao Fu and Guanghua Gu},
  doi          = {10.1016/j.neucom.2022.02.007},
  journal      = {Neurocomputing},
  pages        = {148-159},
  shortjournal = {Neurocomputing},
  title        = {Image-text bidirectional learning network based cross-modal retrieval},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A semi-supervised autoencoder for autism disease diagnosis.
<em>NEUCOM</em>, <em>483</em>, 140–147. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) is a neurological developmental disorder that typically causes impaired communication and compromised social interactions . The current clinical assessment of ASD is typically based on behavioral observations and lack of the understanding of the neurological mechanism and the progression of the brain development. The functional magnetic resonance imaging (fMRI) data is one of the commonly-used imaging modalities for understanding human brain mechanisms as well as the diagnosis and treatment of brain disorders such as ASD. In this paper, we proposed a semi-supervised autoencoder (AE) for autism diagnosis using functional connectivity (FC) pattern obtained from resting-state fMRI. An unsupervised autoencoder in combination with the supervised classification networks enables semi-supervised learning in which an autoencoder for learning hidden features and a neural network based classifier are trained together. Compared to train the autoencoder and classifier in separate phases, the proposed semi-supervised learning essentially helps tune the latent feature representation learning towards the goal of classification, and thus leads to improvements in autism diagnosis performance. The proposed model is evaluated by using cross-validation methods on ABIDE I database. Experimental results demonstrate that the proposed model achieves improved classification performance, and that the proposed semi-supervised learning framework can integrate unlabelled fMRI data for better feature learning and improved classification accuracy .},
  archive      = {J_NEUCOM},
  author       = {Wutao Yin and Longhai Li and Fang-Xiang Wu},
  doi          = {10.1016/j.neucom.2022.02.017},
  journal      = {Neurocomputing},
  pages        = {140-147},
  shortjournal = {Neurocomputing},
  title        = {A semi-supervised autoencoder for autism disease diagnosis},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved feature pyramid network for object detection.
<em>NEUCOM</em>, <em>483</em>, 127–139. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is one of the most important and challenging problems in the field of computer vision. In the current mainstream detection approaches, especially in the architectures of feature pyramid network (FPNs), feature fusion is a basic and essential method for all detectors. However, feature fusion does not fully consider the characteristics of the detection task for most detectors. To obtain suitable features for the detection task, in this paper, we propose two fusion methods: (1) For feature extraction, we propose an improved feature pyramid network (ImFPN) for superior representations. The most essential difference from FPNs is that the ImFPN includes a similarity-based fusion module, which can fuse different features to adapt to varying sizes of instances. (2) For specified tasks, since classification and regression tasks have different considerations in the same region, we build a new fusion mechanism between the dense and sparse heads in any two-stage detector based on an improved region proposal network (ImRPN). After adding these two modified architectures to Faster R-CNN with ResNet-101, the average precision (AP) improves from 39.7 to 41.4 on COCO test-dev . In addition, extensive experiments show the effectiveness of our methods on various models and datasets.},
  archive      = {J_NEUCOM},
  author       = {Linxiang Zhu and Feifei Lee and Jiawei Cai and Hongliu Yu and Qiu Chen},
  doi          = {10.1016/j.neucom.2022.02.016},
  journal      = {Neurocomputing},
  pages        = {127-139},
  shortjournal = {Neurocomputing},
  title        = {An improved feature pyramid network for object detection},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Momentum source-proxy guided initialization for unsupervised
domain adaptive person re-identification. <em>NEUCOM</em>, <em>483</em>,
116–126. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptive person re-identification (UDA Re-ID), aiming to adapt the model trained from source domain to target domain, is especially challenging due to the non-overlapping identities between the two Re-ID domains. State-of-the-art UDA Re-ID methods optimize the model pre-trained on source domain with pseudo labels generated by clustering algorithms on the target domain. The drawback lies in that the initial parameters are learned only from labeled source domain, neglecting the target domain information that can be easily obtained from unlabeled data . In order to better fit the target distribution while preventing from over-fitting to the source one, we propose a novel momentum source-proxy guided initialization (MSPGI) approach to integrate information from unlabeled data into the pre-training process. Specifically, we assign soft labels to unlabeled data according to similarity to the feature proxies of the source domain, based on the finding that different Re-ID datasets share commonalities. In addition, we instantiate the pretext task in unsupervised pre-training as constraining the predicted soft label to be consistent with the one calculated from the temporally-averaged parameters of the model. Experiments are conducted on multiple downstream approaches, pushing forward the state-of-the-art results by an impressive margin on Market-1501 and DukeMTMC-reID. By making use of unlabeled data, MSPGI further improves the performance of a fully supervised network.},
  archive      = {J_NEUCOM},
  author       = {Jiali Xi and Qin Zhou and Xinzhe Li and Shibao Zheng},
  doi          = {10.1016/j.neucom.2022.01.013},
  journal      = {Neurocomputing},
  pages        = {116-126},
  shortjournal = {Neurocomputing},
  title        = {Momentum source-proxy guided initialization for unsupervised domain adaptive person re-identification},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Infer-AVAE: An attribute inference model based on
adversarial variational autoencoder. <em>NEUCOM</em>, <em>483</em>,
105–115. (<a
href="https://doi.org/10.1016/j.neucom.2022.02.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User attributes, such as gender and education, face severe incompleteness in social networks. Attribute inference aims to infer users’ missing attribute labels based on observed data to make this valuable data usable for downstream tasks like user profiling and personalized recommendation. Recently, variational autoencoder (VAE), an end-to-end deep generative model , has shown promising performance by handling the problem in a semi-supervised way. However, VAEs can easily suffer from over-fitting and over-smoothing when applied to attribute inference. Specifically, VAE implemented with multi-layer perceptron (MLP) can only reconstruct input data but fail to infer missing parts. While using the trending graph neural networks (GNNs) as encoder has the problem that GNNs aggregate redundant information from the neighborhood and generate indistinguishable user representations, known as over-smoothing. In this paper, we propose an attribute Infer ence model based on A dversarial VAE (Infer-AVAE) to cope with these issues. Specifically, to overcome over-smoothing, Infer-AVAE unifies MLP and GNNs in the encoder to learn positive and negative latent representations respectively. Meanwhile, an adversarial network is trained to distinguish the two representations, and GNNs are trained to aggregate less noise for more robust representations through adversarial training . Finally, to relieve over-fitting, mutual information constraint is introduced as a regularizer for the decoder to make better use of auxiliary information in representations and generate outputs not limited by observations. We evaluate our model on four real-world social network datasets, and experimental results demonstrate that our model averagely outperforms baselines by 7.0\%\% in accuracy.},
  archive      = {J_NEUCOM},
  author       = {Yadong Zhou and Zhihao Ding and Xiaoming Liu and Chao Shen and Lingling Tong and Xiaohong Guan},
  doi          = {10.1016/j.neucom.2022.02.006},
  journal      = {Neurocomputing},
  pages        = {105-115},
  shortjournal = {Neurocomputing},
  title        = {Infer-AVAE: An attribute inference model based on adversarial variational autoencoder},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep hashing with self-supervised asymmetric semantic
excavation and margin-scalable constraint. <em>NEUCOM</em>,
<em>483</em>, 87–104. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its effectivity and efficiency, deep hashing approaches are widely used for large-scale visual search. However, it is still challenging to produce compact and discriminative hash codes for images associated with multiple semantics for two main reasons, 1) similarity constraints designed in most of the existing methods are based upon an oversimplified similarity assignment(i.e., 0 for instance pairs sharing no label, 1 for instance pairs sharing at least 1 label), 2) the exploration in multi-semantic relevance are insufficient or even neglected in many of the existing methods. These problems significantly limit the discrimination of generated hash codes. In this paper, we propose a novel Deep Hashing with Self-Supervised Asymmetric Semantic Excavation and Margin-Scalable Constraint(SADH) approach to cope with these problems. SADH implements a self-supervised network to sufficiently preserve semantic information in a semantic feature dictionary and a semantic code dictionary for the semantics of the given dataset, which efficiently and precisely guides a feature learning network to preserve multi-label semantic information using an asymmetric learning strategy. By further exploiting semantic dictionaries, a new margin-scalable constraint is employed for both precise similarity searching and robust hash code generation. Extensive empirical research on four popular benchmarks validates the proposed method and shows it outperforms several state-of-the-art approaches. The source codes URL of our SADH is: http://github.com/SWU-CS-MediaLab/SADH .},
  archive      = {J_NEUCOM},
  author       = {Zhengyang Yu and Song Wu and Zhihao Dou and Erwin M. Bakker},
  doi          = {10.1016/j.neucom.2022.01.082},
  journal      = {Neurocomputing},
  pages        = {87-104},
  shortjournal = {Neurocomputing},
  title        = {Deep hashing with self-supervised asymmetric semantic excavation and margin-scalable constraint},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Query-aware video encoder for video moment retrieval.
<em>NEUCOM</em>, <em>483</em>, 72–86. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an untrimmed video and a sentence query, video moment retrieval is to locate a target video moment that semantically corresponds to the query. It is a challenging task that requires a joint understanding of natural language queries and video contents. However, video contains complex contents, including query-related and query-irrelevant contents, which brings difficulty for the joint understanding. To this end, we propose a query-aware video encoder to capture the query-related visual contents. Specifically, we design a query-guided block following each encoder layer to recalibrate the encoded visual features according to the query semantics. The core of query-guided block is a channel-level attention gating mechanism, which could selectively emphasize query-related visual contents and suppress query-irrelevant ones. Besides, to fully match with different levels of contents in videos, we learn hierarchical and structural query clues to guide the visual content capturing. We disentangle sentence query into a semantics graph and capture the local contexts inside the graph via a trilinear model as query clues. Extensive experiments on Charades-STA and TACoS datasets demonstrate the effectiveness of our approach, and we achieve the state-of-the-art on the two datasets.},
  archive      = {J_NEUCOM},
  author       = {Jiachang Hao and Haifeng Sun and Pengfei Ren and Jingyu Wang and Qi Qi and Jianxin Liao},
  doi          = {10.1016/j.neucom.2022.01.085},
  journal      = {Neurocomputing},
  pages        = {72-86},
  shortjournal = {Neurocomputing},
  title        = {Query-aware video encoder for video moment retrieval},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explainable AI techniques with application to NBA gameplay
prediction. <em>NEUCOM</em>, <em>483</em>, 59–71. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an explainable artificial intelligence (AI) technique is employed to analyze the match style and gameplay of the national basketball association (NBA). A descriptive analysis on the evolution of the NBA gameplay is conducted by using clustering and principal component analysis. Supervised-learning based AI models (including the random forest and the feed-forward neural network) are applied to produce accurate predictions on NBA outcomes at a season-by-season and a month-by-month basis. To evaluate the interpretability of the established AI models, an explainable AI algorithm is utilized to deduce and assess the precise reasoning behind the model prediction based on the local interpretable model-agnostic explanation method. To illustrate its application potential, the method is applied to the open-source NBA data from 1980 to 2019. Experimental results demonstrate the effectiveness of the introduced explainable AI algorithm on predicting NBA outcomes with interpretation.},
  archive      = {J_NEUCOM},
  author       = {Yuanchen Wang and Weibo Liu and Xiaohui Liu},
  doi          = {10.1016/j.neucom.2022.01.098},
  journal      = {Neurocomputing},
  pages        = {59-71},
  shortjournal = {Neurocomputing},
  title        = {Explainable AI techniques with application to NBA gameplay prediction},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary deep learning: A survey. <em>NEUCOM</em>,
<em>483</em>, 42–58. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an advanced artificial intelligence technique for solving learning problems, deep learning (DL) has achieved great success in many real-world applications and attracted increasing attention in recent years. However, as the performance of DL depends on many factors such as the architecture and hyperparameters, how to optimize DL has become a hot research topic in the field of DL and artificial intelligence . Evolutionary computation (EC), including evolutionary algorithm and swarm intelligence , is a kind of efficient and intelligent optimization methodology inspired by the mechanisms of biological evolution and behaviors of swarm organisms. Therefore, a large number of researches have proposed EC algorithms to optimize DL, so called evolutionary deep learning (EDL), which have obtained promising results. Given the great progress and rapid development of EDL in recent years, it is quite necessary to review these developments in order to summarize previous research experiences and knowledge, as well as provide references to benefit the development of more researches and applications. For this aim, this paper categorizes existing works in a two-level taxonomy. The higher level includes four categories based on when the EC can be adopted in optimizing the DL, which are the four procedures of the whole DL lifetime, including data processing, model search, model training, and model evaluation and utilization . In the lower level, related works in each category are further classified according to the functionality and the aim of using EC in the corresponding DL procedure, i.e., why using EC in this DL procedure. As a result, the taxonomy can clearly show how an EC algorithm can be used to optimize and improve DL. Moreover, this survey also discusses the potential research directions to provide the prospect of EDL in the future.},
  archive      = {J_NEUCOM},
  author       = {Zhi-Hui Zhan and Jian-Yu Li and Jun Zhang},
  doi          = {10.1016/j.neucom.2022.01.099},
  journal      = {Neurocomputing},
  pages        = {42-58},
  shortjournal = {Neurocomputing},
  title        = {Evolutionary deep learning: A survey},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A differentially private matrix factorization based on
vector perturbation for recommender system. <em>NEUCOM</em>,
<em>483</em>, 32–41. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix factorization (MF) techniques have yielded immense success in recommender systems (RSs). Since a huge amount of user data is collected and used in RS, it raises concerns about data privacy. As a strict privacy protection framework, many efforts attempt to apply Differential Privacy (DP) to MF. However, there are still some challenges or problems in designing MF with privacy preservation, such as error accumulation in the multiple iterations of MF, introduction of unnecessary noises, and difficult sensitivity analysis. To overcome these problems, we devise a vector perturbation-based differentially private matrix factorization (VP-DPMF). Our scheme can prevent error accumulation by perturbing the objective function of MF rather than its factorization process or results. It also addresses the difficulty of analyzing sensitivity by exploiting the polynomial representation of the objective function. Furthermore, our scheme can reduce unnecessary noises by controlling the perturbation within the vector term of the polynomial, and can preserve the convexity property of the original function. Theoretical analysis demonstrates that our scheme can achieve good performance in a large-scale recommender system. Experimental results on some benchmark datasets show that the proposed scheme can provide both rigid privacy guarantee and satisfactory recommendation quality.},
  archive      = {J_NEUCOM},
  author       = {Xun Ran and Yong Wang and Leo Yu Zhang and Jun Ma},
  doi          = {10.1016/j.neucom.2022.01.079},
  journal      = {Neurocomputing},
  pages        = {32-41},
  shortjournal = {Neurocomputing},
  title        = {A differentially private matrix factorization based on vector perturbation for recommender system},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tensor neural networks via circulant convolution.
<em>NEUCOM</em>, <em>483</em>, 22–31. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enough computation and storage resources have made Convolutional Neural Networks (CNNs) prosperous in many fields, but it is still challenging to deploy these models on mobile or embedded devices. Designing effective and efficient convolution modules can vastly reduce the number of parameters and computational complexity of CNNs to favor the deployment. This paper proposes a Circulant Convolution (CC) established on a tensor algebra operator of t-product. Specifically, a feature map can be parameterized by multilinear operation to make the channels positively coupled, and then a more compact parameter space and stronger parameterization capability can be simultaneously obtained. Replacing standard spatial convolution with CC can effectively reduce almost 9 times the number of network parameters and FLOPs , and the impact on accuracy is much smaller than other well-designed convolution modules for lightweight networks. CC can be embedded into existing network architectures as a plug-and-play module, and its topology structure can be easily extended to high-dimensional data. To favor the use of CC in CNNs, a circulant convolution module (CCM), also known as the bottleneck of CC, is also designed by combining CC and pointwise convolution. In further, a lightweight network CCMNet is constructed based on incorporating CC and CCM into an existing lightweight backbone. Extensive experiments on the benchmark dataset CIFAR10/100, ImageNet, Lung-CXR, and MS COCO, demonstrate that our proposed CC could significantly improve the performance of several advanced lightweight networks, and CCMNet is competitive with the start-of-the-art portable neural networks.},
  archive      = {J_NEUCOM},
  author       = {Chang Nie and Huan Wang},
  doi          = {10.1016/j.neucom.2022.01.010},
  journal      = {Neurocomputing},
  pages        = {22-31},
  shortjournal = {Neurocomputing},
  title        = {Tensor neural networks via circulant convolution},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human action recognition by multiple spatial clues network.
<em>NEUCOM</em>, <em>483</em>, 10–21. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action can be recognized in still images since the whole image represents an action with some spatial clues, such as human poses, action-specific parts, and global surroundings. To represent the spatial clues, the recent methods require labor-intensive annotations to locate the human body and objects, which are computationally intensive. To eliminate strong supervision, a Multiple Spatial Clues Network (MSCNet) is proposed to represent the spatial clues with only image-level action label. Neither accurately manual annotated bounding boxes nor extra labeled datasets are required as additional supervision. First, the proposed MSCNet exploits spatial-attention module to generate spatial attention regions, and detects the spatial clues with minimal supervision. Then, spatial clues exploitation is proposed to utilize the learned spatial clues with three modules: the context module, body + context module and body + semantics module. Experiments on three benchmark datasets demonstrate the effectiveness of the proposed MSCNet.},
  archive      = {J_NEUCOM},
  author       = {Xiangtao Zheng and Tengfei Gong and Xiaoqiang Lu and Xuelong Li},
  doi          = {10.1016/j.neucom.2022.01.091},
  journal      = {Neurocomputing},
  pages        = {10-21},
  shortjournal = {Neurocomputing},
  title        = {Human action recognition by multiple spatial clues network},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust cooperative output regulation of linear uncertain
multi-agent systems by distributed event-triggered dynamic feedback
control. <em>NEUCOM</em>, <em>483</em>, 1–9. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, distributed state and output feedback control law based on the dynamic event-triggered mechanism are proposed to solve the robust cooperative output regulation problem for a class of general linear uncertain multi-agent systems (MASs) subject to external disturbances. The discrete-time control law proposed for each agent is equivalent to a discrete one and thus directly implementable in the digital platform . Our design can handle parametric uncertainties, reject external disturbances and track a dynamic leader while excluding the Zeno phenomenon by providing the existence of a lower bound for inter-event times of each agent, the efficiency of which is illustrated by a numerical example.},
  archive      = {J_NEUCOM},
  author       = {Dong Liang and Yi Dong},
  doi          = {10.1016/j.neucom.2022.01.092},
  journal      = {Neurocomputing},
  pages        = {1-9},
  shortjournal = {Neurocomputing},
  title        = {Robust cooperative output regulation of linear uncertain multi-agent systems by distributed event-triggered dynamic feedback control},
  volume       = {483},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A decision support model for handling customer orders in
business chain. <em>NEUCOM</em>, <em>482</em>, 298–309. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the elements of the modern trade and services market is a business chain solution (chain store/retail chain). An example of a business chain is, e.g., a restaurant chain, where each restaurant in the chain has the same decor, organization, menu, and delivery method. Although such solutions have been known for decades, the rapid development of IT technology, the widespread access to the Internet as well as the development of mobile technologies have changed and modernized their formula. Many customers place orders remotely with the option of delivery to their door. This method of ordering and fulfilling orders is becoming more and more popular and ever more common in the recent period due to the pandemic and the resulting restrictions and limitations on the functioning of trade and services. The following key questions arise in relation to customer order processing for chain business managers: How to allocate individual customer orders to selected branches so that the cost of their processing (production and delivery) is the lowest?, How to deliver on time ?, etc. To answer these questions, a decision support model has been developed, which combines routing, allocation and planning problems for restaurant/store chains. Two ways to implement the model have been proposed. The first one uses the methods of mathematical modeling and programming, and the other, which is a proprietary approach that integrates the mechanisms of evolution (specialized representations, repair mechanisms, genetic operators, etc.), uses constraint logic programming and dedicated heuristics. In addition, procedures for constraint handling and presolving have been developed.},
  archive      = {J_NEUCOM},
  author       = {Paweł Sitek and Jarosław Wikarek and Grzegorz Bocewicz and Izabela Nielsen},
  doi          = {10.1016/j.neucom.2021.06.099},
  journal      = {Neurocomputing},
  pages        = {298-309},
  shortjournal = {Neurocomputing},
  title        = {A decision support model for handling customer orders in business chain},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Double sparse low rank decomposition for irregular printed
fabric defect detection. <em>NEUCOM</em>, <em>482</em>, 287–297. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a double sparse low-rank decomposition method is proposed to defect detection for complex irregular printed fabrics. Firstly, a low rank decomposition model with double sparsity is established by taking the sparse components as the printing template prior and the difference between the defective printed fabric graph and the template fabric graph as the defect prior. Secondly, the decomposition is guided by printing prior and defect for the double sparse low rank decomposition model to obtain the saliency map of defects. Furthermore, the defect map is obtained by binarising the defect’s saliency map using the optimal threshold segmentation. Finally, the simulation results are compared with the four existing methods. The results show that the proposed algorithm can effectively detect defects in three types of irregular printed fabrics, such as small-size print, medium-size print, and complex-distribution print. The valid positive rate is 89.29\%, the false positive rate is 0.85\%, and the positive predictive value is 86.21\%. Comparison results show that the proposed algorithm retains the shape details of the defect better than the other four algorithms, and the detection time is 12.49\% less than the current optimal PN-RPCA algorithm.},
  archive      = {J_NEUCOM},
  author       = {Andong Liu and Enjun Yang and Jinhui Wu and You Teng and Li Yu},
  doi          = {10.1016/j.neucom.2021.11.078},
  journal      = {Neurocomputing},
  pages        = {287-297},
  shortjournal = {Neurocomputing},
  title        = {Double sparse low rank decomposition for irregular printed fabric defect detection},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed generalized nash equilibrium seeking: A singular
perturbation-based approach. <em>NEUCOM</em>, <em>482</em>, 278–286. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a distributed optimization algorithm is proposed for aggregative game with coupled constraints. Based on the singular perturbation system, the generalized Nash equilibrium is sought by a group of agents. By employing the average consensus method in the fast manifold, the aggregates in the object function can be estimated via simple information exchanges, as well as the aggregate of dual variables, which provides necessary information for the fully distributed algorithm design. Moreover, the exponential convergence of the proposed algorithm is explored based on the Lyapunov method, the properties of the variational inequality and the characteristic of the singular perturbation system. Application to the resource competition problem in smart grid verifies the effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Wen-Ting Lin and Guo Chen and Chaojie Li and Tingwen Huang},
  doi          = {10.1016/j.neucom.2021.11.073},
  journal      = {Neurocomputing},
  pages        = {278-286},
  shortjournal = {Neurocomputing},
  title        = {Distributed generalized nash equilibrium seeking: A singular perturbation-based approach},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An accurate box localization method based on rotated-RPN
with weighted edge attention for bin picking. <em>NEUCOM</em>,
<em>482</em>, 264–277. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Box localization that aims at localizing the position of the box plays a significant role in the application of bin picking. Accurate box localization is still a challenging problem. The boxes are stacked tightly with all kinds of angles, so that the border is very difficult to accurately locate. Moreover, the feature extraction used in existing methods are easily affected by the background, the shape, the size, the angle of box and the illumination. In this paper, we propose a novel Rotated Region Proposal Network (Rotated-RPN) wi attention to localize boxes in bin picking, named R-DFPN-WEA. It can generate inclined proposals with box orientation angle information and accurately localize the border of box. Moreover, we use point cloud information to extract the foreground information, getting rid of the background interference. Finally, the rotated masks with weighted edge attention are designed to enhance edges, which further improves the accuracy of box localization. We collect box images through depth cameras and preprocess the images, then create the box database, BoxLoc. Extensive experiments show that our proposed method, R-DFPN-WEA, achieves considerable improvement over the state-of-the-art approaches on our BoxLoc Datasets.},
  archive      = {J_NEUCOM},
  author       = {Fengqin Yao and Shengke Wang and Rui Li and Long Chen and Feng Gao and Junyu Dong},
  doi          = {10.1016/j.neucom.2021.11.070},
  journal      = {Neurocomputing},
  pages        = {264-277},
  shortjournal = {Neurocomputing},
  title        = {An accurate box localization method based on rotated-RPN with weighted edge attention for bin picking},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quasi-synchronization of heterogeneous lur’e networks with
uncertain parameters and impulsive effect. <em>NEUCOM</em>,
<em>482</em>, 252–263. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The target of this paper is studying the problem of quasi-synchronization of heterogeneous Lur’e networks with uncertain parameters and impulsive effect. Considering the heterogeneity of Lur’e networks, quasi-synchronization instead of synchronization is discussed. Noting that the uncertain factors exist extensively in reality, uncertain parameters are introduced to the system in this paper. By using the Schur complement lemma, stability theory and the principle of comparison, the sufficient criteria for the heterogeneous networks to achieve quasi-synchronization are derived, and the upper bound of exponential quasi-synchronization errors is calculated. In addition, two corollaries are presented in consideration of homogeneous systems and weighted undirected graphs. Finally, three numerical simulations are given to illustrate the effectiveness of the control protocol and theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Chongfang Jin and Zhengxin Wang and Longyan Gong and Min Xiao and Guo-Ping Jiang},
  doi          = {10.1016/j.neucom.2021.11.057},
  journal      = {Neurocomputing},
  pages        = {252-263},
  shortjournal = {Neurocomputing},
  title        = {Quasi-synchronization of heterogeneous lur’e networks with uncertain parameters and impulsive effect},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CCAFFMNet: Dual-spectral semantic segmentation network with
channel-coordinate attention feature fusion module. <em>NEUCOM</em>,
<em>482</em>, 236–251. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dual-spectral (RGB-thermal) semantic segmentation is a fundamental task for visual perception of autonomous driving in harsh imaging environments (such as darkness, rain, and fog). In recent years, the encoder-decoder dual-spectral semantic segmentation networks have achieved satisfactory results. However, existing networks pay little attention to the feature-fusion strategy of infrared and RGB features at each feature-fusion stage, which limits the performance of semantic segmentation. This study proposes a novel encoder-decoder-based dual-spectral semantic segmentation network. Channel-coordinate attention feature-fusion modules (CCAFFMs) are designed and inserted into each feature-fusion stage to obtain the channel and spatial correlations between infrared and RGB features. Thus, fused feature maps are refined in this way. A down-up-connected decoder with skip connections is designed to restore the resolution of the feature map and ensure that it contains more object details and sharper boundary contours. Furthermore, we manually annotate and augment the RoadScene dataset to construct the RoadScene-seg dataset. In this way, dual-spectral semantic segmentation can be extended to diverse autonomous driving environments. The results of extensive experiments on the MF and RoadScene-seg datasets prove the superiority of the proposed network over state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Shi Yi and Junjie Li and Xi Liu and Xuesong Yuan},
  doi          = {10.1016/j.neucom.2021.11.056},
  journal      = {Neurocomputing},
  pages        = {236-251},
  shortjournal = {Neurocomputing},
  title        = {CCAFFMNet: Dual-spectral semantic segmentation network with channel-coordinate attention feature fusion module},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Investigation of NOx emission under different burner
structures with the optimized combustion model. <em>NEUCOM</em>,
<em>482</em>, 224–235. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As restrictions on NOx (nitrogen oxides) emission become increasingly stringent, many efforts have been put into the development of NOx control strategies. The burner structures of the heating furnace can affect NOx formation by the means of changing the flame temperature. To simulate the turbulent combustion process, the Steady Diffusion Flamelet (SDF) model is used and coupled with detailed mechanisms. It is found that some key flamelet parameters of the SDF model will greatly affect the accuracy of the simulation results. In this study, an efficient optimization procedure is proposed to optimize the combustion model parameters with the surrogate assisted evolutionary algorithm K-RVEA. The surrogate model is used to reduce the computational time of the optimization procedure. Using the optimized model parameters, the temperature field and the concentration fields obtained by the simulations are in good agreement with the measurements. Based on this, the investigation of the impact of the length of pilot wall and jet wall on NOx emission is carried out. The results show that the outlet NOx concentration reaches a local minimal value when the length of pilot wall and jet wall are equal. The length of monotonic increasing interval, where the outlet NOx concentration increases when increasing the length of the pilot wall, is 30 mm. If the length of pilot wall is relatively 30 mm longer than that of the jet wall, the outlet NOx concentration will be further reduced. The proposed optimization procedure and obtained results will benefit the improvement of the burner structure of the heating furnace.},
  archive      = {J_NEUCOM},
  author       = {Qian Yao and Yu Zhang and Xinjie Wang and Zhou Tian and Guihua Hu and Wenli Du},
  doi          = {10.1016/j.neucom.2021.11.051},
  journal      = {Neurocomputing},
  pages        = {224-235},
  shortjournal = {Neurocomputing},
  title        = {Investigation of NOx emission under different burner structures with the optimized combustion model},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural-embedded learning control for fully-actuated flying
platform of aerial manipulation system. <em>NEUCOM</em>, <em>482</em>,
212–223. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the problem of efficient task for the fully-actuated aerial manipulation system, the flight platform control scheme based on neural networks embedding is proposed. We embed the neural networks controllers (NNC) into some base controllers, which are Lyapunov stable for their system. Due to the learning and optimizing capability of NNC, the derivative controllers allow to improve control performance by updating the parameters of NNC under Lyapunov stability condition. The backstepping technology based on the mixture basis functions that approximates unknown system dynamics and the improved disturbance observer is designed for the base controller of platform attitude. And the linear active disturbance rejection controller (LADRC) is utilized as the base controller of platform position. Considering safety and cost, we made some virtual experiments in CoppeliaSim a software which offers high accuracy physical engine. The results of virtual experiments prove that compared with some state-of-the-art technologies the methods proposed are advanced in tracking errors performance due to NNC.},
  archive      = {J_NEUCOM},
  author       = {Le Ma and Yiming Yan and Zhiwei Li and Jie Liu},
  doi          = {10.1016/j.neucom.2021.11.050},
  journal      = {Neurocomputing},
  pages        = {212-223},
  shortjournal = {Neurocomputing},
  title        = {Neural-embedded learning control for fully-actuated flying platform of aerial manipulation system},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Selective ensemble of classifiers trained on selective
samples. <em>NEUCOM</em>, <em>482</em>, 197–211. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifier ensembles are characterized by the high quality of classification, thanks to their generalizing ability. Most existing ensemble algorithms use all learning samples to learn the base classifiers that may negatively impact the ensemble’s diversity. Also, the existing ensemble pruning algorithms often return suboptimal solutions that are biased by the selection criteria. In this work, we present a proposal to alleviate these drawbacks. We employ an instance selection method to query a reduced training set that reduces both the space complexity of the formed ensemble members and the time complexity to classify an instance. Additionally, we propose a guided search-based pruning schema that perfectly explores large-size ensembles and brings on a near-optimal subensemble with less computational requirements in reduced memory space and improved prediction time. We show experimentally how the proposed method could be an alternative to large-size ensembles. We demonstrate how to form less-complex, small-size, and high-accurate ensembles through our proposal. Experiments on 25 datasets show that the proposed method can produce effective ensembles better than Random Forest and baseline classifier pruning methods. Moreover, our proposition is comparable with the Extreme Gradient Boosting Algorithm in terms of accuracy.},
  archive      = {J_NEUCOM},
  author       = {Amgad M. Mohammed and Enrique Onieva and Michał Woźniak},
  doi          = {10.1016/j.neucom.2021.11.045},
  journal      = {Neurocomputing},
  pages        = {197-211},
  shortjournal = {Neurocomputing},
  title        = {Selective ensemble of classifiers trained on selective samples},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EEG fading data classification based on improved manifold
learning with adaptive neighborhood selection. <em>NEUCOM</em>,
<em>482</em>, 186–196. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In electroencephalogram (EEG) signal analysis, data fading problem exists from signal production to collection by brain-computer interface (BCI) device, which can be raised by BCI device deficiency, dynamic network limitation and subject issue. EEG data fading problem changes the distribution of data, which results in the movement of the cluster center and fuzzy class boundary after feature extraction with negative effects in EEG classification results. To decrease the adverse influence of data fading, a novel fading data classification method based on manifold learning and adaptive neighborhood selection is proposed in this paper to mitigate this adverse effect of data fading. In the proposed method, after neighborhood selection according to local linearity, data are mapped into manifold space through local tangent space alignment (LTSA) for dimensionality reduction. The method is carried out on BCI Competition 2008 – Graz data set A of four-class EEG data of motor imagery (MI) experiments. The experimental results are compared with conventional LTSA and indicate that the proposed method effectively improves the classification accuracy of fading data.},
  archive      = {J_NEUCOM},
  author       = {Zitong Wan and Rui Yang and Mengjie Huang and Weibo Liu and Nianyin Zeng},
  doi          = {10.1016/j.neucom.2021.11.039},
  journal      = {Neurocomputing},
  pages        = {186-196},
  shortjournal = {Neurocomputing},
  title        = {EEG fading data classification based on improved manifold learning with adaptive neighborhood selection},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Resource efficient activation functions for neural network
accelerators. <em>NEUCOM</em>, <em>482</em>, 163–185. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implementations of machine learning models in resource-limited embedded systems are becoming highly desired. This has led to a need for resource-efficient building blocks for computing the mathematical operations required for neural network training and inferencing. Efficient activation functions for low-end hardware devices with limited hardware capabilities are important. In this work, we present a method for generating symmetric and asymmetric activation functions for deep and convolution neural networks. Furthermore, we propose a solution that simultaneously computes a symmetric activation function with an integrated scaling functionality for Long Short Term Memory (LSTM) models. This effectively eliminates two of the three element-wise multipliers in an LSTM cell. Also, this built-in scaling requires no additional computation time because it is integrated within the computation of the symmetric non-linear mapping. This approach replaces the need to compute several Tanh activation functions and element-wise multipliers separately. A resource-efficient approximate multiplier is also proposed to eliminate the third element-wise multiplier and potentially replace all the resource-hungry multipliers. The digital implementation of the proposed method is highly amenable to parallelization and is extremely resource-efficient. We record an area-saving on field-programmable gate arrays with different precision. Our proposal’s formulaic equivalents are also computationally fast on CPU-based engines. On an embedded ARM processor, our method achieves a speedup of at least 4.37 × 4.37× for the proposed functions. We show that LSTMs with our method can achieve up to 3.5 × 3.5× resource footprint saving when compared to the hard activation implementation. We demonstrate that our method achieves competitive results with negligible loss of performance.},
  archive      = {J_NEUCOM},
  author       = {Adedamola Wuraola and Nitish Patel},
  doi          = {10.1016/j.neucom.2021.11.032},
  journal      = {Neurocomputing},
  pages        = {163-185},
  shortjournal = {Neurocomputing},
  title        = {Resource efficient activation functions for neural network accelerators},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contrastive predictive coding with transformer for video
representation learning. <em>NEUCOM</em>, <em>482</em>, 154–162. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel framework of self-supervised learning for video representation. Inspired by Contrastive Predictive Coding and Self-attention, we make the following contributions: First, we propose the Contrastive Predictive Coding with Transformer (CPCTR) framework for video representation learning in a self-supervised fashion. Second, we introduce the Transformer architecture to CPCTR to capture long-range spatio-temporal dependencies in order to facilitate the learning of “slow features” in video, and we conduct analysis of Transformer in our model to show its effectiveness. Finally, we evaluate our model by first training on the UCF101 dataset with self-supervised learning, and then fine-tuning on downstream video classification tasks . Using RGB only video data, we achieve state-of-the-art self-supervised performance on both UCF101 (Top1 accuracy of 99.3\%) and HMDB51 (Top1 accuracy of 82.4\%), we show that CPCTR even outperforms fully supervised methods on the two datasets. The code is available at https://github.com/yliu1229/CPCTR .},
  archive      = {J_NEUCOM},
  author       = {Yue Liu and Junqi Ma and Yufei Xie and Xuefeng Yang and Xingzhen Tao and Lin Peng and Wei Gao},
  doi          = {10.1016/j.neucom.2021.11.031},
  journal      = {Neurocomputing},
  pages        = {154-162},
  shortjournal = {Neurocomputing},
  title        = {Contrastive predictive coding with transformer for video representation learning},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy clustering-based neural networks modelling reinforced
with the aid of support vectors-based clustering and regularization
technique. <em>NEUCOM</em>, <em>482</em>, 139–153. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, classical fuzzy clustering-based neural networks (FCNNs) have been successfully applied to regression tasks . The determination of the parameters such as cluster centers of the existing hard c-means (HCM) or fuzzy c-means (FCM), leads to the performance deterioration of the model because of the sensitivity of HCM or FCM to noise and outliers. Moreover, there are also several factors for over-fitting and degradation of the robustness of the ensuing model. To solve such problems, two improved clustering techniques and L 2 norm-regularization are considered in the proposed robust fuzzy clustering-based neural networks (RFCNNs) modeling. SVs-based hard c-means (SVs-based HCM) and SVs-based fuzzy c-means (SVs-based FCM) designed with support vectors (SVs) can reduce the interference of uncorrelated data, including noise and outliers, thereby enhancing the main data characteristics effectively, as well as leading to the construction on the improved network model. L 2 norm-regularization can be used to alleviate the degradation of robustness caused by overfitting. In terms of improving the performance of the model through SVs-based HCM or SVs-based FCM, as well as robustness completed through L 2 norm-regularization, the superiority of RFCNNs was verified by experimenting with synthetic data and publicly available data from machine learning datasets.},
  archive      = {J_NEUCOM},
  author       = {Hao Huang and Sung-Kwun Oh and Chuan-Kun Wu and Witold Pedrycz},
  doi          = {10.1016/j.neucom.2021.11.029},
  journal      = {Neurocomputing},
  pages        = {139-153},
  shortjournal = {Neurocomputing},
  title        = {Fuzzy clustering-based neural networks modelling reinforced with the aid of support vectors-based clustering and regularization technique},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of two-phase logic-oriented fuzzy AND/OR
network. <em>NEUCOM</em>, <em>482</em>, 129–138. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The architecture of AND/OR fuzzy neural networks exhibits outstanding learning abilities and significant interpretation capabilities. However, AND/OR networks suffer from structure-related problems namely low efficiency and slow convergence of learning due to several reasons such as high dimensionality and gradient-based learning algorithms which lead to a visible computing overhead. In this paper, we present a two-phase fuzzy logic-oriented network design that is composed of AND/OR neurons. This design takes advantages of Randomized Neural Network (RNN) to achieve higher convergence while exhibiting good nonlinear approximation capabilities. A gradient–based learning algorithm is implemented in the second phase of the design to further reduce values of performance index. The quality of the proposed design and resulting architecture is quantified through the use of numeric data along with fuzzy sets (information granules). Experimental results meet the research’s objectives and the proposed design methodology opens up new future directions for proceeding with more improvements.},
  archive      = {J_NEUCOM},
  author       = {Majed Alateeq and Witold Pedrycz},
  doi          = {10.1016/j.neucom.2021.11.028},
  journal      = {Neurocomputing},
  pages        = {129-138},
  shortjournal = {Neurocomputing},
  title        = {Development of two-phase logic-oriented fuzzy AND/OR network},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Face hallucination based on degradation analysis for robust
manifold. <em>NEUCOM</em>, <em>482</em>, 116–128. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, face hallucination, also termed face super-resolution (SR), has been widely studied and achieved significant progress. The algorithm based on manifold learning is one of the primary methods for SR. However, when recovering the high-resolution (HR) counterparts from extremely low-resolution (LR) images, the basic assumption of manifold consistence between LR/HR spaces is doubtful and vulnerable. To address this issue, some algorithms usually employ the cascaded models in line with the inherent magnification factors, such as 2, 4 and 8, to maintain the manifold consistence. As a simple cascade mechanism, the inherent factors cannot ensure the optimal performance without the relationship between the manifold relevance and the down-sampling scale. In this paper, we explore the relevance with the groups of gradually down-sampled training sets and divide the scales into different classes for robust manifold consistence. And then, to map the optimal coefficients from LR spaces to HR target ones better, we introduce the weight-mapping neighbour embedding model. Qualitative and quantitative evaluations demonstrate that the enhancing of the manifold relevance can promote effective face hallucination. Based on the weight-mapping and scale clustering, our algorithm achieves better results compared with the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xin Ding and Ruimin Hu and Zheng He and Chao Liang and Zhongyuan Wang},
  doi          = {10.1016/j.neucom.2021.10.087},
  journal      = {Neurocomputing},
  pages        = {116-128},
  shortjournal = {Neurocomputing},
  title        = {Face hallucination based on degradation analysis for robust manifold},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PRNet++: Learning towards generalized occluded pedestrian
detection via progressive refinement network. <em>NEUCOM</em>,
<em>482</em>, 98–115. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian detection has achieved significant progress in recent years. Though promising results have been obtained on standard pedestrians, it remains challenging to detect pedestrians in various occlusion situations. In this paper, we propose Progressive Refinement Network (PRNet) , a novel single-stage detector for occluded pedestrian detection. Inspired by human’s progressive process on annotating occluded pedestrians, PRNet perform sequential refinement in a single-stage detection framework by three phases: finding anchors of visible parts with high confidence, calibrating these anchors with a full body template derived from occlusion statistics, and adjusting the calibrated anchors to target full-body regions. Unlike conventional methods that utilize predefined anchors directly for full-body estimation, the proposed confidence-aware anchor calibration offers an adaptive anchor initialization for detection with occlusions, while helps reduce the gap between visible-part and full-body detection. We also propose an occlusion loss, which automatically up-weights heavily occluded pedestrian samples. In addition, a Receptive Field Backfeed (RFB) module is introduced to diversify receptive fields in early layers that commonly fire only on visible parts or small-size full-body regions. To further learn generalized representations of pedestrians in different occlusion states, we propose to establish a new single-stage detector with dual-stream architecture namely PRNet++. An Easy-branch and a Hard-branch are designed to learn complementary representation that are more robust to various occlusions. Moreover, the generalization ability of models for other domains are critical in real-world applications, but it has not attracted too much attention. To address this issue, we introduce the unsupervised domain adaptation setting. To handle occlusion situations in unknown domain better, we especially design a Dynamic Iterative adaptation strategy and a Multi-experts adaptation strategy for our occlusion-aware detectors PRNet and PRNet++. Extensive supervised within-dataset experiments and unsupervised domain adaptation experiments were performed on CityPersons, Caltech, ECP-night, KITTI and INRIA datasets, which can validate the effectiveness of our proposed methods in occluded pedestrian detection.},
  archive      = {J_NEUCOM},
  author       = {Xiaolin Song and Binghui Chen and Pengyu Li and Biao Wang and Honggang Zhang},
  doi          = {10.1016/j.neucom.2022.01.056},
  journal      = {Neurocomputing},
  pages        = {98-115},
  shortjournal = {Neurocomputing},
  title        = {PRNet++: Learning towards generalized occluded pedestrian detection via progressive refinement network},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Automatic and accurate segmentation of peripherally
inserted central catheter (PICC) from chest x-rays using multi-stage
attention-guided learning. <em>NEUCOM</em>, <em>482</em>, 82–97. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of Peripherally Inserted Central Catheter (PICC) from chest X-rays (CXR) is the first step towards automatic PICC position confirmation. PICC is a relatively small and thin tube that occupies only a small proportion on the entire CXR, while the resolution of CXR is generally quite high. To address such large-scene-thin-object segmentation problem, in this paper we propose an automatic multi-stage attention-guided framework (MAG-Net) for PICC segmentation and tip positioning, which contains a coarse stage for rough locating and a fine stage for precise segmenting. A coarse network with pyramid pooling for larger receptive field is presented to generate an initial segmentation mask. After that, for small object refinement, an adaptive spatial weighting encoder is introduced to achieve a differentiable hard attention, and a position self-attention module is utilized to enhance the relationship between spatial pixels and maintain the integrity of target. Also, a pixelshuffling decoder is designed to restore the resolution without inserting irrelevant pixels. For the experiments, we have collected a CXR image dataset of PICC, where we manually labelled the chest contours, PICC segmentation masks, and tip positions. We propose and evaluate our overall architectures by cross-validation on our PICC dataset. Extensive experiments demonstrate that the efficiency of our approach generates precise and reliable results and superior performance compared to other state-of-the-art networks. Compared to the baseline network (U-Net), MAG-Net achieves a 6\% improvement in DSC (2\% improvement in regional DSC), a 8\% improvement in Recall (9\% improvement in regional Recall), a 2\% reduction in UR (9\% reduction in regional UR) and a 5\% improvement in IOU (2\% improvement in regional IOU).The results show that our coarse-to-fine framework is effective to improve the segmentation accuracy by making good use of both the local and global contextual information. Our code is made publicly available at: https://github.com/zjutwly/muti-stage-PICC-segmentation.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyan Wang and Luyao Wang and Ye Sheng and Chenglu Zhu and Nan Jiang and Cong Bai and Ming Xia and Zhanpeng Shao and Zheng Gu and Xiaojie Huang and Ruiyi Zhao and Zhenjie Liu},
  doi          = {10.1016/j.neucom.2022.01.040},
  journal      = {Neurocomputing},
  pages        = {82-97},
  shortjournal = {Neurocomputing},
  title        = {Automatic and accurate segmentation of peripherally inserted central catheter (PICC) from chest X-rays using multi-stage attention-guided learning},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The combined functional approach to state estimation of
delayed static neural network. <em>NEUCOM</em>, <em>482</em>, 73–81. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This dissertation investigates the H ∞ H∞ state estimation for static neural networks with time-varying delays. In order to fully utilize delay information, a innovative Lyapunov–Krasovskii (L-K) functional is developed, which includes delay-product-type (DPT) terms both in the non-integral and single integral functionals, and the S-dependent integral term is introduced to combine with the single integral DPT functional for the first time. Then, in order to work effectively with the proposed L-K functional to lower the conservatism of the conclusion, generalized free-weighting-matrix integral inequality and other methods are selected. Furthermore, a more general gain inverse solution is given, and the gain matrix independent of the activation function is obtained, which removes the qualification that the activation function must be reversible. At last, numerical examples are used to explain the advantage of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Wei Qian and Hang Shi and Zhonghua Wu and Yunji Zhao},
  doi          = {10.1016/j.neucom.2022.01.054},
  journal      = {Neurocomputing},
  pages        = {73-81},
  shortjournal = {Neurocomputing},
  title        = {The combined functional approach to state estimation of delayed static neural network},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ACORT: A compact object relation transformer for parameter
efficient image captioning. <em>NEUCOM</em>, <em>482</em>, 60–72. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research that applies Transformer-based architectures to image captioning has resulted in state-of-the-art image captioning performance, capitalising on the success of Transformers on natural language tasks. Unfortunately, though these models work well, one major flaw is their large model sizes. To this end, we present three parameter reduction methods for image captioning Transformers: Radix Encoding, cross-layer parameter sharing, and attention parameter sharing. By combining these methods, our proposed ACORT models have 3.7 × × to 21.6 × × fewer parameters than the baseline model without compromising test performance. Results on the MS-COCO dataset demonstrate that our ACORT models are competitive against baselines and SOTA approaches, with CIDEr score ⩾ ⩾ 126. Finally, we present qualitative results and ablation studies to demonstrate the efficacy of the proposed changes further. Code and pre-trained models are publicly available at https://github.com/jiahuei/sparse-image-captioning.},
  archive      = {J_NEUCOM},
  author       = {Jia Huei Tan and Ying Hua Tan and Chee Seng Chan and Joon Huang Chuah},
  doi          = {10.1016/j.neucom.2022.01.081},
  journal      = {Neurocomputing},
  pages        = {60-72},
  shortjournal = {Neurocomputing},
  title        = {ACORT: A compact object relation transformer for parameter efficient image captioning},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). INL: Implicit non-local network. <em>NEUCOM</em>,
<em>482</em>, 50–59. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The attention mechanism of computer vision represented by a non-local network improves the performance of numerous vision tasks while bringing computational burden for deployment Wang et al. (2018). In this work, we explore to release the inference computation for non-local network by decoupling the training/inference procedure. Specifically, we propose the implicit non-local network (iNL). During training, iNL models the dependency between features across long-range affinities like original non-local blocks; during inference, iNL could be reformulated as only two convolution layers but can rival non-local network. In this way, the computation complexity and the memory costs are reduced. In addition, we take a further step and extend our iNL into a more generalized form, which covers the attentions of different orders in computer vision tasks . iNL brings steady improvements on multiple benchmarks of different vision tasks including classification, detection, and instance segmentation . In the meantime, it provides a brand–new perspective to understand the attention mechanism in deep neural networks .},
  archive      = {J_NEUCOM},
  author       = {Yifeng Han and Xi Chen and Songjie Zhang and Donglian Qi},
  doi          = {10.1016/j.neucom.2022.01.047},
  journal      = {Neurocomputing},
  pages        = {50-59},
  shortjournal = {Neurocomputing},
  title        = {INL: Implicit non-local network},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic intervention for causal inference via
reinforcement learning. <em>NEUCOM</em>, <em>482</em>, 40–49. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal inference methods are widely applied in various decision-making domains such as precision medicine, optimal policy and economics. The main focus of causal inference is the treatment effect estimation of intervention strategies, such as changes in drug dosing and increases in financial aid. Existing methods are mostly restricted to the deterministic treatment and compare outcomes under different treatments. However, they are unable to address the substantial recent interests of treatment effect estimation under stochastic intervention, e.g., “how all units health status change if they adopt 50\% dose reduction”. In other words, they lack the capability of addressing fine-grained treatment effect estimation to empower the decision-making applications. In this paper, we advance the causal inference research by proposing a new effective framework to estimate the treatment effect under the stochastic intervention. Particularly, we develop a stochastic intervention effect estimator (SIE) based on nonparametric influence function, with the theoretical guarantees of robustness and fast convergence rates. Additionally, we construct a customised reinforcement learning algorithm based on the random search solver which can effectively find the optimal policy to produce the greatest expected outcomes for the decision-making process. Finally, we conduct extensive empirical experiments to validate that our framework can achieve superior performance in comparison with state-of-the-art baselines. For reproducing experimental results, all the source codes and data are available at https://github.com/tridungduong16/Interpretable-Machine-Learning/tree/master/Source\%20Code.},
  archive      = {J_NEUCOM},
  author       = {Tri Dung Duong and Qian Li and Guandong Xu},
  doi          = {10.1016/j.neucom.2022.01.086},
  journal      = {Neurocomputing},
  pages        = {40-49},
  shortjournal = {Neurocomputing},
  title        = {Stochastic intervention for causal inference via reinforcement learning},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MR-DARTS: Restricted connectivity differentiable
architecture search in multi-path search space. <em>NEUCOM</em>,
<em>482</em>, 27–39. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentiable search methods can be used to find effective network architectures fast. However, these approaches are accompanied by low accuracy when evaluating a searched architecture, especially evaluating a searched architecture after transferring it to a different dataset. Two reasons can explain this phenomenon. The one is that the networks composed of cells have the depth gap in their structures between the search and evaluate stage. Another is that cells have insufficient ability to extract diverse features. This paper presents the Multi-path Restricted DARTS method to address these critical problems, using a multi-path search space and a restricted connectivity algorithm to perform a more exact search with limited resources. Restricted connectivity algorithm deepens the cells’ structure and makes cells more suitable for deep networks to bridge the depth gap. Multi-path search space enables cells to extract and fuse different-scales features to improve the representation capacity of a network. Our approach achieves state-of-the-art performance on CIFAR10 and CIFAR100 with the smallest parameters (only 2.5 M), demonstrating strong transfer learning ability in complex datasets.},
  archive      = {J_NEUCOM},
  author       = {Feng Gao and Bin Song and Dan Wang and Hao Qin},
  doi          = {10.1016/j.neucom.2022.01.080},
  journal      = {Neurocomputing},
  pages        = {27-39},
  shortjournal = {Neurocomputing},
  title        = {MR-DARTS: Restricted connectivity differentiable architecture search in multi-path search space},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Multi-category classification with label noise by robust
binary loss. <em>NEUCOM</em>, <em>482</em>, 14–26. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, deep learning models have achieved state-of-the-art performances in image classification . However, the classification and generalization ability of most achievements have highly relied on the availability of large-scale accurate labeled training data, which are time-consuming, laborious, and expensive to collect. Moreover, in the generalizing process of deep learning models , the noisy labels are the challenges for multi-category classification. Hence, it is essential to explore effective methods that can efficiently and correctly train deep models under label noise to conduct multi-category classification. This paper proposes using robust binary loss functions to train deep models under label noise to address this problem. Specifically, we suggest handling the K -class classification task by using K binary classifiers , which can be completed by a joint adoption of multi-category large margin classification approaches , e.g., Pairwise-Comparison (PC) or One-versus-All (OVA). We also theoretically demonstrate that our method is inherently tolerant to label noise by using symmetric binary loss functions in multi-category classification tasks. Moreover, we designed a truncated CCE loss to combine with the proposed losses to improve the learning ability. Finally, we test our method on three different benchmark datasets with different types of label noise. The experimental results have clearly confirmed the effectiveness of our method, which can reduce the negative effect of noisy labels and improve the generalization ability .},
  archive      = {J_NEUCOM},
  author       = {Defu Liu and Jiayi Zhao and Jinzhao Wu and Guowu Yang and Fengmao Lv},
  doi          = {10.1016/j.neucom.2022.01.031},
  journal      = {Neurocomputing},
  pages        = {14-26},
  shortjournal = {Neurocomputing},
  title        = {Multi-category classification with label noise by robust binary loss},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Upcycling adversarial attacks for infrared object detection.
<em>NEUCOM</em>, <em>482</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, infrared object detection (IOD) has been extensively studied due to the rapid growth of deep neural networks (DNNs). An adversarial attack using imperceptible perturbation can dramatically deteriorate the performance of DNNs. Most of the existing adversarial attacks are focused on visible image recognition (VIR), but there are few attacks for IOD. Moreover, the existing attacks are challenging to exploit for state-of-the-art detectors (e.g., EfficientDet) due to low compatibility. To solve the problem, we propose a novel upcycling adversarial attack for IOD by expanding the highly compatible adversarial attacks for the VIR task. We also propose a novel evaluation metric , attack efficiency (AE), to compare the effectiveness of different adversarial attacks. Since the AE value increases with the small perturbation size and the significant performance drop, we can concurrently compare the similarity and performance degradation between adversarial and clean images for various attacks. We validate our approaches through comprehensive experiments on two challenging datasets (e.g., FLIR and MSOD) for the infrared domain .},
  archive      = {J_NEUCOM},
  author       = {Hoseong Kim and Chanyong Lee},
  doi          = {10.1016/j.neucom.2022.01.090},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {Upcycling adversarial attacks for infrared object detection},
  volume       = {482},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Calibrating the adaptive learning rate to improve
convergence of ADAM. <em>NEUCOM</em>, <em>481</em>, 333–356. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive gradient methods (AGMs) have been widely used to optimize nonconvex problems in the deep learning area. We identify two aspects of AGMs that can be further improved. First, we observe that the adaptive learning rate (A-LR) used by AGMs varies significantly across the dimensions of the optimization problem and over epochs, which we call anisotropic scale of the A-LR. It can slow down the convergence and make the algorithm trap into a sharp local minimizer. Actually, all existing modified AGMs represent efforts in revising the A-LR. Second, we theoretically prove that the convergence rate of AGMs depends on its hyper-parameter used in the A-LR formula, such as the ∊ ∊ ∊ used in ADAM, which has not been examined previously. We then propose new AGMs that calibrate the A-LR with an activation function , such as, the softplus function. Particularly, the Sadam and SAMSGrad methods are two instances of our method. We further prove that SAMSGrad enjoys a better convergence speed than the AMSGrad method under separate conditions including the nonconvex, non-strongly convex, and Polyak-Łojasiewicz conditions. Empirical studies are used to demonstrate the anisotropic A-LR issue and show that the proposed methods outperform existing AGMs and generalize better in multiple deep learning tasks.},
  archive      = {J_NEUCOM},
  author       = {Qianqian Tong and Guannan Liang and Jinbo Bi},
  doi          = {10.1016/j.neucom.2022.01.014},
  journal      = {Neurocomputing},
  pages        = {333-356},
  shortjournal = {Neurocomputing},
  title        = {Calibrating the adaptive learning rate to improve convergence of ADAM},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finite-time observer based tracking control of uncertain
heterogeneous underwater vehicles using adaptive sliding mode approach.
<em>NEUCOM</em>, <em>481</em>, 322–332. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a finite-time consensus tracking problem is investigated for a group of autonomous underwater vehicles (AUVs) with heterogeneous uncertain dynamics. We firstly propose a two-layer distributed control strategy, which consists of an upper-layer distributed observer and a lower-layer controller, without using any global information. Based on Hölder’s inequality and the theory of finite-time stability, a distributed finite-time observer is developed for each follower to estimate the position information of a leader (i.e., an exosystem). Based on the sliding mode control method, a consensus tracking control scheme is designed for each AUV, by which all follower AUVs can track the leader in finite time. Secondly, when the parameters in the AUV dynamics are uncertain, a parameter-adaptive sliding mode control algorithm is introduced to improve the control performance. Finally, simulation results are presented to demonstrate the effectiveness of the proposed control algorithms.},
  archive      = {J_NEUCOM},
  author       = {Bo Chen and Jiangping Hu and Yiyi Zhao and Bijoy Kumar Ghosh},
  doi          = {10.1016/j.neucom.2022.01.038},
  journal      = {Neurocomputing},
  pages        = {322-332},
  shortjournal = {Neurocomputing},
  title        = {Finite-time observer based tracking control of uncertain heterogeneous underwater vehicles using adaptive sliding mode approach},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Minimum-energy synchronization for interconnected networks
with non-periodical information silence. <em>NEUCOM</em>, <em>481</em>,
310–321. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimum-energy synchronization control for interconnected networks is addressed, where network topologies contain leaderless and leader-follower structures and information transmission of the whole network is non-periodically silent. The key characteristic of the current work is that the total energy consumption is minimum in the sense of the linear matrix inequality, while both the guaranteed-cost synchronization and the limited-budget synchronization cannot make the total energy consumption be minimum. Firstly, the leaderless minimum-energy synchronization achievement problem is transformed into the asymptotic stabilization problem by the state decoupling strategy, and sufficient conditions of leaderless minimum-energy synchronization are presented by the Lyapunov-based method. Especially, those conditions can be solved by the generalized eigenvalue approach on the basis of the linear matrix inequality. Then, main results of leaderless minimum-energy synchronization are expanded to leader-follower interconnected networks, where the key challenge is that these networks are nonsymmetrical. Finally, two numerical examples are illustrated to verify main results.},
  archive      = {J_NEUCOM},
  author       = {Junlong Li and Jianxiang Xi and Le Wang and Donghao Qin and Bing Li},
  doi          = {10.1016/j.neucom.2022.01.083},
  journal      = {Neurocomputing},
  pages        = {310-321},
  shortjournal = {Neurocomputing},
  title        = {Minimum-energy synchronization for interconnected networks with non-periodical information silence},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). The range of harmful frequency for DNN corruption
robustness. <em>NEUCOM</em>, <em>481</em>, 294–309. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite having achieved excellent performance on various tasks, deep neural networks have been shown to be vulnerable to image corruptions (noise, blur, etc.). Understanding this vulnerability is a critical step towards robust DNN. Therefore, many researchers analyzed the frequency domain of images and attributed this vulnerability to the high frequency. However, they only qualitatively describe ‘high frequency’ on a relative scale without quantifying the range of harmful high frequency. To fill this gap and obtain a deeper insight into the corruption robustness, we analyze the correlation between the importance of image frequency components for 8 SOTA models and the corruption robustness of them. Results show that about 6/7 high frequency of the images is harmful. Based on our insight, we propose an image augmentation method, which reduces the importance of harmful frequency to DNN by shuffling the harmful frequency of training images. Experiments on ResNet50 show that, compared with SOTA methods, our method achieves comparable DNN corruption robustness with the least time consumption. What’s more, our image augmentation shows a good generalization across DNNs (e.g. ResNet18, VGG16) and corruption benchmarks (e.g. Cifar-10-C, MNIST-C). Our study has enhanced our understanding of the relationship between model robustness and high frequency from a quantitative perspective and shows that by accurately identifying harmful frequency, we can effectively improve DNN corruption robustness without using additional model assistance or multiple transformation combinations like other SOTA methods.},
  archive      = {J_NEUCOM},
  author       = {Zhuang Zhang and Dejian Meng and Lijun Zhang and Wei Xiao and Wei Tian},
  doi          = {10.1016/j.neucom.2022.01.087},
  journal      = {Neurocomputing},
  pages        = {294-309},
  shortjournal = {Neurocomputing},
  title        = {The range of harmful frequency for DNN corruption robustness},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep plug-and-play prior for hyperspectral image
restoration. <em>NEUCOM</em>, <em>481</em>, 281–293. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep-learning-based hyperspectral image (HSI) restoration methods have gained great popularity for their remarkable performance but often demand expensive network retraining whenever the specifics of task changes. In this paper, we propose to restore HSIs in a unified approach with an effective plug-and-play method, which can jointly retain the flexibility of optimization-based methods and utilize the powerful representation capability of deep neural networks . Specifically, we first develop a new deep HSI denoiser leveraging gated recurrent convolution units, short- and long-term skip connections, and an augmented noise level map to better exploit the abundant spatio-spectral information within HSIs. It, therefore, leads to the state-of-the-art performance on HSI denoising under both Gaussian and complex noise settings. Then, the proposed denoiser is inserted into the plug-and-play framework as a powerful implicit HSI prior to tackle various HSI restoration tasks. Through extensive experiments on HSI super-resolution, compressed sensing , and inpainting, we demonstrate that our approach often achieves superior performance, which is competitive with or even better than the state-of-the-art on each task, via a single model without any task-specific training.},
  archive      = {J_NEUCOM},
  author       = {Zeqiang Lai and Kaixuan Wei and Ying Fu},
  doi          = {10.1016/j.neucom.2022.01.057},
  journal      = {Neurocomputing},
  pages        = {281-293},
  shortjournal = {Neurocomputing},
  title        = {Deep plug-and-play prior for hyperspectral image restoration},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning disentangled representation for self-supervised
video object segmentation. <em>NEUCOM</em>, <em>481</em>, 270–280. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel self-supervised method for one-shot video object segmentation where the object annotations are only provided in the first frame. The current self-supervised video object segmentation approaches are implemented by modeling the pairwise correspondence between the target and reference frames. The pairwise correspondence only maintains spatio-temporal consistency. However, the VOS tasks not only require a spatio-temporal relationship between the two frames but also require the salient object information for each frame. In order to achieve this goal, we propose a disentangled representation strategy to disentangle the temporal correspondence into the pairwise term and unary term. The pairwise and unary terms capture inter-frame spatio-temporal and intra-frame salient object information, respectively. To demonstrate the importance of the disentangled representation, we apply the proposed approach to DAVIS-2017 and YouTube-VOS datasets. Experimental results confirm the effectiveness of the proposed solution.},
  archive      = {J_NEUCOM},
  author       = {Wenjie Hou and Zheyun Qin and Xiaoming Xi and Xiankai Lu and Yilong Yin},
  doi          = {10.1016/j.neucom.2022.01.066},
  journal      = {Neurocomputing},
  pages        = {270-280},
  shortjournal = {Neurocomputing},
  title        = {Learning disentangled representation for self-supervised video object segmentation},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Social dual-effect driven group modeling for neural group
recommendation. <em>NEUCOM</em>, <em>481</em>, 258–269. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent group activities of human beings have become an indispensable part of human daily life. Group recommendation aims to recommend preferred items to a group of users in recommender systems . The existing solutions on group recommendation are to explore group modeling with or without the help of auxiliary information on social networks. However, we observe that the social factors can be explored directly in the group without employing social information on social networks. Towards this end, we study the social effect-based design guideline to drive group modeling. In this work, we propose a novel S ocial dual- E ffect driven A ttentive G roup R ecommendation method (SEAGR) that well utilizes social selection effect and social influence effect from sociology to explore group representation learning for neural group recommendation. Specifically, we construct the social selection-driven group inherent modeling from interaction-level and user-level. To mimic interaction-based dynamic group decision-making, we also design a social influence-driven attentive influence mining model in terms of users’ influence distinction in different groups. Based on these two components, an aggregative group representation is obtained. Moreover, neural recommendation for groups and users could be intensified reciprocally considering the impact of groups on users. The experimental results validate the effectiveness of the proposed method on three real-world datasets, and demonstrate its advantages over state-of-the-art methods in accuracy through extensive experiments.},
  archive      = {J_NEUCOM},
  author       = {Peipei Wang and Lin Li and Qing Xie and Ru Wang and Guandong Xu},
  doi          = {10.1016/j.neucom.2022.01.093},
  journal      = {Neurocomputing},
  pages        = {258-269},
  shortjournal = {Neurocomputing},
  title        = {Social dual-effect driven group modeling for neural group recommendation},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring uncertainty in regression neural networks for
construction of prediction intervals. <em>NEUCOM</em>, <em>481</em>,
249–257. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has achieved impressive performance on many tasks in recent years. However, it has been found that it is still not enough for deep neural networks to provide only point estimates. For high-risk tasks, we need to assess the reliability of the model predictions. This requires us to quantify the uncertainty of model prediction and construct prediction intervals. One of the significant advantages of the proposed method is that it simultaneously implements point estimation and uncertainty quantification. In this paper, we explore the uncertainty in regression neural networks to construct the prediction intervals. In general, we comprehensively consider two categories of uncertainties: aleatory uncertainty and epistemic uncertainty. We design a novel loss function, which enables us to learn uncertainty without uncertainty labels. We only need to supervise the learning of regression tasks . In the process of training, the model implicitly learns aleatory uncertainty under the guidance of loss function. And that epistemic uncertainty is accounted for in the ensembled form. Our method correlates the construction of prediction intervals with uncertainty estimation . Experimental results on some publicly available datasets show that the performance of our method is competitive with other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yuandu Lai and Yucheng Shi and Yahong Han and Yunfeng Shao and Meiyu Qi and Bingshuai Li},
  doi          = {10.1016/j.neucom.2022.01.084},
  journal      = {Neurocomputing},
  pages        = {249-257},
  shortjournal = {Neurocomputing},
  title        = {Exploring uncertainty in regression neural networks for construction of prediction intervals},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive ensemble of self-adjusting nearest neighbor
subspaces for multi-label drifting data streams. <em>NEUCOM</em>,
<em>481</em>, 228–248. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label data streams are sequences of multi-label instances arriving over time to a multi-label classifier. The properties of the stream may continuously change due to concept drift. Therefore, algorithms must constantly adapt to the new data distributions. In this paper we propose a novel ensemble method for multi-label drifting streams named Adaptive Ensemble of Self-Adjusting Nearest Neighbor Subspaces (AESAKNNS). It leverages a self-adjusting kNN as a base classifier with the advantages of ensembles to adapt to concept drift in the multi-label environment. To promote diverse knowledge within the ensemble, each base classifier is given a unique subset of features and samples to train on. These samples are distributed to classifiers in a probabilistic manner that follows a Poisson distribution as in online bagging. Accompanying these mechanisms, a collection of ADWIN detectors monitor each classifier for the occurrence of a concept drift on the subspace. Upon detection, the algorithm automatically trains additional classifiers in the background to attempt to capture new concepts on new subspaces of features. The dynamic classifier selection chooses the most accurate classifiers from the active and background ensembles to replace the current ensemble. Our experimental study compares the proposed approach with 30 other classifiers, including problem transformation, algorithm adaptation , kNNs, and ensembles on 30 diverse multi-label datasets and 12 performance metrics. Results, validated using non-parametric statistical analysis, support the better performance of the AESAKNNS and highlight the contribution of its components in improving the performance of the ensemble.},
  archive      = {J_NEUCOM},
  author       = {Gavin Alberghini and Sylvio Barbon Junior and Alberto Cano},
  doi          = {10.1016/j.neucom.2022.01.075},
  journal      = {Neurocomputing},
  pages        = {228-248},
  shortjournal = {Neurocomputing},
  title        = {Adaptive ensemble of self-adjusting nearest neighbor subspaces for multi-label drifting data streams},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Remove and recover: Deep end-to-end two-stage attention
network for single-shot heavy rain removal. <em>NEUCOM</em>,
<em>481</em>, 216–227. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel heavy rain removal algorithm using a deep neural network. Unlike most of the existing deraining methods, heavy rain removal is a more challenging task because it is necessary to remove both the rain marks and the haze effects, which are entangled in a complex manner. Motivated by this, we propose a new end-to-end two-stage attention network for single-shot heavy rain removal. The proposed network is connected serially with a removal network and a recovery network, which are based on a newly introduced dilation-wise attention block and skip attention block. Based on these attention techniques, the removal network predicts the heavy rain effect that needs to be removed from a given image, and the recovery network successfully predicts the details that need to be recovered, resulting in a clean image. We also introduce a new realistic RainCityscapes+ dataset, composed of synthesized outdoor images, and demonstrate extensive experiments, the results of which show our approach outperforms the state-of-the-art methods on both real and synthetic datasets quantitatively and qualitatively.},
  archive      = {J_NEUCOM},
  author       = {Woo Jin Ahn and Tae Koo Kang and Hyun Duck Choi and Myo Taeg Lim},
  doi          = {10.1016/j.neucom.2022.01.041},
  journal      = {Neurocomputing},
  pages        = {216-227},
  shortjournal = {Neurocomputing},
  title        = {Remove and recover: Deep end-to-end two-stage attention network for single-shot heavy rain removal},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fuzzy-enhanced deep learning approach for early detection
of covid-19 pneumonia from portable chest x-ray images. <em>NEUCOM</em>,
<em>481</em>, 202–215. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Covid-19 pandemic is the defining global health crisis of our time. Chest X-Rays (CXR) have been an important imaging modality for assisting in the diagnosis and management of hospitalised Covid-19 patients. However, their interpretation is time intensive for radiologists. Accurate computer aided systems can facilitate early diagnosis of Covid-19 and effective triaging. In this paper, we propose a fuzzy logic based deep learning (DL) approach to differentiate between CXR images of patients with Covid-19 pneumonia and with interstitial pneumonias not related to Covid-19. The developed model here, referred to as CovNNet , is used to extract some relevant features from CXR images, combined with fuzzy images generated by a fuzzy edge detection algorithm . Experimental results show that using a combination of CXR and fuzzy features, within a deep learning approach by developing a deep network inputed to a Multilayer Perceptron (MLP), results in a higher classification performance (accuracy rate up to 81\%), compared to benchmark deep learning approaches. The approach has been validated through additional datasets which are continously generated due to the spread of the virus and would help triage patients in acute settings. A permutation analysis is carried out, and a simple occlusion methodology for explaining decisions is also proposed. The proposed pipeline can be easily embedded into present clinical decision support systems .},
  archive      = {J_NEUCOM},
  author       = {Cosimo Ieracitano and Nadia Mammone and Mario Versaci and Giuseppe Varone and Abder-Rahman Ali and Antonio Armentano and Grazia Calabrese and Anna Ferrarelli and Lorena Turano and Carmela Tebala and Zain Hussain and Zakariya Sheikh and Aziz Sheikh and Giuseppe Sceni and Amir Hussain and Francesco Carlo Morabito},
  doi          = {10.1016/j.neucom.2022.01.055},
  journal      = {Neurocomputing},
  pages        = {202-215},
  shortjournal = {Neurocomputing},
  title        = {A fuzzy-enhanced deep learning approach for early detection of covid-19 pneumonia from portable chest X-ray images},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection of sludge bulking using adaptive fuzzy neural
network and mechanism model. <em>NEUCOM</em>, <em>481</em>, 193–201. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The frequent occurrence of sludge bulking can influence the effluent qualities and destroy the stable operation of activated sludge process (ASP). In order to accurately detect the sludge bulking, a detection method, based on adaptive fuzzy neural network and mechanism model, is proposed in this paper. First, a novel detection scheme is designed, where hybrid detection model and intelligent identification algorithm , are designed to describe the dynamics of sludge bulking. Second, an error compensation model, by using adaptive fuzzy neural network , is established to make up for the errors caused by the assumptions set in hybrid detection model. Finally, an error-assisted detection strategy is designed to evaluate sludge bulking. To verify the effectiveness of the proposed detection method, operating data from ASP are applied. The results show that this proposed method can efficiently detect sludge bulking.},
  archive      = {J_NEUCOM},
  author       = {Lu Zhang and Maiying Zhong and Honggui Han},
  doi          = {10.1016/j.neucom.2022.01.060},
  journal      = {Neurocomputing},
  pages        = {193-201},
  shortjournal = {Neurocomputing},
  title        = {Detection of sludge bulking using adaptive fuzzy neural network and mechanism model},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Planning sequential interventions to tackle depression in
large uncertain social networks using deep reinforcement learning.
<em>NEUCOM</em>, <em>481</em>, 182–192. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies, with the increasing concern for mental health, have shown that interventions along with social support can reduce stress and depression. However, counselling centers do not have enough resources to provide counselling and social support to all the participants in their interest. This paper helps social support organizations (e.g., university counselling centers) sequentially select the participants for interventions. Meanwhile, Deep Reinforcement Learning (DRL) has shown significant success in learning an efficient policy for sequential decision-making problems in both fully observable environments and partially observable environments with small action space. In this paper, we consider emotion propagation from other neighbours of the influencees, initial uncertainties of mental states and influence in the student network. We propose a new architecture called DRLPSO (Deep Reinforcement Learning with Particle Swarm Optimization) to enhance learning performance in a partially observable environment with a large state and action space. DRLPSO consists of two stages: the Discrete Particle Swarm Optimization (DPSO) and Deep Q-learning integrated with Long Short-Term Memory (DQ-LSTM). In the first stage, we apply DPSO by initializing n particles that converge to multiple optimal actions for each belief state. In the second stage, the action with the best Q-value from the DPSO action set is executed to obtain belief and observation (history of action). We evaluated the proposed method empirically with the simulated student networks with mental state propagation compared to the state-of-the-art algorithms. The experimental results demonstrate that DRLPSO outperforms the state-of-the-art DRL methods by an average of 32\%.},
  archive      = {J_NEUCOM},
  author       = {Aye Phyu Phyu Aung and Senthilnath Jayavelu and Xiaoli Li and Bo An},
  doi          = {10.1016/j.neucom.2022.01.030},
  journal      = {Neurocomputing},
  pages        = {182-192},
  shortjournal = {Neurocomputing},
  title        = {Planning sequential interventions to tackle depression in large uncertain social networks using deep reinforcement learning},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive grid-based forest-like clustering algorithm.
<em>NEUCOM</em>, <em>481</em>, 168–181. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an adaptive grid-based clustering algorithm called as “AGFC”, which uses a forest-like query structure to sequentially discovers multiple arbitrary-shaped clusters from the grid. The main advantage of AGFC is that it can effectively generate a reasonable grid division with a simple startup parameter. This method determines the appropriate grid division width through the minimum gap between the peaks and valleys of the density curve in a specific dimension, which depends on the distribution of the sample, to overcome the subjectivity of manual determination to a certain extent. Furthermore, in the forest-like query structure, it constructs a “Aggregation Judgment” criterion for high-density cells to find out the possible clusters through the merging of cells. Finally, using the “Re-clustering process” to eliminate very small clusters and further repairing the edge areas of the main clusters. The experimental results show that the proposed method can obtain competitive results under the premise of automatically determining the grid.},
  archive      = {J_NEUCOM},
  author       = {Mingchang Cheng and Tiefeng Ma and Lin Ma and Jian Yuan and Qijing Yan},
  doi          = {10.1016/j.neucom.2022.01.089},
  journal      = {Neurocomputing},
  pages        = {168-181},
  shortjournal = {Neurocomputing},
  title        = {Adaptive grid-based forest-like clustering algorithm},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weakly-supervised anomaly detection in video surveillance
via graph convolutional label noise cleaning. <em>NEUCOM</em>,
<em>481</em>, 154–167. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we seek to solve the problem of video anomaly detection under the weakly-supervised setting. Different from previous works that usually deal with the problem in a multiple-instance learning manner, we formulate it as a fully-supervised learning task with label noises. Under this new perspective, we can fully leverage the advantages of well-designed action classifiers for anomaly detection as long as the label noises are cleaned. For this purpose, we devise a graph convolutional network for label noise cleaning, which integrates two crucial characteristics for anomaly analysis : feature similarity and temporal consistency. Supervised by both direct and indirect signals, the net propagates supervision information from high-confidence snippets to low-confidence ones and provides cleaned labels for action classifier training. In this way, we design an alternate learning strategy to progressively promote the discrimination of the action classifier. During the test phase, we directly utilize the learned action classifier for anomaly detection in an end-to-end fashion without any intermediate processing. We have conducted extensive experiments on various anomaly datasets of three scales with two main types of action classifiers, and achieved superior or comparable performances compared with state-of-the-art methods. Furthermore, we manually annotate the temporal duration of anomalies in the training data of UCF-Crime, and give out the upper-limit performance of our cleaner net. The annotation can also be used as the ground truth for studying anomaly detection models under multi-level supervisory signals, which will mitigate the present shortage of large-scale anomaly datasets.},
  archive      = {J_NEUCOM},
  author       = {Nannan Li and Jia-Xing Zhong and Xiujun Shu and Huiwen Guo},
  doi          = {10.1016/j.neucom.2022.01.026},
  journal      = {Neurocomputing},
  pages        = {154-167},
  shortjournal = {Neurocomputing},
  title        = {Weakly-supervised anomaly detection in video surveillance via graph convolutional label noise cleaning},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A fault diagnosis method for wind turbines with limited
labeled data based on balanced joint adaptive network. <em>NEUCOM</em>,
<em>481</em>, 133–153. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional machine learning or deep learning relies on a sufficient amount of labeled data for the training of fault diagnosis models. However, for new wind farms, insufficient data and limited labels hinder the establishment of such models. In order to cope with these two challenges, we proposed a new domain adaptive method for wind turbine fault diagnosis: balanced joint adaptive network (BJAN), which can transfer wind turbine data from other wind farms to the target new wind farm. In this method, we proposed a new pseudo-label prediction method that combines the sub-domain majority voting and overall iterations (SMV-I) to label the unlabeled data . In addition, BJAN uses long short-term memory model (LSTM) to replace common convolutional neural network (CNN) as the feature extraction module to improve diagnosis efficiency. Moreover, we also proposed a new distributed adaptive distance for BJAN: balanced joint maximum mean discrepancy (BJMMD), which can balance the data of different states during the distributed adaptive process to improve diagnostic accuracy . Numerical experiments with real wind turbine data in three wind farms not only show that the proposed SMV-I has excellent pseudo-label prediction performance, but also verify that the proposed fault diagnosis model BJAN has higher diagnostic accuracy and efficiency.},
  archive      = {J_NEUCOM},
  author       = {Guangyao Zhang and Yanting Li and Wenbo Jiang and Lianjie Shu},
  doi          = {10.1016/j.neucom.2022.01.067},
  journal      = {Neurocomputing},
  pages        = {133-153},
  shortjournal = {Neurocomputing},
  title        = {A fault diagnosis method for wind turbines with limited labeled data based on balanced joint adaptive network},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-level neural network for implicit causality
detection in web texts. <em>NEUCOM</em>, <em>481</em>, 121–132. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining causality from text is a complex and crucial natural language understanding task corresponding to human cognition . Existing studies on this subject can be divided into two categories: feature engineering-based and neural model-based methods. In this paper, we find that the former has incomplete coverage and intrinsic errors but provides prior knowledge, whereas the latter leverages context information but has insufficient causal inference. To address the limitations, we propose a novel causality detection model named MCDN, which explicitly models the causal reasoning process, and exploits the advantages of both methods. Specifically, we adopt multi-head self-attention to acquire semantic features at the word level and develop the SCRN to infer causality at the segment level. To the best of our knowledge, this is the first time the Relation Network is applied with regard to the causality tasks. The experimental results demonstrate that: i) the proposed method outperforms the strong baselines on causality detection; ii) further analysis manifests the effectiveness and robustness of MCDN.},
  archive      = {J_NEUCOM},
  author       = {Shining Liang and Wanli Zuo and Zhenkun Shi and Sen Wang and Junhu Wang and Xianglin Zuo},
  doi          = {10.1016/j.neucom.2022.01.076},
  journal      = {Neurocomputing},
  pages        = {121-132},
  shortjournal = {Neurocomputing},
  title        = {A multi-level neural network for implicit causality detection in web texts},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep reinforcement learning in loop fusion problem.
<em>NEUCOM</em>, <em>481</em>, 102–120. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loops’ execution time and resource consumption are one of the interest points and vital issues in the field of appraising complex scientific or computational algorithms. This issue caused the proposal of Loop performance optimization techniques such as fusion. In the literature, loop fusion merges the loops by taking into account a set of properties associated with the loops or the system on which the resulting code will be executed. The number of these factors and their interactions on the one hand, and the high runtime of available comprehensive approaches, on the other hand, reveals the need for a new method that could be concerned for further progress in solving this NP-hard problem. For the first time, Deep Reinforcement Learning Loop Fusion (DRLLF) advanced to be an ideal solution for the challenge in this article. For the proposed framework, a particular matrix is configured as the inputs of a deep neural network based on the information of the problem, namely data dependencies , data reuse, loops’ types, and computer system’s register size. These randomly generated matrixes are used in the training phase by reinforcement learning to get the imperative experience on predicting a profitable distribution over loops’ various fusion orders. In the evaluations performed, the presented algorithm was able to achieve the same or better performance in terms of speedup rate, comparing with the methods under study, approximately averaged in 7.36 percent better results. The considerable improvement observed in the results, besides the low run time, proves the comprehensiveness and superiority of this approach.},
  archive      = {J_NEUCOM},
  author       = {Mahsa Ziraksima and Shahriar Lotfi and Jafar Razmara},
  doi          = {10.1016/j.neucom.2022.01.032},
  journal      = {Neurocomputing},
  pages        = {102-120},
  shortjournal = {Neurocomputing},
  title        = {Deep reinforcement learning in loop fusion problem},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SegDQ: Segmentation assisted multi-object tracking with
dynamic query-based transformers. <em>NEUCOM</em>, <em>481</em>, 91–101.
(<a href="https://doi.org/10.1016/j.neucom.2022.01.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Object Tracking (MOT) has been one of the most important topics in computer vision. The traditional tracking-by-detection framework of MOT is severely suffered from the poor detection results. In this paper, based on Transformer, we introduce the tracking-by-query MOT framework, and propose to apply semantic segmentation as an auxiliary task to optimize the training of MOT trackers, which addresses more on extracted foreground features. In addition, a feature-dependent dynamic object query (DOQ), instead of a fixed-learned object query (LOQ), is put forward to retrieve the new detections, improving the flexibility and constringency of the framework. We tested our SegDQ method on various scenarios including MOTChallenge 15, 16 and 17 datasets. The experimental results show that it obviously improves the MOTA and IDF1 indexes of tracking results.},
  archive      = {J_NEUCOM},
  author       = {Yating Liu and Tianxiang Bai and Yonglin Tian and Yutong Wang and Jiangong Wang and Xiao Wang and Fei-Yue Wang},
  doi          = {10.1016/j.neucom.2022.01.073},
  journal      = {Neurocomputing},
  pages        = {91-101},
  shortjournal = {Neurocomputing},
  title        = {SegDQ: Segmentation assisted multi-object tracking with dynamic query-based transformers},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Global-guided asymmetric attention network for image-text
matching. <em>NEUCOM</em>, <em>481</em>, 77–90. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-text matching is a vital yet challenging task in the field of vision and language. Unlike previous methods that usually adopt a symmetrical network to independently embed images and sentences into a joint latent space, we propose a novel Global-guided Asymmetric Attention Network (GAAN) to represent the two modalities more comprehensively. Specifically, we first design a Global Information-guided Transformer Encoder (GITE) to effectively mitigate the drawback of the lack of contextual information of the region features. Taking full advantage of the image global information, GITE is able to model the regional relations and region-global relations simultaneously, so as to obtain a more accurate visual representation. Then, we adopt a Textual Self-Attention (TSA) module to explore the word-word relations and produce the context-aware word representations. Finally, we deploy an Image-guided Textual Attention (ITA) module to explore the fine-grained correspondence between image regions and sentence words. By using context-aware visual information to guide textual representation learning , we can build asymmetric connections between vision and language to better exploit textual information. Experimental results on two benchmark datasets including MSCOCO and Flickr30k show that GAAN significantly surpasses state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Dongqing Wu and Huihui Li and Yinge Tang and Lei Guo and Hang Liu},
  doi          = {10.1016/j.neucom.2022.01.042},
  journal      = {Neurocomputing},
  pages        = {77-90},
  shortjournal = {Neurocomputing},
  title        = {Global-guided asymmetric attention network for image-text matching},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Super-k: A piecewise linear classifier based on voronoi
tessellations. <em>NEUCOM</em>, <em>481</em>, 67–76. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voronoi tessellations are used to partition the Euclidean space into polyhedral regions, which are called Voronoi cells. Labeling the Voronoi cells with the class information, we can map any classification problem into a Voronoi tessellation. In this way, the classification problem changes into a query of just finding the enclosing Voronoi cell. In order to accomplish this task, we have developed a new algorithm which generates a labeled Voronoi tessellation that partitions the training data into polyhedral regions and obtains interclass boundaries as an indirect result. It is called Supervised k-Voxels or in short Super-k. We are introducing Super-k as a foundational new algorithm and opening the possibility of a new family of algorithms. In this paper, it is shown via comparisons on certain datasets that the Super-k algorithm has the potential of providing comparable performance of the well-known SVM family of algorithms.},
  archive      = {J_NEUCOM},
  author       = {Rahman Salim Zengin and Volkan Sezer},
  doi          = {10.1016/j.neucom.2022.01.072},
  journal      = {Neurocomputing},
  pages        = {67-76},
  shortjournal = {Neurocomputing},
  title        = {Super-k: A piecewise linear classifier based on voronoi tessellations},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). SEGCN-DCR: A syntax-enhanced event detection framework with
decoupled classification rebalance. <em>NEUCOM</em>, <em>481</em>,
55–66. (<a href="https://doi.org/10.1016/j.neucom.2022.01.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event Detection (ED) is a pivotal sub-task of Event Extraction(EE). It aims to locate triggers and categorize them into specific event types. Recent researches on ED have shown that graph convolutional neural networks with syntactic information can achieve advanced performance. However, these methods ignore the implicit importance score of tokens. This will weaken their ability of identifying trigger words. In addition, due to the long-tailed distribution in the corpus, previous methods perform poorly on sparsely labeled trigger words and are prone to overfitting on densely labeled ones. In this paper, we propose a Syntax-Enhanced GCN framework with a Decoupled Classification Rebalance mechanism (SEGCN-DCR) to address the above issues. Specifically, we exploit a tree-structured module based on dependency structure to reduce the noise by capturing global hierarchical syntactic information , and DCR mechanism to rescale the classifier weights, which makes classifier decision boundaries more reasonable. Experiments on benchmark ACE2005 show that the proposed method acquires state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Bo Hu and Yun Liu and Naiyue Chen and Lifu Wang and Ning Liu and Xing Cao},
  doi          = {10.1016/j.neucom.2022.01.069},
  journal      = {Neurocomputing},
  pages        = {55-66},
  shortjournal = {Neurocomputing},
  title        = {SEGCN-DCR: A syntax-enhanced event detection framework with decoupled classification rebalance},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Distributed adaptive finite-time tracking for multi-agent
systems and its application. <em>NEUCOM</em>, <em>481</em>, 46–54. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the distributed adaptive finite-time control problem for nonlinear multi-agent systems (MASs). The fast practical finite-time criterion is extended to MASs. As such, a distributed adaptive finite-time protocol is established based on the recursion algorithm and neural networks (NNs), which provides a solution to cope with the adaptive finite-time regulate problem. Moreover, the proposed scheme is able to address the singular problem existing in the adaptive fuzzy/NN practical finite-time control. Furthermore, a simpler adaptive law is constructed. Finally, the presented method is applied to multiple robotic systems to illustrate its effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Peiming Li and Xiang Wu and Xiangyong Chen and Jianlong Qiu},
  doi          = {10.1016/j.neucom.2022.01.065},
  journal      = {Neurocomputing},
  pages        = {46-54},
  shortjournal = {Neurocomputing},
  title        = {Distributed adaptive finite-time tracking for multi-agent systems and its application},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling implicit bias with fuzzy cognitive maps.
<em>NEUCOM</em>, <em>481</em>, 33–45. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a Fuzzy Cognitive Map model to quantify implicit bias in structured datasets where features can be numeric or discrete. In our proposal, problem features are mapped to neural concepts that are initially activated by experts when running what-if simulations, whereas weights connecting the neural concepts represent absolute correlation/association patterns between features. In addition, we introduce a new reasoning mechanism equipped with a normalization-like transfer function that prevents neurons from saturating. Another advantage of this new reasoning mechanism is that it can easily be controlled by regulating nonlinearity when updating neurons’ activation values in each iteration. Finally, we study the convergence of our model and derive analytical conditions concerning the existence and unicity of fixed-point attractors.},
  archive      = {J_NEUCOM},
  author       = {Gonzalo Nápoles and Isel Grau and Leonardo Concepción and Lisa Koutsoviti Koumeri and João Paulo Papa},
  doi          = {10.1016/j.neucom.2022.01.070},
  journal      = {Neurocomputing},
  pages        = {33-45},
  shortjournal = {Neurocomputing},
  title        = {Modeling implicit bias with fuzzy cognitive maps},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing representation learning by exploiting effective
receptive fields for object detection. <em>NEUCOM</em>, <em>481</em>,
22–32. (<a href="https://doi.org/10.1016/j.neucom.2022.01.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of state-of-the-art object detectors depend on multiple anchors/reference boxes in representation learning . However, such anchor-based representation does not completely match with the visual information perceived by the sliding windows, thus degrading the overall performance of object detection. In this paper, we present an effective receptive field (eRF)-dependent region proposal network (eRPN) for proposal generation, which enhances the anchor-based representation via eRFs. Specifically, we define an eRF for each sliding window on the feature map and only encode objects within the eRF for unbiasedly representation learning . The size of eRF depends on its backbone network . An eRF-based matching rule is devised and combined with the commonly used IoU rule for pertinent sample selection. We also design an eRF filter module, which can be appended to RPN for eliminating redundant low-quality region proposals in inference time. eRPN enhances representation learning from two perspectives: input information and sample balance, to make generating region proposals more robust. We evaluate eRPN by combining with two commonly used detection heads: Faster RCNN and Faster RCNN w FPN(Faster-FPN). Experimental results on PASCAL VOC dataset and MS COCO dataset benchmarks demonstrate the effectiveness of the proposed method in learning representation for object detection.},
  archive      = {J_NEUCOM},
  author       = {Qijin Wang and Shengyu Zhang and Yu Qian and Guangcai Zhang and Hongqiang Wang},
  doi          = {10.1016/j.neucom.2022.01.020},
  journal      = {Neurocomputing},
  pages        = {22-32},
  shortjournal = {Neurocomputing},
  title        = {Enhancing representation learning by exploiting effective receptive fields for object detection},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatial-temporal 3D dependency matching with self-supervised
deep learning for monocular visual sensing. <em>NEUCOM</em>,
<em>481</em>, 11–21. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular visual sensing is the task of using a camera to estimate the scene depth, optical flow and camera pose. In this paper, we propose a spatial–temporal 3D dependency matching approach that enforces the robustness of continuous frames matching for monocular visual sensing. 3D structure and warped depth based geometry backpropagation are used to encourage jointly learning the view depth, optical flow and camera pose employing a novel self-supervised neural network from monocular sequences. We designed two different iterative convolutional prediction sub-networks, where the optical flow obtained by depth and camera pose is iteratively used for depth prediction. A virtual frame method is proposed to optimize the optical flow of moving objects. The salient feature of the proposed learning framework is completely unsupervised, requiring only consecutive monocular images for training and testing. Evaluation on publicly benchmark datasets shows that our unsupervised learning model significantly outperforms previous methods and achieves better performance compared with previously unsupervised manners and achieves comparable results with supervised ones.},
  archive      = {J_NEUCOM},
  author       = {Chengqun Song and Maolong Niu and Zhaopeng Liu and Jun Cheng and Peng Wang and Hongjian Li and Luoying Hao},
  doi          = {10.1016/j.neucom.2022.01.074},
  journal      = {Neurocomputing},
  pages        = {11-21},
  shortjournal = {Neurocomputing},
  title        = {Spatial-temporal 3D dependency matching with self-supervised deep learning for monocular visual sensing},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SIECP: Neural network channel pruning based on sequential
interval estimation. <em>NEUCOM</em>, <em>481</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pruning is widely regarded as an effective neural network compression and acceleration method, which can significantly reduce model parameters and speed up inference. This paper proposes a novel network Channel Pruning method based on Sequential Interval Estimation (SIECP). Our method mainly solves the problem that existing methods need to sample and evaluate a large number of sub-structures or introduce a large number of parameters, which leads to slow search. Specifically, we divide the entire channel number search process into multiple stages. In each stage, we divide the channel range that needs to be estimated into multiple channel intervals by grouping and use gradient descent to optimize the number of reserved channels. At the same time, the distribution of the number of channels is counted in each interval. At the end of each search stage, we select the channel interval with the highest frequency for further search to gradually narrow the search range until the final number of channels is determined. Then, the unpruned network is pruned according to the number of channels in each layer of the network to obtain the pruned network. Extensive experiments using ResNet and MobileNet V2 as backbones on CIFAR10, CIAFR100 and Tiny-ImageNet datasets are conducted to demonstrate the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Si-Bao Chen and Yu-Jie Zheng and Chris H. Q. Ding and Bin Luo},
  doi          = {10.1016/j.neucom.2022.01.053},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {SIECP: Neural network channel pruning based on sequential interval estimation},
  volume       = {481},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Soft focal loss: Evaluating sample quality for dense object
detection. <em>NEUCOM</em>, <em>480</em>, 271–280. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classic detectors divide the candidate boxes into positive and negative groups based on their intersection-over-union (IoU) with matched objects. Such a sharp label assignment method does not directly consider the distance between the centers of the two boxes. Consequently, some positive samples are ambiguous, which limits the detection performance. In this paper, we propose a new label assignment method by considering two different perspectives. The first perspective is IoU to indicate the degree of overlap. The other one is the defined variable to characterize the center-distance between the candidate box and its matched ground truth. In addition, the classification is usually optimized by Focal Loss for paying more attention to hard examples, but it affects the training of high-quality samples. Therefore, we define the Soft Focal Loss (SFL) and the quality factor that reflects the quality of the samples. Embedding the quality factor into SFL makes the network focus on learning high-quality rather than hard examples. Furthermore, the quality factor is utilized to re-weight the classification and regression losses to enhance the correlation between these two tasks. Experiments on COCO show that the proposed approach can improve RetinaNet by 1.3\% and 1.2\% AP with backbone ResNet-50 and ResNet-101 in 1x training schedule, without incurring any additional overhead.},
  archive      = {J_NEUCOM},
  author       = {Zhenyuan Wang and Xuemei Xie and Jianxiu Yang and Guangming Shi},
  doi          = {10.1016/j.neucom.2021.12.102},
  journal      = {Neurocomputing},
  pages        = {271-280},
  shortjournal = {Neurocomputing},
  title        = {Soft focal loss: Evaluating sample quality for dense object detection},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Global mask r-CNN for marine ship instance segmentation.
<em>NEUCOM</em>, <em>480</em>, 257–270. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance segmentation technology can provide accurate and efficient segmentation methods for visual perception of marine scenes, especially in the development of unmanned ships. However, the community lacks suitable open-source datasets. In order to address the problem of insufficient datasets, an instance segmentation dataset for the marine ship was collected and labeled. Our dataset, named MariShipInsSeg, consists of 4k high-quality visible light marine ship images with 8,413 instances. Due to marine ships being photographed far away, which causes ship objects with less detail information. Therefore, a global method is adopted to make full use of global location and semantic information, which is helpful for ship instance segmentation. We proposed a new method called Global Mask R-CNN (GM R-CNN), which utilized Precise RoI Pooling and Global Mask Head aiming to preserve global information of instances for improving the performance of ship instance segmentation. Experiments on the challenging MS COCO dataset and MariShipInsSeg dataset show that Global Mask R-CNN achieves state-of-the-art performance. Without any bells and whistles, the proposed GM R-CNN achieves 38.7\% mask AP on MS COCO test-dev and 48.6\% mask AP on MariShipInsSeg testing sets, which are gain of 1.6\% and 1.9\% compared with Mask R-CNN.},
  archive      = {J_NEUCOM},
  author       = {Yuxin Sun and Li Su and Yongkang Luo and Hao Meng and Wanyi Li and Zhi Zhang and Peng Wang and Wen Zhang},
  doi          = {10.1016/j.neucom.2022.01.017},
  journal      = {Neurocomputing},
  pages        = {257-270},
  shortjournal = {Neurocomputing},
  title        = {Global mask R-CNN for marine ship instance segmentation},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cost-forced collective potentiality maximization by
complementary potentiality minimization for interpreting multi-layered
neural networks. <em>NEUCOM</em>, <em>480</em>, 234–256. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper aims to propose a new type of information-theoretic method to augment the ratio of collective potentiality to its cost for the interpretation. Collective potentiality represents how many components, such as connection weights or neurons, are collectively used to deal with relations between inputs and outputs, while individual potentiality shows how an individual component potentially contributes to the inputs or outputs. From our viewpoint, the conventional interpretation methods have focused on the individual potentiality of components, ignoring these collective behaviors. Thus, the present paper stresses that neural networks should try to deal with the collective properties of components and to examine the final results from multiple points of view. For implementing this concept of potentiality maximization, we introduce the complementary potentiality minimization, which aims to reduce the strength of larger weights as much as possible, and at the same time, it can be used for increasing the potentiality. The method was applied to two intuitively interpretable data sets, namely, the absenteeism and online shoppers data sets. With both data sets, experimental results confirmed that the method could increase collective potentiality and considerably reduce the corresponding cost. The new method could extract many groups of weights with the same small strength, all of which tried to respond to the coming inputs, while the conventional methods, including the regularization ones, tried to produce a smaller number of stronger connection weights very selectively. In particular, the present method could produce stable compressed weights similar to the original correlation coefficients of the data sets, meaning that simple, independent, and linear relations could be detected, contrary to the presupposed non-linear ones. Thus, the collective interpretation, applied to two business data sets, revealed a possibility that, behind seemingly complicated non-linear relations between inputs and outputs, neural networks with collective potentiality augmentation with a smaller cost can extract the very simple relations for easy interpretation. All complicated relations can possibly be generated, based on those simple ones.},
  archive      = {J_NEUCOM},
  author       = {Ryotaro Kamimura},
  doi          = {10.1016/j.neucom.2022.01.027},
  journal      = {Neurocomputing},
  pages        = {234-256},
  shortjournal = {Neurocomputing},
  title        = {Cost-forced collective potentiality maximization by complementary potentiality minimization for interpreting multi-layered neural networks},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). UULPN: An ultra-lightweight network for human pose
estimation based on unbiased data processing. <em>NEUCOM</em>,
<em>480</em>, 220–233. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most top-performed human pose estimation methods tend to have a high computational load, which is difficult to transform to resource-limited platforms. To conquer this issue, we propose an ultra-lightweight human pose estimation method based on unbiased data processing called UULPN. Firstly, we design a lightweight bottleneck block with a re-parameterized structure. Through simple linear operations, it generates a large number of feature maps and increases the diversity of feature maps. Secondly, we introduce a multi-branch structure and a single-branch structure in the bottleneck block. In the training phase, a multi-branch structure is adopted to increase the prediction accuracy. In the deploying phase, a single-branch structure is used to improve the model inference speed. These two structures realize the decoupling of the training phase and the deployment phase through the reparameterization technology. In the case of decreased computational cost, they have increased the predicted accuracy. Finally, we present a novel unbiased data processing method to solve quantization errors , which are introduced in the process of image encoding and decoding. Extensive experiment results on the MPII and COCO pose estimation benchmarks indicate that UULPN achieves almost equivalent results with the state-of-the-art methods with less computational cost. In particular, the computational cost of UULPN is almost 31\% of HRNet, and the estimated accuracy on the COCO val2017 dataset is up to 74.1\%, which is almost the same as HRNet-W32 at the resolution of 256 × 192. It shows that the research further develops in depth, which is of great significance. The code and the proposed method are available on https://github.com/Johnren1111/UULPN.},
  archive      = {J_NEUCOM},
  author       = {Wenming Wang and Kaixiang Zhang and Haopan Ren and Dejian Wei and Yanyan Gao and Juncheng Liu},
  doi          = {10.1016/j.neucom.2021.12.083},
  journal      = {Neurocomputing},
  pages        = {220-233},
  shortjournal = {Neurocomputing},
  title        = {UULPN: An ultra-lightweight network for human pose estimation based on unbiased data processing},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prescribed performance control of euler–lagrange systems
tracking targets with unknown trajectory. <em>NEUCOM</em>, <em>480</em>,
212–219. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of tracking uncertain target is interesting and challenging. This paper studies the target tracking control problem of Euler–Lagrange system with unknown target trajectory. Fourier series and neural network are utilized to reconstruct the target trajectory, which is mathematically linked with the actual camouflaged target trajectory and facilitates the design and analysis. An error transformation function is introduced and embedded with the Lyapunov function , with which an adaptive tracking control scheme is developed. It is shown that such strategy is able to ensure the tracking error converging to a prescribed compact set containing the origin at a self-defined convergence rate. The simulation results verify the effectiveness of the proposed control method .},
  archive      = {J_NEUCOM},
  author       = {Shilei Tan and Libei Sun and Yongduan Song},
  doi          = {10.1016/j.neucom.2022.01.058},
  journal      = {Neurocomputing},
  pages        = {212-219},
  shortjournal = {Neurocomputing},
  title        = {Prescribed performance control of Euler–Lagrange systems tracking targets with unknown trajectory},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning sub-patterns in piecewise continuous functions.
<em>NEUCOM</em>, <em>480</em>, 192–211. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most stochastic gradient descent algorithms can optimize neural networks that are sub-differentiable in their parameters; however, this implies that the neural network’s activation function must exhibit a degree of continuity which limits the neural network model’s uniform approximation capacity to continuous functions. This paper focuses on the case where the discontinuities arise from distinct sub-patterns, each defined on different parts of the input space. We propose a new discontinuous deep neural network model trainable via a decoupled two-step procedure that avoids passing gradient updates through the network’s only and strategically placed, discontinuous unit. We provide approximation guarantees for our architecture in the space of bounded continuous functions and universal approximation guarantees in the space of piecewise continuous functions which we introduced herein. We present a novel semi-supervised two-step training procedure for our discontinuous deep learning model , tailored to its structure, and we provide theoretical support for its effectiveness. The performance of our model and trained with the propose procedure is evaluated experimentally on both real-world financial datasets and synthetic datasets .},
  archive      = {J_NEUCOM},
  author       = {Anastasis Kratsios and Behnoosh Zamanlooy},
  doi          = {10.1016/j.neucom.2022.01.036},
  journal      = {Neurocomputing},
  pages        = {192-211},
  shortjournal = {Neurocomputing},
  title        = {Learning sub-patterns in piecewise continuous functions},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quadruple tripatch-wise modular architecture-based real-time
structure from motion. <em>NEUCOM</em>, <em>480</em>, 169–191. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structure from motion (SFM), a research hotspot in the intelligent transportation field (including autonomous driving , environmental perception and augmented reality (AR) for artificial intelligence terminals), can automatically recover ego-motion state estimations and 3D scene reconstructions from multiple images or video sequences. Most existing vision methods operate offline in indoor scenes, and their reconstruction accuracies greatly depend on the tracking lifetimes and accuracies of feature points. Reprojection matrix and redundant regression noise computations are exponential disasters for the calculation and reconstruction drift of large-scale scenes. This paper proposes a quadruple tripatch-wise modular architecture (QTMA) for autonomous vehicle stereo image sequences that decomposes rigid scenes into nonrigid motion-segmented pieces for reconstruction. An advanced energy function for salient image features is established by combining multiple feature types with weighted finite-element mesh. Closed quadruple annular matching and relocation are performed via multiresolution pyramid images. The proposed incremental integral-mapping calculation method and unique tree-like stacked storage containers prolong the tracking lifetimes of consecutive frames and ensure the spatiotemporal consistency and robustness of the homonymous image features in different subsequences. Experimental results verify the effectiveness of this architecture for different transportation scenes; the frame rate processing speed reaches 30 fps, the calculation accuracy regarding the path distance difference reaches 99.49\%, and the estimation results regarding the maximum speeds of motion are closer to the ground truth. The translation error of the motion pose is 0.0136\%, and the rotation error is 0.0035 [deg/m], which has more yaw stability than the existing state-of-the-art methods. Furthermore, in the reconstructed point cloud quality demonstration, the mean value of roughness is reduced by 40.127\%, the mean value of density is improved by 27.701\%, and the accuracy reaches 91.149\% within a certain distance tolerance. This paper has significant theoretical research value and application potential for positioning, path tracking, and navigation in adaptive cruise control (ACC) and advanced driver assistance systems (ADAS).},
  archive      = {J_NEUCOM},
  author       = {Ling Bai and Yinguo Li and Thia Kirubarajan and Xinbo Gao},
  doi          = {10.1016/j.neucom.2022.01.071},
  journal      = {Neurocomputing},
  pages        = {169-191},
  shortjournal = {Neurocomputing},
  title        = {Quadruple tripatch-wise modular architecture-based real-time structure from motion},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-scale and multi-channel neural network for
click-through rate prediction. <em>NEUCOM</em>, <em>480</em>, 157–168.
(<a href="https://doi.org/10.1016/j.neucom.2022.01.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-through rate (CTR) prediction aims to predict the probability of a user clicking on items and ads. Feature engineering plays an important role in improving the accuracy of CTR predict ion because features are normally multi-field. Recently, existing neural network based approaches mostly focus on the feature interactions in both low- and high-order. However, this methodology ignores salient features in both local and global contexts and diverse semantic features in various aspects. In this paper, we propose a novel framework called Multi-Scale and Multi-Channel neural network (MSMC) to learn the feature importance and feature semantics for enhancing CTR prediction. MSMC consists of two parallel modules: a salient feature encoder (SFE) and a diverse semantic feature encoder (DFE). The SFE employs an attentive global–local contexts module to extract the salient features. The DFE uses an attentive semantic module to aggregate the diverse semantic features . Then, a fusion function is adopted to adaptively combine features from the SFE and the DFE so as to obtain high-order feature interactions. Experimental results on two public real datasets illustrate the effectiveness of MSMC compared to the state-of-the-art CTR prediction methods. Our extensive analysis of MSMC shows how the salient features, diverse semantic features, and fusion function positively impact the performance of CTR prediction.},
  archive      = {J_NEUCOM},
  author       = {Jinjin Zhang and Chenhui Ma and Chengliang Zhong and Peng Zhao and Xiaodong Mu},
  doi          = {10.1016/j.neucom.2022.01.035},
  journal      = {Neurocomputing},
  pages        = {157-168},
  shortjournal = {Neurocomputing},
  title        = {Multi-scale and multi-channel neural network for click-through rate prediction},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiple birth support vector machine based on dynamic
quantum particle swarm optimization algorithm. <em>NEUCOM</em>,
<em>480</em>, 146–156. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the parameters of the multiple birth support vector machine (MBSVM) are mainly determined by experience or artificially specified by the grid method. Both of these methods rely too much on the experience value, which is easy to cause the selection of the parameter value to be insufficient. The selection of parameters directly affects the performance of MBSVM, so how to find a set of optimal parameters plays a vital role in improving the performance of MBSVM. To solve this problem, a dynamic quantum particle swarm optimization algorithm (DQPSO) was proposed. Focusing on the contraction – expansion (CE) coefficient control mode, authors propose the concept of the ability factor of particle search and realize the dynamic regulation of CE coefficient by taking it as feedback. Then DQPSO algorithm is used to optimize the parameters of MBSVM. The experimental results show that the proposed DQPSO algorithm has better optimization performance and faster convergence speed than that of the classical QPSO. Meanwhile, experiments on the UCI datasets show that the proposed DQPSO-MBSVM algorithm is effective to improve the classification performance of MBSVM.},
  archive      = {J_NEUCOM},
  author       = {Shifei Ding and Zichen Zhang and Yuting Sun and Songhui Shi},
  doi          = {10.1016/j.neucom.2022.01.012},
  journal      = {Neurocomputing},
  pages        = {146-156},
  shortjournal = {Neurocomputing},
  title        = {Multiple birth support vector machine based on dynamic quantum particle swarm optimization algorithm},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TCCT: Tightly-coupled convolutional transformer on time
series forecasting. <em>NEUCOM</em>, <em>480</em>, 131–145. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is essential for a wide range of real-world applications. Recent studies have shown the superiority of Transformer in dealing with such problems, especially long sequence time series input (LSTI) and long sequence time series forecasting (LSTF) problems. To improve the efficiency and enhance the locality of Transformer, these studies combine Transformer with CNN in varying degrees. However, their combinations are loosely-coupled and do not make full use of CNN. To address this issue, we propose the concept of tightly-coupled convolutional Transformer (TCCT) and three TCCT architectures which apply transformed CNN architectures into Transformer: (1) CSPAttention: through fusing CSPNet with self-attention mechanism, the computation cost of self-attention mechanism is reduced by 30\% and the memory usage is reduced by 50\% while achieving equivalent or beyond prediction accuracy. (2) Dilated causal convolution: this method is to modify the distilling operation proposed by Informer through replacing canonical convolutional layers with dilated causal convolutional layers to gain exponentially receptive field growth. (3) Passthrough mechanism: the application of passthrough mechanism to stack of self-attention blocks helps Transformer-like models get more fine-grained information with negligible extra computation costs. Our experiments on real-world datasets show that our TCCT architectures could greatly improve the performance of existing state-of-the-art Transformer models on time series forecasting with much lower computation and memory costs, including canonical Transformer, LogTrans and Informer.},
  archive      = {J_NEUCOM},
  author       = {Li Shen and Yangzhu Wang},
  doi          = {10.1016/j.neucom.2022.01.039},
  journal      = {Neurocomputing},
  pages        = {131-145},
  shortjournal = {Neurocomputing},
  title        = {TCCT: Tightly-coupled convolutional transformer on time series forecasting},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge embedding via hyperbolic skipped graph
convolutional networks. <em>NEUCOM</em>, <em>480</em>, 119–130. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the aim of constructing a low-dimensional representation space, Hyperbolic Knowledge Embeddings have gradually become a hot spot in various information retrieval and machine learning tasks. However, most of the existing Hyperbolic knowledge embedding methods focus on the shallow embedding, and often ignore the network structure characteristics (e.g., hierarchy) of Knowledge Graphs. Therefore, this paper designs a novel Hyperbolic Skipped Knowledge Graph Convolutional Network, HSKGCN, to improve link prediction accuracy with low embedding dimension requirements. Firstly, the model is designed based on the hyperbolic geometric operations on the Poincaré ball, which can effectively utilize the characteristics of the hyperbolic geometry (e.g., Poincaré ball) to capture the hierarchy of Knowledge Graphs; Secondly, each single-layer convolutional layer introduces the feature aggregation weight, which ensures the reasonable distribution of node features during the aggregation process; In addition, the skip-connection mechanism is applied to HSKGCN to weaken the information loss caused by the stacked of the graph convolutional layers; Finally, we evaluate HSKGCN on benchmark datasets, WN18RR and FB15k-237. Experiments show that HSKGCN achieves substantial improvements against state-of-the-art models on the 32-dimensional embedding task, and the results of different relations on WN18RR show graphs similar with tree topology can performer better.},
  archive      = {J_NEUCOM},
  author       = {Shuanglong Yao and Dechang Pi and Junfu Chen},
  doi          = {10.1016/j.neucom.2022.01.037},
  journal      = {Neurocomputing},
  pages        = {119-130},
  shortjournal = {Neurocomputing},
  title        = {Knowledge embedding via hyperbolic skipped graph convolutional networks},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unified framework for multi-modal federated learning.
<em>NEUCOM</em>, <em>480</em>, 110–118. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a machine learning setting that separates data and protects user privacy. Clients learn global models together without data interaction. However, due to the lack of high-quality labeled data collected from the real world, most of the existing FL methods still rely on single-modal data. In this paper, we consider a new problem of multimodal federated learning. Although multimodal data always benefits from the complementarity of different modalities, it is difficult to solve the multimodal FL problem with traditional FL methods due to the modality discrepancy. Therefore, we propose a unified framework to solve it. In our framework, we use the co-attention mechanism to fuse the complementary information of different modalities. Our enhanced FL algorithm can learn useful global features of different modalities to jointly train common models for all clients. In addition, we use a personalization method based on Model-Agnostic Meta-Learning(MAML) to adapt the final model for each client. Extensive experimental results on multimodal activity recognition tasks demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Baochen Xiong and Xiaoshan Yang and Fan Qi and Changsheng Xu},
  doi          = {10.1016/j.neucom.2022.01.063},
  journal      = {Neurocomputing},
  pages        = {110-118},
  shortjournal = {Neurocomputing},
  title        = {A unified framework for multi-modal federated learning},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gaussian process image classification based on multi-layer
convolution kernel function. <em>NEUCOM</em>, <em>480</em>, 99–109. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification is an important research field of computer vision. Traditional image classification requires manual design of feature extraction methods, and the accuracy of classification is closely related to the selected feature extraction methods. With the rapid development of network multimedia technology, the number of images that need to be classified becomes larger and it is more complex to classify the images. The manual design of feature extraction methods not only consumes time, but also lowers the accuracy. The accuracy of image classification using deep learning methods can reach or even exceed the level of manual classification. In this paper, we first propose an average weight selective kernel networks (AWSKnet) model. The idea of ensemble learning is introduced into selective kernel networks (SKnet) to construct AWSKnet, integrating the features of convolution layer learning. It makes the features learned in the convolution layer more discriminative and confluent, which enhances the feature training effect of network. Second, we use the basic solution of a generalized differential operator to generate a base kernel function in the H 1 H1 space and use the multi-layer strategy of deep learning to construct the multi-layer convolution kernel in the H 2 H2 and H 3 H3 space by using the base kernel functions in the H 1 H1 space.Finally, we use the AWSKnet network model to learn the characteristics of the image data, and then use the Gaussian process classifier based on the multi-layer convolution kernel function (MKGPC) to perform image classification experiments on the CIFAR-10, SVHN and MNIST datasets. An experimental analysis on three public image datasets shows that our methods outperform all state-of-the-art image classification models we use for comparison.},
  archive      = {J_NEUCOM},
  author       = {Lixiang Xu and Biao Zhou and Xinlu Li and Zhize Wu and Yan Chen and Xiaofeng Wang and Yuanyan Tang},
  doi          = {10.1016/j.neucom.2022.01.048},
  journal      = {Neurocomputing},
  pages        = {99-109},
  shortjournal = {Neurocomputing},
  title        = {Gaussian process image classification based on multi-layer convolution kernel function},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Partner learning: A comprehensive knowledge transfer for
vehicle re-identification. <em>NEUCOM</em>, <em>480</em>, 89–98. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intra-class variability and inter-class similarity challenges caused by diverse viewpoints, illumination, and similar appearances are crucial in Re-Identification (Re-ID). Previous vehicle Re-ID methods propose to mine more discriminate and fine-grained clues for alleviating the problem, which costs extra computation and time during inference since the use of additional modules, e.g., detection modules, segmentation modules, or attention modules. We propose a multi-branch architecture to mining the discriminative and fine-grained information without additional time and computation cost during inference. Specifically, we focus on three problems: 1) how can knowledge transfer among multi-branches; 2) what knowledge should be utilized for more effective and more functional transfer; 3) where can be used as the input of multi-branches? For the first problem, we introduce a novel complementary learning scheme named partner learning which transfers the knowledge between global and local branches, and thus we only need the global branch during inference. For the second problem, we propose a hierarchical structural knowledge transfer (HSKT) approach to mine knowledge from partners in three different levels hierarchically. For the last problem, to effectively mine more fine-grained clues, we propose two local specifications: one supervised with the specification of the window area being discriminatively crucial as an expert knowledge while the other unsupervised with horizontal stripe cuts. Extensive ablation studies and experimental result discussions show the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Wen Qian and Zhiqun He and Chen Chen and Silong Peng},
  doi          = {10.1016/j.neucom.2022.01.043},
  journal      = {Neurocomputing},
  pages        = {89-98},
  shortjournal = {Neurocomputing},
  title        = {Partner learning: A comprehensive knowledge transfer for vehicle re-identification},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PLAM: A plug-in module for flexible graph attention
learning. <em>NEUCOM</em>, <em>480</em>, 76–88. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Networks (GCNs) are general deep representation learning models for graph-structured data. In this paper, we propose a simple Plug-in Attention Module (PLAM) to improve the representation power of GCNs, inspired by the recent success of the query-key mechanism in computer vision and natural language processing . With this module, our network is able to adaptively learn the weights from a node towards its neighbors. Different from existing attention-based GCNs, the proposed PLAM has several important properties. First, the parameter space for the attention module is isolated from that for feature learning. This ensures that the proposed approach can be conveniently applied to existing GCNs as a plug-in module. Second, the anchor node and neighbor nodes are treated separately when learning the attention weights, which further enhances the flexibility of our structure. Third, our attention module extracts higher-level information by computing the inner product of the features between the anchor node and neighbor nodes, leading to significantly increased representation power. Last, we take a step forward and propose a novel structural encoding technique for the graph attention module to inject local and global structure information. Although being simple, our PLAM models have achieved state-of-the-art performances on graph-structured datasets under both the transductive and inductive settings. Additionally, experiments on image and point cloud datasets show potential applications of PLAM on several computer vision tasks .},
  archive      = {J_NEUCOM},
  author       = {Xuran Pan and Shiji Song and Yiming Chen and Liejun Wang and Gao Huang},
  doi          = {10.1016/j.neucom.2022.01.045},
  journal      = {Neurocomputing},
  pages        = {76-88},
  shortjournal = {Neurocomputing},
  title        = {PLAM: A plug-in module for flexible graph attention learning},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodal medical image fusion based on multichannel
coupled neural p systems and max-cloud models in spectral total
variation domain. <em>NEUCOM</em>, <em>480</em>, 61–75. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image fusion technology can integrate the positive attributes of images from different imaging devices such that the fusion image contains rich and nonredundant information. Existing fusion images typically suffer from problems of color distortion, detail loss, and poor noise robustness. In this study, a medical image fusion algorithm based on spectral total variation (STV) is proposed to address these problems. First, the base and residual layers of the input images to be fused was acquired using STV. Subsequently, a Max-cloud fusion model was proposed to fuse the base layers, and the energy and contrast brightness information was effectively processed. A multichannel coupled neural P system was proposed to overcome the shortcomings of the single-channel model for the residual layers. Finally, the fused image was reconstructed. Numerous experiments with and without noise were performed, and qualitative and quantitative comparisons were made with the classical fusion methods. The experimental results indicate that the proposed medical image fusion algorithm is more effective and provides clearer edge details, higher luminance, and superior colors, exhibiting higher robustness than the other classical 11 fusion methods.},
  archive      = {J_NEUCOM},
  author       = {Guofen Wang and Weisheng Li and Xinbo Gao and Bin Xiao and Jiao Du},
  doi          = {10.1016/j.neucom.2022.01.059},
  journal      = {Neurocomputing},
  pages        = {61-75},
  shortjournal = {Neurocomputing},
  title        = {Multimodal medical image fusion based on multichannel coupled neural p systems and max-cloud models in spectral total variation domain},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dual-stream collaborative tracking algorithm combined with
reliable memory based update. <em>NEUCOM</em>, <em>480</em>, 39–60. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most visual tracking algorithms based on Siamese network adopt a fixed template in the whole tracking process, which sacrifices the available target appearance information. To address this issue, we propose a dual-stream collaborative tracking algorithm combined with reliable memory based update in this paper. Specifically, we first conduct a multi-task convolutional network consisting of convolutional kernel fusion and semantic integration , hence enhancing the discriminability of the convolutional model. Secondly, a reliable template storage policy is developed to establish a dynamic memory queue that carries available appearance information. In addition, to improve the template adaptability against appearance variation, we train a dynamic update network by serving the memory queue as samples, thereby realizes the adaptive update of the object template. Finally, a dual-stream collaborative tracking framework is proposed to integrate the matching results of the initial branch and the updated branch in the response layer, which alleviates the limited representation problems with the fixed template. We perform a thorough performance evaluation on the OTB2013, OTB2015, DTB70, Temple-Color-128, VOT2016, VOT2018, UAV20L and LaSOT benchmarks. Extensive experimental results show that our proposed method outperforms several state-of-the-art algorithms and achieves real-time operations.},
  archive      = {J_NEUCOM},
  author       = {Yi Zhang and Guixi Liu and Hanlin Huang and Ruke Xiong and Haoyang Zhang},
  doi          = {10.1016/j.neucom.2022.01.046},
  journal      = {Neurocomputing},
  pages        = {39-60},
  shortjournal = {Neurocomputing},
  title        = {Dual-stream collaborative tracking algorithm combined with reliable memory based update},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On multi-agent cognitive cooperation: Can virtual agents
behave like humans? <em>NEUCOM</em>, <em>480</em>, 27–38. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individuals tend to cooperate or collaborate to reach a common goal when the going gets tough creating a common frame of reference that is a common mental representation of the situation. Information exchange among people is fundamental for building a shared strategy through the grounding process that exploits different communication channels like vision, haptic, or voice. Indeed, human perception is typically multi-modal. This work proposes a two-fold study investigating the cognitive collaboration process both among humans and virtual agents of a multi-agent reinforcement learning (MARL) system. The experiment with humans consists of an interactive virtual shared environment that uses multi-modal channels (visual and haptics) as interaction cues. Haptic feedback is fundamental for a good sense of presence and for improving the performance in completing a task. In this manuscript, an experiment, consisting of escaping a virtual maze trying to get the best score possible, is introduced. The experiment is meant to be performed in pairs, and the perceptual information is split among the participants. A custom haptic interface has been used for the interaction with the virtual environment. The machine learning case, instead, proposes two virtual agents implemented using a tabular Q-learning paradigm to control a single avatar in a 2D labyrinth, introducing a new form of MARL setting. As it is known, it is not easy to get familiar with haptics for people that have never used it, and that if not properly transmitted, the cognitive workflow does not produce any improvements. However, the main findings of the proposed work are that haptic-driven multi-modal feedback information is a valuable means of collaboration since it allows to establish a common frame of reference between the two participants. The machine learning experiments show that even independent agents, implemented with properly designed rewards, can learn the intentions of the other participant in the same environment and collaborate to accomplish a common task.},
  archive      = {J_NEUCOM},
  author       = {Salvatore D’Avella and Gerardo Camacho-Gonzalez and Paolo Tripicchio},
  doi          = {10.1016/j.neucom.2022.01.025},
  journal      = {Neurocomputing},
  pages        = {27-38},
  shortjournal = {Neurocomputing},
  title        = {On multi-agent cognitive cooperation: Can virtual agents behave like humans?},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A 2.5D semantic segmentation of the pancreas using attention
guided dual context embedded u-net. <em>NEUCOM</em>, <em>480</em>,
14–26. (<a href="https://doi.org/10.1016/j.neucom.2022.01.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic segmentation of the pancreas from medical images is important for clinical assessment of pancreas-related diseases. However, pancreatic segmentation based on computer tomography (CT) images is time-consuming and prone to errors because of the variances in shape and texture. Since various studies based on 2D/3D convolution neural networks (CNNs) have achieved encouraging performance for medical image segmentation, the 2D methods enjoy low inference time but suffer from a lack of 3D information. 3D methods are superior in performance for difficult targets requiring contextual information, but encounter the issue of high computational cost. Thus, we proposed a 2.5D segmentation method for pancreatic segmentation to balance utilizing contextual information and the high computational cost. This represents the 3D structural relationship among contiguous slices in a special representation. In the preprocessing stage, light-weight 3D voxels and the corresponding label mapping method were designed to explicitly express the differences in the target structure in contiguous slices. This would enable the network to learn spatial relationships directly. A 2D CNN embedded multi-attention mechanism and dual-context feature fusion method were designed to describe 3D information through 2D operations. In the post-processing stage, a fusion method was used to refine the segmentation results. The proposed method was evaluated on an abdominal contrast-enhanced CT dataset. Results showed Dice was 87.19\%. Compared to the corresponding 2D and 3D methods, the proposed 2.5D method improved Dice by 1.14\% and 2.80\%, and was 60 times faster than the 3D method by using 0.1 times of the trainable parameters. Moreover, evaluations were performed on the NIH Pancreas-CT dataset, and the proposed 2.5D method achieved better segmentation performance than state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Jingyuan Li and Guanqun Liao and Wenfang Sun and Ji Sun and Tai Sheng and Kaibin Zhu and Karen M. von Deneen and Yi Zhang},
  doi          = {10.1016/j.neucom.2022.01.044},
  journal      = {Neurocomputing},
  pages        = {14-26},
  shortjournal = {Neurocomputing},
  title        = {A 2.5D semantic segmentation of the pancreas using attention guided dual context embedded U-net},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pixel-accurate road crack detection in presence of
inaccurate annotations. <em>NEUCOM</em>, <em>480</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent road crack detection methods obtain appealing scores but typically allow a few pixel tolerance margin. This is acceptable for locating cracks, but not for measuring their width (indicator of the cracks’ severity). Our baseline model , U-VGG19, obtains an F-score of 71.77\% on CrackForest, which is superior to other approaches when no tolerance is admitted. However, increasing the scores without tolerance is difficult due to inaccurate annotations. We propose a novel synthetic dataset , Syncrack, as a benchmark for the evaluation of training with inaccurate annotations. Our results show that inaccurate annotations have a detrimental impact on the F-measure, decreasing it by up to 20\%. To overcome this, we study label noise correction techniques using weakly supervised learning. Training U-VGG19 with these corrected labels improves the results on Syncrack by up to 12\%. Obtained results on the CrackForest and Aigle-RN datasets support that these approaches are useful for real-life data too.},
  archive      = {J_NEUCOM},
  author       = {Rodrigo Rill-García and Eva Dokladalova and Petr Dokládal},
  doi          = {10.1016/j.neucom.2022.01.051},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {Pixel-accurate road crack detection in presence of inaccurate annotations},
  volume       = {480},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PRL: A game theoretic large margin method for interpretable
feature learning. <em>NEUCOM</em>, <em>479</em>, 106–120. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The crucial role played by interpretability in many practical scenarios has led a large part of the research on machine learning towards the development of interpretable approaches. In this work, we present PRL, a game-theory-based method capable of achieving state-of-the-art accuracy, yet keeping the focus on the interpretability of the predictions. The proposed approach is an instance of the more general preference learning framework. By design, the method identifies the most relevant features even when dealing with high-dimensional problems. This is possible thanks to an online features generation mechanism. Moreover, the algorithm is proven to be theoretically well-founded, thanks to a game-theoretical analysis of its convergence. To assess the quality of the proposed approach, we compared PRL against state-of-the-art methods in a plethora of different classification settings. The experimental evaluation focuses on interpretability, with an in-depth analysis of visualization, feature selection, and explainability.},
  archive      = {J_NEUCOM},
  author       = {Mirko Polato and Guglielmo Faggioli and Fabio Aiolli},
  doi          = {10.1016/j.neucom.2022.01.016},
  journal      = {Neurocomputing},
  pages        = {106-120},
  shortjournal = {Neurocomputing},
  title        = {PRL: A game theoretic large margin method for interpretable feature learning},
  volume       = {479},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). From implicit to explicit feedback: A deep neural network
for modeling sequential behaviours and long-short term preferences of
online users. <em>NEUCOM</em>, <em>479</em>, 89–105. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we examine the advantages of using multiple types of behaviours in recommendation systems. Intuitively, each user often takes some implicit actions (e.g., click) before making an explicit decision (e.g., purchase). Previous studies show that implicit and explicit feedback has different roles for a useful recommendation. However, these studies either exploit implicit and explicit behaviours separately or ignore the semantics of sequential interactions between users and items. In addition, we go from the hypothesis that a user’s preferences at a time are combinations of long-term and short-term interests. In this paper, we propose some Deep Learning architectures. The first one is Implicit to Explicit (ITE) , to exploit users’ interests through the sequence of their actions. The second and third ones are two versions of ITE with Bidirectional Encoder Representations from Transformers based (BERT-based) architecture called BERT-ITE and BERT-ITE-Si , which combine users’ long- and short-term preferences without and with side information to enhance users’ representations. The experimental results show that our models outperform previous state-of-the-art ones and also demonstrate our views on the effectiveness of exploiting the implicit to explicit order as well as combining long- and short-term preferences in three large-scale datasets. The source code of our paper is available at: https://github.com/tranquyenbk173/BERT_ITE.},
  archive      = {J_NEUCOM},
  author       = {Quyen Tran and Lam Tran and Linh Chu Hai and Ngo Van Linh and Khoat Than},
  doi          = {10.1016/j.neucom.2022.01.023},
  journal      = {Neurocomputing},
  pages        = {89-105},
  shortjournal = {Neurocomputing},
  title        = {From implicit to explicit feedback: A deep neural network for modeling sequential behaviours and long-short term preferences of online users},
  volume       = {479},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PDR-net: Progressive depth reconstruction network for color
guided depth map super-resolution. <em>NEUCOM</em>, <em>479</em>, 75–88.
(<a href="https://doi.org/10.1016/j.neucom.2022.01.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low spatial resolution is a common problem for depth maps captured by low-cost consumer depth cameras. Depth map super-resolution (DMSR) can improve the quality of depth maps, but it is an ill-posed problem with many challenges. This paper proposes a progressive depth reconstruction network (PDR-Net) to further enhance the performance of DMSR. Specifically, we design an adaptive feature recombination module to recombine depth and color guidance features. We generate sufficient information from the recombined features with the proposed multi-scale feature fusion module, in which multi-scale feature distillation and joint attention mechanism are employed. We learn high frequency compensations for each up-interpolating and reconstruct corresponding high resolution depth maps in the proposed progressive depth reconstruction module. Experimental results with benchmark datasets verified the proposed method’s superiority over the state-of-the-art DMSR methods.},
  archive      = {J_NEUCOM},
  author       = {Peng Liu and Zonghua Zhang and Zhaozong Meng and Nan Gao and Chao Wang},
  doi          = {10.1016/j.neucom.2022.01.050},
  journal      = {Neurocomputing},
  pages        = {75-88},
  shortjournal = {Neurocomputing},
  title        = {PDR-net: Progressive depth reconstruction network for color guided depth map super-resolution},
  volume       = {479},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SCAN: A shared causal attention network for adverse drug
reactions detection in tweets. <em>NEUCOM</em>, <em>479</em>, 60–74. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twitter is a popular social media site on which people post millions of Tweets every day. As patients often share their experiences with drugs on Twitter, Tweets can also be considered as a rich alternative source of adverse drug reaction (ADR)-related information. This information can be useful for health authorities and drug manufacturing companies to monitor the post-marketing effectiveness of drugs. However, the automatic detection of ADRs in Tweets is challenging, as Tweets are informal and prone to grammatical errors. The existing approaches to automatically detecting ADRs do not consider the cause-effect relationships between a drug and an ADR. In this paper, we propose a novel shared causal attention network that exploits such cause-effect relationships to detect ADRs in Tweets. In our approach, we split a Tweet into the prefix, midfix, and postfix segments based on the position of the drug name in the Tweet and separately extract causal features from the segments. We then share these separate causal features with both word and parts-of-speech features, and apply the multi-head self-attention mechanism. We run extensive experiments on three publicly available benchmark datasets to illustrate the effectiveness of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Humayun Kayesh and Md. Saiful Islam and Junhu Wang and Ryoma Ohira and Zhe Wang},
  doi          = {10.1016/j.neucom.2022.01.019},
  journal      = {Neurocomputing},
  pages        = {60-74},
  shortjournal = {Neurocomputing},
  title        = {SCAN: A shared causal attention network for adverse drug reactions detection in tweets},
  volume       = {479},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). SRDiff: Single image super-resolution with diffusion
probabilistic models. <em>NEUCOM</em>, <em>479</em>, 47–59. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single image super-resolution (SISR) aims to reconstruct high-resolution (HR) images from given low-resolution (LR) images. It is an ill-posed problem because one LR image corresponds to multiple HR images. Recently, learning-based SISR methods have greatly outperformed traditional methods. However, PSNR-oriented, GAN-driven and flow-based methods suffer from over-smoothing, mode collapse and large model footprint issues, respectively. To solve these problems, we propose a novel SISR diffusion probabilistic model (SRDiff), which is the first diffusion-based model for SISR. SRDiff is optimized with a variant of the variational bound on the data likelihood. Through a Markov chain , it can provide diverse and realistic super-resolution (SR) predictions by gradually transforming Gaussian noise into a super-resolution image conditioned on an LR input. In addition, we introduce residual prediction to the whole framework to speed up model convergence. Our extensive experiments on facial and general benchmarks (CelebA and DIV2K datasets) show that (1) SRDiff can generate diverse SR results with rich details and achieve competitive performance against other state-of-the-art methods, when given only one LR input; (2) SRDiff is easy to train with a small footprint(The word “footprint” in this paper represents “model size” (number of model parameters).); (3) SRDiff can perform flexible image manipulation operations, including latent space interpolation and content fusion.},
  archive      = {J_NEUCOM},
  author       = {Haoying Li and Yifan Yang and Meng Chang and Shiqi Chen and Huajun Feng and Zhihai Xu and Qi Li and Yueting Chen},
  doi          = {10.1016/j.neucom.2022.01.029},
  journal      = {Neurocomputing},
  pages        = {47-59},
  shortjournal = {Neurocomputing},
  title        = {SRDiff: Single image super-resolution with diffusion probabilistic models},
  volume       = {479},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decentralized AdaBoost algorithm over sensor networks.
<em>NEUCOM</em>, <em>479</em>, 37–46. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the decentralized AdaBoost problem over sensor networks, and propose a fully decentralized AdaBoost algorithm , where each sensor can obtain the centralized global solution without transmission of private dataset. By decomposing the centralized cost function into a summation of local ones, we convert decentralized AdaBoost problem into a distributed optimization problem, and design a distributed alternating minimization method to solve it. In order to improve convergence rate, motivated by Nesterov gradient descent method , we propose a fast decentralized AdaBoost algorithm. Then, we prove the convergence of proposed algorithms. Moreover, we deduce decentralized AdaBoost algorithm for logistic regression in detail. The simulations with Spam-Email dataset illustrate the effectiveness of proposed algorithms.},
  archive      = {J_NEUCOM},
  author       = {Xibin An and Chen Hu and Zhenhua Li and Haoshen Lin and Gang Liu},
  doi          = {10.1016/j.neucom.2022.01.015},
  journal      = {Neurocomputing},
  pages        = {37-46},
  shortjournal = {Neurocomputing},
  title        = {Decentralized AdaBoost algorithm over sensor networks},
  volume       = {479},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning two groups of discriminative features for
micro-expression recognition. <em>NEUCOM</em>, <em>479</em>, 22–36. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a branch of affective computing and machine learning, recognizing micro-expressions is more difficult than recognizing macro-expressions because micro-expression has a small motion and short duration. A large number of features and methods have been proposed, and feature extraction is a critical focus of research. For improving performance, feature fusion is an effective strategy that involves two groups of features, and two groups of features usually have some differences, such as discriminability, distribution and dimension. In addition, the extracted features usually have redundant or misleading feature information. Thus, before feature fusion, an algorithm that can automatically learn and select discriminative features from two groups of different features is needed. In this paper, we propose a kernelized two-groups sparse learning (KTGSL) model to automatically learn more discriminative features from two groups of features. We propose two learning strategies to learn the weights: one is that the weights of one group of features are fixed and don’t be learned; the other one is that both groups of weights are learned and the two are given to different penalty coefficients, which can flexibly adjust the interrelation between the two groups of features by adjusting the two penalty coefficients. This work is the first one to select discriminative features from two groups of features in micro-expression recognition. The experiments are conducted on three datasets (CASME II, SMIC and SAMM). The experimental results show that our method can automatically select discriminative features from two groups of features and achieve state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Jinsheng Wei and Guanming Lu and Jingjie Yan and Yuan Zong},
  doi          = {10.1016/j.neucom.2021.12.088},
  journal      = {Neurocomputing},
  pages        = {22-36},
  shortjournal = {Neurocomputing},
  title        = {Learning two groups of discriminative features for micro-expression recognition},
  volume       = {479},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-task learning framework for end-to-end aspect
sentiment triplet extraction. <em>NEUCOM</em>, <em>479</em>, 12–21. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect sentiment triplet extraction (ASTE) is a significant and challenging task in aspect-based sentiment analysis, which aims to summarize people’s opinions by extracting triplets consisting of opinion targets, opinion expressions, and sentiment polarities. In this paper, we propose a novel multi-task learning framework to achieve end-to-end ASTE. We decompose ASTE into three subtasks, namely target tagging, opinion tagging, and sentiment tagging. In target tagging and opinion tagging, we adopt the BIO tagging scheme to detect the boundaries of opinion targets and opinion expressions. In sentiment tagging, we introduce a target-aware tagging scheme, which utilizes a series of target-specific tag sequences to identify the correspondences between opinion targets and opinion expressions, and determine their sentiment polarities. We conduct extensive experiments on four benchmark datasets. The experimental results show that our framework achieves consistently superior results. Compared with existing methods, our method has better performance in extracting overlapping triplets and identifying long-range correspondences. Further analysis demonstrates the effectiveness of our framework.},
  archive      = {J_NEUCOM},
  author       = {Fang Chen and Zhongliang Yang and Yongfeng Huang},
  doi          = {10.1016/j.neucom.2022.01.021},
  journal      = {Neurocomputing},
  pages        = {12-21},
  shortjournal = {Neurocomputing},
  title        = {A multi-task learning framework for end-to-end aspect sentiment triplet extraction},
  volume       = {479},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Ensembling perturbation-based oversamplers for imbalanced
datasets. <em>NEUCOM</em>, <em>479</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oversampling is effective to handle imbalanced data and is often combined with ensemble learning to boost its performance, for examples the synthetic minority oversampling technique (SMOTE) and its ensemble variants SMOTEBagging and SMOTEBoost. However, SMOTE-based methods often introduce unnecessary noises when classes are not well separated, which may impinge upon classifier training and hinder the classification performance. In addition, the aggressive generation of SMOTE-based methods would further complicate the learning process. Therefore, we propose a simple yet effective approach to generate diverse instances to balance the class distribution in a more conservative way in this work. Major differences among the proposed method and existing methods, which also highlight the originality of this work, are listed as follows. Firstly, unlike existing methods which utilize nearest neighbors-based methods to determine regions of interest, we analyze and compute the impact of class imbalance quantitatively for each minority instance in order to guide the data generation process. This ensures instances can be synthesized in a safe and informative region to avoid noise generation. Secondly, new instances are generated via perturbing a random subsets of input features of given seed instances. We show that this process generates instances that share the same asymptotic mean and covariance as given seed instances, thus classifiers with high generalization capability can be achieved. The generation process is repeated to train multiple base classifiers which are then fused via a majority voting to further improve its performance. Nonparametric Wilcoxon test and Friedman test confirm that the proposed method significantly outperforms most reference methods over thirty-five imbalanced datasets in terms of five metrics. The important finding of this work is that we show that ensembling simple perturbation-based oversamplers can yield better performance than many advanced ensemble methods for imbalanced datasets.},
  archive      = {J_NEUCOM},
  author       = {Jianjun Zhang and Ting Wang and Wing W.Y. Ng and Witold Pedrycz},
  doi          = {10.1016/j.neucom.2022.01.049},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {Ensembling perturbation-based oversamplers for imbalanced datasets},
  volume       = {479},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Lightweight hierarchical residual feature fusion network
for single-image super-resolution. <em>NEUCOM</em>, <em>478</em>,
104–123. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, numerous lightweight convolution neural networks (CNNs) have made remarkable progress for single image super-resolution (SISR) and showed great power for image reconstruction under constrained resources. However, existing lightweight networks can not fully utilize the informative hierarchical features, which will lead to the degradation of network reconstruction. To alleviate this issue, we propose a hierarchical residual feature network named HRFFN . Specifically, we design an enhanced residual block (ERB) containing multiple mixed attention blocks (MABs) to boost the representative ability of the network. Compared with ordinary residual blocks, ERB can achieve better performance while reducing network parameters and computational complexity . To utilize more features from intermediate convolution layers , we introduce a hierarchical feature fusion strategy (HFFS) to efficiently fuse the detailed information from each ERB step by step. By fully utilizing the hierarchical details with this strategy, we can refine the hierarchical features more efficiently. Besides, we cooperate the global dense connection strategy (GDCS) and residual learning connection (RLC, at low, meditate, and high levels) to construct our HRFFN . By employing these strategies, we can maximize the utilization of hierarchical features with a slight increase in parameters. Comprehensive experiments show the superiority of our method on five benchmark datasets against other state-of-the-art methods, which achieves a comparable trade-off between visual quality and quantitative metrics.},
  archive      = {J_NEUCOM},
  author       = {Jiayi Qin and Feiqiang Liu and Kai Liu and Gwanggil Jeon and Xiaomin Yang},
  doi          = {10.1016/j.neucom.2021.12.090},
  journal      = {Neurocomputing},
  pages        = {104-123},
  shortjournal = {Neurocomputing},
  title        = {Lightweight hierarchical residual feature fusion network for single-image super-resolution},
  volume       = {478},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A context-based meta-reinforcement learning approach to
efficient hyperparameter optimization. <em>NEUCOM</em>, <em>478</em>,
89–103. (<a href="https://doi.org/10.1016/j.neucom.2021.12.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a context-based meta-reinforcement learning approach to tackle the challenging data-inefficiency problem of Hyperparameter Optimization (HPO). Specifically, we design an agent which sequentially selects hyperparameters to maximize the expected accuracy of the machine learning algorithm on the validation set. First, we design a context variable that learns the latent embedding of prior experience, and the agent can solve the new tasks efficiently conditioned on it. Second, we employ a multi-task objective method that aims to maximize the average reward across all the meta-training tasks to meta-train the agent. Third, in the adaptation phase, we introduce a quadratic penalty technique to achieve better performance of the agent. Finally, to further improve the efficiency in the adaptation phase, we use a predictive model to evaluate the accuracy of machine learning algorithm instead of training it. We evaluate our approach on 18 real-world datasets and the results demonstrate that our approach outperforms other state-of-the-art optimization methods in terms of test set accuracy and runtime performance.},
  archive      = {J_NEUCOM},
  author       = {Xiyuan Liu and Jia Wu and Senpeng Chen},
  doi          = {10.1016/j.neucom.2021.12.086},
  journal      = {Neurocomputing},
  pages        = {89-103},
  shortjournal = {Neurocomputing},
  title        = {A context-based meta-reinforcement learning approach to efficient hyperparameter optimization},
  volume       = {478},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Error bounds of adversarial bipartite ranking.
<em>NEUCOM</em>, <em>478</em>, 81–88. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalization analysis for learning models with adversarial examples has attracted increasing attentions recently. However, the previous theoretical results are usually limited to learning models with the pointwise loss. In this paper, we beyond this restriction by investigating generalization ability of bipartite ranking associated with adversarial perturbations. The upper bounds of adversarial ranking risk are established by formulating the pairwise learning in a minimax framework and introducing the transfer mapping to relate data distributions. In particular, our results are suitable to general loss satisfying Lipschitz conditions , e.g, the logistic loss and the least squared loss.},
  archive      = {J_NEUCOM},
  author       = {Yingxiang Mo and Hong Chen and Yuxiang Han and Hao Deng},
  doi          = {10.1016/j.neucom.2021.12.078},
  journal      = {Neurocomputing},
  pages        = {81-88},
  shortjournal = {Neurocomputing},
  title        = {Error bounds of adversarial bipartite ranking},
  volume       = {478},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A self-adaptive gradient descent search algorithm for
fully-connected neural networks. <em>NEUCOM</em>, <em>478</em>, 70–80.
(<a href="https://doi.org/10.1016/j.neucom.2022.01.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks have achieved great success in artificial intelligence . Back propagation is one of the most widely used parameter search techniques for artificial neural networks , and it has been widely used in many deep learning approaches such as convolutional neural networks (CNNs), generator adversarial networks (GANs) and recurrent neural networks (RNNs) to train their fully-connected layers. However, the fully-connected layers of the neural networks with back propagation technique depends on the gradient descent strategy, which has the disadvantage of easily falling into local optima. Meanwhile, many evolutionary computation (EC) techniques are applied to the parameters optimization of neural networks. They take advantage of populations to achieve global search. But their convergence speed is relatively slow since they use their original evolutionary search strategies. In this paper, we propose a self-adaptive gradient descent search algorithm (SaGDSA) to search the parameters for fully-connected neural networks. Different from the existing adaptive gradient descent algorithm, the proposed algorithm does not require the user to have any prior knowledge and manually design the learning rate of different stages to match the different search stages. In addition, four kinds of gradient descent strategies are used to optimize parameters of fully-connected neural networks. All used datasets are collected from the University of California Irvine (UCI) machine learning repository. The experimental results indicate that SaGDSA is better than the comparison algorithms on most of the datasets. By introducing the self-adaptive mechanism, SaGDSA not only has excellent global search capabilities from evolutionary computation but also has local search capabilities from gradient descent.},
  archive      = {J_NEUCOM},
  author       = {Yu Xue and Yankang Wang and Jiayu Liang},
  doi          = {10.1016/j.neucom.2022.01.001},
  journal      = {Neurocomputing},
  pages        = {70-80},
  shortjournal = {Neurocomputing},
  title        = {A self-adaptive gradient descent search algorithm for fully-connected neural networks},
  volume       = {478},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combining dynamic local context focus and dependency cluster
attention for aspect-level sentiment classification. <em>NEUCOM</em>,
<em>478</em>, 49–69. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-level sentiment classification (ASC), as a subtask of Aspect-based sentiment analysis (ABSA), aims to analyze the sentiment polarity of different aspect terms in a sentence. Although the existing methods have been proven to be effective, they fail to effectively identify the range of local context and fully leverage the nonequivalent property of dependency relation . Hence, we propose a concept of dependency cluster and design two modules named Dynamic Local Context Focus (DLCF) and Dependency Cluster Attention (DCA) respectively. The DLCF can dynamically capture the range of local context based on the different max distance from the target aspect term to its context words and the DCA allows the model to pay more attention to the cluster which is more critical for sentiment classification. Together with the two modules, we then propose the DLCF-DCA model, in which the DLCF is equipped before DCA. Considering the DLCF has masked or weighted down the less-semantic-relative words, the semantic information can therefore be better extracted in DCA. Experiments conducted on six benchmark datasets demonstrate that DLCF-DCA achieves the state-of-the-art results. Moreover, the ablation experiment results also verify the effectiveness of each part in DLCF-DCA.},
  archive      = {J_NEUCOM},
  author       = {Mayi Xu and Biqing Zeng and Heng Yang and Junlong Chi and Jiatao Chen and Hongye Liu},
  doi          = {10.1016/j.neucom.2021.12.084},
  journal      = {Neurocomputing},
  pages        = {49-69},
  shortjournal = {Neurocomputing},
  title        = {Combining dynamic local context focus and dependency cluster attention for aspect-level sentiment classification},
  volume       = {478},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dual distribution matching GAN. <em>NEUCOM</em>,
<em>478</em>, 37–48. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Network (GAN) has become the dominant generative model in recent years. Although GAN is capable of generating sharp and realistic images, it faces several problems such as training instability and mode collapse. To address these issues, aside from the usual distribution matching via GAN’s adversarial training in a high-dimensional data space, we propose to perform distribution matching within a low-dimensional latent representation space as well. Such a low-dimensional latent representation space is obtained through training an Autoencoder (AE), which not only captures salient features and modes of the data distribution but can also be regularized to learn a nice latent manifold structure of the data. Based on that, we develop a novel hybrid generative model that combines AE and GAN, namely Dual Distribution Matching GAN ( DM 2 GAN DM2GAN ), that performs distribution matching in both data and latent space simultaneously. We theoretically show that the optimum of the proposed distribution matching constraint in the latent space is attained if and only if the generated and the real data distribution match exactly. The empirical evaluations on the 2D synthetic data, MNIST-1K, and several real-world datasets demonstrate the effectiveness of the proposed method to stabilize the training and increase mode coverage for GAN.},
  archive      = {J_NEUCOM},
  author       = {Zhiwen Zuo and Lei Zhao and Ailin Li and Zhizhong Wang and Haibo Chen and Wi Xing and Dongming Lu},
  doi          = {10.1016/j.neucom.2021.12.095},
  journal      = {Neurocomputing},
  pages        = {37-48},
  shortjournal = {Neurocomputing},
  title        = {Dual distribution matching GAN},
  volume       = {478},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3D saliency guided deep quality predictor for no-reference
stereoscopic images. <em>NEUCOM</em>, <em>478</em>, 22–36. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of 3D technologies is growing rapidly, and stereoscopic imaging is usually used to display the 3D contents. However, compression, transmission and other necessary treatments may reduce the quality of these images. Stereo Image Quality Assessment (SIQA) has attracted more attention to ensure good viewing experience for the users and thus several methods have been proposed in the literature with a clear improvement for deep learning-based methods. This paper introduces a new deep learning-based no-reference SIQA using cyclopean view hypothesis and human visual attention. First, the cyclopean image is constructed considering the presence of binocular rivalry that covers the asymmetric distortion case. Second, the saliency map is computed considering the depth information. The latter aims to extract patches on the most perceptual relevant regions. Finally, a modified version of the pre-trained Convolutional Neural Network (CNN) is fine-tuned and used to predict the quality score through the selected patches. Five distinct pre-trained models were analyzed and compared in term of results. The performance of the proposed metric has been evaluated on four commonly used datasets (3D LIVE phase I and phase II databases as well as Waterloo IVC 3D Phase 1 and Phase 2). Compared with the state-of-the-art metrics, the proposed method gives better outcomes. The implementation code will be made accessible to the public at: https://github.com/o-messai/3D-NR-SIQA},
  archive      = {J_NEUCOM},
  author       = {Oussama Messai and Aladine Chetouani and Fella Hachouf and Zianou Ahmed Seghir},
  doi          = {10.1016/j.neucom.2022.01.002},
  journal      = {Neurocomputing},
  pages        = {22-36},
  shortjournal = {Neurocomputing},
  title        = {3D saliency guided deep quality predictor for no-reference stereoscopic images},
  volume       = {478},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stream-learn — open-source python library for difficult data
stream batch analysis. <em>NEUCOM</em>, <em>478</em>, 11–21. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stream-learn is a Python package compatible with scikit-learn and developed for the drifting and imbalanced data stream analysis. Its main component is a stream generator, which allows producing a synthetic data stream that may incorporate each of the three main concept drift types (i.e., sudden , gradual and incremental drift ) in their recurring or non-recurring version, as well as static and dynamic class imbalance. The package allows conducting experiments following established evaluation methodologies (i.e., Test-Then-Train and Prequential ). Besides, estimators adapted for data stream classification have been implemented, including both simple classifiers and state-of-the-art chunk-based and online classifier ensembles. The package utilises its own implementations of prediction metrics for imbalanced binary classification tasks to improve computational efficiency.},
  archive      = {J_NEUCOM},
  author       = {P. Ksieniewicz and P. Zyblewski},
  doi          = {10.1016/j.neucom.2021.10.120},
  journal      = {Neurocomputing},
  pages        = {11-21},
  shortjournal = {Neurocomputing},
  title        = {Stream-learn — open-source python library for difficult data stream batch analysis},
  volume       = {478},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Defending against adversarial attacks using spherical
sampling-based variational auto-encoder. <em>NEUCOM</em>, <em>478</em>,
1–10. (<a href="https://doi.org/10.1016/j.neucom.2021.12.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep neural networks achieve outstanding performance in many tasks, adding very imperceptible perturbations to clean images can easily fool the deep neural network. In this paper, we propose a new defence model: Adversarial Memory Variational AutoEncoder(AdMVAE), that can be used to transform adversarial images into clean images. At inference time, it finds an output that is similar to a given image in a high probability region of the manifold space. And the memory module uses normal features to reconstruct the image in the process of reconstruction. It can effectively prevent the reconstruction of malicious perturbations and avoid defense failure. Our approach is a pre-processing module that does not change the results of the classifier. Therefore, it can be combined with other defence models to jointly improve the performance robustness of the classifier. The experimental results on three benchmark datasets including Fashion-MNIST, CIFAR10 and Imagenet show that the proposed method outperforms the state-of-the-art defense methods.},
  archive      = {J_NEUCOM},
  author       = {Sheng-lin Yin and Xing-lan Zhang and Li-yu Zuo},
  doi          = {10.1016/j.neucom.2021.12.080},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {Defending against adversarial attacks using spherical sampling-based variational auto-encoder},
  volume       = {478},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Peer selection in opinion dynamics on signed social networks
with stubborn individuals. <em>NEUCOM</em>, <em>477</em>, 104–113. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the impact of local peer selection on global opinion dynamics evolving on signed social networks, where both cooperative and antagonistic ties coexist. Specifically, we focus on how opinions of stubborn individuals can be efficiently learned by a signed social network using peer selection mechanism. First, we examine the correlation between the selection of influence anchors of stubborn individuals and the opinion formation of the signed social network. Then, we proceed to examine an eigenvector-based peer selection strategy and show how the strategy can be beneficial in the spreading efficiency of stubborn individuals’ opinions. Finally, how the local observations of peers’ opinions can be employed for peer selection is investigated, enabling a global opinion spreading efficiency enhancement through only local decision-making amongst social individuals. The application of the proposed peer selection strategy to the Friedkin-Johnsen opinion dynamics model on signed networks is discussed. Numerical examples are provided to demonstrate the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Lulu Pan and Haibin Shao and Dewei Li},
  doi          = {10.1016/j.neucom.2021.12.105},
  journal      = {Neurocomputing},
  pages        = {104-113},
  shortjournal = {Neurocomputing},
  title        = {Peer selection in opinion dynamics on signed social networks with stubborn individuals},
  volume       = {477},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Passivity analysis of fractional-order neural networks with
interval parameter uncertainties via an interval matrix polytope
approach. <em>NEUCOM</em>, <em>477</em>, 96–103. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the passivity analysis problem of a class of fractional-order neural networks with interval parameter uncertainties (FONNs-IPUs). The previous IPU processing methods are mainly divided into three categories, i.e., directly using the maximum upper bound matrix or the minimum lower bound matrix, using the combination of these two matrices, and using the maximum norm bound matrix. These methods have some shortcomings, for example, the coupling of information between different intervals and the effect of the negative sign of connection weight are not considered. In order to better analyze the passivity of FONNs-IPUs, firstly, a novel treatment approach of IPUs called interval matrix polytope is proposed, which considers all possible boundary information matrices and the sign of IPUs. Secondly, based on the interval matrix polytope approach, the passivity criteria of FONNs-IPUs are established in linear matrix inequality forms. Finally, the effectiveness of the theoretical results is illustrated by simulation example.},
  archive      = {J_NEUCOM},
  author       = {Shasha Xiao and Zhanshan Wang and Changlai Wang},
  doi          = {10.1016/j.neucom.2021.12.106},
  journal      = {Neurocomputing},
  pages        = {96-103},
  shortjournal = {Neurocomputing},
  title        = {Passivity analysis of fractional-order neural networks with interval parameter uncertainties via an interval matrix polytope approach},
  volume       = {477},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NAP: Neural architecture search with pruning.
<em>NEUCOM</em>, <em>477</em>, 85–95. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been continuously increasing attention attracted by Neural Architecture Search (NAS). Due to its computational efficiency, gradient-based NAS methods like DARTS have become the most popular framework for NAS tasks. Nevertheless, as the search iterates, the derived model in previous NAS frameworks becomes dominated by skip-connect s, causing the performance downfall. In this work, we present a novel approach to alleviate this issue, named Neural Architecture search with Pruning (NAP). Unlike prior differentiable architecture search works, our approach draws the idea from network pruning. We first train an over-parameterized network, including all candidate operations. Then we propose a criterion to prune the network. Based on a newly designed relaxation of architecture representation, NAP can derive the most potent model by removing trivial and redundant edges from the whole network topology . Experiments show the effectiveness of our proposed approach. Specifically, the model searched by NAP achieves state-of-the-art performances (2.48\% test error) on CIFAR-10. We transfer the model to ImageNet and obtains a 25.1\% test error with only 5.0 M parameters, which is on par with modern NAS methods.},
  archive      = {J_NEUCOM},
  author       = {Yadong Ding and Yu Wu and Chengyue Huang and Siliang Tang and Fei Wu and Yi Yang and Wenwu Zhu and Yueting Zhuang},
  doi          = {10.1016/j.neucom.2021.12.002},
  journal      = {Neurocomputing},
  pages        = {85-95},
  shortjournal = {Neurocomputing},
  title        = {NAP: Neural architecture search with pruning},
  volume       = {477},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Survey on dialogue systems including slavic languages.
<em>NEUCOM</em>, <em>477</em>, 62–84. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slavic languages pose a challenge to the researchers in the domain of dialogue technology. A relatively free word order with a large degree of inflection, such as conjugation of verbs, and declension of adjectives, pronouns, and nouns are exhibited by the Slavic languages, which has a significant impact on the size of lexical inventories that significantly complicate the design of dialogue systems . This article conducts an empirical study on the state-of-the-art dialogue systems within Slavic languages. Moreover, we review the existing models in recent dialogue systems, pinpoint the current main challenges and identify potential research directions of practical and intelligent systems within low-resourced languages.},
  archive      = {J_NEUCOM},
  author       = {Krzysztof Wołk and Agnieszka Wołk and Dominika Wnuk and Tomasz Grześ and Ida Skubis},
  doi          = {10.1016/j.neucom.2021.11.076},
  journal      = {Neurocomputing},
  pages        = {62-84},
  shortjournal = {Neurocomputing},
  title        = {Survey on dialogue systems including slavic languages},
  volume       = {477},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Corrigendum to “dual focal loss to address class imbalance
in semantic segmentation” [neurocomputing 462 (2021) 69-87].
<em>NEUCOM</em>, <em>477</em>, 61. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Md Sazzad Hossain and John M. Betts and Andrew P. Paplinski},
  doi          = {10.1016/j.neucom.2022.01.009},
  journal      = {Neurocomputing},
  pages        = {61},
  shortjournal = {Neurocomputing},
  title        = {Corrigendum to “Dual focal loss to address class imbalance in semantic segmentation” [Neurocomputing 462 (2021) 69-87]},
  volume       = {477},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning approach for defective spot welds
classification using small and class-imbalanced datasets.
<em>NEUCOM</em>, <em>477</em>, 46–60. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Availability of large-scale annotated and class-balanced datasets is of great importance for deep learning based computer vision tasks like spot welds detection. However, it is extremely time and cost consuming to collect sufficient image data of spot welding defects. Severe class-imbalance of image datasets will deteriorate the performance of deep learning algorithms. Generative adversarial networks (GANs) provide an effective method to generate artificial data samples for minor classes. In this work, a framework for improving performance of spot welding defects classification by using GAN-based data augmentation is proposed. Traditional GANs are not suitable to generate minority-class images in a highly class-imbalanced dataset. Balancing GAN and gradient penalty (BAGAN-GP) is utilized herein to generate diverse minority-class images, even in extreme cases where the number of minority-class samples is very small. Then, an image classifier is constructed with the pre-trained deep neural network that employs a transfer learning method. The generated images by the BAGAN-GP are added to the training dataset to improve the classifier for better classification performance. Extensive experiments showed that the proposed approach can generate spot welds defect images efficiently, and improve performance of the classification for industrial inspection with annotation-lack or class-imbalanced dataset. This work provides a valuable reference for industry defect image analysis based on deep learning. The code is available: https://github.com/daiwei9501/Defective-spot-welding .},
  archive      = {J_NEUCOM},
  author       = {Wei Dai and Dayong Li and Ding Tang and Huamiao Wang and Yinghong Peng},
  doi          = {10.1016/j.neucom.2022.01.004},
  journal      = {Neurocomputing},
  pages        = {46-60},
  shortjournal = {Neurocomputing},
  title        = {Deep learning approach for defective spot welds classification using small and class-imbalanced datasets},
  volume       = {477},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fractional-order convolutional neural networks with
population extremal optimization. <em>NEUCOM</em>, <em>477</em>, 36–45.
(<a href="https://doi.org/10.1016/j.neucom.2022.01.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is devoted to the intelligent optimization issue by means of PEO-FOCNN, i.e., the fractional-order convolutional neural networks (FOCNNs) with population extremal optimization (PEO). The Caputo fractional-order gradient method (CFOGM) is adopted to improve the dynamic updating effectiveness of the biases and weights for convolutional neural networks (CNN). Moreover, considering the significance of the initial biases and weights and their updating mechanisms to the optimization performance of FOCNN , the PEO algorithm is used to seek an optimal selection from lots of the initial biases and weights. The optimization effect of PEO method for FOCNN is demonstrated by the training and testing accuracies of PEO-FOCNN compared with standard FOCNN. And, the superiority of the proposed PEO-FOCNN to FOCNN based on some other popular optimization algorithms, such as the genetic algorithm-based FOCNN (GA-FOCNN), differential evolution-based FOCNN (DE-FOCNN) and particle swarm optimization-based FOCNN (PSO-FOCNN), is verified by the experiments on the MNIST dataset in terms of three types of statistical tests.},
  archive      = {J_NEUCOM},
  author       = {Bi-Peng Chen and Yun Chen and Guo-Qiang Zeng and Qingshan She},
  doi          = {10.1016/j.neucom.2022.01.006},
  journal      = {Neurocomputing},
  pages        = {36-45},
  shortjournal = {Neurocomputing},
  title        = {Fractional-order convolutional neural networks with population extremal optimization},
  volume       = {477},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learn more from less: Generalized zero-shot learning with
severely limited labeled data. <em>NEUCOM</em>, <em>477</em>, 25–35. (<a
href="https://doi.org/10.1016/j.neucom.2022.01.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized Zero-Shot Learning (GZSL) aims to recognize samples from both seen (base) and unseen (novel) categories by learning a classification model with assistance of some class-level semantic information. Despite promising results have been achieved, most existing approaches still require a large amount of labeled data for training a basic transfer model. To further alleviate the annotation burden, we present a low-data training setting for zero-shot task, where only a few samples are available for each training class. To compensate the scarcity of the training data, we introduce a novel meta-learning paradigm to train a model-agnostic classifier conditioned on the class semantics with only a few training samples. By mimicking a collection of zero-shot tasks under the training data scarcity scenario, the semantic knowledge can be transferred explicitly. To address the model bias, we introduce a simple but effective strategy via a domain detector called entropy gate to assist the model to search optimal weights respectively for both seen and unseen classes. Experiments on four standard benchmarks, i.e., AWA2, APY, CUB, and FLO demonstrate that our proposed model significantly outperforms state-of-the-art methods under both traditional GZSL and the proposed low-data regime settings.},
  archive      = {J_NEUCOM},
  author       = {Ziqian Lu and Zheming Lu and Yunlong Yu and Zonghui Wang},
  doi          = {10.1016/j.neucom.2022.01.007},
  journal      = {Neurocomputing},
  pages        = {25-35},
  shortjournal = {Neurocomputing},
  title        = {Learn more from less: Generalized zero-shot learning with severely limited labeled data},
  volume       = {477},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Towards real-time object detection in GigaPixel-level
video. <em>NEUCOM</em>, <em>477</em>, 14–24. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection aims to locate and recognize objects in images or videos, which contributes to many downstream intelligent applications. Recently, emerging gigapixel videography has attracted considerable attention from computer vision, microscopy, telescopy and many other communities. Its large field of view and high spatial resolution provide sufficient global and local information simultaneously. Although state-of-the-art detection methods have achieved success in common images, they can not be transferred to gigapixel images with both effectiveness and efficiency. To solve this problem, we make the first attempt towards accurate and real-time object detection in giga-pixel video. In this paper we propose a novel framework, termed as GigaDet, which adopts an efficient global-to-local strategy, following the principle of human vision system. Based on the spatial sparsity of objects, a patch generation network (PGN) is introduced to globally locate possible regions containing objects and determine the proper resize ratio of each patch. Then the collected multi-scale patches are fed into a decorated detector (DecDet) in parallel to perform accurate and fast detection in a local way. We carry out extensive experiments on PANDA dataset and GigaDet yields 76.2\% 76.2\% AP and 5 FPS on a single 2080ti GPU, which is comparably accurate but 50x faster than Faster RCNN. We believe this research can inspire new applications based on gigapixel video for a large range of fields.},
  archive      = {J_NEUCOM},
  author       = {Kai Chen and Zerun Wang and Xueyang Wang and Dahan Gong and Longlong Yu and Yuchen Guo and Guiguang Ding},
  doi          = {10.1016/j.neucom.2021.12.049},
  journal      = {Neurocomputing},
  pages        = {14-24},
  shortjournal = {Neurocomputing},
  title        = {Towards real-time object detection in GigaPixel-level video},
  volume       = {477},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Label embedding semantic-guided hashing. <em>NEUCOM</em>,
<em>477</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hashing technologies have been widely used for information retrieval tasks due to their efficient retrieval and storage capabilities. Generally, most of the current supervised learning only utilizes labels to construct a binary similarity matrix of instance pairs and ignores the rich semantic information contained in the labels. Indeed, the reason why supervised hashing is better than unsupervised hashing is that the labels itself has strong discriminative information. Therefore, how to effectively explore the label information is one of the ways to improve the performance of retrieval tasks. In addition, existing hashing methods have the problems of high time consumption and weak scalability when facing large-scale data. To remedy these problems, in this paper, we present a flexible two-step label embedding hashing method named L abel E mbedding S emantic- G uided H ashing ( LESGH ). In the first step, LESGH leverages an asymmetric discrete learning framework to learn discriminative compact hash codes only from label information, and adds the constraints of bit-balance and bit-decorrelation to boost the quality of the hash code generation. In the second step, LESGH learns the hash projection function through the generated hash codes in the first step. Moreover, an effective and fast iterative discrete optimization algorithm is presented to solve the discrete problem instead of using the relaxation-based scheme. In doing so, we can not only simplify the optimization process, but also easily scale to large-scale data. We conduct several experiments on three public datasets, i.e., WIKI, MIRFlickr and NUS-WIDE, demonstrate that LESGH can improve the retrieval performance over the compared state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Jun Long and Longzhi Sun and Lin Guo and Liujie Hua and Zhan Yang},
  doi          = {10.1016/j.neucom.2021.12.073},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {Label embedding semantic-guided hashing},
  volume       = {477},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural-networks-based adaptive asymptotic tracking control
of MIMO stochastic non-strict-feedback nonlinear systems with full state
constraints and unknown control gains. <em>NEUCOM</em>, <em>476</em>,
137–150. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neural-networks-based adaptive asymptotic tracking control problem is considered for a class of multiple input multiple output (MIMO) stochastic non-strict-feedback nonlinear systems with unknown control gains and full state constraints. Firstly, barrier Lyapunov functions (BLFs) are designed to avoid the violation of the state constraints, the dynamic surface control (DSC) method is adopted to ensure the computation burden is greatly reduced, and the introduced auxiliary virtual controllers solve the design obstacle arised from unknown control gains. Then, by introducing a specific gain suppression inequality, a new adaptive asymptotic tracking control scheme is proposed and its correctness and validity are rigorously proved, which can not only effectively guarantee that all the signals of the closed-loop system are bounded in probability, but also makes the tracking error converge to zero in the fourth moment. At the same time, the impact of the full state constraints on the system performance is also tackled. Finally, the feasibility and practicability of the proposed control scheme are verified by the simulation results.},
  archive      = {J_NEUCOM},
  author       = {Wei Su and Xudong Zhao and Ben Niu and Guangju Zhang and Huanqing Wang},
  doi          = {10.1016/j.neucom.2021.12.103},
  journal      = {Neurocomputing},
  pages        = {137-150},
  shortjournal = {Neurocomputing},
  title        = {Neural-networks-based adaptive asymptotic tracking control of MIMO stochastic non-strict-feedback nonlinear systems with full state constraints and unknown control gains},
  volume       = {476},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generic network for domain adaptation based on
self-supervised learning and deep clustering. <em>NEUCOM</em>,
<em>476</em>, 126–136. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation methods train a model to find similar feature representations between a source and target domain. Recent methods leverage self-supervised learning to discover the analogous representations of the two domains. However, prior self-supervised methods have three significant drawbacks: (1) leveraging pretext tasks that are susceptible to learning low-level representations, (2) aligning the two domains using adversarial loss without considering if the extracted features are low-level representations, (3) the models are not flexible to accommodate various proportions of target labels, i.e., they assume target labels are always available. This paper presents a Generic Domain Adaptation Network (GDAN) to address these issues. First, we introduce a criterion based on instance discrimination to select appropriate pretext tasks to learn high-level domain invariant representations . Then, we propose a semantic neighbor cluster to align the two domain features. The semantic neighbor cluster implements a clustering technique in a feature embedding space to form clusters according to high-level semantic similarities. Finally, we present a weighted target loss function to balance the model weights according to the target labels. This loss function makes GDAN flexible for semi-supervised scenarios, i.e., partly labeled target data. We evaluate the proposed methods on four domain adaptation benchmark datasets. The experiment findings show that the proposed methods align the two domains well and achieve competitive results.},
  archive      = {J_NEUCOM},
  author       = {Adu Asare Baffour and Zhen Qin and Ji Geng and Yi Ding and Fuhu Deng and Zhiguang Qin},
  doi          = {10.1016/j.neucom.2021.12.099},
  journal      = {Neurocomputing},
  pages        = {126-136},
  shortjournal = {Neurocomputing},
  title        = {Generic network for domain adaptation based on self-supervised learning and deep clustering},
  volume       = {476},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DensE: An enhanced non-commutative representation for
knowledge graph embedding with adaptive semantic hierarchy.
<em>NEUCOM</em>, <em>476</em>, 115–125. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capturing the composition patterns of relations is a vital task in knowledge graph completion. It also serves as a fundamental step towards multi-hop reasoning over learned knowledge. Previously, several rotation-based translational methods have been developed to model composite relations using the product of a series of complex-valued diagonal matrices. However, these methods tend to make several oversimplified assumptions on the composite relations, e.g., forcing them to be commutative, independent from entities and lacking semantic hierarchy. To systematically tackle these problems, we have developed a novel knowledge graph embedding method, named DensE, to provide an improved modeling scheme for the complex composition patterns of relations. In particular, our method decomposes each relation into an SO(3) group-based rotation operator and a scaling operator in the three dimensional (3-D) Euclidean space. This design principle leads to several advantages of our method: (1) For composite relations, the corresponding diagonal relation matrices can be non-commutative, reflecting a predominant scenario in real world applications; (2) Our model preserves the natural interaction between relational operations and entity embeddings; (3) The scaling operation provides the modeling power for the intrinsic semantic hierarchical structure of entities; (4) The enhanced expressiveness of DensE is achieved with high computational efficiency in terms of both parameter size and training time; and (5) Modeling entities in Euclidean space instead of quaternion space keeps the direct geometrical interpretations of relational patterns. Experimental results on multiple benchmark knowledge graphs show that DensE is comparable to the current state-of-the-art models for missing link prediction, especially on composite relations. In addition, the interpretations generated by DensE also reveal how relations with distinct patterns (i.e., symmetry/anti-symmetry, inversion and composition) are modeled, which suggests several important directions of future studies.},
  archive      = {J_NEUCOM},
  author       = {Haonan Lu and Hailin Hu and Xiaodong Lin},
  doi          = {10.1016/j.neucom.2021.12.079},
  journal      = {Neurocomputing},
  pages        = {115-125},
  shortjournal = {Neurocomputing},
  title        = {DensE: An enhanced non-commutative representation for knowledge graph embedding with adaptive semantic hierarchy},
  volume       = {476},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrating contrastive learning with dynamic models for
reinforcement learning from images. <em>NEUCOM</em>, <em>476</em>,
102–114. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent methods for reinforcement learning from images use auxiliary tasks to learn image features that are used by the agent’s policy or Q-function. In particular, methods based on contrastive learning that induce linearity of the latent dynamics or invariance to data augmentation have been shown to greatly improve the sample efficiency of the reinforcement learning algorithm and the generalizability of the learned embedding. We further argue, that explicitly improving Markovianity of the learned embedding is desirable and propose a self-supervised representation learning method which integrates contrastive learning with dynamic models to synergistically combine these three objectives: (1) We maximize the InfoNCE bound on the mutual information between the state- and action-embedding and the embedding of the next state to induce a linearly predictive embedding without explicitly learning a linear transition model, (2) we further improve Markovianity of the learned embedding by explicitly learning a non-linear transition model using regression, and (3) we maximize the mutual information between the two nonlinear predictions of the next embeddings based on the current action and two independent augmentations of the current state, which naturally induces transformation invariance not only for the state embedding, but also for the nonlinear transition model. Experimental evaluation on the Deepmind control suite shows that our proposed method achieves higher sample efficiency and better generalization than state-of-art methods based on contrastive learning or reconstruction.},
  archive      = {J_NEUCOM},
  author       = {Bang You and Oleg Arenz and Youping Chen and Jan Peters},
  doi          = {10.1016/j.neucom.2021.12.094},
  journal      = {Neurocomputing},
  pages        = {102-114},
  shortjournal = {Neurocomputing},
  title        = {Integrating contrastive learning with dynamic models for reinforcement learning from images},
  volume       = {476},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-convex logarithm embedding subspace weighted graph
approach to fault detection with missing measurements. <em>NEUCOM</em>,
<em>476</em>, 87–101. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a robust fault detection method to address the problem of increase in missing and/or spurious alarms due to different degrees of loss or corruptions in data. Specifically, given historical data, our aim is to recover a clear low-space representation from corrupted data so that the detection control limits are updated, whenever required. To this end, a novel non-convex logarithm embedding subspace weighted graph detection method is presented. The method compensates the original missing nodes by embedding a non-convex logarithm regularizer, and then constructs an undirected graph model of the compensated nodes. Additionally, the dual constraints of l 2 , 1 l2,1 -norm regularization and specific weights are introduced into the loss function of the graph model to further improve its robustness. Finally, the statistics and detectable criterion of the proposed method are given. Extensive simulations conducted on a real-world hot strip mill process and a multi-phase flow process demonstrate that the proposed method displays more robust detection than other state-of-the-art methods in the presence of outliers and missing measurements.},
  archive      = {J_NEUCOM},
  author       = {Ming-Qing Zhang and Anikesh Kumar and Min-Sen Chiu and Xiong-Lin Luo},
  doi          = {10.1016/j.neucom.2021.12.065},
  journal      = {Neurocomputing},
  pages        = {87-101},
  shortjournal = {Neurocomputing},
  title        = {Non-convex logarithm embedding subspace weighted graph approach to fault detection with missing measurements},
  volume       = {476},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MAT: Motion-aware multi-object tracking. <em>NEUCOM</em>,
<em>476</em>, 75–86. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern multi-object tracking (MOT) systems usually build trajectories through associating per-frame detections. However, facing the challenges of camera motion, fast motion, and occlusion, it is difficult to ensure the quality of long-range tracking or even the tracklet purity, especially for small objects. Most of tracking frameworks depend heavily on the performance of re-identification (ReID) for the data association . Unfortunately, the ReID-based association is not only unreliable and time-consuming, but still cannot address the false negatives for occluded and blurred objects, due to noisy partial-detections, similar appearances, and lack of temporal-spatial constraints. In this paper, we propose an enhanced MOT paradigm, namely Motion-Aware Tracker (MAT). Our MAT is a plug-and-play solution, it mainly focuses on high-performance motion-based prediction, reconnection, and association. First, the nonrigid pedestrian motion and rigid camera motion are blended seamlessly to develop the Integrated Motion Localization (IML) module. Second, the Dynamic Reconnection Context (DRC) module is devised to guarantee the robustness for long-range motion-based reconnection. The core ideas in DRC are the motion-based dynamic-window and cyclic pseudo-observation trajectory filling strategy, which can smoothly fill in the tracking fragments caused by occlusion or blur. At last, we present the 3D Integral Image (3DII) module to efficiently cut off useless track-detection association connections using temporal-spatial constraints. Extensive experiments are conducted on the MOT16&amp;17 challenging benchmarks. The results demonstrate that our MAT can achieve superior performance and surpass other state-of-the-art trackers by a large margin with high efficiency.},
  archive      = {J_NEUCOM},
  author       = {Shoudong Han and Piao Huang and Hongwei Wang and En Yu and Donghaisheng Liu and Xiaofeng Pan},
  doi          = {10.1016/j.neucom.2021.12.104},
  journal      = {Neurocomputing},
  pages        = {75-86},
  shortjournal = {Neurocomputing},
  title        = {MAT: Motion-aware multi-object tracking},
  volume       = {476},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Semi-supervised classification via full-graph attention
neural networks. <em>NEUCOM</em>, <em>476</em>, 63–74. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) leverage graph convolutions or their approximations to extract features of nodes from graph-structured data. Nevertheless, these methods only combine information from nodes’ neighborhoods, without taking into account the impact of other nodes outside neighborhoods. To address the shortcomings, we present full-graph attention neural networks (FGANNs), novel neural network architectures that consider the impact of all nodes when performing self-attention, leveraging masked attention to enable (implicitly) specifying different weights to different nodes in a neighborhood. Under such circumstances, we address several important challenges of spectral-based graph neural networks simultaneously, and make FGANN readily available to semi-supervised classification problems. Extensive experiments on citation networks offer evidence that the proposed approach outperforms state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Fei Yang and Huyin Zhang and Shiming Tao},
  doi          = {10.1016/j.neucom.2021.12.077},
  journal      = {Neurocomputing},
  pages        = {63-74},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised classification via full-graph attention neural networks},
  volume       = {476},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pose graph parsing network for human-object interaction
detection. <em>NEUCOM</em>, <em>476</em>, 53–62. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of interactions between humans and objects is one of the core issues in the area of scene understanding in image analysis. The conventional method is to pair the human body with the object as an entity and pay attention to the human spatial area and object. However, this method does not consider two key aspects: humans use certain body parts to interact with objects, and correlations exist between different body parts. Thus, in this paper, we propose a pose graph parsing network (PGPN) for human-object interaction detection. Specifically, we construct a multibranch network to study high-level semantic features. In addition to emphasizing the appearance area of each instance in an image, feature propagation based on a pose graph is further adopted to consider the features of correlation between different body parts. Furthermore, a branch refines and captures the relationship between human parts and an object using a human pose. We validate this approach on the V-COCO and HICO-DET datasets and compare it with the state-of-the-arts. In comparison to other models, the PGPN superior and significantly improves the performance of human-object interaction detection.},
  archive      = {J_NEUCOM},
  author       = {Zhan Su and Yuting Wang and Qing Xie and Ruiyun Yu},
  doi          = {10.1016/j.neucom.2021.12.085},
  journal      = {Neurocomputing},
  pages        = {53-62},
  shortjournal = {Neurocomputing},
  title        = {Pose graph parsing network for human-object interaction detection},
  volume       = {476},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PT-NAS: Designing efficient keypoint-based object detectors
for desktop CPU platforms. <em>NEUCOM</em>, <em>476</em>, 38–52. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, keypoint-based object detectors have attracted widespread attention, due to their novel structure and excellent performance. However, in terms of their design, there are still two limitations: 1) Most keypoint-based methods are designed for GPU platforms, which makes them inefficient on desktop CPU platforms. 2) Existing works still rely heavily on manual design and prior knowledge. To this end, this work aims to offer a practical solution for designing CPU-efficient key-point detectors. First, we present a set of practical design guidelines by comparing different detection architectures. Following the proposed guidelines, we further develop a progressive three-phase network architecture search (PT-NAS) to achieve the automated design of detection architectures. Benefiting from our hierarchical search space and novel search pipeline, our PT-NAS not only achieves higher search efficiency, but also satisfies the practicality of CPU platforms. On the MS-COCO benchmark, we utilize our PT-NAS to generate several key-point detectors for fast inference on desktop CPUs. Finally, comprehensive comparison experiments prove that the proposed PT-NAS can produce new state-of-the-art keypoint-based detectors for CPU platforms.},
  archive      = {J_NEUCOM},
  author       = {Dong Chen and Hao Shen and Yuchen Shen},
  doi          = {10.1016/j.neucom.2021.12.067},
  journal      = {Neurocomputing},
  pages        = {38-52},
  shortjournal = {Neurocomputing},
  title        = {PT-NAS: Designing efficient keypoint-based object detectors for desktop CPU platforms},
  volume       = {476},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FAIR: Fair adversarial instance re-weighting.
<em>NEUCOM</em>, <em>476</em>, 14–37. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With growing awareness of societal impact of artificial intelligence, fairness has become an important aspect of machine learning algorithms. The issue is that human biases towards certain groups of population, defined by sensitive features like race and gender, are introduced to the training data through data collection and labeling. Two important directions of fairness ensuring research have focused on (i) instance weighting in order to decrease the impact of more biased instances and (ii) adversarial training in order to construct data representations informative of the target variable, but uninformative of the sensitive attributes. In this paper we propose a Fair Adversarial Instance Re-weighting (FAIR) method, which uses adversarial training to learn instance weighting function that ensures fair predictions. Merging the two paradigms, it inherits desirable properties from both interpretability of reweighting and end-to-end trainability of adversarial training. We propose four different variants of the method and, among other things, demonstrate how the method can be cast in a fully probabilistic framework. Additionally, theoretical analysis of FAIR models’ properties is provided. We compare FAIR models to ten other related and state-of-the-art models and demonstrate that FAIR is able to achieve a better trade-off between accuracy and unfairness. To the best of our knowledge, this is the first model that merges reweighting and adversarial approaches by means of a weighting function that can provide interpretable information about fairness of individual instances.},
  archive      = {J_NEUCOM},
  author       = {Andrija Petrović and Mladen Nikolić and Sandro Radovanović and Boris Delibašić and Miloš Jovanović},
  doi          = {10.1016/j.neucom.2021.12.082},
  journal      = {Neurocomputing},
  pages        = {14-37},
  shortjournal = {Neurocomputing},
  title        = {FAIR: Fair adversarial instance re-weighting},
  volume       = {476},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Region-attentive multimodal neural machine translation.
<em>NEUCOM</em>, <em>476</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a multimodal neural machine translation (MNMT) method with semantic image regions called region-attentive multimodal neural machine translation (RA-NMT). Existing studies on MNMT have mainly focused on employing global visual features or equally sized grid local visual features extracted by convolutional neural networks (CNNs) to improve translation performance. However, they neglect the effect of semantic information captured inside the visual features. This study utilizes semantic image regions extracted by object detection for MNMT and integrates visual and textual features using two modality-dependent attention mechanisms . The proposed method was implemented and verified on two neural architectures of neural machine translation (NMT): recurrent neural network (RNN) and self-attention network (SAN). Experimental results on different language pairs of Multi30k dataset show that our proposed method improves over baselines and outperforms most of the state-of-the-art MNMT methods. Further analysis demonstrates that the proposed method can achieve better translation performance because of its better visual feature use.},
  archive      = {J_NEUCOM},
  author       = {Yuting Zhao and Mamoru Komachi and Tomoyuki Kajiwara and Chenhui Chu},
  doi          = {10.1016/j.neucom.2021.12.076},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {Region-attentive multimodal neural machine translation},
  volume       = {476},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DBC-forest: Deep forest with binning confidence screening.
<em>NEUCOM</em>, <em>475</em>, 112–122. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a deep learning model , deep confidence screening forest (gcForestcs) has achieved great success in various applications. Compared with the traditional deep forest approach, gcForestcs effectively reduces the high time cost by passing some instances in the high-confidence region directly to the final stage. However, there is a group of instances with low accuracy in the high-confidence region, which are called mis-partitioned instances. To find these mis-partitioned instances, this paper proposes a deep binning confidence screening forest (DBC-Forest) model, which packs all instances into bins based on their confidences. In this way, more accurate instances can be passed to the final stage, and the performance is improved. Experimental results show that DBC-Forest achieves highly accurate predictions for the same hyperparameters and is faster than other similar models to achieve the same accuracy.},
  archive      = {J_NEUCOM},
  author       = {Pengfei Ma and Youxi Wu and Yan Li and Lei Guo and Zhao Li},
  doi          = {10.1016/j.neucom.2021.12.075},
  journal      = {Neurocomputing},
  pages        = {112-122},
  shortjournal = {Neurocomputing},
  title        = {DBC-forest: Deep forest with binning confidence screening},
  volume       = {475},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022d). An unsupervised domain adaptation model based on
dual-module adversarial training. <em>NEUCOM</em>, <em>475</em>,
102–111. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a dual-module network architecture that employs a domain discriminative feature module to encourage the domain invariant feature module to learn more domain invariant features. The proposed architecture can be applied to any model that utilizes domain invariant features for unsupervised domain adaptation to improve its ability to extract domain invariant features. We conduct experiments with the Domain-Adversarial Training of Neural Networks (DANN) model as a representative algorithm. In the training process, we supply the same input to the two modules and then extract their feature distribution and prediction results respectively. We propose a discrepancy loss to find the discrepancy of the prediction results and the feature distribution between the two modules. Through the adversarial training by maximizing the loss of their feature distribution and minimizing the discrepancy of their prediction results, the two modules are encouraged to learn more domain discriminative and domain invariant features respectively. Extensive comparative evaluations are conducted and the proposed approach outperforms the state-of-the-art in most unsupervised domain adaptation tasks.},
  archive      = {J_NEUCOM},
  author       = {Yiju Yang and Tianxiao Zhang and Guanyu Li and Taejoon Kim and Guanghui Wang},
  doi          = {10.1016/j.neucom.2021.12.060},
  journal      = {Neurocomputing},
  pages        = {102-111},
  shortjournal = {Neurocomputing},
  title        = {An unsupervised domain adaptation model based on dual-module adversarial training},
  volume       = {475},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ASCNet: 3D object detection from point cloud based on
adaptive spatial context features. <em>NEUCOM</em>, <em>475</em>,
89–101. (<a href="https://doi.org/10.1016/j.neucom.2021.12.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel two-stage 3D point cloud object detector named ASCNet for autonomous driving. Most current works project 3D point clouds to 2D space, whereas the quantization loss in the transformation is inevitable. A Pillar-wise Spatial Context Feature Encoding (PSCFE) module is proposed in the paper to drive the learning of discriminative features and reduce the detailed information loss. The inhomogeneity that existed in 3D object detection from the point clouds, such as the inconsistent number of points in the pillars, the diverse size of Regions of Interest (RoI), should be treated wisely due to the sparsity and the individual specificity. We introduce a length-adaptive RNN-based module to solve the inhomogeneity. A novel backbone combining encoder-decoder and shortcut connection is designed in the paper to learn the multi-scale features for 3D object detection. Additionally, we utilize multiple RoI heads and class-wise NMS to deal with the class imbalance in scenes. Extensive experiments on the KITTI dataset demonstrate that our algorithm achieves competitive performance in 3D bounding box detection and BEV detection.},
  archive      = {J_NEUCOM},
  author       = {Guofeng Tong and Hao Peng and Yuyuan Shao and Qijun Yin and Zheng Li},
  doi          = {10.1016/j.neucom.2021.12.061},
  journal      = {Neurocomputing},
  pages        = {89-101},
  shortjournal = {Neurocomputing},
  title        = {ASCNet: 3D object detection from point cloud based on adaptive spatial context features},
  volume       = {475},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DLDL: Dynamic label dictionary learning via hypergraph
regularization. <em>NEUCOM</em>, <em>475</em>, 80–88. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For classification tasks , dictionary learning based methods have attracted lots of attention in recent years. One popular way to achieve this purpose is to introduce label information to generate a discriminative dictionary to represent samples. However, compared with traditional dictionary learning, this category of methods only achieves significant improvements in supervised learning, and has little positive influence on semi-supervised or unsupervised learning . To tackle this issue, we propose a Dynamic Label Dictionary Learning (DLDL) algorithm to generate the soft label matrix for unlabeled data . Specifically, we employ hypergraph manifold regularization to keep the relations among original data, transformed data, and soft labels consistent. We demonstrate the efficiency of the proposed DLDL approach on two kinds of tasks, including remote sensing image classification and human activity recognition . The significant improvements have demonstrated the efficiency of our method.},
  archive      = {J_NEUCOM},
  author       = {Shuai Shao and Rui Xu and Zhenfang Wang and Weifeng Liu and Yan-Jiang Wang and Bao-Di Liu},
  doi          = {10.1016/j.neucom.2021.12.063},
  journal      = {Neurocomputing},
  pages        = {80-88},
  shortjournal = {Neurocomputing},
  title        = {DLDL: Dynamic label dictionary learning via hypergraph regularization},
  volume       = {475},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Supervised assisted deep reinforcement learning for
emergency voltage control of power systems. <em>NEUCOM</em>,
<em>475</em>, 69–79. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity of power systems makes existing deep reinforcement learning-based emergency voltage control methods face challenges in learning speed and data utilization efficiency. Meanwhile, the accumulated data containing expert experience and domain knowledge has not been fully utilized to improve the performance of the deep reinforcement learning methods. To address the above issues, a novel hybrid emergency voltage control method that combines expert experience and machine intelligence is proposed in this paper. Specifically, the expert experience in the off-line demonstration is extracted through a behavioral cloning model and the deep reinforcement learning method is applied to discover and learn new knowledge autonomously. A special supervised expert loss is designed to utilize the pre-trained behavioral cloning model to assist the self-learning process. The demonstration is dynamically updated during the training process such that the behavioral cloning model and the deep reinforcement learning model can facilitate each other continuously. Experiments are conducted on the open-source RLGC platform to validate the performance and the experimental results show that the proposed method can effectively improve the learning speed and the applicability of the model to different test situations.},
  archive      = {J_NEUCOM},
  author       = {Xiaoshuang Li and Xiao Wang and Xinhu Zheng and Yuxin Dai and Zhihong Yu and Jun Jason Zhang and Guangquan Bu and Fei-Yue Wang},
  doi          = {10.1016/j.neucom.2021.12.043},
  journal      = {Neurocomputing},
  pages        = {69-79},
  shortjournal = {Neurocomputing},
  title        = {Supervised assisted deep reinforcement learning for emergency voltage control of power systems},
  volume       = {475},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fixed-time stochastic synchronization of impulsive
multi-weighted complex dynamical networks with non-chattering control.
<em>NEUCOM</em>, <em>475</em>, 53–68. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the fixed-time stochastic synchronization problem of multi-weighted complex dynamical networks with impulsive effects. Different from most of previous networks, stochastic disturbances and impulsive effects are considered in this model. The non-chattering controller is utilized, and by devising a novel time-dependent Lyapunov function and dividing the impulsive intervals, a new sufficient criterion for the fixed-time stochastic synchronization (FDTSS) of multi-weighted complex dynamical networks (MWCDNs) is obtained. Secondly, compared with some existing results, this paper proposes a novel means of calculating the settling time by constructing comparison systems and exploiting the method of the classification discussion, and the settling time does not depend on the initial values of the system. In addition, compared with the existing fixed-time and finite-time controllers, the controller devised in this paper is continuous and do not involve sign functions, which non-chattering phenomenon in practical applications. Finally, the Lorenz system is submitted to certify the justifiability of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Wenying Yuan and Shengli Shi and Yuechao Ma},
  doi          = {10.1016/j.neucom.2021.12.031},
  journal      = {Neurocomputing},
  pages        = {53-68},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time stochastic synchronization of impulsive multi-weighted complex dynamical networks with non-chattering control},
  volume       = {475},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Confidence level auto-weighting robust multi-view subspace
clustering. <em>NEUCOM</em>, <em>475</em>, 38–52. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the subspace clustering task of multi-view data, it is an important research content to mine the complementary feature across all views. However, when learning the consensus representation of all views, each view may have different confidence levels. In addition, owing to the non-linearity and noise pollution of the data, different samples in the same view may have different confidence levels. Unfortunately, most of the existing methods only assign a uniform weight to each view, and may only obtain a suboptimal solution. In this work, we put forward a confidence level auto-weighting robust multi-view subspace clustering (CLWRMSC) model. Specifically, we designed an adaptive sample weighting strategy that enables our model to focus on the confidence of both views and samples while learning the consensus representation of all views. At the same time, using the self-expression property of subspace, an adaptive low-rank multi-kernel learning (MKL) strategy is designed. Further, the Weighted Truncated Schatten p -Norm (WTSN) is proposed to better solve the optimization problem of low-rank constraints. A lot of experiments prove that the proposed model is a superior clustering algorithm .},
  archive      = {J_NEUCOM},
  author       = {Xiaoqian Zhang and Jing Wang and Xuqian Xue and Huaijiang Sun and Jiangmei Zhang},
  doi          = {10.1016/j.neucom.2021.12.029},
  journal      = {Neurocomputing},
  pages        = {38-52},
  shortjournal = {Neurocomputing},
  title        = {Confidence level auto-weighting robust multi-view subspace clustering},
  volume       = {475},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Further results on asymptotic and finite-time stability
analysis of fractional-order time-delayed genetic regulatory networks.
<em>NEUCOM</em>, <em>475</em>, 26–37. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research work aims at investigating the fractional-order genetic regulatory networks (FOGRNs) with feedback regulation delays. First, we have established the existence and uniqueness of considered systems based on the Banach fixed point theorem . Second, based on a Lyapunov method and fractional-order Razumikhin theorem, some novel sufficient criteria are obtained to ensure the global asymptotic stability for addressing fractional-order systems. To this end, a suitable controller that includes discontinuous terms is designed to guarantee the system states tends to zero asymptotically in a finite time when the system states do not admit stable performance. Moreover, the upper bound of the settling-time for finite-time stability is also estimated accurately. Finally, two numerical examples are presented to verify the correctness of the obtained stability results.},
  archive      = {J_NEUCOM},
  author       = {A. Pratap and R. Raja and Ravi P. Agarwal and J. Alzabut and M. Niezabitowski and E. Hincal},
  doi          = {10.1016/j.neucom.2021.11.088},
  journal      = {Neurocomputing},
  pages        = {26-37},
  shortjournal = {Neurocomputing},
  title        = {Further results on asymptotic and finite-time stability analysis of fractional-order time-delayed genetic regulatory networks},
  volume       = {475},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust doubly stochastic graph clustering. <em>NEUCOM</em>,
<em>475</em>, 15–25. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph clustering has achieved promising performance in various real-world applications, and attracted sufficient attention in machine learning . Generally, it encodes the samples’ relationship with an affinity graph, and then conducts graph-theoretic optimization to partition the samples into clusters. The performance of the graph clustering methods may be affected by many factors, i.e., the graph quality, the loss measurement and the ad hoc post-processing. In this paper, a new Robust Doubly Stochastic graph clustering method (RDS) is presented, which has the following advantages: (1) it learns a doubly stochastic graph with the self-expression strategy automatically, and does not need the graph normalization step to improve the graph quality; (2) it utilizes a new loss function to calculate the approximation error, which is robust to the outliers that far from the normal samples; (3) it generates the cluster indicator according to the learned graph directly, such that the uncertainty caused by the post-processing procedure can be avoided. Extensive experiments on eight benchmarks demonstrate the effectiveness of RDS on data clustering , and show its advantages over the previous graph clustering methods are also verified.},
  archive      = {J_NEUCOM},
  author       = {Mulin Chen and Maoguo Gong and Xuelong Li},
  doi          = {10.1016/j.neucom.2021.12.020},
  journal      = {Neurocomputing},
  pages        = {15-25},
  shortjournal = {Neurocomputing},
  title        = {Robust doubly stochastic graph clustering},
  volume       = {475},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Min–max q-learning for multi-player pursuit-evasion games.
<em>NEUCOM</em>, <em>475</em>, 1–14. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address a pursuit-evasion game involving multiple players by utilizing tools and techniques from reinforcement learning and matrix game theory . In particular, we consider the problem of steering an evader to a goal destination while avoiding capture by multiple pursuers, which is a high-dimensional and computationally intractable problem in general. In our proposed approach, we first formulate the multi-agent pursuit-evasion game as a sequence of discrete matrix games. Next, in order to simplify the solution process, we transform the high-dimensional state space into a low-dimensional manifold and the continuous action space into a feature-based space, which is a discrete abstraction of the original space. Based on these transformed state and action spaces, we subsequently employ min–max Q-learning, to generate the entries of the payoff matrix of the game, and subsequently obtain the optimal action for the evader at each stage. Finally, we present extensive numerical simulations to evaluate the performance of the proposed learning-based evading strategy in terms of the evader’s ability to reach the desired target location without being captured, as well as computational efficiency.},
  archive      = {J_NEUCOM},
  author       = {Jhanani Selvakumar and Efstathios Bakolas},
  doi          = {10.1016/j.neucom.2021.12.025},
  journal      = {Neurocomputing},
  pages        = {1-14},
  shortjournal = {Neurocomputing},
  title        = {Min–Max Q-learning for multi-player pursuit-evasion games},
  volume       = {475},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Context-aware deep kernel networks for image annotation.
<em>NEUCOM</em>, <em>474</em>, 154–167. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context plays a crucial role in visual recognition as it provides complementary clues for different learning tasks including image classification and annotation. As the performances of these tasks are currently reaching a plateau, any extra knowledge, including context, should be leveraged in ordficant leaps in these performances. In the particular scenario of kernel machines , context-aware kernel design aims at learning positive semi-definite similarity functions which return high values not only when data share similar contents, but also similar structures (a.k.a. contexts). However, the use of context in kernel design has not been fully explored; indeed, context in these solutions is handcrafted instead of being learned. In this paper, we introduce a novel deep network architecture that learns context in kernel design. This architecture is fully determined by the solution of an objective function mixing a content term that captures the intrinsic similarity between data, a context criterion which models their structure and a regularization term that helps designing smooth kernel network representations. The solution of this objective function defines a particular deep network architecture whose parameters correspond to different variants of learned contexts including layerwise, stationary and classwise; larger values of these parameters correspond to the most influencing contextual relationships between data. Extensive experiments conducted on the challenging ImageCLEF Photo Annotation, Corel5k and NUS-WIDE benchmarks show that our deep context networks are highly effective for image classification and the learned contexts further enhance the performance of image annotation.},
  archive      = {J_NEUCOM},
  author       = {Mingyuan Jiu and Hichem Sahbi},
  doi          = {10.1016/j.neucom.2021.12.006},
  journal      = {Neurocomputing},
  pages        = {154-167},
  shortjournal = {Neurocomputing},
  title        = {Context-aware deep kernel networks for image annotation},
  volume       = {474},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of recommender systems with multi-objective
optimization. <em>NEUCOM</em>, <em>474</em>, 141–153. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have been widely applied to several domains and applications to assist decision making by recommending items tailored to user preferences. One of the popular recommendation algorithms is the model-based approach which optimizes a specific objective to improve the recommendation performance. These traditional recommendation models usually deal with a single objective, such as minimizing the prediction errors or maximizing the ranking quality of the recommendations. In recent years, there is an emerging demand for multi-objective recommender systems in which multiple objectives are considered and the recommendations can be optimized by the multi-objective optimization. For example, a recommendation model may be built by optimizing multiple metrics, such as accuracy, novelty and diversity of the recommendations. The multi-objective optimization methodologies have been well developed and applied to the area of recommender systems. In this article, we provide a comprehensive literature review of the multi-objective recommender systems. Particularly, we identify the circumstances in which a multi-objective recommender system could be useful, summarize the methodologies and evaluation approaches in these systems, point out existing challenges or weaknesses, finally provide the guidelines and suggestions for the development of multi-objective recommender systems.},
  archive      = {J_NEUCOM},
  author       = {Yong Zheng and David (Xuejun) Wang},
  doi          = {10.1016/j.neucom.2021.11.041},
  journal      = {Neurocomputing},
  pages        = {141-153},
  shortjournal = {Neurocomputing},
  title        = {A survey of recommender systems with multi-objective optimization},
  volume       = {474},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Coreset: Hierarchical neuromorphic computing supporting
large-scale neural networks with improved resource efficiency.
<em>NEUCOM</em>, <em>474</em>, 128–140. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crossbar-based neuromorphic chips promise improved energy efficiency for spiking neural networks (SNNs), but suffer from the limited fan-in/fan-out constraints and resource mapping inefficiency. In this paper, we propose a new hardware mechanism to enable configurable combination of cores, called coreset . Using this hierarchical method, our end-to-end CSM (which stands for the ‘CoreSet Method’) framework efficiently solves the fan-in/fan-out issues and significantly improves the resource efficiency. Experiment results show that CSM can efficiently support complex network structures as well as significantly improving accuracies. Up to 4.6\% improvement compared with those achieved by other neuromorphic chips (i.e. IBM TrueNorth and Intel Loihi), on the CIFAR-10, CIFAR-100 and SVHN datasets is achieved, matching the accuracies of state-of-the-art SNN models. In addition, compared with IBM TrueNorth, CSM achieves improvements of up to 18.5 × , 6.04 × 18.5×,6.04× and 3.33 × 3.33× in memory efficiency, core efficiency and extrapolated throughput, respectively, thus enabling support for large-scale modern networks (such as VGG). In fact, our method can find optimal core sizes for minimal silicon area. As a proof of concept, we have implemented an FPGA emulation of coreset-supported neuromorphic computing. It achieves up to 7 , 737 × 7,737× speed-up compared to software simulation, thus not only facilitating SNN structure exploration and verification in a timely manner, but also enabling earlier prototyping for better neuromorphic hardware performance investigation.},
  archive      = {J_NEUCOM},
  author       = {Liwei Yang and Huaipeng Zhang and Tao Luo and Chuping Qu and Myat Thu Linn Aung and Yingnan Cui and Jun Zhou and Ming Ming Wong and Junran Pu and Anh Tuan Do and Rick Siow Mong Goh and Weng Fai Wong},
  doi          = {10.1016/j.neucom.2021.12.021},
  journal      = {Neurocomputing},
  pages        = {128-140},
  shortjournal = {Neurocomputing},
  title        = {Coreset: Hierarchical neuromorphic computing supporting large-scale neural networks with improved resource efficiency},
  volume       = {474},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). RELAXNet: Residual efficient learning and attention
expected fusion network for real-time semantic segmentation.
<em>NEUCOM</em>, <em>474</em>, 115–127. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a dense prediction problem, semantic segmentation consumes extensive memory and computational resources. However, the application of semantic segmentation requires the model to perform real-time analyses in portable devices, thus it is crucial to seek a trade-off between segmentation accuracy and inference speed. In this paper, we propose a lightweight semantic segmentation method based on attention mechanism to address this problem. First, we use novel Efficient Bottleneck Residual (EBR) Module and Efficient Asymmetric Bottleneck Residual (EABR) Module to extract both local and contextual information,which adopt a well-designed combination of depth-wise convolution, dilated convolution and factorized convolution, with channel shuffle to boost information interaction. Second, we introduce attention mechanism into skip connection between the encoder and decoder to promote reasonable fusion of high-level and low-level features, which furtherly enhance the accuracy. With only 1.9 M parameters, our model obtains 74.8\% mIoU and 64 FPS running speed on Cityscapes dataset and 71.2\% mIoU and 79 FPS running speed on Camvid dataset. Experiments demonstrate that our model achieves competitive results in terms of segmentation accuracy and running speed while controlling parameters.},
  archive      = {J_NEUCOM},
  author       = {Jin Liu and Xiaoqing Xu and Yiqing Shi and Cheng Deng and Miaohua Shi},
  doi          = {10.1016/j.neucom.2021.12.003},
  journal      = {Neurocomputing},
  pages        = {115-127},
  shortjournal = {Neurocomputing},
  title        = {RELAXNet: Residual efficient learning and attention expected fusion network for real-time semantic segmentation},
  volume       = {474},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TransMKR: Translation-based knowledge graph enhanced
multi-task point-of-interest recommendation. <em>NEUCOM</em>,
<em>474</em>, 107–114. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point-of-interest (POI) recommendation aims to predict favorite POIs that have never visited before for users given their historical check-ins records. The introduction of knowledge graph can solve the heterogeneity of auxiliary information. However, the existing knowledge graph methods about POI recommendation only make use of the relationship between users and POIs or the context information (such as time series) for recommendation, but they neglect the deep relation consider the attribute connection of POIs themselves. In this paper, we propose a translation-based knowledge graph enhanced multi-task learning framework (TransMKR) for the POI recommendation. We improve the KGE module of MKR with TransR to quantify the relation between POIs and their attributes. As the POIs vector and the entity vector are actually two descriptions of the same item, the cross-sharing of information between them makes them obtain additional information from each other, and this enhances the expressive ability of POI data, thus it can alleviate the problem of data sparsity . An exquisitely designed structure is devised to capture the deep associated attributes of POIs under different relations. Empirically, this approach achieves the state-of-the-art model for POI recommendation based on geographical location on two public real-world datasets.},
  archive      = {J_NEUCOM},
  author       = {Bojing Hu and Yaqin Ye and Yingqiang Zhong and Jiao Pan and Maosheng Hu},
  doi          = {10.1016/j.neucom.2021.11.049},
  journal      = {Neurocomputing},
  pages        = {107-114},
  shortjournal = {Neurocomputing},
  title        = {TransMKR: Translation-based knowledge graph enhanced multi-task point-of-interest recommendation},
  volume       = {474},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sub-AVG: Overestimation reduction for cooperative
multi-agent reinforcement learning. <em>NEUCOM</em>, <em>474</em>,
94–106. (<a href="https://doi.org/10.1016/j.neucom.2021.12.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decomposing the centralized joint action value(JAV) into per-agent individual action value(IAV) is attractive in cooperative multi-agent reinforcement learning(MARL). In such tasks, IAVs based on local observation can perform decentralized policies, and the JAV is used for end-to-end training through traditional reinforcement learning methods, especially through the Q-learning algorithm. However, the Q-learning-based method suffers from overestimation, in which the overestimated action values may result in a suboptimal policy. In this paper, we show that such overestimation can occur in the above Q-learning-based decomposition method . Our solution is Sub-AVG, which utilizes a lower update target by discarding the larger of previously learned IAVs and averaging the retained ones, thus eliminating the excessive overestimation errors. Experiments in the StarCraft Multi-Agent Challenge(SMAC) environment show that Sub-AVG can lead to lower JAV estimations and better-performing policies.},
  archive      = {J_NEUCOM},
  author       = {Haolin Wu and Jianwei Zhang and Zhuang Wang and Yi Lin and Hui Li},
  doi          = {10.1016/j.neucom.2021.12.039},
  journal      = {Neurocomputing},
  pages        = {94-106},
  shortjournal = {Neurocomputing},
  title        = {Sub-AVG: Overestimation reduction for cooperative multi-agent reinforcement learning},
  volume       = {474},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of neural architecture search. <em>NEUCOM</em>,
<em>474</em>, 82–93. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the impressive progress in neural network architecture design, improving the performance of the existing state-of-the-art models has become increasingly challenging. For this reason, the paradigm for neural architecture design is shifting from being expert-driven to almost fully automated. An emerging body of research related to such machine-aided design is called a Neural Architecture Search (NAS). This paper reviews the recent works on NAS and highlights several crucial concepts and problems of this field.},
  archive      = {J_NEUCOM},
  author       = {Dilyara Baymurzina and Eugene Golikov and Mikhail Burtsev},
  doi          = {10.1016/j.neucom.2021.12.014},
  journal      = {Neurocomputing},
  pages        = {82-93},
  shortjournal = {Neurocomputing},
  title        = {A review of neural architecture search},
  volume       = {474},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Investigating hostile post detection in hindi.
<em>NEUCOM</em>, <em>474</em>, 60–81. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hostile content on Social Media platforms is becoming a problem for governments and organizations. There is a need for AI based intervention which can filter hostile content at scale. The challenge lies in ambiguity of language, absence of training data and local context. In this paper, we investigate Hostile Post Detection for the Hindi Language, which is the topmost language in the Indian Subcontinent in terms of speaker population and third in the world. We extend our prior work in this area along the dimensions of (i) Representations (ii) Data and (iii) Architecture, exploring approaches like Transformers and Multi Task Learning among others, along the way. In this highly experimental study, comparisons are drawn, trends are discovered and insights are presented. We manage to improve on the baseline by 16.5\% and 29.77\% on the two evaluation metrics viz. Coarse Grained F1 Score and Fine Grained F1 Score. We are also able to beat our prior work results by 0.93\% and 9.18\% on these two evaluation metrics respectively. Experiments performed by us number 60 which is larger than the number reported in any other work for Hostility Detection in Hindi, to the best of our knowledge.},
  archive      = {J_NEUCOM},
  author       = {Varad Bhatnagar and Prince Kumar and Pushpak Bhattacharyya},
  doi          = {10.1016/j.neucom.2021.11.096},
  journal      = {Neurocomputing},
  pages        = {60-81},
  shortjournal = {Neurocomputing},
  title        = {Investigating hostile post detection in hindi},
  volume       = {474},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discriminative distribution alignment for domain adaptive
object detection. <em>NEUCOM</em>, <em>474</em>, 48–59. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptive object detection has achieved appealing performance by constructing an effective transferable model for unlabeled target images, which takes advantage of the well-labeled source images with different distributions. However, two crucial factors are overlooked by most current methods: 1) different areas of an image should not be equally aligned since some areas may contribute more to distribution alignment if they contain more discriminative information for classifying the objects; and 2) the objectives of feature alignment and classification should not be independently optimized since it will fail to capture the discriminative information of data. To address these issues, we propose a new domain adaptive object detection model, referred to as discriminative distribution alignment domain adaptive detector. To be specific, the proposed method first makes the model focus on the areas that are quantified with high localization probability at the image level to enhance discrimination between foregrounds and backgrounds. Then the source and target images are aligned at the category level to learn class-invariant features by two adversarial regions-of-interest classifiers. Comprehensive experiments on several visual tasks verify that the proposed method outperforms the competitive domain adaptive object detection methods significantly in unsupervised domain adaptation setting.},
  archive      = {J_NEUCOM},
  author       = {Junchu Huang and Shifu Shen and Zhiheng Zhou and Pengyu Zhang and Kefeng Fan},
  doi          = {10.1016/j.neucom.2021.12.009},
  journal      = {Neurocomputing},
  pages        = {48-59},
  shortjournal = {Neurocomputing},
  title        = {Discriminative distribution alignment for domain adaptive object detection},
  volume       = {474},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LMTracker: Lateral movement path detection based on
heterogeneous graph embedding. <em>NEUCOM</em>, <em>474</em>, 37–47. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced Persistent Threats(APT) with the purpose of stealing confidential data take place all the time. In the APT life cycle, lateral movement is a critical stage towards high-level authority and confidential data. Existing lateral movement detection mainly concentrates on endpoint protection to distinguish compromised hosts. These approaches not only have unfortunate effect but also can not detect lateral movement behavior comprehensively. We design LMTracker, an attack path detection algorithm based on the heterogeneous graph, in order to make up for above shortcomings. LMTracker consists of three modules: heterogeneous graph construction, path representation generation, and unsupervised anomaly-based attack path detection. The core idea of LMTracker is to use event logs and traffic to establish heterogeneous graphs and generate representation vectors for lateral movement paths, then use unsupervised algorithm to implement anomaly-based path detection. This method can not only detect lateral movement paths effectively but also preserve the path relationships. Security professionals can use these paths to analyze attack activities. In two frequently-used public datasets, the evaluation results demonstrate that LMTracker performs significantly better than other methods and can adapt to attack detection in different scenarios. The area under the ROC curve is as high as 0.95.},
  archive      = {J_NEUCOM},
  author       = {Yong Fang and Congshuang Wang and Zhiyang Fang and Cheng Huang},
  doi          = {10.1016/j.neucom.2021.12.026},
  journal      = {Neurocomputing},
  pages        = {37-47},
  shortjournal = {Neurocomputing},
  title        = {LMTracker: Lateral movement path detection based on heterogeneous graph embedding},
  volume       = {474},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3D interacting hand pose and shape estimation from a single
RGB image. <em>NEUCOM</em>, <em>474</em>, 25–36. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating 3D interacting hand poses and shapes from a single RGB image is challenging as it is difficult to distinguish the left and right-hands in interacting hand pose analysis. This paper proposes a network called GroupPoseNet using a grouping strategy to address this problem. GroupPoseNet extracts the left- and right-hand features respectively and thus avoids the mutual affection between the interacting hands. Empowered by a novel up-sampling block called MF-Block predicting 2D heat-maps in a progressive way by fusing image features , hand pose features, and multi-scale features, GroupPoseNet is effective and robust to severe occlusions. To achieve an effective 3D hand reconstruction, we design a transformer mechanism based inverse kinematics module(termed TikNet) to map 3D joint locations to hand shape and pose parameters of MANO hand model. Comprehensive experiments on the InterHand2.6M dataset show GroupPoseNet outperforms existing methods by a significant margin. Additional experiments also demonstrate it has a good generalization ability in the problems including left-hand, right-hand and interacting hand pose estimation from a single RGB image . We also show the efficiency of TikNet by the quantitative and qualitative results.},
  archive      = {J_NEUCOM},
  author       = {Chengying Gao and Yujia Yang and Wensheng Li},
  doi          = {10.1016/j.neucom.2021.12.013},
  journal      = {Neurocomputing},
  pages        = {25-36},
  shortjournal = {Neurocomputing},
  title        = {3D interacting hand pose and shape estimation from a single RGB image},
  volume       = {474},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards more effective PRM-based crowd counting via a
multi-resolution fusion and attention network. <em>NEUCOM</em>,
<em>474</em>, 13–24. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper focuses on improving the recent plug-and-play patch rescaling module (PRM) based approaches for crowd counting. In order to make full use of the PRM potential and obtain more reliable and accurate results for challenging images with crowd-variation, large perspective, extreme occlusions, and cluttered background regions, we propose a new PRM based multi-resolution and multi-task crowd counting network by exploiting the PRM module with more effectiveness and potency. The proposed model consists of three deep-layered branches with each branch generating feature maps of different resolutions. These branches perform a feature-level fusion across each other to build the vital collective knowledge to be used for the final crowd estimate. Additionally, early-stage feature maps undergo visual attention to strengthen the later-stage channel’s understanding of the foreground regions. The integration of these deep branches with the PRM module and the early-attended blocks proves to be more effective than the original PRM based schemes through extensive numerical and visual evaluations on four benchmark datasets. The proposed approach yields a significant improvement by a margin of 12.6\% 12.6\% in terms of the RMSE evaluation criterion. It also outperforms state-of-the-art methods in cross-dataset evaluations.},
  archive      = {J_NEUCOM},
  author       = {Usman Sajid and Guanghui Wang},
  doi          = {10.1016/j.neucom.2021.12.027},
  journal      = {Neurocomputing},
  pages        = {13-24},
  shortjournal = {Neurocomputing},
  title        = {Towards more effective PRM-based crowd counting via a multi-resolution fusion and attention network},
  volume       = {474},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Urban scene based semantical modulation for pedestrian
detection. <em>NEUCOM</em>, <em>474</em>, 1–12. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite recent progress, pedestrian detection still suffers from the troublesome problems of small objects, occlusions, and numerous false positives . Intuitively, the rich context information available from urban scenes could help determine the presence and location of pedestrians. For example, roads and sidewalks are good cues for potential pedestrians, while detections on buildings and trees are often false positives. However, most existing pedestrian detectors ignore or inadequately utilize semantic context. In this paper, in order to make full use of the urban-scene semantics to facilitate pedestrian detection, we propose a new method called Semantical Modulation based Pedestrian Detector (SMPD) . First, for efficiency, a semantic prediction module is jointly learned with a baseline detector for semantic predictions. Second, a semantic integration module is designed to exploit the urban-scene semantic context for detection. Specifically, we force it to be an independent detection branch based solely on semantic information. In this way, together with the baseline detector, the fused detection results explicitly depend on both the learned appearance features and the scene context around pedestrians. In addition, while existing methods cannot be applied to the datasets where semantic annotations are not available for training, we introduce a semi-supervised transfer learning approach to make our method suitable for more scenarios. We demonstrate experimentally that, thanks to the integration of semantic context from urban scenes, SMPD can accurately detect small and occluded pedestrians, as well as effectively remove false positives. As a result, SMPD achieves the new state of the art on the Citypersons and Caltech datasets.},
  archive      = {J_NEUCOM},
  author       = {Hangzhi Jiang and Shengcai Liao and Jinpeng Li and Véronique Prinet and Shiming Xiang},
  doi          = {10.1016/j.neucom.2021.11.091},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {Urban scene based semantical modulation for pedestrian detection},
  volume       = {474},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DiverGAN: An efficient and effective single-stage framework
for diverse text-to-image generation. <em>NEUCOM</em>, <em>473</em>,
182–198. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we concentrate on the text-to-image synthesis task that aims at automatically producing perceptually realistic pictures from text descriptions. Recently, several single-stage methods have been proposed to deal with the problems of a more complicated multi-stage modular architecture . However, they often suffer from the lack-of-diversity issue, yielding similar outputs given a single textual sequence. To this end, we present an efficient and effective single-stage framework (DiverGAN) to generate diverse, plausible and semantically consistent images according to a natural-language description. DiverGAN adopts two novel word-level attention modules, i.e., a channel-attention module (CAM) and a pixel-attention module (PAM), which model the importance of each word in the given sentence while allowing the network to assign larger weights to the significant channels and pixels semantically aligning with the salient words. After that, Conditional Adaptive Instance-Layer Normalization (CAdaILN) is introduced to enable the linguistic cues from the sentence embedding to flexibly manipulate the amount of change in shape and texture, further improving visual-semantic representation and helping stabilize the training. Also, a dual-residual structure is developed to preserve more original visual features while allowing for deeper networks, resulting in faster convergence speed and more vivid details. Furthermore, we propose to plug a fully-connected layer into the pipeline to address the lack-of-diversity problem, since we observe that a dense layer will remarkably enhance the generative capability of the network, balancing the trade-off between a low-dimensional random latent code contributing to variants and modulation modules that use high-dimensional and textual contexts to strength feature maps. Inserting a linear layer after the second residual block achieves the best variety and quality. Both qualitative and quantitative results on benchmark data sets demonstrate the superiority of our DiverGAN for realizing diversity, without harming quality and semantic consistency .},
  archive      = {J_NEUCOM},
  author       = {Zhenxing Zhang and Lambert Schomaker},
  doi          = {10.1016/j.neucom.2021.12.005},
  journal      = {Neurocomputing},
  pages        = {182-198},
  shortjournal = {Neurocomputing},
  title        = {DiverGAN: An efficient and effective single-stage framework for diverse text-to-image generation},
  volume       = {473},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nearest neighbors-based adaptive density peaks clustering
with optimized allocation strategy. <em>NEUCOM</em>, <em>473</em>,
159–181. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peaks clustering (DPC) model is simple and effective in clustering data of any shape, and has attracted wide attention from scholars in recent years. However, it is difficult for DPC to determine the cutoff distance when calculating the local density of points, and to select the correct cluster centers of data with large differences of density between clusters or multi-density peaks in clusters; in addition, the point allocation method in DPC has low accuracy. To overcome these drawbacks, this paper presents a novel nearest neighbors-based adaptive DPC algorithm with an optimized allocation strategy (NADPC in short), and demonstrates its application in image clustering. First, the mutual nearest neighbor relationship between points is defined, the mutual neighborhood of point is proposed, and then a new local density of points is defined and does not need to set the cutoff distance . The candidate cluster centers and relative density are developed. According to the relative density and the high-density nearest neighbor distance of candidate cluster centers, their credibility as the cluster centers is calculated, and then the cluster centers are selected. Second, the mutual neighbor degree and similarity between two points are constructed. The neighborhoods of points are defined according to the high-density nearest neighbor, shared nearest neighbors, mutual neighbor degree and similarity, respectively. The similarity set, similarity domain, positive set, negative set, prediction set, positive value and predicted value of point are provided based on the above-mentioned neighborhoods. Then the optimized allocation strategy of points is proposed. Finally, the allocation algorithms of the non-abnormal and abnormal points are designed, respectively, and then the NADPC algorithm is designed. To evaluate the effectiveness of NADPC, it has been applied to 22 synthetic datasets and 26 actual datasets including 4 image datasets, and has great performance in terms of several evaluation metrics when compared with the other latest clustering algorithms.},
  archive      = {J_NEUCOM},
  author       = {Lin Sun and Xiaoying Qin and Weiping Ding and Jiucheng Xu},
  doi          = {10.1016/j.neucom.2021.12.019},
  journal      = {Neurocomputing},
  pages        = {159-181},
  shortjournal = {Neurocomputing},
  title        = {Nearest neighbors-based adaptive density peaks clustering with optimized allocation strategy},
  volume       = {473},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Erratum to “progressive conditional GAN-based augmentation
for 3D object recognition” [neurocomputing 460 (2021) 20–30].
<em>NEUCOM</em>, <em>473</em>, 158. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {A.A.M. Muzahid and Wan Wanggen and Ferdous Sohel and Mohammed Bennamoun and Li Hou and Hidayat Ullah},
  doi          = {10.1016/j.neucom.2021.12.024},
  journal      = {Neurocomputing},
  pages        = {158},
  shortjournal = {Neurocomputing},
  title        = {Erratum to “Progressive conditional GAN-based augmentation for 3D object recognition” [Neurocomputing 460 (2021) 20–30]},
  volume       = {473},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-task manifold learning for small sample size datasets.
<em>NEUCOM</em>, <em>473</em>, 138–157. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we develop a method for multi-task manifold learning. The method aims to improve the performance of manifold learning for multiple tasks, particularly when each task has a small number of samples. Furthermore, the method also aims to generate new samples for new tasks, in addition to new samples for existing tasks. In the proposed method, we use two different types of information transfer: instance transfer and model transfer. For instance transfer , datasets are merged among similar tasks, whereas for model transfer, the manifold models are averaged among similar tasks. For this purpose, the proposed method consists of a set of generative manifold models corresponding to the tasks, which are integrated into a general model of a fiber bundle. We applied the proposed method to artificial datasets and face image sets, and the results showed that the method was able to estimate the manifolds, even for a tiny number of samples.},
  archive      = {J_NEUCOM},
  author       = {Hideaki Ishibashi and Kazushi Higa and Tetsuo Furukawa},
  doi          = {10.1016/j.neucom.2021.11.043},
  journal      = {Neurocomputing},
  pages        = {138-157},
  shortjournal = {Neurocomputing},
  title        = {Multi-task manifold learning for small sample size datasets},
  volume       = {473},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-based decentralized learning scheme for nonlinear
systems with mismatched interconnections. <em>NEUCOM</em>, <em>473</em>,
127–137. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the decentralized learning scheme for nonlinear systems with mismatched interconnections is developed by using the off-policy integral reinforcement leaning algorithm. First, the decentralized control of the overall system is transformed into the optimal control of each subsystem by introducing an auxiliary control. In order to relax the knowledge of system dynamics, a model-free policy iteration algorithm is derived based on the off-policy integral reinforcement learning . Then, the model-free policy iteration algorithm is used to solve the related Hamilton–Jacobi-Bellman equations, where only the collected system data is required. For implementation purpose, neural networks are employed to approximate the optimal cost functions and the optimal control policies, respectively. Moreover, the least squares method and the experience replay technique are combined to learn neural network weights. Finally, a mismatched interconnected system and a photovoltaic power system are presented to verify the effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Chaoxu Mu and Jiangwen Peng and Hao Luo and Ke Wang},
  doi          = {10.1016/j.neucom.2021.11.002},
  journal      = {Neurocomputing},
  pages        = {127-137},
  shortjournal = {Neurocomputing},
  title        = {Data-based decentralized learning scheme for nonlinear systems with mismatched interconnections},
  volume       = {473},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Skeleton-based abnormal gait recognition with
spatio-temporal attention enhanced gait-structural graph convolutional
networks. <em>NEUCOM</em>, <em>473</em>, 116–126. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormal gait recognition is of great significance for medical monitoring and clinical diagnosis. Recent progress on skeleton-based abnormal gait recognition using recurrent neural networks (RNNs) and temporal-only convolutional networks (TCNs) has been substantial. These methods usually rely on hand-crafted features or treat the skeleton as a kind of grid-shape structure data , thus resulting in limited representation and difficulties of generalization. To solve this problem, we propose a spatio-temporal attention enhanced gait-structural graph convolutional network (AGS-GCN). First, we construct a gait skeleton graph according to clinical prior knowledges and reliability of deep sensors in the gait analysis . A novel partition strategy is designed for the gait graph to simultaneously extract multi-scale gait features from the raw skeleton data. Moreover, in order to extract discriminative gait representations, a spatio-temporal attention mechanism is proposed to layer-wise enhance the features of key joints. The soft attention mechanism can boost the ability to explore fine-grained gait features, and alleviate the over-smoothing of feature maps in deep graph convolutional networks . Extensive experiments on two abnormal gait datasets with different numbers of gait patterns and examples demonstrate that our system achieves better performance than the state-of-the-art works.},
  archive      = {J_NEUCOM},
  author       = {Haoyu Tian and Xin Ma and Hanbo Wu and Yibin Li},
  doi          = {10.1016/j.neucom.2021.12.004},
  journal      = {Neurocomputing},
  pages        = {116-126},
  shortjournal = {Neurocomputing},
  title        = {Skeleton-based abnormal gait recognition with spatio-temporal attention enhanced gait-structural graph convolutional networks},
  volume       = {473},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DefectDet: A deep learning architecture for detection of
defects with extreme aspect ratios in ultrasonic images.
<em>NEUCOM</em>, <em>473</em>, 107–115. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-destructive testing (NDT) is a set of techniques used for material inspection and detection of defects. Ultrasonic testing (UT) is one of the NDT techniques, commonly used to inspect components in the oil and gas industry, aerospace, and various types of power plants. Acquisition of the UT data is currently done automatically using robotic manipulators. This ensures the precision and uniformity of the acquired data. On the other hand, the analysis is still done manually by trained experts. Since the acquired UT data can be represented in the form of images, computer vision algorithms can be applied to analyze the content of images and localize defects. In this work, we propose a novel deep learning architecture designed specifically for defect detection from UT images. We propose a lightweight feature extractor that improves the precision and efficiency of the detector. We also modify the detection head to improve the detection of the objects with extreme aspect ratios which are common in UT images. We tested our approach on an in-house dataset with over 4000 images. The proposed architecture outperformed the previous state-of-the-art method by 1.7\% (512 × 512 px input resolution) and 2.7\% (384 × 384 px input resolution) while significantly decreasing the inference time.},
  archive      = {J_NEUCOM},
  author       = {Duje Medak and Luka Posilović and Marko Subašić and Marko Budimir and Sven Lončarić},
  doi          = {10.1016/j.neucom.2021.12.008},
  journal      = {Neurocomputing},
  pages        = {107-115},
  shortjournal = {Neurocomputing},
  title        = {DefectDet: A deep learning architecture for detection of defects with extreme aspect ratios in ultrasonic images},
  volume       = {473},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new approach to smooth path planning of mobile robot based
on quartic bezier transition curve and improved PSO algorithm.
<em>NEUCOM</em>, <em>473</em>, 98–106. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new approach is proposed for the smooth path planning of mobile robot based on a new quartic Bezier transition curve and an improved particle swarm optimization (PSO) algorithm. First, a dedicatedly constructed quartic Bezier transition curve with three overlapped control points is developed to fulfil the G 3 G3 -continuity of the smooth path at the joints of the path segments, so as to guarantee the high-order smoothness of the path for the movement of mobile robot. Then, the smooth path planning of mobile robot is formulated mathematically as an optimization problem under several criteria and constraints of the smooth path, e.g. length, smoothness, safety and robot kinematics. Furthermore, an improved PSO with adaptive weighted delay velocity (PSO-AWDV) algorithm is presented for the optimization problem of smooth path planning, where the parameter relationship to ensure the convergence of PSO-AWDV is derived through the stability analysis of the algorithm. Finally, several simulation experiments are carried out to confirm the effectiveness and superiority of the proposed new approach combined with the new quartic Bezier transition curve and the improved PSO-AWDV algorithm.},
  archive      = {J_NEUCOM},
  author       = {Lin Xu and Maoyong Cao and Baoye Song},
  doi          = {10.1016/j.neucom.2021.12.016},
  journal      = {Neurocomputing},
  pages        = {98-106},
  shortjournal = {Neurocomputing},
  title        = {A new approach to smooth path planning of mobile robot based on quartic bezier transition curve and improved PSO algorithm},
  volume       = {473},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TNCR: Table net detection and classification dataset.
<em>NEUCOM</em>, <em>473</em>, 79–97. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present TNCR, a new table dataset with varying image quality collected from open access websites. TNCR dataset can be used for table detection in scanned document images and their classification into 5 different classes. TNCR contains 9428 labeled tables with approximately 6621 images. In this paper, we have implemented state-of-the-art deep learning-based methods for table detection to create several strong baselines. Deformable DERT with Resnet-50 Backbone Network achieves the highest performance compared to other methods with a precision of 86.7\%, recall of 89.6\%, and f1 score of 88.1\% on the TNCR dataset. We have made TNCR open source in the hope of encouraging more deep learning approaches to table detection, classification and structure recognition. The dataset and trained model checkpoints are available at https://github.com/abdoelsayed2016/TNCR_Dataset .},
  archive      = {J_NEUCOM},
  author       = {Abdelrahman Abdallah and Alexander Berendeyev and Islam Nuradin and Daniyar Nurseitov},
  doi          = {10.1016/j.neucom.2021.11.101},
  journal      = {Neurocomputing},
  pages        = {79-97},
  shortjournal = {Neurocomputing},
  title        = {TNCR: Table net detection and classification dataset},
  volume       = {473},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Addressing scale imbalance for small object detection with
dense detector. <em>NEUCOM</em>, <em>473</em>, 68–78. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are severe challenges on small object detection when using general object detector, especially scale imbalance on samples and features. Anchor-based detector performs poorly on small object detection because IoUs are too low to regress the objects. Key-point detector is hard to detect small objects for containing little semantic information. In contrast, a dense detector which directly learns an object via dense points is potential for small object detection. But they only catch fewer small objects because few of them can address scale imbalance brought by label assignment and feature extraction. We propose a dense detector named Libra EBox which includes Libra Ellipse Sampling (LES) and Residual Low-level Feature Enhancement (RiLFE). LES regulates positive regions of various objects by rescaling an ellipse box to catch samples of small object as much as possible. RiLFE is designed by several low-level feature maps to enhance small object’s feature representation. Experimental results show that our Libra EBox outperforms FoveaBox, FCOS and RetinaNet by 2.0\% AP, 1.7\% AP and 2.2\% AP respectively for small objects on MS-COCO test-dev, and also outperforms most popular dense detectors on VisDrone-DET2018 and TinyPerson.},
  archive      = {J_NEUCOM},
  author       = {Shuqin Huang and Qiong Liu},
  doi          = {10.1016/j.neucom.2021.11.107},
  journal      = {Neurocomputing},
  pages        = {68-78},
  shortjournal = {Neurocomputing},
  title        = {Addressing scale imbalance for small object detection with dense detector},
  volume       = {473},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Trapezoidal type-2 fuzzy inference system with tensor
unfolding structure learning method. <em>NEUCOM</em>, <em>473</em>,
54–67. (<a href="https://doi.org/10.1016/j.neucom.2021.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the paper, trapezoidal type-2 fuzzy inference system ( TT2FIS ) is introduced. To construct the type-2 fuzzy inference system, trapezoidal type-2 fuzzy sets are adopted to construct the antecedent part of the fuzzy rules, the centers of the fuzzy sets are roughly clustered by an evolving autonomous data partitioning algorithm. To further eliminate the effect of the centers that are generated by dataset itself, and it can be easily impacted by the unbalance data, the data clouds that are generated by autonomous data partitioning algorithm are filtered by Hammersley sequence, and symmetrical trapezoidal type-2 fuzzy sets are generated by the generated cluster centers and problem-free standard deviation generating method. To the consequent part, generalized type-2 TSK consequent is formulated by tensor, which is obtained via three constituent parts of the trapezoidal type-2 fuzzy sets ( lower membership function, upper membership function and type-reduction set of data samples), the parameters of consequent part are the iterative results of a matrix equation that is unfolded from the tensor. Finally, simulation results are carried out to verify the effectiveness of the proposed trapezoidal type-2 fuzzy inference system. Simulation results show that the generalization of the TT2FIS is better than the coincide type-2 fuzzy inference system or adaptive type-1 fuzzy inference system.},
  archive      = {J_NEUCOM},
  author       = {Sharina Huang and Guoliang Zhao and Zhi Weng and Shengyun Ma},
  doi          = {10.1016/j.neucom.2021.12.011},
  journal      = {Neurocomputing},
  pages        = {54-67},
  shortjournal = {Neurocomputing},
  title        = {Trapezoidal type-2 fuzzy inference system with tensor unfolding structure learning method},
  volume       = {473},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Chinese named entity recognition: The state of the art.
<em>NEUCOM</em>, <em>473</em>, 37–53. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named Entity Recognition(NER), one of the most fundamental problems in natural language processing , seeks to identify the boundaries and types of entities with specific meanings in natural language text. As an important international language, Chinese has uniqueness in many aspects, and Chinese NER (CNER) is receiving increasing attention. In this paper, we give a comprehensive survey of recent advances in CNER. We first introduce some preliminary knowledge, including the common datasets, tag schemes, evaluation metrics and difficulties of CNER. Then, we separately describe recent advances in traditional research and deep learning research of CNER, in which the CNER with deep learning is our focus. We summarize related works in a basic three-layer architecture, including character representation, context encoder, and context encoder and tag decoder. Meanwhile, the attention mechanism and adversarial-transfer learning methods based on this architecture are introduced. Finally, we present the future research trends and challenges of CNER.},
  archive      = {J_NEUCOM},
  author       = {Pan Liu and Yanming Guo and Fenglei Wang and Guohui Li},
  doi          = {10.1016/j.neucom.2021.10.101},
  journal      = {Neurocomputing},
  pages        = {37-53},
  shortjournal = {Neurocomputing},
  title        = {Chinese named entity recognition: The state of the art},
  volume       = {473},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A dual-model deep learning method for sleep apnea detection
based on representation learning and temporal dependence.
<em>NEUCOM</em>, <em>473</em>, 24–36. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sleep apnea (SA) is a sleep-breathing disorder accompanied by multiple complications. The SA detection method based on a single-lead electrocardiogram (ECG) has the characteristics of low power consumption and is desirable for the development of wearable equipment. This study proposed a dual-model deep learning method to perform representation learning and introduce long-term temporal dependence . First, the Christov algorithm was used to obtain the RR interval (RRI) of each 1-minute ECG segment, and the adaptive synthetic (ADASYN) sampling method was employed to synthesize the RRI series of the minority class to address the imbalanced learning problem. Then, a representation learning model based on the one-dimensional convolutional neural network (1DCNN-RLM) was built to extract the feature vector of the RRI series. Eventually, a temporal dependence model based on the bidirectional gated recurrent unit (BiGRU-TDM) was constructed to learn the state (SA/normal) transition pattern between the segments and complete the classification task . We employed the apnea-ECG database for experiments. For per-segment detection results, the accuracy, sensitivity, and specificity of this method were 91.1\%, 88.9\%, and 92.4\%, respectively. The per-recording detection accuracy reached 100\%. ADASYN alleviates the imbalance of sensitivity and specificity in classification results . The 1DCNN-RLM with powerful representation learning ability has extracted discriminative features . The BiGRU-TDM introduces the long-term time dependence of SA and improves classification performance. The results of this study substantiate that the proposed method is robust and has good transferability. This method provides a reference for the diagnosis of other diseases.},
  archive      = {J_NEUCOM},
  author       = {Hengji Qin and Guanzheng Liu},
  doi          = {10.1016/j.neucom.2021.12.001},
  journal      = {Neurocomputing},
  pages        = {24-36},
  shortjournal = {Neurocomputing},
  title        = {A dual-model deep learning method for sleep apnea detection based on representation learning and temporal dependence},
  volume       = {473},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Adaptive neural network control for a hydraulic knee
exoskeleton with valve deadband and output constraint based on nonlinear
disturbance observer. <em>NEUCOM</em>, <em>473</em>, 14–23. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel disturbance observer-based adaptive neural network control for a hydraulic knee exoskeleton with valve deadband and output constraint. Adaptive neural networks are employed to approximate the unknown nonlinearities of the hydraulic actuator, i.e., the valve deadband and the unmodeled dynamics caused by the valve leakage. A disturbance observer is designed and integrated into the controller to compensate for the external disturbance and the equivalent interactive force acted on the piston rod of the hydraulic actuator. Under the framwork of backstepping technique, both the state feedback and output feedback controllers of the exoskeleton are designed. The velocity of the piston rod is estimated via a high gain observer in the output feedback control design. By utilizing the barrier Lyapunov function method and the proposed control, the output constraints are handled and the semi-globally uniformly boundedness of the closed-loop system is also guaranteed. Comparative simulation results demonstrate the tracking performance of the proposed control approach.},
  archive      = {J_NEUCOM},
  author       = {Yong Yang and Yanan Li and Xia Liu and Deqing Huang},
  doi          = {10.1016/j.neucom.2021.12.010},
  journal      = {Neurocomputing},
  pages        = {14-23},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural network control for a hydraulic knee exoskeleton with valve deadband and output constraint based on nonlinear disturbance observer},
  volume       = {473},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). VFL—a deep learning-based framework for classifying walking
gaits into emotions. <em>NEUCOM</em>, <em>473</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neucom.2021.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human emotion is perceived not only in facial expressions but also in every kind of body language, including a human’s walking gait. In this paper, we propose a VFL framework for classifying a human’s walking gait into emotions. This framework introduces deep learning methods , which are merely applied to gait data, as the main methods for performing emotion recognition tasks with walking gaits. First, we obtain gait movement data from original walking videos or records and use the gait data that contain only body keypoint positions as input. Then, we expand the data to other kinetic features, rebuild the main skeleton in images, and extract vision features from the images. Based on the data and fusion features , we perform feature fusion and apply our framework to the fused features to complete the task. On various human movement datasets, we obtain an overall accuracy of 92 percent.},
  archive      = {J_NEUCOM},
  author       = {Xiao Sun and Kai Su and Chunxiao Fan},
  doi          = {10.1016/j.neucom.2021.12.007},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {VFL—A deep learning-based framework for classifying walking gaits into emotions},
  volume       = {473},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Will you go where you search? A deep learning framework for
estimating user search-and-go behavior. <em>NEUCOM</em>, <em>472</em>,
338–348. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every day, people are using search engines for different purposes such as research, shopping, or entertainment. Among the behaviors of search engine users, we are particularly interested in search-and-go behavior, which intuitively corresponds to a simple but challenging question, i.e., will users go where they search? Accurately estimating such behavior can be of great importance for Internet companies to recommend point-of-interest (POI), advertisement, and route, as well as for governments and public service operators like metro companies to conduct traffic monitoring, crowd management, and transportation scheduling. Therefore, in this study, we first collect search log data and GPS log data with linked and consistent user ID from Yahoo! Japan portal application installed in millions of smart-phones and tablets. Then we propose a framework including a complete data-processing procedure and an end-to-end deep learning model to predict whether a user will check-in the searched place or not. Specifically, as users’ daily activities are considered to have high correlation with their travel, eating, and recreation decision in the future (i.e., go or not), Deep Spatial–Temporal Interaction Network (DeepSTIN) is elaborately designed to automatically learn the sophisticated spatiotemporal interactions between mobility data and search query data. Experimental results based on the standard metrics demonstrate that our proposed framework can achieve satisfactory performances on multiple real-world search scenarios.},
  archive      = {J_NEUCOM},
  author       = {Renhe Jiang and Quanjun Chen and Zekun Cai and Zipei Fan and Xuan Song and Kota Tsubouchi and Ryosuke Shibasaki},
  doi          = {10.1016/j.neucom.2020.10.001},
  journal      = {Neurocomputing},
  pages        = {338-348},
  shortjournal = {Neurocomputing},
  title        = {Will you go where you search? a deep learning framework for estimating user search-and-go behavior},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SA-CGAN: An oversampling method based on single attribute
guided conditional GAN for multi-class imbalanced learning.
<em>NEUCOM</em>, <em>472</em>, 326–337. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data can always be observed in our daily life and various practical tasks. A lot of well-constructed machine learning methodologies may produce ineffective performance, when conducted on this kind of data. This originates from the produced high training biases that towards the majority class instances. Among all the solutions of this problem, data generation of the minority class is always considered the most effective approach. However, in all the previous works, data are always processed sample-wisely and the distribution of each single data attribute is never noticed. So, in this paper, to estimate the mechanism of how each attribute contributes to its label, we explore the potential connection between the two items by Conditional Generative Adversarial Networks (CGAN) separately and individually. Then, the constructed new instances are purified by a designed attribute-based minimax filter and the survivors are concatenated to form the eventual generated data. In other words, different from the CGAN based data generation way, the proposed approach improves it by additionally considering all the single attribute patterns of the data that to construct new instances. In addition, we extend the binary class imbalanced learning framework to multiple class one. In the experimental part, the improved model is compared against GAN, CGAN and some other standard multiple-class oversampling algorithms on several widely used datasets. Results, in terms of four common measurements, have shown that the proposed approach can produce comparable and always superior performance when compared with the competitors.},
  archive      = {J_NEUCOM},
  author       = {Yongfeng Dong and Huaxin Xiao and Yao Dong},
  doi          = {10.1016/j.neucom.2021.04.135},
  journal      = {Neurocomputing},
  pages        = {326-337},
  shortjournal = {Neurocomputing},
  title        = {SA-CGAN: An oversampling method based on single attribute guided conditional GAN for multi-class imbalanced learning},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on deep learning based point-of-interest (POI)
recommendations. <em>NEUCOM</em>, <em>472</em>, 306–325. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location-based Social Networks (LBSNs) enable users to socialize with friends and acquaintances by sharing their check-ins, opinions, photos, and reviews. A huge volume of data generated from LBSNs opens up a new avenue of research that gives birth to a new sub-field of recommendation systems, known as Point-of-Interest (POI) recommendation. A POI recommendation technique essentially exploits users’ historical check-ins and other multi-modal information such as POI attributes and friendship network, to recommend the next set of POIs suitable for a user. A plethora of earlier works focus on traditional machine learning techniques that use hand-crafted features from the dataset. With the recent surge of deep learning research, we have witnessed a large variety of POI recommendation works utilizing different deep learning paradigms. These techniques largely vary in problem formulations, proposed techniques, used datasets and features, etc. To the best of our knowledge, this work is the first comprehensive survey of all major deep learning-based POI recommendation works. Our work categorizes and critically analyzes the recent POI recommendation works based on different deep learning paradigms and other relevant features. This review can be considered a cookbook for researchers or practitioners working in the area of POI recommendation.},
  archive      = {J_NEUCOM},
  author       = {Md. Ashraful Islam and Mir Mahathir Mohammad and Sarkar Snigdha Sarathi Das and Mohammed Eunus Ali},
  doi          = {10.1016/j.neucom.2021.05.114},
  journal      = {Neurocomputing},
  pages        = {306-325},
  shortjournal = {Neurocomputing},
  title        = {A survey on deep learning based point-of-interest (POI) recommendations},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Graph convolutional network meta-learning with
multi-granularity POS guidance for video captioning. <em>NEUCOM</em>,
<em>472</em>, 294–305. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video as information carrier has gained overwhelming popularity in city surveillance and social networks, such as WeChat, Weibo, and TikTok. To bridge the semantic gap between video content ( e.g. , user and landmark building) and textual information ( e.g. , user location), video captioning has emerged as an attracting technique in recent years. Existing works mostly focus on sentence-level Part-of-Speech (POS) information and use Long Short-Term Memory (LSTM) as encoder, which neglects word or phrase-level POS information and also fails to globally consider long-range temporal relations among video frames. To address the drawbacks, we leverage multi-granularity POS guidance to learn Graph Convolutional Network (GCN) via meta-learning, abbreviated as GMMP ( G CN M eta-learning with M ulti-granularity P OS), for generating high-quality captions for videos. It models temporal dependency by treating frames as nodes in the graph, and captures POS information of words and phrases by multi-granularity POS attention mechanism . We adopt meta-learning to better learn GCN by maximizing the reward of generated caption in a reinforcement task and also the probability of ground-truth caption in a supervised task, simultaneously. Experiments have verified the advantages of our GMMP model on several benchmark data sets.},
  archive      = {J_NEUCOM},
  author       = {Ping Li and Pan Zhang and Xianghua Xu},
  doi          = {10.1016/j.neucom.2020.12.137},
  journal      = {Neurocomputing},
  pages        = {294-305},
  shortjournal = {Neurocomputing},
  title        = {Graph convolutional network meta-learning with multi-granularity POS guidance for video captioning},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting flight delay with spatio-temporal trajectory
convolutional network and airport situational awareness map.
<em>NEUCOM</em>, <em>472</em>, 280–293. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To model and forecast flight delays accurately, it is crucial to harness various vehicle trajectory and contextual sensor data on airport tarmac areas. These heterogeneous sensor data, if modelled correctly, can be used to generate a situational awareness map. Existing techniques apply traditional supervised learning methods onto historical data, contextual features and route information among different airports to predict flight delay are inaccurate and only predict arrival delay but not departure delay, which is essential to airlines. In this paper, we propose a vision-based solution to achieve a high forecasting accuracy , applicable to the airport. Our solution leverages a snapshot of the airport situational awareness map, which contains various trajectories of aircraft and contextual features such as weather and airline schedules. We propose an end-to-end deep learning architecture, TrajCNN, which captures both the spatial and temporal information from the situational awareness map. Additionally, we reveal that the situational awareness map of the airport has a vital impact on estimating flight departure delay. Our proposed framework obtained a good result (around 18 min error) for predicting flight departure delay at Los Angeles International Airport.},
  archive      = {J_NEUCOM},
  author       = {Wei Shao and Arian Prabowo and Sichen Zhao and Piotr Koniusz and Flora D. Salim},
  doi          = {10.1016/j.neucom.2021.04.136},
  journal      = {Neurocomputing},
  pages        = {280-293},
  shortjournal = {Neurocomputing},
  title        = {Predicting flight delay with spatio-temporal trajectory convolutional network and airport situational awareness map},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weighted dynamic time warping for traffic flow clustering.
<em>NEUCOM</em>, <em>472</em>, 266–279. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel similarity measure to identify interesting traffic patterns on a large traffic flow time series data for the central suburbs of Melbourne city in Australia. This new measure is a weighted Dynamic Time Warping (DTW) method based on Gaussian probability function, named GWDTW, that reflects the relative importance of peak hours. We have shown its superior performance over two benchmark similarity measures, the Euclidean distance and conventional DTW measure, on the intersection clustering task using k -medoids clustering algorithm, with respect to both internal and external evaluation measures. With intensive evaluation, the results show that GWDTW is a very effective similarity measure for modelling traffic behaviours, which can provide policy makers with more valuable information for infrastructure design, and smart city development.},
  archive      = {J_NEUCOM},
  author       = {Man Li and Ye Zhu and Taige Zhao and Maia Angelova},
  doi          = {10.1016/j.neucom.2020.12.138},
  journal      = {Neurocomputing},
  pages        = {266-279},
  shortjournal = {Neurocomputing},
  title        = {Weighted dynamic time warping for traffic flow clustering},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A real-time dynamic concept adaptive learning algorithm for
exploitability prediction. <em>NEUCOM</em>, <em>472</em>, 252–265. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploitability prediction has become increasingly important in cybersecurity, as the number of disclosed software vulnerabilities and exploits are soaring. Recently, machine learning and deep learning algorithms , including Support Vector Machine (SVM), Decision Tree , deep Neural Networks and their ensemble models, have achieved great success in vulnerability evaluation and exploitability prediction. However, they make a strong assumption that the data distribution is static over time and therefore fail to consider the concept drift problems due to the evolving system behaviours . In this work, we propose a novel consecutive batch learning algorithm, called Real-time Dynamic Concept Adaptive Learning (RDCAL), to deal with the concept drift and dynamic class imbalance problems existing in exploitability prediction. Specifically, we develop a Class Rectification Strategy (CRS) to handle the ‘actual drift’ in sample labels and a Balanced Window Strategy (BWS) to boost the minority class during real-time learning. Experimental results conducted on the real-world vulnerabilities collected between 1988 to 2020 show that the overall performance of classifiers, including Neural Networks, SVM, HoeffdingTree and Logistic Regression (LR), improves over 3\% by adopting our proposed RDCAL algorithm. Furthermore, RDCAL achieves state-of-the-art performance on exploitability prediction compared with other concept drift algorithms.},
  archive      = {J_NEUCOM},
  author       = {Jiao Yin and MingJian Tang and Jinli Cao and Hua Wang and Mingshan You},
  doi          = {10.1016/j.neucom.2021.01.144},
  journal      = {Neurocomputing},
  pages        = {252-265},
  shortjournal = {Neurocomputing},
  title        = {A real-time dynamic concept adaptive learning algorithm for exploitability prediction},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of crowd counting and density estimation based on
convolutional neural network. <em>NEUCOM</em>, <em>472</em>, 224–251.
(<a href="https://doi.org/10.1016/j.neucom.2021.02.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting and crowd density estimation methods are of great significance in the field of public security. Estimating crowd density and counting from single image or video frame has become an essential part of a computer vision system in various scenarios. In this paper, we comprehensively review the recent research advancement on crowd counting and density estimation. First of all, we introduce the background of crowd counting and crowd density estimation. Second, the traditional crowd counting methods are summarized. Third, we focus on reviewing the crowd counting and crowd density methods based on convolutional neural network (CNN) models. Next, we report and discuss the experimental results of a number of typical methods on benchmark datasets. Finally, we present the promising future directions of crowd counting and crowd density.},
  archive      = {J_NEUCOM},
  author       = {Zizhu Fan and Hong Zhang and Zheng Zhang and Guangming Lu and Yudong Zhang and Yaowei Wang},
  doi          = {10.1016/j.neucom.2021.02.103},
  journal      = {Neurocomputing},
  pages        = {224-251},
  shortjournal = {Neurocomputing},
  title        = {A survey of crowd counting and density estimation based on convolutional neural network},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic network embedding survey. <em>NEUCOM</em>,
<em>472</em>, 212–223. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since many real world networks are evolving over time, such as social networks and user-item networks, there are increasing research efforts on dynamic network embedding in recent years. They learn node representations from a sequence of evolving graphs but not only the latest network, for preserving both structural and temporal information from the dynamic networks. Due to the lack of comprehensive investigation of them, we give a survey of dynamic network embedding in this paper. Our survey inspects the data model, representation learning technique, evaluation and application of current related works and derives common patterns from them. Specifically, we present two basic data models, namely, discrete model and continuous model for dynamic networks. Correspondingly, we summarize two major categories of dynamic network embedding techniques, namely, structural-first and temporal-first that are adopted by most related works. Then we build a taxonomy that refines the category hierarchy by typical learning models. The popular experimental data sets and applications are also summarized. Lastly, we have a discussion of several distinct research topics in dynamic network embedding.},
  archive      = {J_NEUCOM},
  author       = {Guotong Xue and Ming Zhong and Jianxin Li and Jia Chen and Chengshuai Zhai and Ruochen Kong},
  doi          = {10.1016/j.neucom.2021.03.138},
  journal      = {Neurocomputing},
  pages        = {212-223},
  shortjournal = {Neurocomputing},
  title        = {Dynamic network embedding survey},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). OPTDP: Towards optimal personalized trajectory differential
privacy for trajectory data publishing. <em>NEUCOM</em>, <em>472</em>,
201–211. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of location-based applications, more and more trajectory data are collected. Trajectory data often contains users’ sensitive information , and direct release it may pose a threat to users’ privacy. Differential privacy , as a privacy preserving method with solid mathematical foundation, has been widely used in trajectory data publishing. However, current trajectory data publishing methods based on differential privacy cannot fully realize the personalized privacy protection. In this paper, an optimal personalized trajectory differential privacy mechanism is proposed. Firstly, by establishing the probabilistic mobility model of trajectories, we cluster the locations to achieve semantic location matching between different trajectories. Based on the semantic similarity, we identify the templet trajectory, and propose a privacy level allocation method based on stay-points and frequent sub-trajectories. Then, according to the location matching results, we can automatically identify the privacy level of all locations. Combined with the optimal location differential privacy mechanism, we disturb the location points on the user’s trajectory before publishing, where different location privacy levels correspond to different privacy budgets. Experiment results on real-world datasets show that our mechanism provides a better tradeoff between privacy protection and data utility compared with traditional differential privacy methods.},
  archive      = {J_NEUCOM},
  author       = {Wenqing Cheng and Ruxue Wen and Haojun Huang and Wang Miao and Chen Wang},
  doi          = {10.1016/j.neucom.2021.04.137},
  journal      = {Neurocomputing},
  pages        = {201-211},
  shortjournal = {Neurocomputing},
  title        = {OPTDP: Towards optimal personalized trajectory differential privacy for trajectory data publishing},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time dynamic network learning for location inference
modelling and computing. <em>NEUCOM</em>, <em>472</em>, 198–200. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User location information contributes to in-depth social network data analytics. This special issue focuses on emerging techniques and trendy applications of real-time dynamic network learning in the fields such as neural network, dynamic network, spatial feature pattern recognition, and active learning. The research included at this special issue will also advance the location based services in real applications.},
  archive      = {J_NEUCOM},
  author       = {Jianxin Li and Aixin Sun and Ziyu Guan and Muhammad Aamir Cheema and Geyong Min},
  doi          = {10.1016/j.neucom.2021.10.086},
  journal      = {Neurocomputing},
  pages        = {198-200},
  shortjournal = {Neurocomputing},
  title        = {Real-time dynamic network learning for location inference modelling and computing},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Egocentric vision-based action recognition: A survey.
<em>NEUCOM</em>, <em>472</em>, 175–197. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The egocentric action recognition EAR field has recently increased its popularity due to the affordable and lightweight wearable cameras available nowadays such as GoPro and similars. Therefore, the amount of egocentric data generated has increased, triggering the interest in the understanding of egocentric videos. More specifically, the recognition of actions in egocentric videos has gained popularity due to the challenge that it poses: the wild movement of the camera and the lack of context make it hard to recognise actions with a performance similar to that of third-person vision solutions. This has ignited the research interest on the field and, nowadays, many public datasets and competitions can be found in both the machine learning and the computer vision communities. In this survey, we aim to analyse the literature on egocentric vision methods and algorithms. For that, we propose a taxonomy to divide the literature into various categories with subcategories, contributing a more fine-grained classification of the available methods. We also provide a review of the zero-shot approaches used by the EAR community, a methodology that could help to transfer EAR algorithms to real-world applications. Finally, we summarise the datasets used by researchers in the literature.},
  archive      = {J_NEUCOM},
  author       = {Adrián Núñez-Marcos and Gorka Azkune and Ignacio Arganda-Carreras},
  doi          = {10.1016/j.neucom.2021.11.081},
  journal      = {Neurocomputing},
  pages        = {175-197},
  shortjournal = {Neurocomputing},
  title        = {Egocentric vision-based action recognition: A survey},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Taylor saves for later: Disentanglement for video prediction
using taylor representation. <em>NEUCOM</em>, <em>472</em>, 166–174. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video prediction is a challenging task with wide application prospects in meteorology and robot systems. Existing works fail to trade off short-term and long-term prediction performances and extract robust latent dynamics laws in video frames. We propose a two-branch seq-to-seq deep model to disentangle the Taylor feature and the residual feature in video frames by a novel recurrent prediction module (TaylorCell) and residual module, based on a novel principle for feature separation. TaylorCell can expand the video frames’ high-dimensional features into the finite Taylor series to describe the latent laws. In TaylorCell, we propose the Taylor prediction unit (TPU) and the memory correction unit (MCU). TPU employs the first input frame’s derivative information to predict the future frames, avoiding error accumulation. MCU distills all past frames’ information to correct the predicted Taylor feature from TPU. Correspondingly, the residual module extracts the residual feature complementary to the Taylor feature. Due to the characteristic of the Taylor series, our model works better on datasets with short-range spatial dependencies and stable dynamics. On three generalist datasets (Moving MNIST, TaxiBJ, Human 3.6), our model reaches and outperforms the state-of-the-art model in the short-term and long-term forecast, respectively. Ablation experiments demonstrate the contributions of each module in our model.},
  archive      = {J_NEUCOM},
  author       = {Ting Pan and Zhuqing Jiang and Jianan Han and Shiping Wen and Aidong Men and Haiying Wang},
  doi          = {10.1016/j.neucom.2021.11.021},
  journal      = {Neurocomputing},
  pages        = {166-174},
  shortjournal = {Neurocomputing},
  title        = {Taylor saves for later: Disentanglement for video prediction using taylor representation},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computer-aided diagnosis of breast cancer in ultrasonography
images by deep learning. <em>NEUCOM</em>, <em>472</em>, 152–165. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasonography of the breast mass is an important imaging technology for diagnosing breast cancer. In China, ultrasound equipment is widely used in medical institutions. Patients obtain a report with highlighted ultrasonography images through an initial clinical screening. However, analyzing these images manually is highly subjective for the variation in the clinical competence of doctors, resulting in poor consistency and low sensitivity. In this study, an automated breast cancer diagnosis system is developed to increase diagnostic accuracy . The system is deployed on mobile phones, takes a photo of the ultrasound report as input and performs diagnosis on each image. The developed system consists of three subsystems. The first subsystem is to reduce noise in the taken photos, reconstructing high-quality images. We develop the first subsystem based on the frameworks of stacked denoising autoencoders and generative adversarial networks . The second subsystem is to classify images into malignant and non-malignant; to extract high-level features from the images, deep convolutional neural networks are employed. The third subsystem is to detect anomalies in model performances, reducing false negative rates. Generative adversarial networks are utilized to distinguish false negative samples from true negative samples. 18,225 breast ultrasonography images and 2416 ultrasound reports are collected to train and evaluate the system. Experimental results show that the performance of our system is comparable to that of human experts. It is believed that this is the first system for breast cancer diagnosis deployed on mobile phones. The developed system is integrated with a cloud computing platform and accessible online to aid in the initial screening and diagnosis of breast cancer, thereby promoting earlier treatment, reducing the morbidity and mortality.},
  archive      = {J_NEUCOM},
  author       = {Xiaofeng Qi and Fasheng Yi and Lei Zhang and Yao Chen and Yong Pi and Yuanyuan Chen and Jixiang Guo and Jianyong Wang and Quan Guo and Jilan Li and Yi Chen and Qing Lv and Zhang Yi},
  doi          = {10.1016/j.neucom.2021.11.047},
  journal      = {Neurocomputing},
  pages        = {152-165},
  shortjournal = {Neurocomputing},
  title        = {Computer-aided diagnosis of breast cancer in ultrasonography images by deep learning},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Introduction to the special issue on edge intelligence:
Neurocomputing meets edge computing. <em>NEUCOM</em>, <em>472</em>,
149–151. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the proliferation of mobile computing and Internet-of-Things (IoT), where billions of mobile and IoT devices are connected to the Internet, generating zillions bytes of data at the network edge. Driving by this trend and the development of wireless communication, edge computing, an emerging computing paradigm, has received tremendous amount of interest. By pushing data storage, computing, and control closer to the network edge, edge computing has been widely recognized as a promising solution to meet the requirements of low latency, high scalability, prompt response, and energy efficiency. In the meanwhile, with the development of neural networks, Artificial Intelligence (AI) has been applied to a variety of disciplines and proved highly successful in a vast class of intelligent applications cross many domains. Edge intelligence, aiming to facilitate the deployment of neural networks on edge computing, has received significant attention. However, there are many challenges existing for a novel design of edge computing architecture to AI applications, and their co-optimization. For instance, conventional neural networks techniques usually entail powerful computing facilities (e.g., cloud computing platforms), while the entities at the edge may have only limited resources for computations and communications. This suggests that AI algorithms should be revisited for edge computing to AI models into the edge device for efficient processing. On the other hand, the adapted deployments of neural networks at the edge empower the efficient learning systems that can provide the “smartification” across different layers, e.g., from network communications to applications, and also involve collaborations across edge to cloud. Finally, designing algorithms for small-scale edge devices in a learning ambience is all the challenging as there are several conflicting issues to account for. These include, memory management, power management, and compute capability of a node, etc.},
  archive      = {J_NEUCOM},
  author       = {Zeng Zeng ( Guest Editor ) and Cen Chen (Guest Editor) and Bharadwaj Veeravalli (Guest Editor) and Keqin Li (Guest Editor) and Joey Tianyi Zhou (Guest Editor)},
  doi          = {10.1016/j.neucom.2021.11.069},
  journal      = {Neurocomputing},
  pages        = {149-151},
  shortjournal = {Neurocomputing},
  title        = {Introduction to the special issue on edge intelligence: Neurocomputing meets edge computing},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Point cloud recognition based on lightweight embeddable
attention module. <em>NEUCOM</em>, <em>472</em>, 138–148. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are challenges in point cloud recognition tasks such as modeling the relationship between points, rotation invariance, disorder, and so on. Many of the previous methods focus on the local structure modeling of point cloud and ignore the global features. Meanwhile, a large number of points need to be input at one time to obtain sufficient information that causes the computational burden. In this paper, we propose a Dual Branch Attention Network (DBAN) considering both global and local information, where a learnable way is used to guide feature aggregation. The main component of DBAN is that we design an effective channel attention module called Lightweight Embeddable Attention Module (LEAM), which not only can be embedded in the existing backbone of the point cloud recognition networks easily but also overcome the contradiction between performance and complexity of general point cloud models. Extensive experiments on challenging benchmark datasets verify that our method performs better with fewer input points in point cloud recognition tasks such as object classification and segmentation.},
  archive      = {J_NEUCOM},
  author       = {Guanyu Zhu and Yong Zhou and Jiaqi Zhao and Rui Yao and Man Zhang},
  doi          = {10.1016/j.neucom.2021.10.098},
  journal      = {Neurocomputing},
  pages        = {138-148},
  shortjournal = {Neurocomputing},
  title        = {Point cloud recognition based on lightweight embeddable attention module},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Instance-level context attention network for instance
segmentation. <em>NEUCOM</em>, <em>472</em>, 124–137. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance segmentation has made great progress in recent years. However, current mainstream detection-based methods ignore the process of distinguishing different instances in the same detected region, making it hard to segment the correct instance when a detected region contains multiple instances. To address this problem, we propose an Instance-level Context Attention Network (ICANet) to generate more discriminative features for different instances based on the context from their respective instance scopes, called instance-level context. Specifically, given a detected region, we first propose an instance attention module to obtain the specific attention maps that focus on the relationships between pixel pairs from the same instance by learning an embedding space. With this type of attention map, the features from the same instance achieve mutual gains, while the features from different instances become more discriminative. Then, we propose a spatial attention module to incorporate spatial information and enhance feature representations based on both feature and spatial relations . Moreover, to obtain clearer attention maps, we further propose a weight clipping strategy to filter out the noise by cutting off the lower weight. We perform extensive experiments to verify the effectiveness of the proposed method. As reported in the results, our method steadily outperforms the baseline by over 1.5\% on the COCO dataset using different backbones and 3.7\% on the Cityscapes dataset, which demonstrates the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Chao Shang and Hongliang Li and Fanman Meng and Heqian Qiu and Qingbo Wu and Linfeng Xu and King Ngi Ngan},
  doi          = {10.1016/j.neucom.2021.11.104},
  journal      = {Neurocomputing},
  pages        = {124-137},
  shortjournal = {Neurocomputing},
  title        = {Instance-level context attention network for instance segmentation},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph neural networks with global noise filtering for
session-based recommendation. <em>NEUCOM</em>, <em>472</em>, 113–123.
(<a href="https://doi.org/10.1016/j.neucom.2021.11.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation leverages anonymous sessions to predict which item a user is most likely to click on next. While previous approaches capture items-transition patterns within current session and neighbor sessions, they do not accurately filter out noise within session or widen the range of feasible data in a more reasonable way. In a current session, the user may accidentally click on an unrelated item, resulting in the fact that, the users’ primary intents from neighbor sessions, may mismatch the current session. Thereby, we propose a new framework, dubbed G raph N eural N etworks with G lobal N oise F iltering for Session-based Recommendation (GNN-GNF), aiming to filter noisy data and exploit items-transition patterns in a more comprehensive and reasonable manner. In simple terms, GNN-GNF contains two parts: data preprocessing and model learning . In data preprocesing, an item-level filter module is used to obtain the main intent of user and a session-level filter module is designed to filter the sessions unrelated to the target session intent by means of edge matching. In model learning, we consider both local-level interest obtained by an aggregation of the items representing the main intent of user within a session, and global-level interest deduced from a global graph. We take two kinds of neighbor aggregations, summation and interactive aggregation, respectively, to iteratively derive the representation of the central node in the global graph. Finally, GNN-GNF concatenates the local and global preference to characterize the current session, towards better recommendation prediction. Experiments on two datasets demonstrate that GNN-GNF can achieve competitive results. The source code is available at: https://github.com/Fenglixia/GNF .},
  archive      = {J_NEUCOM},
  author       = {Lixia Feng and Yongqi Cai and Erling Wei and Jianwu Li},
  doi          = {10.1016/j.neucom.2021.11.068},
  journal      = {Neurocomputing},
  pages        = {113-123},
  shortjournal = {Neurocomputing},
  title        = {Graph neural networks with global noise filtering for session-based recommendation},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PPPNE: Personalized proximity preserved network embedding.
<em>NEUCOM</em>, <em>472</em>, 103–112. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After being proved extremely useful in many applications, the network embedding has played a critical role in the network analysis. Most of recent works usually model the network by minimizing the joint probability that the target node co-occurs with its neighboring nodes. These methods may fail to capture the personalized informativeness of each vertex. In this work, we propose a method named Personalized Proximity Preserved Network Embedding (PPPNE) to adaptively capture the personalization of vertices based on the personalized ranking loss. Our theoretical analysis shows that PPPNE generalizes prior work based on the matrix factorization or the neural network with a single layer, and we argue that preserving personalized proximity is the key to learning more informative representations. Moreover, to better capture the network structure in multiple scales, we exploit the distance ordering of each vertex. Our method can be efficiently optimized with a vertex-anchored sampling strategy. The results of extensive experiments on five real-world networks demonstrate that our approach outperforms state-of-the-art network embedding methods with a considerable improvement on several common tasks including link prediction and vertex classification. Additionally, PPPNE is efficient and can be easily accelerated by parallel computing , which enables PPPNE to work on large-scale networks.},
  archive      = {J_NEUCOM},
  author       = {Ge Fan and Biao Geng and Jianrong Tao and Kai Wang and Changjie Fan and Wei Zeng},
  doi          = {10.1016/j.neucom.2021.11.059},
  journal      = {Neurocomputing},
  pages        = {103-112},
  shortjournal = {Neurocomputing},
  title        = {PPPNE: Personalized proximity preserved network embedding},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint usage of global and local attentions in hourglass
network for human pose estimation. <em>NEUCOM</em>, <em>472</em>,
95–102. (<a href="https://doi.org/10.1016/j.neucom.2021.10.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human pose estimation is a challenging research task in the field of computer vision. The current mainstream work has made great progress in pose estimation, but these works still do not pay enough attention to the negative impact of background on human pose estimation. In this work, we propose a human pose estimation framework characterized by the joint usage of both global and local attention module in an hourglass backbone network . The global attention module aims to reduces the negative impact of background. The local attention module is designed to help refine each joint. We tested our method on two benchmark datasets for human pose estimation, and the experimental results show that the proposed model is superior to current mainstream algorithms.},
  archive      = {J_NEUCOM},
  author       = {Xiena Dong and Jun Yu and Jian Zhang},
  doi          = {10.1016/j.neucom.2021.10.073},
  journal      = {Neurocomputing},
  pages        = {95-102},
  shortjournal = {Neurocomputing},
  title        = {Joint usage of global and local attentions in hourglass network for human pose estimation},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hyperspectral image super-resolution via multi-domain
feature learning. <em>NEUCOM</em>, <em>472</em>, 85–94. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image super-resolution (SR) methods have achieved great success due to deep neural networks . Despite this, these methods hardly utilize more 2D convolutions to explore more spatial features when the spectral information can be extracted. Besides, they do not make full use of multi-domain features to realize information complementation. To address these issues, we propose a multi-domain feature learning network using 2D/3D convolution for hyperspectral image SR. A multi-domain feature learning strategy is proposed to explore the spatial and spectral knowledge by sharing spatial information. To better fuse those feature from different domains, the multi-domain features fusion module is introduced to learn more effective information, so as to further realize information complementation. Moreover, to recover the more edge details, we design the edge generation mechanism to explicitly enable the network provide priori edge. Extensive experiments on two benchmark datasets show that the proposed approach produces the state-of-the-art results over the existing works in terms of spatial reconstruction and spectral fidelity.},
  archive      = {J_NEUCOM},
  author       = {Qiang Li and Yuan Yuan and Qi Wang},
  doi          = {10.1016/j.neucom.2021.10.041},
  journal      = {Neurocomputing},
  pages        = {85-94},
  shortjournal = {Neurocomputing},
  title        = {Hyperspectral image super-resolution via multi-domain feature learning},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predefined-time convergent neural networks for solving the
time-varying nonsingular multi-linear tensor equations. <em>NEUCOM</em>,
<em>472</em>, 68–84. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equation solving is one of the main subjects in various research fields. In this study, we consider tensor equations with time-varying nonsingular coefficient tensors and right-hand side vectors, which generalize the time-invariant tensor equations and also the time-varying or time-invariant linear equations studied by many researchers. Four complex-valued neural networks termed as ZNN-I, ZNN-II, WsbpPTZNN-I and WsbpPTZNN-II are proposed for solving this problem. We show that, under certain conditions, the four models converge to a solution of the original tensor equations. Moreover, we prove that WsbpPTZNN-I and WsbpPTZNN-II models have predefined-time convergence property , which means that they converge to a true solution in a prescribed time. The upper bounds of the convergence time are also given. For comparison, the gradient-based model, termed as GNN, is also introduced. Through many numerical tests, we demonstrate the validity of our theoretical analysis of these models. The simulation results also illustrate the effectiveness and reliability of our proposed neural network models and show that their convergence performance can be improved by using the predefined-time convergent WsbpPTZNN models.},
  archive      = {J_NEUCOM},
  author       = {Xuezhong Wang and Changxin Mo and Sanzheng Qiao and Yimin Wei},
  doi          = {10.1016/j.neucom.2021.11.108},
  journal      = {Neurocomputing},
  pages        = {68-84},
  shortjournal = {Neurocomputing},
  title        = {Predefined-time convergent neural networks for solving the time-varying nonsingular multi-linear tensor equations},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time crowd counting via lightweight scale-aware
network. <em>NEUCOM</em>, <em>472</em>, 54–67. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate crowd counting in congested scenes is still challenging, and its inference speed is also essential in intelligent edge devices. To tackle this issue, we propose a novel lightweight scale-aware network (LSANet) for high-accuracy real-time crowd counting, which consists of four structures: local extractor (LE), scale feature extraction module (SFEM), scale feature fusion module (SFFM), and density map regressor (DMR). Specifically, we devise the SFEM and SFFM carefully to reinforce the learning capability of scale representation, which significantly improves the counting accuracy. Besides, the multi-level intersection-over-union (MIoU) loss function is proposed to reduce background false recognition and estimation errors. Extensive experiments on four mainstream datasets demonstrate that our method achieves the optimal trade-off between effectiveness and efficiency compared with previous lightweight methods.},
  archive      = {J_NEUCOM},
  author       = {Fushun Zhu and Hua Yan and Xinyue Chen and Tong Li},
  doi          = {10.1016/j.neucom.2021.11.099},
  journal      = {Neurocomputing},
  pages        = {54-67},
  shortjournal = {Neurocomputing},
  title        = {Real-time crowd counting via lightweight scale-aware network},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Two-stream network with phase map for few-shot
classification. <em>NEUCOM</em>, <em>472</em>, 45–53. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important research direction of deep learning , few-shot classification mainly solves problems of classification when training samples are scarce. Under this circumstance, how to effectively use the information of existing samples has become the key to solve few-shot classification problems. We propose a method to fully mine existing samples information, which can be implemented in the training and testing stages. Specifically, we introduce a two-stream neural network as an embedding model to extract features of the original image and its phase map, and perform fine-grained adaptive feature fusion to them. The algorithm can learn and extract more fully-informed fusion features under the network. Besides, we also introduce Circle Loss in loss function, which has a non-linear decision boundary. Under the joint supervision of Soft-max Loss and Circle Loss, the distinction between different classes of features in embedding space increases. We conduct experiments on miniImageNet, tieredImageNet, and CIFAR-FS, respectively. The accuracy rate is increased by 0.99\%, 0.96\%, and 0.91\%, which proves the effectiveness of our algorithm.},
  archive      = {J_NEUCOM},
  author       = {Jiahao Wang and Bin Song and Dan Wang and Hao Qin},
  doi          = {10.1016/j.neucom.2021.11.074},
  journal      = {Neurocomputing},
  pages        = {45-53},
  shortjournal = {Neurocomputing},
  title        = {Two-stream network with phase map for few-shot classification},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Heuristic sequencing hopfield neural network for
pick-and-place location routing in multi-functional placers.
<em>NEUCOM</em>, <em>472</em>, 35–44. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hopfield neural network (HNN) is a well-studied optimization method, but has not been able to solve the capacitated location routing problems (CLRP). Transporting components from the feeders to the placement points by a capacitated head set, the pick-and-place location routing in multi-functional placers is studied as a typical CLRP. The original problem is decomposed into three subproblems deciding the placement points grouping, feeders location and inner-group placement sequencing, respectively. The first two subproblems are optimization problems with multiple tours. With heuristics designed for optimization within a single tour, these two subproblems are transformed into the heuristic sequencing optimization problems that optimize the solving sequence of the tours. The typical HNN for the travelling salesman problem is improved, which results in the heuristic sequencing HNN. The energy function is adapted for reflecting the activation states of the energy matrix about the index-sequence pairs. Through exploration into the objective function value of each index-sequence pair, the energy matrix is calculated by a specially designed method combining with a normalization technique. To achieve optimal performance of the HNN-based methods, a multi-start mechanism is employed. The effectiveness and efficiency of the proposed method are finally elucidated by experiments using practical industrial data.},
  archive      = {J_NEUCOM},
  author       = {Zhengkai Li and Hao Sun and Xinghu Yu and Weichao Sun},
  doi          = {10.1016/j.neucom.2021.11.040},
  journal      = {Neurocomputing},
  pages        = {35-44},
  shortjournal = {Neurocomputing},
  title        = {Heuristic sequencing hopfield neural network for pick-and-place location routing in multi-functional placers},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DeepCS: Training a deep learning model for cervical
spondylosis recognition on small-labeled sensor data. <em>NEUCOM</em>,
<em>472</em>, 24–34. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cervical spondylosis (CS) recognition systems provide regular screening services outside of a hospital and promote early detection and treatment of CS. However, in this paper, we propose a deep learning-based CS recognition system. Concerning the state-of-the-art and state-of-the-practice systems, the innovations of our approaches and algorithms are as follows: First, to elevate the reliance upon the sample number required for training the high-quality model, we reduce sample dimension and find optimal neural network architectures to reduce the number of model parameters to fit. Second, we incorporate multi-stream parallel network architecture search with multi-view feature extraction by converting time series classification into an image classification task . Specifically, five feature extraction methods (time-domain, frequency-domain, time–frequency domain, model-based, nonlinear feature extraction) are firstly utilized to extract features from multiple perspectives and form low-dimensional data set with multi-properties. Third, we reorganize low-dimensional data into image one representing the spatio-temporal relationship of muscle activity pattern. Finally, a multi-stream parallel network architecture search is proposed to use a bypass mechanism for optimal neural network architecture, each of which processes a kind of features mentioned above with an idea of the sparse connection of convolution neural network. The results on the real-world data set show that our CS recognition system achieves the average accuracy of 95.54\%, average sensitivity of 99.09\%, and average specificity of 90.00\%, outperforming the state-of-the-art ones.},
  archive      = {J_NEUCOM},
  author       = {Nana Wang and Chunjie Luo and Xi Huang and Yunyou Huang and Jianfeng Zhan},
  doi          = {10.1016/j.neucom.2021.11.008},
  journal      = {Neurocomputing},
  pages        = {24-34},
  shortjournal = {Neurocomputing},
  title        = {DeepCS: Training a deep learning model for cervical spondylosis recognition on small-labeled sensor data},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An associative memory circuit based on physical memristors.
<em>NEUCOM</em>, <em>472</em>, 12–23. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a physical Sr 0.97 Ba 0.03 TiO 3 - x Sr0.97Ba0.03TiO3-x (SBT) memristor with the voltage threshold characteristic was prepared. For characterizing the electrical characteristics of SBT memristor accurately, an adaptive voltage threshold memristor model was proposed. The synaptic plasticity of SBT memristor with different pulse stimulation was analyzed. Moreover, a Pavlov associative memory circuit was designed in the LTSPICE environment, which is composed of neuron circuit and memristive synaptic circuit. The neuron circuit can generate spike signals when the input signals exceed the threshold, and the synaptic weight can be tunable continuously by spike signals. Different from other memristive synaptic circuits, the proposed memristive synaptic circuit is based on physical SBT memristor, and the change of synaptic weight can be truly reflected in the circuit. In Pavlov’s dog experiment, when the presynaptic neuron receives the conditioned stimulus (CS) before the unconditioned stimulus (US), the synaptic weight of SBT memristor is increasing and the associative memory is building. When the presynaptic neuron receives the CS alone, or presynaptic neuron receives the CS after the US, the synaptic weight of SBT memristor is decreasing and the associative memory is losing. This phenomenon is highly similar to the building and losing processes of biological associative memory. These experimental results verify the feasibility and applicability of SBT memristor as electronic synapse in neuromorphic applications, and pave the way towards further development of artificial neural networks .},
  archive      = {J_NEUCOM},
  author       = {Mei Guo and Yongliang Zhu and Renyuan Liu and Kaixuan Zhao and Gang Dou},
  doi          = {10.1016/j.neucom.2021.11.034},
  journal      = {Neurocomputing},
  pages        = {12-23},
  shortjournal = {Neurocomputing},
  title        = {An associative memory circuit based on physical memristors},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anti-periodic solutions on clifford-valued high-order
hopfield neural networks with multi-proportional delays.
<em>NEUCOM</em>, <em>472</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Of concern is the dynamics of anti-periodic solutions on Clifford-valued high-order Hopfield neural networks (CVHOHNNs) with multi-proportional delays. By utilizing differential inequality techniques, Lyapunov method and a rigorous mathematical proof, we establish some sufficient criteria on the existence and global stability of anti-periodic solutions. Finally, a numerical example is offered to verify and extend the analytical results and visualize the interesting phenomenon.},
  archive      = {J_NEUCOM},
  author       = {Demou Luo and Quande Jiang and Qiru Wang},
  doi          = {10.1016/j.neucom.2021.11.001},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {Anti-periodic solutions on clifford-valued high-order hopfield neural networks with multi-proportional delays},
  volume       = {472},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bipartite graph based spectral rotation with fuzzy anchors.
<em>NEUCOM</em>, <em>471</em>, 369–376. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering usually obtains impressive performance owing to the usage of the manifold structure of data. However, it is infeasible to widely apply conventional spectral clustering methods due to the high computational complexity . To address this challenging problem, a series of extensions like anchor points based models have been developed. Nevertheless, the existing approaches separate anchor points selection and the construction of the bipartite graph , which hinders the performance of the anchor-based methods. In this paper, by revealing the connection between the existing anchor-based spectral clustering and fuzzy k -means, the performance of related methods is found to be limited by the early termination. Accordingly, we proposed a complete learning approach to generate high-quality bipartite graphs. Furthermore, the produced bipartite graph can be directly utilized to perform spectral clustering, and the improved spectral rotation is employed to further boost the performance. Eventually, extensive experiments illustrate that the proposed method obtains good performance especially when the anchor points are limited.},
  archive      = {J_NEUCOM},
  author       = {Yuan Yuan and Chengze Wang},
  doi          = {10.1016/j.neucom.2021.11.055},
  journal      = {Neurocomputing},
  pages        = {369-376},
  shortjournal = {Neurocomputing},
  title        = {Bipartite graph based spectral rotation with fuzzy anchors},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic video mix-up for cross-domain action recognition.
<em>NEUCOM</em>, <em>471</em>, 358–368. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, action recognition has been extensively studied. For some general action datasets, such as UCF101 [1] , the recognition accuracy in a specific domain can reach 95\%\% . However, due to the existence of the domain-wise discrepancy, the performance of the model will be significantly reduced when deployed to realistic scenes. Therefore, to support the generalization of the action recognition model in practical scenes, the cross-domain problem should be addressed urgently. In this paper, we propose a cross-domain video data fusion mechanism to reduce the difference between domains. Our method is different from existing methods in two points: (1) Instead of performing mix-up at the feature-level, we propose to execute the mix-up directly at the input-level, which introduces more original information beyond the middle features. In addition, a progressive learning method is introduced for adaptive cross-domain fusion. (2) To make full use of the action class knowledge from the source domain, we also propose pseudo-label guided mix-up data learning. Note that only top-ranking confident pseudo labels are selected to ensure the stable similarity between the source and target domains. We evaluate the proposed method on two widely used cross-domain datasets, including the UCF101-HMDB51 full and UCF-Olympic. Extensive experimental results have shown that the proposed method is effective and achieves the state-of-the-art performance. In the HMDB51(source domain) → → UCF101(target domain) direction, the accuracy of our method can reach 98.60\%\% , which is 9.54\%\% improvement over the existing state-of-the-art method.},
  archive      = {J_NEUCOM},
  author       = {Han Wu and Chunfeng Song and Shaolong Yue and Zhenyu Wang and Jun Xiao and Yanyang Liu},
  doi          = {10.1016/j.neucom.2021.11.054},
  journal      = {Neurocomputing},
  pages        = {358-368},
  shortjournal = {Neurocomputing},
  title        = {Dynamic video mix-up for cross-domain action recognition},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FPCR-net: Feature pyramidal correlation and residual
reconstruction for optical flow estimation. <em>NEUCOM</em>,
<em>471</em>, 346–357. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical flow estimation is a challenging problem in the field of video analytics yet. Features of different semantics levels in a convolutional neural network (CNN) provide information of different granularity . To exploit such flexible and comprehensive information, we propose a Feature Pyramidal Correlation and Residual Reconstruction Network (FPCR-Net) for optical flow estimation from frame pairs. It consists of two main modules: pyramid correlation mapping and residual reconstruction. The pyramid correlation mapping module takes advantage of the multi-scale correlations of global/local representation by aggregating features of different scales to form a multi-level cost volume. The residual reconstruction module aims at reconstructing the sub-band high-frequency residuals of finer optical flow at each stage. Based on the pyramid correlation mapping, we further propose a correlation-warping-normalization (CWN) module to efficiently exploit the correlation dependency. Furthermore, considering the characteristics of flow warping and alignment, we integrate unsupervised and supervised losses to explore the implicit relevance and explicit constraint. Experimental results show that the proposed network achieves the promising performance for two-frame-based optical flow estimation on the challenging Sintel and KITTI 2012/2015 datasets.},
  archive      = {J_NEUCOM},
  author       = {Xiaolin Song and Yuyang Zhao and Jingyu Yang and Cuiling Lan and Wenjun Zeng},
  doi          = {10.1016/j.neucom.2021.11.037},
  journal      = {Neurocomputing},
  pages        = {346-357},
  shortjournal = {Neurocomputing},
  title        = {FPCR-net: Feature pyramidal correlation and residual reconstruction for optical flow estimation},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Semi-supervised anatomical landmark detection via
shape-regulated self-training. <em>NEUCOM</em>, <em>471</em>, 335–345.
(<a href="https://doi.org/10.1016/j.neucom.2021.10.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Well-annotated medical images are costly and sometimes even impossible to acquire, hindering landmark detection accuracy to some extent. Semi-supervised learning alleviates the reliance on large-scale annotated data by exploiting the unlabeled data to understand the population structure of anatomical landmarks. The global shape constraint is the inherent property of anatomical landmarks that provides valuable guidance for more consistent pseudo labelling of the unlabeled data , which is ignored in the previously semi-supervised methods. In this paper, we propose a model-agnostic shape-regulated self-training framework for semi-supervised landmark detection by fully considering the global shape constraint. Specifically, to ensure pseudo labels are reliable and consistent, a PCA-based shape model adjusts pseudo labels and eliminate abnormal ones. A novel Region Attention loss to make the network automatically focus on the structure consistent regions around pseudo labels. Extensive experiments show that our approach outperforms other semi-supervised methods and achieves the relative improvement of 3.8\%, 6.1\% and 6.3\% on three medical image datasets. Furthermore, our framework is flexible and can be used as a plug-and-play module integrated into most superviseüd methods to improve performance further.},
  archive      = {J_NEUCOM},
  author       = {Runnan Chen and Yuexin Ma and Lingjie Liu and Nenglun Chen and Zhiming Cui and Guodong Wei and Wenping Wang},
  doi          = {10.1016/j.neucom.2021.10.109},
  journal      = {Neurocomputing},
  pages        = {335-345},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised anatomical landmark detection via shape-regulated self-training},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classify and generate: Using classification latent space
representations for image generations. <em>NEUCOM</em>, <em>471</em>,
296–334. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utilization of classification latent space information for downstream reconstruction and generation is an intriguing and a relatively unexplored area. In general, discriminative representations are rich in class specific features but are too sparse for reconstruction, whereas, in autoencoders the representations are dense but has limited indistinguishable class specific features, making it less suitable for classification. In this work, we propose a discriminative modelling framework that employs manipulated supervised latent representations to reconstruct and generate new samples belonging to a given class. Unlike generative modelling approaches such as GANs and VAEs that aim to model the data manifold distribution, Representation based Generations (ReGene) directly represents the given data manifold in the classification space. Such supervised representations, under certain constraints, allow for reconstructions and controlled generations using an appropriate decoder without enforcing any prior distribution. Theoretically, given a class, we show that these representations when smartly manipulated using convex combinations retain the same class label. Furthermore, they also lead to novel generation of visually realistic images. Extensive experiments on datasets of varying resolutions demonstrate that ReGene has higher classification accuracy than existing conditional generative models while being competitive in terms of FID.},
  archive      = {J_NEUCOM},
  author       = {Saisubramaniam Gopalakrishnan and Pranshu Ranjan Singh and Yasin Yazici and Chuan-Sheng Foo and Vijay Chandrasekhar and ArulMurugan Ambikapathi},
  doi          = {10.1016/j.neucom.2021.10.090},
  journal      = {Neurocomputing},
  pages        = {296-334},
  shortjournal = {Neurocomputing},
  title        = {Classify and generate: Using classification latent space representations for image generations},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel approach for automatic detection of linear and
nonlinear dependencies between data by means of autoencoders.
<em>NEUCOM</em>, <em>471</em>, 285–295. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autoencoders are widely used in many scientific disciplines for their good performance as so-called building blocks of deep learning . Furthermore, they have a pronounced capability for dimensionality reduction. In this paper it is shown that autoencoders can additionally be used not only to detect but to qualify dependencies among the parameters of input data sets. For doing so, a two-step approach is proposed. Herein, the identical mapping of the input data to the output layer is done with a stacked autoencoder. Evaluating respective sensitivity measures yields the sought interrelations between the input parameters, if there are any. To verify the new approach, numerical experiments are conducted with synthesized data where linear or nonlinear dependencies between the input parameters are known a priori . It is shown that the two-step approach automatically detects these dependencies for all investigated cases.},
  archive      = {J_NEUCOM},
  author       = {Uwe Reuter and Aditha Jayaram and Mina Rezkalla and Wolfgang Weber},
  doi          = {10.1016/j.neucom.2021.10.079},
  journal      = {Neurocomputing},
  pages        = {285-295},
  shortjournal = {Neurocomputing},
  title        = {A novel approach for automatic detection of linear and nonlinear dependencies between data by means of autoencoders},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Multi-agent reinforcement learning by the actor-critic
model with an attention interface. <em>NEUCOM</em>, <em>471</em>,
275–284. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent reinforcement learning algorithms have achieved satisfactory performances in various scenarios, but many of them encounter difficulties in partially observable environments. In partially observable environments, the inability to perceive environment states results in unsteadiness and misconvergence, especially in large-scale multi-agent environments. To improve interactions among homogeneous agents in a partially observable environment, we propose a novel multi-agent actor-critic model with a visual attention interface to solve this problem. First, a recurrent visual attention interface is used to extract a latent state from each agent’s partial observation. These latent states allow agents to focus on several local environments, in which each agent has a complete perception of a local environment and the intricate multi-agent environment is teased out by the interaction among several agents in the same local environment. The proposed method trains multi-agent systems with a centralized training and decentralized execution mechanism. The joint action of agents is approximated by the mean-field theory because the number of agents in a local environment is uncertain. Experimental results on the simulation platform suggest that our model performs better when training large-scale multi-agent systems in partially observable environments than baselines.},
  archive      = {J_NEUCOM},
  author       = {Lixiang Zhang and Jingchen Li and Yi&#39;an Zhu and Haobin Shi and Kao-Shing Hwang},
  doi          = {10.1016/j.neucom.2021.06.049},
  journal      = {Neurocomputing},
  pages        = {275-284},
  shortjournal = {Neurocomputing},
  title        = {Multi-agent reinforcement learning by the actor-critic model with an attention interface},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adversarial α-divergence minimization for bayesian
approximate inference. <em>NEUCOM</em>, <em>471</em>, 260–274. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks are state-of-the-art models for machine learning problems. They are often trained via back-propagation to find a value of the weights that correctly predicts the observed data. Back-propagation has shown good performance in many applications, however, it cannot easily output an estimate of the uncertainty in the predictions made. Estimating this uncertainty is a critical aspect with important applications. One method to obtain this information consists in following a Bayesian approach to obtain a posterior distribution of the model parameters. This posterior distribution summarizes which parameter values are compatible with the observed data. However, the posterior is often intractable and has to be approximated. Several methods have been devised for this task. Here, we propose a general method for approximate Bayesian inference that is based on minimizing α α -divergences, and that allows for flexible approximate distributions. We call this method adversarial α α -divergence minimization (AADM). We have evaluated AADM in the context of Bayesian neural networks. Extensive experiments show that it may lead to better results in terms of the test log-likelihood, and sometimes in terms of the squared error, in regression problems . In classification problems, however, AADM gives competitive results.},
  archive      = {J_NEUCOM},
  author       = {Simón Rodríguez-Santana and Daniel Hernández-Lobato},
  doi          = {10.1016/j.neucom.2020.09.076},
  journal      = {Neurocomputing},
  pages        = {260-274},
  shortjournal = {Neurocomputing},
  title        = {Adversarial α-divergence minimization for bayesian approximate inference},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view clustering based on generalized low rank
approximation. <em>NEUCOM</em>, <em>471</em>, 251–259. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core of most existing graph-based multi-view clustering methods is to learn a rigid consistent spectral embedding from multiple graphs. In practice, however, such a consistency over spectral embedding may be rigorous to limit the final clustering result , since the quality and structure of different graphs are generally different. To this end, we propose to learn a relaxed consistent spectral embedding via a generalized low rank approximation model. Particularly, the proposed model introduces an adaptively weighted system which can further improve the robustness of algorithm by assigning a specific weight for each view. For the involved objective function is non-convex and non-smooth, a Relaxed MM (Majorization-Minimization) approach is developed to solve it. And, we show that Relaxed MM can reduce the computation complexity from O ( n 3 ) O(n3) , required by most existing graph-based methods, to O ( nc 2 ) O(nc2) , where c and n are the number of clusters and samples, respectively, and c ≪ n c≪n . Numerical experiments performed on real world data demonstrate that our algorithm generally achieves comparable or better clustering results compared to eight state-of-the-art multi-view clustering methods .},
  archive      = {J_NEUCOM},
  author       = {Ziheng Li and Zhanxuan Hu and Feiping Nie and Rong Wang and Xuelong Li},
  doi          = {10.1016/j.neucom.2020.08.049},
  journal      = {Neurocomputing},
  pages        = {251-259},
  shortjournal = {Neurocomputing},
  title        = {Multi-view clustering based on generalized low rank approximation},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian active learning with abstention feedbacks.
<em>NEUCOM</em>, <em>471</em>, 242–250. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study pool-based active learning with abstention feedbacks where a labeler can abstain from labeling a queried example with some unknown abstention rate. This is an important problem with many useful applications. We take a Bayesian approach to the problem and develop two new greedy algorithms that learn both the classification problem and the unknown abstention rate at the same time. These are achieved by simply incorporating the estimated average abstention rate into the greedy criteria. We prove that both algorithms have near-optimality guarantees: they respectively achieve a ( 1 - 1 e ) (1-1e) constant factor approximation of the optimal expected or worst-case value of a useful utility function. Our experiments show the algorithms perform well in various practical scenarios.},
  archive      = {J_NEUCOM},
  author       = {Cuong V. Nguyen and Lam Si Tung Ho and Huan Xu and Vu Dinh and Binh T. Nguyen},
  doi          = {10.1016/j.neucom.2021.11.027},
  journal      = {Neurocomputing},
  pages        = {242-250},
  shortjournal = {Neurocomputing},
  title        = {Bayesian active learning with abstention feedbacks},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MPAN: Multi-parallel attention network for session-based
recommendation. <em>NEUCOM</em>, <em>471</em>, 230–241. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A powerful session-based recommender can typically explore the users’ evolving interests (i.e., a combination of her long-term and short-term interests). Recent advances in attention mechanisms have led to state-of-the-art methods for solving this task. However, there are still three main limitations. First, most of the attention-based methods only utilize the last clicked item to represent users’ short-term interests which ignores the temporal information and behavior context. Second, to learn users’ long-term interests, most existing models employ the vanilla attention method, which has difficulty in capturing the diversity of long-term interests. Third, current studies typically assume that long-term interests and short-term interests are equally important ignoring their user-specific importance. Therefore, we propose a Multi-Parallel Attention Network (MPAN) model for Session-based Recommendation. Specifically, we propose a novel time-aware attention mechanism to learn users’ short-term interests by capturing contextual information and temporal signals simultaneously. Next, we design a refined multi-head attention mechanism to extract the diverse long-term interests from different latent subspaces. Besides, we introduce a gated fusion method that adaptively integrates users’ long-term and short-term interests to generate a hybrid interest representation. Experiments on three real-world datasets show that MPAN achieves noticeable improvements than state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Tianzi Zang and Yanmin Zhu and Jing Zhu and Yanan Xu and Haobing Liu},
  doi          = {10.1016/j.neucom.2021.11.030},
  journal      = {Neurocomputing},
  pages        = {230-241},
  shortjournal = {Neurocomputing},
  title        = {MPAN: Multi-parallel attention network for session-based recommendation},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stereo CenterNet-based 3D object detection for autonomous
driving. <em>NEUCOM</em>, <em>471</em>, 219–229. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, three-dimensional (3D) detection based on stereo images has progressed remarkably; however, most advanced methods adopt anchor-based two-dimensional (2D) detection or depth estimation to address this problem. Nevertheless, high computational cost inhibits these methods from achieving real-time performance. In this study, we propose a 3D object detection method, Stereo CenterNet (SC), using geometric information in stereo imagery. SC predicts the four semantic key points of the 3D bounding box of the object in space and utilizes 2D left and right boxes, 3D dimension, orientation, and key points to restore the bounding box of the object in the 3D space. Subsequently, we adopt an improved photometric alignment module to further optimize the position of the 3D bounding box. Experiments conducted on the KITTI dataset indicate that the proposed SC exhibits the best speed-accuracy trade-off among advanced methods without using extra data.},
  archive      = {J_NEUCOM},
  author       = {Yuguang Shi and Yu Guo and Zhenqiang Mi and Xinjie Li},
  doi          = {10.1016/j.neucom.2021.11.048},
  journal      = {Neurocomputing},
  pages        = {219-229},
  shortjournal = {Neurocomputing},
  title        = {Stereo CenterNet-based 3D object detection for autonomous driving},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cooperative density-aware representation learning for
few-shot visual recognition. <em>NEUCOM</em>, <em>471</em>, 208–218. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot visual recognition has achieved remarkable advances along with the rise of deep learning . Its goal is to learn the model parameter from the base category for transferring it to the novel category with limited annotations. However, most of the existing few-shot visual recognition approaches mainly focus on extracting a global feature representation of the sample, which fails to encode the semantic information. To alleviate this issue, this paper presents a novel cooperative density-aware representation learning approach for few-shot visual recognition. Specifically, we first yield the high-level semantic features of the query set and the support set by leveraging a shared convolutional neural network . A cooperative density loss module is then designed to optimize the model to form the discriminative features by incorporating the density global classification loss and the density few-shot loss. The density few-shot loss conducts the semantic alignment with regional features by the mutual information finding manner while the density global classification loss supervises each regional feature lead to more precise classification. Comprehensive experiments in few-shot visual recognition benchmarks validate the effectiveness and superiority of our proposed approach, and elaborate ablations explain the utility of different modules.},
  archive      = {J_NEUCOM},
  author       = {Zijun Zheng and Xiang Feng and Huiqun Yu and Mengqi Gao},
  doi          = {10.1016/j.neucom.2021.10.075},
  journal      = {Neurocomputing},
  pages        = {208-218},
  shortjournal = {Neurocomputing},
  title        = {Cooperative density-aware representation learning for few-shot visual recognition},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). STCM-net: A symmetrical one-stage network for temporal
language localization in videos. <em>NEUCOM</em>, <em>471</em>, 194–207.
(<a href="https://doi.org/10.1016/j.neucom.2021.11.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of temporal language localization in the video is to locate a video segment through natural language description for an untrimmed video. Compared with the general video localization task, it is more flexible and complex, which can accurately locate various scenes described by any natural language without making video labels in advance. It can be widely used for the field such as video retrieval and robot intelligent cognition. The main challenges of this task are the extraction of sentence semantics and the integration of contextual information in videos. Among them, contextual video integration can be optimized through the two-dimensional temporal adjacent network. Therefore, complete extraction of the potential information in the query sentence is necessary to solve the task more granularly. At the same time, we found a large amount of time-related information in the query sentence, which helps improve the localization accuracy. Thus, in this paper, we first define the time concept in a sentence and then propose a Sentence Time Concept Mining Network (STCM-Net), an symmetrical one-stage network. Can effectively extract the time concept contained in the query sentence, it can optimize the process of target localization and improve the localization performance. We also evaluate the proposed STCM-Net on three challenging public benchmarks: Charades-STA, ActivityNet Captions, and TACoS. Our STCM-Net gets encouraging improvements compared with the state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Zixi Jia and Minglin Dong and Jingyu Ru and Lele Xue and Sikai Yang and Chunbo Li},
  doi          = {10.1016/j.neucom.2021.11.019},
  journal      = {Neurocomputing},
  pages        = {194-207},
  shortjournal = {Neurocomputing},
  title        = {STCM-net: A symmetrical one-stage network for temporal language localization in videos},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leader-following consensus of second-order multi-agent
systems with intermittent communication via persistent-hold control.
<em>NEUCOM</em>, <em>471</em>, 183–193. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the leader-following consensus performance of second-order multi-agent systems with intermittent communication, a persistent-hold control protocol is designed in this paper. Some consensus conditions are derived under fixed and switching topologies , which depend upon the coupling strength, the eigenvalue of the Laplacian matrix and the communication structure. Finally, a series of experimental simulations are given to verify the correctness of the theoretical results. The current results provide some new insights into the consensus performance and coordinated control for multi-agent systems.},
  archive      = {J_NEUCOM},
  author       = {Tong-Tong Chen and Fu-Yong Wang and Cheng-Yi Xia and Zeng-Qiang Chen},
  doi          = {10.1016/j.neucom.2021.10.111},
  journal      = {Neurocomputing},
  pages        = {183-193},
  shortjournal = {Neurocomputing},
  title        = {Leader-following consensus of second-order multi-agent systems with intermittent communication via persistent-hold control},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generating natural adversarial examples with universal
perturbations for text classification. <em>NEUCOM</em>, <em>471</em>,
175–182. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent works have demonstrated the vulnerability of text classifiers to universal adversarial attacks , which are splicing carefully designed word sequences into the original text. These word sequences are natural, and adversarial examples generated by splicing them with the original text are unnatural. In this paper, we propose a framework for generating natural adversarial examples with an adversarially regularized autoencoder (ARAE) model and an inverter model. The framework maps discrete text into the continuous space, get the conversion of adversarial examples by adding universal adversarial perturbations in the continuous space, then generates natural adversarial examples. In order to achieve universal adversarial attacks , we design a universal adversarial perturbations search (UAPS) algorithm with the gradient of the loss function of the target classifier. Perturbations found by the UAPS algorithm can be directly added to the conversion of the original text in the continuous space. On two textual entailment datasets, we evaluate the fooling rate of generated adversarial examples on two RNN-based architectures and one Transformer-based architecture. The results show that all architectures are vulnerable to the adversarial examples. For example, on the SNLI dataset, the accuracy of the ESIM model for the “entailment” category drops from 88.35\% to 2.26\%. While achieving a high fooling rate, generated adversarial examples have good performance in naturalness. By further analysis, adversarial examples generated in this paper have transferability in neural networks .},
  archive      = {J_NEUCOM},
  author       = {Haoran Gao and Hua Zhang and Xingguo Yang and Wenmin Li and Fei Gao and Qiaoyan Wen},
  doi          = {10.1016/j.neucom.2021.10.089},
  journal      = {Neurocomputing},
  pages        = {175-182},
  shortjournal = {Neurocomputing},
  title        = {Generating natural adversarial examples with universal perturbations for text classification},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). SiamOAN: Siamese object-aware network for real-time target
tracking. <em>NEUCOM</em>, <em>471</em>, 161–174. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Siamese-based tracking algorithms usually utilize local features to represent the object, which lack sufficient discrimination and may degrade tracking performance in challenging situations. To address this issue, we propose a novel object-aware network to improve feature representation and achieve robust object tracking. The proposed object-aware network contains a background filter module (BFM), channel complementary module (CCM), and template adaptive network (TAN). Specifically, by locating the target in the initial frame on the feature maps, BFM suppresses the background interference of the target template. CCM captures the global context by exploring the complementary information of each channel. The lightweight TAN adaptively recognizes valuable features for the target and represents the target template just through a single vector. Benefiting from these three components, the object-aware network enhances the discrimination of feature maps and alleviates background interference to some extent. The proposed object-aware network could be integrated with the Siamese-based backbone network for real-time object tracking, named SiamOAN. Extensive experiments on the six challenging benchmarks including OTB100, UAV123, VOT2016, VOT2018, GOT10k, and LaSOT, show that the proposed SiamOAN outperforms many state-of-the-art trackers and runs at approximately 67 fps on GPU RTX3090.},
  archive      = {J_NEUCOM},
  author       = {Bingbing Wei and Hongyu Chen and Qinghai Ding and Haibo Luo},
  doi          = {10.1016/j.neucom.2021.10.112},
  journal      = {Neurocomputing},
  pages        = {161-174},
  shortjournal = {Neurocomputing},
  title        = {SiamOAN: Siamese object-aware network for real-time target tracking},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic neural networks based adaptive optimal impedance
control for redundant manipulators under physical constraints.
<em>NEUCOM</em>, <em>471</em>, 149–160. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a dynamic neural network based adaptive impedance control method for redundant robots under multiple physical constraints. In order to provide optimal contact performance without an accurate environment model, an adaptive impedance learning method is proposed to establish the optimal interaction between robot and environment. In the inner loop, a theoretical framework of constraint optimization is constructed, and then a dynamic neural network is established to compensate the nonlinear dynamics, and compliance to physical limitations is also satisfied. These limitations include joint angle restriction, angular velocity restriction, angular acceleration restriction, and torque restriction. Theoretical analysis proves the stability of the closed loop system. Numerical results show the effectiveness of the proposed control scheme.},
  archive      = {J_NEUCOM},
  author       = {Zhihao Xu and Xiaoxiao Li and Shuai Li and Hongmin Wu and Xuefeng Zhou},
  doi          = {10.1016/j.neucom.2021.11.025},
  journal      = {Neurocomputing},
  pages        = {149-160},
  shortjournal = {Neurocomputing},
  title        = {Dynamic neural networks based adaptive optimal impedance control for redundant manipulators under physical constraints},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Explore modeling relation information and direction
information in KBQA. <em>NEUCOM</em>, <em>471</em>, 139–148. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Bases (KB) are composed of multiple entities and relations, which can be organized by an entity-relation-entity pattern. Question Answering models over Knowledge Bases (KBQA) aims to retrieve the answers to a factual question from a given KB. The relation information has gained more attention from existing models due to its ability to generate the key reasoning path. Although effective, the main concern of existing models is that relation information is not fully explored, based on the observation that they utilize the fixed relation representation across different question-aware subgraphs. Thus the relation representation will overlook the rich structured information of different subgraphs. Besides, the direction information, which is inspired by human behaviors , can help the model find the answers more accurately, but it is not fully explored. To address the above two challenges, in this paper, we propose a novel reasoning model, which is capable of making the relation aware of subgraphs and implanting the Direction information into reasoning. Specifically, we convert all relations in each subgraph to additional nodes to learn structure information. Additionally, we utilize direction information to enhance the reasoning ability. We verify the effectiveness and robustness of our proposed model with different KB sizes on two widely used datasets.},
  archive      = {J_NEUCOM},
  author       = {Xu Wang and Shuai Zhao and Bo Cheng and Yuwei Yin and Hao Yang},
  doi          = {10.1016/j.neucom.2021.10.094},
  journal      = {Neurocomputing},
  pages        = {139-148},
  shortjournal = {Neurocomputing},
  title        = {Explore modeling relation information and direction information in KBQA},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mean-square stability of stochastic quaternion-valued neural
networks with variable coefficients and neutral delays. <em>NEUCOM</em>,
<em>471</em>, 130–138. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the stochastic quaternion-valued neural networks model with variable coefficients and neutral delays is considered, and the mean-square stability criterion is provided via the method of mathematical analysis. In deriving stability criterion, the considered stochastic quaternion-valued neural networks model is implemented as an entirety form without separating the model into two complex-valued or four real-valued models. And the obtained result is valid for stochastic real-valued and complex-valued neural networks. A numerical simulation example is given to show the effectiveness of the obtained result.},
  archive      = {J_NEUCOM},
  author       = {Qiankun Song and Runtian Zeng and Zhenjiang Zhao and Yurong Liu and Fuad E. Alsaadi},
  doi          = {10.1016/j.neucom.2021.11.033},
  journal      = {Neurocomputing},
  pages        = {130-138},
  shortjournal = {Neurocomputing},
  title        = {Mean-square stability of stochastic quaternion-valued neural networks with variable coefficients and neutral delays},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TVGCN: Time-variant graph convolutional network for traffic
forecasting. <em>NEUCOM</em>, <em>471</em>, 118–129. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting is a very challenging task due to the complicated and dynamic spatial–temporal correlations between traffic nodes. Most existing methods measure the spatial correlations by defining physical or virtual graphs with distance or similarity measurement, which is constructed with stable edge connections by some prior knowledge. However, the use of such graphs with stable edge connections limits the variations of spatial correlations between traffic nodes at different times, which can not capture the hidden dynamic patterns of traffic graphs. This paper proposes a Time-Variant Graph Convolutional Network (TVGCN) to overcome this limitation. Architecturally, a time-variant spatial convolutional module (TV-SCM) is developed on two graphs without any prior knowledge. One graph is learned to capture the stable spatial correlations of the traffic graph, while the other graph is evolved to model dynamic spatial correlations at different times. Such two graphs are combined hierarchically together under the framework of graph convolutional network (GCN). Moreover, a gated multi-scale temporal convolutional module (GMS-TCM) is designed to extract long-range temporal dependencies within traffic nodes, which are further supplied to the TV-SCM to mutually explore the spatial correlations between traffic nodes. Extensive experiments conducted on three real-world traffic datasets indicate the effectiveness and superiority of our proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Yuhu Wang and Shen Fang and Chunxia Zhang and Shiming Xiang and Chunhong Pan},
  doi          = {10.1016/j.neucom.2021.11.006},
  journal      = {Neurocomputing},
  pages        = {118-129},
  shortjournal = {Neurocomputing},
  title        = {TVGCN: Time-variant graph convolutional network for traffic forecasting},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards deep entity resolution via soft schema matching.
<em>NEUCOM</em>, <em>471</em>, 107–117. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity resolution (ER) leads a key role in data preprocessing . ER identifies records corresponding to the same real-world entity. Recent years have witnessed a growing trend of deep learning based ER (deep ER). However, previous deep ER works do not fully utilize schema semantics, since they either use hard schema matching or disregard schema matching. In this work, we flexibly exploit schema matching to enhance deep ER. We define and implement soft schema matching, where attributes are flexibly associated in probabilities. Attribute associations are generated by aggregating token connections in coarse deep ER. Then we incorporate soft schema matching into hierarchical attention networks for ER, which tremendously improves resolution quality, especially for complex data and corrupted data. Different attentions are utilized for particular sub-tasks in ER networks, such as self-attention for contextualization, inter-attention for alignment and intra-attention for weighting. Finally comprehensive experiments are run over common data, complex data and corrupted data. Evaluation results show that our approach surpasses previous works.},
  archive      = {J_NEUCOM},
  author       = {Chenchen Sun and Derong Shen},
  doi          = {10.1016/j.neucom.2021.10.106},
  journal      = {Neurocomputing},
  pages        = {107-117},
  shortjournal = {Neurocomputing},
  title        = {Towards deep entity resolution via soft schema matching},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic behavior analysis of stepanov-like almost periodic
solution in distribution sense for stochastic neural network with
delays. <em>NEUCOM</em>, <em>471</em>, 94–106. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a class of stochastic neural networks with time delays is studied. Based on the contraction mapping principle, sufficient conditions are derived to ensure the existence of Stepanov-like almost periodic solutions for the stochastic neural networks under consideration. Then, by designing a novel state-feedback controller and constructing a suitable Lyapunov function , the global asymptotic synchronization and exponential stability of the stochastic neural networks are researched. Finally, two numerical examples are provided to show the feasibility of our results.},
  archive      = {J_NEUCOM},
  author       = {Jianglian Xiang and Manchun Tan},
  doi          = {10.1016/j.neucom.2021.10.108},
  journal      = {Neurocomputing},
  pages        = {94-106},
  shortjournal = {Neurocomputing},
  title        = {Dynamic behavior analysis of stepanov-like almost periodic solution in distribution sense for stochastic neural network with delays},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi actor hierarchical attention critic with RNN-based
feature extraction. <em>NEUCOM</em>, <em>471</em>, 79–93. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning has made significant progress in multi-agent tasks in recent years. However, most previous studies focus on solving fully cooperative tasks, which do not perform well in mixed tasks. In mixed tasks, the agent needs to comprehensively consider the information provided by its friends and enemies to learn its strategy, and its strategy is sensitive to the received information. Additionally, the input space of the critic network increases rapidly with the number of agents in the actor-critic framework. It’s of great necessity to efficiently learn information representation to obtain important features. To this end, we present an approach that conducts information representation with attention mechanism . Our approach adopts the framework of centralized training and decentralized execution. We apply the multi-head hierarchical attention mechanism to centrally computed critics, so critics can process the received information more accurately and assist actors in choosing better actions. The hierarchical attention critic adopts a bi-level attention structure which is composed of the agent-level and the group-level. They are designed to assign different weights to friends’ and enemies’ information and then summarize them at each timestep. It achieves high efficiency and scalability in mixed tasks. Furthermore, we use the feature extraction based on the recurrent neural network to encode the state-action sequence information of each agent. Experimental results show that our approach is not only applicable to cooperative environments but also better in mixed environments, especially in the predator-prey task, the reward obtained by our method is twice that of the baselines.},
  archive      = {J_NEUCOM},
  author       = {Dianxi Shi and Chenran Zhao and Yajie Wang and Huanhuan Yang and Gongju Wang and Hao Jiang and Chao Xue and Shaowu Yang and Yongjun Zhang},
  doi          = {10.1016/j.neucom.2021.10.093},
  journal      = {Neurocomputing},
  pages        = {79-93},
  shortjournal = {Neurocomputing},
  title        = {Multi actor hierarchical attention critic with RNN-based feature extraction},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stability of inertial delayed neural networks with
stochastic delayed impulses via matrix measure method. <em>NEUCOM</em>,
<em>471</em>, 70–78. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is mainly concerned with the stability of inertial delayed neural networks (IDNNs) with stochastic delayed impulses. In contrast with previous related works, the stochastic impulsive intensity and density, and impulsive delays are considered simultaneously. Firstly, by appropriate variable substitution, the considered IDNNs model is converted to a first order differential equation with stochastic delayed impulsive effect. Secondly, by using the matrix measure approach and some stochastic analysis techniques, the stability criteria of IDNNs with stochastic delayed impulses are presented. Finally, numerical examples are provided to illustrate the obtained theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Qian Cui and Lulu Li and Jinde Cao},
  doi          = {10.1016/j.neucom.2021.10.113},
  journal      = {Neurocomputing},
  pages        = {70-78},
  shortjournal = {Neurocomputing},
  title        = {Stability of inertial delayed neural networks with stochastic delayed impulses via matrix measure method},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Co-attention network with label embedding for text
classification. <em>NEUCOM</em>, <em>471</em>, 61–69. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing methods for text classification focus on extracting a highly discriminative text representation, which, however, is typically computationally inefficient. To alleviate this issue, label embedding frameworks are proposed to adopt the label-to-text attention that directly uses label information to construct the text representation for more efficient text classification . Although these label embedding methods have achieved promising results, there is still much space for exploring how to use the label information more effectively. In this paper, we seek to exploit the label information by further constructing the text-attended label representation with text-to-label attention. To this end, we propose a Co-attention Network with Label Embedding (CNLE) that jointly encodes the text and labels into their mutually attended representations. In this way, the model is able to attend to the relevant parts of both. Experiments show that our approach achieves competitive results compared with previous state-of-the-art methods on 7 multi-class classification benchmarks and 2 multi-label classification benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Minqian Liu and Lizhao Liu and Junyi Cao and Qing Du},
  doi          = {10.1016/j.neucom.2021.10.099},
  journal      = {Neurocomputing},
  pages        = {61-69},
  shortjournal = {Neurocomputing},
  title        = {Co-attention network with label embedding for text classification},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Corrigendum to “multi-instance learning based on
representative instance and feature mapping” [neurocomputing 216 (2016)
790–796/1]. <em>NEUCOM</em>, <em>471</em>, 60. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Xingqi Wang and Dan Wei and Hui Cheng and Jinglong Fang},
  doi          = {10.1016/j.neucom.2021.11.024},
  journal      = {Neurocomputing},
  pages        = {60},
  shortjournal = {Neurocomputing},
  title        = {Corrigendum to “Multi-instance learning based on representative instance and feature mapping” [Neurocomputing 216 (2016) 790–796/1]},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring fine-grained syntactic information for
aspect-based sentiment classification with dual graph neural networks.
<em>NEUCOM</em>, <em>471</em>, 48–59. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of aspect-based sentiment classification (ASC) is to predict the corresponding emotion of a specific target of a sentence. In neural network-based methods for ASC, various sophisticated models such as Recurrent Neural Networks (RNN) and Convolutional Neural Networks (CNN) are widespread. Recently, ongoing research has integrated syntactic structures into graph neural networks (GNN) to deal with ASC tasks . However, these methods are limited due to the noise and inefficient use of information of syntactic dependency trees. This paper proposes a novel GNN based deep learning model to overcome the deficiencies of prior studies. In the proposed model, to exploit the information in the syntactic dependency trees, a novel part-of-speech (POS) guided syntactic dependency graph is constructed for a relational graph attention network (RGAT) to eliminate the noises. Further, a syntactic distance attention-guided layer is designed for a densely connected graph convolutional network (DCGCN), which can fully extract semantic dependency between contextual words. Experiments on three public datasets are carried out to evaluate the effectiveness of the proposed model. Comparing to the baselines, our model, as a best alternative, achieves state-of-arts performance.},
  archive      = {J_NEUCOM},
  author       = {Luwei Xiao and Yun Xue and Hua Wang and Xiaohui Hu and Donghong Gu and Yongsheng Zhu},
  doi          = {10.1016/j.neucom.2021.10.091},
  journal      = {Neurocomputing},
  pages        = {48-59},
  shortjournal = {Neurocomputing},
  title        = {Exploring fine-grained syntactic information for aspect-based sentiment classification with dual graph neural networks},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Accurate and compact convolutional neural network based on
stochastic computing. <em>NEUCOM</em>, <em>471</em>, 31–47. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) achieve state-of-the-art performance in many recognition problems. However, CNN models are computation-intensive and require enormous resources and power, limiting their applicability in embedded systems with limited area and power budget. An alternative computing technique called Stochastic Computing (SC) can implement resource-demanding algorithms in smaller hardware that indeed reduces the power consumption. In this work, we propose SC-based forward functions for CNN layers that obtain significant area savings and high accuracy to replace the conventional binary-encoded (BE) deterministic computing counterparts. Then, we specify some training considerations to enable achieving low error rates for SC-based CNN. The experimental results show that the SC-based CNN attained 99.19\% and 96.25\% classification accuracy using MNIST digit classification and AT&amp;T face recognition datasets, respectively. Moreover, the SC-based CNN of ResNet-20 model achieved 86.5\% classification accuracy using the CIFAR-10 object dataset . The SC-based CNN functions have better classification accuracy compared to other SC schemes and obtained ultra-low hardware footprint compared to conventional BE counterparts.},
  archive      = {J_NEUCOM},
  author       = {Hamdan Abdellatef and Mohamed Khalil-Hani and Nasir Shaikh-Husin and Sayed Omid Ayat},
  doi          = {10.1016/j.neucom.2021.10.105},
  journal      = {Neurocomputing},
  pages        = {31-47},
  shortjournal = {Neurocomputing},
  title        = {Accurate and compact convolutional neural network based on stochastic computing},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust tracking control of uncertain nonlinear systems with
adaptive dynamic programming. <em>NEUCOM</em>, <em>471</em>, 21–30. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although robust regulation problem has been well studied, solving robust tracking control via online learning has not been fully solved, in particular for nonlinear systems . This paper develops an online adaptive learning technique to complete the robust tracking control design for nonlinear uncertain systems , which uses the ideas of adaptive dynamic programming (ADP) proposed for optimal control. An augmented system is first constructed using the tracking error and reference trajectory, so as to reformulate the tracking control into a modified robust regulation problem. Then, an equivalence between the robust control and the optimal control is established by using a constructive discounted cost function, which allows to design the robust control by tackling the optimal control of its nominal system. Then, the derived Hamilton–Jacobi-Bellman (HJB) equation is solved by training a critic neural network (NN). Finally, an adaptive learning algorithm is adopted to online directly update the unknown NN weights, where the convergence can be guaranteed. The closed-loop system stability is rigorously proved and extensive simulation results are given to show the effectiveness of the developed learning algorithm.},
  archive      = {J_NEUCOM},
  author       = {Jun Zhao and Jing Na and Guanbin Gao},
  doi          = {10.1016/j.neucom.2021.10.081},
  journal      = {Neurocomputing},
  pages        = {21-30},
  shortjournal = {Neurocomputing},
  title        = {Robust tracking control of uncertain nonlinear systems with adaptive dynamic programming},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). QoS prediction for smart service management and
recommendation based on the location of mobile users. <em>NEUCOM</em>,
<em>471</em>, 12–20. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality of Service (QoS) directly reflects the degree to which services offered by providers satisfy the non-functional requirements of users. QoS information is not usually available as a priori to providers when recommending services to user queries, this creates uncertainty in offering right services to right queries. Recent researches in service recommendation and management mainly address the issues of sparse data prediction and user personalized recommendation. Recommendation systems require smart strategies of recommending and managing services in accordance with the user queries. Predicting the QoS requirements of user queries before recommending the services can potentially aid in offering the most suitable services to users. This paper proposes a hybrid mobile service recommendation and management model based on semantic recommendation along with location-based quality preference analysis for emerging 5G mobile networks. The proposed model can effectively predict the QoS by exploiting previously invoked services to identify the best matching mobile services based on the similarity between users and services. Performance evaluation based on a published web services dataset demonstrates an enhanced prediction accuracy with an effective reduction in time overheads when compared to other related methods.},
  archive      = {J_NEUCOM},
  author       = {Lei-lei Shi and Lu Liu and Liang Jiang and Rongbo Zhu and John Panneerselvam},
  doi          = {10.1016/j.neucom.2021.02.107},
  journal      = {Neurocomputing},
  pages        = {12-20},
  shortjournal = {Neurocomputing},
  title        = {QoS prediction for smart service management and recommendation based on the location of mobile users},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Heterogeneous graph driven unsupervised domain adaptation
of person re-identification. <em>NEUCOM</em>, <em>471</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to incrementally optimize a pre-trained classifier in an unlabeled target domain is a core challenging problem of domain adaptation (DA) for many visual tasks, such as Person Re-identification (re-ID). Most of the existing methods optimize the model based on pseudo labels or similarity of instance pairs, but ignoring the diverse manifold structures of unlabeled instances in the whole dataset. In this paper, we address the importance of such structural information in domain adaptation , and propose a Heterogeneous Graph driven Optimization scheme, namely H-GO, for structure based unsupervised learning . In particular, H-GO builds a heterogeneous graph of unlabeled images to consider the heterogeneous properties of images from various cameras with varied visual styles. A heterogeneous affinity propagation method is further applied to explore the graph based affinity between the instances which share similar manifold structures. Finally, a heterogeneous affinity learning procedure is taken to optimize the visual models by using the graph based affinity of instances. Comprehensive experiments are conducted on three large-scale re-ID datasets, and the results demonstrate the flexibility and the superior performance of H-GO than state-of-the-art unsupervised domain adaptation algorithms.},
  archive      = {J_NEUCOM},
  author       = {Shaochuan Lin and Jianming Lv and Zhenguo Yang and Qing Li and Wei-Shi Zheng},
  doi          = {10.1016/j.neucom.2021.11.009},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {Heterogeneous graph driven unsupervised domain adaptation of person re-identification},
  volume       = {471},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantum machine learning: A tutorial. <em>NEUCOM</em>,
<em>470</em>, 457–461. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This tutorial provides an overview of Quantum Machine Learning (QML), a relatively novel discipline that brings together concepts from Machine Learning (ML), Quantum Computing (QC) and Quantum Information (QI). The great development experienced by QC, partly due to the involvement of giant technological companies as well as the popularity and success of ML have been responsible of making QML one of the main streams for researchers working on fuzzy borders between Physics, Mathematics and Computer Science. A possible, although arguably coarse, classification of QML methods may be based on those approaches that make use of ML in a quantum experimentation environment and those others that take advantage of QC and QI to find out alternative and enhanced solutions to problems driven by data, oftentimes offering a considerable speedup and improved performances as a result of tackling problems from a complete different standpoint. Several examples will be provided to illustrate both classes of methods.},
  archive      = {J_NEUCOM},
  author       = {José D. Martín-Guerrero and Lucas Lamata},
  doi          = {10.1016/j.neucom.2021.02.102},
  journal      = {Neurocomputing},
  pages        = {457-461},
  shortjournal = {Neurocomputing},
  title        = {Quantum machine learning: A tutorial},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An introduction to deep learning in natural language
processing: Models, techniques, and tools. <em>NEUCOM</em>,
<em>470</em>, 443–456. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural Language Processing (NLP) is a branch of artificial intelligence that involves the design and implementation of systems and algorithms able to interact through human language. Thanks to the recent advances of deep learning , NLP applications have received an unprecedented boost in performance. In this paper, we present a survey of the application of deep learning techniques in NLP, with a focus on the various tasks where deep learning is demonstrating stronger impact. Additionally, we explore, describe, and revise the main resources in NLP research, including software, hardware, and popular corpora. Finally, we emphasize the main limits of deep learning in NLP and current research directions.},
  archive      = {J_NEUCOM},
  author       = {Ivano Lauriola and Alberto Lavelli and Fabio Aiolli},
  doi          = {10.1016/j.neucom.2021.05.103},
  journal      = {Neurocomputing},
  pages        = {443-456},
  shortjournal = {Neurocomputing},
  title        = {An introduction to deep learning in natural language processing: Models, techniques, and tools},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Goal-driven, neurobiological-inspired convolutional neural
network models of human spatial hearing. <em>NEUCOM</em>, <em>470</em>,
432–442. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human brain effortlessly solves the complex computational task of sound localization using a mixture of spatial cues. How the brain performs this task in naturalistic listening environments (e.g. with reverberation) is not well understood. In the present paper, we build on the success of deep neural networks at solving complex and high-dimensional problems [1] to develop goal-driven, neurobiological-inspired convolutional neural network (CNN) models of human spatial hearing. After training, we visualize and quantify feature representations in intermediate layers to gain insights into the representational mechanisms underlying sound location encoding in CNNs. Our results show that neurobiological-inspired CNN models trained on real-life sounds spatialized with human binaural hearing characteristics can accurately predict sound location in the horizontal plane. CNN localization acuity across the azimuth resembles human sound localization acuity, but CNN models outperform human sound localization in the back. Training models with different objective functions - that is, minimizing either Euclidean or angular distance - modulates localization acuity in particular ways. Moreover, different implementations of binaural integration result in unique patterns of localization errors that resemble behavioral observations in humans. Finally, feature representations reveal a gradient of spatial selectivity across network layers, starting with broad spatial representations in early layers and progressing to sparse, highly selective spatial representations in deeper layers. In sum, our results show that neurobiological-inspired CNNs are a valid approach to modeling human spatial hearing. This work paves the way for future studies combining neural network models with empirical measurements of neural activity to unravel the complex computational mechanisms underlying neural sound location encoding in the human auditory pathway.},
  archive      = {J_NEUCOM},
  author       = {Kiki van der Heijden and Siamak Mehrkanoon},
  doi          = {10.1016/j.neucom.2021.05.104},
  journal      = {Neurocomputing},
  pages        = {432-442},
  shortjournal = {Neurocomputing},
  title        = {Goal-driven, neurobiological-inspired convolutional neural network models of human spatial hearing},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning to detect bacterial colonies for the
production of vaccines. <em>NEUCOM</em>, <em>470</em>, 427–431. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the development of vaccines, bacterial colony forming units (CFUs) are counted in order to quantify the yield in the fermentation process. This manual task is long, tedious, and subject to errors. In this work, multiple segmentation algorithms based on the U-Net CNN architecture are tested and proven to offer robust, automated CFU counting. It is also shown that the multiclass generalisation with a bespoke loss function allows virulent and avirulent colonies to be distinguished with acceptable accuracy. While many possibilities are left to explore, our results show the potential of deep learning for separating and classifying bacterial colonies.},
  archive      = {J_NEUCOM},
  author       = {Thomas Beznik and Paul Smyth and Gael de Lannoy and John A. Lee},
  doi          = {10.1016/j.neucom.2021.04.130},
  journal      = {Neurocomputing},
  pages        = {427-431},
  shortjournal = {Neurocomputing},
  title        = {Deep learning to detect bacterial colonies for the production of vaccines},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A tensor framework for learning in structured domains.
<em>NEUCOM</em>, <em>470</em>, 405–426. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning machines for structured data (e.g., trees) are intrinsically based on their capacity to learn representations by aggregating information from the multi-way relationships emerging from the structure topology. While complex aggregation functions are desirable in this context to increase the expressiveness of the learned representations, the modelling of higher-order interactions among structure constituents is unfeasible, in practice, due to the exponential number of parameters required. Therefore, the common approach is to define models which rely only on first-order interactions among structure constituents. In this work, we leverage tensors theory to define a framework for learning in structured domains. Such a framework is built on the observation that more expressive models require a tensor parameterisation. This observation is the stepping stone for the application of tensor decompositions in the context of recursive models . From this point of view, the advantage of using tensor decompositions is twofold since it allows limiting the number of model parameters while injecting inductive biases that do not ignore higher-order interactions. We apply the proposed framework on probabilistic and neural models for structured data, defining different models which leverage tensor decompositions. The experimental validation clearly shows the advantage of these models compared to first-order and full-tensorial models.},
  archive      = {J_NEUCOM},
  author       = {Daniele Castellana and Davide Bacciu},
  doi          = {10.1016/j.neucom.2021.05.110},
  journal      = {Neurocomputing},
  pages        = {405-426},
  shortjournal = {Neurocomputing},
  title        = {A tensor framework for learning in structured domains},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pyramidal reservoir graph neural network. <em>NEUCOM</em>,
<em>470</em>, 389–404. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a deep Graph Neural Network (GNN) model that alternates two types of layers. The first type is inspired by Reservoir Computing (RC) and generates new vertex features by iterating a non-linear map until it converges to a fixed point. The second type of layer implements graph pooling operations, that gradually reduce the support graph and the vertex features, and further improve the computational efficiency of the RC-based GNN. The architecture is, therefore, pyramidal. In the last layer, the features of the remaining vertices are combined into a single vector, which represents the graph embedding. Through a mathematical derivation introduced in this paper, we show formally how graph pooling can reduce the computational complexity of the model and speed-up the convergence of the dynamical updates of the vertex features. Our proposed approach to the design of RC-based GNNs offers an advantageous and principled trade-off between accuracy and complexity, which we extensively demonstrate in experiments on a large set of graph datasets.},
  archive      = {J_NEUCOM},
  author       = {F.M. Bianchi and Claudio Gallicchio and Alessio Micheli},
  doi          = {10.1016/j.neucom.2021.04.131},
  journal      = {Neurocomputing},
  pages        = {389-404},
  shortjournal = {Neurocomputing},
  title        = {Pyramidal reservoir graph neural network},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ASAP – a sub-sampling approach for preserving topological
structures modeled with geodesic topographic mapping. <em>NEUCOM</em>,
<em>470</em>, 376–388. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topological data analysis tools enjoy increasing popularity in a wide range of applications, such as Computer graphics , Image analysis, Machine learning , and Astronomy for extracting information. However, due to computational complexity , processing large numbers of samples of higher dimensionality quickly becomes infeasible. This contribution is twofold: We present an efficient novel sub-sampling strategy inspired by Coulomb’s law to decrease the number of data points in d -dimensional point clouds while preserving its homology. The method is not only capable of reducing the memory and computation time needed for the construction of different types of simplicial complexes but also preserves the size of the voids in d -dimensions, which is crucial e.g. for astronomical applications. Furthermore, we propose a technique to construct a probabilistic description of the border of significant cycles and cavities inside the point cloud. We demonstrate and empirically compare the strategy in several synthetic scenarios and an astronomical particle simulation of a dwarf galaxy for the detection of superbubbles (supernova signatures).},
  archive      = {J_NEUCOM},
  author       = {Abolfazl Taghribi and Marco Canducci and Michele Mastropietro and Sven De Rijcke and Kerstin Bunte and Peter Tiňo},
  doi          = {10.1016/j.neucom.2021.05.108},
  journal      = {Neurocomputing},
  pages        = {376-388},
  shortjournal = {Neurocomputing},
  title        = {ASAP – a sub-sampling approach for preserving topological structures modeled with geodesic topographic mapping},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). How important is data quality? Best classifiers vs best
features. <em>NEUCOM</em>, <em>470</em>, 365–375. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of choosing the appropriate classifier for a given scenario is not an easy-to-solve question. First, there is an increasingly high number of algorithms available belonging to different families. And also there is a lack of methodologies that can help on recommending in advance a given family of algorithms for a certain type of datasets. Besides, most of these classification algorithms exhibit a degradation in the performance when faced with datasets containing irrelevant and/or redundant features. In this work we analyze the impact of feature selection in classification over several synthetic and real datasets. The experimental results obtained show that the significance of selecting a classifier decreases after applying an appropriate preprocessing step and, not only this alleviates the choice, but it also improves the results in almost all the datasets tested.},
  archive      = {J_NEUCOM},
  author       = {Laura Morán-Fernández and Verónica Bólon-Canedo and Amparo Alonso-Betanzos},
  doi          = {10.1016/j.neucom.2021.05.107},
  journal      = {Neurocomputing},
  pages        = {365-375},
  shortjournal = {Neurocomputing},
  title        = {How important is data quality? best classifiers vs best features},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reservoir stack machines. <em>NEUCOM</em>, <em>470</em>,
352–364. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memory-augmented neural networks equip a recurrent neural network with an explicit memory to support tasks that require information storage without interference over long times. A key motivation for such research is to perform classic computation tasks, such as parsing . However, memory-augmented neural networks are notoriously hard to train, requiring many backpropagation epochs and a lot of data. In this paper, we introduce the reservoir stack machine, a model which can provably recognize all deterministic context-free languages and circumvents the training problem by training only the output layer of a recurrent net and employing auxiliary information during training about the desired interaction with a stack. In our experiments, we validate the reservoir stack machine against deep and shallow networks from the literature on three benchmark tasks for Neural Turing machines and six deterministic context-free languages. Our results show that the reservoir stack machine achieves zero error, even on test sequences longer than the training data, requiring only a few seconds of training time and 100 training sequences.},
  archive      = {J_NEUCOM},
  author       = {Benjamin Paaßen and Alexander Schulz and Barbara Hammer},
  doi          = {10.1016/j.neucom.2021.05.106},
  journal      = {Neurocomputing},
  pages        = {352-364},
  shortjournal = {Neurocomputing},
  title        = {Reservoir stack machines},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interpretable locally adaptive nearest neighbors.
<em>NEUCOM</em>, <em>470</em>, 344–351. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When training automated systems, it has been shown to be beneficial to adapt the representation of data by learning a problem-specific metric. This metric is global. We extend this idea and, for the widely used family of k nearest neighbors algorithms , develop a method that allows learning locally adaptive metrics. These local metrics not only improve performance, but are naturally interpretable. To demonstrate important aspects of how our approach works, we conduct a number of experiments on synthetic data sets, and we show its usefulness on real-world benchmark data sets.},
  archive      = {J_NEUCOM},
  author       = {Jan Philip Göpfert and Heiko Wersing and Barbara Hammer},
  doi          = {10.1016/j.neucom.2021.05.105},
  journal      = {Neurocomputing},
  pages        = {344-351},
  shortjournal = {Neurocomputing},
  title        = {Interpretable locally adaptive nearest neighbors},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient detection of adversarial, out-of-distribution and
other misclassified samples. <em>NEUCOM</em>, <em>470</em>, 335–343. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) are increasingly being considered for safety–critical approaches in which it is crucial to detect misclassified samples. Typically, detection methods are geared towards either the detection of out-of-distribution or adversarial data. Additionally, most detection methods require a significant amount of parameters and runtime. In this contribution we discuss a novel approach for detecting misclassified samples suitable for out-of-distribution, adversarial and additionally real world error-causing corruptions. It is based on the Gradient’s Norm (GraN) of the DNN and is parameter and runtime efficient. We evaluate GraN on two different classification DNNs (DenseNet, ResNet) trained on different datasets (CIFAR-10, CIFAR-100, SVHN). In addition to the detection of different adversarial example types (FGSM, BIM , Deepfool, CWL2) and out-of-distribution data (TinyImageNet, LSUN, CIFAR-10, SVHN) we evaluate GraN for novel corruption set-ups (Gaussian, Shot and Impulse noise). Our experiments show that GraN performs comparable to state-of-the-art methods for adversarial and out-of-distribution detection and is superior for real world corruptions while being parameter and runtime efficient.},
  archive      = {J_NEUCOM},
  author       = {Julia Lust and Alexandru P. Condurache},
  doi          = {10.1016/j.neucom.2021.05.102},
  journal      = {Neurocomputing},
  pages        = {335-343},
  shortjournal = {Neurocomputing},
  title        = {Efficient detection of adversarial, out-of-distribution and other misclassified samples},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep fair models for complex data: Graphs labeling and
explainable face recognition. <em>NEUCOM</em>, <em>470</em>, 318–334.
(<a href="https://doi.org/10.1016/j.neucom.2021.05.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The central goal of Algorithmic Fairness is to develop AI-based systems which do not discriminate subgroups in the population with respect to one or multiple notions of inequity, knowing that data is often humanly biased. Researchers are racing to develop AI-based systems able to reach superior performance in terms of accuracy, increasing the risk of inheriting the human biases hidden in the data. An obvious tension exists between these two lines of research that are currently colliding due to increasing concerns regarding the widespread adoption of these systems and their ethical impact. The problem is even more challenging when the input data is complex (e.g. graphs, trees, or images) and deep uninterpretable models need to be employed to achieve satisfactory performance. In fact, it is required to develop a deep architecture to learn a data representation able, from one side, to be expressive enough to describe the data and lead to highly accurate models and, from the other side, to discard all the information which may lead to unfair behavior . In this work we measure fairness according to Demographic Parity, requiring the probability of the model decisions to be independent of the sensitive information . We investigate how to impose this constraint in the different layers of deep neural networks for complex data, with particular reference to deep networks for graph and face recognition. We present experiments on different real-world datasets, showing the effectiveness of our proposal both quantitatively by means of accuracy and fairness metrics and qualitatively by means of visual explanation.},
  archive      = {J_NEUCOM},
  author       = {Danilo Franco and Nicolò Navarin and Michele Donini and Davide Anguita and Luca Oneto},
  doi          = {10.1016/j.neucom.2021.05.109},
  journal      = {Neurocomputing},
  pages        = {318-334},
  shortjournal = {Neurocomputing},
  title        = {Deep fair models for complex data: Graphs labeling and explainable face recognition},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient computation of counterfactual explanations and
counterfactual metrics of prototype-based classifiers. <em>NEUCOM</em>,
<em>470</em>, 304–317. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing use of machine learning in practice and legal regulations like EU’s GDPR cause the necessity to be able to explain the prediction and behavior of machine learning models. A prominent example of particularly intuitive explanations of AI models in the context of decision making are counterfactual explanations. Yet, it is still an open research problem how to efficiently compute counterfactual explanations for many models. In this contribution, we investigate how to efficiently compute counterfactual explanations for an important class of models, prototype-based classifiers such as learning vector quantization models. In particular, we derive specific convex and non-convex programs depending on the used metric. Typically counterfactual explanations deliver a feedback in terms of changes of the input features which lead to a different output – one application scenario is the link of these required changes to actionable items to change the desired outcome. Yet, rather than minimum changes of the input, it is interesting to address minimum changes of the model itself, which are required to lead to a different result. rather than a change of its inputs. We phrase this question as a counterfactual of the model prescription rather than the data points. We focus on distance-based classifiers (in particular learning vector quantization models), where model changes correspond to changes of metric parameters, and we develop efficient optimization techniques to generate such counterfactual metric changes depending on the chosen model.},
  archive      = {J_NEUCOM},
  author       = {André Artelt and Barbara Hammer},
  doi          = {10.1016/j.neucom.2021.04.129},
  journal      = {Neurocomputing},
  pages        = {304-317},
  shortjournal = {Neurocomputing},
  title        = {Efficient computation of counterfactual explanations and counterfactual metrics of prototype-based classifiers},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Advances in artificial neural networks, machine learning and
computational intelligence. <em>NEUCOM</em>, <em>470</em>, 300–303. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Luca Oneto and Kerstin Bunte and Nicoló Navarin},
  doi          = {10.1016/j.neucom.2021.07.053},
  journal      = {Neurocomputing},
  pages        = {300-303},
  shortjournal = {Neurocomputing},
  title        = {Advances in artificial neural networks, machine learning and computational intelligence},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A deep neural network ensemble of multimodal signals for
classifying excavator operations. <em>NEUCOM</em>, <em>470</em>,
290–299. (<a
href="https://doi.org/10.1016/j.neucom.2020.01.127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prognostics and health management (PHM) aims to provide a comprehensive solution for equipment health care. Classifying the operation mode of excavator, one of the tasks in the PHM, is important to evaluate the remaining useful lifetime. Several studies have been conducted to classify the operations with either video or sensor data, but they have several limitations to use only one type of data. A model trained with sensor data cannot classify the similar operations such as “digging” and “ditch digging” , whereas a model with video data is vulnerable to surrounding condition like weather. In this paper, to overcome these shortcomings, we propose a deep neural network ensemble called FusionNet that classifies the operations of excavator. Two models are trained with sensor data and video frames respectively, where the feature extractors are transferred to the FusionNet. The proposed network ensemble performs a flexible and well-optimized classification by automatically calculating weights according to the extracted feature vectors and combining them. To verify the proposed model, several experiments are conducted with the real-world data. The proposed model achieves the accuracy of 99.17\% which outperforms the conventional methods. We also confirm that the proposed model can address the shortcomings of using only one type of data and maximize the benefits through the automatic weighting of extracted features.},
  archive      = {J_NEUCOM},
  author       = {Jin-Young Kim and Sung-Bae Cho},
  doi          = {10.1016/j.neucom.2020.01.127},
  journal      = {Neurocomputing},
  pages        = {290-299},
  shortjournal = {Neurocomputing},
  title        = {A deep neural network ensemble of multimodal signals for classifying excavator operations},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Wavelet extreme learning machine and deep learning for data
classification. <em>NEUCOM</em>, <em>470</em>, 280–289. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the Extreme Learning Machine (ELM) algorithm has been applied to various fields due to its rapidity and significant generalization performance . Traditionally, deep learning (DL) and wavelet neural networks (WNN) methods reach a high classification accuracy in machine learning applications. As a result, a new structure based on WNN, deep architecture and ELM is proposed in this paper. The proposed method is based on Extreme Learning Machine Auto-Encoder with DL structure and a composite wavelet activation function used in the hidden nodes. To evaluate the performance of our approach, we used standard benchmark data-sets, namely COIL-20, Pima Indian Diabetes (PID), MNIST and EMNIST. Experimental results show that our method offers satisfactory results and performance compared to other approaches.},
  archive      = {J_NEUCOM},
  author       = {Siwar Yahia and Salwa Said and Mourad Zaied},
  doi          = {10.1016/j.neucom.2020.04.158},
  journal      = {Neurocomputing},
  pages        = {280-289},
  shortjournal = {Neurocomputing},
  title        = {Wavelet extreme learning machine and deep learning for data classification},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue SOCO 2019: New trends in soft computing and
its application in industrial and environmental problems.
<em>NEUCOM</em>, <em>470</em>, 278–279. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Francisco Martínez Álvarez and Alicia Troncoso Lora and Héctor Quintián and Emilio Corchado},
  doi          = {10.1016/j.neucom.2021.01.071},
  journal      = {Neurocomputing},
  pages        = {278-279},
  shortjournal = {Neurocomputing},
  title        = {Special issue SOCO 2019: New trends in soft computing and its application in industrial and environmental problems},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mean-square input-to-state stability for stochastic
complex-valued neural networks with neutral delay. <em>NEUCOM</em>,
<em>470</em>, 269–277. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the issue of input-to-state exponential stability (ISES) for stochastic complex-valued neural networks with neutral delay (SCVNNs) and discrete delay is considered. Without separating the SCVNNs into two real-valued systems, two criteria expressed through linear matrix inequality (LMI) to pledge ISES of the considered SCVNNs are derived based on Itô formula in complex-valued field, Lyapunov–Krasovskii functional approach as well as some relevant inequality skills. Two examples are furnished to verify the raised results.},
  archive      = {J_NEUCOM},
  author       = {Qiankun Song and Zhenjiang Zhao and Yurong Liu and Fuad E. Alsaadi},
  doi          = {10.1016/j.neucom.2021.10.117},
  journal      = {Neurocomputing},
  pages        = {269-277},
  shortjournal = {Neurocomputing},
  title        = {Mean-square input-to-state stability for stochastic complex-valued neural networks with neutral delay},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FADER: Fast adversarial example rejection. <em>NEUCOM</em>,
<em>470</em>, 257–268. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks are vulnerable to adversarial examples , i.e., carefully-crafted inputs that mislead classification at test time. Recent defenses have been shown to improve adversarial robustness by detecting anomalous deviations from legitimate training samples at different layer representations - a behavior normally exhibited by adversarial attacks . Despite technical differences, all aforementioned methods share a common backbone structure that we formalize and highlight in this contribution, as it can help in identifying promising research directions and drawbacks of existing methods. The first main contribution of this work is the review of these detection methods in the form of a unifying framework designed to accommodate both existing defenses and newer ones to come. In terms of drawbacks, the overmentioned defenses require comparing input samples against an oversized number of reference prototypes, possibly at different representation layers, dramatically worsening the test-time efficiency. Besides, such defenses are typically based on ensembling classifiers with heuristic methods , rather than optimizing the whole architecture in an end-to-end manner to better perform detection. As a second main contribution of this work, we introduce FADER, a novel technique for speeding up detection-based methods. FADER overcome the issues above by employing RBF networks as detectors: by fixing the number of required prototypes, the runtime complexity of adversarial examples detectors can be controlled. Our experiments outline up to 73 × 73× prototypes reduction compared to analyzed detectors for MNIST dataset, up to 50 × 50× for CIFAR10 dataset, and up to 82 × 82× on ImageNet10 dataset respectively, without sacrificing classification accuracy on both clean and adversarial data.},
  archive      = {J_NEUCOM},
  author       = {Francesco Crecchi and Marco Melis and Angelo Sotgiu and Davide Bacciu and Battista Biggio},
  doi          = {10.1016/j.neucom.2021.10.082},
  journal      = {Neurocomputing},
  pages        = {257-268},
  shortjournal = {Neurocomputing},
  title        = {FADER: Fast adversarial example rejection},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph-based few-shot learning with transformed feature
propagation and optimal class allocation. <em>NEUCOM</em>, <em>470</em>,
247–256. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network has shown impressive ability to capture relations among support(labeled) and query(unlabeled) instances in a few-shot task. It is a feasible way that features are extracted using a pre-trained backbone network , and later adjusted in a few-shot scenario with an episodic meta-trained graph network. However, these adjusted features cannot well represent the few-shot data characteristics owing to the feature distribution mis-match caused by the different optimizations between the backbone and the graph network ( multi-class pre-train v.s. episodic meta-train ). Additionally, learning from the limited support instances fails to depict true data distributions thus cause incorrect class allocation. In this paper, we propose to transform the features extracted by a pre-trained self-supervised feature extractor into a Gaussian-like distribution to reduce the feature distribution mis-match, which significantly benefits the later meta-training of the graph network. To tackle the incorrect class allocation, we propose to leverage support and query instances to estimate class centers by computing an optimal class allocation matrix . Extensive experiments on few-shot benchmarks demonstrate that our graph-based few-shot learning pipeline outperforms baseline by 12\%, and surpasses state-of-the-art results by a large margin under both full-supervised and semi-supervised settings.},
  archive      = {J_NEUCOM},
  author       = {Ruiheng Zhang and Shuo Yang and Qi Zhang and Lixin Xu and Yang He and Fan Zhang},
  doi          = {10.1016/j.neucom.2021.10.110},
  journal      = {Neurocomputing},
  pages        = {247-256},
  shortjournal = {Neurocomputing},
  title        = {Graph-based few-shot learning with transformed feature propagation and optimal class allocation},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatial filtering based on riemannian distance to improve
the generalization of ErrP classification. <em>NEUCOM</em>,
<em>470</em>, 236–246. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the inherent non-stationarity of EEG signals, before each experimental session, BCI is usually calibrated to build the classification models , thus avoiding performance decay. This tedious re-calibration procedure is a limiting factor for real-world applications. Therefore, single-calibration or zero-calibration plays a crucial role in the use of BCIs in real contexts, outside the laboratory. Here, we propose and validate a statistical spatial filter, Riemannian Fisher criterion beamformer, based on Riemannian geometry able to use the invariance properties of Riemannian distance to handle cross-session and cross-subject generalization. The proposed method is validated with two datasets publicly available, consisting of error-related potentials. The results show that the proposed filter improves the generalization across sessions and across subjects and that it is robust to the amount of error samples used to train the classification model.},
  archive      = {J_NEUCOM},
  author       = {Aniana Cruz and Gabriel Pires and Urbano J. Nunes},
  doi          = {10.1016/j.neucom.2021.10.078},
  journal      = {Neurocomputing},
  pages        = {236-246},
  shortjournal = {Neurocomputing},
  title        = {Spatial filtering based on riemannian distance to improve the generalization of ErrP classification},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attribute disentanglement and registration for occluded
person re-identification. <em>NEUCOM</em>, <em>470</em>, 226–235. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occluded person re-identification is a challenging task which suffers from various obstacles. However, existing occluded Re-ID methods tend to exploit body detectors for pedestrian alignment, which are over-reliant on detection and lack of a flexible matching mechanism. To address this issue, we propose an Attribute Disentanglement and Registration (ADR) network to excavate non-occluded regions via attribute feature disentanglement, which can be matched effectively with a robust and soft attribute registration. The proposed ADR takes full advantages of pedestrian attributes’ high-level semantic concepts to alleviate the occlusion problem . First, the Attribute Disentanglement (AD) module obtains the representations of different attributes by localizing their spatial positions. Then the Attribute Registration (AR) module searches and matches these localized regions between different pedestrian images to conduct a registration, which allows the attribute features to be adaptively and efficiently matched. Extensive experiments on occluded, partial, and holistic Re-ID benchmarks demonstrate the effectiveness of the proposed ADR framework as well as its superiority over the existing state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yuxuan Shi and Hefei Ling and Lei Wu and Baiyan Zhang and Ping Li},
  doi          = {10.1016/j.neucom.2021.11.013},
  journal      = {Neurocomputing},
  pages        = {226-235},
  shortjournal = {Neurocomputing},
  title        = {Attribute disentanglement and registration for occluded person re-identification},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). σ2R loss: A weighted loss by multiplicative factors using
sigmoidal functions. <em>NEUCOM</em>, <em>470</em>, 217–225. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In neural networks, the loss function represents the core of the learning process that leads the optimizer to an approximation of the optimal convergence error. Convolutional neural networks (CNN) use the loss function as a supervisory signal to train a deep model and contribute significantly to achieving the state of the art in some fields of artificial vision. Cross-entropy (CE) and Center loss (CL) functions are commonly used to increase the discriminating power of learned functions and increase the generalization performance of the model. Center loss minimizes the class intra-class variance and at the same time penalizes the long distance between the deep features inside each class. However, the total error of the center loss will be heavily influenced by the majority of the instances and can lead to a freezing state in terms of intra-class variance. To address this, we introduce a new loss function called sigma squared reduction loss ( σ 2 σ2 R loss), which is regulated by a sigmoid function to inflate/deflate the error per instance and then continue to reduce the intra-class variance. Our loss has clear intuition and geometric interpretation, furthermore, we demonstrate by experiments the effectiveness of our proposal on several benchmark datasets showing the intra-class variance reduction and overcoming the results obtained with center loss and soft nearest neighbour functions.},
  archive      = {J_NEUCOM},
  author       = {Riccardo La Grassa and Ignazio Gallo and Nicola Landro},
  doi          = {10.1016/j.neucom.2021.11.022},
  journal      = {Neurocomputing},
  pages        = {217-225},
  shortjournal = {Neurocomputing},
  title        = {σ2R loss: A weighted loss by multiplicative factors using sigmoidal functions},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). End-to-end learning for simultaneously generating decision
map and multi-focus image fusion result. <em>NEUCOM</em>, <em>470</em>,
204–216. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The general aim of multi-focus image fusion is to gather focused regions of different images to generate a unique all-in-focus fused image. Deep learning based methods become the mainstream of image fusion by virtue of its powerful feature representation ability. However, most of the existing deep learning structures failed to balance fusion quality and end-to-end implementation convenience. End-to-end decoder design often leads to unrealistic result because of its non-linear mapping mechanism. On the other hand, generating an intermediate decision map achieves better quality for the fused image, but relies on the rectification with empirical post-processing parameter choices. In this work, to handle the requirements of both output image quality and comprehensive simplicity of structure implementation, we propose a cascade network to simultaneously generate decision map and fused result with an end-to-end training procedure. It avoids the dependence on empirical post-processing methods in the inference stage. To improve the fusion quality, we introduce a gradient aware loss function to preserve gradient information in output fused image. In addition, we design a decision calibration strategy to decrease the time consumption in the application of multiple images fusion. Extensive experiments are conducted to compare with 19 different state-of-the-art multi-focus image fusion structures with 6 assessment metrics. The results prove that our designed structure can generally ameliorate the output fused image quality, while implementation efficiency increases over 30\% for multiple images fusion.},
  archive      = {J_NEUCOM},
  author       = {Boyuan Ma and Xiang Yin and Di Wu and Haokai Shen and Xiaojuan Ban and Yu Wang},
  doi          = {10.1016/j.neucom.2021.10.115},
  journal      = {Neurocomputing},
  pages        = {204-216},
  shortjournal = {Neurocomputing},
  title        = {End-to-end learning for simultaneously generating decision map and multi-focus image fusion result},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online multiple object tracking based on fusing global and
partial features. <em>NEUCOM</em>, <em>470</em>, 190–203. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple object tracking (MOT) has gained increasing attention due to its academic and commercial interests in computer vision tasks . Most of the existing state-of-the-art MOT methods consider the tracking-by-detection (TBD) framework, which localizes the pedestrian in each frame and connects these object hypotheses into the trajectories without any initial labeling. These methods heavily depend on detection accuracy and data association . However, occlusion often occurs in real surveillance scenes. The frequent occlusion leads to many false detections and inaccurate appearance, decreasing the tracking performance. In this paper, we aim to propose a novel feature matching method that combines the global and partial feature matching model between two bounding boxes to improve the similarity measurement between them. Moreover, the new feature matching method leverages the advantage that global features can illustrate the whole image, and partial features can effectively handle occlusion and noise. In addition, we propose a detection modifier method based on human pose information. This detection method can be used to filter out false pedestrian detections. Finally, the experimental results demonstrate the effectiveness of our proposed method and achieve comparable performance with the state-of-the-art MOT trackers.},
  archive      = {J_NEUCOM},
  author       = {Zhihong Sun and Jun Chen and Mithun Mukherjee and Chao Liang and Weijian Ruan and Zhigeng Pan},
  doi          = {10.1016/j.neucom.2021.10.107},
  journal      = {Neurocomputing},
  pages        = {190-203},
  shortjournal = {Neurocomputing},
  title        = {Online multiple object tracking based on fusing global and partial features},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cephalometric landmark detection via global and local
encoders and patch-wise attentions. <em>NEUCOM</em>, <em>470</em>,
182–189. (<a
href="https://doi.org/10.1016/j.neucom.2021.11.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cephalometric landmark detection performs an important role in a diagnostic measurements for orthodontic treatment plans. As manual depiction of landmarks is a time-consuming and tedious task, the development of an automated detection algorithm for daily clinics is in high demand. In this study, we propose a single-passing convolutional neural network that performs an accurate landmark detection in a hierarchical fashion. The proposed network first extracts global contexts by regressing initial positions of all the landmarks. Subsequently, local features are extracted from landmark-centered patches, which are obtained through global regression. The encoded global and local features are concatenated and weighed through a novel patch-wise attention module to weigh the relative importance. The experimental results demonstrate that our proposed local patch-wise attention mechanism performs a significant role in accurate detection. The proposed method outperformed other state-of-the-art methods by improving the successful detection rate by approximately 1 ∼ 2\% 1∼2\% . The proposed method suggests that a structured attention, which is developed in a patch-wise fashion, significantly enhances the local feature encoders to further improve the final accuracy.},
  archive      = {J_NEUCOM},
  author       = {Minkyung Lee and Minyoung Chung and Yeong-Gil Shin},
  doi          = {10.1016/j.neucom.2021.11.003},
  journal      = {Neurocomputing},
  pages        = {182-189},
  shortjournal = {Neurocomputing},
  title        = {Cephalometric landmark detection via global and local encoders and patch-wise attentions},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical gate network for fine-grained visual
recognition. <em>NEUCOM</em>, <em>470</em>, 170–181. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The visual classification has achieved unprecedented progress in the last decade, and miscellaneous network architectures have emerged. However, these models yield inferior performance when deployed in fine-grained classification problems, as they are usually devised by enlarging the model capacity or facilitating the optimization, and few concentrate on the problem itself. In this paper, we argue that in most fine-grained classification problems, concepts are intrinsically hierarchically structured rather than evenly distributed, and thus classifying all concepts within a single layer simultaneously deteriorates the discrimination among different categories. Furthermore, the category hierarchy is usually not provided, which fails some existing methods where the human-defined hierarchy is required. In order to tackle these challenges, we propose a new architecture, referred to as Hierarchical Gate Network (HGNet), to exploit the interconnection among hierarchical categories. HGNet adopts an LSTM-like mechanism to transmit dependencies among classes of different levels in the hierarchy. In such a way, the context information in the hierarchical structure is utilized to boost the recognition performance. Experiments conducted on various benchmark datasets, including CUB-200–2011, Stanford Dogs, NABirds, Aircraft, iNaturalist, DeepFashion and DeepFashion2, demonstrate the superiority of the proposed method to the state-of-the-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Ying Chen and Jie Song and Mingli Song},
  doi          = {10.1016/j.neucom.2021.10.096},
  journal      = {Neurocomputing},
  pages        = {170-181},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical gate network for fine-grained visual recognition},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MCRNet: Multi-level context refinement network for semantic
segmentation in breast ultrasound imaging. <em>NEUCOM</em>,
<em>470</em>, 154–169. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated semantic segmentation in breast ultrasound imaging remains a challenging task due to the adverse impacts of poor contrast, indistinct target boundaries, and a large number of shadows. Recently, convolutional neural networks (CNN) with U-shape have demonstrated considerable performance in medical image segmentation. However, classic U-shaped networks suffer from the potential semantic gaps due to the incompatibility of encoder and decoder features, thereby resulting in sub-optimal semantic segmentation performance in ultrasound imaging . In this work, we focus on improving the U-shaped CNN through adaptively reducing semantic gaps and enhancing contextual relationships between encoder and decoder features. Specifically, we propose two lightweight yet effective context refinement blocks including inverted residual pyramid block (IRPB) and context-aware fusion block (CFB). The former can selectively extract multi-scale semantic representations according to input features, aiming to adaptively reduce semantic gaps between encoder and decoder features. The latter can exploit semantic interactions of inter-features to enhance contextual correlations between the encoder and the decoder, aiming at improving the feature fusion scheme of low- and high-level features. Further, we develop a novel multi-level context refinement network (MCRNet) by seamlessly plugging these two context refinement blocks into an encoder-decoder architecture according to the multi-level manner, thereby achieving fully automated semantic segmentation in ultrasound imaging . In order to objectively validate the proposed method, we carry out extensive qualitative and quantitative analyses based on two publicly available breast ultrasound databases including BUSI and UDIAT. The experimental results greatly reflect the efficacy of our proposed method. Meanwhile, compared with nine state-of-the-art semantic segmentation methods, our proposed MCRNet also achieves superior performance while persevering fine computational efficiency.},
  archive      = {J_NEUCOM},
  author       = {Meng Lou and Jie Meng and Yunliang Qi and Xiaorong Li and Yide Ma},
  doi          = {10.1016/j.neucom.2021.10.102},
  journal      = {Neurocomputing},
  pages        = {154-169},
  shortjournal = {Neurocomputing},
  title        = {MCRNet: Multi-level context refinement network for semantic segmentation in breast ultrasound imaging},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel learning algorithm based on computing the rules’
desired outputs of a TSK fuzzy neural network with non-separable fuzzy
rules. <em>NEUCOM</em>, <em>470</em>, 139–153. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel learning approach to train fuzzy neural networks’ parameters based on calculating the desired outputs of their rules, is proposed. We describe the desired outputs of fuzzy rules as values that make the output error equal to the minimum. To find these desired outputs, a new constrained convex optimization problem is introduced and solved. Afterward, the parameters of fuzzy rules are trained to reduce the error between the current rules’ outputs and the estimated desired ones. Therefore, the proposed learning method avoids direct output error backpropagation , which leads to vanishing gradient and consequently getting stuck in a local optimum. Therefore, the proposed method does not need any sophisticated initialization method . This learning method is successfully utilized to train a new Takagi–Sugeno-Kang (TSK) Fuzzy Neural Network with correlated fuzzy rules. The proposed paradigm, including the proposed TSK correlation-aware architecture along with the learning method, is successfully applied to six real-world time-series predictions, regression problems , and nonlinear system identification . According to the experimental results, the performance of our proposed method outperforms other methods with a more parsimonious structure.},
  archive      = {J_NEUCOM},
  author       = {Armin Salimi-Badr and Mohammad Mehdi Ebadzadeh},
  doi          = {10.1016/j.neucom.2021.10.103},
  journal      = {Neurocomputing},
  pages        = {139-153},
  shortjournal = {Neurocomputing},
  title        = {A novel learning algorithm based on computing the rules’ desired outputs of a TSK fuzzy neural network with non-separable fuzzy rules},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). OASIS: One-pass aligned atlas set for medical image
segmentation. <em>NEUCOM</em>, <em>470</em>, 130–138. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation is a fundamental task in medical image analysis. Despite that deep convolutional neural networks have gained stellar performance in this challenging task, they typically rely on large labeled datasets, which have limited their extension to customized applications. By revisiting the superiority of atlas based segmentation methods , we present a new framework of One-pass aligned Atlas Set for Images Segmentation (OASIS). To address the problem of time-consuming iterative image registration used for atlas warping, the proposed method takes advantage of the power of deep learning to achieve one-pass image registration. In addition, by applying label constraint, OASIS makes the registration process focus on the regions to be segmented for improving the performance of segmentation. Furthermore, instead of using image based similarity for label fusion, which can be distracted by the large background areas, we propose a novel strategy to compute the label similarity based weights for label fusion. Our experimental results on the challenging task of prostate MR image segmentation demonstrate that OASIS is able to significantly increase the segmentation performance compared to other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Qikui Zhu and Yanqing Wang and Bo Du and Pingkun Yan},
  doi          = {10.1016/j.neucom.2021.10.114},
  journal      = {Neurocomputing},
  pages        = {130-138},
  shortjournal = {Neurocomputing},
  title        = {OASIS: One-pass aligned atlas set for medical image segmentation},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Smart surgical control under RCM constraint using
bio-inspired network. <em>NEUCOM</em>, <em>470</em>, 121–129. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a control framework for intelligent surgical robots under the Remote Center of Motion (RCM). The goal of a surgical robot is to assist surgeons in performing complex surgeries. RCM constraint implies that the surgical tip attached to the end-effector of the surgical robot does not slide away from the point of the incision while performing surgery. Implementation of a control algorithm to comply with RCM constraints is a complicated task because of the nonlinear model of the surgical robots and stringent conditions of accuracy imposed by the patient’s safety. This paper proposes an optimization-driven approach to perform the surgical maneuver under RCM constraints. We then applied a bio-inspired optimization algorithm to solve the problem efficiently. For testing the performance of ZNNBAS, we used MATLAB to simulate a surgical procedure. A 7-DOF surgical robot (KUKA LBR IIWA 7) was used as a test bench for running the simulations. The simulation results show that the ZNNBAS is comparable with BAS, PSO , and GA and efficiently and robustly performed the task commanded maneuvers while enforcing the RCM constraints.},
  archive      = {J_NEUCOM},
  author       = {Ameer Tamoor Khan and Shuai Li},
  doi          = {10.1016/j.neucom.2021.10.116},
  journal      = {Neurocomputing},
  pages        = {121-129},
  shortjournal = {Neurocomputing},
  title        = {Smart surgical control under RCM constraint using bio-inspired network},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Structural context-based knowledge graph embedding for link
prediction. <em>NEUCOM</em>, <em>470</em>, 109–120. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding, which aims to address the limitation of symbolic representation of knowledge, has become an effective method for many AI downstream tasks, such as relation extraction, question answering. Existing knowledge graph embedding models mainly consider triples individually, and ignore the structural information connected with other entities. However, the connectivity between entities not only provides explicit structural information represented in triples, but also embodies a lot of implicit structure information. In this paper, a new knowledge graph embedding model is proposed, which can capture both the information of relational structure-context and edge structure-context by two-interaction. In addition, in order to model complex relations, we define different score function for different relation types. Moreover, the four relation connectivity types in knowledge graph (i.e. symmetry/antisymmetry, inversion, and composition) also can be modeled and inferred by StructurE. We evaluate our StructurE for knowledge graph link prediction task. Benefiting from the structural context and the relation-type-specific score function, compared with conventional geometric transformation-based knowledge graph embedding models StructurE achieves state-of-the-art results for link prediction. Moreover, compared with GCN-based models StructurE also achieves state-of-the-art results on more challenging dataset WN18RR which contains more symmetric relations.},
  archive      = {J_NEUCOM},
  author       = {Qianjin Zhang and Ronggui Wang and Juan Yang and Lixia Xue},
  doi          = {10.1016/j.neucom.2021.10.088},
  journal      = {Neurocomputing},
  pages        = {109-120},
  shortjournal = {Neurocomputing},
  title        = {Structural context-based knowledge graph embedding for link prediction},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Neural networks-based adaptive event-triggered consensus
control for a class of multi-agent systems with communication faults.
<em>NEUCOM</em>, <em>470</em>, 99–108. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the adaptive distributed event-triggered fault-tolerant consensus problem for a class of multi-agent systems with time delays and external disturbance. The communication faults between the agent and its neighbours are considered, and a fault-tolerant control mechanism is designed to overcome the communication faults. Moreover, a distributed event-triggered mechanism is constructed based on the distributed errors, and hence the communication burden can be reduced. Combining the Lyapunov stability theorem with the Lyapunov-Krasovskii function, it verifies that the consensus tracking errors are bounded with the guaranteed security performance, and the time delays phenomenon can also be compensated. Finally, the effectiveness and utility of the proposed control method are fully validated by two simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Zuo Wang and Yanzheng Zhu and Hong Xue and Hongjing Liang},
  doi          = {10.1016/j.neucom.2021.10.059},
  journal      = {Neurocomputing},
  pages        = {99-108},
  shortjournal = {Neurocomputing},
  title        = {Neural networks-based adaptive event-triggered consensus control for a class of multi-agent systems with communication faults},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modelling EMG driven wrist movements using a bio-inspired
neural network. <em>NEUCOM</em>, <em>470</em>, 89–98. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hidden pattern within the sEMG signal has wide applications in human-robot interaction. Decoding the patterns from sEMG signal tends to use black box models, which limits the further analysis of the mechanism of human musculoskeletal system. Therefore, a bio-inspired neural network (BNN) is proposed to model the information propagation procedures from nerve-related information (i.e. EMG signal) to muscle activation to joint activation to extremity movements. Instead of random parameter initialisation, the priori knowledge , such as muscle-electrode relationship, and muscles’ functionality, are fully considered to initialise the parameters. Besides, an interpretability constraint error back propagation algorithm (ICBP) is proposed to fine-tune the model for movement prediction, without scarifying model’s interpretability . An open sEMG database ISRMyo-I is utilised to verify the proposed methods for the classification of six wrist movements. With the only input of mean absolute value (MAV) feature, the proposed approach achieves an accuracy of &gt; &amp;gt; 82\%, which outperforms the support vector machine (78\%), linear discriminant analysis (80\%), k-nearest neighbors (78\%), multi-layer perceptron (69\%), random forest (74\%), and convolutional neural network (74\%).},
  archive      = {J_NEUCOM},
  author       = {Yinfeng Fang and Jiani Yang and Dalin Zhou and Zhaojie Ju},
  doi          = {10.1016/j.neucom.2021.10.104},
  journal      = {Neurocomputing},
  pages        = {89-98},
  shortjournal = {Neurocomputing},
  title        = {Modelling EMG driven wrist movements using a bio-inspired neural network},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MFC-prov: Media forensics challenge image provenance
evaluation and data analysis on large-scale datasets. <em>NEUCOM</em>,
<em>470</em>, 76–88. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of storage, transmission, editing, and sharing tools, digital forgery images are propagating rapidly. The need for image provenance analysis has never been more timely. Typical applications are content tracking, copyright enforcement, and forensics reasoning. However, large-scale image provenance datasets, which contain diverse manipulation history graphs with various manipulation operations and rich metadata, are still needed to facilitate the research. It is one of the major factors that hinders the development of techniques for image provenance analysis. To address this issue, we introduce large-scale datasets for provenance analysis, namely Media Forensics Challenge-Image Provenance (MFC-Prov) datasets. Two provenance tasks are designed along with evaluation metrics . Furthermore, extensive analysis is conducted for system performance in terms of accuracy on our datasets.},
  archive      = {J_NEUCOM},
  author       = {Xiongnan Jin and Yooyoung Lee and Jonathan Fiscus and Haiying Guan and Amy N. Yates and Andrew Delgado and Daniel F. Zhou},
  doi          = {10.1016/j.neucom.2021.10.042},
  journal      = {Neurocomputing},
  pages        = {76-88},
  shortjournal = {Neurocomputing},
  title        = {MFC-prov: Media forensics challenge image provenance evaluation and data analysis on large-scale datasets},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). News-driven stock prediction via noisy equity state
representation. <em>NEUCOM</em>, <em>470</em>, 66–75. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {News-driven stock prediction investigates the correlation between news events and stock price movements. Previous work has considered effective ways for representing news events and their sequences, but rarely exploited the representation of underlying equity states. We address this issue by making use of a recurrent neural network to represent an equity state transition sequence, integrating news representation using contextualized representations as inputs to the state transition mechanism. Thanks to the separation of news and equity representations, our model can accommodate additional input factors. We design a novel random noise factor for modeling influencing factors beyond news events, and a future event factor to address the delay of news information (e.g., insider trading) and reduce the learning difficulties. Results show that the proposed model outperforms strong baselines in the literature.},
  archive      = {J_NEUCOM},
  author       = {Heyan Huang and Xiao Liu and Yue Zhang and Chong Feng},
  doi          = {10.1016/j.neucom.2021.10.092},
  journal      = {Neurocomputing},
  pages        = {66-75},
  shortjournal = {Neurocomputing},
  title        = {News-driven stock prediction via noisy equity state representation},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed bayesian optimisation framework for deep
neuroevolution. <em>NEUCOM</em>, <em>470</em>, 51–65. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuroevolution is a machine learning method for evolving neural networks parameters and topology with a high degree of flexibility that makes them applicable to a wide range of architectures. Neuroevolution has been popular in reinforcement learning and has also shown to be promising for deep learning . The major feature of Bayesian optimisation is in reducing computational load by approximating the actual model with an acquisition function (surrogate model) that is computationally cheaper. A major limitation of neuroevolution is the high computational time required for convergence since learning (evolution) typically does not utilize gradient information. Bayesian optimisation, which is also known as surrogate-assisted optimisation, has been popular for expensive engineering optimisation problems and hyper-parameter tuning in machine learning. It has potential for training deep learning models via neuroevolution given large datasets and complex models. Recent advances in parallel and distributed computing have enabled efficient implementation of neuroevolution for complex and computationally expensive neural models. In this paper, we present a Bayesian optimisation framework for deep neuroevolution using a distributed architecture to provide computational efficiency in training. Our results demonstrate promising results for simple to deep neural network models such as convolutional neural networks which motivates further applications.},
  archive      = {J_NEUCOM},
  author       = {Rohitash Chandra and Animesh Tiwari},
  doi          = {10.1016/j.neucom.2021.10.045},
  journal      = {Neurocomputing},
  pages        = {51-65},
  shortjournal = {Neurocomputing},
  title        = {Distributed bayesian optimisation framework for deep neuroevolution},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Automatic classification of ASD children using
appearance-based features from videos. <em>NEUCOM</em>, <em>470</em>,
40–50. (<a href="https://doi.org/10.1016/j.neucom.2021.10.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early diagnosis of Autism Spectrum Disorder (ASD) plays a crucial role in the intervention of ASD. Traditionally, an ASD child needs to be diagnosed by a psychiatrist in the hospital, which is expensive, time-consuming, and influenced by expertise. In this paper, we present an objective, convenient, and effective method for classifying ASD children from raw video sequences by integrating the appearance-based features from facial expressions, head pose, and head trajectory. To better extract facial expression features, we propose a novel attention-based facial expression recognition algorithm to focus on key face areas like eyebrows, mouth, etc. Moreover, we use accumulative histogram to individually extract temporal and spatial information from facial expression, head pose and head trajectory of the video sequence. After fusing these three kinds of features, we feed them to Long Short-Term Memory (LSTM) and achieve a classification accuracy of 96.7\% on our self-collected ASD video dataset.},
  archive      = {J_NEUCOM},
  author       = {Jing Li and Zejin Chen and Gongfa Li and Gaoxiang Ouyang and Xiaoli Li},
  doi          = {10.1016/j.neucom.2021.10.074},
  journal      = {Neurocomputing},
  pages        = {40-50},
  shortjournal = {Neurocomputing},
  title        = {Automatic classification of ASD children using appearance-based features from videos},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid attention-based transformer block model for distant
supervision relation extraction. <em>NEUCOM</em>, <em>470</em>, 29–39.
(<a href="https://doi.org/10.1016/j.neucom.2021.10.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With an exponential explosive growth of various digital text information, it is challenging to efficiently obtain specific knowledge from massive unstructured text information. As one basic task for natural language processing (NLP), relation extraction (RE) aims to extract semantic relations between entity pairs based on the given text. To avoid manual labeling of datasets, distant supervision relation extraction (DSRE) has been widely used, aiming to utilize knowledge base to automatically annotate datasets. Unfortunately, this method heavily suffers from wrong labelling due to its underlying strong assumptions. To address this issue, we propose a new framework using hybrid attention-based Transformer block with multi-instance learning for DSRE. More specifically, the Transformer block is, for the first time, used as a sentence encoder, which mainly utilizes multi-head self-attention to capture syntactic information at the word level. Then, a novel sentence-level attention mechanism is proposed to calculate the bag representation, aiming to exploit all useful information in each sentence. Experimental results on the public dataset New York Times (NYT) demonstrate that the proposed approach can outperform the state-of-the-art algorithms on the adopted dataset, which verifies the effectiveness of our model on the DSRE task.},
  archive      = {J_NEUCOM},
  author       = {Yan Xiao and Yaochu Jin and Ran Cheng and Kuangrong Hao},
  doi          = {10.1016/j.neucom.2021.10.037},
  journal      = {Neurocomputing},
  pages        = {29-39},
  shortjournal = {Neurocomputing},
  title        = {Hybrid attention-based transformer block model for distant supervision relation extraction},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Digital twins based on bidirectional LSTM and GAN for
modelling the COVID-19 pandemic. <em>NEUCOM</em>, <em>470</em>, 11–28.
(<a href="https://doi.org/10.1016/j.neucom.2021.10.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The outbreak of the coronavirus disease 2019 (COVID-19) has now spread throughout the globe infecting over 150 million people and causing the death of over 3.2 million people. Thus, there is an urgent need to study the dynamics of epidemiological models to gain a better understanding of how such diseases spread. While epidemiological models can be computationally expensive, recent advances in machine learning techniques have given rise to neural networks with the ability to learn and predict complex dynamics at reduced computational costs. Here we introduce two digital twins of a SEIRS model applied to an idealised town. The SEIRS model has been modified to take account of spatial variation and, where possible, the model parameters are based on official virus spreading data from the UK. We compare predictions from one digital twin based on a data-corrected Bidirectional Long Short-Term Memory network with predictions from another digital twin based on a predictive Generative Adversarial Network. The predictions given by these two frameworks are accurate when compared to the original SEIRS model data. Additionally, these frameworks are data-agnostic and could be applied to towns, idealised or real, in the UK or in other countries. Also, more compartments could be included in the SEIRS model, in order to study more realistic epidemiological behaviour.},
  archive      = {J_NEUCOM},
  author       = {César Quilodrán-Casas and Vinicius L.S. Silva and Rossella Arcucci and Claire E. Heaney and YiKe Guo and Christopher C. Pain},
  doi          = {10.1016/j.neucom.2021.10.043},
  journal      = {Neurocomputing},
  pages        = {11-28},
  shortjournal = {Neurocomputing},
  title        = {Digital twins based on bidirectional LSTM and GAN for modelling the COVID-19 pandemic},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning architecture for the recognition of walking and
prediction of gait period using wearable sensors. <em>NEUCOM</em>,
<em>470</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a novel learning architecture for the recognition and prediction of walking activity and gait period, respectively, using wearable sensors . This approach is composed of a Convolutional Neural Network (CNN), a Predicted Information Gain (PIG) module and an adaptive combination of information sources. The CNN provides the recognition of walking and gait periods. This information is used by the proposed PIG method to estimate the next most probable gait period along the gait cycle. The outputs from the CNN and PIG modules are combined by a proposed adaptive process, which relies on data from the source that shows to be more reliable. This adaptive combination ensures that the learning architecture provides accurate recognition and prediction of walking activity and gait periods over time. The learning architecture uses data from an array of three inertial measurement units attached to the lower limbs of individuals. The validation of this work is performed by the recognition of level-ground walking, ramp ascent and ramp descent, and the prediction of gait periods. The recognition of walking activity and gait period is 100\% and 98.63\%, respectively, when the CNN model is employed alone. The recognition of gait periods achieves a 99.9\% accuracy, when the PIG method and adaptive combination are also used. These results demonstrate the benefit of having a system capable of predicting or anticipating the next information or event over time. Overall, the learning architecture offers an alternative approach for accurate activity recognition, which is essential for the development of wearable robots capable of reliably and safely assisting humans in activities of daily living.},
  archive      = {J_NEUCOM},
  author       = {Uriel Martinez-Hernandez and Mohammed I. Awad and Abbas A. Dehghani-Sanij},
  doi          = {10.1016/j.neucom.2021.10.044},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {Learning architecture for the recognition of walking and prediction of gait period using wearable sensors},
  volume       = {470},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GANLDA: Graph attention network for lncRNA-disease
associations prediction. <em>NEUCOM</em>, <em>469</em>, 384–393. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing studies have indicated that long non-coding RNAs (lncRNAs) play important roles in many physiological and pathological pathways. Identifying lncRNA-disease associations not only contributes to the understanding of biological processes, but also provides new strategies for the diagnosis and prevention of diseases. In this article, an end to end computational model based on graph attention network (GANLDA) is proposed to predict associations between lncRNAs and diseases. In our method, it combines heterogeneous data of lncRNA and disease as original features. Then, the principal component analysis (PCA) is used to reduce the noise of the original features. Further, the graph attention network is utilized to extract the useful information from features of lncRNA and disease. Finally, the multi-layer perceptron is employed to infer lncRNA-disease associations. The experimental results show GANLDA outperforms than other four state-of-the-art methods in 10-fold cross validation and devono test. The case studies also demonstrate that GANLDA is an effective method for lncRNA-disease associations identification.},
  archive      = {J_NEUCOM},
  author       = {Wei Lan and Ximin Wu and Qingfeng Chen and Wei Peng and Jianxin Wang and Yiping Phoebe Chen},
  doi          = {10.1016/j.neucom.2020.09.094},
  journal      = {Neurocomputing},
  pages        = {384-393},
  shortjournal = {Neurocomputing},
  title        = {GANLDA: Graph attention network for lncRNA-disease associations prediction},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). KAICD: A knowledge attention-based deep learning framework
for automatic ICD coding. <em>NEUCOM</em>, <em>469</em>, 376–383. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic International Classification of Diseases (ICD) coding is an important task in the future of artificial intelligence healthcare. In recent years, a lot of traditional machine learning-based methods have been proposed, and they achieved good results on this task. However, these traditional machine learning-based methods for automatic ICD coding only focus on the semantic features of clinical notes and ignore the feature extraction of ICD titles that are the descriptions of ICD codes. In this paper, we propose a knowledge attention-based deep learning framework called KAICD for automatic ICD coding. KAICD makes full use of the clinic notes and the ICD titles. The semantic features of clinic notes are extracted by a multi-scale convolutional neural network . For ICD titles, we use attention-based Bidirectional Gated Recurrent Unit (Bi-GRU) to build a knowledge database, which can offer additional information. Depending on input clinic notes, we can use the attention mechanism to obtain different knowledge vectors from the knowledge database where some ICD titles are more relevant to the input clinic notes. Last, we concatenate the knowledge vectors and the semantic features of clinic notes, and use them for the final prediction. KAICD is tested on a public dataset Medical Information Mart for Intensive Care III (MIMIC III); it achieves micro-precision of 0.502, micro-recall of 0.428, and micro-f1 of 0.462, which outperforms other competing methods. Furthermore, the results of the ablation study show that the knowledge database of ICD titles learned by the attention-based Bi-GRU enhances the feature expression and improves the prediction performance.},
  archive      = {J_NEUCOM},
  author       = {Yifan Wu and Min Zeng and Zhihui Fei and Ying Yu and Fang-Xiang Wu and Min Li},
  doi          = {10.1016/j.neucom.2020.05.115},
  journal      = {Neurocomputing},
  pages        = {376-383},
  shortjournal = {Neurocomputing},
  title        = {KAICD: A knowledge attention-based deep learning framework for automatic ICD coding},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep radiomic signature with immune cell markers predicts
the survival of glioma patients. <em>NEUCOM</em>, <em>469</em>, 366–375.
(<a href="https://doi.org/10.1016/j.neucom.2020.10.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imaging biomarkers offer a non-invasive way to predict the response of immunotherapy prior to treatment. In this work, we propose a novel type of deep radiomic features (DRFs) computed from a convolutional neural network (CNN), which capture tumor characteristics related to immune cell markers and overall survival. Our study uses four MRI sequences (T1-weighted, T1-weighted post-contrast, T2-weighted and FLAIR) with corresponding immune cell markers of 151 patients with brain tumor. The proposed method extracts a total of 180 DRFs by aggregating the activation maps of a pre-trained 3D-CNN within labeled tumor regions of MRI scans. These features offer a compact, yet powerful representation of regional texture encoding tissue heterogeneity. A comprehensive set of experiments is performed to assess the relationship between the proposed DRFs and immune cell markers, and measure their association with overall survival. Results show a high correlation between DRFs and various markers, as well as significant differences between patients grouped based on these markers. Moreover, combining DRFs, clinical features and immune cell markers as input to a random forest classifier helps discriminate between short and long survival outcomes, with AUC of 72\% and p = 2.36 × 10 −5 . These results demonstrate the usefulness of proposed DRFs as non-invasive biomarker for predicting treatment response in patients with brain tumors.},
  archive      = {J_NEUCOM},
  author       = {Ahmad Chaddad and Paul Daniel and Mingli Zhang and Saima Rathore and Paul Sargos and Christian Desrosiers and Tamim Niazi},
  doi          = {10.1016/j.neucom.2020.10.117},
  journal      = {Neurocomputing},
  pages        = {366-375},
  shortjournal = {Neurocomputing},
  title        = {Deep radiomic signature with immune cell markers predicts the survival of glioma patients},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Denoising of MR and CT images using cascaded
multi-supervision convolutional neural networks with progressive
training. <em>NEUCOM</em>, <em>469</em>, 354–365. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As MR Rician noise and CT low-dose perfusion noise have a complicated distribution, it is still a challenging task to automatically and accurately remove the noises existing in MR and CT images. Recently, convolutional neural networks have shown favorable performance on image denoising tasks. However, existing methods ignored the hierarchical features extracted from multi-supervision inner layers and estimated the denoised image just by the last single layer, which can not adequately reserve the details of the image. In this paper, we propose a cascaded multi-supervision convolutional neural network named CMSNet to remove the low-dose perfusion noise in CT images and the Rician noise exist in MR images. The CMSNet consists of a multi-supervision network (MSNet) followed with a Refinement network. MSNet is presented to predict the noise constrained by the supervisions from last three convolution layers , which can help acquire more accurate noise prediction and thus obtain the noise-free image. Refinement network is introduced to relief the details lost problem caused by the denoising operation. We employ a progressive training strategy, i.e. , MSNet is first trained independently to predict the preliminary noise and then jointly trained with Refinement network for more accurate noise estimating, which can boost the network performance. Experiments are conducted on clinic abdominal MR and CT images, and the results show that our proposed model achieved a promising performance in terms of unknown noise level, a specific noise level on peak signal to noise ratio (PSNR) and global structure similarity index measurement (SSIM).},
  archive      = {J_NEUCOM},
  author       = {Hong Song and Lei Chen and Yutao Cui and Qiang Li and Qi Wang and Jingfan Fan and Jian Yang and Le Zhang},
  doi          = {10.1016/j.neucom.2020.10.118},
  journal      = {Neurocomputing},
  pages        = {354-365},
  shortjournal = {Neurocomputing},
  title        = {Denoising of MR and CT images using cascaded multi-supervision convolutional neural networks with progressive training},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MAGE: Automatic diagnosis of autism spectrum disorders using
multi-atlas graph convolutional networks and ensemble learning.
<em>NEUCOM</em>, <em>469</em>, 346–353. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, it is still a great challenge in clinical practice to accurately diagnose autism spectrum disorder (ASD). To address this challenge, in this study we propose a method for automatic diagnosis of ASD based on multi-atlas graph convolutional networks and ensemble learning . Firstly, we extract multiple feature representations based on functional connectivity (FC) of different brain atlases from fMRI data of each subject. Then, to obtain the features that are more helpful for ASD automatic diagnosis, we propose a multi-atlas graph convolutional network method (MAGCN). Finally, to combine different feature representations, we propose a stacking ensemble learning method to perform the final ASD automatic diagnostic task. Our proposed method is evaluated on 949 subjects (including 419 subjects with ASD and 530 subjects with typical control (TC)) from the Autism Brain Imaging Data Exchange (ABIDE). Experimental results show that our proposed method achieves an accuracy of 75.86\% and an area under the receiver operating characteristic curve (AUC) of 0.8314 for automatic diagnosis of ASD. In addition, compared with some methods published in recent years, our proposed method obtains the best performance of ASD diagnosis. Overall, our proposed method is effective and promising for automatic diagnosis of ASD in clinical practice.},
  archive      = {J_NEUCOM},
  author       = {Yufei Wang and Jin Liu and Yizhen Xiang and Jianxin Wang and Qingyong Chen and Jing Chong},
  doi          = {10.1016/j.neucom.2020.06.152},
  journal      = {Neurocomputing},
  pages        = {346-353},
  shortjournal = {Neurocomputing},
  title        = {MAGE: Automatic diagnosis of autism spectrum disorders using multi-atlas graph convolutional networks and ensemble learning},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Deep learning for brain disorder diagnosis based on fMRI
images. <em>NEUCOM</em>, <em>469</em>, 332–345. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern neuroscience and clinical study, neuroscientists and clinicians often use non-invasive imaging techniques to validate theories and computational models , observe brain activities and diagnose brain disorders. The functional Magnetic Resonance Imaging (fMRI) is one of the commonly-used imaging modalities that can be used to understand human brain mechanisms as well as the diagnosis and treatment of brain disorders. The advances in artificial intelligence and the emergence of deep learning techniques have shown promising results to better interpret fMRI data. Deep learning techniques have rapidly become the state of the art for analyzing fMRI data sets and resulted in performance improvements in diverse fMRI applications . Deep learning is normally presented as an end-to-end learning process and can alleviate feature engineering requirements and hence reduce domain knowledge requirements to some extent. Under the framework of deep learning, fMRI data can be considered as images, time series or images series. Hence, different deep learning models such as convolutional neural networks , recurrent neural network , or a combination of both, can be developed to process fMRI data for different tasks. In this review, we discussed the basics of deep learning methods and focused on its successful implementations for brain disorder diagnosis based on fMRI images. The goal is to provide a high-level overview of brain disorder diagnosis with fMRI images from the perspective of deep learning applications.},
  archive      = {J_NEUCOM},
  author       = {Wutao Yin and Longhai Li and Fang-Xiang Wu},
  doi          = {10.1016/j.neucom.2020.05.113},
  journal      = {Neurocomputing},
  pages        = {332-345},
  shortjournal = {Neurocomputing},
  title        = {Deep learning for brain disorder diagnosis based on fMRI images},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Guest editorial: Deep neural networks for precision
medicine. <em>NEUCOM</em>, <em>469</em>, 330–331. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Fang-Xiang Wu ( Guest Editor ) and Min Li (Guest Editor) and Lukasz Kurgan (Guest Editor) and Luis Rueda (Guest Editor)},
  doi          = {10.1016/j.neucom.2021.06.095},
  journal      = {Neurocomputing},
  pages        = {330-331},
  shortjournal = {Neurocomputing},
  title        = {Guest editorial: Deep neural networks for precision medicine},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep prediction networks. <em>NEUCOM</em>, <em>469</em>,
321–329. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge for next generation system identification is to build new flexible models and estimators able to simulate complex systems. This task is especially difficult in the nonlinear setting. In fact, in many real applications the performance of long-term predictors may be severely affected by stability problems arising due to the output feedback. For this purpose, also the use of deep networks, which are having much success to solve classification problems, has not led so far to any significant cross-fertilization with system identification. This paper proposes a novel procedure based on a hierarchical architecture, which we call deep prediction network , whose flexibility is used to favor the identification of stable systems. In particular, its structure contains layers whose aim is to improve long-term predictions, with complexity controlled by a kernel-based strategy. The usefulness of the new approach is demonstrated through many examples, including important real benchmark problems taken from the system identification literature.},
  archive      = {J_NEUCOM},
  author       = {Alberto Dalla Libera and Gianluigi Pillonetto},
  doi          = {10.1016/j.neucom.2021.10.054},
  journal      = {Neurocomputing},
  pages        = {321-329},
  shortjournal = {Neurocomputing},
  title        = {Deep prediction networks},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Dynamic supervisor for cross-dataset object detection.
<em>NEUCOM</em>, <em>469</em>, 310–320. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of cross-dataset training in object detection tasks is complicated because the inconsistency in the category range across datasets transforms fully supervised learning into semi-supervised learning. To address this problem, recent studies focus on the generation of high-quality missing annotations. In this study, we first specify that it is not enough to generate high-quality annotations using a single model, which looks only once for annotations. Through detailed experimental analyses, we further conclude that hard-label training is conducive for generating high-recall annotations, whereas soft-label training tends to obtain high-precision annotations. Inspired by the aspects mentioned above, we propose a dynamic supervisor framework that updates the annotations multiple times through multiple-updated submodels trained using hard and soft labels. In the final generated annotations, recall and precision improve significantly through the integration of hard-label training with soft-label training. Extensive experiments conducted on various dataset combination settings support our analyses and demonstrate the superior performance of the proposed dynamic supervisor.},
  archive      = {J_NEUCOM},
  author       = {Ze Chen and Zhihang Fu and Jianqiang Huang and Mingyuan Tao and Shengyu Li and Rongxin Jiang and Xiang Tian and Yaowu Chen and Xian-Sheng Hua},
  doi          = {10.1016/j.neucom.2021.09.076},
  journal      = {Neurocomputing},
  pages        = {310-320},
  shortjournal = {Neurocomputing},
  title        = {Dynamic supervisor for cross-dataset object detection},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Global correlative network for person re-identification.
<em>NEUCOM</em>, <em>469</em>, 298–309. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (re-id) aims to retrieve the image which belongs to the same person from a set of images according to a few clues. The dataset images are usually from multiple cameras of different locations. Recently, local feature extraction has been one of the mainstream to handle this task. Recent methods show that exploration of part-level characteristics in person re-id can be helpful for its ability in capturing discriminative features . However, those works ignore the association among image regions, and it will lead to wrong retrieval results when not considering such clues. To address this limitation, we propose an effective Global Correlative Network (GCN) to jointly exploit the potential relationships between the features from semantic regions for more discriminative image representations. Specifically, we integrate the association between local areas and the global for discriminative region-aggregated features. With a relatively concise structure, a novel relation learning framework is proposed to enhance the representation with the contextual relations between the local and global perspectives. Experiments on Market-1501, DukeMTMC-reID, and CUHK03 show the effectiveness of our proposed method. Specifically, our method achieves a state-of-the-art rank-1 accuracy of 90.0\%, 83.7\%, 78.5\% on the DukeMTMC-reID, CUHK03(Labeled), and CUHK03(Detected) datasets, so it sets a new state-of-the-art.},
  archive      = {J_NEUCOM},
  author       = {Gengsheng Xie and Xianbin Wen and Liming Yuan and Haixia Xu and Zhanlu Liu},
  doi          = {10.1016/j.neucom.2021.10.055},
  journal      = {Neurocomputing},
  pages        = {298-309},
  shortjournal = {Neurocomputing},
  title        = {Global correlative network for person re-identification},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reinforcement learning based model-free optimized trajectory
tracking strategy design for an AUV. <em>NEUCOM</em>, <em>469</em>,
289–297. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the fact that it is very difficult to fully model an autonomous underwater vehicle (AUV) in the complex water environment, this paper presents a model-free tracking control strategy for an AUV in the presence of unknown disturbances. We first formulate an optimized control problem by defining a tracking Hamilton–Jacobi–Isaac (HJI) equation. Then, we present a reinforcement learning (RL) algorithm to compute an optimized solution by learning from the HJI equation online. It is noted that during the learning period, no information about the AUV’s dynamics is needed. In order to demonstrate the efficiency of the proposed strategy, numerical simulation is considered, results are validated and discussed.},
  archive      = {J_NEUCOM},
  author       = {Kairong Duan and Simon Fong and C.L. Philip Chen},
  doi          = {10.1016/j.neucom.2021.10.056},
  journal      = {Neurocomputing},
  pages        = {289-297},
  shortjournal = {Neurocomputing},
  title        = {Reinforcement learning based model-free optimized trajectory tracking strategy design for an AUV},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Phase entrainment by periodic stimuli in silico: A
quantitative study. <em>NEUCOM</em>, <em>469</em>, 273–288. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a quantitative study of phase entrainment by periodic visual stimuli in a biologically inspired neural network . The objective is to understand the neuronal population dynamics that underlie phase entrainment of brain oscillations by external stimuli, which is used for therapeutic treatment in neurological disorders , for example in Parkinsonian tremor. Yet, the neuronal dynamics underpinning such entrainment is not fully understood. Rhythmic sensory stimulation is one way of studying phase synchronisation in the brain. A recent experimental study has reported phase entrainment of brain oscillations during steady state visually evoked potentials (SSVEP), which are scalp electroencephalogram corresponding to periodic stimuli. We have simulated SSVEP-like signals corresponding to periodic pulse input to our in silico model. We have used phase locking values, normalised Shannon entropy and conditional probability as synchronisation indices to show phase synchrony in the neuronal populations. Our experiment demonstrates that the phase synchronisation disappears with jitter in the input inter-pulse intervals, and this would not be the case if the output signal were to be the superposition of the responses to the different input signals. Thus, the phase synchronisation implies entrainment of the network response by the periodic input. Overall, our study shows the plausibility of using biologically inspired in silico models, validated by experimental works, to understand and make testable predictions on brain entrainment as a therapeutic treatment in specific neurological disorders .},
  archive      = {J_NEUCOM},
  author       = {Swapna Sasi and Basabdatta Sen Bhattacharya},
  doi          = {10.1016/j.neucom.2021.10.077},
  journal      = {Neurocomputing},
  pages        = {273-288},
  shortjournal = {Neurocomputing},
  title        = {Phase entrainment by periodic stimuli in silico: A quantitative study},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-local channel aggregation network for single image rain
removal. <em>NEUCOM</em>, <em>469</em>, 261–272. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rain streaks showing in images or videos would severely degrade the performance of computer vision applications . Thus, it is of vital importance to remove rain streaks and facilitate our vision systems. While recent convolutional neural network based methods have shown promising results in single image rain removal (SIRR), they fail to effectively capture long-range location dependencies or aggregate convolutional channel information simultaneously. However, as SIRR is a highly ill-posed problem, these spatial and channel information are very important clues to solve SIRR. First, spatial information could help our model to understand the image context by gathering long-range dependency location information hidden in the image. Second, aggregating channels could help our model to concentrate on channels more related to image background instead of rain streaks. In this paper, we propose a non-local channel aggregation network (NCANet) to address the SIRR problem. NCANet models 2D rainy images as sequences of vectors in three directions, namely vertical direction, transverse direction, and channel direction. Recurrently aggregating information from all three directions enables our model to capture the long-range dependencies in both channels and spatial locations . Extensive experiments on both heavy and light rain image data sets demonstrate the effectiveness of the proposed NCANet model.},
  archive      = {J_NEUCOM},
  author       = {Zhipeng Su and Yixiong Zhang and Xiao-Ping Zhang and Feng Qi},
  doi          = {10.1016/j.neucom.2021.10.052},
  journal      = {Neurocomputing},
  pages        = {261-272},
  shortjournal = {Neurocomputing},
  title        = {Non-local channel aggregation network for single image rain removal},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Information-based distributed extended kalman filter with
dynamic quantization via communication channels. <em>NEUCOM</em>,
<em>469</em>, 251–260. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new information-based distributed extended Kalman filter algorithm under dynamic quantization. Our quantization framework has the advantage of utilizing online updated quantizer’s parameters. A practical adjustment strategy is derived to ensure the availability of adaptive quantizer’s parameters for the encoder and decoder. It is proved that estimation error of the proposed algorithm is exponentially bounded in mean square under some assumptions. A numerical example concerning target tracking is presented to demonstrate the validity of the main results, in which a complex network model is used to simulate the sensor network.},
  archive      = {J_NEUCOM},
  author       = {Shuqi Chen and Daniel W.C. Ho},
  doi          = {10.1016/j.neucom.2021.10.066},
  journal      = {Neurocomputing},
  pages        = {251-260},
  shortjournal = {Neurocomputing},
  title        = {Information-based distributed extended kalman filter with dynamic quantization via communication channels},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Attack isolation and location for a complex network
cyber-physical system via zonotope theory. <em>NEUCOM</em>,
<em>469</em>, 239–250. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the attack isolation (AI) and attack location (AL) problems for a cyber-physical system (CPS) based on the combination of the H-infinity observer and the zonotope theory, where the real control plant in the physical layer is a nonlinear complex network system. Firstly, for actuator AI and AL purposes, two robust H-infinity observers are designed and the stabilities of them are analyzed based on linear matrix inequalities (LMIs). Secondly, the zonotope theory is used to the error dynamic system of the H-infinite observer such that it can calculate iteratively the interval state estimation if the CPS has no attacks. Third, two residuals are constructed and their interval estimates are also given, and furthermore, based on the residual interval estimates, both actuator AI and AL schemes are developed. Besides, sensor AI and AL issues are discussed by modifying the actuator AI and AL schemes. Finally, the effectiveness of the proposed methods is illustrated through a simulation example.},
  archive      = {J_NEUCOM},
  author       = {Xiangming Zhang and Fanglai Zhu and Jiancheng Zhang and Tianyi Liu},
  doi          = {10.1016/j.neucom.2021.10.070},
  journal      = {Neurocomputing},
  pages        = {239-250},
  shortjournal = {Neurocomputing},
  title        = {Attack isolation and location for a complex network cyber-physical system via zonotope theory},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TedNet: A pytorch toolkit for tensor decomposition networks.
<em>NEUCOM</em>, <em>469</em>, 234–238. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor Decomposition Networks (TDNs) prevail for their inherent compact architectures. To give more researchers a flexible way to exploit TDNs, we present a Pytorch toolkit named TedNet. TedNet implements 5 kinds of tensor decomposition (i.e., CANDECOMP/PARAFAC (CP), Block-Term Tucker (BTT), Tucker-2, Tensor Train (TT) and Tensor Ring (TR)) on traditional deep neural layers, the convolutional layer and the fully-connected layer.By utilizing the basic layers, it is simple to construct a variety of TDNs. TedNet is available at https://github.com/tnbar/tednet .},
  archive      = {J_NEUCOM},
  author       = {Yu Pan and Maolin Wang and Zenglin Xu},
  doi          = {10.1016/j.neucom.2021.10.064},
  journal      = {Neurocomputing},
  pages        = {234-238},
  shortjournal = {Neurocomputing},
  title        = {TedNet: A pytorch toolkit for tensor decomposition networks},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Image sentiment classification via multi-level sentiment
region correlation analysis. <em>NEUCOM</em>, <em>469</em>, 221–233. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human’s understanding of image content is a multi-level and multi-stage process. For visual sentiment analysis , this process can be specified as the gradual perception from semantic to emotion of regions in an image. The mining of emotion-related regions is valuable for sentiment recognition, and it is even more important to further investigate the semantic associations formed between these regions. In this paper, we propose a novel multi-level sentiment region correlation analysis model, which exploits the regions in an image that are most potentially affected by emotions from multiple perspectives and motivates the interaction between sentiment regions. It makes the visual content of multi-level sentiment regions and the implicit correlations within them robust cues for image sentiment recognition. We innovatively propose a module of correlation analysis of multi-level sentiment regions to exploit the effects of higher-order and rich interactions on emotions with encoders of the Transformer. Experiments on a variety of public visual sentiment analysis datasets at different scales show that the proposed MSRCA model achieve excellent performance in image sentiment classification and outperforms other existing methods.},
  archive      = {J_NEUCOM},
  author       = {Jing Zhang and Xinyu Liu and Mei Chen and Qi Ye and Zhe Wang},
  doi          = {10.1016/j.neucom.2021.10.062},
  journal      = {Neurocomputing},
  pages        = {221-233},
  shortjournal = {Neurocomputing},
  title        = {Image sentiment classification via multi-level sentiment region correlation analysis},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CADA: Multi-scale collaborative adversarial domain
adaptation for unsupervised optic disc and cup segmentation.
<em>NEUCOM</em>, <em>469</em>, 209–220. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep neural networks have demonstrated comparable and even better performance than board-certified ophthalmologists in well-annotated datasets. However, the diversity of retinal imaging devices poses a significant challenge: domain shift, which leads to performance degradation when applying the deep learning models trained on one domain to new testing domains. In this paper, we propose a domain adaptation framework comprising of multi-scale inputs along with multiple domain adaptors applied hierarchically in both feature and output spaces. The proposed training strategy and novel unsupervised domain adaptation framework, called Collaborative Adversarial Domain Adaptation (CADA), can effectively overcome the domain shift challenge. Multi-scale inputs can reduce the information loss due to the pooling layers used in the network for feature extraction, while our proposed CADA is an interactive paradigm that presents an exquisite collaborative adaptation through both adversarial learning and ensembling weights at different network layers. In particular, to produce a better prediction for the unlabeled target domain data , we simultaneously achieve domain invariance and model generalizability via adversarial learning at multi-scale outputs from different levels of network layers and maintaining an exponential moving average (EMA) of the historical weights during training. Without annotating any sample from the target domain, multiple adversarial losses in encoder and decoder layers guide the extraction of domain-invariant features to confuse the domain classifier. Meanwhile, the ensembling of weights via EMA reduces the uncertainty of adapting multiple discriminator learning. Comprehensive experimental results demonstrate that our CADA model incorporating multi-scale input training can overcome performance degradation and outperform state-of-the-art domain adaptation methods in segmenting retinal optic disc and cup from fundus images stemming from the REFUGE, Drishti-GS, and Rim-One-r3 datasets. The code is available at https://github.com/cswin/CADA.},
  archive      = {J_NEUCOM},
  author       = {Peng Liu and Charlie T. Tran and Bin Kong and Ruogu Fang},
  doi          = {10.1016/j.neucom.2021.10.076},
  journal      = {Neurocomputing},
  pages        = {209-220},
  shortjournal = {Neurocomputing},
  title        = {CADA: Multi-scale collaborative adversarial domain adaptation for unsupervised optic disc and cup segmentation},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The capacity of the dense associative memory networks.
<em>NEUCOM</em>, <em>469</em>, 198–208. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper revisits the dense associative memory (DAM) networks and studies rigorously the capacity of the DAM networks. We present the capacity theorem of the DAM networks with an attraction radius or a noise level from the messages and prove that the probe can converge to the targeted message just after the one-step update. Under this convergence, the capacity of DAM networks is between a lower bound and an upper bound. Although when the attraction radius is 0.0 0.0 away from the messages, i.e. noiseless, previous literature provides an approximate result. However, a rigorous proof is not given in this study. In addition, we consider a more general notion of capacity which allows the retrieval of messages from noisy probes (the attraction radius is not 0.0 0.0 ). We demonstrates that the convergence result can be acquired just after the one-step update when the probe is a corrupted version with a Gaussian noise from one message. We further provide simulated experiments to validate theorems herein.},
  archive      = {J_NEUCOM},
  author       = {Han Bao and Richong Zhang and Yongyi Mao},
  doi          = {10.1016/j.neucom.2021.10.058},
  journal      = {Neurocomputing},
  pages        = {198-208},
  shortjournal = {Neurocomputing},
  title        = {The capacity of the dense associative memory networks},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive threshold mechanism for accurate and efficient
deep spiking convolutional neural networks. <em>NEUCOM</em>,
<em>469</em>, 189–197. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks(SNNs) can potentially offer an efficient way of performing inference because the neurons in the networks are sparsely activated and computations are event-driven. SNNs with higher accuracy can be obtained by converting deep convolutional neural networks(CNNs) into spiking CNNs. However, there is always a performance loss between CNN and its spiking equivalents, because approximation error occurs in the conversion from the continuous-valued CNNs to the sparsely firing, event-driven SNNs. In this paper, the differences between analog neurons and spiking neurons in neuron models and activities are analyzed, the impact of the balance between weight and threshold on the approximation error is clarified, and an adaptive threshold mechanism for improved balance between weight and threshold of SNNs is proposed. In this method, the threshold can be dynamically adjusted adapting to the input data, which makes it possible to obtain as small a threshold as possible while distinguishing inputs, so as to generate sufficient firing to drive higher layers and consequently can achieve better classification. The SNN with the adaptive threshold mechanism outperforms most of the recently proposed SNNs on CIFAR10 in terms of accuracy, accuracy loss and network latency , and achieved state-of-the-art results on CIFAR100.},
  archive      = {J_NEUCOM},
  author       = {Yunhua Chen and Yingchao Mai and Ren Feng and Jinsheng Xiao},
  doi          = {10.1016/j.neucom.2021.10.080},
  journal      = {Neurocomputing},
  pages        = {189-197},
  shortjournal = {Neurocomputing},
  title        = {An adaptive threshold mechanism for accurate and efficient deep spiking convolutional neural networks},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A neural network learning-based global optimization approach
for aero-engine transient control schedule. <em>NEUCOM</em>,
<em>469</em>, 180–188. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transient performance of aero-engine determines the maneuverability of aircraft. The optimal control schedule can tap the potential transient performance with subject to each constraint. Thus the transient time can be minimized with the optimal transient control schedule. This transient schedule is described by a strong constrained and nonlinear problem. It is therefore challenging to present an optimal method to achieve the best transient schedule. Motivated by solving this problem, a surrogate-assisted optimization framework is presented by using the learning capability of neural networks . It is achieved by presenting a sequential ensemble radial basis function (RBF) neural network-based optimization (SERO) algorithm. The advantage of the RBF neural network such as excellent prediction accuracy is taken and integrated into the surrogate-assisted optimization algorithm to improve the algorithm performance. With the application of the proposed scheme, the global optimization schedule is guaranteed for aero-engine transient control. Numerical validation is finally carried out by applying the presented optimization framework to a mixed-flow aero-engine transient control schedule. It is demonstrated that the SERO approach can minimize the transient process time despite any constraint at any time.},
  archive      = {J_NEUCOM},
  author       = {Xiaobo Zhang and Zhanxue Wang and Bing Xiao and Yifan Ye},
  doi          = {10.1016/j.neucom.2021.01.143},
  journal      = {Neurocomputing},
  pages        = {180-188},
  shortjournal = {Neurocomputing},
  title        = {A neural network learning-based global optimization approach for aero-engine transient control schedule},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Finite-time synchronization and h∞ synchronization of
coupled complex-valued memristive neural networks with and without
parameter uncertainty. <em>NEUCOM</em>, <em>469</em>, 163–179. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, finite-time synchronization and H ∞ H∞ synchronization of coupled complex-valued memristive neural networks (CCVMNNs) with or without parameter uncertainty are analyzed. First, a finite-time synchronization (FTS) condition is presented for CCVMNNs by means of deploying Lyapunov stability theory and developing suitable controllers. Then, we utilize the similar method to derive a criterion of robust finite-time synchronization (RFTS) for the proposed CCVMNNs with uncertain parameter. Furthermore, we establish some criteria for the sake of ensuring that the considered network can reach finite-time H ∞ H∞ synchronization and robust finite-time H ∞ H∞ synchronization. At last, two numerical examples with simulations demonstrate the validity of the acquired results.},
  archive      = {J_NEUCOM},
  author       = {Fang Wu and Yanli Huang},
  doi          = {10.1016/j.neucom.2021.10.067},
  journal      = {Neurocomputing},
  pages        = {163-179},
  shortjournal = {Neurocomputing},
  title        = {Finite-time synchronization and h∞ synchronization of coupled complex-valued memristive neural networks with and without parameter uncertainty},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic layer selection for transfer learning and
quantitative evaluation of layer effectiveness. <em>NEUCOM</em>,
<em>469</em>, 151–162. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of transfer learning in convolutional neural networks depends on the selection of which layer to update and fix. Because the number of layers is increasing, it is becoming increasingly difficult for humans to select layers. Therefore, in this study, we propose a method to automatically select effective update layers for transfer learning using a genetic algorithm. In our experiments, we conducted transfer learning from InceptionV3 pretrained with ImageNet to Canadian Institute for Advanced Research-100 dataset, The Street View House Numbers dataset and Food-101 dataset. We found that the test accuracy obtained by an ensemble of models selected by the genetic algorithm was greater than that obtained by from-scratch and fine-tuning for all target dataset. The distribution of the layers selected by the genetic algorithm as effective update layers was spread over the entire network. We also employed the optimal transport distance to evaluate whether each convolutional layer is an effective update layer for transfer learning. In our experiments, we compared the layer importance values and the accuracy of transfer learning. The layer importance was then correlated with the test accuracy of transfer learning, and the results demonstrate that the proposed method can quantitatively evaluate how well each network layer can detect general features in the target datasets.},
  archive      = {J_NEUCOM},
  author       = {Satsuki Nagae and Daigo Kanda and Shin Kawai and Hajime Nobuhara},
  doi          = {10.1016/j.neucom.2021.10.051},
  journal      = {Neurocomputing},
  pages        = {151-162},
  shortjournal = {Neurocomputing},
  title        = {Automatic layer selection for transfer learning and quantitative evaluation of layer effectiveness},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lag projective synchronization of nonidentical fractional
delayed memristive neural networks. <em>NEUCOM</em>, <em>469</em>,
138–150. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, lag projective synchronization of nonidentical fractional delayed memristive neural networks (NFDMNN) is investigated. Due to the existence of memristor , the analysis is based on the theory of differential equations with discontinuous right-hand side proposed by Filippov. A novel controller with fractional integral sliding-mode surface is devised firstly. Successively, some sufficient criteria ensuring lag projective synchronization of NFDMNN are obtained, depending on the fractional calculus inequalities and Lyapunov direct method. Moreover, the related results improve and enrich previous synchronization works. Lastly, the validity of conclusions is verified through a simulation example.},
  archive      = {J_NEUCOM},
  author       = {Zhixia Ding and Chong Chen and Shiping Wen and Sai Li and Liheng Wang},
  doi          = {10.1016/j.neucom.2021.10.061},
  journal      = {Neurocomputing},
  pages        = {138-150},
  shortjournal = {Neurocomputing},
  title        = {Lag projective synchronization of nonidentical fractional delayed memristive neural networks},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Tracking control via switching and learning for a class of
uncertain flexible joint robots with variable stiffness actuators.
<em>NEUCOM</em>, <em>469</em>, 130–137. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the tracking control of a class of uncertain flexible joint robots with variable stiffness actuators (VSAs). Remarkably, disturbances exist in both the link motor and the stiffness actuator but are regardless of or severely restricted in the related literature which result into the incapability of the existing control design schemes. For this, learning mechanism combined with switching method is introduced to compensate the serious uncertainties contained in the disturbances, and in turn to give a novel control design framework for the control problem under investigation. First, by using backstepping method and the disturbance learning mechanism, a state-feedback controller is explicitly constructed in which certain key controller parameters to be updated online are included. Then, a pivotal switching mechanism is designed to online tune the parameters in the controller. It is shown that the switching occurs only a finite number of times, and then the designed controller guarantees that all the states of the resulting closed-loop system are bounded while the system outputs asymptotically converge to the given reference signals, respectively. Finally, simulation is provided to validate the effectiveness of the proposed theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Jian Li and KaiFa Ma and ZhaoJing Wu},
  doi          = {10.1016/j.neucom.2021.01.140},
  journal      = {Neurocomputing},
  pages        = {130-137},
  shortjournal = {Neurocomputing},
  title        = {Tracking control via switching and learning for a class of uncertain flexible joint robots with variable stiffness actuators},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adapted transformer network for news recommendation.
<em>NEUCOM</em>, <em>469</em>, 119–129. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online news recommendation aims to provide personalized news for users according to their interests. Existing methods usually learn user preference from their historical reading records in a static and independent way, which ignore the dynamic interaction with the target candidate news. In fact, it is important to fully capture the semantic interaction between user?s historical news and candidate news since the user?s interests would be different in terms of different candidate news. In this paper, we propose a novel news recommendation model with an adapted transformer network. There are three parts in our approach, i.e., a news encoder to learn the semantic features of news, a user encoder to learn the initial representations of users, an adapted transformer module to learn the deep interaction between users and candidate news. The core is that we effectively integrate the historical clicked news and the candidate news into the transformer framework to capture their inherent relatedness. Besides, an additive attention layer is proposed to learn different informativeness of words since different words are differently useful for news or users? representation. We conduct extensive experiments on a real-world dataset from MSN news and the results indicates the effectiveness of our proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Jinsheng Huang and Zhuobing Han and Hongyan Xu and Hongtao Liu},
  doi          = {10.1016/j.neucom.2021.10.049},
  journal      = {Neurocomputing},
  pages        = {119-129},
  shortjournal = {Neurocomputing},
  title        = {Adapted transformer network for news recommendation},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Category boundary re-decision by component labels to
improve generation of class activation map. <em>NEUCOM</em>,
<em>469</em>, 105–118. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class Activation Maps (CAMs) visualize the pixels within an image that contribute to classify the image to a certain category, and can be used to localize the object regions from images that benefit to many tasks such as image segmentation and object detection. However, the object regions highlighted by the existing methods are usually small and local. We believe such drawback lies in the image-level labels, because the the image-level label prefers the network to capture the common regions intra-class and the discriminative region inter-class. Due to the variations of objects intra-class and the common region widely shared inter class, the regions based on image-level labels are usually small and local. Based on such observation, we propose a new strategy to use a set of lower-level labels called component labels to replace the image-level labels. The advantage is that the component regions have small feature variation intra-class and are non-overlapping inter-class, which leads to better CAMs generation through their simple combination. Furthermore, since the component labels are also shared by unknown classes, the proposed CAMs generation method can be easily extended to unknown classes, which facilitate the improvement of tasks related to new class processing, such as few-shot segmentation and detection. Specifically, the component labels are set based on the WordNet hierarchy firstly, which can also provides the relationships of classes. Besides, graph convolution networks (GCNs) are used as the classifiers, which can exactly describe not only the component, but also their structural relationships. Based on the component features, a feature fusion module is also designed to merge local component features into the global feature. Better CAM is finally obtained. The experiment section shows the effectiveness of our component labels in terms of better subjective and objective results compared with the existing CAM generation methods. Furthermore, we also show good generalization of our component label on unknown classes.},
  archive      = {J_NEUCOM},
  author       = {Runtong Zhang and Fanman Meng and Hongliang Li and Qingbo Wu and King Ngi Ngan},
  doi          = {10.1016/j.neucom.2021.10.072},
  journal      = {Neurocomputing},
  pages        = {105-118},
  shortjournal = {Neurocomputing},
  title        = {Category boundary re-decision by component labels to improve generation of class activation map},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Centralized and decentralized controller design for
synchronization of coupled delayed inertial neural networks via reduced
and non-reduced orders. <em>NEUCOM</em>, <em>469</em>, 91–104. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper synchronization of coupled inertial neural networks (INNs) with non-differentiable time varying delays is considered. The adaptive synchronization is analyzed with linearly coupled INNs through centralized and decentralized controller techniques. Initially the INNs is taken with reduced order and by using adaptive centralized and decentralized control, the synchronization criterion is obtained in terms of matrix inequalities. Furthermore without using the order reduction, INNs has to taken as it is and studied adaptive synchronization by constructing suitable Lyapunov functional. Finally, simulation results are presented to illustrate the obtained theoretical findings.},
  archive      = {J_NEUCOM},
  author       = {Shanmugasundaram S. and Ardak Kashkynbayev and Udhayakumar K. and Rakkiyappan R.},
  doi          = {10.1016/j.neucom.2021.10.053},
  journal      = {Neurocomputing},
  pages        = {91-104},
  shortjournal = {Neurocomputing},
  title        = {Centralized and decentralized controller design for synchronization of coupled delayed inertial neural networks via reduced and non-reduced orders},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). EvoGAN: An evolutionary computation assisted GAN.
<em>NEUCOM</em>, <em>469</em>, 81–90. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The image synthesis technique is relatively well established which can generate facial images that are indistinguishable even by human beings. However, all of these approaches uses gradients to condition the output, resulting in the outputting the same image with the same input. Also, they can only generate images with basic expression or mimic an expression instead of generating compound expression. In real life, however, human expressions are of great diversity and complexity. In this paper, we propose an evolutionary algorithm (EA) assisted GAN, named EvoGAN, to generate various compound expressions with any accurate target compound expression. EvoGAN uses an EA to search target results in the data distribution learned by GAN. Specifically, we use the Facial Action Coding System (FACS) as the encoding of an EA and use a pre-trained GAN to generate human facial images, and then use a pre-trained classifier to recognize the expression composition of the synthesized images as the fitness function to guide the search of the EA. Combined random searching algorithm, various images with the target expression can be easily sythesized. Quantitative and Qualitative results are presented on several compound expressions, and the experimental results demonstrate the feasibility and the potential of EvoGAN. The source code is available at https://github.com/ECNU-Cross-Innovation-Lab/EvoGAN .},
  archive      = {J_NEUCOM},
  author       = {Feng Liu and Hanyang Wang and Jiahao Zhang and Ziwang Fu and Aimin Zhou and Jiayin Qi and Zhibin Li},
  doi          = {10.1016/j.neucom.2021.10.060},
  journal      = {Neurocomputing},
  pages        = {81-90},
  shortjournal = {Neurocomputing},
  title        = {EvoGAN: An evolutionary computation assisted GAN},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiscale face recognition in cluttered backgrounds based
on visual attention. <em>NEUCOM</em>, <em>469</em>, 65–80. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human vision system can efficiently recognize multiscale objects in cluttered backgrounds. The scheme can be achieved with a visual attention mechanism by concentrating visual resources to the saliency area while ignoring other task-irrelevant areas. However, in the computer vision community, when recognizing multiscale faces in cluttered backgrounds, object detection modules are necessary to locate face regions and reduce the influence of complex backgrounds on the recognition model, which inevitably increases the computational complexity. Motivated by the human vision system, this study proposes the attention developmental network to recognize multiscale faces without using face detectors. A top-down attention mechanism is used to teach the network to focus on the face areas and ignore the backgrounds. An attention-based synapse maintenance mechanism is also introduced to further suppress the background pixels and improve the accuracy of face recognition. Comparative experiments show that our method can attain at least 13\% of accuracy improvement over bionic neural networks and ResNet-based recognition networks on the same model scale with less training epochs.},
  archive      = {J_NEUCOM},
  author       = {Peng Guo and Guoqing Du and Longsheng Wei and Huaiying Lu and Siwei Chen and Changxin Gao and Ying Chen and Jinsheng Li and Dapeng Luo},
  doi          = {10.1016/j.neucom.2021.10.071},
  journal      = {Neurocomputing},
  pages        = {65-80},
  shortjournal = {Neurocomputing},
  title        = {Multiscale face recognition in cluttered backgrounds based on visual attention},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conceptual complexity of neural networks. <em>NEUCOM</em>,
<em>469</em>, 52–64. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a complexity measure of a neural network mapping function based on the order and diversity of the set of tangent spaces from different inputs. Treating each tangent space as a linear PAC concept we use an entropy-based measure of the bundle of concepts to estimate the conceptual capacity of the network. The theoretical maximal capacity of a ReLU network is equivalent to the number of its neurons. In practice, however, due to correlations between neuron activities within the network, the actual capacity can be remarkably small, even for very big networks. We formulate a new measure of conceptual complexity by normalising the capacity of the network by the degree of separation of concepts related to different classes. Empirical evaluations show that this new measure is correlated with the generalisation capabilities of the corresponding network. It captures the effective, as opposed to the theoretical, complexity of the network function. We also showcase some uses of the proposed measures for analysis and comparison of trained neural network models.},
  archive      = {J_NEUCOM},
  author       = {Lech Szymanski and Brendan McCane and Craig Atkinson},
  doi          = {10.1016/j.neucom.2021.10.063},
  journal      = {Neurocomputing},
  pages        = {52-64},
  shortjournal = {Neurocomputing},
  title        = {Conceptual complexity of neural networks},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online continual learning in image classification: An
empirical survey. <em>NEUCOM</em>, <em>469</em>, 28–51. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online continual learning for image classification studies the problem of learning to classify images from an online stream of data and tasks, where tasks may include new classes (class incremental) or data nonstationarity (domain incremental). One of the key challenges of continual learning is to avoid catastrophic forgetting (CF), i.e., forgetting old tasks in the presence of more recent tasks. Over the past few years, a large range of methods and tricks have been introduced to address the continual learning problem, but many have not been fairly and systematically compared under a variety of realistic and practical settings. To better understand the relative advantages of various approaches and the settings where they work best, this survey aims to (1) compare state-of-the-art methods such as Maximally Interfered Retrieval (MIR), iCARL, and GDumb (a very strong baseline) and determine which works best at different memory and data settings as well as better understand the key source of CF; (2) determine if the best online class incremental methods are also competitive in the domain incremental setting; and (3) evaluate the performance of 7 simple but effective tricks such as the ”review” trick and the nearest class mean (NCM) classifier to assess their relative impact. Regarding (1), we observe that iCaRL remains competitive when the memory buffer is small; GDumb outperforms many recently proposed methods in medium-size datasets and MIR performs the best in larger-scale datasets. For (2), we note that GDumb performs quite poorly while MIR – already competitive for (1) – is also strongly competitive in this very different (but important) continual learning setting. Overall, this allows us to conclude that MIR is overall a strong and versatile online continual learning method across a wide variety of settings. Finally for (3), we find that all tricks are beneficial, and when augmented with the “review” trick and NCM classifier, MIR produces performance levels that bring online continual learning much closer to its ultimate goal of matching offline training. Our codes are available at https://github.com/RaptorMai/online-continual-learning.},
  archive      = {J_NEUCOM},
  author       = {Zheda Mai and Ruiwen Li and Jihwan Jeong and David Quispe and Hyunwoo Kim and Scott Sanner},
  doi          = {10.1016/j.neucom.2021.10.021},
  journal      = {Neurocomputing},
  pages        = {28-51},
  shortjournal = {Neurocomputing},
  title        = {Online continual learning in image classification: An empirical survey},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Domain adaptive twin support vector machine learning using
privileged information. <em>NEUCOM</em>, <em>469</em>, 13–27. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the fields of computer vision and machine learning , domain adaptation has been extensively studied and the main challenge in the case is how to transform the existing classifier(s) into an effective adaptive classifier to exploit the latent information in the new data source which typically has a different distribution compared with the original data source. Currently, the Adaptive Support Vector Machines (A-SVM) has been proposed to deal with the domain adaptation problem, which is an effective strategy. However, the resulting optimization task by minimizing a convex quadratic function in A-SVM can not effectively minimize the distance between a source and a target domain as much as possible and typically has high computational complexity . In order to handle these problems, in this paper, we extend the A-SVM by determining a pair of nonparallel up- and down-bound functions solved by two smaller sized quadratic programming problems (QPPs) to achieve a faster learning speed. Notably, our method yields two nonparallel separating hyperplanes to exploit the latent discriminant information based on SVM classification mechanism, which can naturally enhance the classification performance. This method is named as Adaptive Twin Support Vector Machine Learning (A-TSVM). Moreover, we consider a high-level learning paradigm with privilege information (LUPI) to learn a induced model that further constrains the solution in the target space. The learned model is named as domain Adaptive Twin Support Vector Machine Learning Using Privileged Information (A-TSVM+). Finally, a series of comparative experiments with many other methods are performed on three datasets. The experimental results effectively indicate that the proposed method can not only greatly improve the accuracy of classification, but also save computing time.},
  archive      = {J_NEUCOM},
  author       = {Yanmeng Li and Huaijiang Sun and Wenzhu Yan},
  doi          = {10.1016/j.neucom.2021.10.069},
  journal      = {Neurocomputing},
  pages        = {13-27},
  shortjournal = {Neurocomputing},
  title        = {Domain adaptive twin support vector machine learning using privileged information},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-organizing radial basis function neural network using
accelerated second-order learning algorithm. <em>NEUCOM</em>,
<em>469</em>, 1–12. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient-based algorithms are commonly used for training radial basis function neural network (RBFNN). However, it is still difficult to avoid vanishing gradient to improve the learning performance in the training process. For this reason, in this paper, an accelerated second-order learning (ASOL) algorithm is developed to train RBFNN. First, an adaptive expansion and pruning mechanism (AEPM) of gradient space, based on the integrity and orthogonality of hidden neurons, is designed. Then, the effective gradient information is constantly added to gradient space and the redundant gradient information is eliminated from gradient space. Second, with AEPM, the neurons are generated or pruned accordingly. In this way, a self-organizing RBFNN (SORBFNN) which reduces the structure complexity and improves the generalization ability is obtained. Then, the structure and parameters in the learning process can be optimized by the proposed ASOL-based SORBFNN (ASOL-SORBFNN). Third, some theoretical analyses including the efficiency of the proposed AEPM on avoiding the vanishing gradient and the stability of SORBFNN in the process of structural adjustment are given, then the successful application of the proposed ASOL-SORBFNN is guaranteed. Finally, to illustrate the advantages of the proposed ASOL-SORBFNN, several experimental studies are examined. By comparing with other existing approaches, the results show that ASOL-SORBFNN performs well in terms of both learning speed and prediction accuracy.},
  archive      = {J_NEUCOM},
  author       = {Hong-Gui Han ( Senior Member, IEEE ) and Miao-Li Ma and Hong-Yan Yang and Jun-Fei Qiao (Member, IEEE)},
  doi          = {10.1016/j.neucom.2021.10.065},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {Self-organizing radial basis function neural network using accelerated second-order learning algorithm},
  volume       = {469},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning based liver disease diagnosis: A systematic
review. <em>NEUCOM</em>, <em>468</em>, 492–509. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computer-based approach is required for the non-invasive detection of chronic liver diseases that are asymptomatic, progressive, and potentially fatal in nature. In this study, we review the computer-aided diagnosis of hepatic lesions in view of diffuse- and focal liver disorders. This survey mainly focuses on three image acquisition modalities: ultrasonography, computed tomography, and magnetic resonance imaging. We present the insightful analysis with pros and cons for each preliminary step, particularly preprocessing, attribute analysis, and classification techniques to accomplish clinical diagnostic tasks. In preprocessing, we explore and compare commonly used denoising, deblurring and segmentation methods. Denoising is mainly performed with nonlinear models. In contrast, deep neural networks are frequently applied for deblurring and automatic segmentation of region-of-interest. In attribute analysis, the most common approach comprises texture properties. For classification, the support vector machine is mainly utilized across three image acquisition modalities. However, comparative analysis shows the best performance is obtained by deep learning-based convolutional neural networks. Considering biopsy samples or pathological factors such as overall stage, margin, and differentiation can be helpful for improving the prediction performance. In addition, technique breakthrough is expected soon with advances in machine learning models to address data limitation problems and improve the prediction performance.},
  archive      = {J_NEUCOM},
  author       = {Rayyan Azam Khan and Yigang Luo and Fang-Xiang Wu},
  doi          = {10.1016/j.neucom.2021.08.138},
  journal      = {Neurocomputing},
  pages        = {492-509},
  shortjournal = {Neurocomputing},
  title        = {Machine learning based liver disease diagnosis: A systematic review},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Region NMS-based deep network for gigapixel level
pedestrian detection with two-step cropping. <em>NEUCOM</em>,
<em>468</em>, 482–491. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian detection has emerged as a fundamental technology for autonomous cars, robotics, pedestrian search, and other applications. Although a lot of progress has been made in pedestrian detection, it is still a challenging problem in wide field-of-view surveillance videos due to the random distribution and dynamic characteristics of pedestrians. Especially in large-scale high-resolution images, there are many pedestrians and vast scale variance, so it is difficult to accurately detect all pedestrians. In order to solve this problem, sliding window is used to crop all original images to obtain pre-detection results firstly in this paper. Then, the original images are cropped again with the object as the center utilizing the label files shared in the same scene to get multi-scale images. Finally, a region NMS algorithm, a fusion strategy about the results of small images mapped into large images, is proposed to remove the redundant shredded boxes caused by cropping image. We verify the effectiveness of the proposed method with Faster R-CNN, Cascade R-CNN, IterDet and Scale-aware Fast R-CNN models on PANDA dataset.},
  archive      = {J_NEUCOM},
  author       = {Lingling Li and Xiaohui Guo and Yan Wang and Jingjing Ma and Licheng Jiao and Fang Liu and Xu Liu},
  doi          = {10.1016/j.neucom.2021.10.006},
  journal      = {Neurocomputing},
  pages        = {482-491},
  shortjournal = {Neurocomputing},
  title        = {Region NMS-based deep network for gigapixel level pedestrian detection with two-step cropping},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Multi-perspective social recommendation method with graph
representation learning. <em>NEUCOM</em>, <em>468</em>, 469–481. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommender systems (SRS) aim to study how social relations influence users’ choices and how to use them for better learning users embeddings. However, the diversity of social relationships, which is instructive to the propagation of social influence, has been rarely explored. In this paper, we propose a graph convolutional network based representation learning method, namely multi-perspective social recommendation (MPSR), to construct hierarchical user preferences and assign friends’ influences with different levels of trust from varying perspectives. We further utilize the attributes of items to partition and excavate users’ explicit preferences and employ complementary perspective modeling to learn implicit preferences of users. To measure the trust degree of friends from different perspectives, the statistical information of users’ historical behavior is utilized to construct multi-perspective social networks. Experimental results on two public datasets of Yelp and Ciao demonstrate that the MPSR significantly outperforms the state-of-the-art methods. Further detailed analysis verifies the importance of mining explicit characteristics of users and the necessity for diverse social relationships, which show the rationality and effectiveness of the proposed model. The source Python code will be available upon request.},
  archive      = {J_NEUCOM},
  author       = {Hai Liu and Chao Zheng and Duantengchuan Li and Zhaoli Zhang and Ke Lin and Xiaoxuan Shen and Neal N. Xiong and Jiazhang Wang},
  doi          = {10.1016/j.neucom.2021.10.050},
  journal      = {Neurocomputing},
  pages        = {469-481},
  shortjournal = {Neurocomputing},
  title        = {Multi-perspective social recommendation method with graph representation learning},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TensorClus: A python library for tensor (co)-clustering.
<em>NEUCOM</em>, <em>468</em>, 464–468. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor data analysis is the evolutionary step of data analysis to more than two dimensions. Dealing with tensor data is often based on tensor decomposition methods . The present paper focuses on unsupervised learning and provides a python package referred to as TensorClus including novel co-clustering algorithms of three-way data. All proposed algorithms are based on the latent block models and suitable to different types of data, sparse or not. They are successfully evaluated on challenges in text mining, recommender systems , and hyperspectral image clustering. TensorClus is an open-source Python package that allows easy interaction with other python packages such as NumPy and TensorFlow; it also offers an interface with some tensor decomposition packages namely Tensorly and TensorD on the one hand, and on the other, the co-clustering package Coclust . Finally, it provides CPU and GPU compatibility. The TensorClus library is available at https://pypi.org/project/TensorClus/ .},
  archive      = {J_NEUCOM},
  author       = {Rafika Boutalbi and Lazhar Labiod and Mohamed Nadif},
  doi          = {10.1016/j.neucom.2021.09.036},
  journal      = {Neurocomputing},
  pages        = {464-468},
  shortjournal = {Neurocomputing},
  title        = {TensorClus: A python library for tensor (Co)-clustering},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Event-triggered constrained control using explainable global
dual heuristic programming for nonlinear discrete-time systems.
<em>NEUCOM</em>, <em>468</em>, 452–463. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops an event-triggered optimal control method that can deal with asymmetric input constraints for nonlinear discrete-time systems. The implementation is based on an explainable global dual heuristic programming (XGDHP) technique. Different from traditional GDHP, the required derivatives of cost function in the proposed method are computed by explicit analytical calculations, which makes XGDHP more explainable. Besides, the challenge caused by the input constraints is overcome by the combination of a piece-wise utility function and a bounding layer of the actor network. Furthermore, an event-triggered mechanism is introduced to decrease the amount of computation, and the stability analysis is provided with fewer assumptions compared to most existing studies that investigate event-triggered discrete-time control using adaptive dynamic programming. Two simulation studies are carried out to demonstrate the applicability of the constructed approach. The results present that the developed event-triggered XGDHP algorithm can substantially save the computational load, while maintain comparable performance with the time-based approach.},
  archive      = {J_NEUCOM},
  author       = {Bo Sun and Erik-Jan van Kampen},
  doi          = {10.1016/j.neucom.2021.10.046},
  journal      = {Neurocomputing},
  pages        = {452-463},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered constrained control using explainable global dual heuristic programming for nonlinear discrete-time systems},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal control of markovian jump systems via a neural
network-based ADP iterative algorithm. <em>NEUCOM</em>, <em>468</em>,
441–451. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive dynamic programming (ADP) technique is adopted in this work to investigate the optimal control problem of Markovian jump systems. By utilizing Bellman’s optimality principle, a discrete Hamilton Jacobi Bellman (HJB) equation is established to design the optimal controller for the system under consideration. Then, based on value iteration, a new ADP algorithm is proposed for finding the solution of the established HJB equation. It is proven that the iterative solution sequence generated by the developed ADP iterative approach under zero initial values is monotonically convergent. Neural networks are constructed to accomplish the presented value iteration ADP algorithm . At last, simulation researches for two Markovian jump systems demonstrate the effectiveness of the proposed optimal control method .},
  archive      = {J_NEUCOM},
  author       = {Hui-Jie Sun and Jinxiu Zhang and Hamid Reza Karimi},
  doi          = {10.1016/j.neucom.2021.09.059},
  journal      = {Neurocomputing},
  pages        = {441-451},
  shortjournal = {Neurocomputing},
  title        = {Optimal control of markovian jump systems via a neural network-based ADP iterative algorithm},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A payoff-based learning approach for nash equilibrium
seeking in continuous potential games. <em>NEUCOM</em>, <em>468</em>,
431–440. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the Nash equilibrium seeking problem in continuous potential games in a situation that the payoff functions and actions of players are blind to each other due to privacy security or communication limitation. To this end, a payoff-based learning dynamics is proposed with the limitation that only available information for each agent is its own past actions and several observed payoffs. In detail, we formulate a trial-and-error learning protocol to search for proper moving direction and length for action adjustment of each agent, and prove that following the proposed learning dynamics, the action profile of agents will be guaranteed to converge to a Nash equilibrium of the continuous potential game. For illustration of the theoretical development, the proposed payoff-based learning dynamics is further utilized to design an absolute distance-based consensus protocol for multi-agent systems. It is shown that agents can eventually reach a consensus point even when they do not know the relative positions with other agents.},
  archive      = {J_NEUCOM},
  author       = {Shaolin Tan and Yaonan Wang},
  doi          = {10.1016/j.neucom.2021.10.033},
  journal      = {Neurocomputing},
  pages        = {431-440},
  shortjournal = {Neurocomputing},
  title        = {A payoff-based learning approach for nash equilibrium seeking in continuous potential games},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Theoretical guarantees for bridging metric measure embedding
and optimal transport. <em>NEUCOM</em>, <em>468</em>, 416–430. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel approach for comparing distributions whose supports do not necessarily lie on the same metric space. Unlike Gromov-Wasserstein (GW) distance which compares pairwise distances of elements from each distribution, we consider a method allowing to embed the metric measure spaces in a common Euclidean space and compute an optimal transport (OT) on the embedded distributions. This leads to what we call a sub-embedding robust Wasserstein (SERW) distance. Under some conditions, SERW is a distance that considers an OT distance of the (low-distorted) embedded distributions using a common metric. In addition to this novel proposal that generalizes several recent OT works, our contributions stand on several theoretical analyses: (i) we characterize the embedding spaces to define SERW distance for distribution alignment; (ii) we prove that SERW mimics almost the same properties of GW distance, and we give a cost relation between GW and SERW. The paper also provides some numerical illustrations of how SERW behaves on matching problems.},
  archive      = {J_NEUCOM},
  author       = {Mokhtar Z. Alaya and Maxime Bérar and Gilles Gasso and Alain Rakotomamonjy},
  doi          = {10.1016/j.neucom.2021.09.075},
  journal      = {Neurocomputing},
  pages        = {416-430},
  shortjournal = {Neurocomputing},
  title        = {Theoretical guarantees for bridging metric measure embedding and optimal transport},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved consensus algorithm for MAS with directed
topology and binary-valued communication. <em>NEUCOM</em>, <em>468</em>,
407–415. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the consensus of a multiagent system (MAS) under binary-valued communication with directed topology. An improved two-time-scale algorithm that alternates between control and estimation is proposed. Compared with the existing two-time-scale algorithm for the undirected topology case, we relax the conditions on the algorithm parameters, thereby providing more choices for practical implementations. The asymptotic property of the algorithm is analyzed by analyzing the convergence of the explicit closed-loop solution. To reduce the effect of binary communication on the consensus value for a single-sample path, the selection method for obtaining suitable parameters is given. To demonstrate their effectiveness, the selection method and algorithm are applied to the reputation management of a public welfare platform.},
  archive      = {J_NEUCOM},
  author       = {Yueming Guo and Huaibin Tang},
  doi          = {10.1016/j.neucom.2021.10.057},
  journal      = {Neurocomputing},
  pages        = {407-415},
  shortjournal = {Neurocomputing},
  title        = {An improved consensus algorithm for MAS with directed topology and binary-valued communication},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diversity-augmented intrinsic motivation for deep
reinforcement learning. <em>NEUCOM</em>, <em>468</em>, 396–406. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world problems, reward signals received by agents are delayed or sparse, which makes it challenging to train a reinforcement learning (RL) agent. An intrinsic reward signal can help an agent to explore such environments in the quest for novel states. In this work, we propose a general end-to-end diversity-augmented intrinsic motivation for deep reinforcement learning which encourages the agent to explore new states and automatically provides denser rewards. Specifically, we measure the diversity of adjacent states under a model of state sequences based on determinantal point process (DPP); this is coupled with a straight-through gradient estimator to enable end-to-end differentiability. The proposed approach is comprehensively evaluated on the MuJoCo and the Arcade Learning Environments (Atari and SuperMarioBros). The experiments show that an intrinsic reward based on the diversity measure derived from the DPP model accelerates the early stages of training in Atari games and SuperMarioBros. In MuJoCo, the approach improves on prior techniques for tasks using the standard reward setting, and achieves the state-of-the-art performance on 12 out of 15 tasks containing delayed rewards.},
  archive      = {J_NEUCOM},
  author       = {Tianhong Dai and Yali Du and Meng Fang and Anil Anthony Bharath},
  doi          = {10.1016/j.neucom.2021.10.040},
  journal      = {Neurocomputing},
  pages        = {396-406},
  shortjournal = {Neurocomputing},
  title        = {Diversity-augmented intrinsic motivation for deep reinforcement learning},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PSNet: Perspective-sensitive convolutional network for
object detection. <em>NEUCOM</em>, <em>468</em>, 384–395. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view object detection is challenging due to the influence of the different view-angles on intra-class similarity. The uniformed feature representation of traditional detectors couples the object’s perspective attribute and semantic feature , and the variances of perspective will cause intra-class differences. In this paper, a robust perspective-sensitive network (PSNet) is proposed to overcome the above problem. The uniformed feature is replaced by the perspective-specific structural feature, which makes the network perspective sensitive. Its essence is to learn multiple perspective spaces. In each perspective space, the semantic feature is decoupled from the perspective attribute and is robust to perspective variances. Perspective-sensitive RoI pooling and loss function are proposed for perspective-sensitive learning. Experiments on Pascal3D + and SpaceNet MOVI show the effectiveness and superiority of the PSNet.},
  archive      = {J_NEUCOM},
  author       = {Xin Zhang and Yicheng Liu and Chunlei Huo and Nuo Xu and Lingfeng Wang and Chunhong Pan},
  doi          = {10.1016/j.neucom.2021.10.068},
  journal      = {Neurocomputing},
  pages        = {384-395},
  shortjournal = {Neurocomputing},
  title        = {PSNet: Perspective-sensitive convolutional network for object detection},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiple agents’ spatiotemporal data generation based on
recurrent regression dual discriminator GAN. <em>NEUCOM</em>,
<em>468</em>, 370–383. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) have proven their capability of generating realistic-looking data and have been widely used in image related and time-series applications. However, generation of multiple agents’ spatiotemporal data remains an unexplored region. In this work, we propose a recurrent regression dual discriminator GAN named R2D2GAN. A novel generator is designed to learn mappings from prior stochastic process to multiple agents’ spatiotemporal data, which is conditioned on spatial configuration of multiple agents only. A classification discriminator and a regression discriminator are proposed to represent different features of spatiotemporal data. The classification discriminator learns to represent spatial and sequential features of each agent. The regression discriminator learns to represent inherent sequential dependency for target agent. To stabilize training of GAN, a min–max game is elaborately designed and new training losses are proposed for dual discriminators and the generator. To validate learning ability of R2D2GAN, we embed it in vehicle trajectory prediction application. Through qualitative and quantitative evaluation, we show that the R2D2GAN is capable of generating realistic-looking multiple agents’ spatiotemporal data with acceptable performance degradation in prediction task.},
  archive      = {J_NEUCOM},
  author       = {Peng Bao and Zonghai Chen and Jikai Wang and Deyun Dai},
  doi          = {10.1016/j.neucom.2021.10.048},
  journal      = {Neurocomputing},
  pages        = {370-383},
  shortjournal = {Neurocomputing},
  title        = {Multiple agents’ spatiotemporal data generation based on recurrent regression dual discriminator GAN},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical multimodal transformer to summarize videos.
<em>NEUCOM</em>, <em>468</em>, 360–369. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although video summarization has achieved tremendous success benefiting from Recurrent Neural Networks (RNN), RNN-based methods neglect the global dependencies and multi-hop relationships among video frames, which limits the performance. Transformer is an effective model to deal with this problem, and surpasses RNN-based methods in several sequence modeling tasks, such as machine translation, video captioning, etc . Motivated by the great success of transformer and the natural structure of video (frame-shot-video), a hierarchical transformer is developed for video summarization, which can capture the dependencies among frame and shots, and summarize the video by exploiting the scene information formed by shots. Furthermore, we argue that both the audio and visual information are essential for the video summarization task. To integrate the two kinds of information, they are encoded in a two-stream scheme, and a multimodal fusion mechanism is developed based on the hierarchical transformer. In this paper, the proposed method is denoted as Hierarchical Multimodal Transformer (HMT). Practically, extensive experiments show that HMT achieves (F-measure: 0.441, Kendall’s τ τ : 0.079, Spearman’s ρ ρ : 0.080) and (F-measure: 0.601, Kendall’s τ τ : 0.096, Spearman’s ρ ρ : 0.107) on SumMe and TVsum, respectively. It surpasses most of the traditional, RNN-based and attention-based video summarization methods.},
  archive      = {J_NEUCOM},
  author       = {Bin Zhao and Maoguo Gong and Xuelong Li},
  doi          = {10.1016/j.neucom.2021.10.039},
  journal      = {Neurocomputing},
  pages        = {360-369},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical multimodal transformer to summarize videos},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A graph convolutional topic model for short and noisy text
streams. <em>NEUCOM</em>, <em>468</em>, 345–359. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning hidden topics from data streams has become absolutely necessary but posed challenging problems such as concept drift as well as short and noisy data. Using prior knowledge to enrich a topic model is one of potential solutions to cope with these challenges. Prior knowledge that is derived from human knowledge (e.g. Wordnet) or a pre-trained model (e.g. Word2vec) is very valuable and useful to help topic models work better. However, in a streaming environment where data arrives continually and infinitely, existing studies are limited to exploiting these resources effectively. Especially, a knowledge graph, that contains meaningful word relations, is ignored. In this paper, to aim at exploiting a knowledge graph effectively, we propose a novel graph convolutional topic model (GCTM) which integrates graph convolutional networks (GCN) into a topic model and a learning method which learns the networks and the topic model simultaneously for data streams. In each minibatch, our method not only can exploit an external knowledge graph but also can balance the external and old knowledge to perform well on new data. We conduct extensive experiments to evaluate our method with both a human knowledge graph (Wordnet) and a graph built from pre-trained word embeddings (Word2vec). The experimental results show that our method achieves significantly better performances than state-of-the-art baselines in terms of probabilistic predictive measure and topic coherence. In particular, our method can work well when dealing with short texts as well as concept drift.},
  archive      = {J_NEUCOM},
  author       = {Ngo Van Linh and Tran Xuan Bach and Khoat Than},
  doi          = {10.1016/j.neucom.2021.10.047},
  journal      = {Neurocomputing},
  pages        = {345-359},
  shortjournal = {Neurocomputing},
  title        = {A graph convolutional topic model for short and noisy text streams},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Time series predicting of COVID-19 based on deep learning.
<em>NEUCOM</em>, <em>468</em>, 335–344. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 was declared a global pandemic by the World Health Organisation (WHO) on 11th March 2020. Many researchers have, in the past, attempted to predict a COVID outbreak and its effect. Some have regarded time-series variables as primary factors which can affect the onset of infectious diseases like influenza and severe acute respiratory syndrome (SARS). In this study, we have used public datasets provided by the European Centre for Disease Prevention and Control for developing a prediction model for the spread of the COVID-19 outbreak to and throughout Malaysia, Morocco and Saudi Arabia. We have made use of certain effective deep learning (DL) models for this purpose. We assessed some specific major features for predicting the trend of the existing COVID-19 outbreak in these three countries. In this study, we also proposed a DL approach that includes recurrent neural network (RNN) and long short-term memory (LSTM) networks for predicting the probable numbers of COVID-19 cases. The LSTM models showed a 98.58\% precision accuracy while the RNN models showed a 93.45\% precision accuracy. Also, this study compared the number of coronavirus cases and the number of resulting deaths in Malaysia, Morocco and Saudi Arabia. Thereafter, we predicted the number of confirmed COVID-19 cases and deaths for a subsequent seven days. In this study, we presented their predictions using the data that was available up to December 3rd, 2020.},
  archive      = {J_NEUCOM},
  author       = {Madini O. Alassafi and Mutasem Jarrah and Reem Alotaibi},
  doi          = {10.1016/j.neucom.2021.10.035},
  journal      = {Neurocomputing},
  pages        = {335-344},
  shortjournal = {Neurocomputing},
  title        = {Time series predicting of COVID-19 based on deep learning},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TableDet: An end-to-end deep learning approach for table
detection and table image classification in data sheet images.
<em>NEUCOM</em>, <em>468</em>, 317–334. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global supply chains are kept viable through the information shared through billions of electronic documents, many of which extensively use tables to display critical information. Making effective supply chain decisions requires the extraction of data from these tables which is hindered by the variations in layouts and styles of tables. In this paper, we propose Table Det: a deep learning based methodology to solve table detection and table image classification in data sheet images in a single inference as the first stage of the table text extraction pipeline. TableDet utilizes Cascade R-CNN with Complete IOU (CIOU) loss and a deformable convolution backbone as its underlying architecture to capture the variations in scales and orientations of tables. It also detects text and figures to enhance its table detection performance. We demonstrate the effectiveness of training TableDet with a dual-step transfer learning process and fine-tuning it with Table Aware Cutout (TAC) augmentation strategy. We achieved the highest F1 score for table detection against state-of-the-art solutions on ICDAR 2013 (complete set), ICDAR 2017 (test set) and ICDAR 2019 (test set) with 100\%, 99.3\% and 95.1\% respectively. For the table image classification task we attained 100\% recall and above 85\% precision on three test sets. This classification capability ensures that all images with tables would be promoted to the next step in the table text extraction pipeline, with a small number of images without tables making it through.},
  archive      = {J_NEUCOM},
  author       = {Johan Fernandes and Murat Simsek and Burak Kantarci and Shahzad Khan},
  doi          = {10.1016/j.neucom.2021.10.023},
  journal      = {Neurocomputing},
  pages        = {317-334},
  shortjournal = {Neurocomputing},
  title        = {TableDet: An end-to-end deep learning approach for table detection and table image classification in data sheet images},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel deep neural network-based emotion analysis system
for automatic detection of mild cognitive impairment in the elderly.
<em>NEUCOM</em>, <em>468</em>, 306–316. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant number of people are suffering from cognitive impairment all over the world. Early detection of cognitive impairment is of great importance to both patients and caregivers. However, existing approaches have their shortages, such as time consumption and financial expenses involved in clinics and the neuroimaging stage. It has been found that patients with cognitive impairment show abnormal emotion patterns. In this paper, we present a novel deep neural network-based system to detect the cognitive impairment through the analysis of the evolution of facial emotions while participants are watching designed video stimuli. In our proposed system, a novel facial expression recognition algorithm is developed using layers from MobileNet and Support Vector Machine (SVM), which showed satisfactory performance in 3 datasets. To verify the proposed system in detecting cognitive impairment, 61 elderly people including patients with cognitive impairment and healthy people as a control group have been invited to participate in the experiments and a dataset was built accordingly. With this dataset, the proposed system has successfully achieved the detection accuracy of 73.3\%.},
  archive      = {J_NEUCOM},
  author       = {Zixiang Fei and Erfu Yang and Leijian Yu and Xia Li and Huiyu Zhou and Wenju Zhou},
  doi          = {10.1016/j.neucom.2021.10.038},
  journal      = {Neurocomputing},
  pages        = {306-316},
  shortjournal = {Neurocomputing},
  title        = {A novel deep neural network-based emotion analysis system for automatic detection of mild cognitive impairment in the elderly},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive tracking control for an unmanned autonomous
helicopter using neural network and disturbance observer.
<em>NEUCOM</em>, <em>468</em>, 296–305. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive tracking control scheme is investigated for a medium scale unmanned autonomous helicopter (UAH) with unknown external disturbances and system uncertainties to achieve improvement on the flight performance. The neural networks (NNs) are employed to compensate the system uncertainties. The second-order disturbance observers are introduced to restrain the compound disturbances which are combined with the NN approximation errors and the external disturbances. Accordingly, the tracking control law is designed for the UAH. The closed-loop stability of the whole UAH system is proved by using Lyapunov function method. Simulation results show that the developed control scheme can effectively solve the tracking control problems of UAH and certainly accomplish strong robustness with respect to the external disturbances and system uncertainties.},
  archive      = {J_NEUCOM},
  author       = {Min Wan and Mou Chen and Kenan Yong},
  doi          = {10.1016/j.neucom.2021.09.060},
  journal      = {Neurocomputing},
  pages        = {296-305},
  shortjournal = {Neurocomputing},
  title        = {Adaptive tracking control for an unmanned autonomous helicopter using neural network and disturbance observer},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A CNN-based policy for optimizing continuous action control
by learning state sequences. <em>NEUCOM</em>, <em>468</em>, 286–295. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous action control is widespread in real-world applications. It controls an agent to take action in continuous space for transiting from one state to another until achieving the desired goal. The optimization of continuous action control is an important issue, which aims to find the optimal policy for the agent to achieve the desired goal with the lowest consumption in continuous action space. A useful tool for this issue is reinforcement learning where an optimal policy is learned for the agent by maximizing the cumulative reward of the state transitions. When updating the policy at each state, most existing reinforcement learning methods consider only the one-step transition of this state. However, for each state in continuous action control, the recognizable information is usually hidden in the sequence of its previous states, thus these methods cannot learn the policy effectively enough for continuous action control. In this paper, we propose a new policy, called convolutional deterministic policy, to solve this problem. Enlightened from the convolutional neural networks used in natural language processing , our convolutional deterministic policy uses convolutional neural networks to learn the recognizable information in the state sequences. Then for each collected state, we update the convolutional deterministic policy by not only the recognizable information in the one-step transition of this state but also the recognizable information in the sequence of its previous states. As a result, our convolutional deterministic policy can make the agent take better action. Based on an effective reinforcement learning method, TD3, the implementation of our convolutional deterministic policy is in CTD3. The theoretical analysis and the experiment illustrate that our CTD3 can learn the policy not only better than but also faster than the existing RL methods for continuous action control. The source code can be downloaded from https://github.com/grcai .},
  archive      = {J_NEUCOM},
  author       = {Tianyi Huang and Min Li and Xiaolong Qin and William Zhu},
  doi          = {10.1016/j.neucom.2021.10.004},
  journal      = {Neurocomputing},
  pages        = {286-295},
  shortjournal = {Neurocomputing},
  title        = {A CNN-based policy for optimizing continuous action control by learning state sequences},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneous graph embedding by aggregating meta-path and
meta-structure through attention mechanism. <em>NEUCOM</em>,
<em>468</em>, 276–285. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous information networks embedding, which is a promising technique to learn low-dimensional representations for nodes with different types, has obtained very high interests recently. Plenty of graph neural networks models have been proposed for heterogeneous graph embedding. However, there are two limitations in existing models: (1) despite the complex structures of heterogeneous nodes, almost all these models are mainly based on meta-paths; (2) the different importance of different structures are neglected in most models. To address these problems, we propose a meta-path and meta-structure integrated heterogeneous graph neural network through attention mechanisms (PSHGAN). PSHGAN first maps features of heterogeneous nodes into the same space. Then, PSHGAN learns the weights of two nodes at each end of the meta-path or meta-structure by a local attention mechanism. Finally, PSHGAN learns weights of meta-paths and meta-structures by a global attention mechanism and aggregates the nodes representations. Extensive experiments are conducted on real-world benchmark datasets and show that our proposed model outperforms the state-of-the-art models in the node classification and link prediction tasks. Moreover, we make comprehensive analysis on the impacts of meta-structures on the performance of classification training with meta-paths.},
  archive      = {J_NEUCOM},
  author       = {Guangxu Mei and Li Pan and Shijun Liu},
  doi          = {10.1016/j.neucom.2021.10.001},
  journal      = {Neurocomputing},
  pages        = {276-285},
  shortjournal = {Neurocomputing},
  title        = {Heterogeneous graph embedding by aggregating meta-path and meta-structure through attention mechanism},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Networked-prediction-based group output consensus and
stability with reference input and communication constraints.
<em>NEUCOM</em>, <em>468</em>, 265–275. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of stability and group output consensus is investigated for the discrete-time heterogeneous networked multi-agent systems with communication constraints(e.g., time delays and data loss) in this paper. Firstly, the couple-group output consensus is analyzed theoretically, the communication constraints are compensated by the prediction method. Secondly, the necessary and sufficient condition is given to ensure the stability of the system, achieve the couple-group consensus with reference input control, and relax the topology constraint of in-degrees balance by cooperative-competitive interactions. Furthermore, the result of couple-group consensus is extended to multi-group consensus based on a novel predictive control algorithm. Finally, a numerical simulation shows that the proposed networked predictive control method can effectively overcome the communication constraints, the dynamic performance and control effect are similar to the traditional control without communication constraints.},
  archive      = {J_NEUCOM},
  author       = {Chong Tan and Jingxian Wu and Yanjiang Li},
  doi          = {10.1016/j.neucom.2021.10.020},
  journal      = {Neurocomputing},
  pages        = {265-275},
  shortjournal = {Neurocomputing},
  title        = {Networked-prediction-based group output consensus and stability with reference input and communication constraints},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view spectral clustering with adaptive graph learning
and tensor schatten p-norm. <em>NEUCOM</em>, <em>468</em>, 257–264. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the promising clustering performance, existing graph-based multi-view clustering methods still have the following deficiencies. (1) They cannot well exploit the salient difference between graphs of different views, resulting in suboptimal graphs. (2) They minimize the divergence between graphs of different views by one-dimensional, element by element metric model. Thus, they cannot well exploit the complementary information embedded in graphs. (3) They fail to simultaneously take local and global intrinsic geometric structures into account, resulting in suboptimal clustering performance. To handle the aforementioned problems, we propose Multi-view Spectral Clustering with Adaptive Graph Learning and Tensor Schatten p p -norm. Specifically, we present an adaptive weighted strategy that directly takes into account the contribution among different views for clustering. To well learn a good graph, which well characterizes cluster structure, we integrate local and global structure learning into a unified framework and leverage tensor Schatten p p -norm regularizer to minimize the divergence between graphs of different views. Extensive experiments on benchmark datasets have demonstrated the superiority of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yujiao Zhao and Yu Yun and Xiangdong Zhang and Qin Li and Quanxue Gao},
  doi          = {10.1016/j.neucom.2021.09.052},
  journal      = {Neurocomputing},
  pages        = {257-264},
  shortjournal = {Neurocomputing},
  title        = {Multi-view spectral clustering with adaptive graph learning and tensor schatten p-norm},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Temporal consistency two-stream CNN for human motion
prediction. <em>NEUCOM</em>, <em>468</em>, 245–256. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fusion is critical for a two-stream network. In this paper, we propose a novel temporal fusion (TF) module to fuse the two-stream joints’ information to predict human motion , including a temporal concatenation and a reinforcement trajectory spatial-temporal (TST) block that specifically designed to keep prediction temporal consistency. In particular, the temporal concatenation keeps the temporal consistency of preliminary predictions from two streams. Meanwhile, the TST block improves the spatial-temporal feature coupling. However, the TF module can increase the temporal continuities between the first predicted pose and the given poses and between each predicted pose. The fusion is based on a two-stream network that consists of a dynamic velocity stream (V-Stream) and a static position stream (P-Stream) because we found that the joints’ velocity information improves our short-term prediction, while the joints’ position information is better at long-term prediction, and they are complementary in motion prediction. Finally, our approach achieves impressive results on three benchmark datasets, including H3.6M, CMU-Mocap, and 3DPW in both short-term and long-term predictions, confirming its effectiveness and efficiency.},
  archive      = {J_NEUCOM},
  author       = {Jin Tang and Jin Zhang and Jianqin Yin},
  doi          = {10.1016/j.neucom.2021.10.011},
  journal      = {Neurocomputing},
  pages        = {245-256},
  shortjournal = {Neurocomputing},
  title        = {Temporal consistency two-stream CNN for human motion prediction},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ECANet: Explicit cyclic attention-based network for video
saliency prediction. <em>NEUCOM</em>, <em>468</em>, 233–244. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video saliency prediction has received increasing attention in the field of computer vision research. How to model the spatio-temporal information in video frames is a key issue for saliency prediction. Most of the existing methods either show a limited temporal memory ability or fail in jointly processing spatial and temporal information. Besides, these methods take each pixel of video frames as input indiscriminately, which may result in incorrect results because of redundant pixels. To solve the above problems, we propose a novel Explicit Cyclic Attention-based Network (ECANet), which is a two-stream encoder-decoder model. Specifically, an explicit cyclic attention mechanism is proposed for temporal modeling and pixel emphasizing, in which an attentional stream is built, whose input is cropped patches based on the model’s previous prediction. For spatio-temporal information aggregation, 3D convolutional neural network is adopted as the backbone of our encoders and decoder. Stacks of video frames and attentional patches from past steps build up the input of our model. Extensive experimental results over three benchmark datasets show that our model achieves competitive performance against state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Hao Xue and Minghui Sun and Yanhua Liang},
  doi          = {10.1016/j.neucom.2021.10.024},
  journal      = {Neurocomputing},
  pages        = {233-244},
  shortjournal = {Neurocomputing},
  title        = {ECANet: Explicit cyclic attention-based network for video saliency prediction},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). DSGNN: A dynamic and static intentions integrated graph
neural network for session-based recommendation. <em>NEUCOM</em>,
<em>468</em>, 222–232. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation, which aims to predict subsequent user actions based on anonymous sessions, plays a significant role in many online services. Existing methods construct each session as a digraph and then capture the rich transition relationship of items by using graph neural networks . However, their ability to obtain the user’s static intentions is insufficient and they suffer from improper combinations of different user intentions. In this study, we propose a dynamic and static intentions integrated graph neural network (DSGNN) for session-based recommendation, in which the user’s intentions captured by a digraph and an undigraph are comprehensively considered to enhance the recommendation performance. The prediction results from the dynamic and static intentions are combined using a lightweight gating network, which reduces the conflict between the two kinds of information. Furthermore, the weighted inner product is designed to alleviate the impact of the value of the item representation vectors. Extensive experiments on three real-world datasets show that the DSGNN outperforms other state-of-the-art methods and demonstrates that the components in our model are effective.},
  archive      = {J_NEUCOM},
  author       = {Chunkai Zhang and Quan Liu and Zeyu Zhang},
  doi          = {10.1016/j.neucom.2021.10.028},
  journal      = {Neurocomputing},
  pages        = {222-232},
  shortjournal = {Neurocomputing},
  title        = {DSGNN: A dynamic and static intentions integrated graph neural network for session-based recommendation},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scalable graph neural network-based framework for
identifying critical nodes and links in complex networks.
<em>NEUCOM</em>, <em>468</em>, 211–221. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying critical nodes and links in graphs is a crucial task. These nodes/links typically represent critical elements/communication links that play a key role in a system’s performance. However, a majority of the methods available in the literature on the identification of critical nodes/links are based on an iterative approach that explores each node/link of a graph at a time, repeating for all nodes/links in the graph. Such methods suffer from high computational complexity and the resulting analysis is also network-specific. To overcome these challenges, this article proposes a scalable and generic graph neural network (GNN) based framework for identifying critical nodes/links in large complex networks. The proposed framework defines a GNN based model that learns the node/link criticality score on a small representative subset of nodes/links. An appropriately trained model can be employed to predict the scores of unseen nodes/links in large graphs and consequently identify the most critical ones. The scalability of the framework is demonstrated through prediction of nodes/links scores in large scale synthetic and real-world networks. The proposed approach is fairly accurate in approximating the criticality scores and offers a significant computational advantage over conventional approaches.},
  archive      = {J_NEUCOM},
  author       = {Sai Munikoti and Laya Das and Balasubramaniam Natarajan},
  doi          = {10.1016/j.neucom.2021.10.031},
  journal      = {Neurocomputing},
  pages        = {211-221},
  shortjournal = {Neurocomputing},
  title        = {Scalable graph neural network-based framework for identifying critical nodes and links in complex networks},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint network embedding of network structure and node
attributes via deep autoencoder. <em>NEUCOM</em>, <em>468</em>, 198–210.
(<a href="https://doi.org/10.1016/j.neucom.2021.10.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding aims to learn a low-dimensional vector for each node in networks, which is effective in a variety of applications such as network reconstruction and community detection. However, the majority of the existing network embedding methods merely exploit the network structure and ignore the rich node attributes, which tend to generate sub-optimal network representation. To learn more desired network representation, diverse information of networks should be exploited. In this paper, we develop a novel deep autoencoder framework to fuse topological structure and node attributes named FSADA. We firstly design a multi-layer autoencoder which consists of multiple non-linear functions to capture and preserve the highly non-linear network structure and node attribute information. Particularly, we adopt a pre-processing procedure to pre-process the original information, which can better facilitate to extract the intrinsic correlations between topological structure and node attributes. In addition, we design an enhancement module that combines topology and node attribute similarity to construct pairwise constraints on nodes, and then a graph regularization is introduced into the framework to enhance the representation in the latent space. Our extensive experimental evaluations demonstrate the superior performance of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yu Pan and Junhua Zou and Junyang Qiu and Shuaihui Wang and Guyu Hu and Zhisong Pan},
  doi          = {10.1016/j.neucom.2021.10.032},
  journal      = {Neurocomputing},
  pages        = {198-210},
  shortjournal = {Neurocomputing},
  title        = {Joint network embedding of network structure and node attributes via deep autoencoder},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Path planning and dynamic collision avoidance algorithm
under COLREGs via deep reinforcement learning. <em>NEUCOM</em>,
<em>468</em>, 181–197. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the core technologies of the automatic control system for unmanned surface vehicles (USVs), autonomous collision avoidance algorithm is the key to ensure the safe navigation of USVs. In this paper, path planning and dynamic collision avoidance (PPDC) algorithm which obeys COLREGs is proposed for USVs. In order to avoid unnecessary collision avoidance actions, the risk assessment model is developed, which is used to determine the switching time of path planning and dynamic collision avoidance. In order to train the algorithm which complies with the COLREGs, the encounter situation is divided quantitatively, which is regarded as the input state of the system, so that the high-dimensional input is successfully avoided. The state space of the USV is defined by relative parameters to improve the generalization ability of the algorithm, meanwhile, a network structure based on DDPG is designed to achieve the continuous output of thrust and rudder angle. Combined with path planning, collision avoidance, compliance with COLREGs and smooth arrival task, four kinds of reward functions are designed. In order to solve the problem of low training efficiency of experience replay mechanism in DDPG, cumulative priority sampling mechanism is proposed. Through the simulation and verification in a variety of scenarios, it is proved that PPDC algorithm has the function of path planning and dynamic collision avoidance in compliance with COLREGs, which has good real-time performance and security.},
  archive      = {J_NEUCOM},
  author       = {Xinli Xu and Peng Cai and Zahoor Ahmed and Vidya Sagar Yellapu and Weidong Zhang},
  doi          = {10.1016/j.neucom.2021.09.071},
  journal      = {Neurocomputing},
  pages        = {181-197},
  shortjournal = {Neurocomputing},
  title        = {Path planning and dynamic collision avoidance algorithm under COLREGs via deep reinforcement learning},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep kronecker neural networks: A general framework for
neural networks with adaptive activation functions. <em>NEUCOM</em>,
<em>468</em>, 165–180. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new type of neural networks , Kronecker neural networks (KNNs), that form a general framework for neural networks with adaptive activation functions . KNNs employ the Kronecker product , which provides an efficient way of constructing a very wide network while keeping the number of parameters low. Our theoretical analysis reveals that under suitable conditions, KNNs induce a faster decay of the loss than that by the feed-forward networks. This is also empirically verified through a set of computational examples. Furthermore, under certain technical assumptions, we establish global convergence of gradient descent for KNNs. As a specific case, we propose the Rowdy activation function that is designed to get rid of any saturation region by injecting sinusoidal fluctuations, which include trainable parameters. The proposed Rowdy activation function can be employed in any neural network architecture like feed-forward neural networks, Recurrent neural networks , Convolutional neural networks etc. The effectiveness of KNNs with Rowdy activation is demonstrated through various computational experiments including function approximation using feed-forward neural networks, solution inference of partial differential equations using the physics-informed neural networks, and standard deep learning benchmark problems using convolutional and fully-connected neural networks.},
  archive      = {J_NEUCOM},
  author       = {Ameya D. Jagtap and Yeonjong Shin and Kenji Kawaguchi and George Em Karniadakis},
  doi          = {10.1016/j.neucom.2021.10.036},
  journal      = {Neurocomputing},
  pages        = {165-180},
  shortjournal = {Neurocomputing},
  title        = {Deep kronecker neural networks: A general framework for neural networks with adaptive activation functions},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Multinomial logistic regression classifier via
lq,0-proximal newton algorithm. <em>NEUCOM</em>, <em>468</em>, 148–164.
(<a href="https://doi.org/10.1016/j.neucom.2021.10.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multinomial logistic regression (MLR) is a useful tool for solving multi-classification problems. The l q , 0 lq,0 ( q ⩾ 1 ) (q⩾1) norm is an ideal regularization term for characterizing group sparsity in multinomial logistic regression and selecting important features in the high dimensional data . However, l q , 0 lq,0 regularized multinomial logistic regression ( l q , 0 lq,0 -MLR) is nonconvex, discontinuous, and NP-hard. Thus, most prior studies adopted a continuous approximation of the l q , 0 lq,0 norm. In this paper, we present a novel l q , 0 lq,0 -proximal Newton algorithm ( l q , 0 lq,0 - PNA ) to solve the l q , 0 lq,0 -MLR. We first define a strong α α -stationary point and prove that this point is a local minimizer of l q , 0 lq,0 -MLR. We then convert such a point into a stationary equation and solve it by l q , 0 lq,0 - PNA , which is a Newton-type method running on a group sparse subspace with a low computational cost. Furthermore, we establish a locally quadratic convergence of l q , 0 lq,0 - PNA . Finally, numerical experiments on simulated and real data show the superiority of l q , 0 lq,0 - PNA in terms of computational time and accuracy, when compared with six state-of-the-art solvers, especially for high dimensional data .},
  archive      = {J_NEUCOM},
  author       = {Penghe Zhang and Rui Wang and Naihua Xiu},
  doi          = {10.1016/j.neucom.2021.10.005},
  journal      = {Neurocomputing},
  pages        = {148-164},
  shortjournal = {Neurocomputing},
  title        = {Multinomial logistic regression classifier via lq,0-proximal newton algorithm},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Low-power-consumption physical reservoir computing model
based on overdamped bistable stochastic resonance system.
<em>NEUCOM</em>, <em>468</em>, 137–147. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The physical implementation of reservoir computing (RC), a brain-inspired computing framework, is attracting increasing attention in various research fields owing to its capability of quick learning and the relatively simple training process. Although several physical RC models have been envisaged and realized, most of them require additional peripherals; it leads to an increase in the power consumption of the system. In this study, we propose a novel RC model that is based on an overdamped bistable system and exhibits a counter-intuitive phenomenon called stochastic resonance , through which it can transfer noise energy to the information-carrying signal to realize learning with a comparatively low power consumption . The proposed model also possesses the functional capability of filtering and amplification and thus does not require additional peripheral equipment. In order to prove the feasibility and determine the desired operation mode of the system, two basic benchmark tests, namely short-term memory and parity check tasks, were employed to assess the proposed model. The results verify that this work will potentially act as a stepping stone towards realizing even better low-power-consumption physical RC.},
  archive      = {J_NEUCOM},
  author       = {Zhiqiang Liao and Zeyu Wang and Hiroyasu Yamahara and Hitoshi Tabata},
  doi          = {10.1016/j.neucom.2021.09.074},
  journal      = {Neurocomputing},
  pages        = {137-147},
  shortjournal = {Neurocomputing},
  title        = {Low-power-consumption physical reservoir computing model based on overdamped bistable stochastic resonance system},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid interpretable predictive machine learning model for
air pollution prediction. <em>NEUCOM</em>, <em>468</em>, 123–136. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air pollution prediction is a burning issue, as pollutants can harm human health. Traditional machine learning models usually aim to improve the overall prediction accuracy but neglect the accuracy for peak values. Moreover, these models are not interpretable. They fail to explain the interactions between various determining factors and their impacts on air pollution. In this paper, we propose a new Hybrid Interpretable Predictive Machine Learning model for the Particulate Matter 2.5 prediction, which carries two novelties. First, a hybrid model structure is constructed with deep neural network and Nonlinear Auto Regressive Moving Average with Exogenous Input model. Second, automatic feature generation and feature selection procedures are integrated into this hybrid model. The experimental results demonstrate the superiority of our model over other models in prediction accuracy for peak values and model interpretability . The proposed model reveals how PM2.5 prediction is estimated by historical PM2.5, weather, and season. The accuracies (measured by correlation coefficients) of 1, 3 and 6-hour-ahead prediction are 0.9870, 0.9332 and 0.8587, respectively. More importantly, the proposed approach presents a new interpretable machine learning framework for time series data , enabling to explain complex dependence of multimode inputs, and to build reliable predictive models.},
  archive      = {J_NEUCOM},
  author       = {Yuanlin Gu and Baihua Li and Qinggang Meng},
  doi          = {10.1016/j.neucom.2021.09.051},
  journal      = {Neurocomputing},
  pages        = {123-136},
  shortjournal = {Neurocomputing},
  title        = {Hybrid interpretable predictive machine learning model for air pollution prediction},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving graph neural network for session-based
recommendation system via non-sequential interactions. <em>NEUCOM</em>,
<em>468</em>, 111–122. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the absence of user profile information, recommender systems have to only rely on current session information for recommendation. E-commerce sites may use transitions between interactions in each session to improve recommendation. This situation is known as the session-based recommendation. It can be challenging due to the limited information and the uncertain user behavior . Recurrent Neural Networks (RNN) have become the state-of-the-art models for session-based recommendation due to their ability to model long sequences. Although powerful, RNN-based models suffer from learning complex transition between the interactions. To mitigate it, Graph Neural Networks (GNN) have been proposed for session-based recommendation. However, different sequences of interactions may lead to the same outcome especially on E-commerce sites, hence non-sequential interactions between items of the current session may improve the performance of a recommender system. To learn both the sequential and non-sequential transition interactions between the items in the current session, we proposed a GNN based model named GRASER. Specifically, the proposed model first learns the non-sequential and then the sequential transition interactions between the items of the current session using GNN in an end-to-end manner. Extensive experiments were carried out on two datasets: Yoochoose from the RecSys Challenge 2015 and Diginetica from CIKM Cup 2016. The results showed that the proposed model outperforms the other state-of-the-art models by 11\% and 10\% on MRR@20 on Yoochoose and Diginetica datasets respectively.},
  archive      = {J_NEUCOM},
  author       = {Tajuddeen Rabiu Gwadabe and Ying Liu},
  doi          = {10.1016/j.neucom.2021.10.034},
  journal      = {Neurocomputing},
  pages        = {111-122},
  shortjournal = {Neurocomputing},
  title        = {Improving graph neural network for session-based recommendation system via non-sequential interactions},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy entity alignment via knowledge embedding with
awareness of uncertainty measure. <em>NEUCOM</em>, <em>468</em>, 97–110.
(<a href="https://doi.org/10.1016/j.neucom.2021.10.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity alignment refers to associate entities in different knowledge graphs if they are semantically identical. Embedding-based entity alignment approaches encode entities in a continuous embedding space where entities are aligned based on the similarity of learned embeddings. However, there exists ambiguity and uncertainty in entity alignment caused by single alignment metric. In this paper, a fuzzy entity alignment method FuzzyEA is proposed to model the uncertainty in alignment process based on intuitionistic fuzzy set (IFS). Iterative TransE model is designed to learn relational structure of knowledge graphs, where mutual selection and error correction mechanism is proposed to enhance the effect of iteration. The alignment results obtained by name/description embedding and structure embedding are fused based on Dempster’s combination rule. Experiments on three benchmark datasets demonstrate that the proposed FuzzyEA consistently outperforms other entity alignment methods and contributes to promising improvement in alignment accuracy and discrimination ability.},
  archive      = {J_NEUCOM},
  author       = {Wen Jiang and Yuanna Liu and Xinyang Deng},
  doi          = {10.1016/j.neucom.2021.10.026},
  journal      = {Neurocomputing},
  pages        = {97-110},
  shortjournal = {Neurocomputing},
  title        = {Fuzzy entity alignment via knowledge embedding with awareness of uncertainty measure},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Shared state space model for background information
extraction and time series prediction. <em>NEUCOM</em>, <em>468</em>,
85–96. (<a href="https://doi.org/10.1016/j.neucom.2021.10.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series prediction is important for financial analysis, climate forecasting, and so on. Existing works mainly focus on the prediction of target time series based on the prior of the sequence itself, but ignore the background information behind the sequences. Such ignored information is usually essential to build a robust prediction model in complex real-world applications. However, how to extract the shared background information behind multiple sequences and how to incorporate the extracted information in the prediction model are two main challenges. To address the above two challenges, we propose a shared state space model (SSSM) by introducing a shared background information component into the state space model. In SSSM, we consider all sequences as a whole and model each target series by utilizing a state space model with shared same parameters and background information. First, we employ two recurrent neural networks to extract the temporal characteristic of the target sequence as well as the background information. Second, the above extracted information is integrated into a state space model in the form of a linear Gaussian component , whose inference procedure is accomplished by Kalman Filter . Finally, the model is optimized following a log-likelihood of the model with the above two components. Experiments on real-world applications show that our model can extract the share information behind the data and outperforms the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Ruichu Cai and Zhaolong Lin and Wei Chen and Zhifeng Hao},
  doi          = {10.1016/j.neucom.2021.10.010},
  journal      = {Neurocomputing},
  pages        = {85-96},
  shortjournal = {Neurocomputing},
  title        = {Shared state space model for background information extraction and time series prediction},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DE-net: A deep edge network with boundary information for
automatic skin lesion segmentation. <em>NEUCOM</em>, <em>468</em>,
71–84. (<a href="https://doi.org/10.1016/j.neucom.2021.10.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic skin lesion segmentation is one of the most important tasks for computer-aided diagnosis of skin cancer. Although many deep learning-based methods have been proposed, most of them do not pay attention to the boundary information that is critical for achieving more accurate segmentation. In this work, an end-to-end deep edge convolutional neural network (DE-Net) based on the encoder-decoder structure is proposed to pay more attention to the skin lesion boundaries. In the decoder process of the proposed DE-Net, an edge information guided module (EIGM) is designed to introduce the boundary information of the original image and fuse it with different levels of contextual information. Furthermore, to generate more accurate skin lesion boundaries without losing the entire performance and guide the module to highlight more boundary information, we propose an entirety-center-edge (ECE) loss function that can further optimize the boundary details on the basis of the necessary segmentation results. The proposed loss function is backbone-independent and has better performance than other commonly used loss functions in segmentation tasks. In the experiment, the ISIC-2017 dataset is employed to evaluate the effectiveness of the proposed method. It achieves the performance of 0.8792 and 0.8053 on the metrics Dice coefficients and Jaccard index, respectively. Furthermore, we also evaluate the proposed method on ISIC-2016 and PH2 datasets to demonstrate its generalizability. Experimental results demonstrate that the proposed method can outperform the state-of-the-art methods on all these three datasets and has strong generalizability.},
  archive      = {J_NEUCOM},
  author       = {Rui Gu and Lituan Wang and Lei Zhang},
  doi          = {10.1016/j.neucom.2021.10.017},
  journal      = {Neurocomputing},
  pages        = {71-84},
  shortjournal = {Neurocomputing},
  title        = {DE-net: A deep edge network with boundary information for automatic skin lesion segmentation},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge tensor embedding framework with association
enhancement for breast ultrasound diagnosis of limited labeled samples.
<em>NEUCOM</em>, <em>468</em>, 60–70. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the AI diagnosis of breast cancer, instead of ultrasound images from non-standard acquisition process, the Breast Image Reporting and Data System (BI-RADS) reports are widely accepted as the input data since it can give standardized descriptions for the breast ultrasound samples. The BI-RADS reports are usually stored as the format of Knowledge Graph (KG) due to the flexibility, and the KG embedding is a common procedure for the AI analysis on BI-RADS data. However, since most existing embedding methods are based on the local connections in KG, in the situation of limited labeled samples, there is a clear need for embedding based diagnosis method which is capable of representing the global interactions among all entities/relations and associating the labeled/unlabeled samples. To diagnose the breast ultrasound samples with limited labels, in this paper we propose an efficient framework Knowledge Tensor Embedding with Association Enhancement Diagnosis (KTEAED), which adopts tensor decomposition into the embedding to achieve the global representation of KG entities/relations, and introduces the association enhancement strategy to prompt the similarities between embeddings of labeled/unlabeled samples. The embedding vectors are then utilized to diagnose the clinical outcomes of samples by predicting their links to outcomes entities. Through extensive experiments on BI-RADS data with different fractions of labels and ablation studies, our KTEAED displays promising performance in the situations of various fractions of labels. In summary, our framework demonstrates a clear advantage of tackling limited labeled samples of BI-RADS reports in the breast ultrasound diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Jianing Xi and Zhaoji Miao and Longzhong Liu and Xuebing Yang and Wensheng Zhang and Qinghua Huang and Xuelong Li},
  doi          = {10.1016/j.neucom.2021.10.013},
  journal      = {Neurocomputing},
  pages        = {60-70},
  shortjournal = {Neurocomputing},
  title        = {Knowledge tensor embedding framework with association enhancement for breast ultrasound diagnosis of limited labeled samples},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A visual persistence model for image captioning.
<em>NEUCOM</em>, <em>468</em>, 48–59. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object-level features from Faster R-CNN and attention mechanism have been used extensively in image captioning based on Encoder-Decoder frameworks. However, most existing methods feed the average pooling of object features as the global representation to the captioning model and recalculate the attention weights of object regions when generating a new word without considering the visual persistence like humans. In this paper, we respectively build Visual Persistence modules in encoder and decoder: The visual persistence module in encoder seeks the core object features to replace the image global representation; the visual persistence module in decoder evaluates the correlation between previous attention results and current attention results, and fuses them as the final attended feature to generate a new word. The experimental results on MSCOCO validate the effectiveness and competitiveness of our Visual Persistence Model (VPNet). Remarkably, VPNet also achieves competitive scores in most metrics on MSCOCO online test server compared to the existing state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yiyu Wang and Jungang Xu and Yingfei Sun},
  doi          = {10.1016/j.neucom.2021.10.014},
  journal      = {Neurocomputing},
  pages        = {48-59},
  shortjournal = {Neurocomputing},
  title        = {A visual persistence model for image captioning},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). What-where-when attention network for video-based person
re-identification. <em>NEUCOM</em>, <em>468</em>, 33–47. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video-based person re-identification plays a critical role in intelligent video surveillance by learning temporal correlations from consecutive video frames. Most existing methods aim to solve the challenging variations of pose, occlusion, backgrounds and so on by using attention mechanism . They almost all draw attention to the occlusion and learn occlusion-invariant video representations by abandoning the occluded area or frames, while the other areas in these frames contain sufficient spatial information and temporal cues. To overcome these drawbacks, this paper proposes a comprehensive attention mechanism covering what , where , and when to pay attention in the discriminative spatial-temporal feature learning , namely What-Where-When Attention Network (W3AN). Concretely, W3AN designs a spatial attention module to focus on pedestrian identity and obvious attributes by the importance estimating layer ( What and Where ), and a temporal attention module to calculate the frame-level importance ( when ), which is embedded into a graph attention network to exploit temporal attention features rather than computing weighted average feature for video frames like existing methods. Moreover, the experiments on three widely-recognized datasets demonstrate the effectiveness of our proposed W3AN model and the discussion of major modules elaborates the contributions of this paper.},
  archive      = {J_NEUCOM},
  author       = {Chenrui Zhang and Ping Chen and Tao Lei and Yangxu Wu and Hongying Meng},
  doi          = {10.1016/j.neucom.2021.10.018},
  journal      = {Neurocomputing},
  pages        = {33-47},
  shortjournal = {Neurocomputing},
  title        = {What-where-when attention network for video-based person re-identification},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Learning granger causality for non-stationary hawkes
processes. <em>NEUCOM</em>, <em>468</em>, 22–32. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning causal relationships from point processes is of great significance to various real-world applications, e.g., user behaviour study, fault diagnosis. Though several methods have been proposed for this problem, the existing methods rely on the stationarity assumption of the point process. Such a stationarity assumption is usually violated due to the influence of latent confounders of the point processes. Based on the study of various real-world point processes, we find that a non-stationary Hawkes process is usually a mixture of several non-overlap and stationary processes . Thus, we propose an adaptive pattern based method for the non-stationary Hawkes Process (named GC-nsHP). In the proposed method, the following two steps are iteratively employed to adaptively partition the non-stationary processes and learn the causal structure for the partitioned sub-processes: (1) we use a dynamic-programming-based algorithm to partition the non-stationary long process into several stationary sub-processes; (2) we use an expectation–maximization-based algorithm (EM) to learn the Granger Causality of each pattern. Experiments on both synthetic and real-world datasets not only show the effectiveness of the proposed method on the non-stationary point process, but also discover some interesting results on the IPTV data set.},
  archive      = {J_NEUCOM},
  author       = {Wei Chen and Jibin Chen and Ruichu Cai and Yuequn Liu and Zhifeng Hao},
  doi          = {10.1016/j.neucom.2021.10.030},
  journal      = {Neurocomputing},
  pages        = {22-32},
  shortjournal = {Neurocomputing},
  title        = {Learning granger causality for non-stationary hawkes processes},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Differential privacy for bipartite consensus over signed
digraph. <em>NEUCOM</em>, <em>468</em>, 11–21. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the differential privacy-preserving problem for multi-agent systems (MASs) in the presence of antagonistic information over signed digraph . As for the structurally balanced case, an ε ε -differential privacy algorithm is proposed, upon which some sufficient conditions guaranteeing almost sure bipartite consensus are given. Based on the above scheme, the tradeoff between the system performance and the privacy guarantee is elaborated, and the optimal noise is also devised. Moreover, the proposed privacy preserving scheme is further applied to the scenario of structurally unbalanced graph, where a criterion with respect to almost sure stability of the considered system is derived, as well as the privacy preserving condition. This extends the balanced interaction scenario, and consequently the cooperative multi-agent systems. Finally, numerical simulations are presented to demonstrate the effectiveness of our results.},
  archive      = {J_NEUCOM},
  author       = {Zhiqiang Zuo and Ran Tian and Qiaoni Han and Yijing Wang and Wentao Zhang},
  doi          = {10.1016/j.neucom.2021.10.019},
  journal      = {Neurocomputing},
  pages        = {11-21},
  shortjournal = {Neurocomputing},
  title        = {Differential privacy for bipartite consensus over signed digraph},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Federated synthetic data generation with differential
privacy. <em>NEUCOM</em>, <em>468</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed machine learning has attracted much attention in the last decade with the widespread use of the Internet of Things . As a generative model , Generative Adversarial Network (GAN) has excellent empirical performance. However, the distributed storage of data and the fact that data cannot be shared for privacy reasons in a federated learning setting bring new challenges to training GAN. To address this issue, we propose private FL-GAN, a differentially private GAN based on federated learning. By strategically combining the Lipschitz condition with differential privacy sensitivity, our model can generate high-quality synthetic data without sacrificing the training data’s privacy. When communication between clients becomes the main bottleneck for federated learning, we propose to use a serialized model-training paradigm, which significantly reduces communication costs. Considering the distributed data is often non-IID in reality, which poses challenges to modeling, we further propose universal private FL-GAN to approach this problem. We not only theoretically prove that our algorithms can provide strict privacy guarantees with differential privacy, but also experimentally demonstrate that our models can generate satisfactory data while protecting the privacy of the training data, even if the data is non-IID.},
  archive      = {J_NEUCOM},
  author       = {Bangzhou Xin and Yangyang Geng and Teng Hu and Sheng Chen and Wei Yang and Shaowei Wang and Liusheng Huang},
  doi          = {10.1016/j.neucom.2021.10.027},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {Federated synthetic data generation with differential privacy},
  volume       = {468},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SiamPolar: Semi-supervised realtime video object
segmentation with polar representation. <em>NEUCOM</em>, <em>467</em>,
491–503. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video object segmentation (VOS) is an essential part of autonomous vehicle navigation. Besides the accuracy metric, the real-time speed is very important for the algorithms of autonomous vehicles. In this paper, we propose a semi-supervised real-time method based on the Siamese network using a new polar representation. The input of bounding boxes are initialized rather than the object masks, which are applied to the video object detection tasks. The polar representation could reduce the parameters for encoding masks with subtle accuracy loss, so that the algorithm speed can be improved significantly. An asymmetric siamese network is also developed to extract the features from different spatial scales. Moreover, the peeling convolution is proposed to reduce the antagonism among the branches of the polar head. The repeated cross-correlation and semi-FPN are designed based on this idea. The experimental results on the DAVIS-2016 dataset and other public datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yaochen Li and Yuhui Hong and Yonghong Song and Chao Zhu and Ying Zhang and Ruihao Wang},
  doi          = {10.1016/j.neucom.2021.09.063},
  journal      = {Neurocomputing},
  pages        = {491-503},
  shortjournal = {Neurocomputing},
  title        = {SiamPolar: Semi-supervised realtime video object segmentation with polar representation},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AKF-SR: Adaptive kalman filtering-based successor
representation. <em>NEUCOM</em>, <em>467</em>, 476–490. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To understand animals’ behavior in finding relations between similar tasks and adapting themselves to changes in the tasks, it is necessary to know how the brain generalizes the learned knowledge from a previous task to unseen tasks. Recent studies in neuroscience suggest that Successor Representation (SR)-based models provide adaptation to changes in the goal locations or reward function faster than model-free algorithms, together with lower computational cost compared to that of model-based algorithms. However, it is not known how such representation might help animals to manage uncertainty in their decision making. Existing methods for the SR learning based on standard temporal difference methods (e.g., deep neural network-based algorithms) do not capture uncertainty about the estimated SR. In order to address this issue, the paper presents a Kalman filter-based SR framework, referred to as Adaptive Kalman Filtering-based Successor Representation (AKF–SR). First, Kalman temporal difference approach, which is a combination of Kalman filter and the temporal difference method, is used within the AKF–SR framework to cast the SR learning procedure into a filtering problem to benefit from uncertainty estimation of the SR, and also decreases in memory requirement and sensitivity to model’s parameters in comparison to deep neural network-based algorithms. An adaptive Kalman filtering approach is then applied within the proposed AKF–SR framework in order to tune the measurement noise covariance and measurement mapping function of Kalman filter as the most important parameters affecting the filter’s performance. Moreover, an active learning method that exploits the estimated uncertainty of the SR to form the behaviour policy leading to more visits to less certain values is proposed to improve the overall performance of an agent in terms of received rewards while interacting with its environment. Experimental results based on three reinforcement learning environments illustrate the efficacy of the proposed AKF–SR framework over state-of-the-art frameworks in terms of cumulative reward, reliability, time and computational cost, and speed of convergence to changes in the reward function.},
  archive      = {J_NEUCOM},
  author       = {Parvin Malekzadeh and Mohammad Salimibeni and Ming Hou and Arash Mohammadi and Konstantinos N. Plataniotis},
  doi          = {10.1016/j.neucom.2021.10.008},
  journal      = {Neurocomputing},
  pages        = {476-490},
  shortjournal = {Neurocomputing},
  title        = {AKF-SR: Adaptive kalman filtering-based successor representation},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Progressively real-time video salient object detection via
cascaded fully convolutional networks with motion attention.
<em>NEUCOM</em>, <em>467</em>, 465–475. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantics and motion are two cues of essence for the success in video salient object detection. Most existing deep-learning based approaches extract semantic features by the use of only one fully convolutional network with simple stacked encoders. They simulate motion patterns of video objects with two consecutive frames being simultaneously fed into a convolutional LSTM network or a weights-sharing fully convolutional network . However, such approaches have the shortcomings of producing a coarse predicted saliency map or requiring significant computational overheads. In this paper, we present a novel approach with cascaded fully convolutional networks involving motion attention (abbreviated as CFCN-MA), to achieve real-time saliency detection in videos. Our key idea is to construct twofold fully convolutional networks in order to gain a saliency map from coarse to fine. We devise an optical flow-based motion attention mechanism to improve the prediction accuracy of the initial fully convolutional networks, using the popular FlowNet2-SD model that is efficient and effective for motion pattern recognition of distinctive objects in videos. This method can obtain a fine saliency map with a refined region of interest. Moreover, we propose a means for calculating attention-guided intersection-over-union loss (shortnamed as AIoU ) to supervise the CFCN-MA model in learning a saliency map with both clear edge and complete structure. Our approach is evaluated on three popular benchmark datasets, namely DAVIS, ViSal and FBMS . Experimental results demonstrate that our method outperforms many state-of-the-art techniques while meeting the real-time demand at 27 fps.},
  archive      = {J_NEUCOM},
  author       = {Qingping Zheng and Ying Li and Ling Zheng and Qiang Shen},
  doi          = {10.1016/j.neucom.2021.10.007},
  journal      = {Neurocomputing},
  pages        = {465-475},
  shortjournal = {Neurocomputing},
  title        = {Progressively real-time video salient object detection via cascaded fully convolutional networks with motion attention},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Real-time POI recommendation via modeling long- and
short-term user preferences. <em>NEUCOM</em>, <em>467</em>, 454–464. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Next Point-of-Interest (POI) Recommendation which proposes users for their next visiting locations, has gained increasing attention. A timely and accurate next POI recommendation can improve users’ efficient experiences. However, most existing methods typically focus on the sequential influence, but neglect the user’s real-time preference changing over time. In some scenarios, users may need a real-time POI recommendation, for example, when using Take-away Applications, users need recommending the appropriate restaurants at the specific moment. Hence, how to mine users’ patterns of life and their current preferences becomes an essential issue for the real-time POI recommendation. To address the issues above, we propose a real-time preference mining model (RTPM) which is based on LSTM to recommend the next POI with time restrictions. Specifically, RTPM mines users’ real-time preferences from long-term and short-term preferences in a uniform framework. For the long-term preferences, we mine the periodic trends of users’ behaviors between weeks to better reflect users’ patterns of life. While for the short-term preferences, trainable time transition vectors which represent the public preferences in corresponding time slots, are introduced to model users’ current time preferences influenced by the public. At the stage of recommendation, we design a category filter to filter out the POIs whose categories are unpopular in corresponding time slots to reduce the search space and make recommendation fit current time slot better. Note that RTPM does not utilize users’ attributes and their current locations for recommendation, which makes great contributions to users’ privacy protection. Extensive experiments on two real-world datasets demonstrate that RTPM outperforms the state-of-the-art models on Recall and NDCG.},
  archive      = {J_NEUCOM},
  author       = {Xin Liu and Yongjian Yang and Yuanbo Xu and Funing Yang and Qiuyang Huang and Hong Wang},
  doi          = {10.1016/j.neucom.2021.09.056},
  journal      = {Neurocomputing},
  pages        = {454-464},
  shortjournal = {Neurocomputing},
  title        = {Real-time POI recommendation via modeling long- and short-term user preferences},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multitask learning with single gradient step update for task
balancing. <em>NEUCOM</em>, <em>467</em>, 442–453. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multitask learning is a methodology to boost generalization performance and also reduce computational intensity and memory usage. However, learning multiple tasks simultaneously can be more difficult than learning a single task because it can cause imbalance among tasks. To address the imbalance problem, we propose an algorithm to balance between tasks at the gradient level by applying gradient-based meta -learning to multitask learning . The proposed method trains shared layers and task-specific layers separately so that the two layers with different roles in a multitask network can be fitted to their own purposes. In particular, the shared layer that contains informative knowledge shared among tasks is trained by employing single gradient step update and inner/outer loop training to mitigate the imbalance problem at the gradient level. We apply the proposed method to various multitask computer vision problems and achieve state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Sungjae Lee and Youngdoo Son},
  doi          = {10.1016/j.neucom.2021.10.025},
  journal      = {Neurocomputing},
  pages        = {442-453},
  shortjournal = {Neurocomputing},
  title        = {Multitask learning with single gradient step update for task balancing},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-view fine-grained classification of plant species.
<em>NEUCOM</em>, <em>467</em>, 427–441. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic plant classification is challenging due to the vast biodiversity of the existing plant species in a fine-grained scenario. Robust deep learning architectures have been used to improve the classification performance in such a fine-grained problem but usually build models that are highly dependent on a large training dataset and are not scalable. This paper proposes a novel method based on a two-view leaf image representation and a hierarchical classification strategy for fine-grained plant species recognition. It uses the botanical taxonomy as a basis for a coarse-to-fine strategy applied to identify the plant genus and species. The two-view representation provides complementary global and local features of leaf images. A deep metric based on Siamese Convolutional Neural Networks is used to reduce the dependence on many training samples and make the method scalable to new plant species. The experimental results on two challenging fine-grained datasets of leaf images (i.e., PlantCLEF 2015 and LeafSnap) have shown the proposed method’s effectiveness, which achieved recognition accuracy of 0.87 and 0.96, respectively.},
  archive      = {J_NEUCOM},
  author       = {Voncarlos M. Araújo and Alceu S. Britto Jr. and Luiz S. Oliveira and Alessandro L. Koerich},
  doi          = {10.1016/j.neucom.2021.10.015},
  journal      = {Neurocomputing},
  pages        = {427-441},
  shortjournal = {Neurocomputing},
  title        = {Two-view fine-grained classification of plant species},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discriminative adversarial domain generalization with
meta-learning based cross-domain validation. <em>NEUCOM</em>,
<em>467</em>, 418–426. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generalization capability of machine learning models, which refers to generalizing the knowledge for an “unseen” domain via learning from one or multiple seen domain(s), is of great importance to develop and deploy machine learning applications in the real-world conditions. Domain Generalization (DG) techniques aim to enhance such generalization capability of machine learning models, where the learnt feature representation and the classifier are two crucial factors to improve generalization and make decisions. In this paper, we propose Discriminative Adversarial Domain Generalization (DADG) with meta-learning-based cross-domain validation. Our proposed framework tries to learn a domain-invariant feature representation from source domains and generalize it to the unseen domains. It contains two main components that work synergistically to build a domain-generalized Deep Neural Network (DNN) model: (i) discriminative adversarial learning, which proactively learns a generalized feature representation on multiple “seen” domains, and (ii) meta-learning based cross domain validation, which simulates train/test domain shift via applying meta-learning techniques in the training process. In the experimental evaluation, a comprehensive comparison has been made among our proposed approach and other existing approaches on three benchmark datasets. The results shown that DADG consistently outperforms a strong baseline DeepAll, and outperforms the other existing DG algorithms in most of the evaluation cases.},
  archive      = {J_NEUCOM},
  author       = {Keyu Chen and Di Zhuang and J. Morris Chang},
  doi          = {10.1016/j.neucom.2021.09.046},
  journal      = {Neurocomputing},
  pages        = {418-426},
  shortjournal = {Neurocomputing},
  title        = {Discriminative adversarial domain generalization with meta-learning based cross-domain validation},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Discriminative learning of imaginary data for few-shot
classification. <em>NEUCOM</em>, <em>467</em>, 406–417. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans can quickly learn new visual categories, because they can easily visualize or imagine what we need to recognize in an image with a complex background, and how it differs from other images. Incorporating this ability to hallucinate discriminative instances of novel classes might help machine vision systems perform better few-shot classification. In this paper, we propose a Discriminative Hallucination Learning Network based on attentional mechanism, and unify the GNN-based classifier with a “hallucinator” for few-shot classification. Firstly, we use a pre-trained saliency network to hallucinate the foreground image. Then, the hallucination feature network (FNet) and zoom network (ZNet) are designed to extract more fine-grained local images adaptively with intra-cluster similarity and the inter-cluster dissimilarity. The embedding network (Enet) initialize the node representation of the graph structure from a jointly trained convolutional neural network. Finally, the proposed method is evaluated extensively on three challenging ZSL benchmark datasets. It significantly outperforms state-of-the-art methods in both supervised and semi-supervised few-shot image classification experiments.},
  archive      = {J_NEUCOM},
  author       = {Xu Zhang and Youjia Zhang and Zuyu Zhang and Jinzhuo Liu},
  doi          = {10.1016/j.neucom.2021.09.070},
  journal      = {Neurocomputing},
  pages        = {406-417},
  shortjournal = {Neurocomputing},
  title        = {Discriminative learning of imaginary data for few-shot classification},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Projective multi-synchronization of fractional-order
complex-valued coupled multi-stable neural networks with impulsive
control. <em>NEUCOM</em>, <em>467</em>, 392–405. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a projective multi-synchronization problem for fractional-order complex-valued coupled multi-stable neural networks (FCVCMNNs) with time-delays. Using a complex decomposition approach, FCVCMNNs are divided into their real and imaginary components. Our method uses certain conditions for each subnetwork to achieve the multiple local equilibrium points or stable periodic orbits that are exponentially stable, which, when combined with the Lyapunov functions method, result in FCVCMNNs that are projectively multi-synchronized. The FCVCMNNs, on the other hand, are examined directly through the use of the Lyapunov functional method and linear matrix inequality (LMI). Various new sufficient conditions in the form of complex-valued LMIs are presented for the projective multi-synchronization of the considered FCVCMNNs. As a final step, we provide two numerical simulations to verify the effectiveness of the main results derived in this paper.},
  archive      = {J_NEUCOM},
  author       = {K. Udhayakumar and R. Rakkiyappan and Fathalla A. Rihan and Santo Banerjee},
  doi          = {10.1016/j.neucom.2021.10.003},
  journal      = {Neurocomputing},
  pages        = {392-405},
  shortjournal = {Neurocomputing},
  title        = {Projective multi-synchronization of fractional-order complex-valued coupled multi-stable neural networks with impulsive control},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Closed-LSTM neural network based reference modification for
trajectory tracking of piezoelectric actuator. <em>NEUCOM</em>,
<em>467</em>, 379–391. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a trajectory tracking control method for piezoelectric actuators (PEAs) based on long short-term memory neural network (LSTM-NN). Different from traditional control framework where neural network is used to approximate the open-loop PEA dynamics, LSTM-NN is used to establish the mapping between the actual trajectory and the reference trajectory of the closed-loop PEA, leading to a Closed-LSTM neural network control framework. With this framework, the trained LSTM-NN is used to modify the reference trajectory to compensate for the tracking error without changing the controller. First, we analyze and simplify the modeling of the linear and nonlinear characteristics of the PEA, and select the training input features of the LSTM-NN. Then, we use the actual trajectory and reference trajectory of the closed-loop PEA to train the LSTM-NN. The Closed-LSTM neural network control framework enables independent designs of the baseline feedback controller and feedforward compensator. In particular, the feedback controller is used to guarantee the system stability, and the LSTM-NN reference modification module is used as the feedforward compensator to achieve high-precision trajectory tracking, which does not affect the system stability and can be easily applied to off-the-shelf motion control systems. Its validity is experimentally verified on a PEA platform.},
  archive      = {J_NEUCOM},
  author       = {Jiangang Li and Youhua Huang and Qijie Li and Yanan Li},
  doi          = {10.1016/j.neucom.2021.10.012},
  journal      = {Neurocomputing},
  pages        = {379-391},
  shortjournal = {Neurocomputing},
  title        = {Closed-LSTM neural network based reference modification for trajectory tracking of piezoelectric actuator},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Progressive kernel pruning with saliency mapping of
input-output channels. <em>NEUCOM</em>, <em>467</em>, 360–378. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the smallest structural unit of feature mapping, the convolution kernel in a deep convolution neural networks (DCNN) convolutional layer is responsible for the input channel features to output channel features. A specific convolution kernel belongs to a specific group from the perspective of the input channel, and it belongs to a specific filter from the perspective of the output channel. If the input and output channels are simultaneously considered in the pruning process, the performance of the pruning model can be further improved. This paper proposes progressive kernel pruning with salient mapping of input-output channels, introduces the concept of input-output channel saliency and defines single-port salient mapping channels and dual-port salient mapping channels. This study demonstrates that single-port salient mapping channels can ensure that each input channel signal has a relatively strong convolution kernel mapped to the output channel, and vice versa. The dual-port salient mapping channel is a channel with high feature mapping abilities from both the input and output directions. Additionally, the average mapping ability measure index is defined, which is used to control the kernel pruning process of the single-port salient mapping channel to switch to the kernel pruning process of the dual-port salient mapping channel. The experimental results and analysis show that the method proposed in this paper can be used to effectively prune a heavyweight model and a lightweight model and can obtain a better accuracy under the conditions of higher compression ratio and acceleration ratios. For example, when VGG-16 is pruned on CIFAR-10, the compression ratio and acceleration ration are 91.00 × × and 15.24 × × , respectively, and the classification accuracy of the model decreased slightly by 0.22\%. When ResNet-101 is pruned on ImageNet, the compression ratio and acceleration ratio are 3.90 × × and 3.38 × × , respectively, and the classification accuracy of the model decreased slightly by 0.48\%. The proposed method is significantly better than state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Jihong Zhu and Jihong Pei},
  doi          = {10.1016/j.neucom.2021.10.009},
  journal      = {Neurocomputing},
  pages        = {360-378},
  shortjournal = {Neurocomputing},
  title        = {Progressive kernel pruning with saliency mapping of input-output channels},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BorderPointsMask: One-stage instance segmentation with
boundary points representation. <em>NEUCOM</em>, <em>467</em>, 348–359.
(<a href="https://doi.org/10.1016/j.neucom.2021.09.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mechanism of human vision can easily detect and segment objects based on boundary information. Even though the deep learning instance segmentation model based on boundary information can mimic this human vision mechanism, its prospect is rarely explored. In this work, we propose a one-stage and anchor-free instance segmentation framework based on boundary points representation, named BorderPointsMask. The proposed BorderPointsMask doesn’t need to rely on the object detector. It formulates instance segmentation as instance classification, boundary points location prediction, and boundary points attribute prediction. Furthermore, we design two effective approaches to improve the performance of this proposed framework. Specifically, we utilize the proposed BorderPoints Center-ness to suppress the predicted low-quality masks. And the Deformation Before-and-After Stacking Module (DBASM) is formulated to promote instance classification and boundary points learning. BorderPointsMask obtains 35.0\% in mask Average Precision (AP) with single-model (ResNet-101-FPN) and single-scale training/testing on the COCO benchmark, which demonstrates the superior performance among one-stage frameworks. The code will be available.},
  archive      = {J_NEUCOM},
  author       = {Hanqing Yang and Liyang Zheng and Saba Ghorbani Barzegar and Yu Zhang and Bin Xu},
  doi          = {10.1016/j.neucom.2021.09.061},
  journal      = {Neurocomputing},
  pages        = {348-359},
  shortjournal = {Neurocomputing},
  title        = {BorderPointsMask: One-stage instance segmentation with boundary points representation},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven adaptive extended state observer design for
autonomous surface vehicles with unknown input gains based on concurrent
learning. <em>NEUCOM</em>, <em>467</em>, 337–347. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the disturbance estimation and velocity recovery of autonomous surface ve hicles subject to unknown input gains, in addition to lumped uncertainties composed of unknown internal dynamics and external disturbances. Existing extended state observer design methods are not applicable due to the fact that some prior knowledge on model parameters such as the control input gains are assumed to be known in advance. By incorporating a concurrent learning approach into the extended state observer design, a three-order data-driven adaptive extended state observer based on position and acceleration information is proposed to estimate the unknown input gains, lumped disturbance, and unmeasured velocities. An advantage of the proposed data-driven adaptive extended state observer is that the unknown input gains, lumped disturbance, and unknown velocities can be simultaneously estimated with guaranteed convergence thanks to concurrent learning. The result is extended to a data-driven adaptive extended state observer with finite-time convergence. The efficacy of the proposed two data-driven adaptive extended state observers for autonomous surface vehicles is substantiated via simulations.},
  archive      = {J_NEUCOM},
  author       = {Jiawang Yue and Lu Liu and Zhouhua Peng and Dan Wang and Tieshan Li},
  doi          = {10.1016/j.neucom.2021.09.062},
  journal      = {Neurocomputing},
  pages        = {337-347},
  shortjournal = {Neurocomputing},
  title        = {Data-driven adaptive extended state observer design for autonomous surface vehicles with unknown input gains based on concurrent learning},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual question answering by pattern matching and reasoning.
<em>NEUCOM</em>, <em>467</em>, 323–336. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional techniques for visual question answering ( VQA ) are mostly end-to-end neural network based, which often perform poorly ( e.g., low accuracy) due to lack of understanding and reasoning. To overcome the weaknesses, we propose a comprehensive approach with following key features. (1) It represents inputs, i.e., an image I I and a natural language question Q nl Qnl as an entity-attribute graph and a query graph, respectively, and employs pattern matching to find answers; (2) it leverages reinforcement learning based model to identify a set of policies that are used to guide visual tasks and construct an entity-attribute graph, based on Q nl Qnl ; (3) it employs a novel method to parse a question Q nl Qnl and generate corresponding query graph Q ( u o ) Q(uo) for pattern matching; and (4) it integrates inference scheme to further improve result accuracy, in particular, it learns a graph-structured classifier for missing value inference and a co-occurrence matrix for candidate selection. With these features, our approach can not only process visual tasks efficiently, but also answer questions with high accuracy. To evaluate the performance of our approach, we conduct empirical studies on Soccer Soccer , Visual-Genome and GQA GQA , and show that our approach outperforms the state-of-the-art methods in result accuracy and system efficiency.},
  archive      = {J_NEUCOM},
  author       = {Huayi Zhan and Peixi Xiong and Xin Wang and Xin WANG and Lan Yang},
  doi          = {10.1016/j.neucom.2021.10.016},
  journal      = {Neurocomputing},
  pages        = {323-336},
  shortjournal = {Neurocomputing},
  title        = {Visual question answering by pattern matching and reasoning},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pancreatic cancer segmentation in unregistered
multi-parametric MRI with adversarial learning and multi-scale
supervision. <em>NEUCOM</em>, <em>467</em>, 310–322. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated pancreatic cancer segmentation is crucial for successful clinical aid diagnosis and surgical planning. However, the tiny size and inconspicuous boundaries of pancreatic cancer lesions lead to poor segmentation performance with single-modality imaging. The commonly used registration-based multi-modal fusion strategies may not only introduce uncertainties arising from registration, but also underutilize the complementary information between different modalities. Thus, to achieve different modality-based tumor segmentation, we propose for the first time a registration-free multi-modal and multi-scale adversarial segmentation network (MMSA-Net), which consist of a shared encoder and a dual decoder. Specifically, MMSA-Net combine two complementary modules, inter-modality adversarial learning and intra-modality multi-scale adversarial supervision, to obtain mode-specific segmentation results while facilitating multi-modal fusion. The inter-modality adversarial learning module facilitates the fusion of modality-shared features among different modalities by strengthening the similarity of features extracted by the shared encoder. The intra-modality multi-scale adversarial supervision emphasizes modality-specific features in different decoding paths, inherits and fuses modality-shared features while preserving the feature specificity of each modality, thus outputting competitive modality-specific segmentation results for each modality. Quantitative and qualitative experimental results on multi-parametric MRI pancreatic cancer data show that our method can effectively improve the performance of multi-modal segmentation. The method proposed in this work is expected to be another potential paradigm for addressing multi-modal segmentation tasks in addition to registration. Our source codes will be released at https://github.com/SJTUBME-QianLab/PancreaticCancer_Seg_AdvLearning , once the manuscript is accepted for publication.},
  archive      = {J_NEUCOM},
  author       = {Jun Li and Chaolu Feng and Qing Shen and Xiaozhu Lin and Xiaohua Qian},
  doi          = {10.1016/j.neucom.2021.09.058},
  journal      = {Neurocomputing},
  pages        = {310-322},
  shortjournal = {Neurocomputing},
  title        = {Pancreatic cancer segmentation in unregistered multi-parametric MRI with adversarial learning and multi-scale supervision},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SADRL: Merging human experience with machine intelligence
via supervised assisted deep reinforcement learning. <em>NEUCOM</em>,
<em>467</em>, 300–309. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Reinforcement Learning (DRL) has proven its capability to learn optimal policies in decision-making problems by directly interacting with environments. Meanwhile, supervised learning methods also show great capability of learning from data. However, how to combine DRL with supervised learning and leverage additional knowledge and data to assist the DRL agent remains difficult. This study proposes a novel Supervised Assisted Deep Reinforcement Learning (SADRL) framework integrating deep Q-learning from dynamic demonstrations with a behavioral cloning model (DQfDD-BC). Specifically, the proposed DQfDD-BC method leverages historical demonstrations to pre-train a behavioral cloning model and consistently update it by learning the dynamically updated demonstrations. A supervised expert loss function is designed to compare actions generated by the DRL model with those obtained from the BC model to provide advantageous guidance for policy improvements. Experimental results in several OpenAI Gym environments show that the proposed approach accelerates the learning processes, and meanwhile, adapts to different performance levels of demonstrations. As illustrated in an ablation study, the dynamic demonstration and expert loss mechanisms using a BC model contribute to improving the learning convergence performance compared with the baseline models . We believe that SADRL provides an elegant framework and the proposed method can promote the integration of human experience and machine intelligence .},
  archive      = {J_NEUCOM},
  author       = {Xiaoshuang Li and Xiao Wang and Xinhu Zheng and Junchen Jin and Yanhao Huang and Jun Jason Zhang and Fei-Yue Wang},
  doi          = {10.1016/j.neucom.2021.09.064},
  journal      = {Neurocomputing},
  pages        = {300-309},
  shortjournal = {Neurocomputing},
  title        = {SADRL: Merging human experience with machine intelligence via supervised assisted deep reinforcement learning},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Event-triggered adaptive NN tracking control with dynamic
gain for a class of unknown nonlinear systems. <em>NEUCOM</em>,
<em>467</em>, 292–299. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An event-triggered tracking control problem is investigated for a class of unknown nonlinear systems in this paper. First, to approximate the unknown function, the radial basis function neural network is used. Then, we propose an event-triggered adaptive neural network control scheme with dynamic gain. Both the event-triggered mechanism in the controller-to-actuator channel and the dynamic gain in the sensor-to-controller channel are considered to reduce the communication load between the controller and the actuator and in the meantime to alleviate the burden of parameter adjustment as well. This scheme makes full use of the advantage that the dynamic gain is driven by the tracking error to ensure that the system output signal can track the reference signal within a prespecified accuracy without adjusting the parameters in use. Moreover, a detailed theoretical proof is given to illustrate that Zeno behavior can be excluded under the designed event-triggered controller. Finally, a simulation example is provided to show the effectiveness of our control scheme.},
  archive      = {J_NEUCOM},
  author       = {Jing Li and Han Liu and Zhaohui Zhang and Xiaobo Li and Xiaoli Yang},
  doi          = {10.1016/j.neucom.2021.09.069},
  journal      = {Neurocomputing},
  pages        = {292-299},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered adaptive NN tracking control with dynamic gain for a class of unknown nonlinear systems},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing structure modeling for relation extraction with
fine-grained gating and co-attention. <em>NEUCOM</em>, <em>467</em>,
282–291. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction is a critical natural language processing task. Existing dependency-based models captured long-range syntactic relations, but they usually cannot fully exploit information from sentences. They often used hand-crafted rules to prune redundant edges from dependency trees, but suffer from the imbalance of including and removing contents. When incorporating sequence models, they usually ignored the semantic and syntactic interactions between words. In this paper, we propose to automatically learn relational dependency structures with a fine-grained gating strategy. We decompose the dependency tree into differently informative parts and apply different gating methods to each part. To further capture the word-level interactions, we propose to apply the co-attention mechanism to combine structure and sequence models. We apply a neural network to learn the affinity matrix and derive mutual attention weights between semantic and syntactic representations. We conduct experiments on two benchmark datasets and the results indicate the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Yubo Chen and Chuhan Wu and Yongfeng Huang},
  doi          = {10.1016/j.neucom.2021.10.002},
  journal      = {Neurocomputing},
  pages        = {282-291},
  shortjournal = {Neurocomputing},
  title        = {Enhancing structure modeling for relation extraction with fine-grained gating and co-attention},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel power-exponent-type modified RNN for RMP scheme of
redundant manipulators with noise and physical constraints.
<em>NEUCOM</em>, <em>467</em>, 266–281. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Noise and physical constraints of redundant manipulators are the two major challenges in the repetitive motion planning (RMP) problems. Therefore, this paper proposed a power-exponent-type modified recurrent neural network (PET-MRNN) to simultaneously address both noise and physical constraints. Moreover, PET-MRNN model is activated by a new Sbp-sinh type nonlinear activation function proposed in this paper. The Sbp-sinh type activation function is first applied to such time varying quadratic program (TVQP) solving and possesses excellent convergence performance. Theoretical analysis proves that the PET-MRNN model can completely eliminate noise disturbance through learning and compensation during the convergence process , and then converge the residual error to zero and obtain the theoretical solution. Finally, simulation and experiments further proved the superiority of the PET-MRNN and the Sbp-sinh type activation function.},
  archive      = {J_NEUCOM},
  author       = {Yuchuang Tong and Jinguo Liu},
  doi          = {10.1016/j.neucom.2021.09.047},
  journal      = {Neurocomputing},
  pages        = {266-281},
  shortjournal = {Neurocomputing},
  title        = {Novel power-exponent-type modified RNN for RMP scheme of redundant manipulators with noise and physical constraints},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Practical multi-party private collaborative k-means
clustering. <em>NEUCOM</em>, <em>467</em>, 256–265. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {k-means clustering is widely used in many fields such as data mining, machine learning , and information retrieval. In many cases, users need to cooperate to perform k-means clustering tasks . How to perform clustering without revealing privacy has become a hot research topic. However, the existing k-means scheme based on secure multi-party computation cannot effectively protect the privacy of the output results. The multi-party k-means scheme based on differential privacy may lead to loss of data availability. In this article, we propose a practical protocol for k-means clustering in a collaborative manner, while protecting the privacy of each data record. Our protocol is the first to combine secure multi-party computing and differential privacy technology to train a privacy-preserving k-means clustering model. We design a novel algorithm, which is suitable for multi-party collaboration to update cluster centers without leaking data privacy. The algorithm guarantees that noise is added only once in each iteration, regardless of the number of participants. The protocol achieve the ”best of both worlds”, which can simultaneously achieves both the input privacy and the output privacy in the k-means clustering scheme . Evaluation of real data sets shows that our scheme has comparable running time compared with the k-means clustering scheme without privacy protection.},
  archive      = {J_NEUCOM},
  author       = {En Zhang and Huimin Li and Yuchen Huang and Shuangxi Hong and Le Zhao and Congmin Ji},
  doi          = {10.1016/j.neucom.2021.09.050},
  journal      = {Neurocomputing},
  pages        = {256-265},
  shortjournal = {Neurocomputing},
  title        = {Practical multi-party private collaborative k-means clustering},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Single image rain removal using recurrent scale-guide
networks. <em>NEUCOM</em>, <em>467</em>, 242–255. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, removing rain streaks from a single image has attracted a lot of attention because rain streaks can severely degrade the perceptual quality of the image and cause many practical vision systems to fail. Single image deraining can be served as a pre-processing step to improve the performance of high-level vision tasks such as object detection and video surveillance. In this paper, we propose recurrent scale-guide networks for single image deraining. Although the multi-scale strategy has been successfully applied to many computer vision problems, the correlation between different scales has not been explored in most existing methods. To overcome this deficiency, we propose two types of scale-guide blocks and develop two combinations between the blocks. One type of scale-guide block is that small scale guides the large, and the other is that large scale guides the small. Moreover, we extend the single-stage deraining model to the multi-stage recurrent framework and introduce the Long Short-Term Memory (LSTM) to link every stage. Extensive experiments verify that the scale-guide manner boosts the deraining performance and the recurrent style improves the deraining results. Experimental results demonstrate that the proposed method outperforms other state-of-the-art deraining methods on three widely used datasets: Rain100H, Rain100L, and Rain1200. The source codes can be found at https://supercong94.wixsite.com/supercong94 .},
  archive      = {J_NEUCOM},
  author       = {Cong Wang and Honghe Zhu and Wanshu Fan and Xiao-Ming Wu and Junyang Chen},
  doi          = {10.1016/j.neucom.2021.10.029},
  journal      = {Neurocomputing},
  pages        = {242-255},
  shortjournal = {Neurocomputing},
  title        = {Single image rain removal using recurrent scale-guide networks},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-domain person re-identification with pose-invariant
feature decomposition and hypergraph structure alignment.
<em>NEUCOM</em>, <em>467</em>, 229–241. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person Re-identification (Re-ID) has attracted more and more attention thanks to its great practical value in the field of video surveillance. Most works have focused on solving the problem of supervised Re-ID on a single domain and made significant progress. However, the cross-domain Re-ID is still challenging due to the domain bias between the source and target domains. To this end, we propose a dictionary learning algorithm based on matrix factorization to eliminate the influence of style and pedestrian pose information on the cross-domain Re-ID. Specifically, the proposed approach includes two novel parts: (1) the original visual feature is decomposed into pose-invariant feature space, camera-style feature space and residual feature space to extract discriminant pose-invariant feature that is not affected by style and pedestrian pose information, such that the influence of interference information between pedestrians on recognition can be eliminated; (2) considering the domain-invariance of attribute, a hypergraph structure alignment is introduced to integrate pose-invariant feature, attribute and pedestrian identity into a dictionary learning framework. The relationship between pose-invariant feature and attribute is built so that the pedestrian attribute of the target dataset can be accurately predicted during testing. Finally, the pedestrian similarity measurement can be carried out by combining the pose-invariant feature and attribute of pedestrians. The effectiveness of the proposed algorithm is verified with the experiments on several benchmark Re-ID datasets.},
  archive      = {J_NEUCOM},
  author       = {Shuanglin Yan and Yafei Zhang and Minghong Xie and Dacheng Zhang and Zhengtao Yu},
  doi          = {10.1016/j.neucom.2021.09.054},
  journal      = {Neurocomputing},
  pages        = {229-241},
  shortjournal = {Neurocomputing},
  title        = {Cross-domain person re-identification with pose-invariant feature decomposition and hypergraph structure alignment},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stock movement prediction via gated recurrent unit network
based on reinforcement learning with incorporated attention mechanisms.
<em>NEUCOM</em>, <em>467</em>, 214–228. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent advances usually mine market information from the chaotic data to conduct a stock movement prediction task. However, the current stock price movement prediction approaches mainly compute attention weighted sum of the global contextual semantic embeddings , which fails to combine local word-level or char-level ones to jointly learn news-level representation. Moreover, for Chinese stock price movement prediction task, some collected news texts are chaotic even irrelevant to the target stock. It suggests that the models need filter some news-level representations (viewed as noises) to enhance the performance. To that aim, we develop a novel stock price movement prediction network via bidirectional gated recurrent unit (GRU) network based on reinforcement learning (RL) with incorporated attention mechanism . In specific, to reduce the noise of news texts and learn news-level representation with more abundant semantics, two novel attention mechanisms respectively based on add and dot operation were first proposed in this work. We then design a novel GRU structure based on RL to filter some irrelated news-level representations (i.e., news-level noises) and capture abundant long-term dependencies. Finally, the experimental results show that the proposed model far outperforms the recent advances and achieves state-of-the-art performances.},
  archive      = {J_NEUCOM},
  author       = {Hongfeng Xu and Lei Chai and Zhiming Luo and Shaozi Li},
  doi          = {10.1016/j.neucom.2021.09.072},
  journal      = {Neurocomputing},
  pages        = {214-228},
  shortjournal = {Neurocomputing},
  title        = {Stock movement prediction via gated recurrent unit network based on reinforcement learning with incorporated attention mechanisms},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An accurate and practical algorithm for internet traffic
recovery problem. <em>NEUCOM</em>, <em>467</em>, 203–213. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is challenging to recover the large-scale internet traffic data purely from the link-load measurements. With the rapid growth of the problem scale, it will be extremely difficult to sustain the recovery accuracy and the computational cost simultaneously. For the purpose of fast and accurately recovering the traffic data from link-load measurements, we establish a new Sparsity Low-Rank Recovery (SLRR) model based on the intrinsic properties of traffic data and propose an improved Schur Complement Based semi-proximal Alternating Direction Method of Multipliers (SCB-spADMM) to solve the SLRR model. The main contribution lies in the following two aspects. First, we fully exploit the spatial low-rank property and the sparsity of traffic data, which are barely considered in the literature. The model only relates to the traffics in a certain individual time interval. Thus, the scale of the problem is significantly reduced. Second, the global convergence of the proposed ADMM-type algorithm is established and all the intermediate variables’ optimums can be calculated analytically in each iteration. According to the numerical results on the classic datasets Abilene and GÉANT, our method achieves the best accuracy with a low computational cost. Moreover, in our newly released large-scale real-life network traffic dataset HOD, our method perfectly reaches the seconds-level feedback, which meets the essential requirement for practical scenarios.},
  archive      = {J_NEUCOM},
  author       = {Zhenyu Ming and Liping Zhang and Hao Wu and Yanwei Xu and Mayank Bakshi and Bo Bai and Gong Zhang},
  doi          = {10.1016/j.neucom.2021.09.065},
  journal      = {Neurocomputing},
  pages        = {203-213},
  shortjournal = {Neurocomputing},
  title        = {An accurate and practical algorithm for internet traffic recovery problem},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TSPred: A framework for nonstationary time series
prediction. <em>NEUCOM</em>, <em>467</em>, 197–202. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonstationary time series prediction is challenging since it demands knowledge of both data transformation and prediction methods. This paper presents TSPred, a framework for nonstationary time series prediction. It differs from the mainstream frameworks since it establishes a prediction process that seamlessly integrates nonstationary time series transformations with state-of-the-art statistical and machine learning methods. It is made available as an R-package, which provides functions for defining and conducting time series prediction, including data pre(post) processing, decomposition, modeling, prediction, and accuracy assessment. Besides, TSPred enables user-defined methods, which significantly expands the applicability of the framework.},
  archive      = {J_NEUCOM},
  author       = {Rebecca Salles and Esther Pacitti and Eduardo Bezerra and Fabio Porto and Eduardo Ogasawara},
  doi          = {10.1016/j.neucom.2021.09.067},
  journal      = {Neurocomputing},
  pages        = {197-202},
  shortjournal = {Neurocomputing},
  title        = {TSPred: A framework for nonstationary time series prediction},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic subspace dual-graph regularized multi-label feature
selection. <em>NEUCOM</em>, <em>467</em>, 184–196. (<a
href="https://doi.org/10.1016/j.neucom.2021.10.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label learning, feature selection is a topical issue for addressing high-dimension data. However, most of existing methods adopt imperfect labels to perform feature selection. Although some graph-based multi-label feature selection methods are proposed to deal with the problem, they adopt the fixed graph Laplacian matrix so that the performances of these models are under-performing. To this end, this paper proposes a Dynamic Subspace dual-graph regularized Multi-label Feature Selection method named DSMFS. DSMFS decomposes the original label space into a low-dimensional subspace, and then both the dynamic label-level subspace graph and the feature-level graph are used to obtain a high-quality label subspace to conduct feature selection process. Seven state-of-the-art methods are compared to the proposed method on twelve multi-label benchmark data sets in the experiments. Experimental results demonstrate the superiority of DSMFS.},
  archive      = {J_NEUCOM},
  author       = {Juncheng Hu and Yonghao Li and Gaochao Xu and Wanfu Gao},
  doi          = {10.1016/j.neucom.2021.10.022},
  journal      = {Neurocomputing},
  pages        = {184-196},
  shortjournal = {Neurocomputing},
  title        = {Dynamic subspace dual-graph regularized multi-label feature selection},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Grammatical structure detection by instinct plasticity
based echo state networks with genetic algorithm. <em>NEUCOM</em>,
<em>467</em>, 173–183. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel model called Instinct Plasticity Echo State Network with New Weights Selection Method, which is Optimized by Genetic Algorithm, is proposed (IP-NESN-GA). There are three proposed methods that are employed in the conventional ESN. New weights selection method provides a novel approach to replace the random weights of ESN, which obtains much better performance than the conventional ESN. At the same time, Instinct Plasticity is successfully applied in ESN, which enhances the connection among reservoir states and increase the accuracy. Finally, Genetic Algorithm is applied to seek the most suitable parameters. The detecting ability of our proposed model is assessed on two kinds of distinct grammatical constructions data. It not only performs significantly better than the baselines in the meaning error and sentence error, but it also visualizes the expected probabilities for each of the possible thematic roles.},
  archive      = {J_NEUCOM},
  author       = {Zongying Liu and Shaoxi Li and Mingyang Pan and Chu Kiong Loo},
  doi          = {10.1016/j.neucom.2021.09.073},
  journal      = {Neurocomputing},
  pages        = {173-183},
  shortjournal = {Neurocomputing},
  title        = {Grammatical structure detection by instinct plasticity based echo state networks with genetic algorithm},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generative synthesis of logos across DCT domain.
<em>NEUCOM</em>, <em>467</em>, 163–172. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative learning in pixel domain has achieved great success in exploiting their correlations in processing images towards desired objectives, yet learning in frequency domain could provide added benefits in exploiting pixel correlations without worrying about their spatial locations and increasing their modeling costs. In this paper, we analyze the spectral bias from a frequency perspective to overcome such limitations and hence propose a dynamic self-adaptive optimization on GAN-based generative learning, leading to a dynamic and generative logo synthesis in DCT domain. To achieve exploitation of all the pixel correlations inside the whole image regardless of their spatial locations , we introduce an approximated DCT transformation and decompose both the input images and the generated images into relatively independent DCT frequency bands. As a result, a new channel of DCT domain generative learning can be established to support the existing pixel domain learning towards improved logo synthesis. Since learning across different frequency band constantly varies, we further propose a dynamic optimization scheme to maximize the effectiveness of contributions from each individual DCT frequency band. Extensive experiments are carried out and the results in comparison with the existing state of the arts illustrate that our proposed achieves significant superiority in terms of both synthesized logo quality, integrity and variety.},
  archive      = {J_NEUCOM},
  author       = {Lisha Dong and Yu Zhou and Jianmin Jiang},
  doi          = {10.1016/j.neucom.2021.09.068},
  journal      = {Neurocomputing},
  pages        = {163-172},
  shortjournal = {Neurocomputing},
  title        = {Generative synthesis of logos across DCT domain},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-label enhancement based self-supervised deep
cross-modal hashing. <em>NEUCOM</em>, <em>467</em>, 138–162. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep cross-modal hashing which integrates deep learning and hashing into cross-modal retrieval, achieves better performance than traditional cross-modal retrieval methods . Nevertheless, most previous deep cross-modal hashing methods only utilize single-class labels to compute the semantic affinity across modalities but overlook the existence of multiple category labels, which can capture the semantic affinity more accurately. Additionally, almost all existing cross-modal hashing methods straightforwardly employ all modalities to learn hash functions but neglect the fact that original instances in all modalities may contain noise. To avoid the above weaknesses, in this paper, a novel multi-label enhancement based self-supervised deep cross-modal hashing (MESDCH) approach is proposed. MESDCH first propose a multi-label semantic affinity preserving module, which uses ReLU transformation to unify the similarities of learned hash representations and the corresponding multi-label semantic affinity of original instances and defines a positive-constraint Kullback–Leibler loss function to preserve their similarity. Then this module is integrated into a self-supervised semantic generation module to further enhance the performance of deep cross-modal hashing. Extensive evaluation experiments on four well-known datasets demonstrate that the proposed MESDCH achieves state-of-the-art performance and outperforms several excellent baseline methods in the application of cross-modal hashing retrieval. Code is available at: https://github.com/SWU-CS-MediaLab/MESDCH.},
  archive      = {J_NEUCOM},
  author       = {Xitao Zou and Song Wu and Erwin M. Bakker and Xinzhi Wang},
  doi          = {10.1016/j.neucom.2021.09.053},
  journal      = {Neurocomputing},
  pages        = {138-162},
  shortjournal = {Neurocomputing},
  title        = {Multi-label enhancement based self-supervised deep cross-modal hashing},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodal sentiment analysis with unidirectional modality
translation. <em>NEUCOM</em>, <em>467</em>, 130–137. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Sentiment Analysis (MSA) is a challenging research area that investigates sentiment expressed from multiple heterogeneous sources of information. To integrate multimodal information including text, visual and audio modalities, state-of-the-art models focus on developing various fusion strategies, such as attention and outer product. However, the inferior quality of visual and audio features that is commonly observed in this area has not aroused much attention. We argue that this issue will obstruct the performance of the fusion strategies to a considerable extent. Therefore, in this paper, we propose Multimodal Translation for Sentiment Analysis (MTSA), a multimodal framework that improves the quality of visual and audio features by translating them to text features extracted by Bidirectional Encoder Representations from Transformers (BERT). Experiments on two benchmark datasets CMU-MOSI and CMU-MOSEI show that our model performs better than the state-of-the-art methods on both datasets across all the metrics, which illustrates the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Bo Yang and Bo Shao and Lijun Wu and Xiaola Lin},
  doi          = {10.1016/j.neucom.2021.09.041},
  journal      = {Neurocomputing},
  pages        = {130-137},
  shortjournal = {Neurocomputing},
  title        = {Multimodal sentiment analysis with unidirectional modality translation},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-reservoir echo state networks with sequence resampling
for nonlinear time-series prediction. <em>NEUCOM</em>, <em>467</em>,
115–129. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider various schemes of sequence resampling in reservoir computing models for nonlinear time series prediction. These schemes can enrich the features used for training the readout part with batch learning and lead to better prediction performance. To implement these schemes, first, we introduce a modular approach for constructing multi-reservoir ESN models by assembling encoding and decoding modules. The encoding module is composed of a resampling unit, a group-wise reservoir unit, and a collection unit, for extracting various features from a sequence. The decoding module is a linear regressor which is trainable to produce desired outputs. Then, we propose three novel multi-reservoir ESN models, DeepESN with Every-layer Sequence Resampling (DeepESN-ESR), DeepESN with Last-layer Sequence Resampling (DeepESN-LSR), and GroupedESN with Input-layer Sequence Resampling (GroupedESN-ISR). These three models provide demonstrations of sequence resampling on multi-reservoir ESN models. Numerical results on five challenging nonlinear time-series prediction tasks show that the proposed models outperform some state-of-the-art multi-reservoir ESN models. An evaluation of computational time shows that our proposed three models require less computational cost for learning than many existing multi-reservoir ESN models in practice. Moreover, a comprehensive comparative analysis reveals that our proposed models are able to memorize longer temporal information and generate richer dynamics from the reservoir states than some existing models. The proposed schemes for extracting various features hidden in a sequence of reservoir states can be widely leveraged in other reservoir computing systems for improving their performance in nonlinear time series prediction.},
  archive      = {J_NEUCOM},
  author       = {Ziqiang Li and Gouhei Tanaka},
  doi          = {10.1016/j.neucom.2021.08.122},
  journal      = {Neurocomputing},
  pages        = {115-129},
  shortjournal = {Neurocomputing},
  title        = {Multi-reservoir echo state networks with sequence resampling for nonlinear time-series prediction},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022d). Cross-modality synergy network for referring expression
comprehension and segmentation. <em>NEUCOM</em>, <em>467</em>, 99–114.
(<a href="https://doi.org/10.1016/j.neucom.2021.09.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring expression comprehension and segmentation aim to locate and segment a referred instance in an image according to a natural language expression. However, existing methods tend to ignore the interaction between visual and language modalities for visual feature learning , and establishing a synergy between the visual and language modalities remains a considerable challenge. To tackle the above problems, we propose a novel end-to-end framework, Cross-Modality Synergy Network (CMS-Net), to address the two tasks jointly. In this work, we propose an attention-aware representation learning module to learn modal representations for both images and expressions. A language self-attention submodule is proposed in this module to learn expression representations by leveraging the intra-modality relations, and a language-guided channel-spatial attention submodule is introduced to obtain the language-aware visual representations under language guidance, which helps the model pay more attention to the referent-relevant regions in the images and relieve background interference. Then, we design a cross-modality synergy module to establish the inter-modality relations for modality fusion. Specifically, a language-visual similarity is obtained at each position of the visual feature map, and the synergy is achieved between the two modalities in both semantic and spatial dimensions. Furthermore, we propose a multi-scale feature fusion module with a selective strategy to aggregate the important information from multi-scale features, yielding target results. We conduct extensive experiments on four challenging benchmarks, and our framework achieves significant performance gains over state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Qianzhong Li and Yujia Zhang and Shiying Sun and Jinting Wu and Xiaoguang Zhao and Min Tan},
  doi          = {10.1016/j.neucom.2021.09.066},
  journal      = {Neurocomputing},
  pages        = {99-114},
  shortjournal = {Neurocomputing},
  title        = {Cross-modality synergy network for referring expression comprehension and segmentation},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A generic framework for deep incremental cancelable template
generation. <em>NEUCOM</em>, <em>467</em>, 83–98. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a post-COVID-19 world, extensive study of deep learning-based biometric authentication techniques prompts the need to secure them. Further, the biometric data is assumed to be largely immutable; thus, if it is compromised, it is lost forever. Hence, reliable and secure biometric authentication is of utmost importance. In this paper, we address the security and privacy concerns of biometric templates generated via deep networks. We propose a cancelable biometric authentication approach. The framework consists of a lightweight Convolutional Neural Network (CNN) with a few-shot enrollment for generating biometric templates. Further, to enhance biometric templates’ discriminative power and to provide revocability, biometric templates are projected onto a random subspace (based on the user-specific key). Later projected biometric templates are mapped onto robust n n - bit bit unique codes (using a KNN classifier) and protected via. SHA-3 hash digest. Moreover, a real-world biometric authentication system is always dynamic (users keep on changing). Thus we have also integrated phase-wise incremental learning within a deep learning-based cancelable biometric authentication framework. This is the first work in which deep cancelable templates are generated incrementally to the best of our knowledge. We analyze the proposed scheme for its performance and privacy preservation on three benchmarks constrained iris data-sets and over one unconstrained iris data-set along with one publicly available knuckle data-set. Furthermore, it has been demonstrated that the proposed cancelable incremental framework strictly follows the four fundamental properties of cancelability viz. non-invertibility, unlinkability, revocability, and usability.},
  archive      = {J_NEUCOM},
  author       = {Avantika Singh and Chirag Vashist and Pratyush Gaurav and Aditya Nigam},
  doi          = {10.1016/j.neucom.2021.09.055},
  journal      = {Neurocomputing},
  pages        = {83-98},
  shortjournal = {Neurocomputing},
  title        = {A generic framework for deep incremental cancelable template generation},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BiERU: Bidirectional emotional recurrent unit for
conversational sentiment analysis. <em>NEUCOM</em>, <em>467</em>, 73–82.
(<a href="https://doi.org/10.1016/j.neucom.2021.09.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis in conversations has gained increasing attention in recent years for the growing amount of applications it can serve, e.g., sentiment analysis, recommender systems , and human-robot interaction. The main difference between conversational sentiment analysis and single sentence sentiment analysis is the existence of context information that may influence the sentiment of an utterance in a dialogue. How to effectively encode contextual information in dialogues, however, remains a challenge. Existing approaches employ complicated deep learning structures to distinguish different parties in a conversation and then model the context information. In this paper, we propose a fast, compact and parameter-efficient party-ignorant framework named bidirectional emotional recurrent unit for conversational sentiment analysis. In our system, a generalized neural tensor block followed by a two-channel classifier is designed to perform context compositionality and sentiment classification, respectively. Extensive experiments on three standard datasets demonstrate that our model outperforms the state of the art in most cases.},
  archive      = {J_NEUCOM},
  author       = {Wei Li and Wei Shao and Shaoxiong Ji and Erik Cambria},
  doi          = {10.1016/j.neucom.2021.09.057},
  journal      = {Neurocomputing},
  pages        = {73-82},
  shortjournal = {Neurocomputing},
  title        = {BiERU: Bidirectional emotional recurrent unit for conversational sentiment analysis},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalized correntropy induced metric based total least
squares for sparse system identification. <em>NEUCOM</em>, <em>467</em>,
66–72. (<a href="https://doi.org/10.1016/j.neucom.2021.09.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The total least squares (TLS) method has been successfully applied to system identification in the errors-in-variables (EIV) model, which can efficiently describe systems where input–output pairs are contaminated by noise. In this paper, we propose a new gradient-descent TLS filtering algorithm based on the generalized correntropy induced metric (GCIM), called as GCIM-TLS, for sparse system identification. By introducing GCIM as a penalty term to the TLS problem, we can achieve improved accuracy of sparse system identification. We also characterize the convergence behaviour analytically for GCIM-TLS. To reduce computational complexity , we use the first-order Taylor series expansion and further derive a simplified version of GCIM-TLS. Simulation results verify the effectiveness of our proposed algorithms in sparse system identification.},
  archive      = {J_NEUCOM},
  author       = {Ji Zhao and J. Andrew Zhang and Hongbin Zhang and Qiang Li},
  doi          = {10.1016/j.neucom.2021.09.049},
  journal      = {Neurocomputing},
  pages        = {66-72},
  shortjournal = {Neurocomputing},
  title        = {Generalized correntropy induced metric based total least squares for sparse system identification},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributing DNN training over IoT edge devices based on
transfer learning. <em>NEUCOM</em>, <em>467</em>, 56–65. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an approach for distributing the deep neural network (DNN) training onto IoT edge devices is proposed. The approach results in protecting data privacy on the edge devices and decreasing the load on cloud servers. In addition, the technique may reduce the communication traffic between the cloud and the edge devices. Since the available resources in the edge devices are limited, in the proposed approach, we suggest a heuristic technique for generating a smaller network based on the main network in cloud. Next, by exploiting the knowledge distillation method, the knowledge of the main network is transferred to the generated small network. In this approach, small networks on the edge devices under different datasets are trained where some of their parameters are aggregated for updating the main network parameters on the cloud. The effectiveness of this approach is assessed with some state-of-the-art neural networks. Results show that the approach, the price of preserving the data privacy, is, on average, about 3.5\% accuracy loss compared to the case when the network is trained on the cloud and all the datasets of the edge devices are available for training.},
  archive      = {J_NEUCOM},
  author       = {Ehsan Tanghatari and Mehdi Kamal and Ali Afzali-Kusha and Massoud Pedram},
  doi          = {10.1016/j.neucom.2021.09.045},
  journal      = {Neurocomputing},
  pages        = {56-65},
  shortjournal = {Neurocomputing},
  title        = {Distributing DNN training over IoT edge devices based on transfer learning},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated segmentation of knee articular cartilage: Joint
deep and hand-crafted learning-based framework using diffeomorphic
mapping. <em>NEUCOM</em>, <em>467</em>, 36–55. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of knee articular cartilage tissue (ACT) from 3D magnetic resonance images (MRIs) is a fundamental task in assessing knee osteoarthritis (KOA). However, automated ACT segmentation of knee cartilage is complicated by (1) the variability of pathological structures in terms of shape, size, spatial resolution and (2) the uncertainties in delineating inter- and intra-cartilage boundaries (possibly touching inter-cartilage surfaces, intensity inhomogeneity, cartilage loss due to disease progression). To address these problems, we propose a novel joint deep and hand-crafted learning-based (JD-HCl) framework. The fully automated segmentation pipeline is a combination of three main steps: 3D convolutional neural networks (CNNs), diffeomorphic mapping, and a conventional hand-crafted feature-based classification model. Firstly, the initial segmentation of knee ACT was drawn from preprocessed knee MRIs using 3D U-Net. Secondly, the spatial alignment in the image domain was carried out using diffeomorphic image registration derived from an estimate of the anatomical correspondences between the subjects and population-specific template. Finally, a tissue-specific hand-crafted feature set was extracted from the spatially aligned pre-segmented ACT region and combined with the semantic context priors obtained from 3D CNN model to develop the second-stage learning model. The proposed method was evaluated with two publicly available Osteoarthritis Initiative (OAI) datasets and one in-house MRI sequences from the Alfred hospital, Melbourne, Australia. The proposed JD-HCl framework produced strong Dice similarity coefficient (DSC), ranging between 97.4\% and 98.5\% (95\% confidence interval) for all cartilage compartments at baseline to 97.2\% and 98.5\% (the 1-year follow-up) for OAI(-Imorphics) dataset, and 89.3\% and 94.6\% for OAI-ZIB validation dataset, respectively. Average correlations of cartilage volumes between manual and automatic segmentations were 0.9 and 0.83 for OAI-ZIB dataset, respectively, and 0.975, 0.995, and 0.99 for OAI(-Imorphics) validation datasets, respectively. In longitudinal studies, accurate segmentation of knee ACT using the proposed method produces reproducible cartilage volume, thickness measurements valuable for the study of KOA progression.},
  archive      = {J_NEUCOM},
  author       = {Somayeh Ebrahimkhani and Anuja Dharmaratne and Mohamed Hisham Jaward and Yuanyuan Wang and Flavia M. Cicuttini},
  doi          = {10.1016/j.neucom.2021.09.048},
  journal      = {Neurocomputing},
  pages        = {36-55},
  shortjournal = {Neurocomputing},
  title        = {Automated segmentation of knee articular cartilage: Joint deep and hand-crafted learning-based framework using diffeomorphic mapping},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DeepAVO: Efficient pose refining with feature distilling for
deep visual odometry. <em>NEUCOM</em>, <em>467</em>, 22–35. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The technology for Visual Odometry (VO) that estimates the position and orientation of the moving object through analyzing the image sequences captured by on-board cameras, has been well investigated with the rising interest in autonomous driving . This paper studies monocular VO from the perspective of Deep Learning (DL). Unlike most current learning-based methods, our approach, called DeepAVO, is established on the intuition that features contribute discriminately to different motion patterns. Specifically, we present a novel four-branch network to learn the rotation and translation by leveraging Convolutional Neural Networks (CNNs) to focus on different quadrants of optical flow input. To enhance the ability of feature selection, we further introduce an effective channel-spatial attention mechanism to force each branch to explicitly distill related information for specific Frame to Frame (F2F) motion estimation. Experiments on various datasets involving outdoor driving and indoor walking scenarios show that the proposed DeepAVO outperforms the state-of-the-art monocular methods by a large margin, demonstrating competitive performance to the stereo VO algorithm and verifying promising potential for generalization.},
  archive      = {J_NEUCOM},
  author       = {Ran Zhu and Mingkun Yang and Wang Liu and Rujun Song and Bo Yan and Zhuoling Xiao},
  doi          = {10.1016/j.neucom.2021.09.029},
  journal      = {Neurocomputing},
  pages        = {22-35},
  shortjournal = {Neurocomputing},
  title        = {DeepAVO: Efficient pose refining with feature distilling for deep visual odometry},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Model-data-driven image reconstruction with neural networks
for ultrasound computed tomography breast imaging. <em>NEUCOM</em>,
<em>467</em>, 10–21. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the goal of developing an accurate and fast image reconstruction algorithm for ultrasound computed tomography , we combine elements of model- and data-driven approaches and propose a learned method which addresses the disadvantages of both approaches. We design a deep neural network which accounts for a nonlinear forward operator and primal-dual algorithm by its inherent network architecture . The network is trained end-to-end, with ultrasound pressure field data as input to get directly an optimized reconstruction of speed of sound and attenuation images. The training and test data are based on a set of Optical and Acoustic Breast Phantom Database , where we use the image as ground truth and simulate pressure field data according to our forward model. Extensive experiments show that our method achieves significant improvements over state-of-the-art reconstruction methods in this field. Experiments show that the proposed algorithm improves the measures structural similarity measure (SSIM) from 0.74 to 0.95 and root mean squared error (RMSE) from 0.13 to 0.09 on average concerning the speed of sound reconstruction, while it improves the SSIM from 0.60 to 0.94 and RMSE from 0.24 to 0.10 on average in attenuation reconstruction.},
  archive      = {J_NEUCOM},
  author       = {Yuling Fan and Hongjian Wang and Hartmut Gemmeke and Torsten Hopp and Juergen Hesser},
  doi          = {10.1016/j.neucom.2021.09.035},
  journal      = {Neurocomputing},
  pages        = {10-21},
  shortjournal = {Neurocomputing},
  title        = {Model-data-driven image reconstruction with neural networks for ultrasound computed tomography breast imaging},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Video summarization with a dual-path attentive network.
<em>NEUCOM</em>, <em>467</em>, 1–9. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of videos captured everyday, how to efficiently extract useful information from videos has become a more and more important problem. As one of the most effective methods, video summarization aiming to extract the most important frames or shots has attracted more interests recently. Currently, lots of methods employ a recurrent structure . However, due to its step-by-step characteristic, it is difficult to parallelize these models. To address this problem, we propose a dual-path attentive video summarization framework consisting of a temporal spatial encoder, a score-aware encoder and a decoder. And all of them are mainly based on multi-head self-attention and convolutional block attention module. The temporal spatial encoder is to capture the temporal and spatial information while the score-aware encoder incorporates the appearance features with previously predicted frame-level importance scores. By combining the scores and appearance features, our model can better capture the long-range global dependencies and update the importance scores of previous frames continuously. Moreover, entirely based on attention mechanism , our model can be trained in full parallel, which leads to less training time. To validate the method, we employ the two popular datasets SumMe and TVSum. The experimental results show the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Guoqiang Liang and Yanbing Lv and Shucheng Li and Xiahong Wang and Yanning Zhang},
  doi          = {10.1016/j.neucom.2021.09.015},
  journal      = {Neurocomputing},
  pages        = {1-9},
  shortjournal = {Neurocomputing},
  title        = {Video summarization with a dual-path attentive network},
  volume       = {467},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
