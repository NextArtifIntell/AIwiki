<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIJ_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aij---112">AIJ - 112</h2>
<ul>
<li><details>
<summary>
(2022). Convolutional spectral kernel learning with generalization
guarantees. <em>AIJ</em>, <em>313</em>, 103803. (<a
href="https://doi.org/10.1016/j.artint.2022.103803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel methods are powerful tools to capture nonlinear patterns behind given data but often lead to poor performance on complicated tasks compared to convolutional neural networks . The reason is that kernel methods are still shallow and fully connected models, failing to reveal hierarchical features and local interdependencies . In this paper, to acquire hierarchical and local knowledge, we incorporate kernel methods with deep architectures and convolutional operators in a spectral kernel learning framework. Based on the inverse Fourier transform and Rademacher complexity theory , we provide the generalization error bounds for the proposed model and prove that under suitable initialization, deeper networks lead to tighter error bounds. Inspired by theoretical findings, we finally completed the convolutional spectral kernel network ( CSKN ) with two additional regularizers and an initialization strategy. Extensive ablation results validate the effectiveness of non-stationary spectral kernel, multiple layers, additional regularizers, and the convolutional filters , which coincide with our theoretical findings. We further devise a VGG-type 8-layers CSKN , and it outperforms the existing kernel-based networks and popular CNN models on the medium-sized image classification tasks.},
  archive      = {J_AIJ},
  author       = {Jian Li and Yong Liu and Weiping Wang},
  doi          = {10.1016/j.artint.2022.103803},
  journal      = {Artificial Intelligence},
  pages        = {103803},
  shortjournal = {Artif. Intell.},
  title        = {Convolutional spectral kernel learning with generalization guarantees},
  volume       = {313},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The metric distortion of multiwinner voting. <em>AIJ</em>,
<em>313</em>, 103802. (<a
href="https://doi.org/10.1016/j.artint.2022.103802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We extend the recently introduced framework of metric distortion to multiwinner voting. In this framework, n agents and m alternatives are located in an underlying metric space. The exact distances between agents and alternatives are unknown. Instead, each agent provides a ranking of the alternatives, ordered from the closest to the farthest. Typically, the goal is to select a single alternative that approximately minimizes the total distance from the agents, and the worst-case approximation ratio is termed distortion. In the case of multiwinner voting, the goal is to select a committee of k alternatives that (approximately) minimizes the total cost to all agents. We consider the scenario where the cost of an agent for a committee is her distance from the q -th closest alternative in the committee. We reveal a surprising trichotomy on the distortion of multiwinner voting rules in terms of k and q : The distortion is unbounded when q ⩽ k / 3 q⩽k/3 , asymptotically linear in the number of agents when k / 3 k/3&amp;lt; q⩽k/2 , and constant when q &gt; k / 2 q&amp;gt; k/2 .},
  archive      = {J_AIJ},
  author       = {Ioannis Caragiannis and Nisarg Shah and Alexandros A. Voudouris},
  doi          = {10.1016/j.artint.2022.103802},
  journal      = {Artificial Intelligence},
  pages        = {103802},
  shortjournal = {Artif. Intell.},
  title        = {The metric distortion of multiwinner voting},
  volume       = {313},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reasoning about general preference relations. <em>AIJ</em>,
<em>313</em>, 103793. (<a
href="https://doi.org/10.1016/j.artint.2022.103793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preference relations are at the heart of many fundamental concepts in artificial intelligence , ranging from utility comparisons, to defeat among strategies and relative plausibility among states, just to mention a few. Reasoning about such relations has been the object of extensive research and a wealth of formalisms exist to express and reason about them. One such formalism is conditional logic , which focuses on reasoning about the “best” alternatives according to a given preference relation. A “best” alternative is normally interpreted as an alternative that is either maximal (no other alternative is preferred to it) or optimal (it is at least as preferred as all other alternatives). And the preference relation is normally assumed to satisfy strong requirements (typically transitivity and some kind of well-foundedness assumption). Here, we generalize this existing literature in two ways. Firstly, in addition to maximality and optimality , we consider two other interpretations of “best”, which we call unmatchedness and acceptability. Secondly, we do not inherently require the preference relation to satisfy any constraints. Instead, we allow the relation to satisfy any combination of transitivity, totality and anti-symmetry. This allows us to model a wide range of situations, including cases where the lack of constraints stems from a modeled agent being irrational (for example, an agent might have preferences that are neither transitive nor total nor anti-symmetric) or from the interaction of perfectly rational agents (for example, a defeat relation among strategies in a game might be anti-symmetric but not total or transitive). For each interpretation of “best” (maximal, optimal, unmatched or acceptable) and each combination of constraints (transitivity, totality and/or anti-symmetry), we study the sets of valid inferences. Specifically, in all but one case we introduce a sound and strongly complete axiomatization , and in the one remaining case we show that no such axiomatization exists.},
  archive      = {J_AIJ},
  author       = {Davide Grossi and Wiebe van der Hoek and Louwe B. Kuijer},
  doi          = {10.1016/j.artint.2022.103793},
  journal      = {Artificial Intelligence},
  pages        = {103793},
  shortjournal = {Artif. Intell.},
  title        = {Reasoning about general preference relations},
  volume       = {313},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Measuring power in coalitional games with friends, enemies
and allies. <em>AIJ</em>, <em>313</em>, 103792. (<a
href="https://doi.org/10.1016/j.artint.2022.103792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We extend the well-known model of graph-restricted games due to Myerson to signed graphs. In our model, it is possible to explicitly define not only that some players are friends (as in Myerson&#39;s model) but also that some other players are enemies. As such our games can express a wider range of situations, e.g., animosities between political parties. We define the value for signed graph games using the axiomatic approach that closely follows the celebrated characterization of the Myerson value. Furthermore, we propose an algorithm for computing an arbitrary semivalue, including the extension of the Myerson value proposed by us. We also develop a pseudo-polynomial algorithm for power indices in weighted voting games for signed graphs with bounded treewidth. Moreover, we consider signed graph games with a priori defined alliances (unions) between players and propose algorithms to compute the extension of the Owen value to this setting.},
  archive      = {J_AIJ},
  author       = {Oskar Skibski and Takamasa Suzuki and Tomasz Grabowski and Yuko Sakurai and Tomasz Michalak and Makoto Yokoo},
  doi          = {10.1016/j.artint.2022.103792},
  journal      = {Artificial Intelligence},
  pages        = {103792},
  shortjournal = {Artif. Intell.},
  title        = {Measuring power in coalitional games with friends, enemies and allies},
  volume       = {313},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Defense coordination in security games: Equilibrium analysis
and mechanism design. <em>AIJ</em>, <em>313</em>, 103791. (<a
href="https://doi.org/10.1016/j.artint.2022.103791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world security scenarios sometimes involve multiple defenders: security agencies of two or more countries might patrol the same border areas, and domestic security agencies might also operate in the same locations when their areas of jurisdiction overlap. Motivated by these scenarios and the observation that uncoordinated movements of the defenders may lead to an inefficient defense, we introduce a model of multi-defender security games and explore the possibility of improving efficiency by coordinating the defenders — specifically, by pooling the defenders&#39; resources and allocating them jointly. The model generalizes the standard model of Stackelberg security games, where a defender (now a group of defenders) allocates security resources to protect a set of targets, and an attacker picks the best target to attack. In particular, we are interested in the situation with heterogeneous defenders, who may value the same target differently. Our task is twofold. First, we need to develop a good understanding of the uncoordinated situation, as the baseline to be improved. To this end we formulate a new equilibrium concept, and prove that an equilibrium under this concept always exists and can be computed efficiently. Second, to coordinate the heterogeneous defenders we take a mechanism design perspective and aim to find a mechanism to generate joint resource allocation strategies. We seek a mechanism that improves the defenders&#39; utilities upon the uncoordinated baseline, achieves Pareto efficiency, and incentivizes the defenders to report their true incentives and execute the recommended strategies. Our analysis establishes several impossibility results, which indicate the intrinsic difficulties of defense coordination. Specifically, we show that even the basic properties listed above are in conflict with each other: no mechanism can simultaneously satisfy them all, or even some proper subsets of them. In terms of positive results, we present mechanisms that satisfy all combinations of the properties that are not ruled out by our impossibility results, thereby providing a comprehensive profile of the mechanism design problem with respect to the properties considered.},
  archive      = {J_AIJ},
  author       = {Jiarui Gan and Edith Elkind and Sarit Kraus and Michael Wooldridge},
  doi          = {10.1016/j.artint.2022.103791},
  journal      = {Artificial Intelligence},
  pages        = {103791},
  shortjournal = {Artif. Intell.},
  title        = {Defense coordination in security games: Equilibrium analysis and mechanism design},
  volume       = {313},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Actions of the hyperoctahedral group to compute minimal
contractors. <em>AIJ</em>, <em>313</em>, 103790. (<a
href="https://doi.org/10.1016/j.artint.2022.103790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hyperoctahedral group B n Bn is the group of symmetries of the hypercube [ − 1 , 1 ] n [−1, 1]n of R n Rn . For instance permutations, or symmetries along each of the n canonical planes of R n Rn all belong to B n Bn . Now, many sets of equations contain symmetries in B n Bn . This is the case of the addition constraint: x 1 + x 2 = x 3 x1+x2=x3 or the multiplication x 1 ⋅ x 2 = x 3 x1⋅x2=x3 . In robotics, many specific geometrical constraints such as for instance constraints involving distances or angles used for localization also have these symmetries. This paper shows the fundamental role of the hyperoctahedral group for interval-based methods. These methods use operators, called contractors , which contract axis-aligned boxes, without removing any point of the solution set defined by a conjunction of constraints (typically equations, or inequalities). More precisely, the paper presents an algorithm which allows us to build minimal contractors associated to constraints with symmetries in B n Bn . As an application, we will consider the geometrical constraint associated to the angle between vectors. The corresponding contractor will then be used in a constraint propagation framework in order to localize a robot using several radars.},
  archive      = {J_AIJ},
  author       = {Luc Jaulin},
  doi          = {10.1016/j.artint.2022.103790},
  journal      = {Artificial Intelligence},
  pages        = {103790},
  shortjournal = {Artif. Intell.},
  title        = {Actions of the hyperoctahedral group to compute minimal contractors},
  volume       = {313},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gradient-based mixed planning with symbolic and numeric
action parameters. <em>AIJ</em>, <em>313</em>, 103789. (<a
href="https://doi.org/10.1016/j.artint.2022.103789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dealing with planning problems with both logical relations and numeric changes in real-world dynamic environments is challenging. Existing numeric planning systems for the problem often discretize numeric variables or impose convex constraints on numeric variables, which harms the performance when solving problems. In this paper, we propose a novel algorithm framework to solve numeric planning problems mixed with logical relations and numeric changes based on gradient descent . We cast the numeric planning with logical relations and numeric changes as an optimization problem . Specifically, we extend syntax to allow parameters of action models to be either objects or real-valued numbers, which enhances the ability to model real-world numeric effects. Based on the extended modeling language , we propose a gradient-based framework to simultaneously optimize numeric parameters and compute appropriate actions to form candidate plans. The gradient-based framework is composed of an algorithmic heuristic module based on propositional operations to select actions and generate constraints for gradient descent , an algorithmic transition module to update states to next ones, and a loss module to compute loss. We repeatedly minimize loss by updating numeric parameters and compute candidate plans until it converges into a valid plan for the planning problem. In the empirical study, we exhibit that our algorithm framework is both effective and efficient in solving planning problems mixed with logical relations and numeric changes, especially when the problems contain obstacles and non-linear numeric effects.},
  archive      = {J_AIJ},
  author       = {Kebing Jin and Hankz Hankui Zhuo and Zhanhao Xiao and Hai Wan and Subbarao Kambhampati},
  doi          = {10.1016/j.artint.2022.103789},
  journal      = {Artificial Intelligence},
  pages        = {103789},
  shortjournal = {Artif. Intell.},
  title        = {Gradient-based mixed planning with symbolic and numeric action parameters},
  volume       = {313},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards convergence rate analysis of random forests for
classification. <em>AIJ</em>, <em>313</em>, 103788. (<a
href="https://doi.org/10.1016/j.artint.2022.103788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random forests have been one of the successful ensemble algorithms in machine learning , and the basic idea is to construct a large number of random trees individually and make predictions based on an average of their predictions. The great successes have attracted much attention on theoretical understandings of random forests, mostly focusing on regression problems . This work takes one step towards the convergence rates of random forests for classification. We present the first finite-sample rate O ( n − 1 / ( 8 d + 2 ) ) O(n−1/(8d+2)) on the convergence of purely random forests for binary classification , which can be improved to be of O ( n − 1 / ( 3.87 d + 2 ) ) O(n−1/(3.87d+2)) by considering the midpoint splitting mechanism. We introduce another variant of random forests, which follows Breiman&#39;s original random forests but with different mechanisms on splitting dimensions and positions. We present the convergence rate O ( n − 1 / ( d + 2 ) ( ln ⁡ n ) 1 / ( d + 2 ) ) O(n−1/(d+2)(ln⁡n)1/(d+2)) for the variant of random forests, which reaches the minimax rate, except for a factor ( ln ⁡ n ) 1 / ( d + 2 ) (ln⁡n)1/(d+2) , of the optimal plug-in classifier under the L -Lipschitz assumption. We achieve the tighter convergence rate O ( ln ⁡ n / n ) O(ln⁡n/n) under some assumptions over structural data. This work also takes one step towards the convergence rate of random forests for multi-class learning, and presents the same convergence rates of random forests for multi-class learning as that of binary classification , yet with different constants. We finally provide empirical studies to support the theoretical analysis.},
  archive      = {J_AIJ},
  author       = {Wei Gao and Fan Xu and Zhi-Hua Zhou},
  doi          = {10.1016/j.artint.2022.103788},
  journal      = {Artificial Intelligence},
  pages        = {103788},
  shortjournal = {Artif. Intell.},
  title        = {Towards convergence rate analysis of random forests for classification},
  volume       = {313},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Certifiably robust interpretation via rényi differential
privacy. <em>AIJ</em>, <em>313</em>, 103787. (<a
href="https://doi.org/10.1016/j.artint.2022.103787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the recent discovery that the interpretation maps of CNNs could easily be manipulated by adversarial attacks against network interpretability , we study the problem of interpretation robustness from a new perspective of Rényi differential privacy (RDP). The advantages of our Rényi-Robust-Smooth (RDP-based interpretation method) are three-folds. First, it can offer provable and certifiable top- k robustness. That is, the top- k important attributions of the interpretation map are provably robust under any input perturbation with bounded ℓ d ℓd -norm (for any d ≥ 1 d≥1 , including d = ∞ d=∞ ). Second, our proposed method offers ∼12\% better experimental robustness than existing approaches in terms of the top- k attributions. Remarkably, the accuracy of Rényi-Robust-Smooth also outperforms existing approaches. Third, our method can provide a smooth tradeoff between robustness and computational efficiency. Experimentally, its top- k attributions are twice more robust than existing approaches when the computational resources are highly constrained.},
  archive      = {J_AIJ},
  author       = {Ao Liu and Xiaoyu Chen and Sijia Liu and Lirong Xia and Chuang Gan},
  doi          = {10.1016/j.artint.2022.103787},
  journal      = {Artificial Intelligence},
  pages        = {103787},
  shortjournal = {Artif. Intell.},
  title        = {Certifiably robust interpretation via rényi differential privacy},
  volume       = {313},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural large neighborhood search for routing problems.
<em>AIJ</em>, <em>313</em>, 103786. (<a
href="https://doi.org/10.1016/j.artint.2022.103786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning how to automatically solve optimization problems has the potential to provide the next big leap in optimization technology. The performance of automatically learned heuristics on routing problems has been steadily improving in recent years, but approaches based purely on machine learning are still outperformed by state-of-the-art optimization methods. To close this performance gap, we propose a novel large neighborhood search (LNS) framework for vehicle routing that integrates learned heuristics for generating new solutions. The learning mechanism is based on a deep neural network with an attention mechanism and has been especially designed to be integrated into an LNS search setting. We evaluate our approach on the capacitated vehicle routing problem (CVRP), the split delivery vehicle routing problem (SDVRP), and the capacitated team orienteering problem (CTOP). We show that the NLNS approach is able to outperform a handcrafted LNS on the CVRP and SDVRP and match the performance of a standard LNS on the CTOP. NLNS is thus able to quickly and effectively learn high performance heuristics to maneuver through the search space of difficult routing problems, coming close to the performance of state-of-the-art optimization approaches.},
  archive      = {J_AIJ},
  author       = {André Hottung and Kevin Tierney},
  doi          = {10.1016/j.artint.2022.103786},
  journal      = {Artificial Intelligence},
  pages        = {103786},
  shortjournal = {Artif. Intell.},
  title        = {Neural large neighborhood search for routing problems},
  volume       = {313},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Logical separability of labeled data examples under
ontologies. <em>AIJ</em>, <em>313</em>, 103785. (<a
href="https://doi.org/10.1016/j.artint.2022.103785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding a logical formula that separates positive and negative examples given in the form of labeled data items is fundamental in applications such as concept learning, reverse engineering of database queries, generating referring expressions, and entity comparison in knowledge graphs. In this paper, we investigate the existence of a separating formula for data in the presence of an ontology. Both for the ontology language and the separation language, we concentrate on first-order logic and the following important fragments thereof: the description logic ALCI ALCI , the guarded fragment, the two-variable fragment, and the guarded negation fragment. For separation, we also consider (unions of) conjunctive queries . We consider several forms of separability that differ in the treatment of negative examples and in whether or not they admit the use of additional helper symbols to achieve separation. Our main results are model-theoretic characterizations of (all variants of) separability , the comparison of the separating power of different languages, and the investigation of the computational complexity of deciding separability.},
  archive      = {J_AIJ},
  author       = {Jean Christoph Jung and Carsten Lutz and Hadrien Pulcini and Frank Wolter},
  doi          = {10.1016/j.artint.2022.103785},
  journal      = {Artificial Intelligence},
  pages        = {103785},
  shortjournal = {Artif. Intell.},
  title        = {Logical separability of labeled data examples under ontologies},
  volume       = {313},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two’s company, three’s a crowd: Consensus-halving for a
constant number of agents. <em>AIJ</em>, <em>313</em>, 103784. (<a
href="https://doi.org/10.1016/j.artint.2022.103784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the ε - Consensus-Halving problem, in which a set of heterogeneous agents aim at dividing a continuous resource into two (not necessarily contiguous) portions that all of them simultaneously consider to be of approximately the same value (up to ε ). This problem was recently shown to be PPA-complete, for n agents and n cuts, even for very simple valuation functions. In a quest to understand the root of the complexity of the problem, we consider the setting where there is only a constant number of agents, and we consider both the computational complexity and the query complexity of the problem. For agents with monotone valuation functions, we show a dichotomy: for two agents the problem is polynomial-time solvable, whereas for three or more agents it becomes PPA-complete. Similarly, we show that for two monotone agents the problem can be solved with polynomially-many queries, whereas for three or more agents, we provide exponential query complexity lower bounds. These results are enabled via an interesting connection to a monotone Borsuk-Ulam problem, which may be of independent interest. For agents with general valuations, we show that the problem is PPA-complete and admits exponential query complexity lower bounds, even for two agents.},
  archive      = {J_AIJ},
  author       = {Argyrios Deligkas and Aris Filos-Ratsikas and Alexandros Hollender},
  doi          = {10.1016/j.artint.2022.103784},
  journal      = {Artificial Intelligence},
  pages        = {103784},
  shortjournal = {Artif. Intell.},
  title        = {Two&#39;s company, three&#39;s a crowd: Consensus-halving for a constant number of agents},
  volume       = {313},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mind the gap: Cake cutting with separation. <em>AIJ</em>,
<em>313</em>, 103783. (<a
href="https://doi.org/10.1016/j.artint.2022.103783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of fairly allocating a divisible resource, also known as cake cutting, with an additional requirement that the shares that different agents receive should be sufficiently separated from one another. This captures, for example, constraints arising from social distancing guidelines. While it is sometimes impossible to allocate a proportional share to every agent under the separation requirement, we show that the well-known criterion of maximin share fairness can always be attained. We then provide algorithmic analysis of maximin share fairness in this setting—for instance, the maximin share of an agent cannot be computed exactly by any finite algorithm, but can be approximated with an arbitrarily small error. In addition, we consider the division of a pie (i.e., a circular cake) and show that an ordinal relaxation of maximin share fairness can be achieved. We also prove that an envy-free or equitable allocation that allocates the maximum amount of resource exists under separation.},
  archive      = {J_AIJ},
  author       = {Edith Elkind and Erel Segal-Halevi and Warut Suksompong},
  doi          = {10.1016/j.artint.2022.103783},
  journal      = {Artificial Intelligence},
  pages        = {103783},
  shortjournal = {Artif. Intell.},
  title        = {Mind the gap: Cake cutting with separation},
  volume       = {313},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Risk verification of stochastic systems with neural network
controllers. <em>AIJ</em>, <em>313</em>, 103782. (<a
href="https://doi.org/10.1016/j.artint.2022.103782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the fragility of neural network (NN) controllers in safety-critical applications, we present a data-driven framework for verifying the risk of stochastic dynamical systems with NN controllers. Given a stochastic control system, an NN controller, and a specification equipped with a notion of trace robustness (e.g., constraint functions or signal temporal logic), we collect trajectories from the system that may or may not satisfy the specification. In particular, each of the trajectories produces a robustness value that indicates how well (severely) the specification is satisfied (violated). We then compute risk metrics over these robustness values to estimate the risk that the NN controller will not satisfy the specification. We are further interested in quantifying the difference in risk between two systems, and we show how the risk estimated from a nominal system can provide an upper bound the risk of a perturbed version of the system. In particular, the tightness of this bound depends on the closeness of the systems in terms of the closeness of their system trajectories . For Lipschitz continuous and incrementally input-to-state stable systems, we show how to exactly quantify system closeness with varying degrees of conservatism, while we estimate system closeness for more general systems from data in our experiments. We demonstrate our risk verification approach on two case studies, an underwater vehicle and an F1/10 autonomous car.},
  archive      = {J_AIJ},
  author       = {Matthew Cleaveland and Lars Lindemann and Radoslav Ivanov and George J. Pappas},
  doi          = {10.1016/j.artint.2022.103782},
  journal      = {Artificial Intelligence},
  pages        = {103782},
  shortjournal = {Artif. Intell.},
  title        = {Risk verification of stochastic systems with neural network controllers},
  volume       = {313},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph-based construction of minimal models. <em>AIJ</em>,
<em>313</em>, 103754. (<a
href="https://doi.org/10.1016/j.artint.2022.103754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reasoning with minimal models is at the heart of many knowledge representation systems. Yet, it turns out that this task is formidable even when very simple theories are considered. It is, therefore, crucial to devise methods that attain good performances in most cases. To this end, a path to follow is to find ways to break the task at hand into several sub-tasks that can be solved separately and in parallel. And, in fact, we show that minimal models of positive propositional theories can be decomposed based on the structure of the dependency graph of the theories: this observation turns out to be useful for many applications involving computation with minimal models. In particular, we introduce a new algorithm for minimal model finding based on model decomposition . The algorithm temporal worst-case complexity is exponential in the size s of the largest connected component of the dependency graph, but the actual cost depends on the size of the largest component actually encountered at run time that can be far smaller than s , and on the class of theories to which components belong. For example, if all components reduce to either an Head Cycle Free or an Head Elementary-set Free theory, the algorithm is polynomial in the size of the theory.},
  archive      = {J_AIJ},
  author       = {Fabrizio Angiulli and Rachel Ben-Eliyahu-Zohary and Fabio Fassetti and Luigi Palopoli},
  doi          = {10.1016/j.artint.2022.103754},
  journal      = {Artificial Intelligence},
  pages        = {103754},
  shortjournal = {Artif. Intell.},
  title        = {Graph-based construction of minimal models},
  volume       = {313},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simplified risk-aware decision making with belief-dependent
rewards in partially observable domains. <em>AIJ</em>, <em>312</em>,
103775. (<a href="https://doi.org/10.1016/j.artint.2022.103775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent advent of risk awareness, decision-making algorithms&#39; complexity increases, posing a severe difficulty to solve such formulations of the problem online. Our approach is centered on the distribution of the return in the challenging continuous domain under partial observability . This paper proposes a simplification framework to ease the computational burden while providing guarantees on the simplification impact. On top of this framework, we present novel stochastic bounds on the return that apply to any reward function. Further, we consider simplification&#39;s impact on decision making with risk averse objectives, which, to the best of our knowledge, has not been investigated thus far. In particular, we prove that stochastic bounds on the return yield deterministic bounds on Value at Risk. The second part of the paper focuses on the joint distribution of a pair of returns given a pair of candidate policies, thereby, for the first time, accounting for the correlation between these returns. Here, we propose a novel risk averse objective and apply our simplification paradigm. Moreover, we present a novel tool called the probabilistic loss ( PLoss ) to completely characterize the simplification impact for any objective operator in this setting. We provably bound the cumulative and tail distribution function of PLoss using PbLoss to provide such a characterization online using only the simplified problem. In addition, we utilize this tool to offer deterministic guarantees to the simplification in the context of our novel risk averse objective. We employ our proposed framework on a particular simplification technique - reducing the number of samples for reward calculation or belief representation within planning. Finally, we verify the advantages of our approach through extensive simulations.},
  archive      = {J_AIJ},
  author       = {Andrey Zhitnikov and Vadim Indelman},
  doi          = {10.1016/j.artint.2022.103775},
  journal      = {Artificial Intelligence},
  pages        = {103775},
  shortjournal = {Artif. Intell.},
  title        = {Simplified risk-aware decision making with belief-dependent rewards in partially observable domains},
  volume       = {312},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PredDiff: Explanations and interactions from conditional
expectations. <em>AIJ</em>, <em>312</em>, 103774. (<a
href="https://doi.org/10.1016/j.artint.2022.103774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PredDiff is a model-agnostic, local attribution method that is firmly rooted in probability theory. Its simple intuition is to measure prediction changes while marginalizing features. In this work, we clarify properties of PredDiff and its close connection to Shapley values. We stress important differences between classification and regression, which require a specific treatment within both formalisms. We extend PredDiff by introducing a new, well-founded measure for interaction effects between arbitrary feature subsets. The study of interaction effects represents an inevitable step towards a comprehensive understanding of black-box models and is particularly important for science applications. Equipped with our novel interaction measure, PredDiff is a promising model-agnostic approach for obtaining reliable, numerically inexpensive and theoretically sound attributions.},
  archive      = {J_AIJ},
  author       = {Stefan Blücher and Johanna Vielhaben and Nils Strodthoff},
  doi          = {10.1016/j.artint.2022.103774},
  journal      = {Artificial Intelligence},
  pages        = {103774},
  shortjournal = {Artif. Intell.},
  title        = {PredDiff: Explanations and interactions from conditional expectations},
  volume       = {312},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting voting outcomes in the presence of communities,
echo chambers and multiple parties. <em>AIJ</em>, <em>312</em>, 103773.
(<a href="https://doi.org/10.1016/j.artint.2022.103773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When individuals interact in a social network their opinions can change, at times quite significantly, as a result of social influence. In elections, for example, while they might initially support one candidate, what their friends say may lead them to support another. But how do opinions settle in a social network, as a result of social influence? A recently proposed graph-theoretic metric, the influence gap , has shown to be a reliable predictor of the effect of social influence in two-party elections, albeit only tested on regular and scale-free graphs. Here, we investigate whether the influence gap is able to predict the outcome of multi-party elections on networks exhibiting community structure, i.e., made of highly interconnected components, and therefore more resembling of real-world interaction. To encode communities we build on the classical model of caveman graphs, which we extend to a richer graph family that displays different levels of homophily , i.e., how many connections and opinions are intertwined. Our contribution is three-fold. First, we study the predictive power of the influence gap in the presence of communities. We show that when there is no clear initial majority the influence gap is not a good predictor of the election outcome. When we instead allow for varying majorities, although the influence gap improves as a predictor, counting the initial partisan majority does consistently better, across all levels of homophily. Second, we study the combined effect of the more predictive metrics, as function of the homophily levels. Using regression models, we demonstrate that the influence gap combined with the initial votes count does increase the overall predictive power for some levels of homophily. Third, we study elections with more than two parties. Specifically, we extend the definition of the influence gap to any number of parties, considering various generalisations, and show that the initial votes count has an even higher predictive power when compared to influence gap than it did in the two-party case.},
  archive      = {J_AIJ},
  author       = {Jacques Bara and Omer Lev and Paolo Turrini},
  doi          = {10.1016/j.artint.2022.103773},
  journal      = {Artificial Intelligence},
  pages        = {103773},
  shortjournal = {Artif. Intell.},
  title        = {Predicting voting outcomes in the presence of communities, echo chambers and multiple parties},
  volume       = {312},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Preference-based inconsistency-tolerant query answering
under existential rules. <em>AIJ</em>, <em>312</em>, 103772. (<a
href="https://doi.org/10.1016/j.artint.2022.103772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontology-mediated query answering (OMQA) emerged as a paradigm to enhance querying of data sources with an ontology that encodes background knowledge. In applications involving large amounts of data from multiple data sources, it might well be the case that inconsistency arises, making standard query answering useless, since everything is entailed by an inconsistent knowledge base. Being able to provide meaningful query answers in the presence of inconsistency is thus a critical issue to make OMQA systems successful in practice. The problem of querying inconsistent knowledge has attracted a great deal of interest over the years. Different inconsistency-tolerant semantics of query answering have been proposed, that is, approaches to answer queries in a meaningful way despite the knowledge at hand being inconsistent. Most of the semantics in the literature are based on the notion of repair , that is, a “maximal” consistent subset of the database. In general, there can be several repairs, so it is often natural and desirable to express preferences among them. In this paper, we propose a framework for querying inconsistent knowledge bases under user preferences for existential rule languages. Specifically, we introduce preference rules , a declarative formalism which enable users to express (i) preferences over both the database and the knowledge that can be derived from it via an ontology, and (ii) preconditions for preferences to hold. We then define two notions of preferred repairs which take preference rules into account. This naturally leads us to introducing preference-aware counterparts of popular inconsistency-tolerant semantics, where only preferred repairs are considered for query answering. We provide a thorough analysis of the data and combined complexity of different relevant problems for a wide range of existential rule languages.},
  archive      = {J_AIJ},
  author       = {Marco Calautti and Sergio Greco and Cristian Molinaro and Irina Trubitsyna},
  doi          = {10.1016/j.artint.2022.103772},
  journal      = {Artificial Intelligence},
  pages        = {103772},
  shortjournal = {Artif. Intell.},
  title        = {Preference-based inconsistency-tolerant query answering under existential rules},
  volume       = {312},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Q-learning-based model predictive variable impedance control
for physical human-robot collaboration. <em>AIJ</em>, <em>312</em>,
103771. (<a href="https://doi.org/10.1016/j.artint.2022.103771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical human-robot collaboration is increasingly required in many contexts (such as industrial and rehabilitation applications). The robot needs to interact with the human to perform the target task while relieving the user from the workload. To do that, the robot should be able to recognize the human&#39;s intentions and guarantee safe and adaptive behavior along the intended motion directions. The robot-control strategies with such attributes are particularly demanded in the industrial field, where the operator guides the robot manually to manipulate heavy parts ( e.g. , while teaching a specific task). With this aim, this work proposes a Q-Learning-based Model Predictive Variable Impedance Control (Q-LMPVIC) to assist the operators in a physical human-robot collaboration (pHRC) tasks. A Cartesian impedance control loop is designed to implement a decoupled compliant robot dynamics. The impedance control parameters ( i.e. , setpoint and damping parameters) are then optimized online in order to maximize the performance of the pHRC. For this purpose, an ensemble of neural networks is designed to learn the modeling of the human-robot interaction dynamics while capturing the associated uncertainties. The derived modeling is then exploited by the model predictive controller (MPC), enhanced with the stability guarantees by means of Lyapunov constraints. The MPC is solved by making use of a Q-Learning method that, in its online implementation, uses an actor-critic algorithm to approximate the exact solution. Indeed, the Q-learning method provides an accurate and highly efficient solution (in terms of computational time and resources). The proposed approach has been validated through experimental tests, in which a Franka EMIKA panda robot has been used as a test platform. Each user was asked to interact with the robot along the controlled vertical z Cartesian direction. The proposed controller has been compared with a model-based reinforcement learning variable impedance controller (MBRLC) previously developed by some of the authors in order to evaluate the performance. As highlighted in the achieved results, the proposed controller is able to improve the pHRC performance. Additionally, two industrial tasks (a collaborative assembly and a collaborative deposition task) have been demonstrated to prove the applicability of the proposed solution in real industrial scenarios.},
  archive      = {J_AIJ},
  author       = {Loris Roveda and Andrea Testa and Asad Ali Shahid and Francesco Braghin and Dario Piga},
  doi          = {10.1016/j.artint.2022.103771},
  journal      = {Artificial Intelligence},
  pages        = {103771},
  shortjournal = {Artif. Intell.},
  title        = {Q-learning-based model predictive variable impedance control for physical human-robot collaboration},
  volume       = {312},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical clustering optimizes the tradeoff between
compositionality and expressivity of task structures for flexible
reinforcement learning. <em>AIJ</em>, <em>312</em>, 103770. (<a
href="https://doi.org/10.1016/j.artint.2022.103770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hallmark of human intelligence, but challenging for reinforcement learning (RL) agents, is the ability to compositionally generalise, that is, to recompose familiar knowledge components in novel ways to solve new problems. For instance, when navigating in a city, one needs to know the location of the destination and how to operate a vehicle to get there, whether it be pedalling a bike or operating a car. In RL, these correspond to the reward function and transition function, respectively. To compositionally generalize, these two components need to be transferable independently of each other: multiple modes of transport can reach the same goal, and any given mode can be used to reach multiple destinations. Yet there are also instances where it can be helpful to learn and transfer entire structures, jointly representing goals and transitions, particularly whenever these recur in natural tasks (e.g., given a suggestion to get ice cream, one might prefer to bike, even in new towns). Prior theoretical work has explored how, in model-based RL, agents can learn and generalize task components (transition and reward functions). But a satisfactory account for how a single agent can simultaneously satisfy the two competing demands is still lacking. Here, we propose a hierarchical RL agent that learns and transfers individual task components as well as entire structures (particular compositions of components) by inferring both through a non-parametric Bayesian model of the task. It maintains a factorised representation of task components through a hierarchical Dirichlet process, but it also represents different possible covariances between these components through a standard Dirichlet process. We validate our approach on a variety of navigation tasks covering a wide range of statistical correlations between task components and show that it can also improve generalisation and transfer in more complex, hierarchical tasks with goal/subgoal structures. Finally, we end with a discussion of our work including how this clustering algorithm could conceivably be implemented by cortico-striatal gating circuits in the brain.},
  archive      = {J_AIJ},
  author       = {Rex G. Liu and Michael J. Frank},
  doi          = {10.1016/j.artint.2022.103770},
  journal      = {Artificial Intelligence},
  pages        = {103770},
  shortjournal = {Artif. Intell.},
  title        = {Hierarchical clustering optimizes the tradeoff between compositionality and expressivity of task structures for flexible reinforcement learning},
  volume       = {312},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On pareto optimality in social distance games. <em>AIJ</em>,
<em>312</em>, 103768. (<a
href="https://doi.org/10.1016/j.artint.2022.103768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate Pareto stability in Social Distance Games ( SDG SDG s), which are coalition formation games where agents utilities are proportional to their harmonic centralities in the respective coalitions, i.e., to the average inverse distance from the other agents. Pareto optimal solutions have already been considered in the literature as outcomes arising from the strategic interaction of the self-interested agents. In particular, they are stable under the deviation of the grand coalition, as they do not permit a simultaneous deviation by all the agents making all of them weakly better off and some strictly better off. First, by providing a polynomial-time reduction from the NP-complete Restricted Exact 3-Cover by 3-Sets problem, we prove that computing a Pareto stable solution for a SDG SDG maximizing the social welfare is NP-hard also in bounded degree graphs. Then, we show that a 2 min ⁡ ( Δ , n ) 2min⁡(Δ, n) -approximating solution can be determined in polynomial time , where n is the number of agents and Δ the maximum node degree. Moreover, we provide asymptotically tight bounds on the price of Pareto optimality for several classes of social graphs arising from the following combinations: unbounded and bounded node degree, undirected and directed arcs, unweighted and weighted arcs.},
  archive      = {J_AIJ},
  author       = {Alkida Balliu and Michele Flammini and Giovanna Melideo and Dennis Olivetti},
  doi          = {10.1016/j.artint.2022.103768},
  journal      = {Artificial Intelligence},
  pages        = {103768},
  shortjournal = {Artif. Intell.},
  title        = {On pareto optimality in social distance games},
  volume       = {312},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Atlas of AI – book review | atlas of AI, kate crawford, yale
university press (2021). <em>AIJ</em>, <em>312</em>, 103767. (<a
href="https://doi.org/10.1016/j.artint.2022.103767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIJ},
  author       = {Francesca Rossi},
  doi          = {10.1016/j.artint.2022.103767},
  journal      = {Artificial Intelligence},
  pages        = {103767},
  shortjournal = {Artif. Intell.},
  title        = {Atlas of AI – book review | atlas of AI, kate crawford, yale university press (2021)},
  volume       = {312},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inhomogeneous deep q-network for time sensitive
applications. <em>AIJ</em>, <em>312</em>, 103757. (<a
href="https://doi.org/10.1016/j.artint.2022.103757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Q-network (DQN) has attracted increasing attention from both industry and academic communities. Existing methods mostly formulate the decision process as discrete agent-environment interactions, while the intervals between successive interactions are largely neglected, which may otherwise reveal important signals in real-world applications. To bridge this gap, this paper proposes to explicitly model the time intervals in DQN. Specifically, we first cast the agent-environment interactions onto a continuous time dimension, and then define a time-aware learning objective and the corresponding Bellman operator. For sample efficient training, we approximate the Q-function with a neural network , where the time information is modeled by the point process. The intensity function in point process and Q-function are seamlessly integrated by sharing the same history summarization module, such that the time interval information can directly influence the model optimization process. To close the gap between the approximated and optimal Q-function, we theoretically analyze the sample complexity of our model by deriving the finite time bound in continuous time. We conduct both simulation and real-world experiments to demonstrate our model&#39;s effectiveness.},
  archive      = {J_AIJ},
  author       = {Xu Chen and Jun Wang},
  doi          = {10.1016/j.artint.2022.103757},
  journal      = {Artificial Intelligence},
  pages        = {103757},
  shortjournal = {Artif. Intell.},
  title        = {Inhomogeneous deep Q-network for time sensitive applications},
  volume       = {312},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-robot adversarial patrolling strategies via lattice
paths. <em>AIJ</em>, <em>311</em>, 103769. (<a
href="https://doi.org/10.1016/j.artint.2022.103769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In full-knowledge multi-robot adversarial patrolling, a group of robots has to detect an adversary who knows the robots&#39; strategy. The adversary can easily take advantage of any deterministic patrolling strategy, which necessitates the employment of a randomised strategy. While the Markov decision process has been the dominant methodology in computing the penetration detection probabilities on polylines, we apply enumerative combinatorics to characterise the penetration detection probabilities for four penetration configurations. It allows us to provide the closed formulae of these probabilities and facilitates characterising optimal random defence strategies. Comparing to iteratively updating the Markov transition matrices , we empirically show that our method reduces the runtime by up to several hours. This allows us extensive simulations on the two dominant robot movement types for patrolling a perimeter showing that a movement with direction is up to 0.4 more likely to detect an adversary. Therefore, our approach greatly benefits the theoretical and empirical analysis of optimal patrolling strategies with extendability to more complicated attacks and other structured environments.},
  archive      = {J_AIJ},
  author       = {Jan Buermann and Jie Zhang},
  doi          = {10.1016/j.artint.2022.103769},
  journal      = {Artificial Intelligence},
  pages        = {103769},
  shortjournal = {Artif. Intell.},
  title        = {Multi-robot adversarial patrolling strategies via lattice paths},
  volume       = {311},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-agent path finding with mutex propagation.
<em>AIJ</em>, <em>311</em>, 103766. (<a
href="https://doi.org/10.1016/j.artint.2022.103766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mutex propagation is a form of efficient constraint propagation popularly used in AI planning to tightly approximate the reachable states from a given state. We utilize this idea in the context of Multi-Agent Path Finding (MAPF). When adapted to MAPF, mutex propagation provides stronger constraints for conflict resolution in CBS, a popular optimal search-based MAPF algorithm, as well as in MDD-SAT, an optimal satisfiability-based MAPF algorithm. Mutex propagation provides CBS with the ability to break symmetries in MAPF and provides MDD-SAT with the ability to make stronger inferences than unit propagation . While existing work identifies a limited form of symmetries and requires the manual design of symmetry-breaking constraints, mutex propagation is more general and allows for the automated design of symmetry-breaking constraints. Our experimental results show that CBS with mutex propagation is capable of outperforming CBSH-RCT, a state-of-the-art variant of CBS, with respect to the success rate. We also show that MDD-SAT with mutex propagation often performs better than MDD-SAT with respect to the success rate.},
  archive      = {J_AIJ},
  author       = {Han Zhang and Jiaoyang Li and Pavel Surynek and T.K. Satish Kumar and Sven Koenig},
  doi          = {10.1016/j.artint.2022.103766},
  journal      = {Artificial Intelligence},
  pages        = {103766},
  shortjournal = {Artif. Intell.},
  title        = {Multi-agent path finding with mutex propagation},
  volume       = {311},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Risk-averse policy optimization via risk-neutral policy
optimization. <em>AIJ</em>, <em>311</em>, 103765. (<a
href="https://doi.org/10.1016/j.artint.2022.103765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keeping risk under control is a primary objective in many critical real-world domains, including finance and healthcare. The literature on risk-averse reinforcement learning (RL) has mostly focused on designing ad-hoc algorithms for specific risk measures. As such, most of these algorithms do not easily generalize to measures other than the one they are designed for. Furthermore, it is often unclear whether state-of-the-art risk-neutral RL algorithms can be extended to reduce risk. In this paper, we take a step towards overcoming these limitations, proposing a single framework to optimize some of the most popular risk measures, including conditional value-at-risk, utility functions, and mean-variance. Leveraging recent theoretical results on state augmentation, we transform the decision-making process so that optimizing the chosen risk measure in the original environment is equivalent to optimizing the expected cost in the transformed one. We then present a simple risk-sensitive meta-algorithm that transforms the trajectories it collects from the environment and feeds these into any risk-neutral policy optimization method. Finally, we provide extensive experiments that show the benefits of our approach over existing ad-hoc methodologies in different domains, including the Mujoco robotic suite and a real-world trading dataset.},
  archive      = {J_AIJ},
  author       = {Lorenzo Bisi and Davide Santambrogio and Federico Sandrelli and Andrea Tirinzoni and Brian D. Ziebart and Marcello Restelli},
  doi          = {10.1016/j.artint.2022.103765},
  journal      = {Artificial Intelligence},
  pages        = {103765},
  shortjournal = {Artif. Intell.},
  title        = {Risk-averse policy optimization via risk-neutral policy optimization},
  volume       = {311},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimizing the computation of overriding in DLN.
<em>AIJ</em>, <em>311</em>, 103764. (<a
href="https://doi.org/10.1016/j.artint.2022.103764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the factors that is hindering the adoption of nonmonotonic description logics in applications is performance. Even when monotonic and nonmonotonic inferences have the same asymptotic complexity , the implementation of nonmonotonic reasoning may be significantly slower. This happens also with the family of nonmonotonic logics DL N DLN . In this work we address this issue by introducing two optimizations for reasoning in DL N DLN . The first optimization, called optimistic evaluation , aims at exploiting incremental reasoning in a better way. The second is a module extractor for DL N DLN , that has the purpose of focusing reasoning on a relevant subset of the knowledge base. The proposed optimization iterates the module extractor that, unlike classical module extractors, is not idempotent, in general. We prove that the proposed optimizations are correct and complete, and assess them through extensive experiments. Our results prove that optimized DL N DLN reasoning is often compatible with interactive query answering , which brings nonmonotonic description logics closer to practical applications.},
  archive      = {J_AIJ},
  author       = {P.A. Bonatti and I.M. Petrova and L. Sauro},
  doi          = {10.1016/j.artint.2022.103764},
  journal      = {Artificial Intelligence},
  pages        = {103764},
  shortjournal = {Artif. Intell.},
  title        = {Optimizing the computation of overriding in DLN},
  volume       = {311},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A computational model of ostrom’s institutional analysis and
development framework. <em>AIJ</em>, <em>311</em>, 103756. (<a
href="https://doi.org/10.1016/j.artint.2022.103756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Institutional Analysis and Development (IAD) framework developed by Elinor Ostrom and colleagues provides great conceptual clarity on the immensely varied topic of social interactions. In this work, we propose a computational model to examine the impact that any of the variables outlined in the IAD framework has on the resulting social interactions. Of particular interest are the rules adopted by a community of agents, as they are the variables most susceptible to change in the short term. To provide systematic descriptions of social interactions, we define the Action Situation Language (ASL) and provide a game engine capable of automatically generating formal game-theoretical models out of ASL descriptions. Then, by incorporating any agent decision-making models, the connection from a rule configuration description to the outcomes encouraged by it is complete. Overall, our model enables any community of agents to perform what-if analysis, where they can foresee and examine the impact that a set of regulations will have on the social interaction they are engaging in. Hence, they can decide whether their implementation is desirable.},
  archive      = {J_AIJ},
  author       = {Nieves Montes and Nardine Osman and Carles Sierra},
  doi          = {10.1016/j.artint.2022.103756},
  journal      = {Artificial Intelligence},
  pages        = {103756},
  shortjournal = {Artif. Intell.},
  title        = {A computational model of ostrom&#39;s institutional analysis and development framework},
  volume       = {311},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Choice logics and their computational properties.
<em>AIJ</em>, <em>311</em>, 103755. (<a
href="https://doi.org/10.1016/j.artint.2022.103755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Qualitative Choice Logic (QCL) and Conjunctive Choice Logic (CCL) are formalisms for preference handling, with especially QCL being well established in the field of AI . So far, analyses of these logics need to be done on a case-by-case basis, albeit they share several common features. This calls for a more general choice logic framework, with QCL and CCL as well as some of their derivatives being particular instantiations . We provide such a framework, which allows us, on the one hand, to easily define new choice logics and, on the other hand, to examine properties of different choice logics in a uniform setting. In particular, we investigate strong equivalence, a core concept in non-classical logics for understanding formula simplification, and computational complexity . Our analysis also yields new results for QCL and CCL. For example, we show that the main reasoning task regarding preferred models of choice logic formulas is Θ 2 P Θ2P -complete for QCL and CCL, while being Δ 2 P Δ2P -complete for a newly introduced choice logic. The complexity of preferred model entailment for choice logic theories ranges from coNP coNP to Π 2 P Π2P .},
  archive      = {J_AIJ},
  author       = {Michael Bernreiter and Jan Maly and Stefan Woltran},
  doi          = {10.1016/j.artint.2022.103755},
  journal      = {Artificial Intelligence},
  pages        = {103755},
  shortjournal = {Artif. Intell.},
  title        = {Choice logics and their computational properties},
  volume       = {311},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximate weighted model integration on DNF structures.
<em>AIJ</em>, <em>311</em>, 103753. (<a
href="https://doi.org/10.1016/j.artint.2022.103753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weighted model counting consists of computing the weighted sum of all satisfying assignments of a propositional formula . Weighted model counting is well-known to be #P -hard for exact solving, but admits a fully polynomial randomized approximation scheme when restricted to DNF structures. In this work, we study weighted model integration , a generalization of weighted model counting which involves real variables in addition to propositional variables , and pose the following question: Does weighted model integration on DNF structures admit a fully polynomial randomized approximation scheme? Building on classical results from approximate weighted model counting and approximate volume computation, we show that weighted model integration on DNF structures can indeed be approximated for a class of weight functions. Our approximation algorithm is based on three subroutines, each of which can be a weak (i.e., approximate), or a strong (i.e., exact) oracle, and in all cases, comes along with accuracy guarantees. We experimentally verify our approach over randomly generated DNF instances of varying sizes, and show that our algorithm scales to large problem instances, involving up to 1K variables, which are currently out of reach for existing, general-purpose weighted model integration solvers.},
  archive      = {J_AIJ},
  author       = {Ralph Abboud and İsmail İlkan Ceylan and Radoslav Dimitrov},
  doi          = {10.1016/j.artint.2022.103753},
  journal      = {Artificial Intelligence},
  pages        = {103753},
  shortjournal = {Artif. Intell.},
  title        = {Approximate weighted model integration on DNF structures},
  volume       = {311},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Risk-averse autonomous systems: A brief history and recent
developments from the perspective of optimal control. <em>AIJ</em>,
<em>311</em>, 103743. (<a
href="https://doi.org/10.1016/j.artint.2022.103743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an historical overview about the connections between the analysis of risk and the control of autonomous systems . We offer two main contributions. Our first contribution is to propose three overlapping paradigms to classify the vast body of literature: the worst-case , risk-neutral , and risk-averse paradigms . We consider an appropriate assessment for the risk of an autonomous system to depend on the application at hand. In contrast, it is typical to assess risk using an expectation, variance, or probability alone. Our second contribution is to unify the concepts of risk and autonomous systems . We achieve this by connecting approaches for quantifying and optimizing the risk that arises from a system&#39;s behavior across academic fields. The survey is highly multidisciplinary. We include research from the communities of reinforcement learning , stochastic and robust control theory, operations research, and formal verification . We describe both model-based and model-free methods, with emphasis on the former. Lastly, we highlight fruitful areas for further research. A key direction is to blend risk-averse model-based and model-free methods to enhance the real-time adaptive capabilities of systems to improve human and environmental welfare.},
  archive      = {J_AIJ},
  author       = {Yuheng Wang and Margaret P. Chapman},
  doi          = {10.1016/j.artint.2022.103743},
  journal      = {Artificial Intelligence},
  pages        = {103743},
  shortjournal = {Artif. Intell.},
  title        = {Risk-averse autonomous systems: A brief history and recent developments from the perspective of optimal control},
  volume       = {311},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Priority inheritance with backtracking for iterative
multi-agent path finding. <em>AIJ</em>, <em>310</em>, 103752. (<a
href="https://doi.org/10.1016/j.artint.2022.103752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Multi-Agent Path Finding (MAPF) problem, a set of agents moving on a graph must reach their own respective destinations without inter-agent collisions. In practical MAPF applications such as navigation in automated warehouses, where occasionally there are hundreds or more agents, MAPF must be solved iteratively online on a lifelong basis. Such scenarios rule out simple adaptations of offline compute-intensive optimal approaches; and scalable sub-optimal algorithms are hence appealing for such settings. Ideal algorithms are scalable, applicable to iterative scenarios, and output plausible solutions in predictable computation time. For the aforementioned purpose, this study presents Priority Inheritance with Backtracking (PIBT), a novel sub-optimal algorithm to solve MAPF iteratively. PIBT relies on an adaptive prioritization scheme to focus on the adjacent movements of multiple agents ; hence it can be applied to several domains. We prove that, regardless of their number, all agents are guaranteed to reach their destination within finite time when the environment is a graph such that all pairs of adjacent nodes belong to a simple cycle (e.g., biconnected). Experimental results covering various scenarios, including a demonstration with real robots, reveal the benefits of the proposed method. Even with hundreds of agents, PIBT yields acceptable solutions almost immediately and can solve large instances that other established MAPF methods cannot. In addition, PIBT outperforms an existing approach on an iterative scenario of conveying packages in an automated warehouse in both runtime and solution quality.},
  archive      = {J_AIJ},
  author       = {Keisuke Okumura and Manao Machida and Xavier Défago and Yasumasa Tamura},
  doi          = {10.1016/j.artint.2022.103752},
  journal      = {Artificial Intelligence},
  pages        = {103752},
  shortjournal = {Artif. Intell.},
  title        = {Priority inheritance with backtracking for iterative multi-agent path finding},
  volume       = {310},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conjure: Automatic generation of constraint models from
problem specifications. <em>AIJ</em>, <em>310</em>, 103751. (<a
href="https://doi.org/10.1016/j.artint.2022.103751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving a combinatorial problem , the formulation or model of the problem is critical to the efficiency of the solver. Automating the modelling process has long been of interest because of the expertise and time required to produce an effective model of a given problem. We describe a method to automatically produce constraint models from a problem specification written in the abstract constraint specification language Essence . Our approach is to incrementally refine the specification into a concrete model by applying a chosen refinement rule at each step. Any non-trivial specification may be refined in multiple ways, creating a space of models to choose from. The handling of symmetries is a particularly important aspect of automated modelling. Many combinatorial optimisation problems contain symmetry, which can lead to redundant search. If a partial assignment is shown to be invalid, we are wasting time if we ever consider a symmetric equivalent of it. A particularly important class of symmetries are those introduced by the constraint modelling process: modelling symmetries. We show how modelling symmetries may be broken automatically as they enter a model during refinement, obviating the need for an expensive symmetry detection step following model formulation. Our approach is implemented in a system called Conjure . We compare the models produced by Conjure to constraint models from the literature that are known to be effective. Our empirical results confirm that Conjure can reproduce successfully the kernels of the constraint models of 42 benchmark problems found in the literature.},
  archive      = {J_AIJ},
  author       = {Özgür Akgün and Alan M. Frisch and Ian P. Gent and Christopher Jefferson and Ian Miguel and Peter Nightingale},
  doi          = {10.1016/j.artint.2022.103751},
  journal      = {Artificial Intelligence},
  pages        = {103751},
  shortjournal = {Artif. Intell.},
  title        = {Conjure: Automatic generation of constraint models from problem specifications},
  volume       = {310},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). VoCSK: Verb-oriented commonsense knowledge mining with
taxonomy-guided induction. <em>AIJ</em>, <em>310</em>, 103744. (<a
href="https://doi.org/10.1016/j.artint.2022.103744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Commonsense knowledge acquisition is one of the fundamental issues in realizing human-level AI . However, commonsense knowledge is difficult to obtain because it is a human consensus and rarely explicitly appears in texts or other data. In this paper, we focus on the automatic acquisition of a typical kind of implicit verb-oriented commonsense knowledge (e.g., “ person eats food ”), which is the concept-level knowledge of verb phrases. For this purpose, we propose a taxonomy-guided induction method to mine verb-oriented commonsense knowledge from verb phrases with the help of a probabilistic taxonomy. First, we design an entropy-based triplet filter to cope with noisy verb phrases. Then, we propose a joint model based on the minimum description length principle and a neural language model to generate verb-oriented commonsense knowledge. Besides, we introduce two strategies to accelerate the computation, including the simulated annealing-based approximate solution and the verb phrase clustering method . Finally, we conduct extensive experiments to prove that our solution is more effective than competitors in mining verb-oriented commonsense knowledge. We construct a commonsense knowledge base called VoCSK, containing 259 verbs and 18, 406 verb-oriented commonsense knowledge. To verify the usefulness of VoCSK, we utilize the knowledge in this KB to improve the model performance on two downstream applications.},
  archive      = {J_AIJ},
  author       = {Jingping Liu and Tao Chen and Chao Wang and Jiaqing Liang and Lihan Chen and Yanghua Xiao and Yunwen Chen and Ke Jin},
  doi          = {10.1016/j.artint.2022.103744},
  journal      = {Artificial Intelligence},
  pages        = {103744},
  shortjournal = {Artif. Intell.},
  title        = {VoCSK: Verb-oriented commonsense knowledge mining with taxonomy-guided induction},
  volume       = {310},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Shedding new light on the foundations of abstract
argumentation: Modularization and weak admissibility. <em>AIJ</em>,
<em>310</em>, 103742. (<a
href="https://doi.org/10.1016/j.artint.2022.103742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In his seminal 1995 paper, Dung laid the foundations of abstract argumentation, a by now major research area in knowledge representation. He pointed out that there is a problematic issue with self-defeating arguments underlying all traditional semantics. A self-defeat occurs if an argument attacks itself either directly or indirectly via an odd attack loop, unless the loop is broken up by some argument attacking the loop from outside. Motivated by the fact that such arguments represent self-contradictory or paradoxical arguments, he asked for reasonable semantics which overcome the problem that such arguments may indeed invalidate any argument they attack. This paper provides a solution to this problem. More precisely, we introduce alternative foundations for abstract argumentation, namely weak admissibility and weak defense. After showing that these key concepts are compatible as in the classical case we introduce new versions of the classical Dung-style semantics including complete, preferred and grounded semantics. We provide a rigorous study of these new concepts including interrelationships as well as the relations to their Dung-style counterparts. We also conduct an analysis of the relationship of our concepts with similar concepts found in the literature. We show that weak admissibility, although defined in entirely different terms, is in fact equivalent to a notion of acceptability which was defined by Kakas and Mancarella yet never studied in depth. The new semantics presented here overcome the issue with self-defeating arguments, and they are semantically insensitive to syntactic deletions of self-attacking arguments, a special case of self-defeat. 1},
  archive      = {J_AIJ},
  author       = {Ringo Baumann and Gerhard Brewka and Markus Ulbricht},
  doi          = {10.1016/j.artint.2022.103742},
  journal      = {Artificial Intelligence},
  pages        = {103742},
  shortjournal = {Artif. Intell.},
  title        = {Shedding new light on the foundations of abstract argumentation: Modularization and weak admissibility},
  volume       = {310},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A false sense of security. <em>AIJ</em>, <em>310</em>,
103741. (<a href="https://doi.org/10.1016/j.artint.2022.103741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing literature on confidentiality in knowledge representation and reasoning sometimes may cause a false sense of security, due to lack of details about the attacker, and some misconceptions about security-related concepts. This note analyzes the vulnerabilities of some recent knowledge protection methods to increase the awareness about their actual effectiveness and their mutual differences.},
  archive      = {J_AIJ},
  author       = {Piero A. Bonatti},
  doi          = {10.1016/j.artint.2022.103741},
  journal      = {Artificial Intelligence},
  pages        = {103741},
  shortjournal = {Artif. Intell.},
  title        = {A false sense of security},
  volume       = {310},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ASER: Towards large-scale commonsense knowledge acquisition
via higher-order selectional preference over eventualities.
<em>AIJ</em>, <em>309</em>, 103740. (<a
href="https://doi.org/10.1016/j.artint.2022.103740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Commonsense knowledge acquisition and reasoning have long been a core artificial intelligence problem. However, in the past, there has been a lack of scalable methods to collect commonsense knowledge. In this paper, we propose to develop principles for collecting commonsense knowledge based on selectional preference, which is a common phenomenon in human languages that has been shown to be related to semantics. We generalize the definition of selectional preference from one-hop linguistic syntactic relations to higher-order relations over linguistic graphs. Unlike previous commonsense knowledge definitions (e.g., ConceptNet), the selectional preference (SP) knowledge only relies on statistical distributions over linguistic graphs, which can be efficiently and accurately acquired from the unlabeled corpora with modern tools, rather than human-defined relations. As a result, acquiring SP knowledge is a much more scalable way of acquiring commonsense knowledge. Following this principle, we develop a large-scale eventuality (a linguistic term covering activity, state, and event)-based knowledge graph ASER , where each eventuality is represented as a dependency graph , and the relation between them is a discourse relation defined in shallow discourse parsing . The higher-order selectional preference over collected linguistic graphs reflects various kinds of commonsense knowledge. For example, dogs are more likely to bark than cats as the eventuality “dog barks” appears 14, 998 times in ASER while “cat barks” only appears 6 times. “Be hungry” is more likely to be the reason rather than result of “eat food” as the edge 〈“be hungry, ” Cause , “eat food”〉 appears in ASER while 〈“eat food, ” Cause , “be hungry”〉 does not. Moreover, motivated by the observation that humans understand events by abstracting the observed events to a higher level and can thus transfer their knowledge to new events, we propose a conceptualization module on top of the collected knowledge to significantly boost the coverage of ASER. In total, ASER contains 648 million edges between 438 million eventualities. After conceptualization with Probase, a selectional preference based concept-instance relational knowledge base, our concept graph contains 15 million conceptualized eventualities and 224 million edges between them. Detailed analysis is provided to demonstrate its quality. All the collected data, APIs, and tools that can help convert collected SP knowledge into the format of ConceptNet are available at https://github.com/HKUST-KnowComp/ASER .},
  archive      = {J_AIJ},
  author       = {Hongming Zhang and Xin Liu and Haojie Pan and Haowen Ke and Jiefu Ou and Tianqing Fang and Yangqiu Song},
  doi          = {10.1016/j.artint.2022.103740},
  journal      = {Artificial Intelligence},
  pages        = {103740},
  shortjournal = {Artif. Intell.},
  title        = {ASER: Towards large-scale commonsense knowledge acquisition via higher-order selectional preference over eventualities},
  volume       = {309},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the landscape of one-hidden-layer sparse networks and
beyond. <em>AIJ</em>, <em>309</em>, 103739. (<a
href="https://doi.org/10.1016/j.artint.2022.103739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse neural networks have received increasing interest due to their small size compared to dense networks. Nevertheless, most existing works on neural network theory have focused on dense neural networks , and the understanding of sparse networks is very limited. In this paper we study the loss landscape of one-hidden-layer sparse networks. First, we consider sparse networks with a dense final layer. We show that linear networks can have no spurious valleys under special sparse structures, and non-linear networks could also admit no spurious valleys under a wide final layer. Second, we discover that spurious valleys and spurious minima can exist for wide sparse networks with a sparse final layer. This is different from wide dense networks which do not have spurious valleys under mild assumptions.},
  archive      = {J_AIJ},
  author       = {Dachao Lin and Ruoyu Sun and Zhihua Zhang},
  doi          = {10.1016/j.artint.2022.103739},
  journal      = {Artificial Intelligence},
  pages        = {103739},
  shortjournal = {Artif. Intell.},
  title        = {On the landscape of one-hidden-layer sparse networks and beyond},
  volume       = {309},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A tetrachotomy of ontology-mediated queries with a covering
axiom. <em>AIJ</em>, <em>309</em>, 103738. (<a
href="https://doi.org/10.1016/j.artint.2022.103738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our concern is the problem of efficiently determining the data complexity of answering queries mediated by description logic ontologies and constructing their optimal rewritings to standard database queries. Originated in ontology-based data access and datalog optimisation, this problem is known to be computationally very complex in general, with no explicit syntactic characterisations available. In this article, aiming to understand the fundamental roots of this difficulty, we strip the problem to the bare bones and focus on Boolean conjunctive queries mediated by a simple covering axiom stating that one class is covered by the union of two other classes. We show that, on the one hand, these rudimentary ontology-mediated queries, called disjunctive sirups (or d-sirups), capture many features and difficulties of the general case. For example, answering d-sirups is Π 2 p Π2p -complete for combined complexity and can be in or L -, NL -, P -, or coNP -complete for data complexity (with the problem of recognising FO-rewritability of d-sirups being 2 ExpTime -hard); some d-sirups only have exponential-size resolution proofs, some only double-exponential-size positive existential FO-rewritings and single-exponential-size nonrecursive datalog rewritings. On the other hand, we prove a few partial sufficient and necessary conditions of FO- and (symmetric/linear-) datalog rewritability of d-sirups. Our main technical result is a complete and transparent syntactic / NL / P / coNP tetrachotomy of d-sirups with disjoint covering classes and a path-shaped Boolean conjunctive query. To obtain this tetrachotomy, we develop new techniques for establishing P - and coNP -hardness of answering non-Horn ontology-mediated queries as well as showing that they can be answered in NL .},
  archive      = {J_AIJ},
  author       = {Olga Gerasimova and Stanislav Kikot and Agi Kurucz and Vladimir Podolskii and Michael Zakharyaschev},
  doi          = {10.1016/j.artint.2022.103738},
  journal      = {Artificial Intelligence},
  pages        = {103738},
  shortjournal = {Artif. Intell.},
  title        = {A tetrachotomy of ontology-mediated queries with a covering axiom},
  volume       = {309},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Result diversification by multi-objective evolutionary
algorithms with theoretical guarantees. <em>AIJ</em>, <em>309</em>,
103737. (<a href="https://doi.org/10.1016/j.artint.2022.103737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a ground set of items, the result diversification problem aims to select a subset with high “quality” and “diversity” while satisfying some constraints. It arises in various real-world artificial intelligence applications , such as web-based search, document summarization and feature selection, and also has applications in other areas, e.g., computational geometry , databases, finance and operations research. Previous algorithms are mainly based on greedy or local search. In this paper, we propose to reformulate the result diversification problem as a bi-objective maximization problem, and solve it by a multi-objective evolutionary algorithm (EA), i.e., the GSEMO. We theoretically prove that the GSEMO can achieve the (asymptotically) optimal theoretical guarantees under both static and dynamic environments. For cardinality constraints, the GSEMO can achieve the optimal polynomial-time approximation ratio, 1/2. For more general matroid constraints, the GSEMO can achieve an asymptotically optimal polynomial-time approximation ratio, 1 / 2 − ϵ / ( 4 n ) 1/2−ϵ/(4n) , where ϵ &gt; 0 ϵ&amp;gt; 0 and n is the size of the ground set of items. Furthermore, when the objective function (i.e., a linear combination of quality and diversity) changes dynamically, the GSEMO can maintain this approximation ratio in polynomial running time, addressing the open question proposed by Borodin et al. [7] . This also theoretically shows the superiority of EAs over local search for solving dynamic optimization problems for the first time, and discloses the robustness of the mutation operator of EAs against dynamic changes. Experiments on the applications of web-based search, multi-label feature selection and document summarization show the superior performance of the GSEMO over the state-of-the-art algorithms (i.e., the greedy algorithm and local search) under both static and dynamic environments.},
  archive      = {J_AIJ},
  author       = {Chao Qian and Dan-Xuan Liu and Zhi-Hua Zhou},
  doi          = {10.1016/j.artint.2022.103737},
  journal      = {Artificial Intelligence},
  pages        = {103737},
  shortjournal = {Artif. Intell.},
  title        = {Result diversification by multi-objective evolutionary algorithms with theoretical guarantees},
  volume       = {309},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge-based strategies for multi-agent teams playing
against nature. <em>AIJ</em>, <em>309</em>, 103728. (<a
href="https://doi.org/10.1016/j.artint.2022.103728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study teams of agents that play against Nature towards achieving a common objective. The agents are assumed to have imperfect information due to partial observability , and have no communication during the play of the game. We propose a natural notion of higher-order knowledge of agents. Based on this notion, we define a class of knowledge-based strategies, and consider the problem of synthesis of strategies of this class. We introduce a multi-agent extension, MKBSC , of the well-known knowledge-based subset construction applied to such games. Its iterative applications turn out to compute higher-order knowledge of the agents. We show how the MKBSC can be used for the design of knowledge-based strategy profiles, and investigate the transfer of existence of such strategies between the original game and in the iterated applications of the MKBSC, under some natural assumptions. We also relate and compare the “intensional” view on knowledge-based strategies based on explicit knowledge representation and update, with the “extensional” view on finite memory strategies based on finite transducers and show that, in a certain sense, these are equivalent.},
  archive      = {J_AIJ},
  author       = {Dilian Gurov and Valentin Goranko and Edvin Lundberg},
  doi          = {10.1016/j.artint.2022.103728},
  journal      = {Artificial Intelligence},
  pages        = {103728},
  shortjournal = {Artif. Intell.},
  title        = {Knowledge-based strategies for multi-agent teams playing against nature},
  volume       = {309},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-informed knowledge and strategies. <em>AIJ</em>,
<em>309</em>, 103727. (<a
href="https://doi.org/10.1016/j.artint.2022.103727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article proposes a new approach to reasoning about knowledge and strategies in multiagent systems. It emphasizes data, not agents, as the source of strategic knowledge. The approach brings together Armstrong&#39;s functional dependency from database theory, a data-informed knowledge modality based on a recent work by Baltag and van Benthem, and a newly proposed data-informed strategy modality. The main technical result is a sound and complete logical system that describes the interplay between these three logical operators.},
  archive      = {J_AIJ},
  author       = {Junli Jiang and Pavel Naumov},
  doi          = {10.1016/j.artint.2022.103727},
  journal      = {Artificial Intelligence},
  pages        = {103727},
  shortjournal = {Artif. Intell.},
  title        = {Data-informed knowledge and strategies},
  volume       = {309},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diagnosability of fair transition systems. <em>AIJ</em>,
<em>309</em>, 103725. (<a
href="https://doi.org/10.1016/j.artint.2022.103725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integrity of complex dynamic systems often relies on the ability to detect, during operation, the occurrence of faults, or, in other words, to diagnose the system. The feasibility of this task, also known as diagnosability , depends on the nature of the system dynamics , the impact of faults, and the availability of a suitable set of sensors. Standard techniques for analyzing the diagnosability problem rely on a model of the system and on proving the absence of a faulty trace that cannot be distinguished by a non-faulty one (this pair of traces is called critical pair ). In this paper, we tackle the problem of verifying diagnosability under the presence of fairness conditions. These extend the expressiveness of the system models enabling the specification of assumptions on the system behavior such as the infinite occurrence of observations and/or faults. We adopt a comprehensive framework that encompasses fair transition systems, temporally extended fault models, delays between the occurrence of a fault and its detection, and rich operational contexts . We show that in presence of fairness the definition of diagnosability has several interesting variants, and discuss the relative strengths and the mutual relationships. We prove that the existence of critical pairs is not always sufficient to analyze diagnosability, and needs to be generalized to critical sets . We define new notions of critical pairs, called ribbon-shape , with special looping conditions to represent the critical sets. Based on these findings, we provide algorithms to prove the diagnosability under fairness. The approach is built on top of the classical twin plant construction, and generalizes it to cover the various forms of diagnosability and find sufficient delays. The proposed algorithms are implemented within the xSAP platform for safety analysis, leveraging efficient symbolic model checking primitives. An experimental evaluation on a heterogeneous set of realistic benchmarks from various application domains demonstrates the effectiveness of the approach.},
  archive      = {J_AIJ},
  author       = {Benjamin Bittner and Marco Bozzano and Alessandro Cimatti and Marco Gario and Stefano Tonetta and Viktoria Vozarova},
  doi          = {10.1016/j.artint.2022.103725},
  journal      = {Artificial Intelligence},
  pages        = {103725},
  shortjournal = {Artif. Intell.},
  title        = {Diagnosability of fair transition systems},
  volume       = {309},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scheduling with complete multipartite incompatibility graph
on parallel machines: Complexity and algorithms. <em>AIJ</em>,
<em>309</em>, 103711. (<a
href="https://doi.org/10.1016/j.artint.2022.103711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of scheduling on parallel machines with a presence of incompatibilities between jobs is considered. The incompatibility relation can be modeled as a complete multipartite graph in which each edge denotes a pair of jobs that cannot be scheduled on the same machine. The paper provides several results concerning schedules, optimal or approximate with respect to the two most popular criteria of optimality : C max Cmax (makespan) and ∑ C j ∑Cj (total completion time). The problems are considered for a variety of machine types: identical, uniform and unrelated. The results consist of delimitation of the easy (polynomial) and NP-hard problems within these constraints. Also, polynomial-time exact algorithms are provided for easier problems and algorithms with a guaranteed constant worst-case approximation ratio for harder ones. In particular, there is provided a polynomial-time approximation scheme (PTAS) for scheduling with respect to ∑ C j ∑Cj on uniform machines, when the number of parts (i.e. sets of vertices constituting the mentioned graph) is bounded. The problem is addressed by developing a linear programming relaxation technique with appropriate rounding. This technique together with an exhaustive search (albeit in a manner controlled by the precision parameter) allows to provide the desired algorithm. For C max Cmax a PTAS is provided for the case of unit time jobs, but when the number of parts is part of the input. Interestingly, the latter result shows a connection between the considered problem of scheduling and covering problems.},
  archive      = {J_AIJ},
  author       = {Tytus Pikies and Krzysztof Turowski and Marek Kubale},
  doi          = {10.1016/j.artint.2022.103711},
  journal      = {Artificial Intelligence},
  pages        = {103711},
  shortjournal = {Artif. Intell.},
  title        = {Scheduling with complete multipartite incompatibility graph on parallel machines: Complexity and algorithms},
  volume       = {309},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modular materialisation of datalog programs. <em>AIJ</em>,
<em>308</em>, 103726. (<a
href="https://doi.org/10.1016/j.artint.2022.103726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Answering queries over large datasets extended with Datalog rules plays a key role in numerous data management applications, and it has been implemented in several highly optimised Datalog systems in both academic and commercial contexts. Many systems implement reasoning via materialisation , which involves precomputing all consequences of the rules and the dataset in a preprocessing step . Some systems also use incremental reasoning algorithms, which can update the materialisation efficiently when the input dataset changes. Such techniques allow queries to be processed without any reference to the rules, so they are often used in applications where the performance of query answering is critical. Existing materialisation and incremental reasoning techniques enumerate all possible ways to apply rules to the data in order to derive all relevant consequences. This, however, can be inefficient because derivations of rules commonly used in practice are redundant; for example, rules axiomatising a binary predicate as symmetric and transitive can have a cubic number of applications, yet they can derive at most a quadratic number of facts. Such redundancy can be a significant source of overhead in practice and can prevent Datalog systems from successfully processing large datasets. To address this issue, in this paper we present a novel framework for modular materialisation and incremental reasoning . Our key idea is that, for certain combinations of rules commonly used in practice, all consequences can be derived using specialised procedures that do not necessarily enumerate all possible rule applications. Thus, our framework supports materialisation and incremental reasoning via a collection of modules . Each module is responsible for deriving consequences of a subset of the program, by using either standard rule application or proprietary algorithms. We prove that such an approach is complete as long as each module satisfies certain properties. Our formalisation of a module is very general, and in fact it allows modules to keep arbitrary auxiliary information. We also show how to realise custom procedures for four types of modules: transitivity, symmetry–transitivity, chain rules, and sequencing elements of a total order. Finally, we demonstrate empirically that using our custom procedures can speed up materialisation and incremental reasoning by several orders of magnitude on several well-known benchmarks. Thus, our technique has the potential to significantly improve the scalability of Datalog reasoners .},
  archive      = {J_AIJ},
  author       = {Pan Hu and Boris Motik and Ian Horrocks},
  doi          = {10.1016/j.artint.2022.103726},
  journal      = {Artificial Intelligence},
  pages        = {103726},
  shortjournal = {Artif. Intell.},
  title        = {Modular materialisation of datalog programs},
  volume       = {308},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Verification of agent navigation in partially-known
environments. <em>AIJ</em>, <em>308</em>, 103724. (<a
href="https://doi.org/10.1016/j.artint.2022.103724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper establishes a framework based on logic and automata theory in which to model and automatically verify systems of multiple mobile agents moving in environments with partially-known topologies, i.e., ones which are not completely known at design time. Examples include physical agents designed to be used in many spatial environments and not tailored for a specific one, robots in environments not reachable by humans, and software exploring partially-mapped networks. We model spatial environments as graphs whose edges are labelled with directions . We model agents as finite-state machines that move on the graphs by issuing commands of the form “go in direction X”, that can communicate their internal state to other agents, and that can sense agent positions (including current and visited positions). We treat the incomplete information about the spatial environment by studying the decision problem that asks whether a given collection of agents achieve their tasks on all graphs from a class of graphs — this is called the parameterised verification problem . The framework also introduces a new logical language based on Linear Temporal Logic that is tailored for expressing agent navigation tasks in such environments. Although the parameterised verification problem is undecidable, we identify two key dimensions that need to be limited in order to regain decidability, namely, the set of graph-environments and the amount of sensing and communication between agents. In particular, one should limit the families of graphs to exclude grids, and there should be a bound on the number of times an agent senses the position of another agent or communicates its own state to another agent. We prove that dropping either of these assumptions results in undecidability, even for agents with severe restrictions on their abilities (e.g., with very limited sensing abilities and no communication abilities). The importance of this work is that a) it provides a general computational model for mobile multi-agent systems in environments with partially-known topologies, b) it identifies, for the first time, the precise causes of undecidability of these systems and presents minimal restrictions to alleviate this problem, and c) it provides a generic sound and complete procedure for solving the parameterised verification problem over a broad range of spatial-environments and for agents with very powerful sensing and communication abilities.},
  archive      = {J_AIJ},
  author       = {Benjamin Aminof and Aniello Murano and Sasha Rubin and Florian Zuleger},
  doi          = {10.1016/j.artint.2022.103724},
  journal      = {Artificial Intelligence},
  pages        = {103724},
  shortjournal = {Artif. Intell.},
  title        = {Verification of agent navigation in partially-known environments},
  volume       = {308},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Emotional conversation generation with heterogeneous graph
neural network. <em>AIJ</em>, <em>308</em>, 103714. (<a
href="https://doi.org/10.1016/j.artint.2022.103714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The successful emotional conversation system depends on sufficient perception and appropriate expression of emotions. In a real-life conversation, humans firstly instinctively perceive emotions from multi-source information, including the emotion flow hidden in dialogue history , facial expressions, audio, and personalities of speakers. Then, they convey suitable emotions according to their personalities, but these multiple types of information are insufficiently exploited in emotional conversation fields. To address this issue, in this paper, we propose a heterogeneous graph-based model for emotional conversation generation. Firstly, we design a Heterogeneous Graph-Based Encoder to represent the conversation content ( i.e. , the dialogue history , its emotion flow, facial expressions, audio, and speakers&#39; personalities) with a heterogeneous graph neural network , and then predict suitable emotions for feedback. Secondly, we employ an Emotion-Personality-Aware Decoder to generate a response relevant to the conversation context as well as with appropriate emotions, through taking the encoded graph representations , the predicted emotions by the encoder and the personality of the current speaker as inputs. Experiments on both automatic and human evaluation show that our method can effectively perceive emotions from multi-source knowledge and generate a satisfactory response. Furthermore, based on the up-to-date text generator BART, our model still can achieve consistent improvement, which significantly outperforms some existing state-of-the-art models.},
  archive      = {J_AIJ},
  author       = {Yunlong Liang and Fandong Meng and Ying Zhang and Yufeng Chen and Jinan Xu and Jie Zhou},
  doi          = {10.1016/j.artint.2022.103714},
  journal      = {Artificial Intelligence},
  pages        = {103714},
  shortjournal = {Artif. Intell.},
  title        = {Emotional conversation generation with heterogeneous graph neural network},
  volume       = {308},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The distortion of distributed metric social choice.
<em>AIJ</em>, <em>308</em>, 103713. (<a
href="https://doi.org/10.1016/j.artint.2022.103713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a social choice setting with agents that are partitioned into disjoint groups, and have metric preferences over a set of alternatives. Our goal is to choose a single alternative aiming to optimize various objectives that are functions of the distances between agents and alternatives in the metric space, under the constraint that this choice must be made in a distributed way: The preferences of the agents within each group are first aggregated into a representative alternative for the group, and then these group representatives are aggregated into the final winner. Deciding the winner in such a way naturally leads to loss of efficiency, even when complete information about the metric space is available. We provide a series of (mostly tight) bounds on the distortion of distributed mechanisms for variations of well-known objectives, such as the (average) total cost and the maximum cost, and also for new objectives that are particularly appropriate for this distributed setting and have not been studied before.},
  archive      = {J_AIJ},
  author       = {Elliot Anshelevich and Aris Filos-Ratsikas and Alexandros A. Voudouris},
  doi          = {10.1016/j.artint.2022.103713},
  journal      = {Artificial Intelligence},
  pages        = {103713},
  shortjournal = {Artif. Intell.},
  title        = {The distortion of distributed metric social choice},
  volume       = {308},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A polynomial reduction of forks into logic programs.
<em>AIJ</em>, <em>308</em>, 103712. (<a
href="https://doi.org/10.1016/j.artint.2022.103712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research note we present additional results for an earlier published paper [1] . There, we studied the problem of projective strong equivalence (PSE) of logic programs, that is, checking whether two logic programs (or propositional formulas) have the same behaviour (under the stable model semantics) regardless of a common context and ignoring the effect of local auxiliary atoms. PSE is related to another problem called strongly persistent forgetting that consists in keeping a program&#39;s behaviour after removing its auxiliary atoms, something that is known to be not always possible in Answer Set Programming . In [1] , we introduced a new connective ‘|’ called fork and proved that, in this extended language, it is always possible to forget auxiliary atoms, but at the price of obtaining a result containing forks. We also proved that forks can be translated back to logic programs introducing new hidden auxiliary atoms, but this translation was exponential in the worst case. In this note we provide a new polynomial translation of arbitrary forks into regular programs that allows us to prove that brave and cautious reasoning with forks has the same complexity as that of ordinary (disjunctive) logic programs and paves the way for an efficient implementation of forks. To this aim, we rely on a pair of new PSE invariance properties .},
  archive      = {J_AIJ},
  author       = {Felicidad Aguado and Pedro Cabalar and Jorge Fandinno and David Pearce and Gilberto Pérez and Concepción Vidal},
  doi          = {10.1016/j.artint.2022.103712},
  journal      = {Artificial Intelligence},
  pages        = {103712},
  shortjournal = {Artif. Intell.},
  title        = {A polynomial reduction of forks into logic programs},
  volume       = {308},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A complete classification of the complexity and
rewritability of ontology-mediated queries based on the description
logic EL. <em>AIJ</em>, <em>308</em>, 103709. (<a
href="https://doi.org/10.1016/j.artint.2022.103709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a fine-grained analysis of the data complexity and rewritability of ontology-mediated queries (OMQs) based on an EL EL ontology and a conjunctive query (CQ). Our main results are that every such OMQ is in},
  archive      = {J_AIJ},
  author       = {Carsten Lutz and Leif Sabellek},
  doi          = {10.1016/j.artint.2022.103709},
  journal      = {Artificial Intelligence},
  pages        = {103709},
  shortjournal = {Artif. Intell.},
  title        = {A complete classification of the complexity and rewritability of ontology-mediated queries based on the description logic EL},
  volume       = {308},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning infinite-word automata with loop-index queries.
<em>AIJ</em>, <em>307</em>, 103710. (<a
href="https://doi.org/10.1016/j.artint.2022.103710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new framework for active learning of deterministic infinite-words automata . In our framework, the teacher answers standard membership and equivalence queries, and additionally it provides the loop index of the target automaton on w v ω wvω , which is the minimal number of letters of w v ω wvω past which the target automaton reaches the final cycle on w v ω wvω . We argue that in potential applications if one can answer Boolean part in membership (and equivalence) queries, one can compute the loop index as well. Our framework is an extension of Angluin&#39;s ⁎ L ⁎ L⁎ -algorithm with the crucial difference that the queries about the loop index depend on a particular automaton representing an ω -regular language. This allows us to bypass the NP-hardness coming from the minimisation problem for deterministic Büchi automata and provide a polynomial-time algorithm for learning deterministic weighted automata with value function. The algorithm can be easily adjusted for deterministic automata with value function and deterministic Büchi automata. Finally, deterministic parity automata, which recognize all ω -regular languages, can be considered as deterministic automata with value function and hence they can be learned in our framework.},
  archive      = {J_AIJ},
  author       = {Jakub Michaliszyn and Jan Otop},
  doi          = {10.1016/j.artint.2022.103710},
  journal      = {Artificial Intelligence},
  pages        = {103710},
  shortjournal = {Artif. Intell.},
  title        = {Learning infinite-word automata with loop-index queries},
  volume       = {307},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view graph convolutional networks with attention
mechanism. <em>AIJ</em>, <em>307</em>, 103708. (<a
href="https://doi.org/10.1016/j.artint.2022.103708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in graph convolutional networks (GCNs), which mainly focus on how to exploit information from different hops of neighbors in an efficient way, have brought substantial improvement to many graph data modeling tasks. Most of the existing GCN-based models however are built on the basis of a fixed adjacency matrix , i.e., a single view topology of the underlying graph. That inherently limits the expressive power of the developed models especially when the raw graphs are often noisy or even incomplete due to the inevitably error-prone data measurement or collection. In this paper, we propose a novel framework, termed Multi-View Graph Convolutional Networks with Attention Mechanism (MAGCN), by incorporating multiple views of topology and an attention-based feature aggregation strategy into the computation of graph convolution. As an advanced variant of GCNs, MAGCN is fed with multiple “trustable” topologies, which already exist for a given task or are empirically generated by some classical graph construction methods, which has good potential to produce a better learning representation for downstream tasks. Furthermore, we present some theoretical analysis about the expressive power and flexibility of MAGCN, which provides a general explanation as to why multi-view based methods can potentially outperform those relying on a single view. Our experimental study demonstrates the state-of-the-art accuracies of MAGCN on Cora, Citeseer, and Pubmed datasets. Robustness analysis is also undertaken to show the advantage of MAGCN in handling some uncertainty issues in node classification tasks.},
  archive      = {J_AIJ},
  author       = {Kaixuan Yao and Jiye Liang and Jianqing Liang and Ming Li and Feilong Cao},
  doi          = {10.1016/j.artint.2022.103708},
  journal      = {Artificial Intelligence},
  pages        = {103708},
  shortjournal = {Artif. Intell.},
  title        = {Multi-view graph convolutional networks with attention mechanism},
  volume       = {307},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on explainable artificial intelligence (XAI).
<em>AIJ</em>, <em>307</em>, 103705. (<a
href="https://doi.org/10.1016/j.artint.2022.103705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The special issue on Explainable Artificial Intelligence (XAI) provides a representative snapshot of the state of the art in the 2020-2021 time-frame and highlights future research directions. The scope of the special issue is intentionally broad, ranging from technical contributions to human-centered studies, from surveys to philosophical perspectives. A total of 97 papers were submitted for the special issue, of which 27 were finally accepted for publication after thorough peer review.},
  archive      = {J_AIJ},
  author       = {Tim Miller and Robert Hoffman and Ofra Amir and Andreas Holzinger},
  doi          = {10.1016/j.artint.2022.103705},
  journal      = {Artificial Intelligence},
  pages        = {103705},
  shortjournal = {Artif. Intell.},
  title        = {Special issue on explainable artificial intelligence (XAI)},
  volume       = {307},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Advanced algorithms for abstract dialectical frameworks
based on complexity analysis of subclasses and SAT solving.
<em>AIJ</em>, <em>307</em>, 103697. (<a
href="https://doi.org/10.1016/j.artint.2022.103697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract dialectical frameworks (ADFs) constitute one of the most powerful formalisms in abstract argumentation. Their high computational complexity poses, however, certain challenges when designing efficient systems. In this paper, we tackle this issue by (i) analyzing the complexity of ADFs under structural restrictions, (ii) presenting novel algorithms which make use of these insights, and (iii) implementing these algorithms via (multiple) calls to SAT solvers. An empirical evaluation of the resulting implementation on ADF benchmarks generated from ICCMA competitions shows that our solver is able to outperform state-of-the-art ADF systems.},
  archive      = {J_AIJ},
  author       = {Thomas Linsbichler and Marco Maratea and Andreas Niskanen and Johannes P. Wallner and Stefan Woltran},
  doi          = {10.1016/j.artint.2022.103697},
  journal      = {Artificial Intelligence},
  pages        = {103697},
  shortjournal = {Artif. Intell.},
  title        = {Advanced algorithms for abstract dialectical frameworks based on complexity analysis of subclasses and SAT solving},
  volume       = {307},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analyzing generalized planning under nondeterminism.
<em>AIJ</em>, <em>307</em>, 103696. (<a
href="https://doi.org/10.1016/j.artint.2022.103696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In automated planning, there has been a recent interest in solving a class of problems, where a single solution applies for multiple, possibly infinitely many, instances. This necessitates a generalized notion of plans, such as plans with loops. However, the correctness of such plans is non-trivial to define, making it difficult to provide a clear specification of what we should be looking for. In an influential paper, Levesque proposed a formal specification for analyzing the correctness of such plans. He motivated a logical characterization within the situation calculus that included binary sensing actions. This characterization argued that from each state considered possible initially, the plan should terminate while satisfying the goal. Increasingly, classical plan structures are being applied to stochastic environments such as robotics applications . This raises the question as to what the specification for correctness should look like, since Levesque&#39;s account makes the assumption that actions are deterministic. In this work, we aim to generalize Levesque&#39;s account to handle actions with nondeterministic outcomes, which may also be accorded probabilities. By appealing to an extension of the situation calculus to handle probabilistic nondeterminism , we will show that Levesque&#39;s definition, as well as a notion of goal achievability proposed by Lin and Levesque, have limited appeal under stochastic nondeterminism. In essence, they correspond to one correct execution, which is unlikely to be adequate. Rather, we propose to delineate between goal satisfaction and termination leading to a range of correctness criteria. To better study these criteria, and to position the results in a broader context while still allowing for the generality of the situation calculus, we consider an abstract framework to study the correctness of plans with loops, in domains that are possibly unbounded, and/or stochastic, and/or continuous. Within that framework, we then prove numerous relationships between the criteria, including some impossibility results for categorically satisfying goals. Finally, we show that these notions provide a more granular view than those discussed in the literature, such as strong planning and strong cyclic planning.},
  archive      = {J_AIJ},
  author       = {Vaishak Belle},
  doi          = {10.1016/j.artint.2022.103696},
  journal      = {Artificial Intelligence},
  pages        = {103696},
  shortjournal = {Artif. Intell.},
  title        = {Analyzing generalized planning under nondeterminism},
  volume       = {307},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decidability and complexity of action-based temporal
planning over dense time. <em>AIJ</em>, <em>307</em>, 103686. (<a
href="https://doi.org/10.1016/j.artint.2022.103686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the computational complexity of action-based temporal planning interpreted over dense time. When time is assumed to be discrete, the problem is known to be EXPSPACE -complete. However, the official PDDL 2.1 semantics and many implementations interpret time as a dense domain. This work provides several results about the complexity of the problem, focusing on some particularly interesting cases: whether a minimum amount ε of separation between mutually exclusive events is given, in contrast to the separation being simply required to be non-zero, and whether or not actions are allowed to overlap already running instances of themselves. We prove the problem to be PSPACE -complete when self-overlap is forbidden, whereas, when it is allowed, it becomes EXPSPACE -complete with ε -separation and even undecidable with non-zero separation. These results clarify the computational consequences of different choices in the definition at the core of the PDDL 2.1 semantics, which have been vague until now. 1},
  archive      = {J_AIJ},
  author       = {Nicola Gigante and Andrea Micheli and Angelo Montanari and Enrico Scala},
  doi          = {10.1016/j.artint.2022.103686},
  journal      = {Artificial Intelligence},
  pages        = {103686},
  shortjournal = {Artif. Intell.},
  title        = {Decidability and complexity of action-based temporal planning over dense time},
  volume       = {307},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inconsistency-tolerant query answering for existential
rules. <em>AIJ</em>, <em>307</em>, 103685. (<a
href="https://doi.org/10.1016/j.artint.2022.103685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Querying inconsistent knowledge bases is an intriguing problem that gave rise to a flourishing research activity in the knowledge representation and reasoning community during the last years. It has been extensively studied in the context of description logics (DLs), and its computational complexity is rather well-understood. Although DLs are popular formalisms for modeling ontologies, it is generally agreed that rule-based ontologies are well-suited for data-intensive applications, since they allow us to conveniently deal with higher-arity relations, which naturally occur in standard relational databases . The goal of this work is to perform an in-depth complexity analysis of querying inconsistent knowledge bases in the case of the main decidable classes of existential rules, based on the notions of guardedness, linearity, acyclicity, and stickiness, enriched with negative (a.k.a. denial) constraints. Our investigation concentrates on three central inconsistency-tolerant semantics: the ABox repair (AR) semantics, considered as the standard one, and its main sound approximations , the intersection of repairs (IAR) semantics and the intersection of closed repairs (ICR) semantics.},
  archive      = {J_AIJ},
  author       = {Thomas Lukasiewicz and Enrico Malizia and Maria Vanina Martinez and Cristian Molinaro and Andreas Pieris and Gerardo I. Simari},
  doi          = {10.1016/j.artint.2022.103685},
  journal      = {Artificial Intelligence},
  pages        = {103685},
  shortjournal = {Artif. Intell.},
  title        = {Inconsistency-tolerant query answering for existential rules},
  volume       = {307},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian agency: Linear versus tractable contracts.
<em>AIJ</em>, <em>307</em>, 103684. (<a
href="https://doi.org/10.1016/j.artint.2022.103684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study principal-agent problems in which a principal commits to an outcome-dependent payment scheme (a.k.a. contract ) so as to induce an agent to take a costly, unobservable action. We relax the assumption that the principal perfectly knows the agent by considering a Bayesian setting where the agent&#39;s type is unknown and randomly selected according to a given probability distribution, which is known to the principal. Each agent&#39;s type is characterized by her own action costs and action-outcome distributions. In the literature on non-Bayesian principal-agent problems, considerable attention has been devoted to linear contracts , which are simple, pure-commission payment schemes that still provide nice approximation guarantees with respect to principal-optimal (possibly non-linear) contracts. While in non-Bayesian settings an optimal contract can be computed efficiently, this is no longer the case for our Bayesian principal-agent problems. This further motivates our focus on linear contracts, which can be optimized efficiently given their single-parameter nature. Our goal is to analyze the properties of linear contracts in Bayesian settings, in terms of approximation guarantees with respect to optimal contracts and general tractable contracts ( i.e. , efficiently-computable ones). First, we study the approximation guarantees of linear contracts with respect to optimal ones, showing that the former suffer from a multiplicative loss that grows linearly in the number of agent&#39;s types. Nevertheless, we prove that linear contracts can still provide a constant multiplicative approximation ρ of the optimal principal&#39;s expected utility, though at the expense of an exponentially-small additive loss 2 − Ω ( ρ ) 2−Ω(ρ) . Then, we switch to tractable contracts, showing that, surprisingly, linear contracts perform well among them. In particular, we prove that it is NP -hard to design a contract providing a multiplicative loss sublinear in the number of agent&#39;s types, while the same holds for contracts that provide a constant multiplicative approximation ρ at the expense of an additive loss 2 − ω ( ρ ) 2−ω(ρ) . We conclude by showing that, in Bayesian principal-agent problems, an optimal contract can be computed efficiently if we fix either the number of agent&#39;s types or the number of outcomes.},
  archive      = {J_AIJ},
  author       = {Matteo Castiglioni and Alberto Marchesi and Nicola Gatti},
  doi          = {10.1016/j.artint.2022.103684},
  journal      = {Artificial Intelligence},
  pages        = {103684},
  shortjournal = {Artif. Intell.},
  title        = {Bayesian agency: Linear versus tractable contracts},
  volume       = {307},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient projection algorithms onto the weighted ℓ1 ball.
<em>AIJ</em>, <em>306</em>, 103683. (<a
href="https://doi.org/10.1016/j.artint.2022.103683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Projected gradient descent has been proved efficient in many optimization and machine learning problems. The weighted ℓ 1 ℓ1 ball has been shown effective in sparse system identification and features selection. In this paper we propose three new efficient algorithms for projecting any vector of finite length onto the weighted ℓ 1 ℓ1 ball. The first two algorithms have a linear worst case complexity. The third one has a highly competitive performances in practice but the worst case has a quadratic complexity. These new algorithms are efficient tools for machine learning methods based on projected gradient descent such as compressed sensing , feature selection. We illustrate this effectiveness by adapting an efficient compressed sensing algorithm to weighted projections. We demonstrate the efficiency of our new algorithms on benchmarks using very large vectors. For instance, it requires only 8 ms, on an Intel I7 3rd generation, for projecting vectors of size 10 7 .},
  archive      = {J_AIJ},
  author       = {Guillaume Perez and Sebastian Ament and Carla Gomes and Michel Barlaud},
  doi          = {10.1016/j.artint.2022.103683},
  journal      = {Artificial Intelligence},
  pages        = {103683},
  shortjournal = {Artif. Intell.},
  title        = {Efficient projection algorithms onto the weighted ℓ1 ball},
  volume       = {306},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The delay and window size problems in rule-based stream
reasoning. <em>AIJ</em>, <em>306</em>, 103668. (<a
href="https://doi.org/10.1016/j.artint.2022.103668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been an increasing interest in extending stream processing engines with rule-based temporal reasoning capabilities. To ensure correctness, such systems must be able to output results over the partial data received so far as if the entire (infinite) stream had been available; furthermore, these results must be streamed out as soon as the relevant data is received, thus incurring the minimum possible delay; finally, due to memory limitations, systems can only keep a limited history of previous facts in memory to perform further computations. These requirements pose significant theoretical and practical challenges since temporal rules can derive new information and propagate it both towards past and future time points; as a result, streamed answers can depend on data that has not yet been received, as well as on data that arrived far in the past. Towards developing a solid foundation for practical rule-based stream reasoning, we propose and study in this paper a suite of decision problems that can be exploited by stream reasoning algorithms to tackle the aforementioned challenges, and provide tight complexity bounds for a core temporal extension of Datalog . All of the problems we consider can be solved at design time (under reasonable assumptions), prior to the processing of any data. Solving these problems enables the use of reasoning algorithms that process the input streams incrementally using a sliding window, while at the same time supporting an expressive rule-based knowledge representation language and minimising both latency and memory consumption.},
  archive      = {J_AIJ},
  author       = {Alessandro Ronca and Mark Kaminski and Bernardo Cuenca Grau and Ian Horrocks},
  doi          = {10.1016/j.artint.2022.103668},
  journal      = {Artificial Intelligence},
  pages        = {103668},
  shortjournal = {Artif. Intell.},
  title        = {The delay and window size problems in rule-based stream reasoning},
  volume       = {306},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Relation between prognostics predictor evaluation metrics
and local interpretability SHAP values. <em>AIJ</em>, <em>306</em>,
103667. (<a href="https://doi.org/10.1016/j.artint.2022.103667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintenance decisions in domains such as aeronautics are becoming increasingly dependent on being able to predict the failure of components and systems. When data-driven techniques are used for this prognostic task, they often face headwinds due to their perceived lack of interpretability. To address this issue, this paper examines how features used in a data-driven prognostic approach correlate with established metrics of monotonicity, trendability, and prognosability. In particular, we use the SHAP model (SHapley Additive exPlanations) from the field of eXplainable Artificial Intelligence (XAI) to analyze the outcome of three increasingly complex algorithms: Linear Regression, Multi-Layer Perceptron, and Echo State Network. Our goal is to test the hypothesis that the prognostics metrics correlate with the SHAP model&#39;s explanations, i.e., the SHAP values. We use baseline data from a standard data set that contains several hundred run-to-failure trajectories for jet engines. The results indicate that SHAP values track very closely with these metrics with differences observed between the models that support the assertion that model complexity is a significant factor to consider when explainability is a consideration in prognostics.},
  archive      = {J_AIJ},
  author       = {Marcia L. Baptista and Kai Goebel and Elsa M.P. Henriques},
  doi          = {10.1016/j.artint.2022.103667},
  journal      = {Artificial Intelligence},
  pages        = {103667},
  shortjournal = {Artif. Intell.},
  title        = {Relation between prognostics predictor evaluation metrics and local interpretability SHAP values},
  volume       = {306},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sensitive loss: Improving accuracy and fairness of face
representations with discrimination-aware deep learning. <em>AIJ</em>,
<em>305</em>, 103682. (<a
href="https://doi.org/10.1016/j.artint.2022.103682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a discrimination-aware learning method to improve both the accuracy and fairness of biased face recognition algorithms . The most popular face recognition benchmarks assume a distribution of subjects without paying much attention to their demographic attributes. In this work, we perform a comprehensive discrimination-aware experimentation of deep learning-based face recognition. We also propose a notational framework for algorithmic discrimination with application to face biometrics . The experiments include three popular face recognition models and three public databases composed of 64, 000 identities from different demographic groups characterized by sex and ethnicity. We experimentally show that learning processes based on the most used face databases have led to popular pre-trained deep face models that present evidence of strong algorithmic discrimination. Finally, we propose a discrimination-aware learning method, Sensitive Loss, based on the popular triplet loss function and a sensitive triplet generator. Our approach works as an add-on to pre-trained networks and is used to improve their performance in terms of average accuracy and fairness. The method shows results comparable to state-of-the-art de-biasing networks and represents a step forward to prevent discriminatory automatic systems.},
  archive      = {J_AIJ},
  author       = {Ignacio Serna and Aythami Morales and Julian Fierrez and Nick Obradovich},
  doi          = {10.1016/j.artint.2022.103682},
  journal      = {Artificial Intelligence},
  pages        = {103682},
  shortjournal = {Artif. Intell.},
  title        = {Sensitive loss: Improving accuracy and fairness of face representations with discrimination-aware deep learning},
  volume       = {305},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Memory-limited model-based diagnosis. <em>AIJ</em>,
<em>305</em>, 103681. (<a
href="https://doi.org/10.1016/j.artint.2022.103681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various model-based diagnosis scenarios require the computation of the most preferred fault explanations. Existing algorithms that are sound (i.e., output only actual fault explanations) and complete (i.e., can return all explanations), however, require exponential space to achieve this task. As a remedy, and to enable successful diagnosis both on memory-restricted devices and for memory-intensive problem cases, we propose two novel diagnostic search algorithms which build upon tried and tested techniques from the heuristic search domain. The first method, dubbed Recursive Best-First Hitting Set Search (RBF-HS), is based on Korf&#39;s well-known Recursive Best-First Search (RBFS) algorithm. We show that RBF-HS can enumerate an arbitrary predefined finite number of fault explanations in best-first order within linear space bounds, without sacrificing the desirable soundness or completeness properties. The second algorithm, called Hybrid Best-First Hitting Set Search (HBF-HS), is a hybrid between RBF-HS and Reiter&#39;s seminal HS-Tree. The idea is to find a trade-off between runtime optimization and a restricted space consumption that does not exceed the available memory. Notably, both suggested algorithms are generally applicable to any model-based diagnosis problem, regardless of the used (monotonic) logical language to describe the diagnosed system and of the used reasoning mechanism. We conducted extensive experiments on real-world benchmarks from the knowledge-based systems field, a domain where the features soundness, completeness, the best-first property as well as a general applicability are pivotal and where Reiter&#39;s HS-Tree is the predominantly used diagnostic search. The evaluation reveals that, when computing fault explanations minimal-cardinality-first, RBF-HS compared to HS-Tree reduces memory requirements substantially in most cases by up to several orders of magnitude, while also saving runtime in more than a third of the cases. When computing fault explanations most-probable-first, RBF-HS compared to HS-Tree tends to trade memory savings more or less one-to-one for runtime overheads. Whenever runtime overheads were significant, using HBF-HS instead of RBF-HS reduced the runtime to values comparable with HS-Tree while keeping the used memory reasonably bounded.},
  archive      = {J_AIJ},
  author       = {Patrick Rodler},
  doi          = {10.1016/j.artint.2022.103681},
  journal      = {Artificial Intelligence},
  pages        = {103681},
  shortjournal = {Artif. Intell.},
  title        = {Memory-limited model-based diagnosis},
  volume       = {305},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An abstract, logical approach to characterizing strong
equivalence in non-monotonic knowledge representation formalisms.
<em>AIJ</em>, <em>305</em>, 103680. (<a
href="https://doi.org/10.1016/j.artint.2022.103680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two knowledge bases are strongly equivalent if and only if they are mutually interchangeable in arbitrary contexts. This notion is of high interest for any logical formalism, since it allows to locally replace parts of a given theory without changing its meaning. In contrast to classical logic, where strong equivalence coincides with standard equivalence (having the same models), it is possible to find ordinary but not strongly equivalent objects for any nonmonotonic formalism available in the literature. Consequently, much effort has been devoted to characterizing strong equivalence for knowledge representation formalisms such as logic programs under the stable model semantics , Reiter&#39;s default logic, or Dung&#39;s argumentation frameworks. For example, strong equivalence for logic programs under stable models can be characterized by so-called HT-models. More precisely, two logic programs are strongly equivalent if and only if they are standard equivalent in the logic of here and there. This means that the logic of here and there can be seen as a characterizing formalism for logic programs under stable model semantics . The aim of this article is to study whether the existence of such characterization logics can be guaranteed for any logic. One main result is that every knowledge representation formalism that allows for a notion of strong equivalence on its finite knowledge bases also possesses a canonical characterizing formalism. In particular, we argue that those characterizing formalisms can be seen as classical, monotonic logics. Moreover, we will not only show the existence of characterizing formalism, but even that the model theory of any characterizing logic is uniquely determined (up to isomorphism).},
  archive      = {J_AIJ},
  author       = {Ringo Baumann and Hannes Strass},
  doi          = {10.1016/j.artint.2022.103680},
  journal      = {Artificial Intelligence},
  pages        = {103680},
  shortjournal = {Artif. Intell.},
  title        = {An abstract, logical approach to characterizing strong equivalence in non-monotonic knowledge representation formalisms},
  volume       = {305},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AI journal special issue on ethics for autonomous systems.
<em>AIJ</em>, <em>305</em>, 103677. (<a
href="https://doi.org/10.1016/j.artint.2022.103677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIJ},
  author       = {Michael Fisher and Sven Koenig and Marija Slavkovik},
  doi          = {10.1016/j.artint.2022.103677},
  journal      = {Artificial Intelligence},
  pages        = {103677},
  shortjournal = {Artif. Intell.},
  title        = {AI journal special issue on ethics for autonomous systems},
  volume       = {305},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A local method for identifying causal relations under markov
equivalence. <em>AIJ</em>, <em>305</em>, 103669. (<a
href="https://doi.org/10.1016/j.artint.2022.103669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality is important for designing interpretable and robust methods in artificial intelligence research. We propose a local approach to identify whether a variable is a cause of a given target under the framework of causal graphical models of directed acyclic graphs (DAGs). In general, the causal relation between two variables may not be identifiable from observational data as many causal DAGs encoding different causal relations are Markov equivalent. In this paper, we first introduce a sufficient and necessary graphical condition to check the existence of a causal path from a variable to a target in every Markov equivalent DAG. Next, we provide local criteria for identifying whether a variable is a cause/non-cause of a target based only on the local structure instead of the entire graph. Finally, we propose a local learning algorithm for this causal query via learning the local structure of the variable and some additional statistical independence tests related to the target. Simulation studies show that our local algorithm is efficient and effective, compared with other state-of-art methods.},
  archive      = {J_AIJ},
  author       = {Zhuangyan Fang and Yue Liu and Zhi Geng and Shengyu Zhu and Yangbo He},
  doi          = {10.1016/j.artint.2022.103669},
  journal      = {Artificial Intelligence},
  pages        = {103669},
  shortjournal = {Artif. Intell.},
  title        = {A local method for identifying causal relations under markov equivalence},
  volume       = {305},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A counter abstraction technique for verifying properties of
probabilistic swarm systems. <em>AIJ</em>, <em>305</em>, 103666. (<a
href="https://doi.org/10.1016/j.artint.2022.103666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a semantics for reasoning about probabilistic multi-agent systems in which the number of participants is not known at design-time. We define the parameterised model checking problem against PLTL specifications for this semantics, and observe that this is undecidable in general. Nonetheless, we develop a partial decision procedure for it based on counter abstraction. We prove the correctness of this procedure, and present an implementation of it. We then use our implementation to verify a number of example scenarios from swarm robotics and other settings.},
  archive      = {J_AIJ},
  author       = {Alessio Lomuscio and Edoardo Pirovano},
  doi          = {10.1016/j.artint.2022.103666},
  journal      = {Artificial Intelligence},
  pages        = {103666},
  shortjournal = {Artif. Intell.},
  title        = {A counter abstraction technique for verifying properties of probabilistic swarm systems},
  volume       = {305},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised and few-shot parsing from pretrained language
models. <em>AIJ</em>, <em>305</em>, 103665. (<a
href="https://doi.org/10.1016/j.artint.2022.103665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pretrained language models are generally acknowledged to be able to encode syntax [46] , [16] , [13] . In this article, we propose UPOA, an Unsupervised constituent Parsing model that calculates an Out Association score solely based on the self-attention weight matrix learned in a pretrained language model as the syntactic distance for span segmentation. We further propose an enhanced version, UPIO, which exploits both inside association and outside association scores for estimating the likelihood of a span. Experiments with UPOA and UPIO disclose that the linear projection matrices for the query and key in the self-attention mechanism play an important role in parsing. We therefore extend the unsupervised models to few-shot parsing models (FPOA, FPIO) that use a few annotated trees to learn better linear projection matrices for parsing. Experiments on the Penn Treebank demonstrate that our unsupervised parsing model UPIO achieves results comparable to the state of the art on short sentences (length &lt;= 10). Our few-shot parsing model FPIO trained with only 20 annotated trees outperforms a previous few-shot parsing method trained with 50 annotated trees. Experiments on cross-lingual parsing show that both unsupervised and few-shot parsing methods are better than previous methods on most languages of SPMRL [39] .},
  archive      = {J_AIJ},
  author       = {Zhiyuan Zeng and Deyi Xiong},
  doi          = {10.1016/j.artint.2022.103665},
  journal      = {Artificial Intelligence},
  pages        = {103665},
  shortjournal = {Artif. Intell.},
  title        = {Unsupervised and few-shot parsing from pretrained language models},
  volume       = {305},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Envy-free allocations respecting social networks.
<em>AIJ</em>, <em>305</em>, 103664. (<a
href="https://doi.org/10.1016/j.artint.2022.103664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding an envy-free allocation of indivisible resources to agents is a central task in many multiagent systems. Often, non-trivial envy-free allocations do not exist and determining whether they exist is computationally hard even under highly restricted settings. Classical envy-freeness requires that every agent likes the resources allocated to it at least as much as the resources allocated to any other agent. In many situations this assumption can be relaxed since the agents often do not even know each other. We enrich the envy-freeness concept by taking into account (directed) social networks of the agents. Thus, we require that every agent likes its own allocation at least as much as those of all its (out)neighbors. This leads to a “more local” concept of envy-freeness. We also consider a “strong” variant where every agent must like its own allocation more than those of all its (out)neighbors. We analyze the classical and the parameterized complexity of finding allocations that are complete and, at the same time, envy-free with respect to one of the variants of our new concept. To this end, we study different restrictions of the agents&#39; preferences and of the social network structure . We identify cases that become easier (from Σ 2 P Σ2P -hard or NP-hard to polynomial-time solvable) and cases that become harder (from polynomial-time solvable to NP-hard) when comparing classical envy-freeness with our graph envy-freeness. Furthermore, we spot cases where graph envy-freeness is easier to decide than strong graph envy-freeness, and vice versa. On the route to one of our fixed-parameter tractability results, we also establish a connection to a directed and colored variant of the classical Subgraph Isomorphism problem, thereby extending a known fixed-parameter tractability result for the latter.},
  archive      = {J_AIJ},
  author       = {Robert Bredereck and Andrzej Kaczmarczyk and Rolf Niedermeier},
  doi          = {10.1016/j.artint.2022.103664},
  journal      = {Artificial Intelligence},
  pages        = {103664},
  shortjournal = {Artif. Intell.},
  title        = {Envy-free allocations respecting social networks},
  volume       = {305},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online joint bid/daily budget optimization of internet
advertising campaigns. <em>AIJ</em>, <em>305</em>, 103663. (<a
href="https://doi.org/10.1016/j.artint.2022.103663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pay-per-click advertising includes various formats ( e.g. , search, contextual, social) with a total investment of more than 200 billion USD per year worldwide. An advertiser is given a daily budget to allocate over several campaigns, mainly distinguishing for the ad, target, or channel. Furthermore, publishers choose the ads to display and how to allocate them employing auctioning mechanisms, in which, every day and for each campaign, the advertisers set a bid corresponding to the maximum amount of money per click they are willing to pay and the fraction of the daily budget to invest. In this paper, we study the problem of automating the online joint bid/daily budget optimization of pay-per-click advertising campaigns over multiple channels, and we face the challenging goal of designing techniques with theoretical guarantees that can be applied in real-world applications, where, commonly, data scarcity is a crucial issue. We formulate our problem as a combinatorial semi-bandit problem , which requires solving a special case of the Multiple-Choice Knapsack problem every day. Furthermore, we address data scarcity by designing a model for the dependency of the number of clicks on the bid and daily budget, requiring few parameters at the cost of mild regularity assumptions. We propose two algorithms—the first is randomized, while the second is deterministic—and show that they suffer from a regret that is upper bounded with high probability as O ˜ ( T ) O˜(T) , where T is the time horizon of the learning process. We experimentally evaluate our algorithms with synthetic settings generated from real data provided by Yahoo!, and we present the results of adopting our algorithms in a real-world application with a daily spent of 1 , 000 1, 000 Euros for more than one year.},
  archive      = {J_AIJ},
  author       = {Alessandro Nuara and Francesco Trovò and Nicola Gatti and Marcello Restelli},
  doi          = {10.1016/j.artint.2022.103663},
  journal      = {Artificial Intelligence},
  pages        = {103663},
  shortjournal = {Artif. Intell.},
  title        = {Online joint bid/daily budget optimization of internet advertising campaigns},
  volume       = {305},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-agent pathfinding with continuous time. <em>AIJ</em>,
<em>305</em>, 103662. (<a
href="https://doi.org/10.1016/j.artint.2022.103662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Pathfinding (MAPF) is the problem of finding paths for multiple agents such that each agent reaches its goal and the agents do not collide. In recent years, variants of MAPF have risen in a wide range of real-world applications such as warehouse management and autonomous vehicles. Optimizing common MAPF objectives, such as minimizing sum-of-costs or makespan, is computationally intractable, but state-of-the-art algorithms are able to solve optimally problems with dozens of agents. However, most MAPF algorithms assume that (1) time is discretized into time steps and (2) the duration of every action is one time step. These simplifying assumptions limit the applicability of MAPF algorithms in real-world applications and raise non-trivial questions such as how to discretize time in an effective manner. We propose two novel MAPF algorithms for finding optimal solutions that do not rely on any time discretization . In particular, our algorithms do not require quantization of wait and move actions&#39; durations, allowing these durations to take any value required to find optimal solutions. The first algorithm we propose, called Continuous-time Conflict-Based Search (CCBS), draws on ideas from Safe Interval Path Planning (SIPP), a single-agent pathfinding algorithm designed to cope with dynamic obstacles, and Conflict-Based Search (CBS), a state-of-the-art search-based MAPF algorithm. SMT-CCBS builds on similar ideas, but is based on a different state-of-the-art MAPF algorithm called SMT-CBS, which applied a SAT Modulo Theory (SMT) problem-solving procedure. CCBS guarantees to return solutions that have minimal sum-of-costs, while SMT-CCBS guarantees to return solutions that have minimal makespan. We implemented CCBS and SMT-CCBS and evaluated them on grid-based MAPF problems and general graphs (roadmaps). The results show that both algorithms can efficiently solve optimally non-trivial MAPF problems.},
  archive      = {J_AIJ},
  author       = {Anton Andreychuk and Konstantin Yakovlev and Pavel Surynek and Dor Atzmon and Roni Stern},
  doi          = {10.1016/j.artint.2022.103662},
  journal      = {Artificial Intelligence},
  pages        = {103662},
  shortjournal = {Artif. Intell.},
  title        = {Multi-agent pathfinding with continuous time},
  volume       = {305},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LMMS reloaded: Transformer-based sense embeddings for
disambiguation and beyond. <em>AIJ</em>, <em>305</em>, 103661. (<a
href="https://doi.org/10.1016/j.artint.2022.103661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributional semantics based on neural approaches is a cornerstone of Natural Language Processing , with surprising connections to human meaning representation as well. Recent Transformer-based Language Models have proven capable of producing contextual word representations that reliably convey sense-specific information, simply as a product of self-supervision. Prior work has shown that these contextual representations can be used to accurately represent large sense inventories as sense embeddings, to the extent that a distance-based solution to Word Sense Disambiguation (WSD) tasks outperforms models trained specifically for the task. Still, there remains much to understand on how to use these Neural Language Models (NLMs) to produce sense embeddings that can better harness each NLM&#39;s meaning representation abilities. In this work we introduce a more principled approach to leverage information from all layers of NLMs, informed by a probing analysis on 14 NLM variants. We also emphasize the versatility of these sense embeddings in contrast to task-specific models, applying them on several sense-related tasks, besides WSD, while demonstrating improved performance using our proposed approach over prior work focused on sense embeddings. Finally, we discuss unexpected findings regarding layer and model performance variations, and potential applications for downstream tasks.},
  archive      = {J_AIJ},
  author       = {Daniel Loureiro and Alípio Mário Jorge and Jose Camacho-Collados},
  doi          = {10.1016/j.artint.2022.103661},
  journal      = {Artificial Intelligence},
  pages        = {103661},
  shortjournal = {Artif. Intell.},
  title        = {LMMS reloaded: Transformer-based sense embeddings for disambiguation and beyond},
  volume       = {305},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantifying and alleviating political bias in language
models. <em>AIJ</em>, <em>304</em>, 103654. (<a
href="https://doi.org/10.1016/j.artint.2021.103654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current large-scale language models can be politically biased as a result of the data they are trained on, potentially causing serious problems when they are deployed in real-world settings. In this paper, we first describe metrics for measuring political bias in GPT-2 generation, and discuss several interesting takeaways: 1) The generation of vanilla GPT-2 model is mostly liberal-leaning, 2) Such political bias depends on the sensitive attributes mentioned in the context, and 3) Priming the generation with a explicit political identifier, the extent of political bias is imbalanced (between liberal and conservative). We then propose a reinforcement learning (RL) framework for mitigating such political biases in generated text: By using rewards from word embeddings or a classifier, our RL framework guides debiased generation without having access to the training data or requiring the model to be retrained. In empirical experiments on three attributes sensitive to political bias ( gender , location , and topic ), our methods reduced bias according to both our metrics and human evaluation, while maintaining readability and semantic coherence.},
  archive      = {J_AIJ},
  author       = {Ruibo Liu and Chenyan Jia and Jason Wei and Guangxuan Xu and Soroush Vosoughi},
  doi          = {10.1016/j.artint.2021.103654},
  journal      = {Artificial Intelligence},
  pages        = {103654},
  shortjournal = {Artif. Intell.},
  title        = {Quantifying and alleviating political bias in language models},
  volume       = {304},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploration-exploitation in multi-agent learning:
Catastrophe theory meets game theory. <em>AIJ</em>, <em>304</em>,
103653. (<a href="https://doi.org/10.1016/j.artint.2021.103653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploration-exploitation is a powerful and practical tool in multi-agent learning (MAL); however, its effects are far from understood. To make progress in this direction, we study a smooth analogue of Q-learning. We start by showing that our learning model has strong theoretical justification as an optimal model for studying exploration-exploitation. Specifically, we prove (1) that smooth Q-learning has bounded regret in arbitrary games for a cost model that explicitly balances game-rewards and exploration-costs, i.e., costs from testing potentially suboptimal actions, and (2) that it always converges to the set of quantal-response equilibria (QRE), the standard solution concept for games with bounded rationality, in arbitrary weighted potential games. In our main task, we then turn to measure the effect of exploration on collective system performance. We characterize the geometry of the QRE surface in low-dimensional MAL systems and link our findings with catastrophe (bifurcation) theory. In particular, as the exploration hyperparameter evolves over-time, the system undergoes phase transitions where the number and stability of equilibria can change radically given an infinitesimal change to the exploration parameter. Based on this, we provide a formal theoretical treatment of how tuning the exploration parameter can provably lead to equilibrium selection with both positive as well as negative (and potentially unbounded) effects to system performance.},
  archive      = {J_AIJ},
  author       = {Stefanos Leonardos and Georgios Piliouras},
  doi          = {10.1016/j.artint.2021.103653},
  journal      = {Artificial Intelligence},
  pages        = {103653},
  shortjournal = {Artif. Intell.},
  title        = {Exploration-exploitation in multi-agent learning: Catastrophe theory meets game theory},
  volume       = {304},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Imperfect ImaGANation: Implications of GANs exacerbating
biases on facial data augmentation and snapchat face lenses.
<em>AIJ</em>, <em>304</em>, 103652. (<a
href="https://doi.org/10.1016/j.artint.2021.103652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we show that popular Generative Adversarial Network (GAN) variants exacerbate biases along the axes of gender and skin tone in the generated data. The use of synthetic data generated by GANs is widely used for a variety of tasks ranging from data augmentation to stylizing images. While practitioners celebrate this method as an economical way to obtain synthetic data to train data-hungry machine learning models or provide new features to users of mobile applications, it is unclear whether they recognize the perils of such techniques when applied to real world datasets biased along latent dimensions. Although one expects GANs to replicate the distribution of the original data, in real-world settings with limited data and finite network capacity, GANs suffer from mode collapse . First, we show readily-accessible GAN variants such as DCGANs ‘imagine’ faces of synthetic engineering professors that have masculine facial features and fair skin tones. When using popular GAN architectures that attempt to address mode-collapse, we observe that these variants either provide a false sense of security or suffer from other inherent limitations due to their design choice. Second, we show that a conditional GAN variant transforms input images of female and nonwhite faces to have more masculine features and lighter skin when asked to generate faces of engineering professors. Worse yet, prevalent filters on Snapchat end up consistently lightening the skin tones in people of color when trying to make face images appear more feminine. Thus, our study is meant to serve as a cautionary tale for practitioners and educate them about the side-effect of bias amplification when applying GAN-based techniques.},
  archive      = {J_AIJ},
  author       = {Niharika Jain and Alberto Olmo and Sailik Sengupta and Lydia Manikonda and Subbarao Kambhampati},
  doi          = {10.1016/j.artint.2021.103652},
  journal      = {Artificial Intelligence},
  pages        = {103652},
  shortjournal = {Artif. Intell.},
  title        = {Imperfect ImaGANation: Implications of GANs exacerbating biases on facial data augmentation and snapchat face lenses},
  volume       = {304},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Treewidth-aware reductions of normal ASP to SAT – is normal
ASP harder than SAT after all? <em>AIJ</em>, <em>304</em>, 103651. (<a
href="https://doi.org/10.1016/j.artint.2021.103651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Answer Set Programming (ASP) is a paradigm for modeling and solving problems for knowledge representation and reasoning . There are plenty of results dedicated to studying the hardness of (fragments of) ASP. So far, these studies resulted in characterizations in terms of computational complexity as well as in fine-grained insights presented in form of dichotomy-style results, lower bounds when translating to other formalisms like propositional satisfiability (SAT), and even detailed parameterized complexity landscapes. A generic parameter in parameterized complexity originating from graph theory is the so-called treewidth , which in a sense captures structural density of a program. Recently, there was an increase in the number of treewidth-based solvers related to SAT. While there are translations from (normal) ASP to SAT, no reduction that preserves treewidth or at least keeps track of the treewidth increase is known. In this paper we propose a novel reduction from normal ASP to SAT that is aware of the treewidth, and guarantees that a slight increase of treewidth is indeed sufficient. Further, we show a new result establishing that, when considering treewidth, already the fragment of normal ASP is slightly harder than SAT (under reasonable assumptions in computational complexity). This also confirms that our reduction probably cannot be significantly improved and that the slight increase of treewidth is unavoidable. Finally, we present an empirical study of our novel reduction from normal ASP to SAT, where we compare treewidth upper bounds that are obtained via known decomposition heuristics. Overall, our reduction works better with these heuristics than existing translations.},
  archive      = {J_AIJ},
  author       = {Markus Hecher},
  doi          = {10.1016/j.artint.2021.103651},
  journal      = {Artificial Intelligence},
  pages        = {103651},
  shortjournal = {Artif. Intell.},
  title        = {Treewidth-aware reductions of normal ASP to SAT – is normal ASP harder than SAT after all?},
  volume       = {304},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exact stochastic constraint optimisation with applications
in network analysis. <em>AIJ</em>, <em>304</em>, 103650. (<a
href="https://doi.org/10.1016/j.artint.2021.103650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an extensive study of methods for exactly solving stochastic constraint (optimisation) problems (SCPs) in network analysis . These problems are prevalent in science, governance and industry. The first method we study is generic and decomposes stochastic constraints into a multitude of smaller local constraints that are solved using a constraint programming (CP) or mixed-integer programming (MIP) solver. However, many SCPs are formulated on probability distributions with a monotonic property, meaning that adding a positive decision to a partial solution to the problem cannot cause a decrease in solution quality. The second method is specifically designed for solving global stochastic constraints on monotonic probability distributions (SCMDs) in CP. Both methods use knowledge compilation to obtain a decision diagram encoding of the relevant probability distributions, where we focus on ordered binary decision diagrams (OBDDs). We discuss theoretical advantages and disadvantages of these methods and evaluate them experimentally. We observed that global approaches to solving SCMDs outperform decomposition approaches from CP, and perform complementarily to MIP-based decomposition approaches, while scaling much more favourably with instance size. Both methods have many alternative design choices, as both knowledge compilation and constraint solvers are used in a single pipeline. To identify which configurations work best, we apply programming by optimisation. Specifically, we show how an automated algorithm configurator can be used to find optimised configurations of our pipeline. After configuration, our global SCMD solving pipeline outperforms its closest competitor (a MIP-based decomposition pipeline) on all test sets we considered by up to two orders of magnitude in terms of PAR10 scores.},
  archive      = {J_AIJ},
  author       = {Anna L.D. Latour and Behrouz Babaki and Daniël Fokkinga and Marie Anastacio and Holger H. Hoos and Siegfried Nijssen},
  doi          = {10.1016/j.artint.2021.103650},
  journal      = {Artificial Intelligence},
  pages        = {103650},
  shortjournal = {Artif. Intell.},
  title        = {Exact stochastic constraint optimisation with applications in network analysis},
  volume       = {304},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient algorithm for counting markov equivalent DAGs.
<em>AIJ</em>, <em>304</em>, 103648. (<a
href="https://doi.org/10.1016/j.artint.2021.103648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of counting the number of DAGs which are Markov equivalent, i.e., which encode the same conditional independencies between random variables . The problem has been studied, among others, in the context of causal discovery, and it is known that it reduces to counting the number of so-called moral acyclic orientations of certain undirected graphs , notably chordal graphs . Our main empirical contribution is a new algorithm which outperforms previously known exact algorithms for the considered problem by a significant margin. On the theoretical side, we show that our algorithm is guaranteed to run in polynomial time on a broad cubic-time recognisable class of chordal graphs , including interval graphs .},
  archive      = {J_AIJ},
  author       = {Robert Ganian and Thekla Hamm and Topi Talvitie},
  doi          = {10.1016/j.artint.2021.103648},
  journal      = {Artificial Intelligence},
  pages        = {103648},
  shortjournal = {Artif. Intell.},
  title        = {An efficient algorithm for counting markov equivalent DAGs},
  volume       = {304},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Logic tensor networks. <em>AIJ</em>, <em>303</em>, 103649.
(<a href="https://doi.org/10.1016/j.artint.2021.103649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attempts at combining logic and neural networks into neurosymbolic approaches have been on the increase in recent years. In a neurosymbolic system, symbolic knowledge assists deep learning , which typically uses a sub-symbolic distributed representation, to learn and reason at a higher level of abstraction. We present Logic Tensor Networks (LTN), a neurosymbolic framework that supports querying, learning and reasoning with both rich data and abstract knowledge about the world. LTN introduces a fully differentiable logical language, called Real Logic, whereby the elements of a first-order logic signature are grounded onto data using neural computational graphs and first-order fuzzy logic semantics. We show that LTN provides a uniform language to represent and compute efficiently many of the most important AI tasks such as multi-label classification, relational learning, data clustering , semi-supervised learning, regression, embedding learning and query answering . We implement and illustrate each of the above tasks with several simple explanatory examples using TensorFlow 2. The results indicate that LTN can be a general and powerful framework for neurosymbolic AI .},
  archive      = {J_AIJ},
  author       = {Samy Badreddine and Artur d&#39;Avila Garcez and Luciano Serafini and Michael Spranger},
  doi          = {10.1016/j.artint.2021.103649},
  journal      = {Artificial Intelligence},
  pages        = {103649},
  shortjournal = {Artif. Intell.},
  title        = {Logic tensor networks},
  volume       = {303},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rethinking formal models of partially observable multiagent
decision making. <em>AIJ</em>, <em>303</em>, 103645. (<a
href="https://doi.org/10.1016/j.artint.2021.103645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiagent decision-making in partially observable environments is usually modelled as either an extensive-form game (EFG) in game theory or a partially observable stochastic game (POSG) in multiagent reinforcement learning (MARL). One issue with the current situation is that while most practical problems can be modelled in both formalisms, the relationship of the two models is unclear, which hinders the transfer of ideas between the two communities. A second issue is that while EFGs have recently seen significant algorithmic progress, their classical formalization is unsuitable for efficient presentation of the underlying ideas, such as those around decomposition. To solve the first issue, we introduce factored-observation stochastic games (FOSGs), a minor modification of the POSG formalism which distinguishes between private and public observation and thereby greatly simplifies decomposition. To remedy the second issue, we show that FOSGs and POSGs are naturally connected to EFGs: by “unrolling” a FOSG into its tree form, we obtain an EFG. Conversely, any perfect-recall timeable EFG corresponds to some underlying FOSG in this manner. Moreover, this relationship justifies several minor modifications to the classical EFG formalization that recently appeared as an implicit response to the model&#39;s issues with decomposition. Finally, we illustrate the transfer of ideas between EFGs and MARL by presenting three key EFG techniques – counterfactual regret minimization, sequence form, and decomposition – in the FOSG framework.},
  archive      = {J_AIJ},
  author       = {Vojtěch Kovařík and Martin Schmid and Neil Burch and Michael Bowling and Viliam Lisý},
  doi          = {10.1016/j.artint.2021.103645},
  journal      = {Artificial Intelligence},
  pages        = {103645},
  shortjournal = {Artif. Intell.},
  title        = {Rethinking formal models of partially observable multiagent decision making},
  volume       = {303},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diversity of solutions: An exploration through the lens of
fixed-parameter tractability theory. <em>AIJ</em>, <em>303</em>, 103644.
(<a href="https://doi.org/10.1016/j.artint.2021.103644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When modeling an application of practical relevance as an instance of a combinatorial problem X, we are often interested not merely in finding one optimal solution for that instance, but in finding a sufficiently diverse collection of good solutions. In this work we initiate a systematic study of diversity from the point of view of fixed-parameter tractability theory. First, we consider an intuitive notion of diversity of a collection of solutions which suits a large variety of combinatorial problems of practical interest. We then present an algorithmic framework which – automatically – converts a tree-decomposition-based dynamic programming algorithm for a given combinatorial problem X into a dynamic programming algorithm for the diverse version of X. Surprisingly, our algorithm has a polynomial dependence on the diversity parameter.},
  archive      = {J_AIJ},
  author       = {Julien Baste and Michael R. Fellows and Lars Jaffke and Tomáš Masařík and Mateus de Oliveira Oliveira and Geevarghese Philip and Frances A. Rosamond},
  doi          = {10.1016/j.artint.2021.103644},
  journal      = {Artificial Intelligence},
  pages        = {103644},
  shortjournal = {Artif. Intell.},
  title        = {Diversity of solutions: An exploration through the lens of fixed-parameter tractability theory},
  volume       = {303},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online perceptual learning and natural language acquisition
for autonomous robots. <em>AIJ</em>, <em>303</em>, 103637. (<a
href="https://doi.org/10.1016/j.artint.2021.103637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the problem of bootstrapping knowledge in language and vision for autonomous robots is addressed through novel techniques in grammar induction and word grounding to the perceptual world. In particular, we demonstrate a system, called OLAV, which is able, for the first time, to (1) learn to form discrete concepts from sensory data; (2) ground language ( n -grams) to these concepts; (3) induce a grammar for the language being used to describe the perceptual world; and moreover to do all this incrementally, without storing all previous data. The learning is achieved in a loosely-supervised manner from raw linguistic and visual data. Moreover, the learnt model is transparent, rather than a black-box model and is thus open to human inspection. The visual data is collected using three different robotic platforms deployed in real-world and simulated environments and equipped with different sensing modalities, while the linguistic data is collected using online crowdsourcing tools and volunteers. The analysis performed on these robots demonstrates the effectiveness of the framework in learning visual concepts, language groundings and grammatical structure in these three online settings.},
  archive      = {J_AIJ},
  author       = {Muhannad Alomari and Fangjun Li and David C. Hogg and Anthony G. Cohn},
  doi          = {10.1016/j.artint.2021.103637},
  journal      = {Artificial Intelligence},
  pages        = {103637},
  shortjournal = {Artif. Intell.},
  title        = {Online perceptual learning and natural language acquisition for autonomous robots},
  volume       = {303},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Complexity results for preference aggregation over
(m)CP-nets: Max and rank voting. <em>AIJ</em>, <em>303</em>, 103636. (<a
href="https://doi.org/10.1016/j.artint.2021.103636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aggregating preferences over combinatorial domains has a plethora of applications in AI . Due to the exponential nature of combinatorial preferences, compact representations are needed, and conditional ceteris paribus preference networks (CP-nets) are among the most studied compact representation formalisms. Unlike the problem of outcome dominance over individual CP-nets, which received an extensive complexity analysis in the literature, m CP-nets (and global voting/preference aggregation over CP-nets) lacked such a thorough complexity characterization, despite this being reported multiple times in the literature as an open problem. An initial complexity analysis for m CP-nets was carried out only recently, where Pareto and majority dominance semantics were studied. In this paper, we further explore the complexity of m CP-nets, giving a precise complexity analysis of the dominance semantics in m CP-nets when the max and rank voting schemes are considered. In particular, we show that deciding dominance under max voting is Θ 2 P Θ2P -complete, while deciding optimal outcomes and their existence under max voting is complete for Π 2 P Π2P and Σ 3 P Σ3P , respectively. We also show that, under max voting, deciding optimum outcomes is Π 2 P Π2P -complete, and deciding their existence is Π 2 P Π2P -hard and in Σ 3 P Σ3P . As for rank voting, apart from deciding whether m CP-nets have rank optimal outcomes, which is a trivial problem, as all m CP-nets have rank optimal outcomes, all the other rank voting tasks considered are tractable and in P. Interestingly, we show here that these problems are not only in P, but also P-hard (and hence P-complete). Furthermore, we show that deciding whether m CP-nets have Pareto optimum outcomes, which was known to be feasible in polynomial time , is actually P-complete, as well as that various tasks for CP-nets are P-complete. These results provide interesting insights, as P-complete problems are (currently believed to be) inherently sequential, and hence they cannot benefit from highly parallel computations.},
  archive      = {J_AIJ},
  author       = {Thomas Lukasiewicz and Enrico Malizia},
  doi          = {10.1016/j.artint.2021.103636},
  journal      = {Artificial Intelligence},
  pages        = {103636},
  shortjournal = {Artif. Intell.},
  title        = {Complexity results for preference aggregation over (m)CP-nets: Max and rank voting},
  volume       = {303},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CVPR 2020 continual learning in computer vision competition:
Approaches, results, current challenges and future directions.
<em>AIJ</em>, <em>303</em>, 103635. (<a
href="https://doi.org/10.1016/j.artint.2021.103635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few years, we have witnessed a renewed and fast-growing interest in continual learning with deep neural networks with the shared objective of making current AI systems more adaptive, efficient and autonomous. However, despite the significant and undoubted progress of the field in addressing the issue of catastrophic forgetting, benchmarking different continual learning approaches is a difficult task by itself. In fact, given the proliferation of different settings, training and evaluation protocols, metrics and nomenclature, it is often tricky to properly characterize a continual learning algorithm, relate it to other solutions and gauge its real-world applicability. The first Continual Learning in Computer Vision challenge held at CVPR in 2020 has been one of the first opportunities to evaluate different continual learning algorithms on a common hardware with a large set of shared evaluation metrics and 3 different settings based on the realistic CORe50 video benchmark. In this paper, we report the main results of the competition, which counted more than 79 teams registered and 11 finalists. We also summarize the winning approaches, current challenges and future research directions.},
  archive      = {J_AIJ},
  author       = {Vincenzo Lomonaco and Lorenzo Pellegrini and Pau Rodriguez and Massimo Caccia and Qi She and Yu Chen and Quentin Jodelet and Ruiping Wang and Zheda Mai and David Vazquez and German I. Parisi and Nikhil Churamani and Marc Pickett and Issam Laradji and Davide Maltoni},
  doi          = {10.1016/j.artint.2021.103635},
  journal      = {Artificial Intelligence},
  pages        = {103635},
  shortjournal = {Artif. Intell.},
  title        = {CVPR 2020 continual learning in computer vision competition: Approaches, results, current challenges and future directions},
  volume       = {303},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge-based programs as building blocks for planning.
<em>AIJ</em>, <em>303</em>, 103634. (<a
href="https://doi.org/10.1016/j.artint.2021.103634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge-based programs contain both world-altering actions, which upon execution change the state of the world, and sensing actions, which upon execution change the knowledge state of the agent. Knowledge-based programming has been proposed as an alternative to planning, since programs allow solving families of planning problems. Notwithstanding, agents equipped with a variety of knowledge-based procedures can compose these procedures to achieve goals, exhibiting greater degrees of flexibility. Optimized state-of-the-art planners, unfortunately, cannot be used directly to compose programs since they require operators (not programs), defined by preconditions and effects. In this article we study how to compute preconditions and effects of knowledge-based programs in order to allow state-of-the-art planners to construct plans with knowledge-based programs as building blocks . We study the problem in the language of the situation calculus , appealing to Golog to represent our programs. To this end, we propose an offline execution semantics for Golog programs with sensing. We then propose a compilation method that transforms our action theory with programs into a new theory where programs are replaced by primitive actions . This enables us to use state-of-the-art, operator-based planning techniques to plan with programs that sense for a restricted but compelling class of problems. Finally, we discuss the applicability of these results to existing operator-based planners that support sensing and illustrate the computational advantage of planning with programs that sense via an experiment.},
  archive      = {J_AIJ},
  author       = {Jorge A. Baier and Sheila A. McIlraith},
  doi          = {10.1016/j.artint.2021.103634},
  journal      = {Artificial Intelligence},
  pages        = {103634},
  shortjournal = {Artif. Intell.},
  title        = {Knowledge-based programs as building blocks for planning},
  volume       = {303},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fair allocation of indivisible goods: Beyond additive
valuations. <em>AIJ</em>, <em>303</em>, 103633. (<a
href="https://doi.org/10.1016/j.artint.2021.103633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We conduct a study on the problem of fair allocation of indivisible goods when maximin share [1] is used as the measure of fairness. Most of the current studies on this notion are limited to the case that the valuations are additive. In this paper, we go beyond additive valuations and consider the cases that the valuations are submodular, fractionally subadditive, and subadditive. We give constant approximation guarantees for agents with submodular and XOS XOS valuations, and a logarithmic bound for the case of agents with subadditive valuations. Furthermore, we complement our results by providing close upper bounds for each class of valuation functions. Finally, we present algorithms to find such allocations for submodular and XOS XOS settings in polynomial time .},
  archive      = {J_AIJ},
  author       = {Mohammad Ghodsi and MohammadTaghi HajiAghayi and Masoud Seddighin and Saeed Seddighin and Hadi Yami},
  doi          = {10.1016/j.artint.2021.103633},
  journal      = {Artificial Intelligence},
  pages        = {103633},
  shortjournal = {Artif. Intell.},
  title        = {Fair allocation of indivisible goods: Beyond additive valuations},
  volume       = {303},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). End-to-end neural event coreference resolution.
<em>AIJ</em>, <em>303</em>, 103632. (<a
href="https://doi.org/10.1016/j.artint.2021.103632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional event coreference systems commonly use a pipeline architecture and rely heavily on handcrafted features, which often causes error propagation problems and leads to poor generalization ability . In this paper, we propose a neural network-based end-to-end event coreference architecture ( E 3 C E3C ) that can jointly model event detection and event coreference resolution tasks and learn to extract features from raw text automatically. Furthermore, because event mentions are highly diversified and event coreference is intricately governed by long-distance and semantically-dependent decisions, a type-enhanced event coreference mechanism is further proposed in our E 3 C E3C neural network . Experiments show that our method achieves a new state-of-the-art performance on both standard datasets.},
  archive      = {J_AIJ},
  author       = {Yaojie Lu and Hongyu Lin and Jialong Tang and Xianpei Han and Le Sun},
  doi          = {10.1016/j.artint.2021.103632},
  journal      = {Artificial Intelligence},
  pages        = {103632},
  shortjournal = {Artif. Intell.},
  title        = {End-to-end neural event coreference resolution},
  volume       = {303},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diffusion auction design. <em>AIJ</em>, <em>303</em>,
103631. (<a href="https://doi.org/10.1016/j.artint.2021.103631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies an auction design problem for a seller to sell a single commodity in a social network, where each individual (the seller or a buyer) can only communicate with her neighbors. The challenge is to design a mechanism to incentivize the buyers, who are aware of the auction, to further propagate the information to their neighbors, so that more buyers can participate in the auction and hence, the seller will be able to make a higher revenue and a higher welfare. We build a general framework for this new scenario and propose several novel diffusion auctions, which not only incentivize the buyers to report their valuations on the commodity truthfully, but also to propagate the auction information to all their neighbors. Particularly, the direct extension of the well-known Vickrey-Clarke-Groves (VCG) mechanism on social networks can have the incentives, but it will decrease the seller&#39;s revenue or even lead to a deficit. We also show that in the social network setting all efficient mechanisms that are individually rational and incentive compatible can lead to a deficit. The goal in this article is to increase the seller&#39;s revenue by attracting more buyers, so we give up welfare maximization and propose a class of mechanisms called critical diffusion mechanisms . It is proved that both the seller&#39;s revenue and the social welfare achieved in critical diffusion mechanisms are not less than that given in the VCG mechanism before attracting new buyers. The intuition behind the proposed mechanisms is that buyers who join the mechanism earlier have higher priorities to buy the commodity. If a buyer does not win the commodity because of her propagation, then she will be compensated. The formalization of the problem has not been well-studied in the literature of mechanism design, and there are many open problems worth further investigation. The study of this problem will provide insights for the emerging market based on the participants&#39; recommendations via their social networks.},
  archive      = {J_AIJ},
  author       = {Bin Li and Dong Hao and Hui Gao and Dengji Zhao},
  doi          = {10.1016/j.artint.2021.103631},
  journal      = {Artificial Intelligence},
  pages        = {103631},
  shortjournal = {Artif. Intell.},
  title        = {Diffusion auction design},
  volume       = {303},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian auctions with efficient queries. <em>AIJ</em>,
<em>303</em>, 103630. (<a
href="https://doi.org/10.1016/j.artint.2021.103630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing dominant-strategy incentive compatible (DSIC) mechanisms for a seller to generate (approximately) optimal revenue by selling items to players is a fundamental problem in Bayesian mechanism design. However, most existing studies assume that the seller knows the entire distribution from which the players&#39; values are drawn. Unfortunately, this assumption may not hold in reality: for example, when the distributions have exponentially large supports or do not have succinct representations. In this work we consider, for the first time, the query complexity of Bayesian mechanisms. The seller only has limited oracle accesses to the players&#39; distributions, via quantile queries and value queries . For single-item auctions, we design mechanisms with logarithmic number of value or quantile queries which achieve almost optimal revenue. We then prove logarithmic lower-bounds, i.e., logarithmic number of queries are necessary for any constant approximation DSIC mechanisms, even when randomized and adaptive queries are allowed. Thus our mechanisms are almost optimal regarding query complexity. Our lower-bounds can be extended to multi-item auctions with monotone subadditive valuations, and we complement this part with constant approximation mechanisms for unit-demand or additive valuation functions. Our results are robust even if the answers to the queries contain noises. Thus, in those settings the seller needs to access much less than the entire distribution to achieve approximately optimal revenue.},
  archive      = {J_AIJ},
  author       = {Jing Chen and Bo Li and Yingkai Li and Pinyan Lu},
  doi          = {10.1016/j.artint.2021.103630},
  journal      = {Artificial Intelligence},
  pages        = {103630},
  shortjournal = {Artif. Intell.},
  title        = {Bayesian auctions with efficient queries},
  volume       = {303},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the impact of the performance metric on efficient
algorithm configuration. <em>AIJ</em>, <em>303</em>, 103629. (<a
href="https://doi.org/10.1016/j.artint.2021.103629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algorithm configurators are automated methods to optimise the parameters of an algorithm for a class of problems. We analyse the impact of the cutoff time κ (the time spent evaluating a configuration for a problem instance) on the expected number of configuration comparisons required to find the optimal parameter value for the performance metrics (the measure used to judge the performance of a configuration) that compare configurations using either the best-found fitness values or optimisation times. We first prove that the configurators that use optimisation time as performance metric are not able to tune any unary unbiased algorithm for any function with up to an exponential number of optima using κ ≤ ( n ln ⁡ n ) / 2 κ≤(nln⁡n)/2 . Afterwards, we show that for simple algorithm configuration scenarios the required cutoff time for the optimisation time metric may be considerably larger while using the best fitness metric allows the tuners to configure the target algorithm in linear time in the number of parameters.},
  archive      = {J_AIJ},
  author       = {George T. Hall and Pietro S. Oliveto and Dirk Sudholt},
  doi          = {10.1016/j.artint.2021.103629},
  journal      = {Artificial Intelligence},
  pages        = {103629},
  shortjournal = {Artif. Intell.},
  title        = {On the impact of the performance metric on efficient algorithm configuration},
  volume       = {303},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrating social influence modeling and user modeling for
trust prediction in signed networks. <em>AIJ</em>, <em>302</em>, 103628.
(<a href="https://doi.org/10.1016/j.artint.2021.103628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust and distrust between online users play an important role in social network applications, especially in the security domain. For example, trust information can enhance social recommendation and distrust information can be used for fraud detection. However, trust prediction is challenging due to the existence and imbalance of the three kinds of social status in signed social networks (i.e., trust, distrust and no-relation). Furthermore, there are a variety types of no-relation status in reality, e.g., strangers and frenemies, which cannot be well distinguished from the other social status by existing approaches. In this paper, we propose a novel Framework of Integrating both Latent and Explicit features (FILE), to better deal with the no-relation status and hence improve the overall trust/distrust prediction performance. In particular, we design two latent features to model user&#39;s intrinsic personality. Meanwhile, we design explicit features by extending social theories, to model the external social influence from mutual neighbors. The proposed model learns the features for each user via matrix factorization with a specially designed ranking-oriented loss function. Experimental results demonstrate the superior of our approach over the state-of-the-art methods, and the effectiveness of our approach in security applications. Our work sheds light on trust prediction in signed networks as well as security applications like fraud detection.},
  archive      = {J_AIJ},
  author       = {Hui Fang and Xiaoming Li and Jie Zhang},
  doi          = {10.1016/j.artint.2021.103628},
  journal      = {Artificial Intelligence},
  pages        = {103628},
  shortjournal = {Artif. Intell.},
  title        = {Integrating social influence modeling and user modeling for trust prediction in signed networks},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge graphs as tools for explainable machine learning:
A survey. <em>AIJ</em>, <em>302</em>, 103627. (<a
href="https://doi.org/10.1016/j.artint.2021.103627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides an extensive overview of the use of knowledge graphs in the context of Explainable Machine Learning . As of late, explainable AI has become a very active field of research by addressing the limitations of the latest machine learning solutions that often provide highly accurate, but hardly scrutable and interpretable decisions. An increasing interest has also been shown in the integration of Knowledge Representation techniques in Machine Learning applications, mostly motivated by the complementary strengths and weaknesses that could lead to a new generation of hybrid intelligent systems. Following this idea, we hypothesise that knowledge graphs, which naturally provide domain background knowledge in a machine-readable format, could be integrated in Explainable Machine Learning approaches to help them provide more meaningful, insightful and trustworthy explanations. Using a systematic literature review methodology we designed an analytical framework to explore the current landscape of Explainable Machine Learning. We focus particularly on the integration with structured knowledge at large scale, and use our framework to analyse a variety of Machine Learning domains, identifying the main characteristics of such knowledge-based, explainable systems from different perspectives. We then summarise the strengths of such hybrid systems, such as improved understandability , reactivity, and accuracy, as well as their limitations, e.g. in handling noise or extracting knowledge efficiently. We conclude by discussing a list of open challenges left for future research.},
  archive      = {J_AIJ},
  author       = {Ilaria Tiddi and Stefan Schlobach},
  doi          = {10.1016/j.artint.2021.103627},
  journal      = {Artificial Intelligence},
  pages        = {103627},
  shortjournal = {Artif. Intell.},
  title        = {Knowledge graphs as tools for explainable machine learning: A survey},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast optimal and bounded suboptimal euclidean pathfinding.
<em>AIJ</em>, <em>302</em>, 103624. (<a
href="https://doi.org/10.1016/j.artint.2021.103624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider optimal and suboptimal algorithms for the Euclidean Shortest Path Problem (ESPP) in two dimensions. For optimal path planning , Our approach leverages ideas from two recent works: Polyanya, a mesh-based ESPP planner which we use to represent and reason about the environment, and Compressed Path Databases (CPD), a speedup technique for pathfinding on grids and spatial networks, which we exploit to efficiently compute candidate paths, in order to construct a completely novel ESPP algorithm, End Point Search (EPS). In a range of experiments and empirical comparisons we show that: (i) the auxiliary data structures required by EPS are cheap to build and store; (ii) for optimal search, the new algorithm is faster than a range of recent ESPP planners, with speedups ranging from several factors to over one order of magnitude; (iii) for anytime search, where feasible solutions are needed fast, we report even better performance. For suboptimal path planning , we extend the CPD such that it computes and compresses first move data of a larger number of selected candidate nodes covering every point in the Euclidean space. Our approach is search-free, simultaneously fast, and returns a path within a fixed bound of the optimal solution. In a range of empirical results, we show that: (i) our approach outperforms both offline/online optimal and suboptimal ESPP algorithms proposed in the literature; (ii) our approach demonstrates excellent path quality, better than all existing suboptimal ESPP algorithms; and (iii) the approach offers flexibility by allowing a trade-off between the CPD construction cost (space and time) and the suboptimality bound.},
  archive      = {J_AIJ},
  author       = {Bojie Shen and Muhammad Aamir Cheema and Daniel D. Harabor and Peter J. Stuckey},
  doi          = {10.1016/j.artint.2021.103624},
  journal      = {Artificial Intelligence},
  pages        = {103624},
  shortjournal = {Artif. Intell.},
  title        = {Fast optimal and bounded suboptimal euclidean pathfinding},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Strategyproof mechanisms for friends and enemies games.
<em>AIJ</em>, <em>302</em>, 103610. (<a
href="https://doi.org/10.1016/j.artint.2021.103610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate strategyproof mechanisms for Friends and Enemies Games , a subclass of Hedonic Games in which every agent classifies any other one as a friend or as an enemy . In this setting, we consider the two classical scenarios proposed in the literature, called Friends Appreciation ( FA FA ) and Enemies Aversion ( EA EA ). Roughly speaking, in the former each agent gives priority to the number of friends in her coalition, while in the latter to the number of enemies. We focus on the objective of maximizing the sum of the utilities of the agents and provide strategyproof mechanisms for both settings. More precisely, for FA FA we first present a deterministic n -approximation mechanism, n being the number of agents, and then show that a much better approximation can be achieved by resorting to randomization . Namely, we provide a randomized mechanism whose expected approximation ratio is 4, and arbitrarily close to 4 with high probability. For EA EA , we give a simple ( 1 + 2 ) n (1+2)n -approximation mechanism, and show that its performance is asymptotically tight by proving that it is NP-hard to approximate the optimal solution within O ( n 1 − ε ) O(n1−ε) for any fixed ε &gt; 0 ε&amp;gt; 0 . We also show that, if computational efficiency is not a concern, it is possible to achieve a ( 1 + 2 ) (1+2) -approximation by means of a deterministic strategyproof mechanism with exponential runtime. Finally, we show how to extend our results in the presence of neutrals , i.e., when agents can also be indifferent about other agents.},
  archive      = {J_AIJ},
  author       = {Michele Flammini and Bojana Kodric and Giovanna Varricchio},
  doi          = {10.1016/j.artint.2021.103610},
  journal      = {Artificial Intelligence},
  pages        = {103610},
  shortjournal = {Artif. Intell.},
  title        = {Strategyproof mechanisms for friends and enemies games},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On fair selection in the presence of implicit and
differential variance. <em>AIJ</em>, <em>302</em>, 103609. (<a
href="https://doi.org/10.1016/j.artint.2021.103609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrimination in selection problems such as hiring or college admission is often explained by implicit bias from the decision maker against disadvantaged demographic groups. In this paper, we consider a model where the decision maker receives a noisy estimate of each candidate&#39;s quality, whose variance depends on the candidate&#39;s group—we argue that such differential variance is a key feature of many selection problems. We analyze two notable settings: in the first, the noise variances are unknown to the decision maker who simply picks the candidates with the highest estimated quality independently of their group; in the second, the variances are known and the decision maker picks candidates having the highest expected quality given the noisy estimate. We show that both baseline decision makers yield discrimination, although in opposite directions: the first leads to underrepresentation of the low-variance group while the second leads to underrepresentation of the high-variance group. We study the effect on the selection utility of imposing a fairness mechanism that we term the γ -rule (it is an extension of the classical four-fifths rule and it also includes demographic parity). In the first setting (with unknown variances), we prove that under mild conditions, imposing the γ -rule increases the selection utility—here there is no trade-off between fairness and utility. In the second setting (with known variances), imposing the γ -rule decreases the utility but we prove a bound on the utility loss due to the fairness mechanism.},
  archive      = {J_AIJ},
  author       = {Vitalii Emelianov and Nicolas Gast and Krishna P. Gummadi and Patrick Loiseau},
  doi          = {10.1016/j.artint.2021.103609},
  journal      = {Artificial Intelligence},
  pages        = {103609},
  shortjournal = {Artif. Intell.},
  title        = {On fair selection in the presence of implicit and differential variance},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A framework for analysing state-abstraction methods.
<em>AIJ</em>, <em>302</em>, 103608. (<a
href="https://doi.org/10.1016/j.artint.2021.103608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstraction has been used in combinatorial search and action planning from the very beginning of AI . Many different methods and formalisms for state abstraction have been proposed in the literature, but they have been designed from various points of view and with varying purposes. Hence, these methods have been notoriously difficult to analyse and compare in a structured way. In order to improve upon this situation, we present a coherent and flexible framework for modelling abstraction (and abstraction-like) methods based on graph transformations. The usefulness of the framework is demonstrated by applying it to problems in both search and planning. We model six different abstraction methods from the planning literature and analyse their intrinsic properties. We show how to capture many search abstraction concepts (such as avoiding backtracking between levels) and how to put them into a broader context. We also use the framework to identify and investigate connections between refinement and heuristics—two concepts that have usually been considered as unrelated in the literature. This provides new insights into various topics, e.g. Valtorta&#39;s theorem and spurious states. We finally extend the framework with composition of transformations to accommodate for abstraction hierarchies, and other multi-level concepts. We demonstrate the latter by modelling and analysing the merge-and-shrink abstraction method.},
  archive      = {J_AIJ},
  author       = {Christer Bäckström and Peter Jonsson},
  doi          = {10.1016/j.artint.2021.103608},
  journal      = {Artificial Intelligence},
  pages        = {103608},
  shortjournal = {Artif. Intell.},
  title        = {A framework for analysing state-abstraction methods},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation of argument strength in attack graphs:
Foundations and semantics. <em>AIJ</em>, <em>302</em>, 103607. (<a
href="https://doi.org/10.1016/j.artint.2021.103607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An argumentation framework is a pair made of a graph and a semantics . The nodes and the edges of the graph represent respectively arguments and relations (e.g., attacks, supports) between arguments while the semantics evaluates the strength of each argument of the graph. This paper investigates gradual semantics dealing with weighted graphs , a family of graphs where each argument has an initial weight and may be attacked by other arguments. It contains four contributions. The first consists of laying the foundations of gradual semantics by proposing key principles on which evaluation of argument strength may be based. Foundations are important not only for a better understanding of the evaluation process in general, but also for clarifying the basic assumptions underlying semantics, for comparing different (families of) semantics, and for identifying families of semantics that have not been explored yet. The second contribution consists of providing a formal analysis and a comprehensive comparison of the semantics that have been defined in the literature for evaluating arguments in weighted graphs. As a third contribution, the paper proposes three novel semantics and shows which principles they satisfy. The last contribution is the implementation and empirical evaluation of the three novel semantics. We show that the three semantics are very efficient in that they compute the strengths of arguments in less than 20 iterations and in a very short time. This holds even for very large graphs, meaning that the three semantics scale very well.},
  archive      = {J_AIJ},
  author       = {Leila Amgoud and Dragan Doder and Srdjan Vesic},
  doi          = {10.1016/j.artint.2021.103607},
  journal      = {Artificial Intelligence},
  pages        = {103607},
  shortjournal = {Artif. Intell.},
  title        = {Evaluation of argument strength in attack graphs: Foundations and semantics},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Answers set programs for non-transferable utility games:
Expressiveness, complexity and applications. <em>AIJ</em>, <em>302</em>,
103606. (<a href="https://doi.org/10.1016/j.artint.2021.103606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coalitional games are mathematical models suited to study payoff distribution problems in cooperative scenarios. In abstract terms, a coalitional game can be specified by explicitly listing all possible—in fact, exponentially many—coalitions with their associated distributions. This naïve representation, however, quickly becomes infeasible over games involving many agents, thereby calling for suitable compact representations, that is, encoding mechanisms that (on some specific classes of games of interest) take an amount of space that grows polynomially with the number of agents. To date, a plethora of compact encodings have been already introduced and analyzed from the algorithm and computational viewpoints. Despite their specific technical differences, these encodings typically share the assumption that the utility associated with a coalition can be freely transferred among agents. Indeed, designing encoding mechanisms for the non-transferable utility (NTU) setting is a research issue that has been largely unexplored so far. The paper addresses this issue by proposing a compact encoding for representing and reasoning about the outcomes of NTU coalitional games founding on answer set programming . By exploiting the expressiveness of this well-known knowledge representation formalism , it is shown that the proposed representation can succinctly encode several games of interest within a wide range of application domains. Computational issues arising in the setting have been studied too, by addressing questions related to certain payoff distributions enjoying desirable stability properties. Eventually, a prototype system supporting the proposed framework has been implemented by leveraging a state-of-the-art answer set engine, and results of a thorough experimental activity conducted on top of it have been discussed.},
  archive      = {J_AIJ},
  author       = {Giovanni Amendola and Gianluigi Greco and Pierfrancesco Veltri},
  doi          = {10.1016/j.artint.2021.103606},
  journal      = {Artificial Intelligence},
  pages        = {103606},
  shortjournal = {Artif. Intell.},
  title        = {Answers set programs for non-transferable utility games: Expressiveness, complexity and applications},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient multi-agent epistemic planning: Teaching planners
about nested belief. <em>AIJ</em>, <em>302</em>, 103605. (<a
href="https://doi.org/10.1016/j.artint.2021.103605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many AI applications involve the interaction of multiple autonomous agents , requiring those agents to reason about their own beliefs, as well as those of other agents. However, planning involving nested beliefs is known to be computationally challenging. In this work, we address the task of synthesizing plans that necessitate reasoning about the beliefs of other agents. We plan from the perspective of a single agent with the potential for goals and actions that involve nested beliefs, non-homogeneous agents, co-present observations, and the ability for one agent to reason as if it were another. We formally characterize our notion of planning with nested belief, and subsequently demonstrate how to automatically convert such problems into problems that appeal to classical planning technology for solving efficiently. Our approach represents an important step towards applying the well-established field of automated planning to the challenging task of planning involving nested beliefs of multiple agents .},
  archive      = {J_AIJ},
  author       = {Christian Muise and Vaishak Belle and Paolo Felli and Sheila McIlraith and Tim Miller and Adrian R. Pearce and Liz Sonenberg},
  doi          = {10.1016/j.artint.2021.103605},
  journal      = {Artificial Intelligence},
  pages        = {103605},
  shortjournal = {Artif. Intell.},
  title        = {Efficient multi-agent epistemic planning: Teaching planners about nested belief},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SAT encodings for pseudo-boolean constraints together with
at-most-one constraints. <em>AIJ</em>, <em>302</em>, 103604. (<a
href="https://doi.org/10.1016/j.artint.2021.103604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving a combinatorial problem using propositional satisfiability (SAT), the encoding of the problem is of vital importance. We study encodings of Pseudo-Boolean (PB) constraints, a common type of arithmetic constraint that appears in a wide variety of combinatorial problems such as timetabling, scheduling, and resource allocation. In some cases PB constraints occur together with at-most-one (AMO) constraints over subsets of their variables (forming PB(AMO) constraints). Recent work has shown that taking account of AMOs when encoding PB constraints using decision diagrams can produce a dramatic improvement in solver efficiency. In this paper we extend the approach to other state-of-the-art encodings of PB constraints, developing several new encodings for PB(AMO) constraints. Also, we present a more compact and efficient version of the popular Generalized Totalizer encoding, named Reduced Generalized Totalizer. This new encoding is also adapted for PB(AMO) constraints for a further gain. Our experiments show that the encodings of PB(AMO) constraints can be substantially smaller than those of PB constraints. PB(AMO) encodings allow many more instances to be solved within a time limit, and solving time is improved by more than one order of magnitude in some cases. We also observed that there is no single overall winner among the considered encodings, but efficiency of each encoding may depend on PB(AMO) characteristics such as the magnitude of coefficient values .},
  archive      = {J_AIJ},
  author       = {Miquel Bofill and Jordi Coll and Peter Nightingale and Josep Suy and Felix Ulrich-Oltean and Mateu Villaret},
  doi          = {10.1016/j.artint.2021.103604},
  journal      = {Artificial Intelligence},
  pages        = {103604},
  shortjournal = {Artif. Intell.},
  title        = {SAT encodings for pseudo-boolean constraints together with at-most-one constraints},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Propositional and predicate logics of incomplete
information. <em>AIJ</em>, <em>302</em>, 103603. (<a
href="https://doi.org/10.1016/j.artint.2021.103603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most common scenarios of handling incomplete information occurs in relational databases . They describe incomplete knowledge with three truth values, using Kleene&#39;s logic for propositional formulae and a rather peculiar extension to predicate calculus . This design by a committee from several decades ago is now part of the standard adopted by vendors of database management systems . But is it really the right way to handle incompleteness in propositional and predicate logics ? Our goal is to answer this question. Using an epistemic approach, we first characterize possible levels of partial knowledge about propositions, which leads to six truth values. We impose rationality conditions on the semantics of the connectives of the propositional logic , and prove that Kleene&#39;s logic is the maximal sublogic to which the standard optimization rules apply, thereby justifying this design choice. For extensions to predicate logic, however, we show that the additional truth values are not necessary: every many-valued extension of first-order logic over databases with incomplete information represented by null values is no more powerful than the usual two-valued logic with the standard Boolean interpretation of the connectives. We use this observation to analyze the logic underlying SQL query evaluation, and conclude that the many-valued extension for handling incompleteness does not add any expressiveness to it.},
  archive      = {J_AIJ},
  author       = {Marco Console and Paolo Guagliardo and Leonid Libkin},
  doi          = {10.1016/j.artint.2021.103603},
  journal      = {Artificial Intelligence},
  pages        = {103603},
  shortjournal = {Artif. Intell.},
  title        = {Propositional and predicate logics of incomplete information},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analyzing differentiable fuzzy logic operators.
<em>AIJ</em>, <em>302</em>, 103602. (<a
href="https://doi.org/10.1016/j.artint.2021.103602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The AI community is increasingly putting its attention towards combining symbolic and neural approaches, as it is often argued that the strengths and weaknesses of these approaches are complementary. One recent trend in the literature is weakly supervised learning techniques that employ operators from fuzzy logics. In particular, these use prior background knowledge described in such logics to help the training of a neural network from unlabeled and noisy data. By interpreting logical symbols using neural networks, this background knowledge can be added to regular loss functions, hence making reasoning a part of learning. We study, both formally and empirically, how a large collection of logical operators from the fuzzy logic literature behave in a differentiable learning setting. We find that many of these operators, including some of the most well-known, are highly unsuitable in this setting. A further finding concerns the treatment of implication in these fuzzy logics, and shows a strong imbalance between gradients driven by the antecedent and the consequent of the implication. Furthermore, we introduce a new family of fuzzy implications (called sigmoidal implications) to tackle this phenomenon. Finally, we empirically show that it is possible to use Differentiable Fuzzy Logics for semi-supervised learning, and compare how different operators behave in practice. We find that, to achieve the largest performance improvement over a supervised baseline, we have to resort to non-standard combinations of logical operators which perform well in learning, but no longer satisfy the usual logical laws.},
  archive      = {J_AIJ},
  author       = {Emile van Krieken and Erman Acar and Frank van Harmelen},
  doi          = {10.1016/j.artint.2021.103602},
  journal      = {Artificial Intelligence},
  pages        = {103602},
  shortjournal = {Artif. Intell.},
  title        = {Analyzing differentiable fuzzy logic operators},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An action language for multi-agent domains. <em>AIJ</em>,
<em>302</em>, 103601. (<a
href="https://doi.org/10.1016/j.artint.2021.103601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this paper is to investigate an action language, called m ⁎ A ⁎ A⁎ , for representing and reasoning about actions and change in multi-agent domains. The language, as designed, can also serve as a specification language for epistemic planning, thereby addressing an important issue in the development of multi-agent epistemic planning systems. The m ⁎ A ⁎ A⁎ action language is a generalization of the single-agent action languages, extensively studied in the literature, to the case of multi-agent domains. The language allows the representation of different types of actions that an agent can perform in a domain where many other agents might be present—such as world-altering actions, sensing actions, and communication actions. The action language also allows the specification of agents&#39; dynamic awareness of action occurrences—which has implications on what agents&#39; know about the world and other agents&#39; knowledge about the world. These features are embedded in a language that is simple, yet powerful enough to address a large variety of knowledge manipulation scenarios in multi-agent domains. The semantics of m ⁎ A ⁎ A⁎ relies on the notion of state, which is described by a pointed Kripke model and is used to encode the agents&#39; knowledge 1 and the real state of the world. The semantics is defined by a transition function that maps pairs of actions and states into sets of states. The paper presents a number of properties of the action theories and relates m ⁎ A ⁎ A⁎ to other relevant formalisms in the area of reasoning about actions in multi-agent domains.},
  archive      = {J_AIJ},
  author       = {Chitta Baral and Gregory Gelfond and Enrico Pontelli and Tran Cao Son},
  doi          = {10.1016/j.artint.2021.103601},
  journal      = {Artificial Intelligence},
  pages        = {103601},
  shortjournal = {Artif. Intell.},
  title        = {An action language for multi-agent domains},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Margin of victory for tournament solutions. <em>AIJ</em>,
<em>302</em>, 103600. (<a
href="https://doi.org/10.1016/j.artint.2021.103600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tournament solutions are frequently used to select winners from a set of alternatives based on pairwise comparisons between them. Prior work has shown that several common tournament solutions tend to select large winner sets and therefore have low discriminative power . In this paper, we propose a general framework for refining tournament solutions. In order to distinguish between winning alternatives, and also between non-winning ones, we introduce the notion of margin of victory ( MoV MoV ) for tournament solutions. MoV MoV is a robustness measure for individual alternatives: For winners, the MoV MoV captures the distance from dropping out of the winner set, and for non-winners, the distance from entering the set. In each case, distance is measured in terms of which pairwise comparisons would have to be reversed in order to achieve the desired outcome. For common tournament solutions, including the top cycle, the uncovered set, and the Banks set, we determine the complexity of computing the MoV MoV and provide bounds on the MoV MoV for both winners and non-winners. We then reveal a number of structural insights on the MoV MoV by investigating fundamental properties such as monotonicity and consistency with respect to the covering relation. Furthermore, we provide experimental evidence on the extent to which the MoV MoV notion refines winner sets in tournaments generated according to various stochastic models . Our results can also be viewed from the perspective of bribery and manipulation.},
  archive      = {J_AIJ},
  author       = {Markus Brill and Ulrike Schmidt-Kraepelin and Warut Suksompong},
  doi          = {10.1016/j.artint.2021.103600},
  journal      = {Artificial Intelligence},
  pages        = {103600},
  shortjournal = {Artif. Intell.},
  title        = {Margin of victory for tournament solutions},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Globalizing constraint models. <em>AIJ</em>, <em>302</em>,
103599. (<a href="https://doi.org/10.1016/j.artint.2021.103599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method to detect implicit model patterns (such as global constraints) that might be able to replace parts of a combinatorial problem model that are expressed at a low-level. This can help non-expert users write higher-level models that are easier to reason about and often yield better performance. Our method generates candidate model patterns by analyzing both the structure of the model – its constraints, variables, parameters and loops – and the input data from one or more data files. Each candidate is scored by comparing a sample of its solution space with that of the part of the model it is intended to replace. The top-scoring candidates are presented to the user through an interactive display, which shows how they could be incorporated into the model. The method is implemented for the MiniZinc modeling language and available as part of the MiniZinc distribution.},
  archive      = {J_AIJ},
  author       = {Kevin Leo and Christopher Mears and Guido Tack and Maria Garcia de la Banda},
  doi          = {10.1016/j.artint.2021.103599},
  journal      = {Artificial Intelligence},
  pages        = {103599},
  shortjournal = {Artif. Intell.},
  title        = {Globalizing constraint models},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Situation calculus for controller synthesis in manufacturing
systems with first-order state representation. <em>AIJ</em>,
<em>302</em>, 103598. (<a
href="https://doi.org/10.1016/j.artint.2021.103598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manufacturing is transitioning from a mass production model to a service model in which facilities ‘bid’ to produce products. To decide whether to bid for a complex, previously unseen product, a facility must be able to synthesize, on the fly, a process plan controller that delegates abstract manufacturing tasks in a supplied process recipe to the available manufacturing resources. Often manufacturing processes depend on the data and objects (parts) they produce and consume. To formalize this aspect we need to adopt a first-order representation of the state of the processes. First-order representations of the state are commonly considered in reasoning about action in AI , and here we show that we can leverage the wide literature on the Situation Calculus and ConGolog programs to formalize this kind of manufacturing. With such a formalization available, we investigate how to synthesize process plan controllers in this first-order state setting. We also identify two important decidable cases—finite domains and bounded action theories—for which we provide techniques to actually synthesize the controller.},
  archive      = {J_AIJ},
  author       = {Giuseppe De Giacomo and Paolo Felli and Brian Logan and Fabio Patrizi and Sebastian Sardiña},
  doi          = {10.1016/j.artint.2021.103598},
  journal      = {Artificial Intelligence},
  pages        = {103598},
  shortjournal = {Artif. Intell.},
  title        = {Situation calculus for controller synthesis in manufacturing systems with first-order state representation},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pareto optimization for subset selection with dynamic cost
constraints. <em>AIJ</em>, <em>302</em>, 103597. (<a
href="https://doi.org/10.1016/j.artint.2021.103597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the subset selection problem for function f with constraint bound B that changes over time. Within the area of submodular optimization, various greedy approaches are commonly used. For dynamic environments we observe that the adaptive variants of these greedy approaches are not able to maintain their approximation quality. Investigating the recently introduced POMC Pareto optimization approach, we show that this algorithm efficiently computes a ϕ = ( α f / 2 ) ( 1 − 1 e α f ) ϕ=(αf/2)(1−1eαf) -approximation, where α f αf is the submodularity ratio of f , for each possible constraint bound b ≤ B b≤B . Furthermore, we show that POMC is able to adapt its set of solutions quickly in the case that B increases. Our experimental investigations for the influence maximization in social networks show the advantage of POMC over generalized greedy algorithms . We also consider EAMC, a new evolutionary algorithm with polynomial expected time guarantee to maintain ϕ approximation ratio, and NSGA-II with two different population sizes as advanced multi-objective optimization algorithm, to demonstrate their challenges in optimizing the maximum coverage problem. Our empirical analysis shows that, within the same number of evaluations, POMC is able to perform as good as NSGA-II under linear constraint , while EAMC performs significantly worse than all considered algorithms in most cases.},
  archive      = {J_AIJ},
  author       = {Vahid Roostapour and Aneta Neumann and Frank Neumann and Tobias Friedrich},
  doi          = {10.1016/j.artint.2021.103597},
  journal      = {Artificial Intelligence},
  pages        = {103597},
  shortjournal = {Artif. Intell.},
  title        = {Pareto optimization for subset selection with dynamic cost constraints},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian feature interaction selection for factorization
machines. <em>AIJ</em>, <em>302</em>, 103589. (<a
href="https://doi.org/10.1016/j.artint.2021.103589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factorization machines are a generic supervised method for a wide range of tasks in the field of artificial intelligence , such as prediction, inference, etc., which can effectively model feature interactions. However, handling combinations of features is expensive due to the exponential growth of feature interactions with the order. In nature, not all feature interactions are equally useful for prediction. Recently, a large number of methods that perform feature interaction selection have attracted great attention because of their effectiveness at filtering out useless feature interactions. Current feature interaction selection methods suffered from the following limitations: (1) they assume that all users share the same feature interactions; and (2) they select pairwise feature interactions only. In this paper, we propose novel Bayesian variable selection methods, targeting feature interaction selection for factorization machines, which effectively reduce the number of interactions. We study personalized feature interaction selection to account for individual preferences, and further extend the model to investigate higher-order feature interaction selection on higher-order factorization machines. We provide empirical evidence for the advantages of the proposed Bayesian feature interaction selection methods using different prediction tasks.},
  archive      = {J_AIJ},
  author       = {Yifan Chen and Yang Wang and Pengjie Ren and Meng Wang and Maarten de Rijke},
  doi          = {10.1016/j.artint.2021.103589},
  journal      = {Artificial Intelligence},
  pages        = {103589},
  shortjournal = {Artif. Intell.},
  title        = {Bayesian feature interaction selection for factorization machines},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Overlapping communities and roles in networks with node
attributes: Probabilistic graphical modeling, bayesian formulation and
variational inference. <em>AIJ</em>, <em>302</em>, 103580. (<a
href="https://doi.org/10.1016/j.artint.2021.103580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community and role discovery are key tasks in network analysis . The former unveils the organization of a network, whereas the latter highlights the social functions of nodes. The integration of community discovery and role analysis has been investigated, to gain a deeper understanding of topology, i.e., the social functions fulfilled by nodes to pursue community purposes. However, hitherto, node attributes and behavioral role patterns have been ignored in the combination of both tasks. In this manuscript, we study the seamless integration of community discovery and behavioral role analysis, in the domain of networks with node attributes. In particular, we focus on unifying the two tasks, by explicitly harnessing node attributes and behavioral role patterns in a principled manner. To this end, we propose two Bayesian probabilistic generative models of networks, whose novelty consists in the interrelationship of overlapping communities, roles, their behavioral patterns and node attributes. The devised models allow for a variety of exploratory, descriptive and predictive tasks. These are carried out through mean-field variational inference, which is in turn mathematically derived and implemented into a coordinate-ascent algorithm. A wide spectrum of experiments is designed, to validate the devised models against three classes of state-of-the-art competitors using various real-world benchmark data sets from different social networking services. Our models are found to be more accurate in community detection, link prediction and attribute prediction. Notably, the gain in accuracy is robust to perturbations in the form of noise or lack of observations in either network structure or node attributes. Beside accuracy, scalability is also comparatively investigated. Finally, a qualitative demonstration of the tasks enabled by our models is developed, in which node roles are intuitively explained through an unprecedented visual representation.},
  archive      = {J_AIJ},
  author       = {Gianni Costa and Riccardo Ortale},
  doi          = {10.1016/j.artint.2021.103580},
  journal      = {Artificial Intelligence},
  pages        = {103580},
  shortjournal = {Artif. Intell.},
  title        = {Overlapping communities and roles in networks with node attributes: Probabilistic graphical modeling, bayesian formulation and variational inference},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Probabilistic modelling of general noisy multi-manifold data
sets. <em>AIJ</em>, <em>302</em>, 103579. (<a
href="https://doi.org/10.1016/j.artint.2021.103579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intrinsic nature of noisy and complex data sets is often concealed in low-dimensional structures embedded in a higher dimensional space. Number of methodologies have been developed to extract and represent such structures in the form of manifolds (i.e. geometric structures that locally resemble continuously deformable intervals of R j Rj 1 ). Usually a-priori knowledge of the manifold&#39;s intrinsic dimensionality is required. Additionally, their performance can often be hampered by the presence of a significant high-dimensional noise aligned along the low-dimensional core manifold. In real-world applications, the data can contain several low-dimensional structures of different dimensionalities. We propose a framework for dimensionality estimation and reconstruction of multiple noisy manifolds embedded in a noisy environment . To the best of our knowledge, this work represents the first attempt at detection and modelling of a set of coexisting general noisy manifolds by uniting two aspects of multi-manifold learning: the recovery and approximation of core noiseless manifolds and the construction of their probabilistic models. The easy-to-understand hyper-parameters can be manipulated to obtain an emerging picture of the multi-manifold structure of the data. We demonstrate the workings of the framework on two synthetic data sets, presenting challenging features for state-of-the-art techniques in Multi-Manifold learning. The first data set consists of multiple sampled noisy manifolds of different intrinsic dimensionalities, such as Möbius strip, toroid and spiral arm. The second one is a topologically complex set of three interlocked toroids. Given the absence of such unified methodologies in the literature, the comparison with existing techniques is organized along the two separate aspects of our approach mentioned above, namely manifold approximation and probabilistic modelling . The framework is then applied to a complex data set containing simulated gas volume particles from a particle simulation of a dwarf galaxy interacting with its host galaxy cluster. Detailed analysis of the recovered 1D and 2D manifolds can help us to understand the nature of Star Formation in such complex systems.},
  archive      = {J_AIJ},
  author       = {M. Canducci and P. Tiño and M. Mastropietro},
  doi          = {10.1016/j.artint.2021.103579},
  journal      = {Artificial Intelligence},
  pages        = {103579},
  shortjournal = {Artif. Intell.},
  title        = {Probabilistic modelling of general noisy multi-manifold data sets},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The quest of parsimonious XAI: A human-agent architecture
for explanation formulation. <em>AIJ</em>, <em>302</em>, 103573. (<a
href="https://doi.org/10.1016/j.artint.2021.103573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread use of Artificial Intelligence (AI), understanding the behavior of intelligent agents and robots is crucial to guarantee successful human-agent collaboration since it is not straightforward for humans to understand an agent&#39;s state of mind. Recent empirical studies have confirmed that explaining a system&#39;s behavior to human users fosters the latter&#39;s acceptance of the system. However, providing overwhelming or unnecessary information may also confuse the users and cause failure. For these reasons, parsimony has been outlined as one of the key features allowing successful human-agent interaction with parsimonious explanation defined as the simplest explanation ( i.e. least complex) that describes the situation adequately ( i.e. descriptive adequacy). While parsimony is receiving growing attention in the literature, most of the works are carried out on the conceptual front. This paper proposes a mechanism for parsimonious eXplainable AI (XAI). In particular, it introduces the process of explanation formulation and proposes HAExA, a human-agent explainability architecture allowing to make it operational for remote robots. To provide parsimonious explanations, HAExA relies on both contrastive explanations and explanation filtering. To evaluate the proposed architecture, several research hypotheses are investigated in an empirical user study that relies on well-established XAI metrics to estimate how trustworthy and satisfactory the explanations provided by HAExA are. The results are analyzed using parametric and non-parametric statistical testing.},
  archive      = {J_AIJ},
  author       = {Yazan Mualla and Igor Tchappi and Timotheus Kampik and Amro Najjar and Davide Calvaresi and Abdeljalil Abbas-Turki and Stéphane Galland and Christophe Nicolle},
  doi          = {10.1016/j.artint.2021.103573},
  journal      = {Artificial Intelligence},
  pages        = {103573},
  shortjournal = {Artif. Intell.},
  title        = {The quest of parsimonious XAI: A human-agent architecture for explanation formulation},
  volume       = {302},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
