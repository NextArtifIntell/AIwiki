<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJNS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijns---71">IJNS - 71</h2>
<ul>
<li><details>
<summary>
(2022). Exploiting textual information for fake news detection.
<em>IJNS</em>, <em>32</em>(12), 2250058. (<a
href="https://doi.org/10.1142/S0129065722500587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Fake news” refers to the deliberate dissemination of news with the purpose to deceive and mislead the public. This paper assesses the accuracy of several Machine Learning (ML) algorithms, using a style-based technique that relies on textual information extracted from news, such as part of speech counts. To expand the already proposed styled-based techniques, a new method of enhancing a linguistic feature set is proposed. It combines Named Entity Recognition (NER) with the Frequent Pattern (FP) Growth association rule mining algorithm, aiming to provide better insight into the papers’ sentence level structure. Recursive feature elimination was used to identify a subset of the highest performing linguistic characteristics, which turned out to align with the literature. Using pre-trained word embeddings, document embeddings and weighted document embeddings were constructed using each word’s TF-IDF value as the weight factor. The document embeddings were mixed with the linguistic features providing a variety of training/test feature sets. For each model, the best performing feature set was identified and fine-tuned regarding its hyper parameters to improve accuracy. ML algorithms’ results were compared with two Neural Networks: Convolutional Neural Network (CNN) and Long-Short-Term Memory (LSTM). The results indicate that CNN outperformed all other methods in terms of accuracy, when companied with pre-trained word embeddings, yet SVM performs almost the same with a wider variety of input feature sets. Although style-based technique scores lower accuracy, it provides explainable results about the author’s writing style decisions. Our work points out how new technologies and combinations of existing techniques can enhance the style-based approach capturing more information.},
  archive      = {J_IJNS},
  author       = {Dimitrios Panagiotis Kasseropoulos and Paraskevas Koukaras and Christos Tjortjis},
  doi          = {10.1142/S0129065722500587},
  journal      = {International Journal of Neural Systems},
  number       = {12},
  pages        = {2250058},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Exploiting textual information for fake news detection},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A conditional generative adversarial network and transfer
learning-oriented anomaly classification system for electrospun
nanofibers. <em>IJNS</em>, <em>32</em>(12), 2250054. (<a
href="https://doi.org/10.1142/S012906572250054X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a generative model and transfer learning powered system for classification of Scanning Electron Microscope (SEM) images of defective nanofibers (D-NF) and nondefective nanofibers (ND-NF) produced by electrospinning (ES) process. Specifically, a conditional-Generative Adversarial Network ( c -GAN) is developed to generate synthetic D-NF/ND-NF SEM images. A transfer learning-oriented strategy is also proposed. First, a Convolutional Neural Network (CNN) is pre-trained on real images. The transfer-learned CNN is trained on synthetic SEM images and validated on real ones, reporting accuracy rate up to 95.31%. The achieved encouraging results endorse the use of the proposed generative model in industrial applications as it could reduce the number of needed laboratory ES experiments that are costly and time consuming.},
  archive      = {J_IJNS},
  author       = {Cosimo Ieracitano and Nadia Mammone and Annunziata Paviglianiti and Francesco Carlo Morabito},
  doi          = {10.1142/S012906572250054X},
  journal      = {International Journal of Neural Systems},
  number       = {12},
  pages        = {2250054},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A conditional generative adversarial network and transfer learning-oriented anomaly classification system for electrospun nanofibers},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convolutional neural networks-based framework for early
identification of dementia using MRI of brain asymmetry. <em>IJNS</em>,
<em>32</em>(12), 2250053. (<a
href="https://doi.org/10.1142/S0129065722500538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-aided diagnosis of health problems and pathological conditions has become a substantial part of medical, biomedical, and computer science research. This paper focuses on the diagnosis of early and progressive dementia, building on the potential of deep learning (DL) models. The proposed computational framework exploits a magnetic resonance imaging (MRI) brain asymmetry biomarker, which has been associated with early dementia, and employs DL architectures for MRI image classification. Identification of early dementia is accomplished by an eight-layered convolutional neural network (CNN) as well as transfer learning of pretrained CNNs from ImageNet. Different instantiations of the proposed CNN architecture are tested. These are equipped with Softmax, support vector machine (SVM), linear discriminant (LD), or k -nearest neighbor (KNN) classification layers, assembled as a separate classification module, which are attached to the core CNN architecture. The initial imaging data were obtained from the MRI directory of the Alzheimer’s disease neuroimaging initiative 3 (ADNI3) database. The independent testing dataset was created using image preprocessing and segmentation algorithms applied to unseen patients’ imaging data. The proposed approach demonstrates a 90.12% accuracy in distinguishing patients who are cognitively normal subjects from those who have Alzheimer’s disease (AD), and an 86.40% accuracy in detecting early mild cognitive impairment (EMCI).},
  archive      = {J_IJNS},
  author       = {Nitsa J Herzog and George D Magoulas},
  doi          = {10.1142/S0129065722500538},
  journal      = {International Journal of Neural Systems},
  number       = {12},
  pages        = {2250053},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Convolutional neural networks-based framework for early identification of dementia using MRI of brain asymmetry},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convolutional neural networks quantization with double-stage
squeeze-and-threshold. <em>IJNS</em>, <em>32</em>(12), 2250051. (<a
href="https://doi.org/10.1142/S0129065722500514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been proven that, compared to using 32-bit floating-point numbers in the training phase, Deep Convolutional Neural Networks (DCNNs) can operate with low-precision during inference, thereby saving memory footprint and power consumption. However, neural network quantization is always accompanied by accuracy degradation. Here, we propose a quantization method called double-stage Squeeze-and-Threshold (double-stage ST) to close the accuracy gap with full-precision models. While accurate colors in pictures can be pleasing to the viewer, they are not necessary for distinguishing objects. The era of black and white television proves this idea. As long as the limited colors are filled reasonably for different objects, the objects can be well identified and distinguished. Our method utilizes the attention mechanism to adjust the activations and learn the thresholds to distinguish objects (features). We then divide the numerically rich activations into intervals (a limited variety of numerical values) by the learned thresholds. The proposed method supports both binarization and multi-bit quantization. Our method achieves state-of-the-art results. In binarization, ReActNet [Z. Liu, Z. Shen, S. Li, K. Helwegen, D. Huang and K. Cheng, arXiv:abs/2106.11309 ] trained with our method outperforms the previous state-of-the-art result by 0.2 percentage points. Whereas in multi-bit quantization, the top-1 accuracy of the 3-bit ResNet-18 [K. He, X. Zhang, S. Ren and J. Sun, Deep residual learning for image recognition, 2016 IEEE Conf. Computer Vision and Pattern Recognition, CVPR 2016 , 27–30 June 2016, Las Vegas, NV, USA (IEEE Computer Society, 2016), pp. 770–778] model exceeds the top-1 accuracy of its full-precision baseline model by 0.4 percentage points. The double-stage ST activation quantization method is easy to apply by inserting it before the convolution. Besides, the double-stage ST is detachable after training and introducing no computational cost in inference.},
  archive      = {J_IJNS},
  author       = {Binyi Wu and Bernd Waschneck and Christian Georg Mayr},
  doi          = {10.1142/S0129065722500514},
  journal      = {International Journal of Neural Systems},
  number       = {12},
  pages        = {2250051},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Convolutional neural networks quantization with double-stage squeeze-and-threshold},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reward-penalty weighted ensemble for emotion state
classification from multi-modal data streams. <em>IJNS</em>,
<em>32</em>(12), 2250049. (<a
href="https://doi.org/10.1142/S0129065722500496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers have shown the limitations of using the single-modal data stream for emotion classification. Multi-modal data streams are therefore deemed necessary to improve the accuracy and performance of online emotion classifiers. An online decision ensemble is a widely used approach to classify emotions in real-time using multi-modal data streams. There is a plethora of online ensemble approaches; these approaches use a fixed parameter ( β ) to adjust the weights of each classifier (called penalty) in case of wrong classification and no reward for a good performing classifier. Also, the performance of the ensemble depends on the β , which is set using trial and error. This paper presents a new Reward-Penalty-based Weighted Ensemble (RPWE) for real-time multi-modal emotion classification using multi-modal physiological data streams. The proposed RPWE is thoroughly tested using two prevalent benchmark data sets, DEAP and AMIGOS. The first experiment confirms the impact of the base stream classifier with RPWE for emotion classification in real-time. The RPWE is compared with different popular and widely used online ensemble approaches using multi-modal data streams in the second experiment. The average balanced accuracy, F1-score results showed the usefulness and robustness of RPWE in emotion classification in real-time from the multi-modal data stream.},
  archive      = {J_IJNS},
  author       = {Arijit Nandi and Fatos Xhafa and Laia Subirats and Santi Fort},
  doi          = {10.1142/S0129065722500496},
  journal      = {International Journal of Neural Systems},
  number       = {12},
  pages        = {2250049},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Reward-penalty weighted ensemble for emotion state classification from multi-modal data streams},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Personalized watch-based fall detection using a
collaborative edge-cloud framework. <em>IJNS</em>, <em>32</em>(12),
2250048. (<a href="https://doi.org/10.1142/S0129065722500484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of current smart health applications are deployed on a smartphone paired with a smartwatch. The phone is used as the computation platform or the gateway for connecting to the cloud while the watch is used mainly as the data sensing device. In the case of fall detection applications for older adults, this kind of setup is not very practical since it requires users to always keep their phones in proximity while doing the daily chores. When a person falls, in a moment of panic, it might be difficult to locate the phone in order to interact with the Fall Detection App for the purpose of indicating whether they are fine or need help. This paper demonstrates the feasibility of running a real-time personalized deep-learning-based fall detection system on a smartwatch device using a collaborative edge-cloud framework. In particular, we present the software architecture we used for the collaborative framework, demonstrate how we automate the fall detection pipeline, design an appropriate UI on the small screen of the watch, and implement strategies for the continuous data collection and automation of the personalization process with the limited computational and storage resources of a smartwatch. We also present the usability of such a system with nine real-world older adult participants.},
  archive      = {J_IJNS},
  author       = {Anne Hee Ngu and Vangelis Metsis and Shuan Coyne and Priyanka Srinivas and Tarek Salad and Uddin Mahmud and Kyong Hee Chee},
  doi          = {10.1142/S0129065722500484},
  journal      = {International Journal of Neural Systems},
  number       = {12},
  pages        = {2250048},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Personalized watch-based fall detection using a collaborative edge-cloud framework},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Introduction. <em>IJNS</em>, <em>32</em>(12), 2202002. (<a
href="https://doi.org/10.1142/S0129065722020026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJNS},
  author       = {Professor Lazaros Iliadis},
  doi          = {10.1142/S0129065722020026},
  journal      = {International Journal of Neural Systems},
  number       = {12},
  pages        = {2202002},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Introduction},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting a time-dependent quantity using recursive
generative query network. <em>IJNS</em>, <em>32</em>(11), 2250056. (<a
href="https://doi.org/10.1142/S0129065722500563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose here a novel neural architecture dedicated to the prediction of time series. It can be considered as an adaptation of the idea of (GQN) to the data which is of a sequence nature. The new approach, dubbed here as the (RGQN), allows for efficient prediction of time series. The predictor information (i.e. the independent variable) is one or more of the other time series which are in some relationship with the predicted sequence. Each time series is accompanied by additional meta-information reflecting its selected properties. This meta-information, together with the standard dynamic component, is provided simultaneously in (RNN). During the inference phase, meta-information becomes a query reflecting the expected properties of the predicted time series. The proposed idea is illustrated with use cases of strong practical relevance. In particular, we discuss the example of an industrial pipeline that transports liquid media. The trained RGQN model is applied to predict pressure signals, assuming that the training was carried out during routine operational conditions. The subsequent comparison of the prediction with the actual data gathered under extraordinary circumstances, e.g. during the leakage, leads to a specific residual distribution of the prediction. This information can be applied directly within the data-driven Leak Detection and Location framework. The RGQN approach can be applied not only to pressure time series but also in many other use cases where the quantity of sequence nature is accompanied by a meta-descriptor.},
  archive      = {J_IJNS},
  author       = {Grzegorz Miebs and Michał Wójcik and Adam Karaszewski and Małgorzata Mochol-Grzelak and Paulina Wawdysz and Rafał A. Bachorz},
  doi          = {10.1142/S0129065722500563},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2250056},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Predicting a time-dependent quantity using recursive generative query network},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enzymatic numerical spiking neural membrane systems and
their application in designing membrane controllers. <em>IJNS</em>,
<em>32</em>(11), 2250055. (<a
href="https://doi.org/10.1142/S0129065722500551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural P systems (SN P systems), inspired by biological neurons, are introduced as symbolical neural-like computing models that encode information with multisets of symbolized spikes in neurons and process information by using spike-based rewriting rules. Inspired by neuronal activities affected by enzymes, a numerical variant of SN P systems called enzymatic numerical spiking neural P systems (ENSNP systems) is proposed wherein each neuron has a set of variables with real values and a set of enzymatic activation-production spiking rules, and each synapse has an assigned weight. By using spiking rules, ENSNP systems can directly implement mathematical methods based on real numbers and continuous functions. Furthermore, ENSNP systems are used to model ENSNP membrane controllers (ENSNP-MCs) for robots implementing wall following. The trajectories, distances from the wall, and wheel speeds of robots with ENSNP-MCs for wall following are compared with those of a robot with a membrane controller for wall following. The average error values of the designed ENSNP-MCs are compared with three recently fuzzy logical controllers with optimization algorithms for wall following. The experimental results showed that the designed ENSNP-MCs can be candidates as efficient controllers to control robots implementing the task of wall following.},
  archive      = {J_IJNS},
  author       = {Luping Zhang and Fei Xu and Dongyang Xiao and Jianping Dong and Gexiang Zhang and Ferrante Neri},
  doi          = {10.1142/S0129065722500551},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2250055},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Enzymatic numerical spiking neural membrane systems and their application in designing membrane controllers},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization of neuroprosthetic vision via end-to-end deep
reinforcement learning. <em>IJNS</em>, <em>32</em>(11), 2250052. (<a
href="https://doi.org/10.1142/S0129065722500526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual neuroprostheses are a promising approach to restore basic sight in visually impaired people. A major challenge is to condense the sensory information contained in a complex environment into meaningful stimulation patterns at low spatial and temporal resolution. Previous approaches considered task-agnostic feature extractors such as edge detectors or semantic segmentation, which are likely suboptimal for specific tasks in complex dynamic environments. As an alternative approach, we propose to optimize stimulation patterns by end-to-end training of a feature extractor using deep reinforcement learning agents in virtual environments. We present a task-oriented evaluation framework to compare different stimulus generation mechanisms, such as static edge-based and adaptive end-to-end approaches like the one introduced here. Our experiments in Atari games show that stimulation patterns obtained via task-dependent end-to-end optimized reinforcement learning result in equivalent or improved performance compared to fixed feature extractors on high difficulty levels. These findings signify the relevance of adaptive reinforcement learning for neuroprosthetic vision in complex environments.},
  archive      = {J_IJNS},
  author       = {Burcu Küçükoğlu and Bodo Rueckauer and Nasir Ahmad and Jaap de Ruyter van Steveninck and Umut Güçlü and Marcel van Gerven},
  doi          = {10.1142/S0129065722500526},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2250052},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Optimization of neuroprosthetic vision via end-to-end deep reinforcement learning},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic seizure identification from EEG signals based on
brain connectivity learning. <em>IJNS</em>, <em>32</em>(11), 2250050.
(<a href="https://doi.org/10.1142/S0129065722500502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a neurological disorder caused by brain dysfunction, which could cause uncontrolled behavior, loss of consciousness and other hazards. Electroencephalography (EEG) is an indispensable auxiliary tool for clinical diagnosis. Great progress has been made by current seizure identification methods. However, the performance of the methods on different patients varies a lot. In order to deal with this problem, we propose an automatic seizure identification method based on brain connectivity learning. The connectivity of different brain regions is modeled by a graph. Different from the manually defined graph structure, our method can extract the optimal graph structure and EEG features in an end-to-end manner. Combined with the popular graph attention neural network (GAT), this method achieves high performance and stability on different patients from the CHB-MIT dataset. The average values of accuracy, sensitivity, specificity, F1-score and AUC of the proposed model are 98.90%, 98.33%, 98.48%, 97.72% and 98.54%, respectively. The standard deviations of the above five indicators are 0.0049, 0.0125, 0.0116 and 0.0094, respectively. Compared with the existing seizure identification methods, the stability of the proposed model is improved by 78–95%.},
  archive      = {J_IJNS},
  author       = {Yanna Zhao and Mingrui Xue and Changxu Dong and Jiatong He and Dengyu Chu and Gaobo Zhang and Fangzhou Xu and Xinting Ge and Yuanjie Zheng},
  doi          = {10.1142/S0129065722500502},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2250050},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Automatic seizure identification from EEG signals based on brain connectivity learning},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diagnosis of autism disorder based on deep network trained
by augmented EEG signals. <em>IJNS</em>, <em>32</em>(11), 2250046. (<a
href="https://doi.org/10.1142/S0129065722500460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder is a neurodevelopmental disorder typically characterized by abnormalities in social interaction and stereotyped and repetitive behaviors. Diagnosis of autism is mainly based on behavioral tests and interviews. In recent years, studies involving the diagnosis of autism based on analysis of EEG signals have increased. In this paper, recorded signals from people suffering from autism and healthy individuals are divided to without overlap windows considered as images and these images are classified using a two-dimensional Deep Convolution Neural Network (2D-DCNN). Deep learning models require a lot of data to extract the appropriate features and automate data classification. But, in most neurological studies, preparing a large number of measurements is difficult (a few 1000s as compared to million natural images), due to the cost, time, and difficulty of recording these signals. Therefore, to make the appropriate number of data, in our proposed method, some of the data augmentation methods are used. These data augmentation methods are mainly introduced for image databases and should be generalized for EEG-as-an-image database. In this paper, one of the nonlinear image mixing methods is used that mixes the rows of two images. According to the fact that any row in our image is one channel of EEG signal, this method is named channel combination. The result is that in the best case, i.e., augmentation according to channel combination, the average accuracy of 88.29% is achieved in the classification of short signals of healthy people and ASD ones and 100% for ASD and epilepsy ones, using 2D-DCNN. After the decision on joined windows related to each subject, we could achieve 100% accuracy in detecting ASD subjects, according to long EEG signals.},
  archive      = {J_IJNS},
  author       = {Habib Adabi Ardakani and Maryam Taghizadeh and Farzaneh Shayegh},
  doi          = {10.1142/S0129065722500460},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2250046},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Diagnosis of autism disorder based on deep network trained by augmented EEG signals},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adolescent depression detection model based on multimodal
data of interview audio and text. <em>IJNS</em>, <em>32</em>(11),
2250045. (<a href="https://doi.org/10.1142/S0129065722500459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression is a common mental disease that has a tendency to develop at a younger age. Early detection of depression with psychological intervention may effectively prevent youth suicide. The establishment of the computer-aided model may be efficient for early detection. However, the existing methods of automatic detection for depression mostly rely on unimodal data. Clinical research shows that patients with depression have specificity in speech, text, expression, and other modal data. Multimodal machine learning is emerging but not yet widely used for the detection of psychiatric disorders. The problem of existing multimodal detection models is that only global or local information is considered in feature fusion, which leads to the low accuracy of the depression detection model. Therefore, this study constructs an automatic detection model based on multimodal machine learning for adolescent depression. The proposed method first extracted four features from audio and text globally and locally; then construct a coarse-grained fusion model and fine-grained fusion model base on these four features; and fuse the coarse-grained and the fine-grained fusion model finally. Experiments on the real-world dataset demonstrate that the proposed method could improve the accuracy of depression detection automatically.},
  archive      = {J_IJNS},
  author       = {Lei Zhang and Yuanxiao Fan and Jingwen Jiang and Yuchen Li and Wei Zhang},
  doi          = {10.1142/S0129065722500459},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2250045},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Adolescent depression detection model based on multimodal data of interview audio and text},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of an AI-enabled system for pain monitoring
using skin conductance sensoring in socks. <em>IJNS</em>,
<em>32</em>(10), 2250047. (<a
href="https://doi.org/10.1142/S0129065722500472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background : Where self-report is unfeasible or observations are difficult, physiological estimates of pain are needed. Methods : Pain-data from 30 healthy adults were gathered to create a database of physiological pain responses. A model was then developed, to analyze pain-data and visualize the AI-estimated level of pain on a mobile app. Results : The initial low precision and F1-score of the pain classification algorithm were resolved by interpolating a percentage of similar data. Discussion : This system presents a novel approach to assess pain in noncommunicative people with the use of a sensor sock, AI predictor and mobile app. Performance analysis and the limitations of the AI algorithm are discussed.},
  archive      = {J_IJNS},
  author       = {Helen Korving and Di Zhou and Huan Xiang and Paula Sterkenburg and Panos Markopoulos and Emilia Barakova},
  doi          = {10.1142/S0129065722500472},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2250047},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Development of an AI-enabled system for pain monitoring using skin conductance sensoring in socks},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Emotion classification from EEG with a low-cost BCI versus a
high-end equipment. <em>IJNS</em>, <em>32</em>(10), 2250041. (<a
href="https://doi.org/10.1142/S0129065722500411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assessment of physiological signals such as the electroencephalography (EEG) has become a key point in the research area of emotion detection. This study compares the performance of two EEG devices, a low-cost brain–computer interface (BCI) (Emotiv EPOC+) and a high-end EEG (BrainVision), for the detection of four emotional conditions over 20 participants. For that purpose, signals were acquired with both devices under the same experimental procedure, and a comparison was made under three different scenarios, according to the number of channels selected and the sampling frequency of the signals analyzed. A total of 16 statistical, spectral and entropy features were extracted from the EEG recordings. A statistical analysis revealed a major number of statistically significant features for the high-end EEG than the BCI device under the three comparative scenarios. In addition, different machine learning algorithms were used for evaluating the classification performance of the features extracted from high-end EEG and low-cost BCI in each scenario. Artificial neural networks reported the best performance for both devices with an F 1 -score of 75.08% for BCI and 98.78% for EEG. Although the professional EEG outcomes were higher than the low-cost BCI ones, both devices demonstrated a notable performance for the classification of the four emotional conditions.},
  archive      = {J_IJNS},
  author       = {Roberto Sánchez-Reolid and María Cruz Martínez-Sáez and Beatriz García-Martínez and Luz Fernández-Aguilar and Laura Ros and José Miguel Latorre and Antonio Fernández-Caballero},
  doi          = {10.1142/S0129065722500411},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2250041},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Emotion classification from EEG with a low-cost BCI versus a high-end equipment},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Affective action and interaction recognition by multi-view
representation learning from handcrafted low-level skeleton features.
<em>IJNS</em>, <em>32</em>(10), 2250040. (<a
href="https://doi.org/10.1142/S012906572250040X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human feelings expressed through verbal (e.g. voice) and non-verbal communication channels (e.g. face or body) can influence either human actions or interactions. In the literature, most of the attention was given to facial expressions for the analysis of emotions conveyed through non-verbal behaviors. Despite this, psychology highlights that the body is an important indicator of the human affective state in performing daily life activities. Therefore, this paper presents a novel method for affective action and interaction recognition from videos, exploiting multi-view representation learning and only full-body handcrafted characteristics selected following psychological and proxemic studies. Specifically, 2D skeletal data are extracted from RGB video sequences to derive diverse low-level skeleton features, i.e. multi-views, modeled through the bag-of-visual-words clustering approach generating a condition-related codebook. In this way, each affective action and interaction within a video can be represented as a frequency histogram of codewords. During the learning phase, for each affective class, training samples are used to compute its global histogram of codewords stored in a database and later used for the recognition task. In the recognition phase, the video frequency histogram representation is matched against the database of class histograms and classified as the closest affective class in terms of Euclidean distance. The effectiveness of the proposed system is evaluated on a specifically collected dataset containing 6 emotion for both actions and interactions, on which the proposed system obtains 93.64% and 90.83% accuracy, respectively. In addition, the devised strategy also achieves in line performances with other literature works based on deep learning when tested on a public collection containing 6 emotions plus a neutral state, demonstrating the effectiveness of the presented approach and confirming the findings in psychological and proxemic studies.},
  archive      = {J_IJNS},
  author       = {Danilo Avola and Marco Cascio and Luigi Cinque and Alessio Fagioli and Gian Luca Foresti},
  doi          = {10.1142/S012906572250040X},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2250040},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Affective action and interaction recognition by multi-view representation learning from handcrafted low-level skeleton features},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Facial affect recognition in immersive virtual reality:
Where is the participant looking? <em>IJNS</em>, <em>32</em>(10),
2250029. (<a href="https://doi.org/10.1142/S0129065722500290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recognition of facial expression of emotions in others is essential in daily social interactions. The different areas of the face play different roles in decoding each emotion. To find out which ones are more important, the traditional approach has been to use eye-tracking devices with static pictures to capture which parts of the face people are looking at when decoding emotions. However, the ecological validity of this approach is limited because, unlike in real life, there is no movement in the face that can be used to identify the emotion. The use of virtual reality technology opens the door to new experiences in which the users perceive that they are in front of dynamic virtual humans. Therefore, our main aim is to investigate whether the user’s immersion in a virtual environment influences the way dynamic virtual faces are visually scanned when decoding emotions. An experiment involving 74 healthy participants was carried out. The results obtained are consistent with previous works. Having confirmed the correct functioning of our solution, it is our intention to study whether emotion recognition deficits in patients with neuropsychiatric disorders are related to the way they visually scan faces.},
  archive      = {J_IJNS},
  author       = {Miguel A. Vicente-Querol and Antonio Fernández-Caballero and José P. Molina and Luz M. González-Gualda and Patricia Fernández-Sotos and Arturo S. García},
  doi          = {10.1142/S0129065722500290},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2250029},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Facial affect recognition in immersive virtual reality: Where is the participant looking?},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation of brain functional connectivity from
electroencephalographic signals under different emotional states.
<em>IJNS</em>, <em>32</em>(10), 2250026. (<a
href="https://doi.org/10.1142/S0129065722500265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of the emotional states corresponding to the four quadrants of the valence/arousal space has been widely analyzed in the scientific literature by means of multiple techniques. Nevertheless, most of these methods were based on the assessment of each brain region separately, without considering the possible interactions among different areas. In order to study these interconnections, this study computes for the first time the functional connectivity metric called cross-sample entropy for the analysis of the brain synchronization in four groups of emotions from electroencephalographic signals. Outcomes reported a strong synchronization in the interconnections among central, parietal and occipital areas, while the interactions between left frontal and temporal structures with the rest of brain regions presented the lowest coordination. These differences were statistically significant for the four groups of emotions. All emotions were simultaneously classified with a 95.43% of accuracy, overcoming the results reported in previous studies. Moreover, the differences between high and low levels of valence and arousal, taking into account the state of the counterpart dimension, also provided notable findings about the degree of synchronization in the brain within different emotional conditions and the possible implications of these outcomes from a psychophysiological point of view.},
  archive      = {J_IJNS},
  author       = {Beatriz García-Martínez and Antonio Fernández-Caballero and Arturo Martínez-Rodrigo and Raúl Alcaraz and Paulo Novais},
  doi          = {10.1142/S0129065722500265},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2250026},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Evaluation of brain functional connectivity from electroencephalographic signals under different emotional states},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Introduction. <em>IJNS</em>, <em>32</em>(10), 2202001. (<a
href="https://doi.org/10.1142/S0129065722020014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJNS},
  author       = {José M. Ferrández and Eduardo Fernandez and Diego Andina and Kazuyuki Murase},
  doi          = {10.1142/S0129065722020014},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2202001},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Introduction},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uncovering brain differences in preschoolers and young
adolescents with autism spectrum disorder using deep learning.
<em>IJNS</em>, <em>32</em>(9), 2250044. (<a
href="https://doi.org/10.1142/S0129065722500447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying brain abnormalities in autism spectrum disorder (ASD) is critical for early diagnosis and intervention. To explore brain differences in ASD and typical development (TD) individuals by detecting structural features using T1-weighted magnetic resonance imaging (MRI), we developed a deep learning-based approach, three-dimensional (3D)-ResNet with inception (I-ResNet), to identify participants with ASD and TD and propose a gradient-based backtracking method to pinpoint image areas that I-ResNet uses more heavily for classification. The proposed method was implemented in a preschool dataset with 110 participants and a public autism brain imaging data exchange (ABIDE) dataset with 1099 participants. An extra epilepsy dataset with 200 participants with clear degeneration in the parahippocampal area was applied as a verification and an extension. Among the datasets, we detected nine brain areas that differed significantly between ASD and TD. From the ROC in PASD and ABIDE, the sensitivity was 0.88 and 0.86, specificity was 0.75 and 0.62, and area under the curve was 0.787 and 0.856. In a word, I-ResNet with gradient-based backtracking could identify brain differences between ASD and TD. This study provides an alternative computer-aided technique for helping physicians to diagnose and screen children with an potential risk of ASD with deep learning model.},
  archive      = {J_IJNS},
  author       = {Shijun Li and Ziyang Tang and Nanxin Jin and Qiansu Yang and Gang Liu and Tiefang Liu and Jianxing Hu and Sijun Liu and Ping Wang and Jingru Hao and Zhiqiang Zhang and Xiaojing Zhang and Jinfeng Li and Xin Wang and Zhenzhen Li and Yi Wang and Baijian Yang and Lin Ma},
  doi          = {10.1142/S0129065722500447},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2250044},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Uncovering brain differences in preschoolers and young adolescents with autism spectrum disorder using deep learning},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient semi-supervised framework with multi-task and
curriculum learning for medical image segmentation. <em>IJNS</em>,
<em>32</em>(9), 2250043. (<a
href="https://doi.org/10.1142/S0129065722500435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A practical problem in supervised deep learning for medical image segmentation is the lack of labeled data which is expensive and time-consuming to acquire. In contrast, there is a considerable amount of unlabeled data available in the clinic. To make better use of the unlabeled data and improve the generalization on limited labeled data, in this paper, a novel semi-supervised segmentation method via multi-task curriculum learning is presented. Here, curriculum learning means that when training the network, simpler knowledge is preferentially learned to assist the learning of more difficult knowledge. Concretely, our framework consists of a main segmentation task and two auxiliary tasks, i.e. the feature regression task and target detection task. The two auxiliary tasks predict some relatively simpler image-level attributes and bounding boxes as the pseudo labels for the main segmentation task, enforcing the pixel-level segmentation result to match the distribution of these pseudo labels. In addition, to solve the problem of class imbalance in the images, a bounding-box-based attention (BBA) module is embedded, enabling the segmentation network to concern more about the target region rather than the background. Furthermore, to alleviate the adverse effects caused by the possible deviation of pseudo labels, error tolerance mechanisms are also adopted in the auxiliary tasks, including inequality constraint and bounding-box amplification. Our method is validated on ACDC2017 and PROMISE12 datasets. Experimental results demonstrate that compared with the full supervision method and state-of-the-art semi-supervised methods, our method yields a much better segmentation performance on a small labeled dataset. Code is available at https://github.com/DeepMedLab/MTCL .},
  archive      = {J_IJNS},
  author       = {Kaiping Wang and Yan Wang and Bo Zhan and Yujie Yang and Chen Zu and Xi Wu and Jiliu Zhou and Dong Nie and Luping Zhou},
  doi          = {10.1142/S0129065722500435},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2250043},
  shortjournal = {Int. J. Neural Syst.},
  title        = {An efficient semi-supervised framework with multi-task and curriculum learning for medical image segmentation},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection of alzheimer’s dementia by using signal
decomposition and machine learning methods. <em>IJNS</em>,
<em>32</em>(9), 2250042. (<a
href="https://doi.org/10.1142/S0129065722500423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dementia is one of the most common neurological disorders causing defection of cognitive functions, and seriously affects the quality of life. In this study, various methods have been proposed for the detection and follow-up of Alzheimer’s dementia (AD) with advanced signal processing methods by using electroencephalography (EEG) signals. Signal decomposition-based approaches such as empirical mode decomposition (EMD), ensemble EMD (EEMD), and discrete wavelet transform (DWT) are presented to classify EEG segments of control subjects (CSs) and AD patients. Intrinsic mode functions (IMFs) are obtained from the signals using the EMD and EEMD methods, and the IMFs showing the most significant differences between the two groups are selected by applying previously suggested selection procedures. Five-time-domain and 5-spectral-domain features are calculated using selected IMFs, and five detail and approximation coefficients of DWT. Signal decomposition processes are conducted for both 1 min and 5 s EEG segment durations. For the 1 min segment duration, all the proposed approaches yield prominent classification performances. While the highest classification accuracies are obtained using EMD (91.8%) and EEMD (94.1%) approaches from the temporal/right brain cluster, the highest classification accuracy for the DWT (95.2%) approach is obtained from the temporal/left brain cluster for 1 min segment duration.},
  archive      = {J_IJNS},
  author       = {Ozlem Karabiber Cura and Aydin Akan and Gulce Cosku Yilmaz and Hatice Sabiha Ture},
  doi          = {10.1142/S0129065722500423},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2250042},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Detection of alzheimer’s dementia by using signal decomposition and machine learning methods},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep convolution generative adversarial network-based
electroencephalogram data augmentation for post-stroke rehabilitation
with motor imagery. <em>IJNS</em>, <em>32</em>(9), 2250039. (<a
href="https://doi.org/10.1142/S0129065722500393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The motor imagery brain–computer interface (MI-BCI) system is currently one of the most advanced rehabilitation technologies, and it can be used to restore the motor function of stroke patients. The deep learning algorithms in the MI-BCI system require lots of training samples, but the electroencephalogram (EEG) data of stroke patients is quite scarce. Therefore, the expansion of EEG data has become an important part of stroke clinical rehabilitation research. In this paper, a deep convolution generative adversarial network (DCGAN) model is proposed to generate artificial EEG data and further expand the scale of the stroke dataset. First, multichannel one-dimensional EEG data is converted into a two-dimensional EEG spectrogram using EEG2Image based on the modified S-transform. Then, DCGAN is used to artificially generate EEG data based on MI. Finally, the validity of the generated artificial EEG data is proved. This paper preliminarily indicates that generating artificial stroke data is a promising strategy, which contributes to the further development of stroke clinical rehabilitation.},
  archive      = {J_IJNS},
  author       = {Fangzhou Xu and Gege Dong and Jincheng Li and Qingbo Yang and Lei Wang and Yanna Zhao and Yihao Yan and Jinzhao Zhao and Shaopeng Pang and Dongju Guo and Yang Zhang and Jiancai Leng},
  doi          = {10.1142/S0129065722500393},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2250039},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Deep convolution generative adversarial network-based electroencephalogram data augmentation for post-stroke rehabilitation with motor imagery},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neuro-inspired reinforcement learning to improve trajectory
prediction in reward-guided behavior. <em>IJNS</em>, <em>32</em>(9),
2250038. (<a href="https://doi.org/10.1142/S0129065722500381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hippocampal pyramidal cells and interneurons play a key role in spatial navigation. In goal-directed behavior associated with rewards, the spatial firing pattern of pyramidal cells is modulated by the animal’s moving direction toward a reward, with a dependence on auditory, olfactory, and somatosensory stimuli for head orientation. Additionally, interneurons in the CA1 region of the hippocampus monosynaptically connected to CA1 pyramidal cells are modulated by a complex set of interacting brain regions related to reward and recall. The computational method of reinforcement learning (RL) has been widely used to investigate spatial navigation, which in turn has been increasingly used to study rodent learning associated with the reward. The rewards in RL are used for discovering a desired behavior through the integration of two streams of neural activity: trial-and-error interactions with the external environment to achieve a goal, and the intrinsic motivation primarily driven by brain reward system to accelerate learning. Recognizing the potential benefit of the neural representation of this reward design for novel RL architectures, we propose a RL algorithm based on Q -learning with a perspective on biomimetics (neuro-inspired RL) to decode rodent movement trajectories. The reward function, inspired by the neuronal information processing uncovered in the hippocampus, combines the preferred direction of pyramidal cell firing as the extrinsic reward signal with the coupling between pyramidal cell–interneuron pairs as the intrinsic reward signal. Our experimental results demonstrate that the neuro-inspired RL, with a combined use of extrinsic and intrinsic rewards, outperforms other spatial decoding algorithms, including RL methods that use a single reward function. The new RL algorithm could help accelerate learning convergence rates and improve the prediction accuracy for moving trajectories.},
  archive      = {J_IJNS},
  author       = {Bo-Wei Chen and Shih-Hung Yang and Chao-Hung Kuo and Jia-Wei Chen and Yu-Chun Lo and Yun-Ting Kuo and Yi-Chen Lin and Hao-Cheng Chang and Sheng-Huang Lin and Xiao Yu and Boyi Qu and Shuan-Chu Vina Ro and Hsin-Yi Lai and You-Yin Chen},
  doi          = {10.1142/S0129065722500381},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2250038},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Neuro-inspired reinforcement learning to improve trajectory prediction in reward-guided behavior},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatial enhanced pattern through graph convolutional neural
network for epileptic EEG identification. <em>IJNS</em>, <em>32</em>(9),
2250033. (<a href="https://doi.org/10.1142/S0129065722500332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction is an essential procedure in the detection and recognition of epilepsy, especially for clinical applications. As a type of multichannel signal, the association between all of the channels in EEG samples can be further utilized. To implement the classification of epileptic seizures from the nonseizures in EEG samples, one graph convolutional neural network (GCNN)-based framework is proposed for capturing the spatial enhanced pattern of multichannel signals to characterize the behavior of EEG activity, which is capable of visualizing the salient regions in each sequence of EEG samples. Meanwhile, the presented GCNN could be exploited to discriminate normal, ictal and interictal EEGs as a novel classifier. To evaluate the proposed approach, comparison experiments were conducted between state-of-the-art techniques and ours. From the experimental results, we found that for ictal and interictal EEG signal discrimination, the presented approach can achieve a sensitivity of 98.33%, specificity of 99.19% and accuracy of 98.38%.},
  archive      = {J_IJNS},
  author       = {Jian Lian and Fangzhou Xu},
  doi          = {10.1142/S0129065722500332},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2250033},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Spatial enhanced pattern through graph convolutional neural network for epileptic EEG identification},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the tuning of the computation capability of spiking
neural membrane systems with communication on request. <em>IJNS</em>,
<em>32</em>(8), 2250037. (<a
href="https://doi.org/10.1142/S012906572250037X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural P systems (abbreviated as SNP systems) are models of computation that mimic the behavior of biological neurons. The spiking neural P systems with communication on request (abbreviated as SNQP systems) are a recently developed class of SNP system, where a neuron actively requests spikes from the neighboring neurons instead of passively receiving spikes. It is already known that small SNQP systems, with four unbounded neurons, can achieve Turing universality. In this context, ‘unbounded’ means that the number of spikes in a neuron is not capped. This work investigates the dependency of the number of unbounded neurons on the computation capability of SNQP systems. Specifically, we prove that (1) SNQP systems composed entirely of bounded neurons can characterize the family of finite sets of numbers; (2) SNQP systems containing two unbounded neurons are capable of generating the family of semilinear sets of numbers; (3) SNQP systems containing three unbounded neurons are capable of generating nonsemilinear sets of numbers. Moreover, it is obtained in a constructive way that SNQP systems with two unbounded neurons compute the operations of Boolean logic gates, i.e., OR, AND, NOT, and XOR gates. These theoretical findings demonstrate that the number of unbounded neurons is a key parameter that influences the computation capability of SNQP systems.},
  archive      = {J_IJNS},
  author       = {Tingfang Wu and Ferrante Neri and Linqiang Pan},
  doi          = {10.1142/S012906572250037X},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2250037},
  shortjournal = {Int. J. Neural Syst.},
  title        = {On the tuning of the computation capability of spiking neural membrane systems with communication on request},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On spiking neural membrane systems with neuron and synapse
creation. <em>IJNS</em>, <em>32</em>(8), 2250036. (<a
href="https://doi.org/10.1142/S0129065722500368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural membrane systems are models of computation inspired by the natural functioning of the brain using the concepts of neurons and synapses, and represent a way of building computational systems of a biological inspiration. A variant of such a model, allowing to create new neurons and synapses during the computation, has been considered in the literature to attack computationally hard problems, like problems in the class NP. In this work, we investigate the computational properties of this variant, by proposing three solutions to computationally hard problems, by models with different features, and comparing them with those present in the literature. In particular, we first propose a nondeterministic solution for the NP-complete problem 3-SAT, by a model using dynamic organization of synapses. Then, we propose a deterministic solution for the same problem, by a model using neuron division and dissolution rules. Finally, we show that dissolution rules are not strictly necessary (by accepting a certain amount of slowdown in computing time), and that also problems beyond the class NP can be solved by systems with neuron division alone.},
  archive      = {J_IJNS},
  author       = {Marco Gatti and Alberto Leporati and Claudio Zandron},
  doi          = {10.1142/S0129065722500368},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2250036},
  shortjournal = {Int. J. Neural Syst.},
  title        = {On spiking neural membrane systems with neuron and synapse creation},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A layered spiking neural system for classification problems.
<em>IJNS</em>, <em>32</em>(8), 2250023. (<a
href="https://doi.org/10.1142/S012906572250023X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological brains have a natural capacity for resolving certain classification tasks. Studies on biologically plausible spiking neurons, architectures and mechanisms of artificial neural systems that closely match biological observations while giving high classification performance are gaining momentum. Spiking neural P systems (SN P systems) are a class of membrane computing models and third-generation neural networks that are based on the behavior of biological neural cells and have been used in various engineering applications. Furthermore, SN P systems are characterized by a highly flexible structure that enables the design of a machine learning algorithm by mimicking the structure and behavior of biological cells without the over-simplification present in neural networks. Based on this aspect, this paper proposes a novel type of SN P system, namely, layered SN P system (LSN P system), to solve classification problems by supervised learning. The proposed LSN P system consists of a multi-layer network containing multiple weighted fuzzy SN P systems with adaptive weight adjustment rules. The proposed system employs specific ascending dimension techniques and a selection method of output neurons for classification problems. The experimental results obtained using benchmark datasets from the UCI machine learning repository and MNIST dataset demonstrated the feasibility and effectiveness of the proposed LSN P system. More importantly, the proposed LSN P system presents the first SN P system that demonstrates sufficient performance for use in addressing real-world classification problems.},
  archive      = {J_IJNS},
  author       = {Gexiang Zhang and Xihai Zhang and Haina Rong and Prithwineel Paul and Ming Zhu and Ferrante Neri and Yew-Soon Ong},
  doi          = {10.1142/S012906572250023X},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2250023},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A layered spiking neural system for classification problems},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A time series forecasting approach based on nonlinear
spiking neural systems. <em>IJNS</em>, <em>32</em>(8), 2250020. (<a
href="https://doi.org/10.1142/S0129065722500204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear spiking neural P (NSNP) systems are a recently developed theoretical model, which is abstracted by nonlinear spiking mechanism of biological neurons. NSNP systems have a nonlinear structure and the potential to describe nonlinear dynamic systems. Based on NSNP systems, a novel time series forecasting approach is developed in this paper. During the training phase, a time series is first converted to frequency domain by using a redundant wavelet transform, and then according to the frequency data, an NSNP system is automatically constructed and adaptively trained in frequency domain. Then, the well-trained NSNP system can automatically generate sequence data for future time as the prediction results. Eight benchmark time series data sets and two real-life time series data sets are utilized to compare the proposed approach with several state-of-the-art forecasting approaches. The comparison results demonstrate availability and effectiveness of the proposed forecasting approach.},
  archive      = {J_IJNS},
  author       = {Lifan Long and Qian Liu and Hong Peng and Qian Yang and Xiaohui Luo and Jun Wang and Xiaoxiao Song},
  doi          = {10.1142/S0129065722500204},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2250020},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A time series forecasting approach based on nonlinear spiking neural systems},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A neurorobotic embodiment for exploring the dynamical
interactions of a spiking cerebellar model and a robot arm during
vision-based manipulation tasks. <em>IJNS</em>, <em>32</em>(8), 2150028.
(<a href="https://doi.org/10.1142/S0129065721500283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the original goal for developing robots is replacing humans in dangerous and tedious tasks, the final target shall be completely mimicking the human cognitive and motor behavior. Hence, building detailed computational models for the human brain is one of the reasonable ways to attain this. The cerebellum is one of the key players in our neural system to guarantee dexterous manipulation and coordinated movements as concluded from lesions in that region. Studies suggest that it acts as a forward model providing anticipatory corrections for the sensory signals based on observed discrepancies from the reference values. While most studies consider providing the teaching signal as error in joint-space, few studies consider the error in task-space and even fewer consider the spiking nature of the cerebellum on the cellular-level. In this study, a detailed cellular-level forward cerebellar model is developed, including modeling of Golgi and Basket cells which are usually neglected in previous studies. To preserve the biological features of the cerebellum in the developed model, a hyperparameter optimization method tunes the network accordingly. The efficiency and biological plausibility of the proposed cerebellar-based controller is then demonstrated under different robotic manipulation tasks reproducing motor behavior observed in human reaching experiments.},
  archive      = {J_IJNS},
  author       = {Omar Zahra and David Navarro-Alarcon and Silvia Tolu},
  doi          = {10.1142/S0129065721500283},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2150028},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A neurorobotic embodiment for exploring the dynamical interactions of a spiking cerebellar model and a robot arm during vision-based manipulation tasks},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel binary image cryptosystem via spiking neural
networks variants. <em>IJNS</em>, <em>32</em>(8), 2150014. (<a
href="https://doi.org/10.1142/S0129065721500143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the inefficiency of multiple binary images encryption, a parallel binary image encryption framework based on the typical variants of spiking neural networks, spiking neural P (SNP) systems is proposed in this paper. More specifically, the two basic units in the proposed image cryptosystem, the permutation unit and the diffusion unit, are designed through SNP systems with multiple channels and polarizations (SNP-MCP systems), and SNP systems with astrocyte-like control (SNP-ALC systems), respectively. Different from the serial computing of the traditional image permutation/diffusion unit, SNP-MCP-based permutation/SNP-ALC-based diffusion unit can realize parallel computing through the parallel use of rules inside the neurons. Theoretical analysis results confirm the high efficiency of the binary image proposed cryptosystem. Security analysis experiments demonstrate the security of the proposed cryptosystem.},
  archive      = {J_IJNS},
  author       = {Mingzhe Liu and Feixiang Zhao and Xin Jiang and Hong Zhang and Helen Zhou},
  doi          = {10.1142/S0129065721500143},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2150014},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Parallel binary image cryptosystem via spiking neural networks variants},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The task-dependent modular covariance networks unveiled by
multiple-way fusion-based analysis. <em>IJNS</em>, <em>32</em>(7),
2250035. (<a href="https://doi.org/10.1142/S0129065722500356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive processes induced by the specific task are underpinned by intrinsic anatomical structures with functional neural activation patterns. However, current covariance network analysis still pays much attention to brain morphologies or baseline activity due to the lack of an effective method for capturing the structural–functional covarying during tasks. Here, a multimodal covariance network (MCN) construction method was proposed to identify inter-regional covariations of the structural skeleton and functional activities by simultaneous magnetic resonance imaging and electroencephalogram (EEG). Results from two independent cohorts confirmed that MCNs could capture cognition-specific hierarchical modules in joint comprehensive multimodal features well, especially when time-resolved EEG was further integrated. The quantitative evaluation further demonstrates significantly larger modularity of MCN integrating fine-grained features from EEG. The application to the discovery cohort identified prominent modular covarying across the default mode and salience networks at rest, while the visual oddball task was accomplished by synchronous structural–functional cooperation within networks associated with attention control and working memory updating. Strikingly, the results of an external validation cohort showed a different covariant pattern corresponding to decision-specific cognitive modules. Overall, the results suggested that multimodal covariance analysis provides a reliable definition of multistate neural cognitive networks, further discloses modular-specific structural and functional co-variation.},
  archive      = {J_IJNS},
  author       = {Lin Jiang and Fali Li and Baodan Chen and Chanlin Yi and Yueheng Peng and Tao Zhang and Dezhong Yao and Peng Xu},
  doi          = {10.1142/S0129065722500356},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2250035},
  shortjournal = {Int. J. Neural Syst.},
  title        = {The task-dependent modular covariance networks unveiled by multiple-way fusion-based analysis},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A robust 3D-convolutional neural network-based
electroencephalogram decoding model for the intra-individual difference.
<em>IJNS</em>, <em>32</em>(7), 2250034. (<a
href="https://doi.org/10.1142/S0129065722500344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convolutional neural network (CNN) has emerged as a powerful tool for decoding electroencephalogram (EEG), which owns the potential use in the event-related potential-based brain–computer interface (ERP-BCI). However, the intra-individual difference of ERP makes the traditional learning models trained on static EEG data hard to decode when the EEG features vary along the time, which limits the long-time performance of the model. Addressing this problem, this study proposes a three-dimension CNN (3D-CNN)-based model to decode the ERPs dynamically. As input, the EEG is transformed into a brain topographic map stream along time. Then the 3D-CNN applies three-dimension kernels to capture the dynamical characteristic of spatial feature at several time points. Ten subjects participated in a cross-time task for 6 or 12 h. The 3D-CNN shows higher accuracies and shorter computational cost than the baseline models of the 2D-CNN, the long short term memory (LSTM), the back propagation (BP), and the fisher linear discriminant analysis (FLDA) when detecting the ERPs. In addition, four schemes of the 3D-CNN are compared to explore the influence of the structure on the performance. This result demonstrates advanced robustness of the 3D-CNN kernel to the intra-individual EEG difference, helping to launch a more practical EEG decoding model for a long-time use.},
  archive      = {J_IJNS},
  author       = {Mengfan Li and Lingyu Wu and Guizhi Xu and Feng Duan and Chi Zhu},
  doi          = {10.1142/S0129065722500344},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2250034},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A robust 3D-convolutional neural network-based electroencephalogram decoding model for the intra-individual difference},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Epileptic seizure prediction using deep neural networks via
transfer learning and multi-feature fusion. <em>IJNS</em>,
<em>32</em>(7), 2250032. (<a
href="https://doi.org/10.1142/S0129065722500320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is one of the most common neurological diseases, which can seriously affect the patient’s psychological well-being and quality of life. An accurate and reliable seizure prediction system can generate alarm before epileptic seizures to provide patients and their caregivers with sufficient time to take appropriate action. This study proposes an efficient seizure prediction system based on deep learning in order to anticipate the onset of the seizure as early as possible. Handcrafted features extracted based on the prior knowledge and hidden deep features are complementarily fused through the feature fusion module, and then the hybrid features are fed into the multiplicative long short-term memory (MLSTM) to explore the temporal dependency in EEG signals. A one-dimensional channel attention mechanism is implemented to emphasize the more representative information in the multi-channel output of the MLSTM. Finally, a transfer learning strategy is proposed to transfer the weights of the base model trained on the EEG data of all patients to the target patient model, and the latter is then continuously trained using the EEG data of the target patient. The proposed method achieves an average sensitivity of 95.56% and a false positive rate (FPR) of 0.27/h on the SWEC-ETHZ intracranial EEG data. For the more challenging CHB-MIT scalp EEG database, an average sensitivity of 89.47% and a FPR of 0.34/h are obtained. Experimental results demonstrate that the proposed method has good robustness and generalization ability in both intracranial and scalp EEG signals.},
  archive      = {J_IJNS},
  author       = {Zuyi Yu and Laurent Albera and Regine Le Bouquin Jeannes and Amar Kachenoura and Ahmad Karfoul and Chunfeng Yang and Huazhong Shu},
  doi          = {10.1142/S0129065722500320},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2250032},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Epileptic seizure prediction using deep neural networks via transfer learning and multi-feature fusion},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fractal dimension feature as a signature of severity in
disorders of consciousness: An EEG study. <em>IJNS</em>, <em>32</em>(7),
2250031. (<a href="https://doi.org/10.1142/S0129065722500319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An accurate diagnosis of the disorder of consciousness (DOC) is essential for generating tailored treatment programs. Accurately diagnosing patients with a vegetative state (VS) and patients in a minimally conscious state (MCS), however, might be very complicated, reaching a misdiagnosis of approximately 40% if clinical scales are not carefully administered and continuously repeated. To improve diagnostic accuracy for those patients, tools such as electroencephalography (EEG) might be used in the clinical setting. Many linear indices have been developed to improve the diagnosis in DOC patients, such as spectral power in different EEG frequency bands, spectral power ratios between these bands, and the difference between eyes-closed and eyes-open conditions (i.e. alpha-blocking). On the other hand, much less has been explored using nonlinear approaches. Therefore, in this work, we aim to discriminate between MCS and VS groups using a nonlinear method called Higuchi’s Fractal Dimension (HFD) and show that HFD is more sensitive than linear methods based on spectral power methods. For the sake of completeness, HFD has also been tested against another nonlinear approach widely used in EEG research, the Entropy (E). To our knowledge, this is the first time that HFD has been used in EEG data at rest to discriminate between MCS and VS patients. A comparison of Bayes factors found that differences between MCS and VS were 11 times more likely to be detected using HFD than the best performing linear method tested and almost 32 times with respect to the E. Machine learning has also been tested for HFD, reaching an accuracy of 88.6% in discriminating among VS, MCS and healthy controls. Furthermore, correlation analysis showed that HFD was more robust to outliers than spectral power methods, showing a clear positive correlation between the HFD and Coma Recovery Scale-Revised (CRS-R) values. In conclusion, our work suggests that HFD could be used as a sensitive marker to discriminate between MCS and VS patients and help decrease misdiagnosis in clinical practice when combined with commonly used clinical scales.},
  archive      = {J_IJNS},
  author       = {Camillo Porcaro and Marco Marino and Simone Carozzo and Miriam Russo and Maria Ursino and Valentina Ruggiero and Carmela Ragno and Stefania Proto and Paolo Tonin},
  doi          = {10.1142/S0129065722500319},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2250031},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Fractal dimension feature as a signature of severity in disorders of consciousness: An EEG study},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Masked transformer for image anomaly localization.
<em>IJNS</em>, <em>32</em>(7), 2250030. (<a
href="https://doi.org/10.1142/S0129065722500307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image anomaly detection consists in detecting images or image portions that are visually different from the majority of the samples in a dataset. The task is of practical importance for various real-life applications like biomedical image analysis, visual inspection in industrial production, banking, traffic management, etc. Most of the current deep learning approaches rely on image reconstruction: the input image is projected in some latent space and then reconstructed, assuming that the network (mostly trained on normal data) will not be able to reconstruct the anomalous portions. However, this assumption does not always hold. We thus propose a new model based on the Vision Transformer architecture with patch masking: the input image is split in several patches, and each patch is reconstructed only from the surrounding data, thus ignoring the potentially anomalous information contained in the patch itself. We then show that multi-resolution patches and their collective embeddings provide a large improvement in the model’s performance compared to the exclusive use of the traditional square patches. The proposed model has been tested on popular anomaly detection datasets such as MVTec and head CT and achieved good results when compared to other state-of-the-art approaches.},
  archive      = {J_IJNS},
  author       = {Axel De Nardin and Pankaj Mishra and Gian Luca Foresti and Claudio Piciarelli},
  doi          = {10.1142/S0129065722500307},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2250030},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Masked transformer for image anomaly localization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiview feature fusion representation for interictal
epileptiform spikes detection. <em>IJNS</em>, <em>32</em>(7), 2250014.
(<a href="https://doi.org/10.1142/S0129065722500149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interictal epileptiform spikes (IES) of scalp electroencephalogram (EEG) signals have a strong relation with the epileptogenic region. Since IES are highly unlikely to be detected in scalp EEG signals, the primary diagnosis depends heavily on the visual evaluation of IES. However, visual inspection of EEG signals, the standard IES detection procedure is time-consuming, highly subjective, and error-prone. Furthermore, the highly complex, nonlinear, and nonstationary characteristics of EEG signals lead to the incomplete representation of EEG signals in existing computer-aided methods and consequently unsatisfactory detection performance. Therefore, a novel multiview feature fusion representation (MVFFR) method was developed and combined with a robustness classifier to detect EEG signals with/without IES. MVFFR comprises two steps: First, temporal, frequency, temporal-frequency, spatial, and nonlinear domain features are transformed by the IES to express the latent information effectively. Second, the unsupervised infinite feature-selection method determines the most distinct feature fusion representations. Experimental results using a balanced dataset of six patients showed that MVFFR achieved the optimal detection performance (accuracy: 89.27%, sensitivity: 89.01%, specificity: 89.54%, and precision: 89.82%) compared with other feature ranking methods, and the MVFFR-related method were complementary and indispensable. Additionally, in an independent test, MVFFR maintained excellent generalization capacity with a false detection rate per minute of 0.15 on the unbalanced dataset of one patient.},
  archive      = {J_IJNS},
  author       = {Chenchen Cheng and Yuanfeng Zhou and Bo You and Yan Liu and Gao Fei and Liling Yang and Yakang Dai},
  doi          = {10.1142/S0129065722500149},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2250014},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Multiview feature fusion representation for interictal epileptiform spikes detection},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Characterizing fractal genetic variation in the human genome
from the hapmap project. <em>IJNS</em>, <em>32</em>(6), 2250028. (<a
href="https://doi.org/10.1142/S0129065722500289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last decades, the exuberant development of next-generation sequencing has revolutionized gene discovery. These technologies have boosted the mapping of single nucleotide polymorphisms (SNPs) across the human genome, providing a complex universe of heterogeneity characterizing individuals worldwide. Fractal dimension (FD) measures the degree of geometric irregularity, quantifying how “complex” a self-similar natural phenomenon is. We compared two FD algorithms, box-counting dimension (BCD) and Higuchi’s fractal dimension (HFD), to characterize genome-wide patterns of SNPs extracted from the HapMap data set, which includes data from 1184 healthy subjects of eleven populations. In addition, we have used cluster and classification analysis to relate the genetic distances within chromosomes based on FD similarities to the geographical distances among the 11 global populations. We found that HFD outperformed BCD at both grand average clusterization analysis by the cophenetic correlation coefficient, in which the closest value to 1 represents the most accurate clustering solution (0.981 for the HFD and 0.956 for the BCD) and classification (79.0% accuracy, 61.7% sensitivity, and 96.4% specificity for the HFD with respect to 69.1% accuracy, 43.2% sensitivity, and 94.9% specificity for the BCD) of the 11 populations present in the HapMap data set. These results support the evidence that HFD is a reliable measure helpful in representing individual variations within all chromosomes and categorizing individuals and global populations.},
  archive      = {J_IJNS},
  author       = {Alessandro Borri and Antonio Cerasa and Paolo Tonin and Luigi Citrigno and Camillo Porcaro},
  doi          = {10.1142/S0129065722500289},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2250028},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Characterizing fractal genetic variation in the human genome from the hapmap project},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A feed-forward neural network for increasing the
hopfield-network storage capacity. <em>IJNS</em>, <em>32</em>(6),
2250027. (<a href="https://doi.org/10.1142/S0129065722500277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the hippocampal dentate gyrus (DG), pattern separation mainly depends on the concepts of ‘expansion recoding’, meaning random mixing of different DG input channels. However, recent advances in neurophysiology have challenged the theory of pattern separation based on these concepts. In this study, we propose a novel feed-forward neural network, inspired by the structure of the DG and neural oscillatory analysis, to increase the Hopfield-network storage capacity. Unlike the previously published feed-forward neural networks, our bio-inspired neural network is designed to take advantage of both biological structure and functions of the DG. To better understand the computational principles of pattern separation in the DG, we have established a mouse model of environmental enrichment. We obtained a possible computational model of the DG, associated with better pattern separation ability, by using neural oscillatory analysis. Furthermore, we have developed a new algorithm based on Hebbian learning and coupling direction of neural oscillation to train the proposed neural network. The simulation results show that our proposed network significantly expands the storage capacity of Hopfield network, and more effective pattern separation is achieved. The storage capacity rises from 0.13 for the standard Hopfield network to 0.32 using our model when the overlap in patterns is 10%.},
  archive      = {J_IJNS},
  author       = {Shaokai Zhao and Bin Chen and Hui Wang and Zhiyuan Luo and Tao Zhang},
  doi          = {10.1142/S0129065722500277},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2250027},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A feed-forward neural network for increasing the hopfield-network storage capacity},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantitative assessment of electroencephalogram reactivity
in comatose patients on extracorporeal membrane oxygenation.
<em>IJNS</em>, <em>32</em>(6), 2250025. (<a
href="https://doi.org/10.1142/S0129065722500253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective assessment of the brain’s responsiveness in comatose patients on Extracorporeal Membrane Oxygenation (ECMO) support is essential to clinical care, but current approaches are limited by subjective methodology and inter-rater disagreement. Quantitative electroencephalogram (EEG) algorithms could potentially assist clinicians, improving diagnostic accuracy. We developed a quantitative, stimulus-based algorithm to assess EEG reactivity features in comatose patients on ECMO support. Patients underwent a stimulation protocol of increasing intensity (auditory, peripheral, and nostril stimulation). A total of 129 20-s EEG epochs were collected from 24 patients (age 5 6 . 9 ± 1 5 . 1 , 10 females, 14 males) on ECMO support with a Glasgow Coma Scale &lt; 8. EEG reactivity scores ( R -scores) were calculated using aggregated spectral power and permutation entropy for each of five frequency bands ( δ , 𝜃 , α , β , γ ) . Parameter estimation techniques were applied to R -scores to identify properties that replicate the decision process of experienced clinicians performing visual analysis. Spectral power changes from audio stimulation were concentrated in the β band, whereas peripheral stimulation elicited an increase in spectral power across multiple bands, and nostril stimulation changed the entropy of the γ band. The findings of this pilot study on R -score lay a foundation for a future prediction tool with clinical applications.},
  archive      = {J_IJNS},
  author       = {Autumn Williams and Yinuo Zeng and Ziwei Li and Nitish Thakor and Romergryko G. Geocadin and Jay Bronder and Nirma Carballido Martinez and Eva K. Ritzl and Sung-Min Cho},
  doi          = {10.1142/S0129065722500253},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2250025},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Quantitative assessment of electroencephalogram reactivity in comatose patients on extracorporeal membrane oxygenation},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid time-distributed deep neural architecture for
speech emotion recognition. <em>IJNS</em>, <em>32</em>(6), 2250024. (<a
href="https://doi.org/10.1142/S0129065722500241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, speech emotion recognition (SER) has emerged as one of the most active human–machine interaction research areas. Innovative electronic devices, services and applications are increasingly aiming to check the user emotional state either to issue alerts under some predefined conditions or to adapt the system responses to the user emotions. Voice expression is a very rich and noninvasive source of information for emotion assessment. This paper presents a novel SER approach based on that is a hybrid of a time-distributed convolutional neural network (TD-CNN) and a long short-term memory (LSTM) network. Mel-frequency log-power spectrograms (MFLPSs) extracted from audio recordings are parsed by a sliding window that selects the input for the TD-CNN. The TD-CNN transforms the input image data into a sequence of high-level features that are feed to the LSTM, which carries out the overall signal interpretation. In order to reduce overfitting, the MFLPS representation allows innovative image data augmentation techniques that have no immediate equivalent on the original audio signal. Validation of the proposed hybrid architecture achieves an average recognition accuracy of 73.98% on the most widely and hardest publicly distributed database for SER benchmarking. A permutation test confirms that this result is significantly different from random classification ( p &lt; 0 . 0 0 1 ). The proposed architecture outperforms state-of-the-art deep learning models as well as conventional machine learning techniques evaluated on the same database trying to identify the same number of emotions.},
  archive      = {J_IJNS},
  author       = {Javier De Lope and Manuel Graña},
  doi          = {10.1142/S0129065722500241},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2250024},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A hybrid time-distributed deep neural architecture for speech emotion recognition},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Both cross-patient and patient-specific seizure detection
based on self-organizing fuzzy logic. <em>IJNS</em>, <em>32</em>(6),
2250017. (<a href="https://doi.org/10.1142/S0129065722500174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic epilepsy detection is of great significance for the diagnosis and treatment of patients. Most detection methods are based on patient-specific models and have achieved good results. However, in practice, new patients do not have their own previous EEG data and therefore cannot be initially diagnosed. If the EEG data of other patients can be used to achieve cross-patient detection, and cross-patient and patient-specific experiments can be combined at the same time, this method will be more widely used. In this work, an EEG classification model based on a self-organizing fuzzy logic (SOF) classifier is proposed for both cross-patient and patient-specific seizure detection. After preprocessing, the features of the original EEG signal are extracted and sent to the SOF classifier. This classification model is free from predefined parameters or a prior assumption regarding the EEG data generation model and only stores the key meta-parameters in memory. Therefore, it is very suitable for large-scale EEG signals in cross-patient detection. Selecting different granularity and classification distance in two different experiments after post-processing will achieve the best results. Experiments were conducted using a long-term continuous scalp EEG database and the G -mean of cross-patient and patient-specific detection reached 83.35% and 92.04%, respectively. A comparison with other methods shows that there is greater performance and generalizability with this method.},
  archive      = {J_IJNS},
  author       = {Jiazheng Zhou and Li Liu and Yan Leng and Yuying Yang and Bin Gao and Zonghong Jiang and Weiwei Nie and Qi Yuan},
  doi          = {10.1142/S0129065722500174},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2250017},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Both cross-patient and patient-specific seizure detection based on self-organizing fuzzy logic},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Patient-independent seizure detection based on
channel-perturbation convolutional neural network and bidirectional long
short-term memory. <em>IJNS</em>, <em>32</em>(6), 2150051. (<a
href="https://doi.org/10.1142/S0129065721500519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic seizure detection is of great significance for epilepsy diagnosis and alleviating the massive burden caused by manual inspection of long-term EEG. At present, most seizure detection methods are highly patient-dependent and have poor generalization performance. In this study, a novel patient-independent approach is proposed to effectively detect seizure onsets. First, the multi-channel EEG recordings are preprocessed by wavelet decomposition. Then, the Convolutional Neural Network (CNN) with proper depth works as an EEG feature extractor. Next, the obtained features are fed into a Bidirectional Long Short-Term Memory (BiLSTM) network to further capture the temporal variation characteristics. Finally, aiming to reduce the false detection rate (FDR) and improve the sensitivity, the postprocessing, including smoothing and collar, is performed on the outputs of the model. During the training stage, a novel channel perturbation technique is introduced to enhance the model generalization ability. The proposed approach is comprehensively evaluated on the CHB-MIT public scalp EEG database as well as a more challenging SH-SDU scalp EEG database we collected. Segment-based average accuracies of 97.51% and 93.70%, event-based average sensitivities of 86.51% and 89.89%, and average AUC-ROC of 90.82% and 90.75% are yielded on the CHB-MIT database and SH-SDU database, respectively.},
  archive      = {J_IJNS},
  author       = {Guoyang Liu and Lan Tian and Weidong Zhou},
  doi          = {10.1142/S0129065721500519},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2150051},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Patient-independent seizure detection based on channel-perturbation convolutional neural network and bidirectional long short-term memory},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamics of the “cognitive” brain wave p3b at rest for
alzheimer dementia prediction in mild cognitive impairment.
<em>IJNS</em>, <em>32</em>(5), 2250022. (<a
href="https://doi.org/10.1142/S0129065722500228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is the most common cause of dementia that involves a progressive and irrevocable decline in cognitive abilities and social behavior, thus annihilating the patient’s autonomy. The theoretical assumption that disease-modifying drugs are most effective in the early stages hopefully in the prodromal stage called mild cognitive impairment (MCI) urgently pushes toward the identification of robust and individualized markers of cognitive decline to establish an early pharmacological intervention. This requires the combination of well-established neural mechanisms and the development of increasingly sensitive methodologies. Among the neurophysiological markers of attention and cognition, one of the sub-components of the ‘cognitive brain wave’ P300 recordable in an odd-ball paradigm -namely the P3b- is extensively regarded as a sensitive indicator of cognitive performance. Several studies have reliably shown that changes in the amplitude and latency of the P3b are strongly related to cognitive decline and aging both healthy and pathological. Here, we used a P3b spatial filter to enhance the electroencephalographic (EEG) characteristics underlying 175 subjects divided into 135 MCI subjects, 20 elderly controls (EC), and 20 young volunteers (Y). The Y group served to extract the P3b spatial filter from EEG data, which was later applied to the other groups during resting conditions with eyes open and without being asked to perform any task. The group of 135 MCI subjects could be divided into two subgroups at the end of a month follow-up: 75 with stable MCI (MCI-S, not converted to AD), 60 converted to AD (MCI-C). The P3b spatial filter was built by means of a signal processing method called Functional Source Separation (FSS), which increases signal-to-noise ratio by using a weighted sum of all EEG recording channels rather than relying on a single, or a small sub-set, of channels. A clear difference was observed for the P3b dynamics at rest between groups. Moreover, a machine learning approach showed that P3b at rest could correctly distinguish MCI from EC (80.6% accuracy) and MCI-S from MCI-C (74.1% accuracy), with an accuracy as high as 93.8% in discriminating between MCI-C and EC. Finally, a comparison of the Bayes factor revealed that the group differences among MCI-S and MCI-C were 138 times more likely to be detected using the P3b dynamics compared with the best performing single electrode (Pz) approach. In conclusion, we propose that P3b as measured through spatial filters can be safely regarded as a simple and sensitive marker to predict the conversion from an MCI to AD status eventually combined with other non-neurophysiological biomarkers for a more precise definition of dementia having neuropathological Alzheimer characteristics.},
  archive      = {J_IJNS},
  author       = {Camillo Porcaro and Fabrizio Vecchio and Francesca Miraglia and Giancarlo Zito and Paolo Maria Rossini},
  doi          = {10.1142/S0129065722500228},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2250022},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Dynamics of the “Cognitive” brain wave p3b at rest for alzheimer dementia prediction in mild cognitive impairment},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning methods for multi-channel EEG-based emotion
recognition. <em>IJNS</em>, <em>32</em>(5), 2250021. (<a
href="https://doi.org/10.1142/S0129065722500216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, Fourier-based, wavelet-based, and Hilbert-based time–frequency techniques have generated considerable interest in classification studies for emotion recognition in human–computer interface investigations. Empirical mode decomposition (EMD), one of the Hilbert-based time–frequency techniques, has been developed as a tool for adaptive signal processing. Additionally, the multi-variate version strongly influences designing the common oscillation structure of a multi-channel signal by utilizing the common instantaneous concepts of frequency and bandwidth. Additionally, electroencephalographic (EEG) signals are strongly preferred for comprehending emotion recognition perspectives in human–machine interactions. This study aims to herald an emotion detection design via EEG signal decomposition using multi-variate empirical mode decomposition (MEMD). For emotion recognition, the SJTU emotion EEG dataset (SEED) is classified using deep learning methods. Convolutional neural networks (AlexNet, DenseNet-201, ResNet-101, and ResNet50) and AutoKeras architectures are selected for image classification. The proposed framework reaches 99% and 100% classification accuracy when transfer learning methods and the AutoKeras method are used, respectively.},
  archive      = {J_IJNS},
  author       = {Ali Olamat and Pinar Ozel and Sema Atasever},
  doi          = {10.1142/S0129065722500216},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2250021},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Deep learning methods for multi-channel EEG-based emotion recognition},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantifying differences between affine and nonlinear spatial
normalization of FP-CIT spect images. <em>IJNS</em>, <em>32</em>(5),
2250019. (<a href="https://doi.org/10.1142/S0129065722500198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial normalization helps us to compare quantitatively two or more input brain scans. Although using an affine normalization approach preserves the anatomical structures, the neuroimaging field is more common to find works that make use of nonlinear transformations. The main reason is that they facilitate a voxel-wise comparison, not only when studying functional images but also when comparing MRI scans given that they fit better to a reference template. However, the amount of bias introduced by the nonlinear transformations can potentially alter the final outcome of a diagnosis especially when studying functional scans for neurological disorders like Parkinson’s Disease. In this context, we have tried to quantify the bias introduced by the affine and the nonlinear spatial registration of FP-CIT SPECT volumes of healthy control subjects and patients with PD. For that purpose, we calculated the deformation fields of each participant and applied these deformation fields to a 3D-grid. As the space between the edges of small cubes comprising the grid change, we can quantify which parts from the brain have been enlarged, compressed or just remain the same. When the nonlinear approach is applied, scans from PD patients show a region near their striatum very similar in shape to that of healthy subjects. This artificially increases the interclass separation between patients with PD and healthy subjects as the local intensity is decreased in the latter region, and leads machine learning systems to biased results due to the artificial information introduced by these deformations.},
  archive      = {J_IJNS},
  author       = {Diego Castillo-Barnes and Carmen Jimenez-Mesa and Francisco J. Martinez-Murcia and Diego Salas-Gonzalez and Javier Ramírez and Juan M. Górriz},
  doi          = {10.1142/S0129065722500198},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2250019},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Quantifying differences between affine and nonlinear spatial normalization of FP-CIT spect images},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of depth of coma using complexity measures
and nonlinear features of electroencephalogram signals. <em>IJNS</em>,
<em>32</em>(5), 2250018. (<a
href="https://doi.org/10.1142/S0129065722500186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, some electrophysiological analysis methods of consciousness have been proposed. Most of these studies are based on visual interpretation or statistical analysis, and there is hardly any work classifying the level of consciousness in a deep coma. In this study, we perform an analysis of electroencephalography complexity measures by quantifying features efficiency in differentiating patients in different consciousness levels. Several measures of complexity have been proposed to quantify the complexity of signals. Our aim is to lay the foundation of a system that will objectively define the level of consciousness by performing a complexity analysis of Electroencephalogram (EEG) signals. Therefore, a nonlinear analysis of EEG signals obtained with a recording scheme proposed by us from 39 patients with Glasgow Coma Scale (GCS) between 3 and 8 was performed. Various entropy values (approximate entropy, permutation entropy, etc.) obtained from different algorithms, Hjorth parameters, Lempel–Ziv complexity and Kolmogorov complexity values were extracted from the signals as features. The features were analyzed statistically and the success of features in classifying different levels of consciousness was measured by various classifiers. Consequently, levels of consciousness in deep coma (GCS between 3 and 8) were classified with an accuracy of 90.3%. To the authors’ best knowledge, this is the first demonstration of the discriminative nonlinear features extracted from tactile and auditory stimuli EEG signals in distinguishing different GCSs of comatose patients.},
  archive      = {J_IJNS},
  author       = {Çiğdem Gülüzar Altıntop and Fatma Latifoğlu and Aynur Karayol Akın and Adnan Bayram and Murat Çiftçi},
  doi          = {10.1142/S0129065722500186},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2250018},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Classification of depth of coma using complexity measures and nonlinear features of electroencephalogram signals},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Human silhouette and skeleton video synthesis through wi-fi
signals. <em>IJNS</em>, <em>32</em>(5), 2250015. (<a
href="https://doi.org/10.1142/S0129065722500150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing availability of wireless access points (APs) is leading toward human sensing applications based on Wi-Fi signals as support or alternative tools to the widespread visual sensors, where the signals enable to address well-known vision-related problems such as illumination changes or occlusions. Indeed, using image synthesis techniques to translate radio frequencies to the visible spectrum can become essential to obtain otherwise unavailable visual data. This domain-to-domain translation is feasible because both objects and people affect electromagnetic waves, causing radio and optical frequencies variations. In the literature, models capable of inferring radio-to-visual features mappings have gained momentum in the last few years since frequency changes can be observed in the radio domain through the channel state information (CSI) of Wi-Fi APs, enabling signal-based feature extraction, e.g. amplitude. On this account, this paper presents a novel two-branch generative neural network that effectively maps radio data into visual features, following a teacher–student design that exploits a cross-modality supervision strategy. The latter conditions signal-based features in the visual domain to completely replace visual data. Once trained, the proposed method synthesizes human silhouette and skeleton videos using exclusively Wi-Fi signals. The approach is evaluated on publicly available data, where it obtains remarkable results for both silhouette and skeleton videos generation, demonstrating the effectiveness of the proposed cross-modality supervision strategy.},
  archive      = {J_IJNS},
  author       = {Danilo Avola and Marco Cascio and Luigi Cinque and Alessio Fagioli and Gian Luca Foresti},
  doi          = {10.1142/S0129065722500150},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2250015},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Human silhouette and skeleton video synthesis through wi-fi signals},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new multi-resolution approach to EEG brain modeling using
local-global graphs and stochastic petri-nets. <em>IJNS</em>,
<em>32</em>(5), 2250006. (<a
href="https://doi.org/10.1142/S012906572250006X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent modeling of brain activities encompasses the fusion of different modalities. However, fusing brain modalities requires not only the efficient and compatible representation of the signals but also the benefits associated with it. For instance, the combination of the functional characteristics of EEGs with the structural features of functional magnetic resonance imaging contributes to a better interpretation localization of brain activities. In this paper, we consider the EEG signals as parallel 2D string images from which we extract their visual abstract representations of EEG features. This representation can benefit not only the EEG modeling of the signals but also a future fusion with another modality, like fMRI. In particular, the new methodology, called Bar-LG, provides a reduced discretization of the EEG signals into selected minima/maxima in order to be used in a form of tokens for EEG brain activities of interest. A formal context-free language is used to express and represent the extracted tokens for the selected active brain regions. Then, a Generalized Stochastic Petri-Nets (GSPN) model is used for expressing the functional associations and interactions of these EEG signals as 2D image regions. An illustrative EEG example of epileptic seizure is presented to show the Bar-LG methodology’s abstract capabilities.},
  archive      = {J_IJNS},
  author       = {Nikolaos G. Bourbakis and Kostas Michalopoulos and Marios Antonakakis and Michail Zervakis},
  doi          = {10.1142/S012906572250006X},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2250006},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A new multi-resolution approach to EEG brain modeling using local-global graphs and stochastic petri-nets},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uncertainty-guided voxel-level supervised contrastive
learning for semi-supervised medical image segmentation. <em>IJNS</em>,
<em>32</em>(4), 2250016. (<a
href="https://doi.org/10.1142/S0129065722500162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning reduces overfitting and facilitates medical image segmentation by regularizing the learning of limited well-annotated data with the knowledge provided by a large amount of unlabeled data. However, there are many misuses and underutilization of data in conventional semi-supervised methods. On the one hand, the model will deviate from the empirical distribution under the training of numerous unlabeled data. On the other hand, the model treats labeled and unlabeled data differently and does not consider inter-data information. In this paper, a semi-supervised method is proposed to exploit unlabeled data to further narrow the gap between the semi-supervised model and its fully-supervised counterpart. Specifically, the architecture of the proposed method is based on the mean-teacher framework, and the uncertainty estimation module is improved to impose constraints of consistency and guide the selection of feature representation vectors. Notably, a voxel-level supervised contrastive learning module is devised to establish a contrastive relationship between feature representation vectors, whether from labeled or unlabeled data. The supervised manner ensures that the network learns the correct knowledge, and the dense contrastive relationship further extracts information from unlabeled data. The above overcomes data misuse and underutilization in semi-supervised frameworks. Moreover, it favors the feature representation with intra-class compactness and inter-class separability and gains extra performance. Extensive experimental results on the left atrium dataset from Atrial Segmentation Challenge demonstrate that the proposed method has superior performance over the state-of-the-art methods.},
  archive      = {J_IJNS},
  author       = {Yu Hua and Xin Shu and Zizhou Wang and Lei Zhang},
  doi          = {10.1142/S0129065722500162},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2250016},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Uncertainty-guided voxel-level supervised contrastive learning for semi-supervised medical image segmentation},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of low and high schizotypy levels via
evaluation of brain connectivity. <em>IJNS</em>, <em>32</em>(4),
2250013. (<a href="https://doi.org/10.1142/S0129065722500137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Schizotypy is a latent cluster of personality traits that denote a vulnerability for schizophrenia or a type of spectrum disorder. The aim of the study is to investigate parametric effective brain connectivity features for classifying high versus low schizotypy (LS) status. Electroencephalography (EEG) signals are recorded from 13 high schizotypy (HS) and 11 LS participants during an emotional auditory odd-ball task. The brain connectivity signals for machine learning are taken after the settlement of event-related potentials. A multivariate autoregressive (MVAR)-based connectivity measure is estimated from the EEG signals using the directed transfer functions (DTFs) method. The values of DTF power in five standard frequency bands are used as features. The support vector machines (SVMs) revealed significant differences between HS and LS. The accuracy, specificity, and sensitivity of the results using SVM are as high as 89.21%, 90.3%, and 88.2%, respectively. Our results demonstrate that the effective brain connectivity in prefrontal/parietal and prefrontal/frontal brain regions considerably changes according to schizotypal status. These findings prove that the brain connectivity indices offer valuable biomarkers for detecting schizotypal personality. Further monitoring of the changes in DTF following the diagnosis of schizotypy may lead to the early identification of schizophrenia and other spectrum disorders.},
  archive      = {J_IJNS},
  author       = {Ahmad Zandbagleh and Sattar Mirzakuchaki and Mohammad Reza Daliri and Preethi Premkumar and Saeid Sanei},
  doi          = {10.1142/S0129065722500137},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2250013},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Classification of low and high schizotypy levels via evaluation of brain connectivity},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis of fMRI signals from working memory tasks and
resting-state of brain: Neutrosophic-entropy-based clustering algorithm.
<em>IJNS</em>, <em>32</em>(4), 2250012. (<a
href="https://doi.org/10.1142/S0129065722500125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study applies a neutrosophic-entropy-based clustering algorithm (NEBCA) to analyze the fMRI signals. We consider the data obtained from four different working memory tasks and the brain’s resting state for the experimental purpose. Three non-overlapping clusters of data related to temporal brain activity are determined and statistically analyzed. Moreover, we used the Uniform Manifold Approximation and Projection (UMAP) method to reduce system dimensionality and present the effectiveness of NEBCA. The results show that using NEBCA, we are able to distinguish between different working memory tasks and resting-state and identify subtle differences in the related activity of brain regions. By analyzing the statistical properties of the entropy inside the clusters, the various regions of interest (ROIs), according to Automated Anatomical Labeling (AAL) atlas crucial for clustering procedure, are determined. The inferior occipital gyrus is established as an important brain region in distinguishing the resting state from the tasks. Moreover, the inferior occipital gyrus and superior parietal lobule are identified as necessary to correct the data discrimination related to the different memory tasks. We verified the statistical significance of the results through the two-sample t -test and analysis of surrogates performed by randomization of the cluster elements. The presented methodology is also appropriate to determine the influence of time of day on brain activity patterns. The differences between working memory tasks and resting-state in the morning are related to a lower index of small-worldness and sleep inertia in the first hours after waking. We also compared the performance of NEBCA to two existing algorithms, KMCA and FKMCA. We showed the advantage of the NEBCA over these algorithms that could not effectively accumulate fMRI signals with higher variability.},
  archive      = {J_IJNS},
  author       = {Pritpal Singh and Marcin Wa̧torek and Anna Ceglarek and Magdalena Fąfrowicz and Koryna Lewandowska and Tadeusz Marek and Barbara Sikora-Wachowicz and Paweł Oświȩcimka},
  doi          = {10.1142/S0129065722500125},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2250012},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Analysis of fMRI signals from working memory tasks and resting-state of brain: Neutrosophic-entropy-based clustering algorithm},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An experimental study of neural approaches to multi-hop
inference in question answering. <em>IJNS</em>, <em>32</em>(4), 2250011.
(<a href="https://doi.org/10.1142/S0129065722500113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question answering aims at computing the answer to a question given a context with facts. Many proposals focus on questions whose answer is explicit in the context; lately, there has been an increasing interest in questions whose answer is not explicit and requires multi-hop inference to be computed. Our analysis of the literature reveals that there is a seminal proposal with increasingly complex follow-ups. Unfortunately, they were presented without an extensive study of their hyper-parameters, the experimental studies focused exclusively on English, and no statistical analysis to sustain the conclusions was ever performed. In this paper, we report on our experience devising a very simple neural approach to address the problem, on our extensive grid search over the space of hyper-parameters, on the results attained with English, Spanish, Hindi, and Portuguese, and sustain our conclusions with statistically sound analyses. Our findings prove that it is possible to beat many of the proposals in the literature with a very simple approach that was likely overlooked due to the difficulty to perform an extensive grid search, that the language does not have a statistically significant impact on the results, and that the empirical differences found among some existing proposals are not statistically significant.},
  archive      = {J_IJNS},
  author       = {Patricia Jiménez and Rafael Corchuelo},
  doi          = {10.1142/S0129065722500113},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2250011},
  shortjournal = {Int. J. Neural Syst.},
  title        = {An experimental study of neural approaches to multi-hop inference in question answering},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Brain network organization following post-stroke
neurorehabilitation. <em>IJNS</em>, <em>32</em>(4), 2250009. (<a
href="https://doi.org/10.1142/S0129065722500095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain network analysis can offer useful information to guide the rehabilitation of post-stroke patients. We applied functional network connection models based on multiplex-multilayer network analysis (MMN) to explore functional network connectivity changes induced by robot-aided gait training (RAGT) using the Ekso, a wearable exoskeleton, and compared it to conventional overground gait training (COGT) in chronic stroke patients. We extracted the coreness of individual nodes at multiple locations in the brain from EEG recordings obtained before and after gait training in a resting state. We found that patients provided with RAGT achieved a greater motor function recovery than those receiving COGT. This difference in clinical outcome was paralleled by greater changes in connectivity patterns among different brain areas central to motor programming and execution, as well as a recruitment of other areas beyond the sensorimotor cortices and at multiple frequency ranges, contemporarily. The magnitude of these changes correlated with motor function recovery chances. Our data suggest that the use of RAGT as an add-on treatment to COGT may provide post-stroke patients with a greater modification of the functional brain network impairment following a stroke. This might have potential clinical implications if confirmed in large clinical trials.},
  archive      = {J_IJNS},
  author       = {Antonino Naro and Loris Pignolo and Rocco Salvatore Calabrò},
  doi          = {10.1142/S0129065722500095},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2250009},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Brain network organization following post-stroke neurorehabilitation},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A spatio-temporal method for extracting gamma-band features
to enhance classification in a rapid serial visual presentation task.
<em>IJNS</em>, <em>32</em>(3), 2250010. (<a
href="https://doi.org/10.1142/S0129065722500101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid serial visual presentation (RSVP) is a type of electroencephalogram (EEG) pattern commonly used for target recognition. Besides delta- and theta-band responses already used for classification, RSVP task also evokes gamma-band responses having low amplitude and large individual difference. This paper proposes a filter bank spatio-temporal component analysis (FBSCA) method, extracting spatio-temporal features of the gamma-band responses for the first time, to enhance the RSVP classification performance. Considering the individual difference in time latency and responsive frequency, the proposed FBSCA method decomposes the gamma-band EEG data into sub-components in different time–frequency-space domains and seeks the weight coefficients to optimize the combinations of electrodes, common spatial pattern (CSP) components, time windows and frequency bands. Two state-of-the-art methods, i.e. hierarchical discriminant principal component analysis (HDPCA) and discriminative canonical pattern matching (DCPM), were used for comparison. The performance was evaluated in 1 0 × 1 0 cross validations using a public dataset. Study results showed that the FBSCA method outperformed the other methods regardless of number of training trials. These results suggest that the proposed FBSCA method can enhance the RSVP classification.},
  archive      = {J_IJNS},
  author       = {Ping Xie and Shencai Hao and Jing Zhao and Zhenhu Liang and Xiaoli Li},
  doi          = {10.1142/S0129065722500101},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2250010},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A spatio-temporal method for extracting gamma-band features to enhance classification in a rapid serial visual presentation task},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Supported diagnosis of attention deficit and hyperactivity
disorder from EEG based on interpretable kernels for hidden markov
models. <em>IJNS</em>, <em>32</em>(3), 2250008. (<a
href="https://doi.org/10.1142/S0129065722500083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a neurodevelopmental pathology, Attention Deficit Hyperactivity Disorder (ADHD) mainly arises during childhood. Persistent patterns of generalized inattention, impulsivity, or hyperactivity characterize ADHD that may persist into adulthood. The conventional diagnosis relies on clinical observational processes yielding high rates of overdiagnosis due to varying interpretations among specialists or missing information. Although several studies have designed objective behavioral features to overcome such an issue, they lack significance. Despite electroencephalography (EEG) analyses extracting alternative biomarkers using signal processing techniques, the nonlinearity and nonstationarity of EEG signals restrain performance and generalization of hand-crafted features. This work proposes a methodology to support ADHD diagnosis by characterizing EEG signals from hidden Markov models (HMM), classifying subjects based on similarity measures for probability functions, and spatially interpreting the results using graphic embeddings of stochastic dynamic models. The methodology learns a single HMM for EEG signal from each patient, so favoring the inter-subject variability. Then, the Probability Product Kernel, specifically developed for assessing the similarity between HMMs, fed a support vector machine that classifies subjects according to their stochastic dynamics. Lastly, the kernel variant of Principal Component Analysis provided a means to visualize the EEG transitions in a two-dimensional space, evidencing dynamic differences between ADHD and Healthy Control children. From the electrophysiological perspective, we recorded EEG under the Stop Signal Task modified with reward levels, which considers cognitive features of interest as insufficient motivational circuits recruitment. The methodology compares the supported diagnosis in two EEG channel setups (whole channel set and channels of interest in frontocentral area) and four frequency bands (Theta, Alpha, Beta rhythms, and a wideband). Results evidence an accuracy rate of 97.0% in the Beta band and in the channels where previous works found error-related negativity events. Such accuracy rate strongly supports the dual pathway hypothesis and motivational deficit concerning the pathophysiology of ADHD. It also demonstrates the utility of joining inhibitory and motivational paradigms with dynamic EEG analysis into a noninvasive and affordable diagnostic tool for ADHD patients.},
  archive      = {J_IJNS},
  author       = {M. C. Maya-Piedrahita and P. M. Herrera-Gomez and L. Berrío-Mesa and D. A. Cárdenas-Peña and A. A. Orozco-Gutierrez},
  doi          = {10.1142/S0129065722500083},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2250008},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Supported diagnosis of attention deficit and hyperactivity disorder from EEG based on interpretable kernels for hidden markov models},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tiled sparse coding in eigenspaces for image classification.
<em>IJNS</em>, <em>32</em>(3), 2250007. (<a
href="https://doi.org/10.1142/S0129065722500071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automation in the diagnosis of medical images is currently a challenging task. The use of Computer Aided Diagnosis (CAD) systems can be a powerful tool for clinicians, especially in situations when hospitals are overflowed. These tools are usually based on artificial intelligence (AI), a field that has been recently revolutionized by deep learning approaches. These alternatives usually obtain a large performance based on complex solutions, leading to a high computational cost and the need of having large databases. In this work, we propose a classification framework based on sparse coding. Images are first partitioned into different tiles, and a dictionary is built after applying PCA to these tiles. The original signals are then transformed as a linear combination of the elements of the dictionary. Then, they are reconstructed by iteratively deactivating the elements associated with each component. Classification is finally performed employing as features the subsequent reconstruction errors. Performance is evaluated in a real context where distinguishing between four different pathologies: control versus bacterial pneumonia versus viral pneumonia versus COVID-19. Our system differentiates between pneumonia patients and controls with an accuracy of 97.74%, whereas in the 4-class context the accuracy is 86.73%. The excellent results and the pioneering use of sparse coding in this scenario evidence that our proposal can assist clinicians when their workload is high.},
  archive      = {J_IJNS},
  author       = {Juan E Arco and Andrés Ortiz and Javier Ramírez and Yu-Dong Zhang and Juan M Górriz},
  doi          = {10.1142/S0129065722500071},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2250007},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Tiled sparse coding in eigenspaces for image classification},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). From intricacy to conciseness: A progressive transfer
strategy for EEG-based cross-subject emotion recognition. <em>IJNS</em>,
<em>32</em>(3), 2250005. (<a
href="https://doi.org/10.1142/S0129065722500058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion plays a significant role in human daily activities, and it can be effectively recognized from EEG signals. However, individual variability limits the generalization of emotion classifiers across subjects. Domain adaptation (DA) is a reliable method to solve the issue. Due to the nonstationarity of EEG, the inferior-quality source domain data bring negative transfer in DA procedures. To solve this problem, an auto-augmentation joint distribution adaptation (AA-JDA) method and a burden-lightened and source-preferred JDA (BLSP-JDA) approach are proposed in this paper. The methods are based on a novel transfer idea, learning the specific knowledge of the target domain from the samples that are appropriate for transfer, which reduces the difficulty of transfer between two domains. On multiple emotion databases, our model shows state-of-the-art performance.},
  archive      = {J_IJNS},
  author       = {Ziliang Cai and Lingyue Wang and Miaomiao Guo and Guizhi Xu and Lei Guo and Ying Li},
  doi          = {10.1142/S0129065722500058},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2250005},
  shortjournal = {Int. J. Neural Syst.},
  title        = {From intricacy to conciseness: A progressive transfer strategy for EEG-based cross-subject emotion recognition},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A vector quantization-based spike compression approach
dedicated to multichannel neural recording microsystems. <em>IJNS</em>,
<em>32</em>(3), 2250001. (<a
href="https://doi.org/10.1142/S0129065722500010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implantable high-density multichannel neural recording microsystems provide simultaneous recording of brain activities. Wireless transmission of the entire recorded data causes high bandwidth usage, which is not tolerable for implantable applications. As a result, a hardware-friendly compression module is required to reduce the amount of data before it is transmitted. This paper presents a novel compression approach that utilizes a spike extractor and a vector quantization (VQ)-based spike compressor. In this approach, extracted spikes are vector quantized using an unsupervised learning process providing a high spike compression ratio (CR) of 10–80. A combination of extracting and compressing neural spikes results in a significant data reduction as well as preserving the spike waveshapes. The compression performance of the proposed approach was evaluated under variant conditions. We also developed new architectures such that the hardware blocks of our approach can be implemented more efficiently. The compression module was implemented in a 180-nm standard CMOS process achieving a SNDR of 14.49 dB and a classification accuracy (CA) of 99.62% at a CR of 20, while consuming 4 μ W power and 0.16 mm 2 chip area per channel.},
  archive      = {J_IJNS},
  author       = {Nazanin Ahmadi-Dastgerdi and Hossein Hosseini-Nejad and Hadi Amiri and Afshin Shoeibi and Juan Manuel Gorriz},
  doi          = {10.1142/S0129065722500010},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2250001},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A vector quantization-based spike compression approach dedicated to multichannel neural recording microsystems},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Wavelet-based biphase analysis of brain rhythms in automated
wake–sleep classification. <em>IJNS</em>, <em>32</em>(2), 2250004. (<a
href="https://doi.org/10.1142/S0129065722500046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many studies in the field of sleep have focused on connectivity and coherence. Still, the nonstationary nature of electroencephalography (EEG) makes many of the previous methods unsuitable for automatic sleep detection. Time-frequency representations and high-order spectra are applied to nonstationary signal analysis and nonlinearity investigation, respectively. Therefore, combining wavelet and bispectrum, wavelet-based bi-phase (Wbiph) was proposed and used as a novel feature for sleep–wake classification. The results of the statistical analysis with emphasis on the importance of the gamma rhythm in sleep detection show that the Wbiph is more potent than coherence in the wake–sleep classification. The Wbiph has not been used in sleep studies before. However, the results and inherent advantages, such as the use of wavelet and bispectrum in its definition, suggest it as an excellent alternative to coherence. In the next part of this paper, a convolutional neural network (CNN) classifier was applied for the sleep–wake classification by Wbiph. The classification accuracy was 97.17% in nonLOSO and 95.48% in LOSO cross-validation, which is the best among previous studies on sleep–wake classification.},
  archive      = {J_IJNS},
  author       = {Ehsan Mohammadi and Bahador Makkiabadi and Mohammad Bagher Shamsollahi and Parham Reisi and Saeed Kermani},
  doi          = {10.1142/S0129065722500046},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2250004},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Wavelet-based biphase analysis of brain rhythms in automated Wake–Sleep classification},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decoding color visual working memory from EEG signals using
graph convolutional neural networks. <em>IJNS</em>, <em>32</em>(2),
2250003. (<a href="https://doi.org/10.1142/S0129065722500034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Color has an important role in object recognition and visual working memory (VWM). Decoding color VWM in the human brain is helpful to understand the mechanism of visual cognitive process and evaluate memory ability. Recently, several studies showed that color could be decoded from scalp electroencephalogram (EEG) signals during the encoding stage of VWM, which process visible information with strong neural coding. Whether color could be decoded from other VWM processing stages, especially the maintaining stage which processes invisible information, is still unknown. Here, we constructed an EEG color graph convolutional network model (ECo-GCN) to decode colors during different VWM stages. Based on graph convolutional networks, ECo-GCN considers the graph structure of EEG signals and may be more efficient in color decoding. We found that (1) decoding accuracies for colors during the encoding, early, and late maintaining stages were 81.58%, 79.36%, and 77.06%, respectively, exceeding those during the pre-stimuli stage (67.34%), and (2) the decoding accuracy during maintaining stage could predict participants’ memory performance. The results suggest that EEG signals during the maintaining stage may be more sensitive than behavioral measurement to predict the VWM performance of human, and ECo-GCN provides an effective approach to explore human cognitive function.},
  archive      = {J_IJNS},
  author       = {Xiaowei Che and Yuanjie Zheng and Xin Chen and Sutao Song and Shouxin Li},
  doi          = {10.1142/S0129065722500034},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2250003},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Decoding color visual working memory from EEG signals using graph convolutional neural networks},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Kuramoto model-based analysis reveals oxytocin effects on
brain network dynamics. <em>IJNS</em>, <em>32</em>(2), 2250002. (<a
href="https://doi.org/10.1142/S0129065722500022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The oxytocin effects on large-scale brain networks such as Default Mode Network (DMN) and Frontoparietal Network (FPN) have been largely studied using fMRI data. However, these studies are mainly based on the statistical correlation or Bayesian causality inference, lacking interpretability at the physical and neuroscience level. Here, we propose a physics-based framework of the Kuramoto model to investigate oxytocin effects on the phase dynamic neural coupling in DMN and FPN. Testing on fMRI data of 59 participants administrated with either oxytocin or placebo, we demonstrate that oxytocin changes the topology of brain communities in DMN and FPN, leading to higher synchronization in the FPN and lower synchronization in the DMN, as well as a higher variance of the coupling strength within the DMN and more flexible coupling patterns at group level. These results together indicate that oxytocin may increase the ability to overcome the corresponding internal oscillation dispersion and support the flexibility in neural synchrony in various social contexts, providing new evidence for explaining the oxytocin modulated social behaviors. Our proposed Kuramoto model-based framework can be a potential tool in network neuroscience and offers physical and neural insights into phase dynamics of the brain.},
  archive      = {J_IJNS},
  author       = {Shuhan Zheng and Zhichao Liang and Youzhi Qu and Qingyuan Wu and Haiyan Wu and Quanying Liu},
  doi          = {10.1142/S0129065722500022},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2250002},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Kuramoto model-based analysis reveals oxytocin effects on brain network dynamics},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Epileptic seizure prediction using deep transformer model.
<em>IJNS</em>, <em>32</em>(2), 2150058. (<a
href="https://doi.org/10.1142/S0129065721500581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electroencephalogram (EEG) is the most promising and efficient technique to study epilepsy and record all the electrical activity going in our brain. Automated screening of epilepsy through data-driven algorithms reduces the manual workload of doctors to diagnose epilepsy. New algorithms are biased either towards signal processing or deep learning, which holds subjective advantages and disadvantages. The proposed pipeline is an end-to-end automated seizure prediction framework with a Fourier transform feature extraction and deep learning-based transformer model, a blend of signal processing and deep learning — this imbibes the potential features to automatically identify the attentive regions in EEG signals for effective screening. The proposed pipeline has demonstrated superior performance on the benchmark dataset with average sensitivity and false-positive rate per hour (FPR/h) as 98.46%, 94.83% and 0.12439, 0, respectively. The proposed work shows great results on the benchmark datasets and a big potential for clinics as a support system with medical experts monitoring the patients.},
  archive      = {J_IJNS},
  author       = {Abhijeet Bhattacharya and Tanmay Baweja and S. P. K. Karri},
  doi          = {10.1142/S0129065721500581},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2150058},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Epileptic seizure prediction using deep transformer model},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). One-dimensional convolutional neural networks combined with
channel selection strategy for seizure prediction using long-term
intracranial EEG. <em>IJNS</em>, <em>32</em>(2), 2150048. (<a
href="https://doi.org/10.1142/S0129065721500489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seizure prediction using intracranial electroencephalogram (iEEG) has attracted an increasing attention during recent years. iEEG signals are commonly recorded in the form of multiple channels. Many previous studies generally used the iEEG signals of all channels to predict seizures, ignoring the consideration of channel selection. In this study, a method of one-dimensional convolutional neural networks (1D-CNN) combined with channel selection strategy was proposed for seizure prediction. First, we used 30-s sliding windows to segment the raw iEEG signals. Then, the 30-s iEEG segments, which were in three channel forms (single channel, channels only from seizure onset or free zone and all channels from seizure onset and free zones), were used as the inputs of 1D-CNN for classification, and the patient-specific model was trained. Finally, the channel form with the best classification was selected for each patient. The proposed method was evaluated on the Freiburg Hospital iEEG dataset. In the situation of seizure occurrence period (SOP) of 30 min and seizure prediction horizon (SPH) of 5 min, 98.60 % accuracy, 98.85 % sensitivity and 0.01/h false prediction rate (FPR) were achieved. In the situation of SOP of 60 min and SPH of 5 min, 98.32 % accuracy, 98.48 % sensitivity and 0.01/h FPR were attained. Compared with the many existing methods using the same iEEG dataset, our method showed a better performance.},
  archive      = {J_IJNS},
  author       = {Xiaoshuang Wang and Guanghui Zhang and Ying Wang and Lin Yang and Zhanhua Liang and Fengyu Cong},
  doi          = {10.1142/S0129065721500489},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2150048},
  shortjournal = {Int. J. Neural Syst.},
  title        = {One-dimensional convolutional neural networks combined with channel selection strategy for seizure prediction using long-term intracranial EEG},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Synchronization analysis in epileptic EEG signals via state
transfer networks based on visibility graph technique. <em>IJNS</em>,
<em>32</em>(2), 2150041. (<a
href="https://doi.org/10.1142/S0129065721500416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a persistent and recurring neurological condition in a community of brain neurons that results from sudden and abnormal electrical discharges. This paper introduces a new form of assessment and interpretation of the changes in electroencephalography (EEG) recordings from different brain regions in epilepsy disorders based on graph analysis and statistical rescale range analysis. In this study, two different states of epilepsy EEG data (preictal and ictal phases), obtained from 17 subjects (18 channels each), were analyzed by a new method called state transfer network (STN). The analysis performed by STN yields a network metric called motifs, which are averaged over all channels and subjects in terms of their persistence level in the network. The results showed an increase of overall motif persistence during the ictal over the preictal phase, reflecting the synchronization increase during the seizure phase (ictal). An evaluation of intermotif cross-correlation indicated a definite manifestation of such synchronization. Moreover, these findings are compared with several other well-known methods such as synchronization likelihood (SL), visibility graph similarity (VGS), and global field synchronization (GFS). It is hinted that the STN method is in good agreement with approaches in the literature and more efficient. The most significant contribution of this research is introducing a novel nonlinear analysis technique of generalized synchronization. The STN method can be used for classifying epileptic seizures based on the synchronization changes between multichannel data.},
  archive      = {J_IJNS},
  author       = {Ali Olamat and Pinar Ozel and Aydin Akan},
  doi          = {10.1142/S0129065721500416},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2150041},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Synchronization analysis in epileptic EEG signals via state transfer networks based on visibility graph technique},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection of movement intention in EEG-based brain-computer
interfaces using fourier-based synchrosqueezing transform.
<em>IJNS</em>, <em>32</em>(1), 2150059. (<a
href="https://doi.org/10.1142/S0129065721500593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patients with motor impairments need caregivers’ help to initiate the operation of brain-computer interfaces (BCI). This study aims to identify and characterize movement intention using multichannel electroencephalography (EEG) signals as a means to initiate BCI systems without extra accessories/methodologies. We propose to discriminate the resting and motor imagery (MI) states with high accuracy using Fourier-based synchrosqueezing transform (FSST) as a feature extractor. FSST has been investigated and compared with other popular approaches in 28 healthy subjects for a total of 6657 trials. The accuracy and f-measure values were obtained as 99.8% and 0.99, respectively, when FSST was used as the feature extractor and singular value decomposition (SVD) as the feature selection method and support vector machines as the classifier. Moreover, this study investigated the use of data that contain certain amount of noise without any preprocessing in addition to the clean counterparts. Furthermore, the statistical analysis of EEG channels with the best discrimination (of resting and MI states) characteristics demonstrated that F4-Fz-C3-Cz-C4-Pz channels and several statistical features had statistical significance levels, p , less than 0.05. This study showed that the preparation of the movement can be detected in real-time employing FSST-SVD combination and several channels with minimal pre-processing effort.},
  archive      = {J_IJNS},
  author       = {Nedime Karakullukcu and Bülent Yilmaz},
  doi          = {10.1142/S0129065721500593},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2150059},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Detection of movement intention in EEG-based brain-computer interfaces using fourier-based synchrosqueezing transform},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Brain networks modulation in young and old subjects during
transcranial direct current stimulation applied on prefrontal and
parietal cortex. <em>IJNS</em>, <em>32</em>(1), 2150056. (<a
href="https://doi.org/10.1142/S0129065721500568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evidence indicates that the transcranial direct current stimulation (tDCS) has the potential to transiently modulate cognitive function, including age-related changes in brain performance. Only a small number of studies have explored the interaction between the stimulation sites on the scalp, task performance, and brain network connectivity within the frame of physiological aging. We aimed to evaluate the spread of brain activation in both young and older adults in response to anodal tDCS applied to two different scalp stimulation sites: Prefrontal cortex (PFC) and posterior parietal cortex (PPC). EEG data were recorded during tDCS stimulation and evaluated using the Small World (SW) index as a graph theory metric. Before and after tDCS, participants performed a behavioral task; a performance accuracy index was computed and correlated with the SW index. Results showed that the SW index increased during tDCS of the PPC compared to the PFC at higher EEG frequencies only in young participants. tDCS at the PPC site did not exert significant effects on the performance, while tDCS at the PFC site appeared to influence task reaction times in the same direction in both young and older participants. In conclusion, studies using tDCS to modulate functional connectivity and influence behavior can help identify suitable protocols for the aging brain.},
  archive      = {J_IJNS},
  author       = {Francesca Miraglia and Fabrizio Vecchio and Maria Concetta Pellicciari and Jesus Cespon and Paolo Maria Rossini},
  doi          = {10.1142/S0129065721500568},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2150056},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Brain networks modulation in young and old subjects during transcranial direct current stimulation applied on prefrontal and parietal cortex},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep multimodal neural network based on data-feature fusion
for patient-specific quality assurance. <em>IJNS</em>, <em>32</em>(1),
2150055. (<a href="https://doi.org/10.1142/S0129065721500556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patient-specific quality assurance (QA) for Volumetric Modulated Arc Therapy (VMAT) plans is routinely performed in the clinical. However, it is labor-intensive and time-consuming for medical physicists. QA prediction models can address these shortcomings and improve efficiency. Current approaches mainly focus on single cancer and single modality data. They are not applicable to clinical practice. To assess the accuracy of QA results for VMAT plans, this paper presents a new model that learns complementary features from the multi-modal data to predict the gamma passing rate (GPR). According to the characteristics of VMAT plans, a feature-data fusion approach is designed to fuse the features of imaging and non-imaging information in the model. In this study, 690 VMAT plans are collected encompassing more than ten diseases. The model can accurately predict the most VMAT plans at all three gamma criteria: 2%/2 mm, 3%/2 mm and 3%/3 mm. The mean absolute error between the predicted and measured GPR is 2.17%, 1.16% and 0.71%, respectively. The maximum deviation between the predicted and measured GPR is 3.46%, 4.6%, 8.56%, respectively. The proposed model is effective, and the features of the two modalities significantly influence QA results.},
  archive      = {J_IJNS},
  author       = {Ting Hu and Lizhang Xie and Lei Zhang and Guangjun Li and Zhang Yi},
  doi          = {10.1142/S0129065721500556},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2150055},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Deep multimodal neural network based on data-feature fusion for patient-specific quality assurance},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). VPNET: Variable projection networks. <em>IJNS</em>,
<em>32</em>(1), 2150054. (<a
href="https://doi.org/10.1142/S0129065721500544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce VPNet, a novel model-driven neural network architecture based on variable projection (VP). Applying VP operators to neural networks results in learnable features, interpretable parameters, and compact network structures. This paper discusses the motivation and mathematical background of VPNet and presents experiments. The VPNet approach was evaluated in the context of signal processing, where we classified a synthetic dataset and real electrocardiogram (ECG) signals. Compared to fully connected and one-dimensional convolutional networks, VPNet offers fast learning ability and good accuracy at a low computational cost of both training and inference. Based on these advantages and the promising results obtained, we anticipate a profound impact on the broader field of signal processing, in particular on classification, regression and clustering problems.},
  archive      = {J_IJNS},
  author       = {Péter Kovács and Gergő Bognár and Christian Huber and Mario Huemer},
  doi          = {10.1142/S0129065721500544},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2150054},
  shortjournal = {Int. J. Neural Syst.},
  title        = {VPNET: Variable projection networks},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Control of transcranial direct current stimulation duration
by assessing functional connectivity of near-infrared spectroscopy
signals. <em>IJNS</em>, <em>32</em>(1), 2150050. (<a
href="https://doi.org/10.1142/S0129065721500507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transcranial direct current stimulation (tDCS) has been shown to create neuroplasticity in healthy and diseased populations. The control of stimulation duration by providing real-time brain state feedback using neuroimaging is a topic of great interest. This study presents the feasibility of a closed-loop modulation for the targeted functional network in the prefrontal cortex. We hypothesize that we cannot improve the brain state further after reaching a specific state during a stimulation therapy session. A high-definition tDCS of 1 mA arranged in a ring configuration was applied at the targeted right prefrontal cortex of 15 healthy male subjects for 10 min. Functional near-infrared spectroscopy was used to monitor hemoglobin chromophores during the stimulation period continuously. The correlation matrices obtained from filtered oxyhemoglobin were binarized to form subnetworks of short- and long-range connections. The connectivity in all subnetworks was analyzed individually using a new quantification measure of connectivity percentage based on the correlation matrix. The short-range network in the stimulated hemisphere showed increased connectivity in the initial stimulation phase. However, the increase in connection density reduced significantly after 6 min of stimulation. The short-range network of the left hemisphere and the long-range network gradually increased throughout the stimulation period. The connectivity percentage measure showed a similar response with network theory parameters. The connectivity percentage and network theory metrics represent the brain state during the stimulation therapy. The results from the network theory metrics, including degree centrality, efficiency, and connection density, support our hypothesis and provide a guideline for feedback on the brain state. The proposed neuro-feedback scheme is feasible to control the stimulation duration to avoid overdosage.},
  archive      = {J_IJNS},
  author       = {M. Atif Yaqub and Keum-Shik Hong and Amad Zafar and Chang-Seok Kim},
  doi          = {10.1142/S0129065721500507},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2150050},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Control of transcranial direct current stimulation duration by assessing functional connectivity of near-infrared spectroscopy signals},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection of trees on street-view images using a
convolutional neural network. <em>IJNS</em>, <em>32</em>(1), 2150042.
(<a href="https://doi.org/10.1142/S0129065721500428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time detection of possible deforestation of urban landscapes is an essential task for many urban forest monitoring services. Computational methods emerge as a rapid and efficient solution to evaluate bird’s-eye-view images taken by satellites, drones, or even street-view photos captured at the ground level of the urban scenery. Identifying unhealthy trees requires detecting the tree itself and its constituent parts to evaluate certain aspects that may indicate unhealthiness, being street-level images a cost-effective and feasible resource to support the fieldwork survey. This paper proposes detecting trees and their specific parts on street-view images through a Convolutional Neural Network model based on the well-known You Only Look Once network with a MobileNet as the backbone for feature extraction. Essentially, from a photo taken from the ground, the proposed method identifies trees, isolates them through their bounding boxes, identifies the crown and stem, and then estimates the height of the trees by using a specific handheld object as a reference in the images. Experiment results demonstrate the effectiveness of the proposed method.},
  archive      = {J_IJNS},
  author       = {Danilo Samuel Jodas and Takashi Yojo and Sergio Brazolin and Giuliana Del Nero Velasco and João Paulo Papa},
  doi          = {10.1142/S0129065721500428},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2150042},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Detection of trees on street-view images using a convolutional neural network},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
