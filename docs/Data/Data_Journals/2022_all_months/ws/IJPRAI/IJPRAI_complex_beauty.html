<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJPRAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijprai---219">IJPRAI - 219</h2>
<ul>
<li><details>
<summary>
(2022). Computer-aided diagnosis using hybrid technique for fastened
and accurate analysis of tuberculosis detection with adaboost and
learning vector quantization. <em>IJPRAI</em>, <em>36</em>(16), 2240008.
(<a href="https://doi.org/10.1142/S0218001422400080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: The concept of tuberculosis diagnosis plays a significant role in the current world since, in accordance with the Global Tuberculosis (TB) Report in 2019, more than one million cases are reported per year in India. Various tests are available even then the chest X-ray is the most significant one, devoid of which the diagnosis will be incomplete. By the usage of computationally designed algorithms, various clinical, as well as diagnostic functions, were built in ancient poster anterior chest radiographs. The Digital image (X-ray) may be an essential medium for examining and annotating patient’s demographics coverage in the screening of TB via chest radiography. Results: Even though several medicines are available to cure TB, diagnosis with accuracy is a major challenge. So, we have introduced a fastened technique with the merged combination of Adaptive Boosting (AdaBoost) and learning vector quantization (LVQ) for determining TB in an easier way with the input chest X-ray image of a person with the aid of computer-aided diagnosis with greatest accuracy, precision, recall and F1 values. This finest technique got an accuracy of 94.73% when compared to the prior conventional methods used such as SVM and Convolutional Neural Network. Conclusions: Tuberculosis detection can be done in a meaningful way with the aid of MATLAB simulation using Computer Aided Diagnosis. The algorithms Adaboost and LVQ works best with the datasets for around 400 chest X-ray images for detecting the normal and abnormal images conditions for the detection of the disease for a patient suspected to have TB, in a fraction of seconds.},
  archive      = {J_IJPRAI},
  author       = {Emil M. Paul and B. Perumal},
  doi          = {10.1142/S0218001422400080},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2240008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Computer-aided diagnosis using hybrid technique for fastened and accurate analysis of tuberculosis detection with adaboost and learning vector quantization},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial neural network-based medical diagnostics and
therapeutics. <em>IJPRAI</em>, <em>36</em>(16), 2240007. (<a
href="https://doi.org/10.1142/S0218001422400079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of healthcare technology is impossible without machine learning (ML). There have been numerous advances in ML to analyze, predict, and diagnose medical data. Integrating a centralized scheme and therapy for classifying and diagnosing illnesses and disorders is a major obstacle in modern healthcare. To standardize all medical data into a single repository, researchers have proposed using ML using the centralized artificial neural network model (ML-CANNM). Random tree, support vector machine, and gradient booster are just a few proposed ML classifiers. Artificial neural networks (ANNs) have been trained using a variety of medical datasets to predict and analyze outcomes. ML-CANNM collects patient data from various studies and uses ML and ANNs to determine the results. Three layers make up an ANN. ML is used to classify the given patients’ data in the input layer. In the hidden layer, classification data are compared to a training dataset. The output layer’s job is to identify, classify, and diagnose diseases. As a result, disease diagnosis and detection are integrated into a single healthcare database. The proposed framework has proven that ML-CANNM works with more accuracy and lesser execution time. Thus, the numerical outcome suggested ML-CANNM increased accuracy ratio of 99.2% and a prediction ratio of 97.5%. The findings further show that the execution time is enhanced by less than 2 h, decision table using ML and results in an efficiency ratio of 97.5%.},
  archive      = {J_IJPRAI},
  author       = {Mohammed Hasan Ali and Mustafa Musa Jaber and Sura Khalil Abd and Ahmed Alkhayyat and Abdali Dakhil Jasim},
  doi          = {10.1142/S0218001422400079},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2240007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Artificial neural network-based medical diagnostics and therapeutics},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed clustering approach by apache pyspark based on
SEER for clinical data. <em>IJPRAI</em>, <em>36</em>(16), 2240006. (<a
href="https://doi.org/10.1142/S0218001422400067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data clustering is a thoroughly studied data mining issue. As the amount of information being analyzed grows exponentially, there are several problems with clustering diagnostic large datasets like the monitoring, microbiology, and end results (SEER) carcinoma feature sets. These traditional clustering methods are severely constrained in terms of speed, productivity, and adaptability. This paper summarizes the most modern distributed clustering algorithms, organized according to the computing platforms used to process vast volumes of data. The purpose of this work was to offer an optimized distributed clustering strategy for reducing the algorithm’s total execution time. We obtained, preprocessed, and analyzed clinical SEER data on liver cancer, respiratory cancer, human immunodeficiency virus (HIV)-related lymphoma, and lung cancer for large-scale data clustering analysis. Three major contributions and their effects were covered in this paper: To begin, three current Pyspark distributed clustering algorithms were evaluated on SEER clinical data using a simulated New York cancer dataset. Second, systemic inflammatory response syndrome (SIRS) model inference was done and described using three SEER cancer datasets. Third, employing lung cancer data, we suggested an optimized distributed bisecting k -means method. We have shown the outcomes of our suggested optimized distributed clustering technique, demonstrating the performance enhancement.},
  archive      = {J_IJPRAI},
  author       = {R. Ramesh and M. V. Judy},
  doi          = {10.1142/S0218001422400067},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2240006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Distributed clustering approach by apache pyspark based on SEER for clinical data},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Liver tumor classification using optimal opposition-based
grey wolf optimization. <em>IJPRAI</em>, <em>36</em>(16), 2240005. (<a
href="https://doi.org/10.1142/S0218001422400055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image processing plays a significant role in various fields like military, business, healthcare and science. Ultrasound (US), Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) are the various image tests used in the treatment of the cancer. Detecting the liver tumor by these tests is a complex process. Hence, in this research work, a novel approach utilizing a deep learning model is used. That is Deep Belief Network (DBN) with Opposition-Based Learning (OBL)-Grey Wolf Optimization (GWO) is used for the classification of liver cancer. This process undergoes five major processes. Initially, in pre-processing the color contrast is improved by Contrast Limited Adaptive Histogram Equalization (CLAHE) and the noise is removed by Wiener Filtering (WF). The liver is segmented by adaptive thresholding following pre-processing. Following that, the kernelizedFuzzy C Means (FCM) method is used to segment the tumor area. The form, color, and texture features are then extracted during the feature extraction process. Finally, these traits are categorized using DBN, and OBL-GWO is employed to enhance system performance. The entire evaluation is done on Liver Tumor Segmentation (LiTS) benchmark dataset. Finally, the performance of the proposed DBN-OBL-GWO is compared to other models and their achievements are proved. The proposed DBN-OBL-GWO achieves a better accuracy of 0.995, precision of 0.948 and false positive rate (FPR) of 0.116, respectively.},
  archive      = {J_IJPRAI},
  author       = {Reshma Jose and Shanty Chacko and J. Jayakumar and T. Jarin},
  doi          = {10.1142/S0218001422400055},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2240005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Liver tumor classification using optimal opposition-based grey wolf optimization},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A composite medical image optimization scheme using honey
encryption and antlion algorithms for secured diagnostic systems.
<em>IJPRAI</em>, <em>36</em>(16), 2240004. (<a
href="https://doi.org/10.1142/S0218001422400043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical imaging technology is one of the most critical applications necessitating data protection, particularly if we need to keep track of any important patient information. This medical imaging system employs encryption and decryption. Using several cryptographic techniques, the security key was established to protect the data. Every network that sends and receives data needs to be secure in some way. In this paper, ALO along with the encryption algorithm honey is used to enhance the security of medical imaging technologies, the proposed study uses a variety of ways to protect important health information. In comparison to the existing one, the proposed honey algorithm attains better results. Further, the antlion optimizer uses random keys throughout the encryption and decryption. In the next step, the keys are remodeled using antlion optimization. After that, the updated key is optimized by analyzing every element and generating paths that trigger the traps and latching functions. The mean square error (MSE) is reduced to 1% and the peak signal-to-noise ratio (PSNR) is increased to 98% by using a hybrid strategy.},
  archive      = {J_IJPRAI},
  author       = {G. Jayahari Prabhu and B. Perumal and T. Jarin},
  doi          = {10.1142/S0218001422400043},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2240004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A composite medical image optimization scheme using honey encryption and antlion algorithms for secured diagnostic systems},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparison of convolutional neural network for classifying
lung diseases from chest CT images. <em>IJPRAI</em>, <em>36</em>(16),
2240003. (<a href="https://doi.org/10.1142/S0218001422400031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a convolutional neural network for diagnosing various lung illnesses from chest CT images based on a customized Medical Image Analysis and Detection network (MIDNet18). With simplified model building, minimal complexity, easy technique, and high-performance accuracy, the MIDNet-18 CNN architecture classifies binary and multiclass medical images. Fourteen convolutional layers, 7 pooling layers, 4 dense layers, and 1 classification layer comprise the MIDNet-18 architecture. The medical image classification process involves training, validating, and testing the MIDNet-18 model. In the Lung CT image binary class dataset, 2214 images as training set, 1800 images as validation set, and 831 as test set are considered for classifying COVID images and normal lung images. In the multiclass dataset, 6720 images as training sets belonging to 3 classes, 3360 images as validation sets and 601 images as test sets are considered for classifying COVID, cancer images and normal images. Independent sample size calculated for binary classification is 26 samples for each group. Similarly, 10 sample sizes are calculated for multiclass dataset classification keeping GPower at 80%. To validate the performance of the MIDNet18 CNN architecture, the medical images of two different datasets are compared with existing models like LeNet-5, VGG-16, VGG-19, ResNet-50. In multiclass classification, the MIDNet-18 architecture gives better training accuracy and test accuracy, while the LeNet5 model obtained 92.6% and 95.9%, respectively. Similarly, VGG-16 is 89.3% and 77.2% respectively; VGG-19 is 85.8% and 85.4%, respectively; ResNet50 is 90.6% and 99%, respectively. For binary classification, the MIDNet18 architecture gives better training accuracy and test accuracy, while the LeNet-5 model has obtained 52.3% and 54.3%, respectively. Similarly, VGG 16 is 50.5% and 45.6%, respectively; VGG-19 is 50.6% and 45.6%, respectively; ResNet-50 is 96.1% and 98.4%, respectively. The classified images are further predicted using detectron-2 model and the results identify abnormalities (cancer, COVID-19) with 99% accuracy. The MIDNET18 is significantly more accurate than LeNet5, VGG19, VGG16 algorithms and is marginally better than the RESNET50 algorithm for the given lung binary dataset (Bonferroni — one-way Anova and pairwise comparison of MIDNET, LeNet5, VGG19, VGG16, and RESNET 50 ( p &gt; 0 . 0 5 )). The proposed MIDNet18 model is significantly more accurate than LeNet5, VGG19, VGG16, ResNet50 algorithms in classifying the diseases for the given multiclass lung dataset (Bonferroni — one-way Anova and pairwise comparison of MIDNET18, LeNet5, VGG19, VGG16, ResNet50 ( p &gt; 0 . 0 5 )).},
  archive      = {J_IJPRAI},
  author       = {Ramya Mohan and A. Rama and Kirupa Ganapathy},
  doi          = {10.1142/S0218001422400031},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2240003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Comparison of convolutional neural network for classifying lung diseases from chest CT images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ITL-CNN: Integrated transfer learning-based convolution
neural network for ultrasound PCOS image classification.
<em>IJPRAI</em>, <em>36</em>(16), 2240002. (<a
href="https://doi.org/10.1142/S021800142240002X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Polycystic Ovary Syndrome (PCOS) becomes one of the most prominent research areas, where several researchers are concentrating to improve the accuracy of PCOS classification. It is much difficult to find the presence of PCOS in women with traditional techniques and various researchers are dealt with the problem that affects the accuracy in detecting such symptom. In this paper, we have proposed Integrated Transfer Learning-based Convolutional Neural Network (ITL-CNN) model to improve the classification accuracy for the detection of PCOS using ultrasound images. In this proposed model, we have used active contour with modified Otsu method and Multifactor Dimension Reduction-based GIST feature extractor for improving the performance of the ITL-CNN model. The performance of the proposed model is analyzed using various performance metrics such as accuracy, sensitivity, precision, recall, and F1 score. Furthermore, the results show that the proposed ITL-CNN model outperforms by achieving 98.9% of accuracy when compared with other existing techniques such as Convolutional Neural Network (CNN), Artificial Neural Network (ANN), Support Vector Machine (SVM), and Gaussian Naïve Bayes (NB).},
  archive      = {J_IJPRAI},
  author       = {C. Gopalakrishnan and M. Iyapparaja},
  doi          = {10.1142/S021800142240002X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2240002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {ITL-CNN: Integrated transfer learning-based convolution neural network for ultrasound PCOS image classification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting lung cancer region from CT image using
meta-heuristic optimized segmentation approach. <em>IJPRAI</em>,
<em>36</em>(16), 2240001. (<a
href="https://doi.org/10.1142/S0218001422400018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung tumor detection using computer-aided modeling improves the accuracy of detection and clinical recommendation precision. An optimal tumor detection requires noise reduced computed tomography (CT) images for pixel classification. In this paper, the butterfly optimization algorithm-based K -means clustering (BOAKMC) method is introduced for reducing CT image segmentation uncertainty. The introduced method detects the overlapping features for optimal edge classification. The best-fit features are first trained and verified for their similarity. The clustering process recurrently groups the feature matched pixels into clusters and updates the centroid based on further classifications. In this classification process, the uncertain pixels are identified and mitigated in the tumor detection analysis. The best-fit features are used to train local search instances in the BOA process, which influences the similar pixel grouping in the uncertainty detection process. The proposed BOAKMC improves accuracy and precision by 10.2% and 13.39% and reduces classification failure and time by 11.29% and 11.52%, respectively.},
  archive      = {J_IJPRAI},
  author       = {Pethuraj Mohamed Shakeel and Burhanuddin bin Mohd Aboobaider and Lizawati Binti Salahuddin},
  doi          = {10.1142/S0218001422400018},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2240001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Detecting lung cancer region from CT image using meta-heuristic optimized segmentation approach},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rice variety identification based on the leaf hyperspectral
feature via LPP-SVM. <em>IJPRAI</em>, <em>36</em>(15), 2350001. (<a
href="https://doi.org/10.1142/S0218001423500015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rice variety identification is important for genetic breeding classification and crop yield estimation. Traditional identification methods are time-consuming and inaccurate. This paper proposes a method for rice variety identification based on the hyperspectral characteristics of leaves. Hyperspectral data of rice leaves were collected using a geophysical spectrometer imaging system. To reduce the redundance among the hyperspectral data and save the identification cost, locality preserving projections (LPP) is first applied to extract low-dimensional representative features from the leaf hyperspectral data. Then, support vector machine (SVM) is combined for conducting the identification of rice varieties. The experimental results show that the identification rate of 10 varieties of early rice was found to be 91.67% and the identification rate of 10 varieties of late rice was 97.33%.},
  archive      = {J_IJPRAI},
  author       = {Tian Hu and Yineng Chen and Di Li and Chenfeng Long and Zhidong Wen and Rong Hu and Guanghui Chen},
  doi          = {10.1142/S0218001423500015},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2350001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Rice variety identification based on the leaf hyperspectral feature via LPP-SVM},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Locally differentially private frequent pattern mining for
high-dimensional data in mobile smart services. <em>IJPRAI</em>,
<em>36</em>(15), 2259039. (<a
href="https://doi.org/10.1142/S021800142259039X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collecting users’ historical data such as movie watching and music listening, and mining frequent items from them, can improve the utility of smart services, but there is also a risk of compromising user privacy. Local differential privacy is a strict definition of privacy and has been widely used in various privacy-preserving data collection scenarios. However, the accuracy of existing locally differentially private frequent items mining methods decreases significantly with the increase in the dimensions of data to be collected. In this paper, we propose a new locally differentially private frequent item mining method for high-dimensional data, which decreases the dimension used for data perturbation by grouping the contents and improving the interference matrix generation method, so as to improve the data reconstruction accuracy. The experimental results show that our proposed method can significantly improve the accuracy of frequent item mining and provide a better trade-off between privacy and accuracy compared with existing methods.},
  archive      = {J_IJPRAI},
  author       = {Qi Li and Shunshun Peng and Haonan Wu and Ruisheng Ran and Yong Li and Mingliang Zhou and Taolin Guo and Qin Mao},
  doi          = {10.1142/S021800142259039X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2259039},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Locally differentially private frequent pattern mining for high-dimensional data in mobile smart services},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-input file data symmetry placement method
considering job execution frequency for MapReduce join operation.
<em>IJPRAI</em>, <em>36</em>(15), 2259037. (<a
href="https://doi.org/10.1142/S0218001422590376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, data-parallel computing frameworks such as Hadoop have become increasingly popular among scientists. Data-grouping-aware multiple input file data placement for Hadoop is becoming increasingly popular. However, we note that many data-grouping-aware data placement schemes for multiple input files do not take MapReduce job execution frequency into account. Through the study, such data placement schemes will increase the data transmission between nodes. The starting point of this paper is that if a certain type of MapReduce job has been executed more frequently recently, then it can be assumed that this type of job will also have a higher chance of being executed later. Based on this assumption, we proposed a data-grouping-aware multiple input files data symmetry placement method based on MapReduce jobs execution frequency (DGAMF). Based on the history of MapReduce job executions, this method first creates an inter-block join access correlation model, then divides the correlated blocks into groups according to this model and gives a mathematical model for data placement. The model can be used to guide the placement of data blocks centrally to solve the node load balancing issue caused by data asymmetry. Using the proposed method, correlated blocks from the same groups were placed in the same set of nodes, thereby effectively reducing the amount of data transmitted between nodes. Our data placement method was validated by setting up an experimental Hadoop environment. Experimental results showed that the proposed method effectively processed massive datasets and improved MapReduce’s efficiency significantly.},
  archive      = {J_IJPRAI},
  author       = {Jia-Xuan Wu and Yu-Zhu Zhang and Yue-Qiu Jiang and Xin Zhang},
  doi          = {10.1142/S0218001422590376},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2259037},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A multi-input file data symmetry placement method considering job execution frequency for MapReduce join operation},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hate and aggression analysis in NLP with explainable AI.
<em>IJPRAI</em>, <em>36</em>(15), 2259036. (<a
href="https://doi.org/10.1142/S0218001422590364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social platforms such as Twitter and Facebook have now become only media to express their thoughts, and due to lack of censorship, it often embellishes themselves as an abode for hate towards minorities. People of color, Asian people, Muslims, women, transgenders, and LGBTQ+ communities are often the target of such online hate and aggression. Though several companies have incorporated considerable algorithms on their platforms, nevertheless due to being rather hard to often detect such comments still make it to the platforms, creating a negative space towards targeted people. This research involves the study and comparison of different hate and aggression detection algorithms with intent on two languages, i.e. English and German including machine learning models (linear SVC, logistic regression, multinomial naive Bayes and random forests) with their variations with feature engineering and bag of words and deep learning (CNN-GRU static, TCN static, Seq2Seq) with their variations vis-à-vis Word2Vec embedding. CNN+GRU static + Word2Vec embedding has outperformed all the other techniques with an accuracy of 68.29%.},
  archive      = {J_IJPRAI},
  author       = {Shatakshi Raman and Vedika Gupta and Preeti Nagrath and KC Santosh},
  doi          = {10.1142/S0218001422590364},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2259036},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Hate and aggression analysis in NLP with explainable AI},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bivariate barycentric and newton rational interpolation over
rectangular grids. <em>IJPRAI</em>, <em>36</em>(15), 2259034. (<a
href="https://doi.org/10.1142/S0218001422590340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the problem of computing bivariate barycentric and Newton rational interpolation over rectangular grids. Given a set of rectangular grids, under the conditions that the degrees of the numerator and denominator of rational interpolant are prescribed, we provide a matrix method for calculating barycentric weight vector and denominator value vector, which, respectively, induce barycentric and Newton representations of rational interpolants. We aim at constructing the rational interpolants that globally approximate interpolated function. Numerical examples compare the maximum errors of barycentric rational interpolant, Newton rational interpolant, linear interpolant, cubic interpolant and spline interpolant. Numerical results show the higher accuracy of barycentric and Newton rational interpolation.},
  archive      = {J_IJPRAI},
  author       = {Zhidan Cai and Ming Fang and Zhe Li and Longfei Yang},
  doi          = {10.1142/S0218001422590340},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2259034},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Bivariate barycentric and newton rational interpolation over rectangular grids},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reduction algorithm of interval-valued intuitionistic fuzzy
probability rough set under dominant relation. <em>IJPRAI</em>,
<em>36</em>(15), 2259031. (<a
href="https://doi.org/10.1142/S0218001422590315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction is a part of the most basic and significant research contents in rough set theory. The so-called attribute reduction is the smallest independent subset that keeps certain properties of information table unchanged. In this paper, four interval-valued intuitionistic fuzzy probabilistic rough set models and their natures are given on the basis of the dominant-, inferior- and interval-valued intuitionistic fuzzy probabilistic rough set models. At the same time, the interval-valued intuitionistic fuzzy numbers are transformed by fuzzy degree, and the approximate accuracy and approximate classification quality under the dominance relation are used for reduction, at last, the feasibility is verified by an example.},
  archive      = {J_IJPRAI},
  author       = {Qiuna Zhang and Chunhai Hu},
  doi          = {10.1142/S0218001422590315},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2259031},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Reduction algorithm of interval-valued intuitionistic fuzzy probability rough set under dominant relation},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view high precise 3D human body reconstruction method
for virtual fitting. <em>IJPRAI</em>, <em>36</em>(15), 2256023. (<a
href="https://doi.org/10.1142/S0218001422560237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online shopping has experienced rapid development recently. However, compared to offline shopping, the return rate and complaint rate of online shopping are much higher, especially for online clothes shopping. In order to solve this problem, virtual fitting technology arises at the right moment, and 3D human modeling is a crucial part of virtual fitting technology. The reconstruction of the parametric 3D human models often faces challenges as long fitting time, low accuracy and fuzzy depth information. Although the reconstruction of nonparametric 3D human model has improved accuracy and detail to some extent, such models typically lack flexibility and controllability. Therefore, this paper reconstructs a high-precision parametric 3D human model by proposing a multi-view iterative registration strategy based on pose prior estimation, which is integrated with a nonparametric 3D human model based on implicit functions. The resulting model retains not only high-precision and detail but also high flexibility and controllability, which has achieved a good effect on the application of 3D virtual fitting. The proposed method is tested on the open-source 3D human body dataset multi-garment network (MGN). The Chamfer distance of the SMPL mannequin reconstructed from multiple views can reach 2.18 cm and the per-vertical-error can reach 1.63 cm.},
  archive      = {J_IJPRAI},
  author       = {Shufang Zhang and Yanran Liu and Jiang Liu and Yuhong Liu},
  doi          = {10.1142/S0218001422560237},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2256023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-view high precise 3D human body reconstruction method for virtual fitting},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variable structure and modeling units for chinese
lipreading. <em>IJPRAI</em>, <em>36</em>(15), 2256021. (<a
href="https://doi.org/10.1142/S0218001422560213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lipreading is a type of Human–Computer Interaction (HCI) based on visual information. From a linguistic point of view, Chinese is a monosyllabic language with a much higher proportion of homophones than English. Identifying homophones in Chinese Mandarin lipreading is very challenging. Since the lip shape in the context can distinguish homophones, and smaller recognition units can reduce the types of recognition and alleviate data sparsity, we propose to improve the accuracy of lipreading by simultaneously exploiting the correlation of lip features at different distances and smaller modeling units. We implement a long short-term multi-feature space to represent lip features, and CTC–Attention to learn temporal correlations. We also introduce Weight Finite State Transducer (WFST) to enhance the semantic analysis capability of the model. Our model aims to distinguish homophones and improve the accuracy of lipreading. To reduce data sparsity, we use Tonal Initials and Finals (TIF) as the modeling units. We record a sentence-level Chinese lipreading dataset, ICSLR, and label Mandarin characters, syllables, and TIF. We demonstrate the effectiveness of the proposed approach compared to its counterparts through extensive experiments on Grid, ICSLR, and CMLR datasets.},
  archive      = {J_IJPRAI},
  author       = {Baosheng Sun and Dongliang Xie and Tiantian Duan},
  doi          = {10.1142/S0218001422560213},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2256021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Variable structure and modeling units for chinese lipreading},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Wavelet entropy-based method for migration imaging of hidden
microcracks by using the optimal wave velocity. <em>IJPRAI</em>,
<em>36</em>(15), 2254021. (<a
href="https://doi.org/10.1142/S0218001422540210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring the shape and direction of hidden cracks in a tunnel lining structure is one of the main objectives of ground penetrating radar (GPR) map interpretation. The most important factor that restricts the migration imaging of hidden cracks is the propagation velocity of electromagnetic waves. Determining the optimal electromagnetic wave velocity is the key to truthfully restoring the actual shape of hidden cracks. To study the GPR characteristic response signals of hidden cracks, forward simulation and model experiments of different cracks were performed. Subsequently, a method to determine the optimal electromagnetic wave velocity based on the wavelet entropy theory was proposed, and the frequency wavenumber domain migration (F-K) and Kirchhoff integral migration imaging method were combined. Horizontal, S-type, and inclined hidden fractures were examined by migration imaging. The results show that the radar characteristic response images of different cracks can be simulated forward by using the finite difference time domain method to write the fracture model instruction. Based on the wavelet entropy theory, the error range between the estimated value and true value was controlled within 4%. Taking the optimal electromagnetic wave velocity as the velocity parameter of the conventional migration method can make the migration more effective and suppress the interference of echo signals so that the diffraction wave converges, and the energy is more concentrated; thus, the real fracture morphology can be restored to the greatest extent. The research results can provide technical support for the fine detection of hidden quality defects in tunnel lining structures by GPR mapping.},
  archive      = {J_IJPRAI},
  author       = {Fei Hua and Tonghua Ling and Wenchao He and Xianjun Liu},
  doi          = {10.1142/S0218001422540210},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2254021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Wavelet entropy-based method for migration imaging of hidden microcracks by using the optimal wave velocity},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel image copy–move forgery detection algorithm using
the characteristics of local descriptors. <em>IJPRAI</em>,
<em>36</em>(15), 2254019. (<a
href="https://doi.org/10.1142/S0218001422540192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The image copy–move forgery can achieve the realistic effects without leaving any obvious manipulation traces because the copied source and pasted target belong to the homogenous sources. Image copy–move forgery detection (CMFD) is still a serious challenge issue for researchers, e.g. computational efficiency, occlusive (smoothing) object detection, and partial object detection, under various post-processing and geometrical transformations. This paper proposes a novel CMFD scheme using the characteristics of local descriptors. First, the proposed method deeply analyzes the structure and mines the inherent characteristics of the local descriptor (SURF) for feature extraction in the coarse and smooth regions. Subsequently, the proposed method takes the kernel features as coarse feature matching to decrease matching costs. Then, the found candidate keypoints with a relatively small quantity are used with complete features to perform fine keypoint matching for getting suspicious candidate keypoint pairs. Furthermore, based on the deep mining of the inherent local descriptor characteristics, the proposed method can indicate the forgery region localizations through keypoint pairs, even the forgeries suffering from various geometrical transformations. Then, the proposed method proposes adaptive dual-filtering algorithms of K -means relying on keypoint characteristics, and spatial distance for hierarchical progress of feature filtering. Finally, Delaunay Triangulation relies on the true-positive keypoint pairs to perform the forgery region matting effectively and efficiently. The experimental results demonstrate that the proposed method can achieve the best F 1 scores compared to the state-of-the-art methods in most cases, especially in anti-scaling transformations.},
  archive      = {J_IJPRAI},
  author       = {Jun-Liu Zhong and Ji-Xiang Yang and Hua Zeng and Ying-Qi Zhao},
  doi          = {10.1142/S0218001422540192},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2254019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel image Copy–Move forgery detection algorithm using the characteristics of local descriptors},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensemble learning for multispectral scene classification.
<em>IJPRAI</em>, <em>36</em>(15), 2251013. (<a
href="https://doi.org/10.1142/S0218001422510132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent decades, various techniques based on deep convolutional neural networks (DCNNs) have been applied to scene classification. Most of the techniques are established upon single-spectral images such that environmental conditions may greatly affect the quality of images in the visible (RGB) spectrum. One remedy for this downside is to merge the infrared (IR) with the visible spectrum for gaining the complementary information in comparison with the unimodal analysis. This paper incorporates the RGB, IR and near-infrared (NIR) images into a multispectral analysis for scene classification. For this purpose, two strategies are adopted. In the first strategy, each RGB, IR and NIR image is separately applied to DCNNs and then classified according to the output score of each network. In addition, an optimal decision threshold is obtained based on the same output score of each network. In the second strategy, three image components are extracted from each type of image using wavelet transform decomposition. Independent DCNNs are then trained on the image components of all the scene classes. Eventually, the final classification of the scene is accomplished through an appropriate ensemble architecture. The use of this architecture alongside a transfer learning approach and simple classifiers leads to lesser computational costs in small datasets. These experiments reveal the superiority of the proposed method over the state-of-the-art architectures in terms of the accuracy of scene classification.},
  archive      = {J_IJPRAI},
  author       = {Rahman Soroush and Yasser Baleghi},
  doi          = {10.1142/S0218001422510132},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2251013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Ensemble learning for multispectral scene classification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic detection of bridge surface crack using improved
YOLOv5s. <em>IJPRAI</em>, <em>36</em>(15), 2250047. (<a
href="https://doi.org/10.1142/S0218001422500471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bridge crack detection is a key task in the structural health monitoring of Civil Engineering. In the traditional bridge crack detection methods, there exist some problems such as high cost, low speed, and complex structure. This paper developed a bridge surface crack detection system based on improved YOLOv5s. The GhostBottleneck module was employed to replace the classic C3 module of the YOLOv5s backbone network, meanwhile the channel attention module namely ECA-Net was also added to the network, which not only reduced the amount of calculation, but also enhanced the ability of the network in extracting cross-channel information features. The adaptive spatial feature fusion (ASFF) was introduced to address the conflict problem caused by the inconsistency of feature scale in the network feature fusion stage, and the transfer learning was utilized to train the network. The experimental results showed that the improved YOLOv5s performed better than Faster R-CNN, SSD, YOLOv3, and YOLOv5s, with the Precision of 93.6%, Recall of 95.4%, and mAP of 98.4%. Further, the improved YOLOv5s was deployed in PyQt5 to realize the real-time detection of bridge cracks. This research showed that the proposed model not only provides a novel solution for bridge surface crack detection, but also has certain industrial application value.},
  archive      = {J_IJPRAI},
  author       = {Haoyan Yang and Lina Yang and Thomas Wu and Zuqiang Meng and Youju Huang and Patrick Shen-Pei Wang and Peng Li and Xichun Li},
  doi          = {10.1142/S0218001422500471},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2250047},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Automatic detection of bridge surface crack using improved YOLOv5s},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A knowledge enforcement network-based approach for
classifying a photographer’s images. <em>IJPRAI</em>, <em>36</em>(15),
2250046. (<a href="https://doi.org/10.1142/S021800142250046X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of photos captured by different photographers is an important and challenging problem in knowledge-based and image processing. Monitoring and authenticating images uploaded on social media are essential, and verifying the source is one key piece of evidence. We present a novel framework for classifying photos of different photographers based on the combination of local features and deep learning models. The proposed work uses focused and defocused information in the input images to extract contextual information. The model estimates the weighted gradient and calculates entropy to strengthen context features. The focused and defocused information is fused to estimate cross-covariance and define a linear relationship between them. This relationship results in a feature matrix fed to Knowledge Enforcement Network (KEN) for obtaining representative features. Due to the strong discriminative ability of deep learning models, we employ the lightweight and accurate MobileNetV2. The output of KEN and MobileNetV2 is sent to a classifier for photographer classification. Experimental results of the proposed model on our dataset of 46 photographer classes (46234 images) and publicly available datasets of 41 photographer classes (218303 images) show that the method outperforms the existing techniques by 5%–10% on average. The dataset created for the experimental purpose will be made available upon publication.},
  archive      = {J_IJPRAI},
  author       = {Palaiahnakote Shivakumara and Pinaki Nath Chowdhury and Umapada Pal and David Doermann and Raghavendra Ramachandra and Tong Lu and Michael Blumenstein},
  doi          = {10.1142/S021800142250046X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2250046},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A knowledge enforcement network-based approach for classifying a photographer’s images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computing the wide-band earth return impedance of submarine
cable considering complex paths. <em>IJPRAI</em>, <em>36</em>(14),
2259026. (<a href="https://doi.org/10.1142/S0218001422590261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the various earth return pathways in practical projects, calculating the wide-band earth return impedance of submarine cable is problematic. Using the dynamic Hertz magnetic potential, the formula for estimating the earth return impedance has been obtained based on the three-layer structure of air, sea water, and seafloor. Furthermore, in the frequency range of 50 ∼ 10 MHz, the enhanced complex image approach and numerical integration method have been developed to compute the earth return impedance. The suggested iterative complex image method outperforms the classic complex image method in terms of accuracy and computation speed, with a global fitting error of less than 10 −6 . Finally, the impact of various models on the real and imaginary parts of submarine cable wide-band earth return impedance has been investigated. The results demonstrate that the actual component has a more complicated variation, whereas the imaginary part is clearly affected by the skin effect, with a bigger difference in the high-frequency range. The method presented in this research can be utilized as a supplement to existing methods, as well as a reference methodology for analyzing the influence of over-voltage on submarine cable engineering.},
  archive      = {J_IJPRAI},
  author       = {Shuyi Shen and Dong He and Yingjing He and Fan Li and Keping Zhu and Zhuohong Pan},
  doi          = {10.1142/S0218001422590261},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2259026},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Computing the wide-band earth return impedance of submarine cable considering complex paths},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Road friction coefficient estimation via weakly supervised
semantic segmentation and uncertainty estimation. <em>IJPRAI</em>,
<em>36</em>(14), 2258009. (<a
href="https://doi.org/10.1142/S0218001422580095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-based road friction coefficient estimation received extensive attention in the field of road maintenance and autonomous driving. However, the current mainstream coarse-grained friction estimation methods are basically based on image classification tasks. This makes it difficult to deal with complex road conditions in changing weathers. Many models can correctly predict the friction coefficients of the road as a whole in consistent and simple road conditions, but perform poorly otherwise. The existing image benchmarks in this field rarely consider the above problems as well, which limits the comparable evaluations of different models. Therefore, in this paper, we first construct a challenging pixel-level friction coefficient estimation dataset WRF-P to evaluate model performances under mixed road conditions. Then, we propose a friction coefficient estimation method based on weakly supervised learning and uncertainty estimation to realize pixel-level road friction prediction with low annotation cost. The model outperforms existing weakly supervised methods and reaches 39.63% mIOU on the WRF-P dataset. The WRF-P dataset will be made publicly available at https://github.com/blackholeLFL/The-WRF-dataset soon.},
  archive      = {J_IJPRAI},
  author       = {Feilin Liu and Yan Wu and Yujian Mo and Yujun Liao and Yufei He},
  doi          = {10.1142/S0218001422580095},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2258009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Road friction coefficient estimation via weakly supervised semantic segmentation and uncertainty estimation},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving the performance of finger vein recognition using
the local histogram concatenation of image descriptors. <em>IJPRAI</em>,
<em>36</em>(14), 2256020. (<a
href="https://doi.org/10.1142/S0218001422560201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a system based on image descriptor and Local Histogram Concatenation (LHC) for finger vein recognition is introduced. The LHC of image descriptors such as LBP, LDP CLBP cannot be inverted back to the original images, therefore they can provide good security if stored as enrolled data. On the other hand, the technique of LHC does not depict spatial information, therefore it is expected to be less sensitive to image misalignment if a measure such as the histogram difference ( d X 2 ) is used for recognition. The use of histogram difference makes the system more robust to misalignment compared to the pixel-by-pixel-based measures such as the Hamming Distance (HD). The approach of LHC is implemented by dividing the image descriptor into non-overlapped grids, then the histogram within each grid is calculated and concatenated with the histograms of the preceding grids and finally, the concatenated histograms of each two images are compared using d X 2 measure. Two datasets, UTFVP and SDUMLA-HMT, are used for testing the performance of the system. The results have shown that the Identification Recognition Rate (IRR) is improved when LHCs of the image descriptors with ( d X 2 ) measure are used compared to the use of only the image descriptors with HD measure. For UTFVP dataset, the IRR values were 97.44%, 95% and 98.37% when LHC and ( d X 2 ) were used with LBP, LDP and CLBP, respectively, while these values were 89.44%, 92.63% and 92.92% when only LBP, LDP and CLBP with HD were used. For SDUMLA-HMT dataset, the IRR values of the system were 98.43%, 98.69% and 98.85% when LHC and ( d X 2 ) were used with LBP, LDP and CLBP, respectively, while these values were 97.6%, 98.24% and 97.27% when only the image descriptors LBP, LDP and CLBP with HD were used.},
  archive      = {J_IJPRAI},
  author       = {Ahmed AK. Tahir and Ahmed A. Mustafa},
  doi          = {10.1142/S0218001422560201},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2256020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Improving the performance of finger vein recognition using the local histogram concatenation of image descriptors},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An intelligent face recognition technology for IoT-based
smart city application using condition-CNN with foraging learning PSO
model. <em>IJPRAI</em>, <em>36</em>(14), 2256018. (<a
href="https://doi.org/10.1142/S0218001422560183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The internet of things (IoT) is a rapidly expanding network of smart digital devices that can communicate with one another and be controlled remotely over the internet. Moreover, IoT devices are cheap and can be used to control and monitor activities remotely. Due to this reason, IoT is widely used in the applications of a smart city. Moreover, the smart devices that are used in IoT-based smart city applications are used to gather information from devices, humans, and other sources for analyzing purposes. Hence, it is crucial to conduct the face recognition process to ensure the safety of the city. Several works were conducted by the researchers to recognize the face accurately. Typically, the effectiveness of achieving face recognition is still an intricate one. To tackle those issues, we have proposed a novel condition convolutional neural network (condition-CNN)-based bee foraging learning (BFL)-based particle swarm optimization (PSO) algorithm (CCNNBFLPSO). To recognize the facial images from the face image datasets, the proposed CCNNBFLPSO model is used. To ensure the prediction accuracy condition, CNN uses the conditional probability weight matrix (CPWM) to estimate the higher and lower class level of image features. Meanwhile, the learning of CPWM can be performed by utilizing the adopted BPL-PSO approach. For experimental purposes, we have taken three datasets namely the CVL face database, the MUCT database, and the CMU multi-PIE face database. The training time and the training accuracy are analyzed for all the three datasets, and comparative studies are performed with state-of-art works such as LBPH, FoL TDL, and TPS approaches. The training and validation loss functions are analyzed with baseline CNNs, B-CNN, and condition-CNN. The proposed approach accomplishes better face recognition accuracy and F1-score of about 99.9% and 99.9%, respectively.},
  archive      = {J_IJPRAI},
  author       = {Surendran Rajendran and Arun Mozhi Selvi Sundarapandi and Anbazhagan Krishnamurthy and Tamilvizhi Thanarajan},
  doi          = {10.1142/S0218001422560183},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2256018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An intelligent face recognition technology for IoT-based smart city application using condition-CNN with foraging learning PSO model},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient adaptive upsampling module for real-time semantic
segmentation. <em>IJPRAI</em>, <em>36</em>(14), 2255020. (<a
href="https://doi.org/10.1142/S0218001422550205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Upsampling operation is necessary for semantic segmentation and other pixel-level prediction tasks. Among the commonly used upsampling operations, some are too simple to effectively recover the spatial details lost during downsampling process, and some are too complex and have high computation complexity. In real-world applications, it is critical to achieve high accuracy and maintain real-time inference speed. Therefore, an efficient upsampling operation is essential for these tasks. In this paper, we introduce efficient adaptive upsampling module (EAUM) for real-time semantic segmentation. Inspired by dynamic filter networks, EAUM adaptively predicts the kernel weight of each point in the upsampled feature map according to the corresponding points in the input feature map. To reduce computational cost, EAUM decomposes the spatial information and channel information required for upsampling. The proposed EAUM shows impressive performance on Cityscapes and CamVid benchmarks. Specifically, DenseENet with EAUM outperforms the baseline by 1.4% ( 7 3 . 6 % → 7 5 . 0 % ) and 1.6% ( 7 5 . 2 % → 7 6 . 8 % ) in accuracy with a slight drop in inference speed on Cityscapes test dataset.},
  archive      = {J_IJPRAI},
  author       = {Xinneng Yang and Yan Wu and Junqiao Zhao and Feilin Liu and Yujun Liao and Yujian Mo},
  doi          = {10.1142/S0218001422550205},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2255020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Efficient adaptive upsampling module for real-time semantic segmentation},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of convolutional neural networks for analyzing
game icon and screenshot images. <em>IJPRAI</em>, <em>36</em>(14),
2254023. (<a href="https://doi.org/10.1142/S0218001422540234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Icons and screenshots are important media displayed in game distribution platforms for providing a brief understanding of the game content to the customers. In this study, we develop ensemble convolutional neural networks for icon and screenshot analysis as three applications: an automatic genre classification, a similar game searching, and a recognition quality assessment. First, the genre classifier is developed using 154358 images from 18 030 games in 17 genres. The proposed genre classifiers achieve 40.5% and 47.6% accuracies for classifying a single icon and a single screenshot, which outperform the average performance of the human testers. The accuracy can be boosted to 54.2% by aggregating results from every image of the game. The Grad-CAM is applied to analyze what models learned. Then, the feature extraction part trained by this task is transferred to the other two applications. For the similar game searching, a dissimilarity of two images is directly computed by the Euclidean distance in the feature space. We define a dissimilarity between two games which are sets of multiple images based on their image-pairwise dissimilarity. The results show that the features are successfully transferred, and the model seems to be able to cluster the games with a similar gameplay and differentiate them from the other gameplays even if they come from the same genre. For the third application, we develop a system for quality assessment of game images based on the correctness of viewers’ understanding of game content by combining multiple models from three different problem definitions. Our system can identify good-genre-representing game images which most of the human testers can recognize their genre correctly with 75.0% accuracy for icons and 76.2% accuracy for screenshots.},
  archive      = {J_IJPRAI},
  author       = {Chayanin Suatap and Karn Patanukhom},
  doi          = {10.1142/S0218001422540234},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2254023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Development of convolutional neural networks for analyzing game icon and screenshot images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced deep learning hybrid model of CNN based on spatial
transformer network for facial expression recognition. <em>IJPRAI</em>,
<em>36</em>(14), 2252028. (<a
href="https://doi.org/10.1142/S0218001422520280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most common approaches through which people communicate is facial expressions. A large number of features documented in the literature were created by hand, with the goal of overcoming specific challenges such as occlusions, scale, and illumination variations. These classic methods are then applied to a dataset of facial images or frames in order to train a classifier. The majority of these studies perform admirably on datasets of images shot in a controlled environment, but they struggle with more difficult datasets (FER-2013) that have higher image variation and partial faces. The nonuniform features of the human face as well as changes in lighting, shadows, facial posture, and direction are the key obstacles. Techniques of deep learning have been studied as a set of methodologies for gaining scalability and robustness on new forms of data. In this paper, we look at how well-known deep learning techniques (e.g. GoogLeNet, AlexNet) perform when it comes to facial expression identification, and propose an enhanced hybrid deep learning model based on STN for facial emotion recognition, which gives the best feature extraction and classification in one go and maximizes the accuracy for a large number of samples on FERG, JAFFE, FER-2013, and CK+ datasets. It is capable of focusing on the main parts of the face and attaining extensive development over preceding fashions on the FERG, JAFFE, CK+ datasets, and the more challenging one namely FER-2013.},
  archive      = {J_IJPRAI},
  author       = {Nizamuddin Khan and Ajay Vikram Singh and Rajeev Agrawal},
  doi          = {10.1142/S0218001422520280},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2252028},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Enhanced deep learning hybrid model of CNN based on spatial transformer network for facial expression recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of local color simulation method of landscape
painting based on deep learning generative adversarial networks.
<em>IJPRAI</em>, <em>36</em>(14), 2252026. (<a
href="https://doi.org/10.1142/S0218001422520267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional computer simulation landscape painting has the defect that it cannot completely present the painting, the application research of local color simulation method of landscape painting based on deep learning adversarial networks is proposed. Based on the improved generative adversarial networks design, the semantic label hierarchical classification design of landscape paintings is carried out. Through the training and design of generative adversarial networks, the generator and discriminator of landscape painting are designed, and the semantic segmentation algorithm of landscape painting of generative adversarial networks is proposed. Finally, a simulation experiment test is carried out on the local color simulation of landscape painting. The results show that this application method is better than the traditional computer simulation method, it can fully reflect the realism of landscape art painting and the integrity of the picture itself. The texture detail clarity of the generated map is stronger than that of the traditional one, and the semantic content is more accurate. It has important practical reference value.},
  archive      = {J_IJPRAI},
  author       = {Lihao He},
  doi          = {10.1142/S0218001422520267},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2252026},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Application of local color simulation method of landscape painting based on deep learning generative adversarial networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance analysis of federated learning aggregation
algorithms for secure and efficient data handling. <em>IJPRAI</em>,
<em>36</em>(14), 2252024. (<a
href="https://doi.org/10.1142/S0218001422520243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional machine learning projects have revolved around training the model with the help of previously observed data to be able to predict output for future unknown data. In the current scenario, when the data generated are huge, centralized training of the model becomes inefficient. Hence, distributed approach with client server model has to be used for training the models. This introduces data handling and critical data privacy issues. This paper concentrates on Federated learning (FL) which builds a model for the server by aggregating the parameters obtained from the local models of the client devices. The research work focuses on design and evaluation of three new FL algorithms against the average of the performances of the local models. The evolved approach considering weights of the local models proportional to accuracy of the local model is found to be the most accurate and better than the centralized approach. The evaluation is done using three different algorithms belonging to regression and classification on multiple datasets. It is observed that there is only one round of communication between the clients and server required in the federated learning setup to achieve the benchmarked accuracy set by the centralized setup. This is a considerable development and state-of-the-art approach to reduce communication and computation costs.},
  archive      = {J_IJPRAI},
  author       = {Vaibhav Agarwal and Girija Attigeri and Sucheta V. Kolekar},
  doi          = {10.1142/S0218001422520243},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2252024},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Performance analysis of federated learning aggregation algorithms for secure and efficient data handling},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design of graph neural network social recommendation
algorithm based on coupling influence. <em>IJPRAI</em>, <em>36</em>(14),
2251016. (<a href="https://doi.org/10.1142/S0218001422510168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosively growing amount of online information, recommender system becomes an important tool to help users efficiently find their desired information. In this paper, we propose a Graph Neural Network Social Recommendation Based on Coupled Influence by analyzing the social influence of 2-level friends (CI-GNNSR). First, we mine the user’s historical rating information and second-degree social information. Then, to learn the feature representation of users and movies, multiple Graph Attention Networks (GAT) are used to model the user-movie Graph and social network Graph. Our algorithm uses an attention-based memory network to learn the interest influence representation between users and their collaborative friends, which can distinguish the related factors among different users’ friends. The experiment results show that CI-GNNSR enhances the accuracy of recommendation by considering users’ social influence factors from multiple perspectives.},
  archive      = {J_IJPRAI},
  author       = {Wei Qi and Jiaxu Yu and Qiao Liang and Zhenzhen Huang and Zhiou Xu and Haifeng Jiang},
  doi          = {10.1142/S0218001422510168},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2251016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Design of graph neural network social recommendation algorithm based on coupling influence},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A pattern mining approach for improving speech emotion
recognition. <em>IJPRAI</em>, <em>36</em>(14), 2250045. (<a
href="https://doi.org/10.1142/S0218001422500458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech-driven user interfaces are becoming more common in our lives. To interact with such systems naturally and effectively, machines need to recognize the emotional states of users and respond to them accordingly. At the heart of the emotion recognition research done to this end lies the emotion representation that enables machines to learn and predict emotions. Speech emotion recognition studies use a wide range of low-to-high-level acoustic features for representation purposes such as LLDs, their functionals, and BoAW. In this paper, we present a new method for extracting a novel set of high-level features for classifying emotions. For this purpose, we (1) reduce the dimension of discrete-time speech signals, (2) perform a quantization operation on the new signals and assign a distinct symbol to each quantization level, (3) use the symbol sequences representing the signals to extract discriminative patterns that are capable of distinguishing different emotions from each other, and (4) generate a separate set of features for each emotion from the extracted patterns. Experimental results show that pattern features outperform Energy, Voicing, MFCC, Spectral, and RASTA feature sets. We also demonstrate that combining the pattern-based features and the acoustic features further improves the classification performance.},
  archive      = {J_IJPRAI},
  author       = {Umut Avci},
  doi          = {10.1142/S0218001422500458},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2250045},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A pattern mining approach for improving speech emotion recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-supervised multi-source transfer learning for motor
imagery recognition. <em>IJPRAI</em>, <em>36</em>(14), 2250041. (<a
href="https://doi.org/10.1142/S0218001422500410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of motor imagery (MI) recognition, poor generalization and low recognition performance are major challenges. An MI recognition method based on semi-supervised learning and multi-source transfer learning is proposed. In this approach, samples are transferred from some source domains to the target domain using the multi-source transfer learning method. The source domains selection method based on distribution similarity is designed to select source domains with similar distribution to the target domain, and samples with high information entropy are selected from these source domains for transfer. In this regard, we propose a semi-supervised learning labeling method for labeling the unlabeled samples of the target domain, which utilizes the labeling information from a few labeled samples without increasing the labeling cost. The sample confidence measurement method and the dynamic adjustment mechanism are proposed to ensure labeling accuracy and minimize the influence of mislabeled samples. A fusion classification model can identify the new sample in the target domain. As a measure of the effectiveness of the proposed method, four types of MI from the BCI Competition IV dataset 2A were used to evaluate the recognition ability, and the outcomes confirmed an excellent recognition performance as well as a superior training efficiency when compared with the currently used methods.},
  archive      = {J_IJPRAI},
  author       = {Chang Gao and Jie Sun},
  doi          = {10.1142/S0218001422500410},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2250041},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Semi-supervised multi-source transfer learning for motor imagery recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Form-finding method of site road from the perspective of
meta-design. <em>IJPRAI</em>, <em>36</em>(14), 2250039. (<a
href="https://doi.org/10.1142/S0218001422500392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Site road alignment is one of the main elements of architectural environmental design [B. Holdsworth, Refocus 6 (1) (2005) 58–60]. It is difficult for traditional methods to achieve both qualitative exploration and quantitative optimization objectives, and optimization algorithms can only optimize quantitative objectives. On the other hand, the shape of the site road is subject to various other human interventions besides the designer, which is a multi-objective problem. Based on the idea of meta-design, this paper proposes a new method for “form-finding” of site roads. This method develops the architecture and components of an expert system, which can handle both qualitative and quantitative objectives in conceptual design, and can realize various human interventions. Component development combines site specification, recursive algorithm, and genetic algorithm, which treats human intervention as a factor of variation, allows for qualitative exploration of different preferences, and finally demonstrates the capabilities of this new approach through case studies.},
  archive      = {J_IJPRAI},
  author       = {Yong Liu and Junhang Lin and Rongsheng Cai},
  doi          = {10.1142/S0218001422500392},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2250039},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Form-finding method of site road from the perspective of meta-design},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel SDMFO-MBSVM-based segmentation and classification
framework for glaucoma detection using OCT and fundus images.
<em>IJPRAI</em>, <em>36</em>(14), 2250038. (<a
href="https://doi.org/10.1142/S0218001422500380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma is an eye disease that causes loss of vision and blindness by damaging a nerve in the back of the eye called optic nerve. The optic nerve collects the visual information from the eyes and transmits to the brain. Glaucoma is mainly caused by an abnormal high pressure in the eyes. Over time, the increased pressure can erode the tissues of optic nerve, leading to vision loss or blindness. If it is diagnosed in advance, then only it can prevent the vision loss. To diagnose the glaucoma, it must accurately differentiate between the optic disc (OD), optic cup (OC), and the retinal nerve fiber layer (RNFL). The segmentation of the OD, OC, and RNFL remains a challenging issue under a minimum contrast image of boundaries. Therefore, in this study, an innovative method of Hybrid Symbiotic Differential Evolution Moth-Flame Optimization (SDMFO)-Multi-Boost Ensemble and Support Vector Machine (MBSVM)-based segmentation and classification framework is proposed for accurately detecting the glaucoma disease. By using Group Search Optimizer (GSO), the affected parts of the OD, OC and RNFL are segmented. The proposed SDMFO-MBSVM method is executed in MATLAB site, its performance is analyzed with three existing methods. From the comparison, the accuracy of the proposed method in OD segmentation gives better results of 3.37%, 4.54% and 2.22%, OC segmentation gives better results of 2.22%, 3.37% and 4.54%, and RNFL segmentation gives the better results of 3.37%, 97.21% and 5.74%.},
  archive      = {J_IJPRAI},
  author       = {P. Rayavel and C. Murukesh},
  doi          = {10.1142/S0218001422500380},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2250038},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel SDMFO-MBSVM-based segmentation and classification framework for glaucoma detection using OCT and fundus images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SSD optimization model based on shallow feature fusion.
<em>IJPRAI</em>, <em>36</em>(13), 2259033. (<a
href="https://doi.org/10.1142/S0218001422590339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection has been an important research branch in the field of computer vision. The single-shot-detection (SSD) is an object detection model based on deep learning, which can achieve a good balance between the detection accuracy and the detection speed, but has the problem of poor recognition accuracy for small objects. To address this limitation, this paper improves the structure of the SSD feature pyramid and up-samples the shallow feature map with small object information and fuses it with the upper feature map, thus enhancing the ability of the shallow feature map to represent detailed information. In this way, not only the overall detection accuracy of the SSD is improved, but also a relatively high detection speed is maintained. The proposed model is verified by experiments on two common datasets, the Pascal VOC and MS COCO datasets. On the Pascal VOC07+12, MS COCO14, and VOC07+12+COCO datasets, the improved model achieves the mean average precision values of 80.1% (+3.3% compared with the conventional model), 49.9% (+6.8%), and 82.1% (+3.0%), respectively. Meanwhile, the proposed model can achieve the detection speed of 42.2 frames per second.},
  archive      = {J_IJPRAI},
  author       = {Zhe Yang and Zi-Yu Bu and Chun-Ping Liu},
  doi          = {10.1142/S0218001422590339},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2259033},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {SSD optimization model based on shallow feature fusion},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence-aided computation for green’s
function of the spherical layered earth. <em>IJPRAI</em>,
<em>36</em>(13), 2259030. (<a
href="https://doi.org/10.1142/S0218001422590303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, there are considerable challenges associated with the theoretical derivation and numerical calculation of Green’s function for spherical layered earths. In order to study the coupling effect between wide-area interconnected systems and the earth, this earth model is widely used. Artificial intelligence methods have been applied in order to overcome these challenges. First, Green’s function in the form of infinite Legendre series is derived using intelligent symbolic operations, and the weight function of Legendre series is recursively computed by means of a recursive algorithm. It is on this basis that the intelligent complex image method has been developed for solving spherical layered Green’s functions, which transforms the summation of infinite series of Green’s functions into the superposition of complex image potentials. Additionally, the upper error limit of the algorithm has been determined, and examples have been provided to demonstrate the accuracy of the algorithm. A solution based on multiple precision algorithms has been proposed to resolve the numerical singularity problem and the extremely slow convergence of the spherical layered Green’s function at the earth’s scale. It has been demonstrated that the intelligent complex image method has advantages in terms of computing speed and accuracy. A spherical layered Green’s function at the earth scale is presented in this paper as an effective and intelligent solution.},
  archive      = {J_IJPRAI},
  author       = {Zhuohong Pan and Baoquan Wang and Jianben Liu and Yan Wang and Yang Tian and Haocheng Wang},
  doi          = {10.1142/S0218001422590303},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2259030},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Artificial intelligence-aided computation for green’s function of the spherical layered earth},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). CenterNet plus: Multiscale prediction with FPN for
CenterNet. <em>IJPRAI</em>, <em>36</em>(13), 2259024. (<a
href="https://doi.org/10.1142/S0218001422590248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the CenterNet object detection method can be used to achieve high accuracy, it cannot be used to detect objects with overlapping or almost overlapping centers. However, a good trade-off between detection speed and accuracy cannot be achieved when utilizing this method. We improved a series of backbones using CenterNet, output the fusion of multiple feature maps in backbone, and used the feature pyramid network (FPN) mechanism for multiscale object detection. Additionally, we improved the head of the detector and considered adding intersection over union (IoU) branches. Finally, the loss function was improved to improve detection accuracy. Based on the above research, the CenterNet Plus object detection method is proposed in this paper. Through experiments on the COCO dataset, it can be seen that the use of a multiscale FPN mechanism not only solves the problem of center point overlap but also helps improve the accuracy of detection. CenterNet Plus can be used to greatly improve the detection accuracy on the premise of having a higher detection speed.},
  archive      = {J_IJPRAI},
  author       = {Xianrang Shi and Yang Su and Yan Ti and Tinglun Song},
  doi          = {10.1142/S0218001422590248},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2259024},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {CenterNet plus: Multiscale prediction with FPN for CenterNet},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EntailSum: An entailment-based approach to aspect-based text
summarization with automated aspect adaptation. <em>IJPRAI</em>,
<em>36</em>(13), 2259017. (<a
href="https://doi.org/10.1142/S0218001422590170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based summarization differs from generic text-summarization in which the generated summary must be conditioned on a given topic. A fundamental challenge to the aspect-based summarization approach is the lack of labeled data for training models, which limits the usage of supervised methods. One approach to address this issue is to introduce human intervention to generate unique datasets per aspect. However, there is a large number of possible aspects to summarize which makes this option impossible to scale. This limits the use of typical modeling techniques, and requires methods which excel in few-shot, or ideally zero-shot regimes. Hence, in this research, we propose a modular, two-step approach that does not need any aspect-based supervision. This research combines recent advances in zero-shot text classification and generic summarization in a novel way. The backbone of the proposed approach is a transformer network trained for the task of textual entailment, which is used to reduce a document to the set of on topic sentences. In the experiments, our model achieves a new state of the art compared to other unsupervised models on the MA-News dataset (ROUGE-1 35.70 and ROUGE-2 15.52), and even outperforms fine-tuned models without any supervision of its own.},
  archive      = {J_IJPRAI},
  author       = {Zachary Ankner and Purvaja Balaji and Ye Zhu and Chun Keat Hiew and Patrick Wang and Amar Gupta},
  doi          = {10.1142/S0218001422590170},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2259017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {EntailSum: An entailment-based approach to aspect-based text summarization with automated aspect adaptation},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel optimal design of SSR response signal processing
algorithms based on GPU. <em>IJPRAI</em>, <em>36</em>(13), 2258008. (<a
href="https://doi.org/10.1142/S0218001422580083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the key problems of secondary surveillance radar signal debugging on special devices such as DSP and FPGA, a parallel processing scheme of secondary surveillance radar response signal is proposed based on CPU–GPU architecture. It can effectively reduce the difficulty of code development and improve the portability of program. The parallel optimization design of each processing model of response signal is made through the characteristics of shared memory in CPU–GPU architecture to improve the processing speed of the algorithm. The proposed scheme is tested and analyzed on different graphics cards by the secondary surveillance radar Mode-5 response signal in this paper. The experimental results showed that it takes 8390.52960 us to implement the signal processing algorithm based on NVIDIA Tesla K40c graphics card, which can save 51.98% of time than NVIDIA Quadro K4200 graphics card, and makes it possible to do the real-time processing of the secondary surveillance radar signal.},
  archive      = {J_IJPRAI},
  author       = {Ke Li and Jianqiang Zhang and Shengjun Li},
  doi          = {10.1142/S0218001422580083},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2258008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Parallel optimal design of SSR response signal processing algorithms based on GPU},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An interpretable time series clustering neural network based
on shape feature extraction. <em>IJPRAI</em>, <em>36</em>(13), 2254022.
(<a href="https://doi.org/10.1142/S0218001422540222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series is a very common but important data type. A large number of time series data are generated in various professional research fields and daily life. Although there are many models being developed to deal with time series, the cluster methods for time series are insufficient and need to improve. This paper is focused on time series clustering, which uses deep learning approach to discover the shape characteristics of time series. We establish a new neural network model of time series clustering to jointly optimize the representation learning and clustering tasks of time series. Focusing on shape features with time series, we built the Soft-DTW layer into the neural network to learn the interpretable time series representation. Maximized regularization mutual information is used to jointly optimize representation learning and clustering tasks. Experiments show that this model can help obtain an excellent representation of time series. In comparison with the benchmark model, the best clustering effect is achieved in the proposed model on multiple data sets. This model has broad applicability in time series data.},
  archive      = {J_IJPRAI},
  author       = {Weide Li and Zihan Hao and Zhihe Zhang},
  doi          = {10.1142/S0218001422540222},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2254022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An interpretable time series clustering neural network based on shape feature extraction},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A structure preservation and denoising low-light enhancement
model via coefficient of variation. <em>IJPRAI</em>, <em>36</em>(13),
2254018. (<a href="https://doi.org/10.1142/S0218001422540180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a structure-preserving and denoising low-light enhancement method that uses the coefficient of variation. First, we use the coefficient of variation to process the original low-light image, which is used to obtain the enhanced illumination gradient reference map. Second, we use the total variation (TV) norm to regularize the reflectance gradient, which is used to maintain the smoothness of the image and eliminate the artifacts in the reflectance estimation. Finally, we combine the above two constraint terms with the Retinex theory, which contains the denoising regular term. The final enhanced and denoised low-light image is obtained by iterative solution. Experimental results show that our method can achieve superior performance in both subjective and objective assessments compared with other state-of-the-art methods (the source code is available at: https://github.com/bbxavi/SPDLEM .).},
  archive      = {J_IJPRAI},
  author       = {Xingtai Wu and Bin Wu and Jingyuan He and Bin Fang and Zhaowei Shang and Mingliang Zhou},
  doi          = {10.1142/S0218001422540180},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2254018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A structure preservation and denoising low-light enhancement model via coefficient of variation},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Plants disease image classification based on lightweight
convolution neural networks. <em>IJPRAI</em>, <em>36</em>(13), 2254013.
(<a href="https://doi.org/10.1142/S0218001422540131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plants diseases is a major threat to agricultural production. Reduced yield due to plant diseases can lead to immeasurable economic losses. Therefore, the detection and classification of plant diseases are of great significance. Most of the existing plant disease detection methods focus on improving the identification accuracy. However, besides accuracy, real-time performance cannot be ignored. In this paper, a new module named 2-way residual dense layer is presented to effectively decrease the number of parameters in our network. In this module, depth separable convolution is introduced, which reduces the amount of parameter calculation and achieves a performance of over 98%. Our network is verified by an open dataset which includes 4503 images from four classes, including Mango, Arjun, Alstonia Scholaris, Guava, Bael, Jamun, Jatropha, Pongamia Pinnata, Basil, Pomegranate, Lemon, and Chinar. The leaf images of these plants have healthy and diseased condition. The experimental results showed that this method can be practically applied to the identification of plant leaf diseases and provide a basis for the identification of other leaf diseases.},
  archive      = {J_IJPRAI},
  author       = {Lili Liao and Bo Li and Jinhong Tang},
  doi          = {10.1142/S0218001422540131},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2254013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Plants disease image classification based on lightweight convolution neural networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DeepJoint segmentation-based lung segmentation and hybrid
optimization-enabled deep learning for lung nodule classification.
<em>IJPRAI</em>, <em>36</em>(13), 2252021. (<a
href="https://doi.org/10.1142/S0218001422520218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer is an aggressive disease among all cancer-based diseases, because of causing huge mortality in humans. Thus, earlier discovery is a basic task for diagnosing lung cancer and it helps increase the survival rate. Computed tomography (CT) is a powerful imaging technique used to discover lung cancer. However, it is time-consuming for examining each CT image. This paper develops an optimized deep model for classifying the lung nodules. Here, the pre-processing is done using Region of Interest (ROI) extraction and adaptive Wiener filter. The segmentation is done using the DeepJoint model wherein distance is computed with a congruence coefficient for extracting the segments. The nodule identification is done by a grid-based scheme. The features such as Global Binary Pattern (GBP), Texton features, statistical features, perimeter and area, barycenter difference, number of slices, short axis and long axis and volume are considered. The lung nodule classification is done to classify part solid, solid nodules and ground-glass opacity (GGO) using Deep Residual Network (DRN), which is trained by the proposed Shuffled Shepard Sine–Cosine Algorithm (SSSCA). The developed SSSCA is generated by the integration of the Sine–Cosine Algorithm (SCA) and Shuffled Shepard Optimization Algorithm (SSOA). The proposed SSSCA-based DRN outperformed with the highest testing accuracy of 92.5%, sensitivity of 93.2%, specificity of 83.7% and F 1 -score of 81.5%.},
  archive      = {J_IJPRAI},
  author       = {P. Chinniah and Balajee Maram and P. Velrajkumar and Ch. Vidyadhari},
  doi          = {10.1142/S0218001422520218},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2252021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DeepJoint segmentation-based lung segmentation and hybrid optimization-enabled deep learning for lung nodule classification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive compute offloading algorithm for metasystem based
on deep reinforcement learning. <em>IJPRAI</em>, <em>36</em>(13),
2252019. (<a href="https://doi.org/10.1142/S021800142252019X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been a lot of research on edge-computing task offloading in deep reinforcement learning (DRL). Deep reinforcement learning is one of the important algorithms in the current AI field, but there is still room for improvement in the time cost and adaptive correction ability of the algorithm. This paper studies the application of DRL algorithms in edge-computing task offloading, and its key innovation is to propose an MADRLCO algorithm, which is based on the design idea of the Actor–Critic framework, uses the DNN model to act as an Actor, and can more accurately locate the initial decision through iterative training, and use the LSTM model to optimize the Critic, which can be more accurate. The optimal decision can be located in a short period of time. The main work of this paper is divided into three parts: (1) The AC algorithm of the Actor–Critic framework in DRL is proposed to be applied to edge-computing task offloading. (2) To address the weak generalization ability of the basic version of the Actor–Critic algorithm in multi-objective optimization, the sequential quantitative correction and adaptive correction parameter K method are used to optimize the Critic frame, thereby improving the generalization ability of the model in multi-objective decision-making and improving the rationality of decision-making results. (3) Aiming at the problem of large time cost in the critical framework of the model, a search algorithm for resource allocation-related parameters based on the time-series prediction method is proposed (time-series forecasting is a research branch of pattern recognition), which reduces the time overhead of the algorithm and improves the adaptive correction capability of the model. The algorithm in this paper can adapt to not only the time-varying network channel state, but also the time-varying number of device connections. Finally, it is proved by experiments that compared with the DRL calculation offloading algorithm based on DNN plus binary search, the MADRLCO algorithm reduces the model training time by 66.27%, and in the environment of the time-varying number of devices in the metasystem, the average model average. The standard calculation rate is 0.0403 higher than that of the current optimal algorithm.},
  archive      = {J_IJPRAI},
  author       = {Chunxin Wang and Wensheng Wang and Wenjing Li and Zhu Liu and Jinhong Zhu and Nan Zhang},
  doi          = {10.1142/S021800142252019X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2252019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Adaptive compute offloading algorithm for metasystem based on deep reinforcement learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GAAT: Group adaptive adversarial training to improve the
trade-off between robustness and accuracy. <em>IJPRAI</em>,
<em>36</em>(13), 2251015. (<a
href="https://doi.org/10.1142/S0218001422510156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial training is by far one of the most effective methods to improve the robustness of deep neural networks against adversarial examples. However, the trade-off between robustness and accuracy is still a challenge in adversarial training. Previous methods used adversarial examples with a fixed perturbation budget or specific perturbation budgets for each example, which is inefficient in improving the trade-off and lacks the ability to control the trade-off flexibly. In this paper, we show that the largest element of logit, z max , can roughly represent the minimum distance between an example and its neighboring decision boundary. Thus, we propose group adaptive adversarial training (GAAT) that divides the training dataset into several groups based on z max and develops a binary search algorithm to determine the group perturbation budgets for each group. Using the group perturbation budgets to perform adversarial training can fine-tune the trade-off between robustness and accuracy. Extensive experiments conducted on CIFAR-10 and ImageNet-30 show that our GAAT can achieve a more perfect trade-off than TRADES, MMA, and MART.},
  archive      = {J_IJPRAI},
  author       = {Yaguan Qian and Xiaoyu Liang and Ming Kang and Bin Wang and Zhaoquan Gu and Xing Wang and Chunming Wu},
  doi          = {10.1142/S0218001422510156},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2251015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {GAAT: Group adaptive adversarial training to improve the trade-off between robustness and accuracy},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling and prediction of NOx emission of a coal-fired
boiler by a learning-based KNN mechanism. <em>IJPRAI</em>,
<em>36</em>(13), 2251014. (<a
href="https://doi.org/10.1142/S0218001422510144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The production of nitrogen oxides (NO x ) in coal-fired boiler combustion has been found as a significant source of environmental pollution. Flue gas denitrification is a standard NO x control technology for small- and medium-sized coal-fired boilers. Achieving steady-state control in flue gas denitrification can be challenging since coal-fired boiler systems have complexity and significant delay. A model based on a learning-based K -nearest neighbor ( K NN) query mechanism created for NO x output soft prediction is proposed in this study. First, a knowledge base in the proposed model is established through spatial division in accordance with the previous combustion parameters. Moreover, the clusters are established based on the output NO x values. Next, the domain of values of combustion parameters for the respective cluster is obtained. Second, the optimal cluster is selected using the knowledge base for an input vector q with new combustion parameters ( q 1 , q 2 , … , q n ) . Lastly, the K tuples in the cluster the closest to the values of the input vector q are adopted to predict the output NO x value of q . The predicted NO x value can serve as a feedforward signal to control the output of the reductant for accurate denitrification. As revealed by the experimental results, the proposed practical model, capable of conducting the prediction in a sub-second time, is highly competitive with existing techniques. Furthermore, a deep learning algorithm (DLA) is designed, whereas it underperforms the K NN model.},
  archive      = {J_IJPRAI},
  author       = {Xin Song and Liang Zhu and Haibo Liu and Yonggang Wei},
  doi          = {10.1142/S0218001422510144},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2251014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Modeling and prediction of NOx emission of a coal-fired boiler by a learning-based KNN mechanism},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tangut character stroke detection with improved hough
transform. <em>IJPRAI</em>, <em>36</em>(13), 2250042. (<a
href="https://doi.org/10.1142/S0218001422500422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the research of Tangut character recognition, it was attempted to detect the stroke of character with standard Hough transform (SHT), but hindered by the inability of SHT to detect the curve-line. In this paper, Hough transform with guidance of endpoints (HTGE) was proposed to achieve better performance on the aspect of curve and short line detection. HTGE is implemented based on the conception of hypothesis and verification, first, to assume there is line between each pair of endpoints, and then the existence of line is checked according to the corresponding area accumulated value in the parameter domain. With setting up of test object and evaluation criterion, the experiment was carried out to determine the key parameter for the best performance, and it can be concluded from the experiment result that considerable performance can be achieved with HTGE in the application of line detection.},
  archive      = {J_IJPRAI},
  author       = {Yifei Meng and Peng Zhang and Bin Meng and Minfei Hu},
  doi          = {10.1142/S0218001422500422},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2250042},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Tangut character stroke detection with improved hough transform},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards an intrinsic interpretability approach for
multimodal hate speech detection. <em>IJPRAI</em>, <em>36</em>(13),
2250040. (<a href="https://doi.org/10.1142/S0218001422500409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of social media, multimodal hate speech that relies on images and text has become an emerging way of spreading hate. The detection of multimodal hate speech is gradually becoming an increasingly challenging task. While many works based on neural networks and multimodal machine learning were proposed to detect multimodal hate speech, only few attempts have been made in terms of the interpretability of the task. This leads to difficulties in analyzing prediction results and model improvement. Therefore, this paper investigates the interpretable multimodal hate speech detection task and develops an intrinsically interpretable deep learning method by leveraging the multimodal architecture. Specifically, we leverage a multimodal pretrained model as the backbone of the final detection results and parallel an interpretability module via a joint training approach, which calculates the input tokens and fine-grained tags through a filter-gate attention mechanism. The interpretability module provides an interpretable basis for the final result judgment. We conduct experiments on the hate speech detection dataset and demonstrate that our proposed method not only significantly outperforms other methods but also provides interpretable insights into the decisions of our model.},
  archive      = {J_IJPRAI},
  author       = {Pengfei Du and Yali Gao and Xiaoyong Li},
  doi          = {10.1142/S0218001422500409},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2250040},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Towards an intrinsic interpretability approach for multimodal hate speech detection},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiple-AGV path planning method for two industrial links.
<em>IJPRAI</em>, <em>36</em>(12), 2259029. (<a
href="https://doi.org/10.1142/S0218001422590297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, increasing automatic guided vehicles (AGVs) are being introduced into the production line. The path planning and scheduling of multiple AGVs are complex tasks that are closely related to application scenarios. In this study, a robot’s working area was divided to minimize the collision probability. Improved ant colony optimization (ACO) and improved probabilistic road map (PRM) algorithms were used for path planning to enhance the transportation efficiency. The priorities of AGVs were specified. The collision criteria were determined, and the responses for different collision types were provided.},
  archive      = {J_IJPRAI},
  author       = {Song Chen and Qian Zhang and Guo-Chao He and Yue-Bo Wu},
  doi          = {10.1142/S0218001422590297},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2259029},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multiple-AGV path planning method for two industrial links},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new network pruning framework based on rewind.
<em>IJPRAI</em>, <em>36</em>(12), 2259028. (<a
href="https://doi.org/10.1142/S0218001422590285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model pruning is one of the main methods of deep neural network model compression. However, the existing model pruning methods are inefficient, there is still a lot of redundancy in the network, and the pruning has a great impact on the accuracy. In addition, the traditional pruning process usually needs to fine-tune the network to restore accuracy, and fine-tuning has a limited effect on accuracy recovery, so it is difficult to achieve a high level of accuracy. In this paper, we propose a new neural network pruning framework: the channel sparsity is realized by introducing a scale factor, and the sparse network is pruned by setting a global threshold, which greatly improves the efficiency of pruning. After pruning, this paper proposes a rewind method to restore the accuracy, that is, save the weight after training, and then reload it on the network for training to restore the accuracy. In addition, we also study the best rewind point of the three networks. The experimental results show that our method significantly reduces the number of parameters and FLOPs without affecting or even improving the accuracy, and the rewind method proposed by us achieves a better accuracy recovery effect than fine-tuning. At the same time, we find that the epoch with the highest accuracy is the best rewind point, and the accuracy is the highest after saving its corresponding weight and retraining the model.},
  archive      = {J_IJPRAI},
  author       = {Haoran Yu and Weiwei Zhang and Hongbo Zhou and Xin Ma},
  doi          = {10.1142/S0218001422590285},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2259028},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A new network pruning framework based on rewind},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A simplex method-based bacterial colony optimization
algorithm for data clustering analysis. <em>IJPRAI</em>,
<em>36</em>(12), 2259027. (<a
href="https://doi.org/10.1142/S0218001422590273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data clustering is the task of separating data samples into a set of clusters. K -means is a popular partitional clustering algorithm. However, it has a lot of weaknesses, including sensitivity to initialization and the ability to become stuck in local optima. Hence, nature-inspired optimization algorithms were applied to the clustering problem to overcome the limitations of the K -means algorithm. However, due to the high-dimensionality of a search space, the nature-inspired optimization algorithm suffers from local optima and poor convergence rates. To address the mentioned issues, this paper presents a simplex method-based bacterial colony optimization (SMBCO) algorithm. The simplex method is a stochastic variant approach that improves population diversity while increasing the algorithm’s local searching ability. The potential and effectiveness of the proposed SMBCO clustering algorithm are assessed using a variety of benchmark machine learning datasets and the generated groups were evaluated using different performance measures. When compared to several well-known nature-inspired algorithms, the experimental results reveal that the SMBCO model produces superior clustering efficiency and a faster convergence rate.},
  archive      = {J_IJPRAI},
  author       = {S. Suresh Babu and K. Jayasudha},
  doi          = {10.1142/S0218001422590273},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2259027},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A simplex method-based bacterial colony optimization algorithm for data clustering analysis},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A particle swarm with local decision algorithm for
functional distributed constraint optimization problems.
<em>IJPRAI</em>, <em>36</em>(12), 2259025. (<a
href="https://doi.org/10.1142/S021800142259025X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional Distributed Constraint Optimization Problems (F-DCOPs) are a constraint processing framework for continuous variables in the multi-agent system. Particle swarm optimization-based F-DCOP (PFD) is a population-based algorithm to solve F-DCOP collaboratively. Although it can significantly reduce the computational overhead and memory requirements, its solution depends on the decision of root agent in the Breadth First Search (BFS) pseudo-tree and it is easy to fall into local optimum. To solve the above problems, this paper designed an improved PFD algorithm with Local Decision named PFD-LD, which effectively reduces the dependence on root agent through local decision. In addition, a mutation operator is used to avoid falling into local optimum. It is proved that PFD-LD is an anytime algorithm and local decision can expand the search of the solution space. Finally, the extensive experiments based on four types of benchmark problems show that the proposed algorithm outperforms state-of-the-art F-DCOP solving algorithms.},
  archive      = {J_IJPRAI},
  author       = {Meifeng Shi and Xin Liao and Yuan Chen},
  doi          = {10.1142/S021800142259025X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2259025},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A particle swarm with local decision algorithm for functional distributed constraint optimization problems},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Global mittag-leffler stability and global asymptotic
ω-period for fractional-order cohen–grossberg neural networks with
time-varying delays. <em>IJPRAI</em>, <em>36</em>(12), 2259023. (<a
href="https://doi.org/10.1142/S0218001422590236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic behaviors for fractional-order Cohen–Grossberg neural networks with time-varying delays (FCGNND) are studied in this paper. By introducing the Mittag-Leffler (ML) function, based on properties of fractional calculus, the differential mean-value theorem and Arzela–Ascoli theorem, we give some sufficient theorems to determine the boundedness, global Mittag-Leffler stability (GMLS) and global asymptotical ω -periodicity (GAP) for FCGNND. Finally, a numerical example is given to verify the effectiveness of the theorems.},
  archive      = {J_IJPRAI},
  author       = {Wangdong Jiang and Zhiying Li and Yuehong Zhang},
  doi          = {10.1142/S0218001422590236},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2259023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Global mittag-leffler stability and global asymptotic ω-period for fractional-order Cohen–Grossberg neural networks with time-varying delays},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monitoring the growth status of corn crop from UAV images
based on dense convolutional neural network. <em>IJPRAI</em>,
<em>36</em>(12), 2257007. (<a
href="https://doi.org/10.1142/S0218001422570075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring corn crop growth status is of great significance to crop production, breeding, and seed production. The Unmanned Aerial Vehicles’ (UAVs) technology makes it possible to use computer vision technology to identify corn growth stage intelligently. A model customized for corn growth status monitoring based on a dense convolutional neural network (CM-CNN) was proposed, including a two-way dense module and a new activation function ELU. The two-way dense module enlarges the receptive field, while the ELU alleviates gradient disappearance and speeds up learning in deep neural networks. Dense architecture concatenates all the previous layer features to enhance feature reuse. The proposed CM-CNN performs well in classifying corn growth stages. Experimental results show that CM-CNN is a state-of-the-art method, with an accuracy of its relevant data up to 99.3%. Compared with other CNN models, viz. AlexNet, ZFNet, VGG, InceptionV3, Xception and ResNet, fewer parameters are in CM-CNN.},
  archive      = {J_IJPRAI},
  author       = {Yu Li and Jia Zhu and Yuling Xing and Zhangyan Dai and Jin Huang and Saeed-Ul Hassan},
  doi          = {10.1142/S0218001422570075},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2257007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Monitoring the growth status of corn crop from UAV images based on dense convolutional neural network},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Person re-identification method based on the construction of
graph convolutional network with attribute feature. <em>IJPRAI</em>,
<em>36</em>(12), 2256019. (<a
href="https://doi.org/10.1142/S0218001422560195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To fully pay attention to identity-sensitive feature information and utilize the correlations of inter-attributes and attributes-body parts, this paper proposes a person re-identification (re-ID) method based on the construction of graph convolutional network (GCN) with crucial attribute feature and body parts. First, it establishes the multiscale context-aware network (MSCAN) using dilated convolution with different expansion ratios, which can learn multiscale context information and obtain diversified global features. Subsequently, the human parsing model is utilized to extract the body part features. According to the attribute importance degree, the paper constructs low-dimensional GCN integrating the vital attributes and body parts of person descriptions to obtain discriminative local features. Finally, based on attribute prediction, it reduces the range of the images to be matched with discriminating possible objects from query images, thereby simplifying retrieval process. The experimental results demonstrate that the novel designed method can effectively improve person re-ID performance and achieve competitive evaluation results on typical public testing datasets.},
  archive      = {J_IJPRAI},
  author       = {Xiuhua Hu and Yingyu Liang and Yan Hui and Xi Wu and Huan Liu and Xuyang Hu},
  doi          = {10.1142/S0218001422560195},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2256019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Person re-identification method based on the construction of graph convolutional network with attribute feature},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3D human pose estimation via spatio-temporal matching from
monocular RGB images. <em>IJPRAI</em>, <em>36</em>(12), 2255017. (<a
href="https://doi.org/10.1142/S0218001422550175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) human pose estimation aims to locate 3D keypoints of individuals from given input RGB images. For two-dimensional (2D) human pose estimation problems, majority methods inferring 2D poses are from 2D heatmaps. However, it is hard to extend this method to 3D poses inferring area which makes computational loads increase sharply. To address the above problem, we propose STM-CNN method to estimate reconstruction coefficient matrix to calculate the final 3D pose instead of estimating 3D heatmaps to decrease the computational loads. First, STM-CNN does a preprocessing procedure to calculate a set of shape and weight bases. Second, STM-CNN infers a 2D matrix called reconstruction coefficient from the STM-CNN architecture. Third, STM-CNN utilizes the preprocessing shape and weight bases and estimated reconstruction coefficient matrix to calculate the final 3D pose. Meanwhile, STM-CNN method achieves better performances compared with the state-of-the-art methods on Human3.6M.},
  archive      = {J_IJPRAI},
  author       = {Jielu Yan and Ming Liang Zhou and Bin Fang and Ke Xu},
  doi          = {10.1142/S0218001422550175},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2255017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {3D human pose estimation via spatio-temporal matching from monocular RGB images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pupil detection using hybrid vision transformer.
<em>IJPRAI</em>, <em>36</em>(12), 2255016. (<a
href="https://doi.org/10.1142/S0218001422550163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pupil detection is an indispensable part of the process of eye-tracking. Due of the limitation of existing methods on pupil image quality, we propose a pupil detection method using vision transformer with a hybrid structure. We first extract the local features of the image with CNN, and then obtain the global dependence through the encoder of the transformer, to excavate more accurate information on pupil position. We trained and tested the proposed model on 10 600 images from three publicly available datasets and compared with other pupil detection models. The analysis of the outcomes demonstrated that the hybrid vision transformer was superior to these comparison approaches in terms of accuracy and robustness in locating the pupil position. It achieved a detection rate of more than 90% for pupils within a 5-pixel error in all evaluated datasets.},
  archive      = {J_IJPRAI},
  author       = {Li Wang and Changyuan Wang and Yu Zhang},
  doi          = {10.1142/S0218001422550163},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2255016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Pupil detection using hybrid vision transformer},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tri-modal dense video captioning based on fine-grained
aligned text and anchor-free event proposals generator. <em>IJPRAI</em>,
<em>36</em>(12), 2255014. (<a
href="https://doi.org/10.1142/S021800142255014X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal dense video captioning is a task using multiple information to detect all meaningful events and generate a textual description for each event. The existing works mainly rely on single visual or dual audio-visual modals in dense video captioning, while completely ignoring the text modal (subtitle). The text modal has a similar data structure as the video captions, which provides immediate semantic information to the content description for a video. In this paper, we propose a novel framework, called Two-Stage Cross-Modal Encoding Transformer Network (TS-CMETN), to realize the multi-modal dense video captioning task by fusing multiple features, including audio, visual, and text. First, we design a two-stage feature fusion encoder that hierarchically achieves the intra- and inter-modal information interaction. Second, we propose an anchor-free temporal event proposal module, which efficiently generates event proposals at each time step without the complex anchor calculation. Extensive experiments on the ActivityNet Captions dataset show that our proposed framework achieves high performance. Moreover, our approach can adaptively handle cases of the missing text modal. Our code and data are available at https://github.com/xieyulai/TM-CMETN .},
  archive      = {J_IJPRAI},
  author       = {Jingjing Niu and Yulai Xie and Yang Zhang and Jinyu Zhang and Yanfei Zhang and Xiao Lei and Fang Ren},
  doi          = {10.1142/S021800142255014X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2255014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Tri-modal dense video captioning based on fine-grained aligned text and anchor-free event proposals generator},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep morphological neural networks. <em>IJPRAI</em>,
<em>36</em>(12), 2252023. (<a
href="https://doi.org/10.1142/S0218001422520231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical morphology intends to extract object features such as geometric and topological structures in digital images. Given a set of target images and original images, it is cumbersome and time-consuming to determine the suitable morphological operations and structuring elements. In this paper, we propose deep morphological neural networks, which include a nonlinear feature extraction layer to learn the structuring element correctly and an adaptive layer to select appropriate morphological operations automatically. We demonstrate the applications of object recognition, including hand-written digits, geometric shapes, traffic signs, and brain tumor. Experimental results show the higher computational efficiency and higher accuracy of our developed model as compared against existing convolutional neural network models.},
  archive      = {J_IJPRAI},
  author       = {Yucong Shen and Frank Y. Shih and Xin Zhong and I-Cheng Chang},
  doi          = {10.1142/S0218001422520231},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2252023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep morphological neural networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive image reconstruction for defense against
adversarial attacks. <em>IJPRAI</em>, <em>36</em>(12), 2252022. (<a
href="https://doi.org/10.1142/S021800142252022X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks can fool convolutional networks and make the systems vulnerable to fraud and deception. How to defend against malicious attacks is a critical challenge in practice. Adversarial attacks are often conducted by adding tiny perturbations on images to cause network misclassification. Noise reduction can defend the attacks; however, it is not suited for all the cases. Considering that different models have different tolerance abilities on adversarial attacks, we develop a novel detecting module to remove noise by adaptive process and detect adversarial attacks without modifying the models. Experimental results show that by comparing the classification results on adversarial samples of MNIST and two subclasses of ImageNet datasets, our models can successfully remove most of the noise and obtain detection accuracies of 97.71% and 92.96%, respectively. Furthermore, our adaptive module can be assembled into different networks to achieve detection accuracies of 70.83% and 71.96%, respectively, on the white-box adversarial attacks of ResNet18 and SCD01MLP images. The best accuracy of 62.5% is obtained for both networks when dealing with the black-box attacks.},
  archive      = {J_IJPRAI},
  author       = {Yanan Yang and Frank Y. Shih and I-Cheng Chang},
  doi          = {10.1142/S021800142252022X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2252022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Adaptive image reconstruction for defense against adversarial attacks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification and model method of convolutional features in
sketch images based on deep learning. <em>IJPRAI</em>, <em>36</em>(12),
2252020. (<a href="https://doi.org/10.1142/S0218001422520206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the poor convergence of the current sketch image classification and unable to meet the growing network needs, a classification and model method of convolution feature in sketch image based on deep learning is proposed. Based on the classification principle of deep learning, a classification experiment was carried out on the semantic features of sketch works through the analysis of convolution neural network, convolution feature model, convolution and sketch extraction boundary. The experimental results show that the proposed convolution classification and recognition method is better than the traditional classification method and has higher accuracy in dimensionality reduction and error rate detection than the traditional method. It can better meet the needs of network intelligent processing of sketch image feature classification.},
  archive      = {J_IJPRAI},
  author       = {Jun Chen},
  doi          = {10.1142/S0218001422520206},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2252020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Classification and model method of convolutional features in sketch images based on deep learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-modal fusion sign language recognition based on
residual network and attention mechanism. <em>IJPRAI</em>,
<em>36</em>(12), 2250036. (<a
href="https://doi.org/10.1142/S0218001422500367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign language recognition (SLR) is a useful tool for the deaf-mute to communicate with the outside world. Although many SLR methods have been proposed and have demonstrated good performance, continuous SLR (CSLR) is still challenging. Meanwhile, due to the heavy occlusions and closely interacting motions, there is a higher requirement for the real-time efficiency of CSLR. Therefore, the performance of CSLR needs further improvement. The highlights include: (1) to overcome these challenges, this paper proposes a novel video-based CSLR framework. This framework consists of three components: an OpenPose-based skeleton stream extraction module, a RGB stream extraction module, and a combination module of the BiLSTM network and the conditional hidden Markov model (CHMM) for CSLR. (2) A new residual network with Squeeze-and-Excitation blocks (SEResNet50) for video sequence feature extraction. (3) This paper combines the SEResNet50 module with the BiLSTM network to extract the feature information from video streams with different modalities. To evaluate the effectiveness of our proposed framework, experiments are conducted on two CSL datasets. The experimental results indicate that our method is superior to the methods in the literature.},
  archive      = {J_IJPRAI},
  author       = {Chaoqin Chu and Qinkun Xiao and Yinhuan Zhang and Xing Liu},
  doi          = {10.1142/S0218001422500367},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2250036},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-modal fusion sign language recognition based on residual network and attention mechanism},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Mental workload artificial intelligence assessment of
pilots’ EEG based on multi-dimensional data fusion and LSTM with
attention mechanism model. <em>IJPRAI</em>, <em>36</em>(11), 2259035.
(<a href="https://doi.org/10.1142/S0218001422590352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {EEG has been proved to be an effective tool for researchers’ cognition and mental workload by detecting the changes of brain activity potential. The mental workload of pilots in aviation flight is closely related to the characteristics of flight tasks. The previous methods have problems such as lack of objectivity, low EEG analysis ability and lack of real-time analysis ability. In order to solve these problems, this paper proposes a multi-dimensional data fusion brain workload calculation method based on flight effect evaluation, which integrates vision, operational behavior and visual gaze, and classifies and analyzes them in combination with EEG data. This method evaluates the mental workload of pilots from three aspects: visual gaze behavior, control behavior and flight effect in the simulated flight experimental environment, and realizes a more objective mental workload analysis. Then, the synchronously collected EEG data are segmented and sampled to form a dataset, and an LSTM neural network model integrating attention mechanism is established, in which the attention mechanism is used to improve the feature processing ability of the network model for the classification of complex EEG data. After machine learning training, the final model can achieve 94% detection accuracy for 2-s EEG data, and has the ability of real-time analysis in the application environment. Compared with the previous similar LSTM model, the accuracy is improved by 6%, which also shows the effectiveness of the model.},
  archive      = {J_IJPRAI},
  author       = {Guangyi Jiang and Hua Chen and Changyuan Wang and Pengxiang Xue},
  doi          = {10.1142/S0218001422590352},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2259035},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Mental workload artificial intelligence assessment of pilots’ EEG based on multi-dimensional data fusion and LSTM with attention mechanism model},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A driving assistance system for solving a-pillar blind spots
through gaze detection and field-of-view estimation. <em>IJPRAI</em>,
<em>36</em>(11), 2259022. (<a
href="https://doi.org/10.1142/S0218001422590224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The blind spots brought by a car’s A-pillar are main reasons of most of accidents. In this work, a vision system that focuses on eliminating A-pillar blind spot of a car without any affection of driver’s operation is investigated. The driver’s facial features are captured by a binocular vision system that is mounted on A-pillar, head poses and gaze line directions are reconstructed. The generated blind spot by A-pillar is then simultaneously calculated according to the position of driver’s gaze. A field-of-view of the blind spots is displayed in a screen system mounted on the A-pillar. The screen conjointly with front and side windows thus provides a full view field for the driver, which can effectively reduce the occurrence of accidents.},
  archive      = {J_IJPRAI},
  author       = {Minling Yang and Yukun He and Hongwei Song and Tianjun Li and Shengyong Chen},
  doi          = {10.1142/S0218001422590224},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2259022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A driving assistance system for solving A-pillar blind spots through gaze detection and field-of-view estimation},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simulation of destructive test for arch reinforcement area
of tunnel lining by MSIM. <em>IJPRAI</em>, <em>36</em>(11), 2259018. (<a
href="https://doi.org/10.1142/S0218001422590182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meshless Shepard interpolation method (MSIM) is used to simulate the destruction process within the arch reinforcement area of tunnel lining. In this method, the shape functions are formed by the partition of unity and the finite cover technology, which is not affected by discontinuous domains, with delta property at any desired node, and applies boundary conditions in an easy and correct way. The MSIM method combines the advantages of both the conventional meshless method and the numerical manifold method. The finite cover technology enables the shape functions to not be affected by the discontinuities in the solution domain, which overcomes the difficulty resulting from the conventional meshless method. The finite covers and the partition of unity functions are formed using the influence domains of a series of nodes, which removes the obstacle from conventional numerical manifold method and has simpler formation of finite covers than numerical manifold method. Virtual crack closure technique is used to calculate the intensity factor of crack-tip stress. The results of progressive destruction process simulation on the cracking patterns within the arch reinforcement area indicate that the method is suitable for tracking the crack propagation in complex stress conditions.},
  archive      = {J_IJPRAI},
  author       = {Dangfeng Yang and Lixiao Yao},
  doi          = {10.1142/S0218001422590182},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2259018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Simulation of destructive test for arch reinforcement area of tunnel lining by MSIM},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Context data fusion model enlightened multi-scale capsule
network for fruit diseases identification. <em>IJPRAI</em>,
<em>36</em>(11), 2257006. (<a
href="https://doi.org/10.1142/S0218001422570063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pests and diseases of tomato fruits are the foremost factors leading to the reduction in produce quantity. Effective and prompt differentiation of these lesion symptoms is essential for agricultural production. Due to the lack of a global receptive field, commonly used convolution neural network models restrict the capability on tomato images under complicated backgrounds. In this paper, we present an efficient and robust method for field diagnosis of tomato fruits based on the context data fusion and capsule network. First, in order to make better the point of inadequate images, the Cycle-GAN algorithm is used to realize the augmentation of the diseases dataset. To improve the quality of the generated images, the feature reconstruction loss function is proposed for the Cycle-GAN method, named Fruit-GAN. The proposed Fruit-GAN learns features of healthy and diseased tomatoes, respectively, and forms lesions based on healthy tomato fruit images. Adding lesion tomato images produced on Fruit-GAN to training sets improves the diagnostic capability compared to classical data augmentation techniques. Subsequently, context fusion studies were used to construct intermediate feature maps from different layers into the fruit diseases recognition compact representation to efficiently leverage the feature reuse mechanism. Finally, the fusion model’s enlightened multi-scale capsule network is integrated to form deep features and determine the disease diagnosis. After analyzing the hyper-parameters, the integral technique provides 96.16% accuracy. This research of tomato diseases diagnosis demonstrates the context capsule network model is efficient and establishes a foundation for tomato fruits determination in natural growing environment.},
  archive      = {J_IJPRAI},
  author       = {Yawei Wang and Yifei Chen and Dongfeng Wang},
  doi          = {10.1142/S0218001422570063},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2257006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Context data fusion model enlightened multi-scale capsule network for fruit diseases identification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Disease recognition of maize leaf based on KNN and feature
extraction. <em>IJPRAI</em>, <em>36</em>(11), 2257004. (<a
href="https://doi.org/10.1142/S021800142257004X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maize is one of the main crops in Shangluo. The maize yield and quality are adversely affected by leaf spot and rust. In order to realize the early prevention of maize leaf spot and rust and avoid problems of environmental pollution induced by the conventional chemical reagents, computer vision technology was proposed for disease detection in this research. The algorithm of K -means was used to process the image samples obtained from the test field. The healthy area, disease area and background area were separated. Based on the healthy area and disease area, ten parameters were extracted, including four parameters of color characteristic, four parameters of texture feature and two parameters of shape feature, which were taken as the classification criteria in the classification training by KNN algorithm. In total, 200 test image samples (100 samples of leaf spot and 100 samples of maize rust) were sent into the training model for disease identification. The results showed that the algorithm proposed can efficiently and nondestructively identify maize leaf spot and rust based on image segmentation and multi-feature fusion. The method was convenient and environmentally friendly. It can provide technical support for plant protection and can supply research ideas of precise control of crop diseases.},
  archive      = {J_IJPRAI},
  author       = {Yawen Li and Yuexing Chen and Yang Wang},
  doi          = {10.1142/S021800142257004X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2257004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Disease recognition of maize leaf based on KNN and feature extraction},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DRCP: Dimensionality reduced chess pattern for person
independent facial expression recognition. <em>IJPRAI</em>,
<em>36</em>(11), 2256016. (<a
href="https://doi.org/10.1142/S021800142256016X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic Facial Expression Recognition (FER) has become essential today as it has many applications in real time such as animation, driver mood detection, lie detection, and clinical psychology. The effectiveness of FER systems mainly depends on the extracted features. For extracting distinctive features with low dimensions, a new local texture-based image descriptor named Dimensionality Reduced Chess Pattern (DRCP) is proposed for recognizing facial expressions in a person independent scenario. DRCP, an improvement over Chess Pattern (CP), is mainly proposed for effectively reducing the feature vector length of CP. For feature extraction, DRCP also considers the movements of chessmen in a 5 × 5 neighborhood, as like CP. As a part of feature extraction through DRCP, apart from the center pixel, the remaining 24 pixels are arranged into four groups in such a manner that each group contains the pixels corresponding to three chessmen. From each group, one feature is extracted and thus corresponding to four groups, four features are extracted in a 5 × 5 neighborhood. The extracted features are fed into multi-class Support Vector Machine (SVM) for expression recognition. The experiments are performed on five “in the lab” datasets (MUG, TFEID, JAFFE, CK + and KDEF) and on two “in the wild” datasets (RAF and SFEW) in person independent setup to simulate a real world scenario.},
  archive      = {J_IJPRAI},
  author       = {Mukku Nisanth Kartheek and Munaga V. N. K. Prasad and Raju Bhukya},
  doi          = {10.1142/S021800142256016X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2256016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DRCP: Dimensionality reduced chess pattern for person independent facial expression recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards an efficient and robust adversarial attack against
neural text classifier. <em>IJPRAI</em>, <em>36</em>(11), 2253007. (<a
href="https://doi.org/10.1142/S021800142253007X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attack is a serious threat to neural network-based natural language processing applications. Adversarial attack uses tiny well-crafted perturbations to mislead neural networks. While existing adversarial text attacks can achieve good attack effects, they still do not guarantee efficiency and robustness. The adversarial text attacks are more efficient if they use less perturbation to achieve a higher attack success rate. The attacks are more robust if they can achieve a higher success rate when defense strategies are applied. To improve the efficiency and robustness of the adversarial attack, we propose SMAL: Saliency Map Attack with Levenshtein-similarity. The proposed attack consists of two parts: (1) The saliency map measures the perturbation priority of each word. It considers not only the influence of each word on the classification result but also how to maintain the misled classification result to improve the robustness of the attack. (2) Levenshtein-similarity network embeds words into edit distance space. When perturbing sentences, some words are replaced by substitutions with less edit distance. This can reduce the amount of modification, which improves the efficiency of the attack. Since the words are embedded in edit distance space rather than semantic space, the semantic-based defense is not effective for this attack, which improves the robustness. The experiments show that SMAL achieves a higher attack success rate with fewer perturbations. Also, the proposed attack is better when attacking a classifier defended by adversarial training.},
  archive      = {J_IJPRAI},
  author       = {Zibo Yi and Shasha Li and Jun Ma and Jie Yu and Yusong Tan and Qingbo Wu},
  doi          = {10.1142/S021800142253007X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2253007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Towards an efficient and robust adversarial attack against neural text classifier},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimized convolutional neural network for tamil handwritten
character recognition. <em>IJPRAI</em>, <em>36</em>(11), 2253003. (<a
href="https://doi.org/10.1142/S0218001422530032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital recognitions are playing a vital function in the current era of technological advancements. Hence, they offer more possible ways of performing handwritten character recognition (HCR). Generally, recognizing the Tamil handwritten texts is highly complicated, in comparison to the Western scripts. Nevertheless, many researchers have presented several real-time approaches to achieve Tamil character recognition (TCR) in offline mode. This paper introduces a new handwritten TCR (HTCR) approach with two phases: (1) pre-processing and (2) classification. Primarily, the scanned document in the Tamil language is pre-processed via the steps like RGB to grayscale conversion, binarization with thresholding, image complementation, application of morphological operations and linearization. The pre-processed images are then classified using an optimized convolutional neural network (CNN) model. Further, the fully connected layer (FCL) and the weights are tuned optimally via a new sea lion with self-adaptiveness (SL-SA) algorithm. Lastly, the adopted model is evaluated using various measures to prove its supremacy over the existing schemes.},
  archive      = {J_IJPRAI},
  author       = {R. Babitha Lincy and R. Gayathri},
  doi          = {10.1142/S0218001422530032},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2253003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimized convolutional neural network for tamil handwritten character recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Driving state discrimination algorithm based on lightweight
network and contrast learning. <em>IJPRAI</em>, <em>36</em>(11),
2252025. (<a href="https://doi.org/10.1142/S0218001422520255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driver misbehavior is one of the major traffic safety hazards as car ownership increases year by year. So, it is important to have driver fatigue detection and behavior recognition. Initially, given the fatigue detection problem that the images captured by the visible light camera cannot capture the eyes of a driver wearing sunglasses or eye glasses. As a solution, this paper introduces a DCT-HSV preprocessing algorithm for infrared images, which is believed to enhance the target characteristics of infrared images. The paper also introduces a more efficient lightweight SSD detection model, which achieves a better balance in terms of model size and detection performance. It also shows a better performance in self-built datasets and basic vehicle operation datasets. Secondly, aiming at the problems of high complexity and poor accuracy of the existing driving behavior detection model, this paper designs a driver abnormal behavior discrimination model based on the comparison twin, which has good performance on the Kaggle public dataset. The relevant experimental detection results show that the method constructed in this paper has high detection accuracy, low warning delay, and good practical use value.},
  archive      = {J_IJPRAI},
  author       = {Wuqi Gao and Liangliang Li and Ting Yang},
  doi          = {10.1142/S0218001422520255},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2252025},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Driving state discrimination algorithm based on lightweight network and contrast learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Segmentation and synthesis of embroidery art images based on
deep learning convolutional neural networks. <em>IJPRAI</em>,
<em>36</em>(11), 2252018. (<a
href="https://doi.org/10.1142/S0218001422520188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional embroidery identification technology cannot present the target image of the art network in a more comprehensive and three-dimensional manner. A research on the segmentation and synthesis of embroidery art images based on deep learning convolutional neural network is proposed. Based on the semantic image segmentation technology of deep learning, this paper analyzes the embroidery semantic image segmentation technology, obtains the information of image technology, analyzes the embroidery rendering technology of convolutional neural networks, and puts forward the embroidery rendering algorithm. In order to verify the effectiveness of the algorithm, a simulation test experiment was carried out on the target content image and the embroidery art network image. The test results show that compared with the traditional method, this method has more specific and flexible image generation, stronger three-dimensional sense, closer to the real art embroidery network, and the direction of its needlework is also more hierarchical.},
  archive      = {J_IJPRAI},
  author       = {Zhang Wei and Young Chun Ko},
  doi          = {10.1142/S0218001422520188},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2252018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Segmentation and synthesis of embroidery art images based on deep learning convolutional neural networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning-based verification of iridology in diagnosing
type II diabetes mellitus. <em>IJPRAI</em>, <em>36</em>(11), 2252017.
(<a href="https://doi.org/10.1142/S0218001422520176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Type II Diabetes Mellitus (Type II DM) is a chronic condition that has detrimental effect on vital organs if left untreated, necessitating early diagnosis and treatment. Iridology, a subset of Complementary and Alternative Medicine (CAM), has the potential to serve as a tool for noninvasive early diagnosis of Type II DM. Iridology involves analyzing the characteristics of iris such as color and pattern for detection of organ and system defects. Deep learning algorithm is one of the promising methods in diagnosing various health-related issues. In this study, we have demonstrated the efficiency of iridology in diagnosing Type II DM using deep learning algorithms. Near Infra-Red images of iris were captured using iris scanner from 178 voluntary subjects belonging to two categories namely, Type II DM (95 subjects) and nondiabetic or healthy category (83 subjects). We have developed an algorithm using Fully Convolutional Neural network for effective iris segmentation. Normalized iris images were used to crop out our region of interest, pancreas, based on the iridology chart. Classification networks such as AlexNet, VGG-16, and ResNet-50 were used to classify Type II DM versus healthy category. Our proposed model for iris segmentation achieved an accuracy and sensitivity of 0.99, specificity and F-Score of 0.98, and a precision of 0.97. Results obtained using AlexNet classifier exhibits better classification accuracy of 95.85% for Zero-padding based resized image. The classifier yielded a sensitivity, specificity, and precision of 95.80%, 95.85%, and 96.11%, respectively. Our study results establish the efficacy and emphasize the importance of the proposed algorithm for diagnosing Type II DM.},
  archive      = {J_IJPRAI},
  author       = {K. Sruthi and J. Vijayakumar and S. Thavamani},
  doi          = {10.1142/S0218001422520176},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2252017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep learning-based verification of iridology in diagnosing type II diabetes mellitus},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent wear debris identification of gearbox based on
virtual ferrographic images and two-level transfer learning.
<em>IJPRAI</em>, <em>36</em>(11), 2251012. (<a
href="https://doi.org/10.1142/S0218001422510120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ferrography analysis is one of main means to identify wear state of mechanical equipment, and its key is the intelligent recognition of wear debris ferrographic images. Ferrographic image acquisition is a complex and time-consuming work, so the direct deep learning cannot been carried out for the small tested samples. A virtual ferrographic image dataset is prepared firstly and then two-level transfer learning scheme is proposed to improve the identification rate of the tested samples based on the deep learning model trained by the virtual samples. A combined network of YOLOv3 and DarkNet53 is constructed, and the application effect of model is improved by two-level transfer learning of virtual dataset to open dataset and then open dataset to tested dataset, and the model errors before and after twice transfer learning are analyzed. The average identification accuracy of the model in the validation dataset is 86.1%, which is 44.5% higher than that without two-level transfer learning, and the average recall reaches 95.8%. The experimental results prove the proposed method have a high identification rate for the tested ferrographic images of an actual gearbox.},
  archive      = {J_IJPRAI},
  author       = {Hongwei Fan and Shuoqi Gao and Qi Liu and Ningge Ma and Xuhui Zhang and Xiangang Cao},
  doi          = {10.1142/S0218001422510120},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2251012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Intelligent wear debris identification of gearbox based on virtual ferrographic images and two-level transfer learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Crow search with adaptive awareness probability-based deep
belief network for detecting ransomware. <em>IJPRAI</em>,
<em>36</em>(11), 2251010. (<a
href="https://doi.org/10.1142/S0218001422510107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Crypto ransomware is defined as malware that blocks the user file’s access by encrypting them and demands them with a ransom for obtaining the decryption key”. This causes some major threats in many of the companies. Therefore, the detection of ransomware is needful for reducing the workloads of the analysts and also for finding the variations in unknown samples. The adopted scheme encompasses 3 phases: (i) feature extraction, (ii) feature selection and (iii) classification. Initially, the sequential frequent patterns are extracted using the apriori framework. However, the major challenge in this extracted sequential pattern is the curse of dimensionality. To overcome this, the selection of optimal features is very important, which is done as the second stage. In this, the optimization concept is evolved for the optimal selection of these extracted sequential patterns. Furthermore, the optimal patterns are given for classification, where DBN is deployed. Particularly, for the selection of the optimal sequential pattern, this work proposes a new crow search with adaptive awareness probability (CS-AAP) model. In the end, analysis is performed to authorize the supremacy of the developed scheme.},
  archive      = {J_IJPRAI},
  author       = {Shemitha P A and Julia Punitha Malar Dhas},
  doi          = {10.1142/S0218001422510107},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2251010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Crow search with adaptive awareness probability-based deep belief network for detecting ransomware},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification method of grape leaf diseases based on
improved CCT model. <em>IJPRAI</em>, <em>36</em>(11), 2250037. (<a
href="https://doi.org/10.1142/S0218001422500379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grape is an important cash crop that is susceptible to diseases when growing, resulting in lower yield and quality. In recent years, transformers have achieved excellent performance in a variety of natural language processing and image recognition tasks through the self-attention mechanism. Therefore, this paper proposes a grape leaf disease recognition model named Dense Convolutional Transformer (DensCT). The compact convolutional transformer (CCT) is used as the backbone in this model, which improves the convolutional module of the original model by introducing densely connected modules, enhancing the transfer and reuse of features between networks. This also modifies the single-scale feature extraction method of the original model to multi-scale, which improves the feature extraction performance. Finally, the model was trained on two small-scale datasets from scratch, and the recognition accuracy of the final model on the test sets reached 89.19% and 93.92%. Compared with CCT, DenseNet121, ResNet50, MobileNetV3 and ViT, the recognition accuracy improved by 4.73%, 3.38%, 10.81%, 0.68% and 18.24% on the first dataset and 6.08%, 5.41%, 1.35%, 3.38% and 12.84% on the second dataset. The experimental results show that the proposed model can effectively identify grape leaf diseases, which can provide a reference for building disease leaf recognition models on small-scale datasets.},
  archive      = {J_IJPRAI},
  author       = {Cheng Li and Ming Li and Xinghui Zhu and Yineng Chen and Yanbin Wu and Nan Deng and Kui Fang},
  doi          = {10.1142/S0218001422500379},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2250037},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Identification method of grape leaf diseases based on improved CCT model},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The improved cooperative particle swarm optimization (ICPSO)
with dynamic information adjustment and controllable speed and its
application in neural network optimization. <em>IJPRAI</em>,
<em>36</em>(10), 2259021. (<a
href="https://doi.org/10.1142/S0218001422590212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of the premature convergence of particle swarm optimization (PSO) that is often caused by the loss of diversity, an improved cooperative PSO (ICPSO) is proposed. The method can dynamically combine the optimum values of the particles themselves, the global particles and the optimum values in groups, use the current optimization stage to dynamically adjust the shared proportion of information and effectively fuse various reference information, which can obtain superior global and local optimization performance. Additionally, to improve the diversity of the algorithm, a dynamic adjustment method using the grouping coefficient r for the convergence rate is put forward. This method makes the algorithm have a more appropriate convergence rate while improving the convergence precision and enhancing the performance of the algorithm. Finally, the algorithm is used to optimize a neural network. The convergence condition and convergence rate of the algorithm are assessed by theoretical analysis and simulation experiments. The results show that ICPSO has more advantages in its diversity and the adjustment of the convergence rate compared to other related algorithms. Regarding neural network optimization, the training speed and optimization precision of the ICPSO-BP neural network are the highest, which has reached the best and average level of classification accuracy 98.5%, 96.3% for 20 iterations in Iris, and 98.7%, 95.1% in Wine. Its average iteration times score the best in five problems out of six.},
  archive      = {J_IJPRAI},
  author       = {Li-Hui Fu and Junfeng Dai},
  doi          = {10.1142/S0218001422590212},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2259021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {The improved cooperative particle swarm optimization (ICPSO) with dynamic information adjustment and controllable speed and its application in neural network optimization},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). K-means clustering with optimal centroid: An optimization
insisted model for removing outliers. <em>IJPRAI</em>, <em>36</em>(10),
2259007. (<a href="https://doi.org/10.1142/S0218001422590078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data cleaning, the process of detecting and correcting corrupt, inaccurate or irrelevant records from the record set is a tedious task. Particularly, the process of “outlier detection” occupies a significant role in data cleaning that removes or eliminates the outlier’s that exist in data. Traditionally, more efforts have been taken to remove the outliers, and one of the promising ways is customizing clustering models. In this manner, this paper intends to propose a new outlier detection model via enhanced k-means with outlier removal (E-KMOR), which assigns all outliers into a group naturally during the clustering process. For assigning the point to be outliers, a new intra-cluster based distance evaluation is employed. The main contribution of this paper is to select cluster centroid optimally through a newly proposed hybrid optimization algorithm termed particle updated lion algorithm (PU-LA), which hybrids the concepts of LA and particle swarm optimization (PSO), respectively. Thereby, the proposed work is named as E-KMOR-PU-LA. Finally, the efficacy of the proposed E-KMOR-PU-LA model is proved through a comparative analysis over conventional models by concerning runtime and accuracy.},
  archive      = {J_IJPRAI},
  author       = {Kumar Rahul and Rohitash Kumar Banyal},
  doi          = {10.1142/S0218001422590078},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2259007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {K-means clustering with optimal centroid: An optimization insisted model for removing outliers},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Phylogenetic analysis: A novel method of protein sequence
similarity analysis. <em>IJPRAI</em>, <em>36</em>(10), 2258007. (<a
href="https://doi.org/10.1142/S0218001422580071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein sequence similarity analysis (PSSA) is a significant task in bioinformatics, which can obtain information about unknown sequences such as protein structures and homology relationships. Protein sequence refers to the series of amino acids with rich physical and chemical properties, namely the basic structure of proteins. However, sequence similarity analysis and phylogenetic analysis between different species which have complex amino acid sequences is a challenging problem. In this paper, nine properties of amino acids were considered and the sequence was converted into numerical values by principal component analysis (PCA); with Haar Wavelet Transform, and Higuchi fractal dimension (HFD), a new feature vector is constructed to represent the sequence; Spearman distance was selected to calculate the distance matrix and the phylogenetic tree was constructed. In this paper, two representative protein sequences (9 ND5 (NADH dehydrogenase 5) and 8 ND6 (NADH dehydrogenase 6)) were selected for similarity analysis and phylogenetic analysis, and compared with MEGA software and other existing methods. The extensive results show that our method is outperforming and results consistent with the known facts.},
  archive      = {J_IJPRAI},
  author       = {Wei Li and Lina Yang and Zuqiang Meng and Yu Qiu and Patrick Shen-Pei Wang and Xichun Li},
  doi          = {10.1142/S0218001422580071},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2258007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Phylogenetic analysis: A novel method of protein sequence similarity analysis},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hypergraph convolutional neural network for fast and
accurate diagnosis (FAT) of COVID from x-ray images. <em>IJPRAI</em>,
<em>36</em>(10), 2257005. (<a
href="https://doi.org/10.1142/S0218001422570051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and objective: The Covid-19 pandemic significantly affects the global population’s fitness and day-to-day life. The necessary action to fight against Covid is to have a fast, accurate and affordable diagnosis system. Most of the diagnostic systems available today have a low detection rate and are time consuming. Hence, there is a demand to design an affordable, accurate, and fast diagnostic system for Covid. The diagnostic system that uses the Convolutional Neural Network (CNN) does not consider the complex correlation of multimodal image data, thus misleading the diagnostic results. Graph Convolutional Network (GCN) provides a better solution for the complex representation of data, as it is modeled based on the pairwise relationship in the image features. Method: Diagnosis of Covid, Parasite, or Lung Tumor from X-ray images needs a more complex representative model. There is a demand to categorize the images grounded on highly complex features. To solve the issue mentioned earlier, this work proposes a Hypergraph- and convolutional neural network-based Fast and Accurate Diagnosis (FAT) system for Covid. The in-depth features are mined using a residual neural network from the X-ray images. The learning-based method optimizes a high-level correlation in the deep structures by constructing it as a hypergraph. Results: The proposed method is assessed based on the Covid dataset. The experimental outcomes show that the proposed system FAT provides the accuracy of 99.8%, sensitivity of 99.5%, and specificity of 99%. It outperforms all the current diagnosis systems for Covid. Conclusion: The proposed deep learning-based model is well suited for Covid diagnosis at the preliminary level. It allows diagnosing Covid by low radiation chest X-ray images with higher accuracy.},
  archive      = {J_IJPRAI},
  author       = {N. Sasikaladevi and A. Revathi},
  doi          = {10.1142/S0218001422570051},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2257005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Hypergraph convolutional neural network for fast and accurate diagnosis (FAT) of COVID from X-ray images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A self-supervised model advance OCTA image disease
diagnosis. <em>IJPRAI</em>, <em>36</em>(10), 2257003. (<a
href="https://doi.org/10.1142/S0218001422570038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the lack of medical image datasets, transfer learning/fine-tuning is generally used to realize disease detection (mainly the ImageNet transfer model). Significant differences of dominance between natural and medical images seriously restrict the performance of the model. In this paper, a contrastive learning method (BY-OCTA) combined with patient metadata is proposed to detect the pathology in fundus OCTA images. This method uses the patient’s metadata to construct positive sample pairs. By introducing super-parameters into the loss function, we can reasonably adjust the approximate proportion of the same patient metadata sample pair, so as to produce a better representation and initialization model. This paper evaluates the performance of downstream tasks by fine-tuning the multi-layer perceptron of the model. Experiments show that the linear model pretrained by BY-OCTA is better than that pretrained by ImageNet and BYOL on multiple datasets. Furthermore, in the case of limited labeled training data, BY-OCTA provides the most significant benefit. This shows that the BY-OCTA pretraining model has better characterization extraction ability and transferability. This method allows a flexible combination of medical opinions and uses metadata to construct positive sample pairs, which can be widely used in medical image interpretation.},
  archive      = {J_IJPRAI},
  author       = {Bingbing Li and Yiheng Ding and Ziqiang Wei and Zhijie Fu and Peng Sun and Qi Sun and Hong Zhang and Hongwei Mo},
  doi          = {10.1142/S0218001422570038},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2257003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A self-supervised model advance OCTA image disease diagnosis},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancement of hand gesture recognition using convolutional
neural networks integrating a combination of an autoencoder network and
PCA. <em>IJPRAI</em>, <em>36</em>(10), 2256015. (<a
href="https://doi.org/10.1142/S0218001422560158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand gestures offer people a convenient way to interact with computers, in addition to give them the ability to communicate without physical contact and at a distance, which is essential in today’s health conditions, especially during an epidemic infectious viruses such as the COVID-19 coronavirus. However, factors, such as the complexity of hand gesture patterns, differences in hand size and position, and other aspects, can affect the performance of hand gesture recognition and classification algorithms. Some deep learning approaches such as convolutional neural networks (CNN), capsule networks (CapsNets) and autoencoders have been proposed by researchers to improve the performance of image recognition systems in this particular field: While CNNs are arguably the most widely used networks for object detection and image classification, CapsNets and Autoencoder seem to resolve some of the limitations identified in the first approach. For this reason, in this work, a specific combination of these networks is proposed to effectively solve the ASL problem. The results obtained in this work show that the proposed group with a simple data augmentation process improves precision performance by 99.43%.},
  archive      = {J_IJPRAI},
  author       = {Khalil Bousbai and Mostefa Merah},
  doi          = {10.1142/S0218001422560158},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2256015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Enhancement of hand gesture recognition using convolutional neural networks integrating a combination of an autoencoder network and PCA},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Face detection based on dynamic min size and dense
connection. <em>IJPRAI</em>, <em>36</em>(10), 2254017. (<a
href="https://doi.org/10.1142/S0218001422540179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the face detection technology is widely used, improving the detection speed and accuracy in face detection tasks has become a key challenge. Therefore, this paper takes the MTCNN model as the research object and makes improvements, the purpose of which is to optimize the detection speed and accuracy simultaneously. A dynamic min size algorithm is proposed. According to the size of the input image, it dynamically controls the minimum size of the face to be recognized by the model and reduces the number of iterations of the image pyramid, increasing the number of detection frames per second by 4 fps. Then, the standard convolution structure in the P-Net and R-Net models is replaced by the depth-wise separable convolution, which effectively reduces the number of parameters and computation of the model. Meanwhile, an O-Net model with a densely connected structure is also developed. Our experiments with well-known public datasets have demonstrated that the proposed network structure can improve the detection frame rate. By reusing the features of different levels of the image, the recall rate and the precision rate of the MTCNN model on the validation set are increased by 2.39% and 1.65%, respectively.},
  archive      = {J_IJPRAI},
  author       = {Wuqi Gao and Man Wang and Ning Zhang and Liangliang Li and Lina Gao},
  doi          = {10.1142/S0218001422540179},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2254017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Face detection based on dynamic min size and dense connection},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A keypoint-based and block-based fusion method for image
copy–move forgery detection. <em>IJPRAI</em>, <em>36</em>(10), 2254016.
(<a href="https://doi.org/10.1142/S0218001422540167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, image copy–move forgery issues have brought increasingly serious problems to the social fields. Many research have been devoted to address the image copy–move forgery issues. However, image copy–move forgery detection (CMFD) is still a challenging problem to image forensics. This paper proposes a coarse-to-fine detection method fusing the superiorities of both keypoint-based and block-based methods. The fusion method gets good geometric invariances of keypoint-based methods and good matching robustness with the invariant moment of block-based methods. In the coarse detection stage, a robust SIFT descriptor is used to extract the candidate keypoints, and then the 2NN test is applied to match the suspicious keypoint couples. The proposed three-pass filtering relying on the Euclidean distance, scaling coefficient ratio, and correlation coefficient of block-based features, remove the false-positive outlier couples. Finally, the scaling coefficient ratio statistics of the remaining keypoint couples get the scaling coefficient ratio between the size of copied/pasted or pasted/copied snippets. In the fine detection stage, the block-based thought relying on the scaling coefficient ratio uses the DAFMT to extract the block-based features of multiple scaling levels. Subsequently, LSH is presented to classify block features and finally indicate the fine forgery snippets. Finally, the morphological operations are presented to indicate the forgery accurately. The benchmark IMD and CoMoFoD image copy–move datasets are used to measure the performances between the proposed fusion method and the state-of-the-art CMFD methods. The numerous experimental results demonstrate that the proposed fusion method achieves nearly the best performances to resist various attacks, especially large-scaling attacks, among the compared state-of-the-art methods.},
  archive      = {J_IJPRAI},
  author       = {Jun-Liu Zhong and Yan-Fen Gan and Cai-Feng Zou},
  doi          = {10.1142/S0218001422540167},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2254016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A keypoint-based and block-based fusion method for image Copy–Move forgery detection},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved semi-supervised variational autoencoder with
gate mechanism for text classification. <em>IJPRAI</em>,
<em>36</em>(10), 2253006. (<a
href="https://doi.org/10.1142/S0218001422530068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, semi-supervised learning has been investigated to take full advantages of increasing unlabeled data. Although pretrained deep learning models are successfully adopted on a massive amount of unlabeled data, they may not be applicable in specific domains as the data is limited. In this paper, we propose a model, termed Semi-supervised Variational AutoEncoder (SVAE), which consists of Gated Convolutional Neural Networks (GCNN) as both the encoder and the decoder. Since the canonical VAE suffers from Kullback–Leibler (KL) vanishing problem, we attach a layer named Scalar after Batch Normalization (BN) to scale the output of the BN. We conduct experiments on two domain-specific datasets with a small amount of data. The results show that SVAE outperforms other alternative baselines for language modeling and semi-supervised learning studies. Especially, the results in the language modeling validate the effect of combining BN and Scalar for tackling the KL vanishing problem. Moreover, the visualization of the latent representations verifies the performance of SVAE on less data.},
  archive      = {J_IJPRAI},
  author       = {Haiming Ye and Weiwen Zhang and Mengna Nie},
  doi          = {10.1142/S0218001422530068},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2253006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An improved semi-supervised variational autoencoder with gate mechanism for text classification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel deep learning-based bidirectional elman neural
network for facial emotion recognition. <em>IJPRAI</em>,
<em>36</em>(10), 2252016. (<a
href="https://doi.org/10.1142/S0218001422520164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial emotion recognition (FER) is an interesting area of research. It has a wide range of applications, but there is still a deficiency of an accurate approach to provide better results. A novel FER system to maximize classification accuracy has been introduced in this paper. The proposed approach constitutes the following phases: pre-processing, feature extraction, feature selection, and classification. Initially, the images are pre-processed using the extended cascaded filter (ECF) and then the geometric and appearance-based features are extracted. An enhanced battle royale optimization (EBRO) for feature selection has been proposed to select the relevant features and to reduce the dimensionality problem. Then, the classification is carried out using a novel bidirectional Elman neural network (Bi-ENN) that offers high classification results. The proposed Bi-ENN-based emotion classification can accurately discriminate the input features. It enabled the model to predict the labels for classification accurately. The proposed model on evaluations attained an accuracy rate of 98.57% on JAFFE and 98.75% on CK+ datasets.},
  archive      = {J_IJPRAI},
  author       = {Fakir Mashuque Alamgir and Md. Shafiul Alam},
  doi          = {10.1142/S0218001422520164},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2252016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel deep learning-based bidirectional elman neural network for facial emotion recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards a reliable text summarization evaluation metric
using predictive models. <em>IJPRAI</em>, <em>36</em>(10), 2251011. (<a
href="https://doi.org/10.1142/S0218001422510119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With an increasing number of new summarization systems proposed in recent years, an automatic text evaluation metric that can accurately and reliably rate the performance of summarization systems has been a pressing need. However, current automatic text evaluation metrics can only measure one or certain aspects of the quality between two summary texts and do not agree with human judgments consistently. In this paper, we show that combining multiple well-chosen evaluation metrics and training predictive models using human annotated datasets can lead to more reliable evaluation scores than using any individual automatic metric. Our predictive models trained on a human annotated subset of the CNN/DailyMail corpus demonstrate significant improvements (e.g. approximately 25% along coherence dimension) over selected individual metrics. Furthermore, a concise meta-evaluation on automatic metrics is provided along with an analysis of the performance of 12 predictive models. We also investigate the sensitivity of automatic metrics when mixed together for training these models. We have made the code, the instructions for experiment setup, and the trained models available as a tool for comparing and evaluating text summarization systems. a},
  archive      = {J_IJPRAI},
  author       = {Bo Zhao and Yui Man Lui},
  doi          = {10.1142/S0218001422510119},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2251011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Towards a reliable text summarization evaluation metric using predictive models},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Active learning algorithm based on fast optimization of
support vectors. <em>IJPRAI</em>, <em>36</em>(10), 2251005. (<a
href="https://doi.org/10.1142/S0218001422510053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the solution to the problems of being difficult to gain mass class-labeled samples in the supervised learning process and of reducing the cost of data labeling, a fast optimization of support vectors based on convex hull vector is proposed with the learning mechanism of Support Vector Machine (SVM). By means of calculating the hull vectors of the sample set, label those chosen hull vectors that are largest possible to be support vectors, and also add the unlabeled samples with high confidence coefficient of classifiers to the training sample set. The very information beneficial to the learner in the unlabeled samples set will be exploited. Hence, the thick convex hull method and the modified weighted SVM are separately directed for the nonlinear separable problem and the unbalanced training sample set. Via experimental testing on the UCI data set, the results demonstrate that the algorithm harvests SVM classifiers of higher classification accuracy and better generalization performance with fewer labeled samples, so as to cut down the labeling cost of samples for SVM training and learning.},
  archive      = {J_IJPRAI},
  author       = {Hailong Xu and Longyue Li and Pengsong Guo},
  doi          = {10.1142/S0218001422510053},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2251005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Active learning algorithm based on fast optimization of support vectors},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Temporal-variation skeleton point correction algorithm for
improved accuracy of human action recognition. <em>IJPRAI</em>,
<em>36</em>(10), 2250035. (<a
href="https://doi.org/10.1142/S0218001422500355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The technique of human action recognition can be applied in a number of fields, such as medical rehabilitation, posture in the domain of sports, and emotion perception in counselling. Deep learning action recognition models that consider the continuous changes in the human skeleton can efficiently identify action states, such as rehabilitation processes, posture, and changes in emotion. However, the keypoints of the human skeleton are susceptible to occlusion due to body movement, resulting in a lower confidence level in their positions, which in turn affects the training and execution of human action recognition models. This paper proposes a keypoint correction algorithm based on continuous-time images of temporal variation that can predict and correct the skeleton keypoints with low confidence, based on the previous and subsequent multiple images. The proposed temporal-variation skeleton keypoint correction algorithm can provide accurate feature association training for the locations of the skeleton keypoints. The proposed method is shown to improve the accuracy of human action recognition by at least 30% over three alternative models in the literature: STV-GCN, GCN-NAS, and 2S-AGCN. The proposed algorithm is also improved by at least 30% compared with the above-mentioned methods in the literature, based on an action recognition model with a Gaussian filter.},
  archive      = {J_IJPRAI},
  author       = {Ming-Fong Tsai and Sheng-Hong Huang},
  doi          = {10.1142/S0218001422500355},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2250035},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Temporal-variation skeleton point correction algorithm for improved accuracy of human action recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid feature extraction with ensemble classifier for brain
tumor classification. <em>IJPRAI</em>, <em>36</em>(10), 2250031. (<a
href="https://doi.org/10.1142/S0218001422500318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor is one of the most severe nervous system disorders affecting the health of humans and critically it will lead to death. The most elevated disease that causes a major death rate is Glioma, i.e. a primary intracranial tumor. One of the widely used techniques in medical imaging is Magnetic Resonance Imaging (MRI) which turned out as the principle diagnosis model for the analysis of glioma and its treatment. However, the brain tumor segmentation and classification process are more complicated problems to execute. This paper intends to introduce a novel brain tumor classification model that includes four major phases: (i) Pre-processing (ii) Segmentation (iii) Brain Feature extraction (iv) Brain tumor Classification. Initially, the input image is subjected to the pre-processing phase, in which the image is pre-processed under a certain process. The pre-processed images are then subjected to the segmentation phase, which is carried out by the k -means clustering. Subsequently, the segmented images are subjected to the brain feature extraction phase, in which the features are extracted using the hybrid Principal Component Analysis (PCA)-GIST feature extraction method. Then, these features are given as the input to the classification process, where the ensemble classifier is exploited for the same. Moreover, the proposed ensemble technique includes k -Nearest Neighbor ( k -NN), Optimized Neural Network (NN), Random Forest (RF), and Support Vector Machine (SVM). To precisely detect the tumor classification, the NN training is performed using Elephant Herding Optimization with mutation operations (EHOMO) Algorithm via selecting the optimal weights.},
  archive      = {J_IJPRAI},
  author       = {B. Leena and A. N. Jayanthi},
  doi          = {10.1142/S0218001422500318},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2250031},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Hybrid feature extraction with ensemble classifier for brain tumor classification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A control strategy for unmanned surface vehicles flocking.
<em>IJPRAI</em>, <em>36</em>(9), 2259020. (<a
href="https://doi.org/10.1142/S0218001422590200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized control allows each unmanned surface vehicle (USV) in a flock to be autonomous to some extent. In this paper, the flocking algorithm put forth by Olfati-Saber was improved and applied in the multi-leader scenario based on its original flocking movement. Repulsion was also taken into account in the formation. Subsequently, the concept of neighborhood in finite-range communications was borrowed to control the communication distance of each USV. In this way, USVs could satisfy the restriction of a given communication distance, and avoid collision in motion. USVs might have collaborative tracking of a virtual leader and obtain the distributed cooperative control strategy. Based on the simulation results, the improved flocking control algorithm allowed every USV to accurately track the speed of the virtual leader they followed, respectively. The test results also demonstrated the effectiveness of the algorithm in safe flock navigation, and proved that the proposed control algorithm must be an effective way to ensure the safe flocking of multiple USVs.},
  archive      = {J_IJPRAI},
  author       = {Yan Li and Jianqiang Zhang and Hongbin Wang and Yi Li and Bowen Sui},
  doi          = {10.1142/S0218001422590200},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2259020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A control strategy for unmanned surface vehicles flocking},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph neural network social recommendation algorithm
integrating static and dynamic features. <em>IJPRAI</em>,
<em>36</em>(9), 2259019. (<a
href="https://doi.org/10.1142/S0218001422590194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the study of social-based recommender systems has become an active research topic. We incorporate a combination of static and dynamic interest characteristics to predict users’ real-time dynamic interests, which has rarely been considered in previous studies. In this paper, we propose a graph neural network social recommendation model that integrates static and dynamic feature relationships (FSDFR-GNNSR). The model uses a graph embedding algorithm to extract static features of users and movies, and takes the static features as input to gated recurrent unit (GRU), so that the model can take static features into consideration while modeling user dynamic behavior. Finally, we use graph attention networks to represent the dynamic influence of friends, simplify the update strategy of second-order neighbor nodes. We apply graph pooling operations to improve the generalization ability of the algorithm. Empirical analyses on real datasets show that the proposed approach achieves superior performance to existing approaches.},
  archive      = {J_IJPRAI},
  author       = {Wei Qi and Zhenzhen Huang and Dongqing Zhu and Jiaxu Yu},
  doi          = {10.1142/S0218001422590194},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2259019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Graph neural network social recommendation algorithm integrating static and dynamic features},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heavy overload prediction method of distribution transformer
based on GBDT. <em>IJPRAI</em>, <em>36</em>(9), 2259014. (<a
href="https://doi.org/10.1142/S0218001422590145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distribution transformer voltage may be overloaded, which may lead to the aging of distribution transformer components, shorten the service life of distribution transformer components and even affect the daily life of community residents and the operation of enterprises. A large amount of real data are collected, and the factors that affect the heavy overload of distribution transformer are comprehensively considered from multiple angles, so as to establish a model for future prediction and early maintenance to reduce losses. First, the collected data is analyzed by attributes and preprocessed to improve the quality of the data. Then, the time attributes are generalized according to seasons, months, holidays and weekends. The test results show that the data prediction value is more accurate when generalized according to seasons. For the prediction model, the gradient lifting decision tree algorithm is selected to establish the model, and then the parameters are further optimized, and finally the model is evaluated. Lastly, the prediction accuracy of the model reaches a high level, and it can be determined that the prediction is close to the objective fact. The model can be used to predict the heavy overload of distribution transformer voltage, so as to reduce the loss caused by abnormal conditions of relevant equipment for the enterprises.},
  archive      = {J_IJPRAI},
  author       = {Ganglong Duan and Weiyu Han},
  doi          = {10.1142/S0218001422590145},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2259014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Heavy overload prediction method of distribution transformer based on GBDT},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ergonomic assessment method of risk factors for
musculoskeletal disorders associated with sitting postures.
<em>IJPRAI</em>, <em>36</em>(9), 2256017. (<a
href="https://doi.org/10.1142/S0218001422560171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Musculoskeletal disorders (MSDs) are associated with sitting postures. The assessment and prevention of risk factors for workplace exposure are indispensable aspects of reducing the occurrence of MSDs. This paper proposes an ergonomic assessment method of risk factors for MSDs associated with sitting postures in the actual working conditions. A Kinect sensor with the RULA method was primarily used to collect the data and evaluate the relevant postures. The results obtained were compared with the evaluation results by a human expert. Additionally, we verified the capability and effectiveness of this method. A program system for human joint recognition and acquisition was implemented. The results indicated that the Kinect joint data is generally accurate and can adequately complete the RULA evaluation table. The results from the front and right-hand side obtained by the Kinect were consistent with the results of the expert evaluation, and no significant difference was observed between them ( p &gt; 0 . 0 5 ). However, when the participants faced the Kinect, the sensor performed better, and the evaluation result was more accurate. A high consistency was observed between the evaluation results obtained from the front and the expert (proportion agreement index = 0 . 6 5 , Cohen’s kappa = 0 . 7 7 ). Only a slight consistency was observed between the evaluation results obtained from the right-hand side and the expert (proportion agreement index = 0 . 4 1 , Cohen’s kappa = 0 . 0 8 ). This research created a new ergonomic method for the risk assessment of MSDs associated with sitting postures. The combination of theory and practice is crucial in the risk assessment of sitting postures in workplaces.},
  archive      = {J_IJPRAI},
  author       = {Jianwei Li and Sihan Huang and Faming Wang and Sixi Chen and Huiru Zheng},
  doi          = {10.1142/S0218001422560171},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2256017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Ergonomic assessment method of risk factors for musculoskeletal disorders associated with sitting postures},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature-based correspondence filtering using structural
similarity index for visual odometry. <em>IJPRAI</em>, <em>36</em>(9),
2255013. (<a href="https://doi.org/10.1142/S0218001422550138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stereo correspondence problem is one of the most pre-eminent problems in a stereo vision system. With the right correspondence, a stereo vision system can help cap over diverse problems, while on the other hand, a wrong correspondence can be costly. While the performance of a feature-based correspondence approach is exceptional, the method can still produce wrong correspondences. This work presents an amalgam of feature-based and correlation-based correspondence, where the local pixels around a feature pair are compared using Structural SIMilarity index (SSIM), enhancing the correspondences, and a semantic-based filtering module, which further filters the obtained corresponding features using semantic data whenever detected in both the stereo image pair. While approaches in the literature are focused towards finding better features and their representation, the proposed approach advocates that correlation-based verification of the features can filter out bad correspondences, and in addition, aided by semantic-level filtering. These two modules establish the novelty of the work. The proposed correspondence matching algorithm is used to solve the problem of Visual Odometry to let a low-cost robot compute its pose in a novel environment. The experimental results show adequate filtering of wrong feature correspondence wherein, different environments with different lighting conditions were also considered. The proposed approach outperformed numerous state-of-the-art approaches available in the literature. The visual odometry algorithm using the proposed correspondence matching is compared against classical methods and a deep learning method, and it is observed that the proposed approach delivers lower trajectory error values in most scenarios on the KITTI dataset sequences.},
  archive      = {J_IJPRAI},
  author       = {Lhilo Kenye and Rahul Kala},
  doi          = {10.1142/S0218001422550138},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2255013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Feature-based correspondence filtering using structural similarity index for visual odometry},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decoupling of cell refractive index and thickness under
three-wavelength phase imaging. <em>IJPRAI</em>, <em>36</em>(9),
2254015. (<a href="https://doi.org/10.1142/S0218001422540155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative phase imaging (QPI) technology is one of the important techniques for nondestructive imaging of a cell’s morphology. In QPI, the decoupling of refractive index (RI) and thickness of a cell is a key problem. We aim at the multiple hypothesis constraints (MHC) shortcomings of the traditional method in the decoupling of multi-media and nonspherical cells. A method is proposed to decouple the RI and the thickness of a cell under three-wavelength phase imaging in this paper. In this method, the sample’s RI and thickness distributions can be obtained by solving three-wavelength phase equations using the approximate setting under dispersion based on the optical dispersion theories. In simulation experiments, the results show that the method can effectively decouple the RI and thickness for homogeneous and multi-media nonspherical cells and has high accuracy. Because the method in this paper is obtained by using few approximate assumptions and strict mathematical analysis, it can decouple the RI and thickness of nuclear cells with any shape, and moreover, it provides an important basis for the technological development of cell morphology analysis.},
  archive      = {J_IJPRAI},
  author       = {Jingrong Liao and Yawei Wang and Shuangshuang Xue and Yujuan Sun and Yuanyuan Xu},
  doi          = {10.1142/S0218001422540155},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2254015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Decoupling of cell refractive index and thickness under three-wavelength phase imaging},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-AGV task allocation with attention based on deep
reinforcement learning. <em>IJPRAI</em>, <em>36</em>(9), 2252015. (<a
href="https://doi.org/10.1142/S0218001422520152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated guided vehicle (AGV) is an important transportation equipment, which is widely used in warehouses and factories. In the scenarios of multi-AGVs application, an efficient AGVs task assignment strategy is beneficial for transportation costs, balance of workload and increasing distribution efficiency. The traditional method usually depends on a powerful scheduling system, which solves the task assignment problem in a regular way. In this paper, we present a decentralized framework of multi-task allocation with attention (MTAA) in deep reinforcement learning, which combines with the methods of task assignment in balance and path planning in cooperation for distribution application. As for task assignment balance, we adopt DNN network to achieve task assignment equilibrium. In multi-AGVs path planning, methods of A3C are embedded in MTAA framework, which are instrumental in improving the stationarity and performance in deep reinforcement learning application. In experiments, we designed two different scenarios under different obstacles to verify the performance of MTAA-A3C and MTAA-DQN methods. The experiments show that the proposed approach has feasibility and effectiveness used in multi-AGVs application.},
  archive      = {J_IJPRAI},
  author       = {Zuozhong Yin and Jihong Liu and Dianpeng Wang},
  doi          = {10.1142/S0218001422520152},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2252015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-AGV task allocation with attention based on deep reinforcement learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Actor-critic for multi-agent reinforcement learning with
self-attention. <em>IJPRAI</em>, <em>36</em>(9), 2252014. (<a
href="https://doi.org/10.1142/S0218001422520140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of deep reinforcement learning makes it widely used in multi-agent environments to solve the multi-agent cooperation problem. However, due to the instability of multi-agent environments, the performance is insufficient when using deep reinforcement learning algorithms to train each agent independently. In this work, we use the framework of centralized training with decentralized execution to extend the maximum entropy deep reinforcement learning algorithm Soft Actor-Critic (SAC) and proposes the multi-agent deep reinforcement learning algorithm MASAC based on the maximum entropy framework. Proposed model treats all the agents as part of the environment, it can effectively solve the problem of poor convergence of algorithms due to environmental instability. At the same time, we have noticed the shortcoming of centralized training, using all the information of the agents as input of critics, and it is easy to lose the information related to the current agent. Inspired by the application of self-attention mechanism in machine translation, we use the self-attention mechanism to improve the critic and propose the ATT-MASAC algorithm. Each agent can discover their relationship with other agents through encoder operation and attention calculation as part of the critic networks. Compared with the recent multi-agent deep reinforcement learning algorithms, ATT-MASAC has better convergence effect. Also, it has better stability when the number of agents in the environment increases.},
  archive      = {J_IJPRAI},
  author       = {Juan Zhao and Tong Zhu and Shuo Xiao and Zongqian Gao and Hao Sun},
  doi          = {10.1142/S0218001422520140},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2252014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Actor-critic for multi-agent reinforcement learning with self-attention},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New deep spatio-structural features of handwritten text
lines for document age classification. <em>IJPRAI</em>, <em>36</em>(9),
2252013. (<a href="https://doi.org/10.1142/S0218001422520139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document age estimation using handwritten text line images is useful for several pattern recognition and artificial intelligence applications such as forged signature verification, writer identification, gender identification, personality traits identification, and fraudulent document identification. This paper presents a novel method for document age classification at the text line level. For segmenting text lines from handwritten document images, the wavelet decomposition is used in a novel way. We explore multiple levels of wavelet decomposition, which introduce blur as the number of levels increases for detecting word components. The detected components are then used for a direction guided-driven growing approach with linearity, and nonlinearity criteria for segmenting text lines. For classification of text line images of different ages, inspired by the observation that, as the age of a document increases, the quality of its image degrades, the proposed method extracts the structural, contrast, and spatial features to study degradations at different wavelet decomposition levels. The specific advantages of DenseNet, namely, strong feature propagation, mitigation of the vanishing gradient problem, reuse of features, and the reduction of the number of parameters motivated us to use DenseNet121 along with a Multi-layer Perceptron (MLP) for the classification of text lines of different ages by feeding features and the original image as input. To demonstrate the efficacy of the proposed model, experiments were conducted on our own as well as standard datasets for both text line segmentation and document age classification. The results show that the proposed method outperforms the existing methods for text line segmentation in terms of precision, recall, F-measure, and document age classification in terms of average classification rate.},
  archive      = {J_IJPRAI},
  author       = {Palaiahnakote Shivakumara and Alloy Das and K. S. Raghunandan and Umapada Pal and Michael Blumenstein},
  doi          = {10.1142/S0218001422520139},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2252013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {New deep spatio-structural features of handwritten text lines for document age classification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variational graph autoencoder with mutual information
maximization for graph representations learning. <em>IJPRAI</em>,
<em>36</em>(9), 2252012. (<a
href="https://doi.org/10.1142/S0218001422520127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network (GNN) is a powerful representation learning framework for graph-structured data. Some GNN-based graph embedding methods, including variational graph autoencoder (VGAE), have been presented recently. However, existing VGAE-based methods typically focus on reconstructing the adjacent matrix, i.e. topological structure, instead of the node features matrix, this strategy makes graphical features difficult to be fully learned, which weakens and restricts the capacity of a generative network to learn higher-quality representations. To address the issue, we use a contrastive estimator on the representation mechanism, i.e. on the encoding process under the framework of VGAE. In particular, we maximize the mutual information (MI) between encoded latent representation and node attributes which acts as a regularizer forcing the encoder to select the most informative with respect to the node attributes. Additionally, we also solve another key question how to effectively estimate the mutual information by drawing samples from the joint and marginal, and explain why the maximization of MI can contribute to the encoder obtaining more node feature information. Ultimately, extensive experiments on three citation networks and four web-age networks show that our method outperforms contemporary popular algorithms (such as DGI) on node classifications and clustering tasks, and the best result is an 8 . 2 8 % increase on node clustering task.},
  archive      = {J_IJPRAI},
  author       = {Dongjie Li and Dong Li and Guang Lian},
  doi          = {10.1142/S0218001422520127},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2252012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Variational graph autoencoder with mutual information maximization for graph representations learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation model of urban smart energy system based on
improved genetic algorithm-bp neural network. <em>IJPRAI</em>,
<em>36</em>(9), 2251009. (<a
href="https://doi.org/10.1142/S0218001422510090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many problems such as strong subjectivity, complex calculations, and lack of intelligence in most of the current energy system evaluation models, so a design of an evaluation system for urban smart energy systems based on an improved genetic algorithm-back propagation (BP) neural network is proposed. First of all, the hierarchical structure of the indicator evaluation system for energy system was established, analytic hierarchy process (AHP) was used to assign weights to each indicator, and data samples were classified. Then, SeqGAN was used to expand the data set, which solved the difficult problem of data acquisition. Finally, the genetic algorithm was used to determine the best initial values of the weights and thresholds of the BP neural network structure parameters designed for this research. The simulation experiment results showed that the method in this paper has higher classification accuracy than the traditional method, and comprehensive evaluation model proposed can effectively evaluate the urban smart energy system.},
  archive      = {J_IJPRAI},
  author       = {Guobao Zhang and Yunhu Wang and Qing Duan and Yongming Huang and Chunyan Ma and Ruobing Xu and Lin Chai},
  doi          = {10.1142/S0218001422510090},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2251009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Evaluation model of urban smart energy system based on improved genetic algorithm-bp neural network},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving single-stage object detectors for nighttime
pedestrian detection. <em>IJPRAI</em>, <em>36</em>(9), 2250034. (<a
href="https://doi.org/10.1142/S0218001422500343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the reliability of nighttime pedestrian detection is a crucial challenge towards the design of robust autonomous systems. Not surprisingly, most pedestrian fatalities occur in low-illumination settings, thus emphasizing the need for new algorithmic advances. This work presents a novel pedestrian detection approach that makes a number of crucial modifications to the state-of-the-art YOLOV5-PANet architecture, in order to improve the reliability of features extracted from nighttime images. More specifically, the proposed architecture systematically incorporates powerful shuffle attention mechanisms and a transformer module to improve the feature learning pipeline. Instead of advocating the use of other sensing modalities that are better suited for nighttime detection, our approach relies only on conventional RGB cameras and is hence broadly applicable. Our empirical studies with nighttime pedestrian detection benchmarks show that with only minimal increase in model complexity, our approach provides significant improvements in detection efficacy over existing solutions. Finally, we explore the impact of post-hoc network pruning on the speed-accuracy trade-off of our approach and demonstrate that it is well suited for reduced memory/compute requirements.},
  archive      = {J_IJPRAI},
  author       = {Devi S and Kowshik Thopalli and Malarvezhi P and Jayaraman J. Thiagarajan},
  doi          = {10.1142/S0218001422500343},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2250034},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Improving single-stage object detectors for nighttime pedestrian detection},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human–object interaction detection based on star graph.
<em>IJPRAI</em>, <em>36</em>(9), 2250033. (<a
href="https://doi.org/10.1142/S0218001422500331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph attention networks (GATs)-based method performs well in Human–Object Interaction (HOI) detection due to its ability to aggregate contextual information. However, the traditional GATs-based methods are computationally intensive, and the graph’s structure cannot effectively represent the HOI in an image. Meanwhile, the graph models are unable to predict the interactions that involve less contextual information correctly. In this paper, we design a method based on graph models called V-SGATs, which stands for Visual Branch and Star Graph Attention Networks. The human-centric star graph and object-centric star graph are adopted to reduce computational complexity, and the logical structure of the star graph can represent HOI more reasonably. Meanwhile, the visual branch that recognizes the interaction without utilizing the contextual information is designed to aid the graph model in predicting the interactions that involve less contextual information. Experiments are carried out on two large-scale HOI public benchmarks V-COCO and HICO-DET, and the results show that the proposed method performs better than most of the existing methods based on GATs.},
  archive      = {J_IJPRAI},
  author       = {Shuang Cai and Shiwei Ma and Dongzhou Gu and Chang Wang},
  doi          = {10.1142/S0218001422500331},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2250033},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Human–Object interaction detection based on star graph},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). R-GEFS: Condorcet rank aggregation with graph theoretic
ensemble feature selection algorithm for classification.
<em>IJPRAI</em>, <em>36</em>(9), 2250032. (<a
href="https://doi.org/10.1142/S021800142250032X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few years, ensemble learning has received more interest primarily for the task of classification. It is based on the postulation that combining the output of multiple experts is better than the output of any individual expert. Ensemble feature selection may improve the performance of the learning algorithms and has the ability to obtain more stable and robust results. However, during the process of feature aggregation and selection, selected feature subset may contain high levels of inter-feature redundancy. To address this issue, a novel algorithm based on feature rank aggregation and graph theoretic technique for ensemble feature selection (R-GEFS) with the fusion of Pearson and Spearman correlation metrics is proposed. The method works by aggregation of the profile of preferences of five feature rankers as the base feature selectors. Then similar features are grouped into clusters using graph theoretic approach. The most representative feature strongly co-related to target decision classes is drawn from each cluster. The efficiency and effectiveness of the R-GEFS algorithm are evaluated through an empirical study. Extensive experiments on 15 diverse benchmark datasets are carried out to compare R-GEFS with seven state-of-the-art feature selection models with respect to four popular classifiers, namely decision tree, k nearest neighbor, random forest, and support vector machine. The proposed method turns out to be effective by selecting smaller feature subsets with lesser computational complexities and it assists in increasing the classification accuracy.},
  archive      = {J_IJPRAI},
  author       = {Rubul Kumar Bania},
  doi          = {10.1142/S021800142250032X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2250032},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {R-GEFS: Condorcet rank aggregation with graph theoretic ensemble feature selection algorithm for classification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-target passive location method based on GDOP value
and beam resolution. <em>IJPRAI</em>, <em>36</em>(8), 2258006. (<a
href="https://doi.org/10.1142/S021800142258006X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In passive location systems on the ground, the judgment and location of multi-target is more challenging compared with the case of single target. In this paper, we propose a method for multi-target identification and location in an arbitrary structure with three base stations (BSs). First of all, we discuss the scene of multi-targets judgment based on geometric dilution of precision (GDOP) value. Secondly, we propose an algorithm that calculates the system coverage radius based on arbitrary three BS structures. The algorithm helps to identify the number of targets for unsupervised learning. Finally, we locate each target individually located again based on the linear constrained minimum variance (LCMV) beam former and time difference of arrival (TDOA) algorithm. In the simulations, we analyzed the location dispersion under different signal-to-noise ratio (SNR), then calculated the termination threshold of the k -means algorithm under different SNR. The simulation results show that, compared to the probability hypothesis density (PHD) filter and TDOA-angle-of-arrival (AOA) joint algorithm, the proposed method can increase more than 12.5% and 15.6% points. With the increase of the number of targets, the running time of our algorithm is controllable with better stability.},
  archive      = {J_IJPRAI},
  author       = {Sheng Miao and Liang Dong and Xiaorui Wang},
  doi          = {10.1142/S021800142258006X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2258006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A multi-target passive location method based on GDOP value and beam resolution},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of acute pathology for vocal cord using
advanced multi-resolution algorithm. <em>IJPRAI</em>, <em>36</em>(8),
2258004. (<a href="https://doi.org/10.1142/S0218001422580046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vocal fold, a significant body structure, is accountable for phonation, which regulates air motion within and out of the lungs. The disorders in the vocal fold influence the quality of life. Thus, diagnosis of vocal fold disorders has a significant need, and CT of the neck is employed for an effective imaging scheme. Accordingly, this paper proposes an advanced multi-resolution algorithm (MRA) that optimally identifies and classifies pathologies. The vocal regions are acquired using the genetic k-means algorithm. The pathology features are generated using the local directional pattern (LDP) fed to pathology classification using moth search-rider optimization-based deep convolutional neural networks (MRA-based DCNN). The hybrid optimization (MRA), integrates the standard rider optimization algorithm (ROA) and moth search algorithm (MS) that trains deep learning classifier (DCNN). The analysis using the real databases regarding the performance metrics divulge that the proposed pathology detection module obtained the accuracy, specificity, and sensitivity of 97.020%, 91.698%, and 96.624%.},
  archive      = {J_IJPRAI},
  author       = {N Antony Sophia and G. Wiselin Jiji},
  doi          = {10.1142/S0218001422580046},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2258004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Classification of acute pathology for vocal cord using advanced multi-resolution algorithm},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Regional self-attention convolutional neural network for
facial expression recognition. <em>IJPRAI</em>, <em>36</em>(8), 2256013.
(<a href="https://doi.org/10.1142/S0218001422560134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) has been a challenging task in the field of artificial intelligence. In this paper, we propose a novel model, named regional self-attention convolutional neural network (RSACNN), for FER. Different from the previous methods, RSACNN makes full use of the facial texture of expression salient region, so yields a robust feature representation for FER. The proposed model contains two novel parts: regional local multiple pattern (RLMP) based on the improved K-means algorithm and the regional self-attention module (RSAM). First, RLMP uses the improved K-means algorithm to dynamically cluster the pixels to ensure the robustness of texture features with expression salient variation. Besides, the texture description is enhanced by extending the binary pattern to the multiple patterns and integrating the information of gray difference between pixels in the region. Next, RSAM can adaptively form weights for each region through the self-attention mechanism, and use rank regularization loss (RRLoss) to constrain the weights of different regions. By jointly combining RLMP and RSAM, RSACNN can effectively enhance the feature representation of expression salient regions, so that the performance of expression recognition can be improved. Extensive experiments on public datasets, i.e. CK + , Oulu-CASIA, Fer2013 and SFEW, prove the superiority of our method over state-of-the-art approaches.},
  archive      = {J_IJPRAI},
  author       = {Lifang Zhou and Yi Wang and Bangjun Lei and Weibin Yang},
  doi          = {10.1142/S0218001422560134},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2256013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Regional self-attention convolutional neural network for facial expression recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ORB features and isophotes curvature information for eye
center accurate localization. <em>IJPRAI</em>, <em>36</em>(8), 2256005.
(<a href="https://doi.org/10.1142/S0218001422560055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pupil center recognition and location is an essential branch of ergonomics. It can be applied to emotion analysis and attention judgment. How to get the position of the pupil center from eye photos is the core of this field. Previous studies provided a helpful method, using scale-invariant feature transform (SIFT) to extract relevant features and combine them with the K-Nearest Neighbor (KNN) classifier. However, this method’s accuracy is not satisfying, and under some conditions, it will be position drift and other problems. We put forward a new idea to solve it by using Oriented FAST and Rotated BRIEF (ORB) features and Random Forest (RF) classifies. It is proved by experiment that our method improves the robustness of localization and the use of isophotes yields low computational cost, allowing for real-time processing. Meanwhile, we found that the ORB and RF are nearly as good, yielding an accuracy of 92.88% (BioID database).},
  archive      = {J_IJPRAI},
  author       = {Pengxiang Xue and Changyuan Wang and Wenbo Huang and Guanghao Zhou},
  doi          = {10.1142/S0218001422560055},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2256005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {ORB features and isophotes curvature information for eye center accurate localization},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attention mechanism based on improved spatial-temporal
convolutional neural networks for traffic police gesture recognition.
<em>IJPRAI</em>, <em>36</em>(8), 2256001. (<a
href="https://doi.org/10.1142/S0218001422560018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action recognition has attracted extensive research efforts in recent years, in which traffic police gesture recognition is important for self-driving vehicles. One of the crucial challenges in this task is how to find a representation method based on spatial-temporal features. However, existing methods performed poorly in spatial and temporal information fusion, and how to extract features of traffic police gestures has not been well researched. This paper proposes an attention mechanism based on the improved spatial-temporal convolutional neural network (AMSTCNN) for traffic police gesture recognition. This method focuses on the action part of traffic police and uses the correlation between spatial and temporal features to recognize traffic police gestures, so as to ensure that traffic police gesture information is not lost. Specifically, AMSTCNN integrates spatial and temporal information, uses weight matching to pay more attention to the region where human action occurs, and extracts region proposals of the image. Finally, we use Softmax to classify actions after spatial-temporal feature fusion. AMSTCNN can strongly make use of the spatial-temporal information of videos and select effective features to reduce computation. Experiments on AVA and the Chinese traffic police gesture datasets show that our method is superior to several state-of-the-art methods.},
  archive      = {J_IJPRAI},
  author       = {Zhixuan Wu and Nan Ma and Yue Gao and Jiahong Li and Xinkai Xu and Yongqiang Yao and Li Chen},
  doi          = {10.1142/S0218001422560018},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2256001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Attention mechanism based on improved spatial-temporal convolutional neural networks for traffic police gesture recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). End-to-end multi-resolution 3D capsule network for people
action detection. <em>IJPRAI</em>, <em>36</em>(8), 2255015. (<a
href="https://doi.org/10.1142/S0218001422550151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an end-to-end multi-resolution three-dimensional (3D) capsule network for detecting actions of multiple actors in a video scene. Unlike previous capsule, network-based action recognition does not specifically concern with the individual action of multiple actors in a single scene, our 3D capsule network takes advantage of multi-resolution technique to detect different actions of multiple actors that have different sizes, scales, and aspect ratios. Our 3D capsule network is built on top of 3D convolutional neural network (3DCNN) that extracts spatio-temporal features from video frames inside regions of interest generated by Faster RCNN object detection. We first apply our method to the problem of detecting illegal cheating activities in a classroom examination scene with multiple subjects involved. Second, we test our system on the publicly available and extensively studied UCF-101 dataset. We compare our method with several state-of-the-art 3DCNN-based methods, first the multi-resolution 3DCNN, the single-resolution 3D capsule network, and a combination of both these models. We show that models containing 3D capsule networks have a slight advantage over the conventional 3DCNN and multi-resolution 3DCNN. Our 3D capsule networks not only perform a classification of said actions but also generate videos of single actions. Our experimental results show that the use of multi-resolution pathways in the 3D capsule networks make the result even better. Such findings also hold even when we use pre-trained C3D (convolutional 3D) features to train these networks. We believe that the multiple resolutions capture lower-level features at different scales. At the same time, the 3D capsule layers combine these features in more complex ways than conventional convolutional models.},
  archive      = {J_IJPRAI},
  author       = {Mohamad Ivan Fanany and Ahmad Arinaldi},
  doi          = {10.1142/S0218001422550151},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2255015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {End-to-end multi-resolution 3D capsule network for people action detection},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AFFNet: Attention mechanism network based on fusion feature
for image cloud removal. <em>IJPRAI</em>, <em>36</em>(8), 2254014. (<a
href="https://doi.org/10.1142/S0218001422540143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clouds frequently affect optical remote sensing pictures throughout the gathering process, resulting in low-resolution images that affect judgment and subsequent use of ground data. Because of the thick cloud cover, the ground surface information below is entirely incorrect. This kind of end-to-end image problem should not be dismissed as a simple task of image inpainting or image translation. Therefore, this paper proposes a multi-head self-attention module based on the encoding–decoding generative adversarial network, considering the redundant information of the deep network, furthermore this paper introduces Ghost convolution to effectively solve the influence of redundant feature maps in the network on the increase of time consumption and parameters. The method in this paper can solve the problem of cloud occlusion. By considering spatial information, it can better complete the prediction of cloud removal. It can reduce the amount of network calculations and parameters while maintaining the effect. In addition, Feature Fusion Module is proposed to integrate high-level features with low-level features, so that the network can extract enough feature information and better supplement the details to complete the cloud removal. The method in this paper has achieved excellent results on the RICE1 and RICE2 datasets.},
  archive      = {J_IJPRAI},
  author       = {Runhan Shen and Xiaofeng Zhang and Yonggang Xiang},
  doi          = {10.1142/S0218001422540143},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2254014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {AFFNet: Attention mechanism network based on fusion feature for image cloud removal},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-attention residual network for image super resolution.
<em>IJPRAI</em>, <em>36</em>(8), 2254009. (<a
href="https://doi.org/10.1142/S021800142254009X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many studies have shown that deep convolutional neural network can achieve superior performance in image super resolution (SR). The majority of current CNN-based SR methods tend to use deeper architecture to get excellent performance. However, with the growing depth and width of network, the hierarchical features from low-resolution (LR) images cannot be exploited effectively. On the other hand, most models lack the ability of discriminating different types of information and treating them equally, which results in limiting the representational capacity of the models. In this study, we propose the multi-attention residual network (MARN) to address these problems. Specifically, we propose a new multi-attention residual block (MARB), which is composed of attention mechanism and multi-scale residual network. At the beginning of each residual block, the channel importance of image features is adaptively recalibrated by attention mechanism. Then, we utilize convolutional kernels of different sizes to adaptively extract the multi-attention features on different scales. At the end of blocks, local multi-attention features fusion is applied to get more effective hierarchical features. After obtaining the outputs of each MARB, global hierarchical feature fusion jointly fuses all hierarchical features for reconstructing images. Our extensive experiments show that our model outperforms most of the state-of-the-art methods.},
  archive      = {J_IJPRAI},
  author       = {Qing Chang and Xiaotian Jia and Chenhao Lu and Jian Ye},
  doi          = {10.1142/S021800142254009X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2254009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-attention residual network for image super resolution},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local resultant gradient vector difference and inpainting
for 3D text detection in the wild. <em>IJPRAI</em>, <em>36</em>(8),
2253005. (<a href="https://doi.org/10.1142/S0218001422530056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) text appearing in natural scene images is common due to 3D cameras and the capture of text from different angles, which presents new problems for text detection. This is because of the presence of depth information, shadows, and decorative characters in the images. In this work, we consider those images where 3D text appears with depth, as well as shadow information for text detection. We propose a novel method based on local resultant gradient vector difference (LRGVD), inpainting and a deep learning model for detecting 3D as well as two-dimensional (2D) texts in natural scene images. The boundary of components that are invariant to the above challenges is detected by exploring LRGVD. The LRGVD uses gradient magnitude and direction in a novel way for detecting the boundary of the components. Further, we propose an inpainting method in a new way for restoring the character background information using boundaries. For a given region and the input image, the inpainting method divides the whole image into planes and then propagates the values in the planes into the missing region based on posterior probabilities and neighboring information. This results in text regions with false positives. Then, the differential binarization network (DB-Net) is proposed for detecting text irrespective of orientation, background, 3D or 2D, etc. Experiments conducted on our 3D text images and standard datasets of natural scene text images, namely ICDAR 2019 MLT, ICDAR 2019 ArT, DAST1500, Total-Text and SCUT-CTW1500, show that the proposed method is effective in detecting 3D and 2D texts in the images.},
  archive      = {J_IJPRAI},
  author       = {Dajian Zhong and Palaiahnakote Shivakumara and Lokesh Nandanwar and Umapada Pal and Michael Blumenstein and Yue Lu},
  doi          = {10.1142/S0218001422530056},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2253005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Local resultant gradient vector difference and inpainting for 3D text detection in the wild},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Text representation model for multiple language forms in
spoken chinese expression. <em>IJPRAI</em>, <em>36</em>(8), 2253004. (<a
href="https://doi.org/10.1142/S0218001422530044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixture of multiple language forms in spoken Chinese is a common but unfavorable issue.. It increases the difficulty of intent understanding and leads to inconvenience for information communication. Existing studies on intent recognition mainly focus on single language form or parallel multilingual language while paying little attention to spoken texts including multiple language forms. In considering that it is hard to capture the semantics of an expression with multiple language forms, it is important to study the problem. To solve this issue, a text representation model for the spoken Chinese expression mixed with English and Chinese Pinyin is proposed. And the feature matrix is built to mine the composition information of English and Pinyin. Besides, the model can efficiently distinguish English from Chinese Pinyin even though both fragments are composed of English letters. Meanwhile, it can effectively process the problem of hidden text information since the problem has been transformed into the Chinese translation task of English and Pinyin. In addition, to verify the performance of the model, the texts processed by this model are used as the input of the classifier. extensive experiments on a large online logistics manual customer service corpus show that this text representation model is correct and effective. It can not only eliminate the obstacles of the mixing of multiple language forms but also bring better results for intent understanding.},
  archive      = {J_IJPRAI},
  author       = {Miao Hu and Junjie Peng and Wenqiang Zhang and Jingxiang Hu and Lizhe Qi and Huanxiang Zhang},
  doi          = {10.1142/S0218001422530044},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2253004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Text representation model for multiple language forms in spoken chinese expression},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent decision method of multi-agricultural commodity
model based on machine learning. <em>IJPRAI</em>, <em>36</em>(8),
2251003. (<a href="https://doi.org/10.1142/S021800142251003X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {China Agricultural Outlook publishes the outlook report on major agricultural commodities and the estimates of the supply–demand balance sheet of agricultural commodities in the next decade, so as to release agricultural information and guide the development of modern agriculture. A large amount of data has been accumulated in the work associated with agriculture outlook in recent years. This paper will optimize the agriculture commodity model through deep learning and create an analysis tool based on long short-term memory (LSTM) deep learning by comprehensively considering the key factors of supply and demand of agricultural commodities including the output, consumption and price and combining the impact of complex natural, social and economic factors. In this way, the close relevance of different varieties and multi-variable strong coupling of the analysis and prediction model of major agricultural commodities can be solved. The “random sampling” and “stress on causality” of traditional complex agriculture analysis models are replaced by the “whole data” and “emphasis on relevance over causality”. The intelligent decision method of agricultural commodity model based on deep learning proposed in this study can effectively improve the analysis efficiency and accuracy of multi-variety coupling model of agricultural commodities (at least by 15%), and enhance the intelligence of the supply–demand analysis and prediction, especially with the accumulation of future data, the prediction accuracy will continue to improve. Machine learning has been regarded as an effective method to provide forecast and early-warning of future agricultural development in a timely manner based on real-time monitoring of agricultural data.},
  archive      = {J_IJPRAI},
  author       = {Jiayu Zhuang and Shiwei Xu and Ganqiong Li and Zhiping Zhong},
  doi          = {10.1142/S021800142251003X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2251003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Intelligent decision method of multi-agricultural commodity model based on machine learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Golden mutator recommendation based on mutation pattern
mining. <em>IJPRAI</em>, <em>36</em>(8), 2250025. (<a
href="https://doi.org/10.1142/S0218001422500252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mutation testing is widely used in the research of evaluation and optimization of test set quality, and has been paid attention to the study of bug localization and fixing. But one inherent problem of mutation testing is huge computation cost. Selective mutation is an important method to reduce mutation testing cost. However, the existing selective mutation researches indicate that there is no universal selection strategy. This paper proposes a method which integrates with historical software data mining to recommend suitable mutator for program under test. The basic idea of the method is in the software version control system, any pair of nonfixed and post-fixed programs can be original program and mutant of each other. The edit performed during bug fixing contains mutators, and such mutator can guide buggy program to correct program, hence it is called Golden Mutator. The basic method is to compare the buggy files and the corresponding fixed files in the version control system, obtain historical faulty statements and their fix editing operations, thereby accumulating the bug-fix instance base, and then mining mutation patterns from it. Before mutating the target statement, we first find out faulty instances similar to the target statement, and use their fixing edits to match with the mutation pattern, so as to get the golden mutator applicable to the target statement. This paper uses Defects4j dataset in the test, verifies the accuracy of the proposed recommendation method, and further uses the method in bug localization. Compared to fixedly selected mutators, when applying the golden mutator recommended by using the proposed method, the average accuracy of bug localization is higher.},
  archive      = {J_IJPRAI},
  author       = {Dan Gong and Tiantian Wang and Xiaohong Su},
  doi          = {10.1142/S0218001422500252},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2250025},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Golden mutator recommendation based on mutation pattern mining},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attribute-guided global and part-level identity network for
person re-identification. <em>IJPRAI</em>, <em>36</em>(8), 2250011. (<a
href="https://doi.org/10.1142/S0218001422500112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the person re-identification (re-ID) algorithms based on deep learning mainly learn the global feature representation of pedestrians, while ignoring the important role of fine-grained pedestrian attribute features on re-ID tasks. Pedestrian attributes are middle-level semantic features, which have invariance in different poses, camera views, and illumination conditions. Considering the robustness and promotion of pedestrian attributes for person re-ID task, we propose an Attribute-guided Global and Part-level identity Network (AGPNet), which consists of a global identity task, a part-level identity task, and a pedestrian attributes learning task. AGPNet takes advantage of perceived semantic information of pedestrian attributes and deploys them as guidance to attend to human body regions and learn robust feature representation in the feature representation construction stage. Extensive experiments on two large-scale person re-ID datasets (Market-1501 and DukeMTMC-reID) show the effectiveness of our method, which is competitive with the state-of-the-art algorithms.},
  archive      = {J_IJPRAI},
  author       = {Shaoming Pan and Wenqiang Feng and Yanwen Chong},
  doi          = {10.1142/S0218001422500112},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2250011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Attribute-guided global and part-level identity network for person re-identification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic object detection and direction prediction of
unmanned vessels based on multiple convolutional neural network
technology. <em>IJPRAI</em>, <em>36</em>(8), 2250002. (<a
href="https://doi.org/10.1142/S0218001422500021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to detect objects quickly and accurately and then start the necessary obstacle avoidance procedure when the uncrewed vessel is at sea. This study uses a multivariate convolutional neural network (CNN) to perform automatic object detection and direction prediction for uncrewed vessels. This study is divided into three parts for processing. The first part of this process uses camera calibration technology to correct the image. Discrete cosine transform (DCT) is then used to detect sea level. Finally, this study uses Kalman filtering and affine transformation to stabilize images taken by uncrewed vessels at sea. The second part of the processing system uses a CNN to detect sea objects automatically. The third part of the process uses the dual-lens camera installed on the vessel to detect the distance and direction of objects at sea. In the experiment, the detection rate can reach more than 91% in this study method. In the experiment on image stabilization, this study’s method can also effectively improve video instability. In the experiment involving the distance and direction of the object, the experimental results show that the distance and direction of the object obtained by this study method have a distance error value of less than 10%, and the prediction results have a good effect no matter whether the object is at a short or long distance. It is hoped that this paper’s method can be applied to the automatic obstacle avoidance of unmanned vessels.},
  archive      = {J_IJPRAI},
  author       = {Chuen-Horng Lin and Xin-Cheng Wang},
  doi          = {10.1142/S0218001422500021},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2250002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Automatic object detection and direction prediction of unmanned vessels based on multiple convolutional neural network technology},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Short-packet transmission in irregular repetition slotted
ALOHA system over the rayleigh fading channel. <em>IJPRAI</em>,
<em>36</em>(7), 2259016. (<a
href="https://doi.org/10.1142/S0218001422590169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random access systems are potential for Internet of Things in the future wireless communication network for its operational simplicity. Irregular repetition slotted ALOHA (IRSA) system is one of the high-efficiency random access systems. In this paper, performance analysis of the irregular repetition slotted ALOHA systems with short-packet, i.e. finite-blocklength, transmission for the quasi-static Rayleigh fading channel is given. A cumulative distribution function of signal-to-interference power ratio (SIR) is derived and thus a closed-form expression of an average packet error probability (PEP) at the SIR with short packets for the Rayleigh fading channel is given. The closed-form expression makes it possible to optimize the degree distributions at a specific blocklength in the sense that the systems give the maximum system load.},
  archive      = {J_IJPRAI},
  author       = {Ni Tian and Xuelian Cai and Jun Cheng and Wenwei Yue and Maofeng Luo},
  doi          = {10.1142/S0218001422590169},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2259016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Short-packet transmission in irregular repetition slotted ALOHA system over the rayleigh fading channel},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conformance between choreography and collaboration in BPMN
involving multi-instance participants. <em>IJPRAI</em>, <em>36</em>(7),
2259013. (<a href="https://doi.org/10.1142/S0218001422590133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI-based process model analysis has attracted more and more interest. Model quality is crucial for such research. At present, inter-organizational business process (IOBP) has been widely used in the model design and development of the distributed system. Before implementing the intelligent analysis of the IOBP model, conformance as a foundation for model quality checking plays a key role because it ensures in advance that the participants can successfully interact without violating the global communication constraints imposed by the choreography. In fact, the multi-instance participant is a common requirement in IOBP. This paper provides a formal approach and framework supporting the conformance between BPMN choreography and collaboration while considering multi-instance participants and message communication modes. As a core, the formalization proposed is based on BNF syntax and structured CSP# processes. It can well support multi-instance features and multiple communication modes. Combined with CSP#, the formal definitions of communication modes and verification properties are given. On this basis, an integrated framework is provided to support automated formal verification referring to multiple communication modes. Finally, a set of experiments is conducted to demonstrate the effectiveness of the proposal.},
  archive      = {J_IJPRAI},
  author       = {Tianhong Xiong and Maolin Pan and Yang Yu and Dingjun Lou},
  doi          = {10.1142/S0218001422590133},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2259013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Conformance between choreography and collaboration in BPMN involving multi-instance participants},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DMS-SK/BLSTM-CTC hybrid network for gesture/speech fusion
and its application in lunar robot–astronauts interaction.
<em>IJPRAI</em>, <em>36</em>(7), 2258005. (<a
href="https://doi.org/10.1142/S0218001422580058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the future manned lunar exploration mission, astronauts would work with the lunar robots, which has a high requirement for human–robot interaction (HRI). As the accuracy of gesture recognition interaction does not fulfill the requirement for human–robot joint exploration missions, we propose the DMS-SK/BLSTM-CTC hybrid network to improve the performance of HRI. For gesture recognition, considering VGG-SK has low accuracy and complex architecture, we delete the fourth convolution module, optimize the last global pooling layer, introduce dilated convolution block and multiscale convolution block in VGG-SK, and get the DMS-SK-based gesture recognition sub-network. Compared with the traditional recognition methods, the accuracy and performance of DMS-SK improve. For speech recognition, considering that Bidirectional long–short-term memory unit (BLSTM) has the advantages of processing temporal information, and the Connectionist Temporal Classification (CTC) algorithm can simplify speech data preprocessing, we use BLSTM based on CTC as the speech recognition sub-network. Finally, we combine DMS-SK with BLSTM-CTC, and propose the DMS-SK/BLSTM-CTC hybrid network as the gesture/speech hybrid network. In addition, we use 10 gestures in the American Sign Language (ASL) dataset and 10 speech commands to construct the gesture/speech hybrid dataset. Experimental results show that compared with the pure gesture or pure speech networks, the recognition accuracy of the gesture-speech hybrid network improves by 2% and 12%, respectively, its accuracy reaches 97.38%, which fulfills the requirement of astronauts for HRI.},
  archive      = {J_IJPRAI},
  author       = {Jian Ding and Jin Liu and Xiaolin Ning and Zhiwei Kang},
  doi          = {10.1142/S0218001422580058},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2258005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DMS-SK/BLSTM-CTC hybrid network for Gesture/Speech fusion and its application in lunar Robot–Astronauts interaction},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Small-footprint keyword spotting based on gated channel
transformation sandglass residual neural network. <em>IJPRAI</em>,
<em>36</em>(7), 2258003. (<a
href="https://doi.org/10.1142/S0218001422580034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keyword spotting plays a crucial role in realizing voice-based user interaction on intelligent equipment terminals and service robots. In this task, it remains challenging to achieve the balance between low memory and high precision. To better satisfy this requirement, we propose an end-to-end neural architecture with sandglass residual blocks embedded with the gated channel-wise attention mechanism. The sandglass residual blocks utilize 1D separable convolutions to extract bottleneck temporal features, which can effectively drive the model to focus more on the speech segment with lower parameters. Especially, the gated attention mechanism helps the model enhance the critical speech temporal features and suppress the useless ones and further focus on the most important part of the human speech region for keyword spotting. The experimental results on Google Speech Commands Dataset show that our proposed model has an accuracy of 97.4 % with only 46K parameters. Compared with the baseline method with the highest accuracy, our model parameters are decreased by 54 % and accuracy is increased by 0.8 % . That makes us take further step in achieving the goal of low memory and high precision.},
  archive      = {J_IJPRAI},
  author       = {Ying Zhang and Shirong Zhu and Chao Yu and Lasheng Zhao},
  doi          = {10.1142/S0218001422580034},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2258003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Small-footprint keyword spotting based on gated channel transformation sandglass residual neural network},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inverse representation inspired multi-resolution dictionary
learning method for face recognition. <em>IJPRAI</em>, <em>36</em>(7),
2256012. (<a href="https://doi.org/10.1142/S0218001422560122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition is widely used and is one of the most challenging tasks in computer vision. In recent years, many face recognition methods based on dictionary learning have been proposed. However, most methods only focus on the resolution of the original image, and the change of resolution may affect the recognition results when dealing with practical problems. Aiming at the above problems, a method of multi-resolution dictionary learning combined with sample reverse representation is proposed and applied to face recognition. First, the dictionaries associated with multiple resolution images are learnt to obtain the first representation error. Then different auxiliary samples are generated for each test sample, and a dictionary consisted of test sample, auxiliary samples, and other classes of training samples is established to sequentially represent all training samples at this resolution, and to obtain the second representation error. Finally, a weighted fusion scheme is used to obtain the ultimate classification result. Experimental results on four widely used face datasets show that the proposed method achieves better performance and is effective for resolution change.},
  archive      = {J_IJPRAI},
  author       = {Chunman Yan and Yuyao Zhang},
  doi          = {10.1142/S0218001422560122},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2256012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Inverse representation inspired multi-resolution dictionary learning method for face recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid random forest classifier for chronic kidney disease
prediction from 2D ultrasound kidney images. <em>IJPRAI</em>,
<em>36</em>(7), 2256010. (<a
href="https://doi.org/10.1142/S0218001422560109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chronic kidney disease (CKD) is one of the causes of mortality in almost all countries across the globe and the notable thing is its asymptomatic nature in the early stages. This disease is characterized by the gradual loss of kidney function in an individual. Frequently chronic kidney disease is diagnosed based on the Estimated Glomerular Filtration Rate (eGFR) determined from blood and urine tests. In order to reduce the risk factors arising due to chronic kidney disease, it is essential to be diagnosed in the earlier stages itself. This work proposes an automated chronic kidney disease detection based on the textural features of the kidney using a hybrid random forest classifier from 2D ultrasound kidney images. The proposed classifier is compared with the other competing machine learning classifiers through experimenting on a dataset of 150 images and gives a better accuracy of 9 6 . 6 7 % with 1 0 0 % of recall and precision, thus proving it to be promising in detecting CKD noninvasively in the early stages.},
  archive      = {J_IJPRAI},
  author       = {Deepthy Mary Alex and D. Abraham Chandy and A. Hepzibah Christinal and Arvinder Singh and M. Pushkaran},
  doi          = {10.1142/S0218001422560109},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2256010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A hybrid random forest classifier for chronic kidney disease prediction from 2D ultrasound kidney images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human body pose distance image analysis for action
recognition. <em>IJPRAI</em>, <em>36</em>(7), 2255012. (<a
href="https://doi.org/10.1142/S0218001422550126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Body pose analysis is an important factor of human action recognition. Recently, the proposed Recurrent Neural Networks (RNNs) and deep ConvNets-based methods are showing good performances in learning sequential information. Despite these good performances, RNN lacks to efficiently learn spatial relation between body parts while deep ConvNets require a huge amount of data for training. We propose a Distance-based Neural Network (DNN) for action recognition in static images. We compute effective distances between a set of body part pairs for a given image and feed to DNN to learn effective representation of complex actions. We also propose Distance-based Convolutional Neural Network (DCNN) to learn representations from 2D images. The distances are rearranged in 2D grayscale image called as a Distance Image. This 2D representation allows the network to learn specific discriminative information between adjacent pixel distance values corresponding to different body part pairs. We evaluate our method on two real-world datasets i.e. UT-Interaction and SBU Kinect Interaction. Results show that our proposed method achieves better performance compared to the state-of-the-art approaches.},
  archive      = {J_IJPRAI},
  author       = {Amit Verma and Toshanlal Meenpal and Bibhudendra Acharya},
  doi          = {10.1142/S0218001422550126},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2255012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Human body pose distance image analysis for action recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A_CenterNet: Object as a point by attention.
<em>IJPRAI</em>, <em>36</em>(7), 2255011. (<a
href="https://doi.org/10.1142/S0218001422550114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, in view of the insufficiency of the CenterNet detector’s inability to achieve high real-time performance with high accuracy when performing object detection, we designed a new detector called A_CenterNet. In the detector, we use our newly designed lightweight Hourglass-256 model, and we also use the feature map fusion method we designed, as well as our improved attention mechanism. Through the experimental results on multiple datasets, it can be known that the A_CenterNet proposed in this paper has a competitive advantage compared with some existing classic detectors. A_CenterNet achieves the best speed-accuracy trade-off on the MS COCO dataset, with 44.6 AP at 36 FPS. Compared with CenterNet, A_CenterNet greatly improves the detection speed without loss of detection accuracy.},
  archive      = {J_IJPRAI},
  author       = {Xianrang Shi and Yang Su and Yan Ti and Tinglun Song},
  doi          = {10.1142/S0218001422550114},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2255011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A_CenterNet: Object as a point by attention},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lane detection based on multi-frame image input.
<em>IJPRAI</em>, <em>36</em>(7), 2254012. (<a
href="https://doi.org/10.1142/S021800142254012X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lane detection is one of the difficulties in implementing an advanced driving assistance system. In this paper, we show that the existing single frame-based algorithm suffers from the problem of unsatisfied detection result, which is directly caused by some extremely poor road environments (such as severe shadow occlusion and severe fading). To solve the problem, this paper proposes a multi-lane detection method based on the improved U-SegNet model. In order to get better feature extraction results, the number of network layers of the U-SegNet model is deepened, and a many-to-many structure is also proposed to improve the recognition rate of the algorithm. During the training stage, continuous multiple frames are input into the RNN module to get the feature maps for feature learning and prediction. The proposed method is tested on Caltech lane marking dataset, the results show that the proposed algorithm has good robustness and real-time performance, the multi-lane marking can be better detected under most complex road conditions, and the average detecting accuracy can achieve 96.95%.},
  archive      = {J_IJPRAI},
  author       = {Chao Fan and Fangfang Chen and Yupei Song},
  doi          = {10.1142/S021800142254012X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2254012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Lane detection based on multi-frame image input},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid optimization algorithm-based generative adversarial
network for change detection using pre-operative and post-operative MRI.
<em>IJPRAI</em>, <em>36</em>(7), 2251007. (<a
href="https://doi.org/10.1142/S0218001422510077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic detection of tumors is important to speed up treatment and to increase the survival rate of patients. In brain tumor detection, Magnetic Resonance Imaging (MRI) is considered an effective imaging model, which offers the internal structure of the brain. Change detection by pre-operative as well as post-operative multimodal images is an important research area in recent decades. Thus, this paper designs a hybrid optimization algorithm-based deep learning classifier to find the percentage of change detection in multimodal images. Initially, preprocessing is progressed to eradicate the noise from MRI images and then segmentation is performed using the modified DeepJoint model. After that, the pre-operative and the post-operative MRI images are engaged for the classification of a tumor. The classification of brain tumors is performed by Deep Convolutional Neural Network (Deep CNN) trained by a Tunicate Exponential Weighted Moving Average (TEWMA) algorithm, which is the integration of Tunicate Swarm Algorithm (TSA) and Exponential Weighted Moving Average (EWMA). After classification, the volume difference and the percentage of change detection are computed by GAN trained by PS-TEWMA, which is the integration of Particle Swarm Optimization (PSO) with TSA and EWMA. The proposed PS-TEWMA-based GAN obtained lower MSE and RMSE of 0.0881 and 0.2968 by measuring the volume detection. Also, it obtained minimal MSE and RMSE of 0.102 and 0.3194 concerning the percentage of change detection.},
  archive      = {J_IJPRAI},
  author       = {Divya S and L. Padma Suresh and Ansamma John},
  doi          = {10.1142/S0218001422510077},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2251007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Hybrid optimization algorithm-based generative adversarial network for change detection using pre-operative and post-operative MRI},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Region-based split octonion networks with channel attention
module for tuna classification. <em>IJPRAI</em>, <em>36</em>(7),
2250030. (<a href="https://doi.org/10.1142/S0218001422500306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tuna fish is a popular food because of its nutritional value and taste. Demand for various species of tuna increases over time, necessitating the development of a system to sort tuna fish into distinct species in export sectors in order to accelerate the process. The work proposes an automated tuna classification system based on split octonion network. The images are initially preprocessed and divided into region images. Each region image is applied to a split octonion network with eleven layers. In addition, a split octonion channel attention module is presented, which is fed to the last two convolutional layers. The features from the three octonion networks are fused and applied to a series of dense layers. In the last layer, a softmax classifier is utilized for final classification. Results show that the proposed region-based split octonion network with attention module gives an accuracy of 98.01% on tuna database. The region-based tuna classification model is fine-tuned for the categorization of six species from QUT-FishBase dataset and Fish-Pak dataset. The system shows accuracies of 97.83% and 98.17% on QUT-FishBase and Fish-Pak datasets, respectively. The proposed methodology is also compared with existing approaches using a variety of evaluation criteria.},
  archive      = {J_IJPRAI},
  author       = {Jisha Anu Jose and C. Sathish Kumar and S. Sureshkumar},
  doi          = {10.1142/S0218001422500306},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2250030},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Region-based split octonion networks with channel attention module for tuna classification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Four-stream network and nonsignificant feature learning for
visible–infrared person re-identification. <em>IJPRAI</em>,
<em>36</em>(7), 2250029. (<a
href="https://doi.org/10.1142/S021800142250029X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible–infrared person re-identification (VI-ReID) is a current focused area in the field of re-identification. In order to reduce the gap between two modalities in VI-ReID and improve recognition accuracy, this paper proposes a four-stream network and nonsignificant feature learning (FS-NSF) method for VI-ReID. First, the dual-intermediate modality images of visible and infrared modalities are generated by two lightweight networks, and the labels are inherited from the visible and infrared images. Second, the ResNet50 backbone network is split in order to reconstruct the network adapted to shared feature learning of the four modalities. Finally, a multi-branch, multi-scale and multi-granularity feature extraction strategy is used to extract both significant and nonsignificant features. The comparison experiments are conducted on SYSU-MM01 dataset and RegDB dataset. The experimental results show that, compared with state-of-the-arts, our method has excellent performance on both datasets, especially on the SYSU-MM01 dataset, with an increase in performance of 1.9–6.28% for each index.},
  archive      = {J_IJPRAI},
  author       = {Yilei Liang and Hua Han and Li Huang and Chunyuan Wang},
  doi          = {10.1142/S021800142250029X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2250029},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Four-stream network and nonsignificant feature learning for Visible–Infrared person re-identification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lightweight convolution neural network based on multi-scale
parallel fusion for weed identification. <em>IJPRAI</em>,
<em>36</em>(7), 2250028. (<a
href="https://doi.org/10.1142/S0218001422500288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of weed species is the premise for controlling weeds in field. But it is a challenging task due to the complexity and high-dimensional nonlinearity of the weed images in natural field. Convolutional neural networks (CNNs) model has been widely applied to image identification, but most of the CNNs models have the problems of large parameters, low identification accuracy, and single feature scale. This paper presents a novel deep neural network structure, named as MPF-Net for weed species identification. In MPF-Net, firstly, the weed images is sent into two different scales of depthwise separable convolution layers; secondly, the parallel output feature information is cross-fused, and uses the residual learning structure to increase the network model depth and feature extraction ability; finally the lightweight model PL-Model and the scale reduction module SR-Model are stacked together to construct the lightweight network. We have performed extensive experiments on real weed datasets, and compared the proposed MPF-Net against several variations of lightweight networks. The experimental results on the weed image dataset show that the proposed method is effective and feasible for weed species identification.},
  archive      = {J_IJPRAI},
  author       = {Zhen Wang and Jianxin Guo and Shanwen Zhang},
  doi          = {10.1142/S0218001422500288},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2250028},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Lightweight convolution neural network based on multi-scale parallel fusion for weed identification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lightweight hardware architecture for object detection in
driver assistance systems. <em>IJPRAI</em>, <em>36</em>(7), 2250027. (<a
href="https://doi.org/10.1142/S0218001422500276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection on hardware platforms plays a very significant role in developing driver assistance systems (DASs) with limited computational resources. Object detection for DAS is a multiclass detection problem that involves detecting various objects like cars, auto, traffic lights, bicycles, pedestrians, etc. DAS also requires accuracy, speed, and sensitivity for detecting these objects in various challenging conditions. The lighting and weather conditions pose a serious challenge for accurate object detection for DAS. This paper proposes a speed-efficient and lightweight fully convolutional neural network (CNN) architecture for object detection in adverse rainy conditions. The proposed architecture uses a CNN-based deraining network with a custom SSIM loss function in the object detection pipeline, which can give an accurate performance using limited computational and memory resources. The object detection architecture contains some architectural modifications to the existing single shot multibox detector (SSD) architecture to make it more hardware efficient and improve accuracy on small objects. It uses a trainable color transformation module using 1 × 1 convolutions for handling the adverse lighting conditions encountered in DAS. The architecture uses feature fusion and the dilated convolution approach to enhance the accuracy of the proposed architecture on small objects. The datasets available for object detection in DAS are very imbalanced with cars as a predominant object. The class weight penalization technique is used to improve the performance of the architecture on scarcely present objects. The performance of the architecture is evaluated on well-known datasets like Kitti, Udacity, Indian Driving Dataset (IDD), and DAWN. The architecture achieves satisfactory performance in terms of mean average precision (mAP) and detection time on all these datasets. It requires three times fewer hardware resources compared to existing architectures. The lightweight nature of the proposed architecture and modification of CNN architecture with TensorRT allow the efficient implementation on the jetson nanohardware platform for prototyping, which can be integrated with other intelligent transportation systems.},
  archive      = {J_IJPRAI},
  author       = {Bhaumik Vaidya and Chirag Paunwala},
  doi          = {10.1142/S0218001422500276},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2250027},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Lightweight hardware architecture for object detection in driver assistance systems},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Link connectivity-based access selection method for
multi-UAV heterogeneous networks. <em>IJPRAI</em>, <em>36</em>(6),
2259012. (<a href="https://doi.org/10.1142/S0218001422590121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While UAV ad hoc networks have made significant progress, implementing it in most of real-application scenarios is challenging due to data explosion. Instead of only ad hoc mode, this work simultaneously considers non-orthogonal multiple access technique (NOMA) and ad hoc mode to handle the problem. We further propose an effective framework to seamlessly integrate these two techniques, namely Multi-UAV heterogeneous networks. Specifically, we formulate the framework as a mixed integer nonlinear programming, in which original problem can be decomposed into two sub-problems, e.g., access mode selection for UAV to UAV mode (U2U) and UAV to Ground Base mode (U2G), and transmission rate optimization. For the access mode selection, to reduce the computational complexity at each UAV, a candidate set is constructed based on the connection time and link quality. After that, the component in candidate set that maximizes the objective function is selected as the access point. Due to the different communication techniques in U2U mode and U2G mode, we can obtain the optimal rate for each UAV by using the NOMA technique in U2G mode and channel prediction method with local information in U2U mode, respectively. For the transmission rate optimization, an effective algorithm is proposed for U2G mode and U2U mode, which considers the effects of the network connectivity and link quality on the optimization performance. Simulation results show that our method can reduce the outage rate and improve the network throughput effectively.},
  archive      = {J_IJPRAI},
  author       = {Shaojie Wen and Lianbing Deng and Zengliang Liu},
  doi          = {10.1142/S0218001422590121},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2259012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Link connectivity-based access selection method for multi-UAV heterogeneous networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). POGT: A peking opera gesture training system using infrared
sensors. <em>IJPRAI</em>, <em>36</em>(6), 2256011. (<a
href="https://doi.org/10.1142/S0218001422560110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peking opera is one of the national cultural heritages in China. However, it is difficult for people to learn the gestures in Peking opera performance, which limits the spread of this traditional culture. To address this issue, we propose a Peking opera gesture training system using infrared sensors. Specifically, we build a character avatar for demonstrating the gestures in Peking opera in the proposed system. Based on the data collected by infrared sensors, a method for calculating gesture similarity is proposed and is applied for the training of Peking opera gestures, which allows natural interactions and provides interactive feedback for user gestures. We conducted multiple experiments to verify the feasibility and effectiveness of the training system. The experimental results showed that the proposed system can overcome the difficulties in the traditional learning process of Peking opera gestures, which helps users to achieve the goal of learning standard Peking opera gestures. The proposed training system greatly eases the learning of Peking opera gestures, adding vitality into the culture of traditional Peking opera.},
  archive      = {J_IJPRAI},
  author       = {Xingquan Cai and Tong Wang and Xin Bai and Zaichao Lin and Yakun Ge and Haiyan Sun},
  doi          = {10.1142/S0218001422560110},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2256011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {POGT: A peking opera gesture training system using infrared sensors},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An accelerated and flexible SIFT parallel-computing approach
based on the general multi-core platform. <em>IJPRAI</em>,
<em>36</em>(6), 2255010. (<a
href="https://doi.org/10.1142/S0218001422550102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual retrieval has been a significant technology in the computer vision task. Visual feature descriptors are the key to the visual retrieval. The famous local feature descriptor is called the Scale Invariant Feature Transform (SIFT), which can keep invariant mapping for the scale, rotate and simulate images. To utilize effectively the SIFT feature descriptor for visual matching on different hardware platforms, this paper proposes an accelerated SIFT algorithm based on the SIFT feature computing principle of the general multi-core platform. First, our multi-core task allocation method introduces the WFM theory into task assignment for each core to improve the core computing resource utilization for high-efficient parallel computing. Then, to improve the efficiency of picture matching, we introduce global geometric constraints condition to optimal picture matching for the multi-core parallelization approach. Experimental results show that the proposed approach can save on average 87.31% on the Intel X86 platform, compared to the single-core time. Also, our approach can save on average 33.79% on the Raspberry Pi platform, compared to the single-core time.},
  archive      = {J_IJPRAI},
  author       = {Gang Wang and Mingliang Zhou and Bin Fang and Haichao Huang and Zhenyu Shu and Xueshu Chen},
  doi          = {10.1142/S0218001422550102},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2255010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An accelerated and flexible SIFT parallel-computing approach based on the general multi-core platform},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Indoor positioning and navigation model based on semantic
grid. <em>IJPRAI</em>, <em>36</em>(6), 2255009. (<a
href="https://doi.org/10.1142/S0218001422550096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional GPS positioning technology cannot be used in indoor space. With the development of the new positioning technology and the Internet of things, the indoor mobile object positioning and navigation model have been the focus of the relevant research institutions at home and abroad. Based on this, indoor positioning technology was studied starting from Wi-Fi, RFID, and iBeacon technology in this paper. However, the accuracy of indoor positioning and navigation needs to be further improved. This paper presents a semantic space model based on artificial intelligence technology, through semantic pattern matching, semantic concept extension, semantic reasoning and semantic mapping, and interior semantic localization is realized. The indoor semantic network and indoor grid navigation model are constructed, and the indoor semantic path is modeled from time, location, user, and congestion. At the same time, the improved Term Frequency-Inverse Document Frequency is combined with the Hidden Markov Model to improve the accuracy of matching the stay area with the most likely location to visit and improve the accuracy of semantic annotation. It was found that the research on the indoor positioning and navigation model based on the semantic grid can realize the uniform expression of the complex spatial semantics of the theme, geometry, connectivity, and distance, which can promote the development of indoor positioning and navigation.},
  archive      = {J_IJPRAI},
  author       = {Cuncun Wei and Qianqian Ge},
  doi          = {10.1142/S0218001422550096},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2255009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Indoor positioning and navigation model based on semantic grid},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Proximity-distance mapping and jaya optimization algorithm
based on localization for wireless sensor network. <em>IJPRAI</em>,
<em>36</em>(6), 2255008. (<a
href="https://doi.org/10.1142/S0218001422550084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problem of large location errors of traditional ranging-free algorithms in Wireless Sensor Network (WSN), a novel node location algorithm based on proximity-distance mapping (PDM) and Jaya optimization was proposed. In this algorithm, proximity and Euclidean distance are extracted from the relationship of anchor nodes to construct a mapping matrix by using the idea of PDM. It is calculated by using the mapping matrix that the estimated distance from the unknown node to the anchor node can be used for the subsequent calculations. After the estimated distance is obtained, the Jaya optimization algorithm is imported to calculate the location of the unknown one. To accelerate the convergence and enhance the accuracy of the algorithm, the idea of a boundary box is used to limit the initial feasible region of unknown nodes. The experiment results show that the PDM–Jaya algorithm has better positioning accuracy than the original PDM in the same condition.},
  archive      = {J_IJPRAI},
  author       = {Duo Peng and Yuwei Gao},
  doi          = {10.1142/S0218001422550084},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2255008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Proximity-distance mapping and jaya optimization algorithm based on localization for wireless sensor network},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mutual information variational autoencoders and its
application to feature extraction of multivariate time series.
<em>IJPRAI</em>, <em>36</em>(6), 2255005. (<a
href="https://doi.org/10.1142/S0218001422550059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of deep learning in time-series prediction has developed gradually. In this paper, we propose a deep generative network model for feature extraction of multivariate time series, namely, mutual information variational autoencoders (MI-VAE). In the architecture of the proposed model, we use the latent space of VAE for feature learning, which can extract the essential features of multivariate time-series data effectively. The latent space employed directly as a feature extractor can avoid poor interpretability of model. In addition, we introduce a mutual information term into the loss function, which improves the expression capability and accuracy of model. The proposed model, combining the merits of VAE and mutual information, extracts features for multivariate time-series data from a new perspective. The Lorenz system and Beijing air quality time series are used to test performance of the proposed model and comparative models. Results show that the proposed model is superior to other similar models in terms of accuracy and expression capability of latent space.},
  archive      = {J_IJPRAI},
  author       = {Junying Li and Weijie Ren and Min Han},
  doi          = {10.1142/S0218001422550059},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2255005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Mutual information variational autoencoders and its application to feature extraction of multivariate time series},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LWRN: Light-weight residual network for edge detection.
<em>IJPRAI</em>, <em>36</em>(6), 2254007. (<a
href="https://doi.org/10.1142/S0218001422540076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge detection is one of the most fundamental fields in computer vision. With the rapid development of the combination of Convolutional Neural Network and Multi-Scale Representation of image, significant progress has been made in this field. However, most of them have a huge size, which makes it hard to apply in reality, and a huge number of parameters may lead to waste of computing resources. In this paper, we focus on qualitative analysis of the role of each part in the network, and propose a modified light-weight architecture based on our result and the study of former works. Our new architecture is composed of residual-blocks, max-pooling layers and batch normalization layers. Compared with the previous models, the new architecture performs better in memory, convergence and computation efficiency with similar model size. Moreover, the new architecture can achieve better accuracy with smaller model size. When evaluating our model on the well-known BSDS500 benchmark, we achieve ODS F-measure of 0.769 with parameters less than 0.3 M, which shows a better property than the state-of-the-art result 0.766 at this level.},
  archive      = {J_IJPRAI},
  author       = {Chen Han and Dingyu Li and Xuanyin Wang},
  doi          = {10.1142/S0218001422540076},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2254007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {LWRN: Light-weight residual network for edge detection},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Construction of english pronunciation judgment and detection
model based on deep learning neural networks data stream fusion.
<em>IJPRAI</em>, <em>36</em>(6), 2252011. (<a
href="https://doi.org/10.1142/S0218001422520115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the defects of pronunciation errors and limited collection of pronunciation data resources in traditional artificial neural networks, an English pronunciation judgment and detection model based on deep learning neural networks data stream fusion is proposed. Taking Chinese English pronunciation as the research object, three groups of phonetic data were selected as experimental auxiliary data, based on the convolutional neural network, through the preset reset of the pronunciation detection system of the model, the sampling and recognition extraction of the speech system, the wrong speech detection and the feature analysis of the multi-level data stream tandem, the experiments are carried out with CU-CHLOE language learning database, WSJ1 database and 863 Mandarin database. The experimental results show that the recognition accuracy of this model is higher than that of the traditional neural network model, the accuracy of error type diagnosis is significantly improved, and its noise robustness is the best.},
  archive      = {J_IJPRAI},
  author       = {Yi Shi and Young Chun Ko},
  doi          = {10.1142/S0218001422520115},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2252011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Construction of english pronunciation judgment and detection model based on deep learning neural networks data stream fusion},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimized convolutional neural network for road detection
with structured contour and spatial information for intelligent vehicle
system. <em>IJPRAI</em>, <em>36</em>(6), 2252002. (<a
href="https://doi.org/10.1142/S0218001422520024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Road detection is said to be a major research area in remote sensing analysis and it is usually complex due to the data complexities as it gets varied in appearance with minor inter-class and huge intra-class variations that often cause errors and gaps in the extraction of the road”. Moreover, the majority of supervised learning techniques endure from the high price of manual annotation or inadequate training data. Thereby, this paper intends to introduce a new model for road detection. This work exploits a siamesed fully convolutional network (named as “s-FCN-loc”) based on VGG-net architecture that considers semantic contour, RGB channel and location prior for segmenting road regions precisely. As a major contribution, super pixel segmentation was carried out, where the RGB images are given as input to the FCN network and the road regions of images are set as a target. Further, the segmented outputs are fused using AND operation to attain the final segmented output that detects the road regions accurately. To make the detection more accurate, the convolutional layers of FCN are optimally chosen by a new improved model termed as distance oriented sea lion algorithm (DSLnO) model. The presented DSLnO + FCN model has achieved a minimal value of negative measures and accuracy is 8.2% higher than traditional methods. Finally, the presented method is evaluated on the KITTI road detection dataset, and achieves a better result. The analysis was done with respect to positive measures and negative measures.},
  archive      = {J_IJPRAI},
  author       = {Deepak Kumar Dewangan and Satya Prakash Sahu},
  doi          = {10.1142/S0218001422520024},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2252002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimized convolutional neural network for road detection with structured contour and spatial information for intelligent vehicle system},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-modal sparse tracking by jointing timing and modal
consistency. <em>IJPRAI</em>, <em>36</em>(6), 2251008. (<a
href="https://doi.org/10.1142/S0218001422510089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a multi-modal sparse tracking by jointing timing and modal consistency to locate the target location with the similarity of multiple local appearances. First, we propose an alignable patching strategy for red-green-blue (RGB) color mode and thermal infrared mode to adapt to the local changes of the target. Second, we propose a consistency expression of the corresponding aligned patches between the modes and the correlation of the gaussian mapping within mode to reconstruct the target judgment likelihood function. Finally, we propose an updating scenario based on timing correlation and mode sparsity to fit with the target changes. According to the experimental results, significant improvement in terms of tracking accuracy can be achieved on average compared with the state-of-the-art algorithms. The source code of our algorithm is available on https://github.com/Liincq/tracker .},
  archive      = {J_IJPRAI},
  author       = {Jiajun Li and Bin Fang and Mingliang Zhou},
  doi          = {10.1142/S0218001422510089},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2251008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-modal sparse tracking by jointing timing and modal consistency},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-extended target tracking algorithm based on VBEM-CPHD.
<em>IJPRAI</em>, <em>36</em>(6), 2250026. (<a
href="https://doi.org/10.1142/S0218001422500264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering that the extended targets tracking problem of the measurement is a glint noise with an unknown inverse covariance, a new algorithm from a multi-extended target tracking based on the Variational Bayesian Expectation Maximization (VBEM) is proposed. To improve the variational Bayesian technique, a modeled Student’s t distribution is proposed based on multiple Gaussian mixture terms in order to replace the probability hypothesis density (PHD) intensity. The extended target was modeled with a Student’s t distribution with the glint noise, using Gauss-Gamma distribution combining the variational Bayesian technique to obtain an approximate distribution and applying the expectation-maximization algorithm for iterative estimation. The two experiments are compared and analyzed with the VBEM-CPHD algorithm and the traditional extended target tracking algorithm. Experiment 1 estimated the trajectory of the target, compared algorithms of VBEM-CPHD and GM-CPHD with OSPA distance, varied glint noise with the three different measurement noise standard deviations. Experiment 2 completed the examination of the tracking performance and stability of the proposed method and performed to compare the VBEM-CPHD algorithm proposed with the VB-based GM-CPHD (GM-VBCPHD) algorithm under an unknown measurement noise covariance. The experimental results indicate that the algorithm of VBEM-CPHD has high tracking accuracy, good adaptability, and a strong antijamming ability for multiple extended targets under glint noise conditions.},
  archive      = {J_IJPRAI},
  author       = {Yawen Li and Bo Wang},
  doi          = {10.1142/S0218001422500264},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2250026},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-extended target tracking algorithm based on VBEM-CPHD},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optical film damage classification based on neural network.
<em>IJPRAI</em>, <em>36</em>(6), 2250024. (<a
href="https://doi.org/10.1142/S0218001422500240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional machine learning requires users to have a strong ability to control features and distance calculation formulas, especially in the use of support vector machine SVM and nearest neighbor KNN. Traditional machine learning uses PCA in feature extraction will actually lead to Information is lost. In order to solve the problem of low optical film damage detection rate of traditional methods, a new method is proposed in this paper based on a convolutional neural network instead of traditional machine learning to classify CCD images with different damage degrees of SiO 2 film and K9 glass. First, film images are collected by online CCD, and the proposed algorithm is designed to extract the image characteristic parameters of the film microscopic images, filter denoising, and run binarization to analyze film images. Second, gray values of images are extracted and classified by unsupervised learning. Finally, the film microscopic images under the microscope are analyzed. The experimental results show that the defect positions on the images can be detected after the images are detected and processed by a convolution neural network, binarization, and connected domains. The defective parts can be intercepted from the images, and the data related is saved for damage type determination. The average classification rate is over 99%, which is better than the traditional method by 9.1%. Therefore, it has a high application value.},
  archive      = {J_IJPRAI},
  author       = {Guoliang Yang and Junhong Su and Wenbo Huang and Gaohan Zhou and Yuan Li},
  doi          = {10.1142/S0218001422500240},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2250024},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optical film damage classification based on neural network},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Accurate locating and recognizing of ID card information.
<em>IJPRAI</em>, <em>36</em>(6), 2250021. (<a
href="https://doi.org/10.1142/S0218001422500215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important identification certificate for citizens, ID card plays a significant role in daily life and its information has found its way into almost every aspect. However, traditional ways tend to adopt manual input, which is not only time-consuming and labor-intensive, but also expensive as well as inaccuracy. In this paper, we proposed a novel algorithm to locate and recognize ID card information, in which several fresh strategies are presented to rectify image, detect boundary, and locate information, respectively. To solve the problem of image rotating, the image is rectified by searching the best rotating angle that can lead to the maximum corner point projection peak. Meanwhile, the boundary of ID card is detected by finding the best lines in the predicted boundary area based on the deviation between the predicted boundary and the detected boundary, and the position of information is located by incorporating the prior information and the location relation between the key information. Experimental results show that the proposed algorithm can achieve a state-of-the-art effect for recognizing ID card’s information.},
  archive      = {J_IJPRAI},
  author       = {Jingting Zhong and Cihui Yang and Xingmiao Xu and Wuzhida Bao and Jianyong Guo},
  doi          = {10.1142/S0218001422500215},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2250021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Accurate locating and recognizing of ID card information},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-content merging network based on focal loss and
convolutional block attention in hyperspectral image classification.
<em>IJPRAI</em>, <em>36</em>(6), 2250018. (<a
href="https://doi.org/10.1142/S0218001422500185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous extraction of spectral and spatial features and their fusion is currently a popular solution in hyperspectral image (HSI) classification. It has achieved satisfactory results in some research. Because the scales of objects are often different in HSI, it is necessary to extract multi-scale features. However, this aspect was not taken into account in many spectral-spatial feature fusion methods. This causes the model to be unable to get sufficient features on scales with a large difference range. The model (MCMN: Multi-Content Merging Network) proposed in this paper designs a multi-branch fusion structure to extract multi-scale spatial features by using multiple dilated convolution kernels. Considering the interference of the surrounding heterogeneous objects, the useful information from different directions is also fused together to realize the merging of multiple regional features. MCMN introduces a convolution block attention mechanism, which fully extracts attention features in both spatial and spectral directions, so that the network can focus on more useful parts, which can effectively improve the performance of the model. In addition, since the number of objects in each class is often discrepant, it will have some impact on the training process. We apply the focal loss function to eliminate the negative factor. The experimental results of MCMN on three data sets have a breakthrough compared with the other comparison models, which highlights the role of MCMN structure.},
  archive      = {J_IJPRAI},
  author       = {Lina Yang and Fengqi Zhang and Patrick Shen-Pei Wang and Xichun Li and Huiwu Luo},
  doi          = {10.1142/S0218001422500185},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2250018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-content merging network based on focal loss and convolutional block attention in hyperspectral image classification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Transformer network intelligent flight situation awareness
assessment based on pilot visual gaze and operation behavior data.
<em>IJPRAI</em>, <em>36</em>(5), 2259015. (<a
href="https://doi.org/10.1142/S0218001422590157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Situational awareness is the ability of pilots to master flight status, which is of great significance to aviation flight safety and flight effect. According to the information processing model, the pilot’s main steps of processing information are feeling, perception and execution. There are many problems in situation awareness analysis guided by visual gaze, such as large analysis deviation and high delay due to various influencing factors and complex characteristics. In order to solve this problem, this paper proposes a situation awareness assessment method based on artificial intelligence neural network and integrating visual gaze and flight control. First, this paper carries out simulated flight training experiments for flight cadets, and collects the data of eye movement, line of sight tracking, flight control and flight parameters of pilot cadets. Then, aiming at the flight subjects, a situation awareness analysis method based on events is established, and the situation awareness state in the experiment is evaluated and analyzed through the flight parameter data. Then, the visual gaze and flight control data are sliced in the unit of situational awareness events, and the data set is constructed. Finally, this paper designs a multi-channel sequence data classification and analysis model based on transformer, in which the situation awareness characteristics of visual gaze and operation behavior are analyzed through the attention mechanism. The experimental results show that the accuracy of situation awareness classification of the designed neural network model to the experimental data set is 96%, and can classify and evaluate the pilot’s situation awareness state in 5 s.},
  archive      = {J_IJPRAI},
  author       = {Guangyi Jiang and Hua Chen and Changyuan Wang and Pengxiang Xue},
  doi          = {10.1142/S0218001422590157},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2259015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Transformer network intelligent flight situation awareness assessment based on pilot visual gaze and operation behavior data},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic twitter crime prediction using hybrid wavelet
convolutional neural network with world cup optimization.
<em>IJPRAI</em>, <em>36</em>(5), 2259005. (<a
href="https://doi.org/10.1142/S0218001422590054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media are digitally mediated platforms that allow people to create and exchange content, professional interests, ideas, and other forms of expression through virtual networks. Users often utilize web-based programs on their PCs and laptops to visit social media sites, or they download programs that provide their devices social media capabilities. As users connect with these platforms, groups, organizations, and individuals can upload, co-create, discuss, engage in, and update self-curated or user-generated information. Although the platforms such as Facebook, Twitter, Instagram, etc., aid in the communication purposes, it also has some demerits like cyber-crime, hacking, etc. The growing number of crimes through these platforms needs to be deducted by predicting the crimes. For the crime prediction, the data acquired from Twitter is pre-processed for the data cleansing process. Later the features are extracted using various techniques like bag of words (BoW), Glove, term frequency-inverse document frequency (TF-IDF), and feature hashing. The feature selection is done using a modified tree growth algorithm (MTGA) and clustering is performed using the fuzzy manta ray foraging (FMRF). Finally, the crime detection is done using hybrid wavelet convolutional neural network with world cup organization (WCNN-WCO). The PYTHON tool is used for the implementation and the Twitter user dataset is used for analysis. The results showed that the proposed method outperforms the existing method in terms of precision, accuracy, F 1 measure, and recall.},
  archive      = {J_IJPRAI},
  author       = {Monika and Aruna Bhat},
  doi          = {10.1142/S0218001422590054},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2259005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Automatic twitter crime prediction using hybrid wavelet convolutional neural network with world cup optimization},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-automatic ontology matching based on interactive
compact genetic algorithm. <em>IJPRAI</em>, <em>36</em>(5), 2257002. (<a
href="https://doi.org/10.1142/S0218001422570026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontology matching is able to identify the entity correspondences between two heterogeneous ontologies, which is an effective method to solve the data heterogeneous problem on the Semantic Web. Traditional fully-automatic ontology matching techniques suffer from the limitation of similarity measure, whose alignment’s quality cannot be ensured. To overcome this drawback, in this work, an Interactive Compact Genetic Algorithm (ICGA)-based ontology matching technique is proposed, which utilizes both the compact encoding mechanism and expert interacting mechanism to improve the algorithm’s performance and the alignment’s quality. In addition, an optimization model is established to formally define the ontology entity matching problem, and an efficient interacting strategy is proposed, which is able to reduce the expert’s workload and maximize his working value. The experiment uses Ontology Alignment Evaluation Initiative (OAEI)’s benchmark to test our proposal’s performance. The experimental results show that our approach is able to make use of the expert knowledge to improve the alignment’s quality, and it also outperforms OAEI’s participants.},
  archive      = {J_IJPRAI},
  author       = {Xingsi Xue and Chaofan Yang and Guojun Mao and Hai Zhu},
  doi          = {10.1142/S0218001422570026},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2257002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Semi-automatic ontology matching based on interactive compact genetic algorithm},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced edge detection for 3D crack segmentation and depth
measurement with laser data. <em>IJPRAI</em>, <em>36</em>(5), 2255006.
(<a href="https://doi.org/10.1142/S0218001422550060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the usage of computer visual technology in civil engineering, pavement crack survey with imaging sensor gained wide attention in the past years. Unfortunately, it is still a challenge to achieve the satisfying results. This paper presents a pavement crack survey approach based on edge detection for laser data. At first, the LS-40 line-laser scanner is implemented to achieve 3D pavement surface data. With the advantage of the various depth information exhibited in the pavement data, an enhanced edge detection based on fractional differential is proposed for 3D crack segmentation. The proposed method could effectively enhance the crack boundary and maintain texture details, which can guarantee the high accuracy in crack segmentation. Moreover, a novel plane fitting method based on dynamic threshold is studied to calculate crack depth information. It can not only identify and remove invalid points effectively, but also accomplish plane calculation with errors in three directions. Experiments verify that the proposed approach can achieve the satisfying result and can work well in F-measure system.},
  archive      = {J_IJPRAI},
  author       = {Ting Cao and Jinyuan Hu and Sheng Liu},
  doi          = {10.1142/S0218001422550060},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2255006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Enhanced edge detection for 3D crack segmentation and depth measurement with laser data},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Image attribute migration based on decoupling and adaptive
layer instance normalization. <em>IJPRAI</em>, <em>36</em>(5), 2254011.
(<a href="https://doi.org/10.1142/S0218001422540118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of image attribute migration is one of the hot research topics in the field of computer vision, which has received extensive research interest. However, current unsupervised image attribute migration models using symmetric generative adversarial network structure do not work well on datasets with large geometric variations, where the results lack diversity and are of low quality. To address these problems, we present an image attribute migration model based on decoupling and adaptive layer instance normalization. First, a codec structure based on a decoupled representation is constructed as the generator, and an adaptive layer instance normalization operation is used in the decoder. Then, the iterations of the model are constrained by various improved loss functions. We conducted controlled experiments and compared the results of our method with other methods using several datasets with large geometric variations. The experimental results demonstrate that the proposed method can achieve high quality and diverse image attribute migration.},
  archive      = {J_IJPRAI},
  author       = {Xingquan Cai and Fajian Li and Keng Chen and Yuechao Wei and Haiyan Sun},
  doi          = {10.1142/S0218001422540118},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2254011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Image attribute migration based on decoupling and adaptive layer instance normalization},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). User-specified image color transfer. <em>IJPRAI</em>,
<em>36</em>(5), 2254010. (<a
href="https://doi.org/10.1142/S0218001422540106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a flexible example-based color transfer system, providing an automatic mode and an advanced mode, for novices and expert users, respectively. The experimental results show that the proposed color transfer system not only can introduce natural results with simple operation by novices in the first use, but also can produce various desired results by users with short-term learning.},
  archive      = {J_IJPRAI},
  author       = {Hsiau-Wen Lin and Yen-Yu Chen and Yoshimasa Tokuyama and Hwei-Jen Lin},
  doi          = {10.1142/S0218001422540106},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2254010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {User-specified image color transfer},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning for covid-19 screening using chest x-rays in
2020: A systematic review. <em>IJPRAI</em>, <em>36</em>(5), 2252010. (<a
href="https://doi.org/10.1142/S0218001422520103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) has promoted countless contributions in the field of healthcare and medical imaging. In this paper, we thoroughly analyze peer-reviewed research findings/articles on AI-guided tools for Covid-19 analysis/screening using chest X-ray images in the year 2020. We discuss on how far deep learning algorithms help in decision-making. We identify/address data collections, methodical contributions, promising methods, and challenges. However, a fair comparison is not trivial as dataset sizes vary over time, throughout the year 2020. Even though their unprecedented efforts in building AI-guided tools to detect, localize, and segment Covid-19 cases are limited to education and training, we elaborate on their strengths and possible weaknesses when we consider the need of cross-population train/test models. In total, with search keywords: (Covid-19 OR Coronavirus) AND chest x-ray AND deep learning AND artificial intelligence AND medical imaging in both PubMed Central Repository and Web of Science, we systematically reviewed 58 research articles and performed meta-analysis.},
  archive      = {J_IJPRAI},
  author       = {KC Santosh and Supriti Ghosh and Debasmita GhoshRoy},
  doi          = {10.1142/S0218001422520103},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2252010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep learning for covid-19 screening using chest X-rays in 2020: A systematic review},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Method of short-circuit fault diagnosis in transmission line
based on deep learning. <em>IJPRAI</em>, <em>36</em>(5), 2252009. (<a
href="https://doi.org/10.1142/S0218001422520097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is important to locate the fault distance and identify the fault types quickly, take effective measures to maintain line stability, and minimize the losses timely when there are short-circuit faults in transmission lines. For this purpose, a method based on deep learning is proposed for short-circuit faults identification in the transmission line. According to the similarity of samples in the reconstruction phase, a minimum neighborhood sample set is selected from the massive samples firstly, and then, the samples are trained using the back propagation algorithm along time in a recurrent neural network (RNN) with long-short term memory (LSTM) units. Compared with existing algorithms, the experimental results show that this algorithm meets the requirements of rapid fault diagnosis in the case of variable parameters, and higher fault type recognition accuracy and lower fault distance error can be obtained.},
  archive      = {J_IJPRAI},
  author       = {Tong Li and Hai Zhao and Xiaoming Zhou and Shidong Zhu and Zheng Yang and Hongping Yang and Wei Liu and Zhenliu Zhou},
  doi          = {10.1142/S0218001422520097},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2252009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Method of short-circuit fault diagnosis in transmission line based on deep learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neighborhood learning-based cuckoo search algorithm for
global optimization. <em>IJPRAI</em>, <em>36</em>(5), 2251006. (<a
href="https://doi.org/10.1142/S0218001422510065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new variant of cuckoo search (CS) algorithm named neighborhood learning-based CS (NLCS) to address global optimization problems. Specifically, in this modified version, each individual learns from the personal best solution rather than the best solution found so far in the entire population to discourage premature convergence. To further enhance the performance of CS on complex multimode problems, each individual is allowed to learn from different learning exemplars on different dimensions. Moreover, the exemplar individual is chosen from a predefined neighborhood to further maintain the population diversity. This scheme enables each individual to interact with the historical experience of its own or its neighbors, which is controlled by using a learning probability. Extensive comparative experiments are conducted on 39 benchmark functions and two application problems of neural network training. Comparison results indicate that the proposed NLCS algorithm exhibits competitive convergence performance.},
  archive      = {J_IJPRAI},
  author       = {Yan Xiong and Jiatang Cheng and Lieping Zhang},
  doi          = {10.1142/S0218001422510065},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2251006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Neighborhood learning-based cuckoo search algorithm for global optimization},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine reading comprehension with rich knowledge.
<em>IJPRAI</em>, <em>36</em>(5), 2251004. (<a
href="https://doi.org/10.1142/S0218001422510041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine reading comprehension (MRC) is a crucial and challenging task in natural language processing (NLP). With the development of deep learning, language models have achieved excellent results. However, these models still cannot answer complex questions. Currently, researchers often utilize structured knowledge, such as knowledge bases (KBs), as external knowledge by directly extracting triples to enhance the results of machine reading. Although they can support certain background knowledge, the triples are limited to the interrelationships among entities or words. Unlike structured knowledge, unstructured knowledge is rich and extensive. However, these methods ignore unstructured knowledge resources, such as Wikipedia. In addition, the effect of combining the two types of knowledge is still not known. In this study, we first attempt to explore the usefulness of combining them. We introduce a fusion mechanism into a rich knowledge fusion layer (RKF) to obtain more useful and relevant knowledge from different external knowledge resources. Further to promote interaction among different types of knowledge, a bi-matching layer is added. We propose the RKF-NET framework based on BERT, and our experimental results demonstrate the effectiveness of two classic datasets: SQuAD1.1 and the Easy-Challenge (ARC).},
  archive      = {J_IJPRAI},
  author       = {Jun He and Li Peng and Yinghui Zhang and Bo Sun and Rong Xiao and Yongkang Xiao},
  doi          = {10.1142/S0218001422510041},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2251004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Machine reading comprehension with rich knowledge},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Network intrusion logit detection model with IO port
cross-classification. <em>IJPRAI</em>, <em>36</em>(5), 2250023. (<a
href="https://doi.org/10.1142/S0218001422500239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, information networks are becoming a significant part of daily life, so keeping the system’s security is necessary for security tools, such as firewalls and encryption. However, because of the weaknesses of the existing tools, the Intrusion Detection System (IDS) has been implemented to solve the problem. In the application of IDS, feature classification and data analysis are the two most important steps. In this paper, by using the Logit regression model, we attempt to search for the optimal cutting value based on the relationship between cutting value and accuracy index and put forward an input-output port crossed (IOPC) classification for IDS to distinguish the new intrusion features. First, we discuss whole features and propose a taxonomy of IOPC classification for CIC-IDS2017 that is different from other former studies, which can reduce the data space. Second, we compute the distribution curve of cutting values varied with the accuracy index, the purpose of which is to search for the optimal cutting values. Finally, utilizing IOPC classification, the difference between the distribution of the cutting values under the attacks of distributed denial of service (DDoS) and PortScan in CIC-IDS2017 is discussed, which highlights the characteristic that cutting values besieged the attack by PortScan has a conditional distribution compared with DDoS.},
  archive      = {J_IJPRAI},
  author       = {Jingchun Sun and Fei Deng and Qin Su},
  doi          = {10.1142/S0218001422500239},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2250023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Network intrusion logit detection model with IO port cross-classification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient detection and recognition system for multiple
motorcycle license plates based on decision tree. <em>IJPRAI</em>,
<em>36</em>(5), 2250022. (<a
href="https://doi.org/10.1142/S0218001422500227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic detection and recognition for motorcycle license plates present a very challenging task since they appear more compact and versatile than vehicle license plates. In this paper, we present an efficient detection and recognition system for motorcycle license plates based on decision tree and deep learning. It can be successfully carried out under various conditions, such as frontal, horizontally or vertically skewed, blurry, poor illumination, large viewing distances or angles, distortions, multiple license plates in an image, at night or interfered with brake lights, and headlights. Experimental results show that our system performs the best when testing with multiple license plates images under different conditions as compared against six state-of-the-art methods. Furthermore, our detection and recognition system have shown more accurate results than three commercial automatic license plate recognition systems in evaluation using accuracy, precision, recall, and F1 rates.},
  archive      = {J_IJPRAI},
  author       = {Chun-Ming Tsai and Frank Y. Shih},
  doi          = {10.1142/S0218001422500227},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2250022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An efficient detection and recognition system for multiple motorcycle license plates based on decision tree},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Newton algorithm based DELM for enhancing offline tamil
handwritten character recognition. <em>IJPRAI</em>, <em>36</em>(5),
2250020. (<a href="https://doi.org/10.1142/S0218001422500203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous research based on offline Tamil recognition deals only with few Tamil characters since it becomes extremely complicated in distinguishing small variations in large handwritten document. The writer’s complexity affects the overall formation of the characters. Such types of complexities are due to discontinuation of structures, unnecessary over loops, variation in shapes as well as irregular curves. This complex issue results in enhanced error value rate. Therefore, to conquer such issues, this paper proposes a novel approach to enhance the offline Tamil handwritten character recognition by utilizing four principal steps: pre-processing, segmentation, feature extraction and classification. For optimal segmentation of Tamil characters, this paper utilizes the Tsallis entropy approach-based atom search (TEAS) optimization algorithm. Then a Newton algorithm based deep convolution extreme learning (DELM) approach is utilized for the extraction and classification of input images. Finally, experiments are carried out for numerous Tamil handwritten recognition-based approaches. The proposed Tamil character recognition utilizes the datasets of isolated Tamil handwritten characters established by HP lab India to evaluate the efficiency of the system.},
  archive      = {J_IJPRAI},
  author       = {K. Shanmugam and B. Vanathi},
  doi          = {10.1142/S0218001422500203},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2250020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Newton algorithm based DELM for enhancing offline tamil handwritten character recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SMOTE-LMKNN: A synthetic minority oversampling technique
based on local means-based k-nearest neighbor. <em>IJPRAI</em>,
<em>36</em>(5), 2250019. (<a
href="https://doi.org/10.1142/S0218001422500197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional classifiers are trapped by the class-imbalanced problem due to the fact that they are biased toward the majority class. Oversampling methods can improve imbalanced classification by creating synthetic minority class samples. Noise generation has been a great challenge in oversampling methods. Filtering-based and direction-change methods are proposed against noise generation. Yet, the adopted noise filters in filtering-based methods are biased to the majority class. Besides, the k -nearest neighbor (KNN)-based interpolation in filtering-based and direction-change methods is susceptible to abnormal samples (e.g. outliers, noise or unsafe borderline samples). To overcome noise generation while solving the above shortcomings of filtering-based and direction-change methods, this work presents a new synthetic minority oversampling technique based on local means-based KNN (SMOTE-LMKNN). In SMOTE-LMKNN, the local mean-based KNN (LMKNN) is first introduced to describe the local characteristic of imbalanced data. Second, a new LMKNN-based noise filter is proposed to remove noise and unsafe borderline samples. Third, the interpolation between a base sample and its LMKNN is proposed to create synthetic minority class samples. Empirical results of extensive experiments with 18 data sets show that SMOTE-LMKNN is competent compared with seven popular oversampling methods in training KNN classifier and classification and regression tree (CART).},
  archive      = {J_IJPRAI},
  author       = {Shuang Liu},
  doi          = {10.1142/S0218001422500197},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2250019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {SMOTE-LMKNN: A synthetic minority oversampling technique based on local means-based k-nearest neighbor},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving utterance rewriter based on MMI and text data
augmentation. <em>IJPRAI</em>, <em>36</em>(4), 2259011. (<a
href="https://doi.org/10.1142/S021800142259011X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-round dialogue tasks, how to maintain the consistency of model answers is a major research challenge. Every answer to the model should be time dependent, causal, and logical. In order to maintain the consistency of the personality, dialogue style, and context of the model, it is necessary to retain the key information in the historical dialogue as much as possible so that the model can generate more accurate answers. Utterance rewriting is a technique that replenishes the information of the current sentence by analyzing the historical dialogue, so as to retain the key information. This paper mainly uses text augmentation, Maximum Mutual Information (MMI) method and character correction method based on Knuth–Morria–Pratt (KMP) algorithm to improve the effect of utterance rewriting generation. The number of original statement rewriting datasets is limited, and the cost of manual manufacturing is too high. By using the method of text data augmentation based on coreference resolution, the positive dataset that is missing from the statement rewriting dataset is repaired. At the same time, the existing datasets are expanded to increase the number of data. The generated results are optimized by using the MMI method, and the KMP character correction method is used to modify the wrong characters to improve the overall accuracy.},
  archive      = {J_IJPRAI},
  author       = {Lina Yang and Hai Lin and Wei Li and Zuqiang Meng and Patrick Shen-Pei Wang and Xichun Li and Huiwu Luo},
  doi          = {10.1142/S021800142259011X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2259011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Improving utterance rewriter based on MMI and text data augmentation},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved exploration-enhanced gray wolf optimizer for a
mechanical model of braided bicomponent ureteral stents.
<em>IJPRAI</em>, <em>36</em>(4), 2259010. (<a
href="https://doi.org/10.1142/S0218001422590108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ureteral stent tubes are important medical devices used to repair ureteral obstruction or injury. However, relevant experiments of ureteral stent tubes are usually time-consuming and expensive. This research introduces a mechanical model that can simulate the force and deformation of ureteral stents. In addition, a novel optimization algorithm called improved exploration-enhanced gray wolf optimizer (IEE-GWO) is proposed to optimize parameters of the model. In order to balance exploration and exploitation of gray wolf optimizer (GWO), a dimension learning-based hunting (DLH) search strategy and a nonlinear control parameter strategy are integrated into the IEE-GWO. The experimental results show that the proposed IEE-GWO has better performance, such as fast convergence speed and high solution quality. Furthermore, the novel approach can improve the accuracy of the mechanical modal.},
  archive      = {J_IJPRAI},
  author       = {Zhikai Sun and Xiaoyan Liu and Lihong Ren and Kuangrong Hao},
  doi          = {10.1142/S0218001422590108},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2259010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Improved exploration-enhanced gray wolf optimizer for a mechanical model of braided bicomponent ureteral stents},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodal medical image fusion using nonsubsampled shearlet
transform and smallest uni-value segment assimilating nucleus.
<em>IJPRAI</em>, <em>36</em>(4), 2257001. (<a
href="https://doi.org/10.1142/S0218001422570014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new fusion scheme for medical (CT-MRI) images which is based on the nonsubsampled shearlet transform (NSST). The various image pairs to be fused are obtained from primary and internet sources. Initially, the images are decomposed through NSST into general and detailed features. The smallest uni-value segment assimilating nucleus (SUSAN) and local sum of Gaussian weighted pixel intensities-based activity measures are proposed to fuse the detailed sub-bands and low-frequency sub-band of NSST, respectively, for faster execution of the algorithm. Visual and parametric comparison of the proposed scheme is done through five traditional fusion algorithms using nine fusion performance parameters. In addition, Wilcoxon signed ranks test is also applied to compare different methods scientifically with the proposed fusion scheme. It is observed that the presented method is better in retaining bone, calcification, cerebrospinal fluid (CSF), edema and tumor details of the source images and is faster than other classical fusion schemes. The fused images of the proposed method are suitable for locating the site of biopsy externally or incision location in the bone of the brain skull with minimum diagnostic time.},
  archive      = {J_IJPRAI},
  author       = {Sharma Dileepkumar Ramlal and Jainy Sachdeva and Chirag Kamal Ahuja and Niranjan Khandelwal},
  doi          = {10.1142/S0218001422570014},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2257001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multimodal medical image fusion using nonsubsampled shearlet transform and smallest uni-value segment assimilating nucleus},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive hardness indicator softmax for deep face
recognition. <em>IJPRAI</em>, <em>36</em>(4), 2256009. (<a
href="https://doi.org/10.1142/S0218001422560092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their simplicity and efficiency, the margin-based Softmax losses are proposed to enhance feature discrimination in face recognition. Recently, the strategy of hard sample mining is incorporated to the margin-based Softmax losses for focusing the misclassified samples and achieves superior performance. However, the current mining-based Softmax losses indicate the sample difficultness only from the perspective of the negative cosine similarity, which is local and not robust. To obtain more discriminative deep face features, a novel adaptive hardness indicator Softmax (AHI-Softmax) loss is proposed in this paper to fully exploit the hardness information of samples. Our AHI-Softmax firstly defines a global sample hardness indicator function that integrates three difficultness factors to robustly indicate the level of “hardness” in numerical form. Then, a training stage indicator is incorporated to avoid the convergence issue. Finally, a novel sample-related modulation coefficient of the negative cosine similarity which combines the global and local hardness indicator will be defined to further enhance the differentiation of constraints imposed on samples. The experimental results on general face datasets, including LFW, AgeDB-30, CFP-FP, CALFW, CPLFW, MegaFace, IJB-B and IJB-C, show that our method can obtain more discriminative features and achieve superior verification and recognition results.},
  archive      = {J_IJPRAI},
  author       = {Mao Cai and Ning Cheng and Chunzheng Cao and Jianwei Yang and Yunjie Chen},
  doi          = {10.1142/S0218001422560092},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2256009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Adaptive hardness indicator softmax for deep face recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Facial makeup detection using multi-scale local binary
patterns and convolutional neural network fusion. <em>IJPRAI</em>,
<em>36</em>(4), 2256008. (<a
href="https://doi.org/10.1142/S0218001422560080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel facial makeup detection scheme using fusion of multi-scale Local Binary Patterns (ms-LBP) texture methods and convolutional neural network (CNN) deep learning extractor. Facial makeups affect the accuracy of face recognition systems due to appearance alteration of individuals. In order to fuse the facial features, the proposed scheme first considers concatenation of extracted global histogram of a whole image using three different LBP operators. The LBP scales are used to extract and then concatenate the local histogram of overlapping and nonoverlapping blocks of images. This way utilizes the advantages of microtexton information of local primitives besides the extracted global textures. Finally, the extracted features using CNN feature extractor are combined with global and local multi-scale textures. In general, CNN deep learning extractor learns high-level discriminative characteristics of images and therefore the proposed system improves the facial makeup detection rate by involving both microtexton and discriminative information of facial images. In addition, the proposed method attempts to select the optimized subset of facial features to increase the detection performance of system by applying Particle Swarm Optimization (PSO) technique after feature level fusion. The paper uses Support Vector Machine (SVM) classifier for classifying the facial vectors into makeup or no-makeup classes. The proposed scheme is then evaluated using YMU, VMU and MIW facial makeup databases with consideration of light, medium and heavy makeups on several datasets. Experimental results analysis clarifies the effectiveness of proposed facial makeup detection framework of this study.},
  archive      = {J_IJPRAI},
  author       = {Maryam Eskandari and Omid Sharifi},
  doi          = {10.1142/S0218001422560080},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2256008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Facial makeup detection using multi-scale local binary patterns and convolutional neural network fusion},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SentiNet: A nonverbal facial sentiment analysis using
convolutional neural network. <em>IJPRAI</em>, <em>36</em>(4), 2256007.
(<a href="https://doi.org/10.1142/S0218001422560079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human facial expressions are an essential and fundamental component for expressing the state of the human mind. The automatic analysis of these nonverbal facial expressions has become a fascinating and quite challenging problem in computer vision, with its application in different areas, such as psychology, human–machine interaction, health, and augmented reality. Recently, deep learning (DL) has become a widespread technique for studying human nonverbal facial sentiment expressions, and some research attempts have been made to propose a certain model on this topic. The purpose of this paper is to apply the appropriate convolutional neural network (CNN) approach by adding several layers of different dimensions, which allows the CNN approach to efficiently classify human facial sentiment expressions with data augmentation capable of recognizing seven basic human facial expressions: anger, sadness, fear, disgust, happiness, surprise, and neutral. In particular, this study mainly proposes a convolution neural network architecture, as well as learning factors that minimize the memory space and total training time of the proposed network due to the shallow architecture of the model. Following that, we demonstrated our proposed model’s network complexity, computational cost, and classification accuracy on the three benchmark datasets: FER2013, KDEF, and JAFFE. As a result, our proposed approach achieves accuracy of 6 7 . 5 % , 7 9 . 5 % , 9 0 . 0 % in the FER2013, KDEF, and JAFFE, respectively, which is better compared to other state-of-the-art approaches.},
  archive      = {J_IJPRAI},
  author       = {Md Abu Rumman Refat and Bikash Chandra Singh and Mohammad Muntasir Rahman},
  doi          = {10.1142/S0218001422560079},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2256007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {SentiNet: A nonverbal facial sentiment analysis using convolutional neural network},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DWT lifting scheme for image compression with
cordic-enhanced operation. <em>IJPRAI</em>, <em>36</em>(4), 2254006. (<a
href="https://doi.org/10.1142/S0218001422540064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an innovative image compression scheme by utilizing the Adaptive Discrete Wavelet Transform-based Lifting Scheme (ADWT-LS). The most important feature of the proposed DWT lifting method is splitting the low-pass and high-pass filters into upper and lower triangular matrices. It also converts the filter execution into banded matrix multiplications with an innovative lifting factorization presented with fine-tuned parameters. Further, optimal tuning is the most important contribution that is achieved via a new hybrid algorithm known as Lioness-Integrated Whale Optimization Algorithm (LI-WOA). The proposed algorithm hybridizes the concepts of both the Lion Algorithm (LA) and Whale Optimization Algorithm (WOA). In addition, innovative cosine evaluation is initiated in this work under the CORDIC algorithm. Also, this paper defines a single objective function that relates multi-constraints like the Peak Signal-to-Noise Ratio (PSNR) as well as Compression Ratio (CR). Finally, the performance of the proposed work is compared over other conventional models regarding certain performance measures.},
  archive      = {J_IJPRAI},
  author       = {M. I. Anju and J. Mohan},
  doi          = {10.1142/S0218001422540064},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2254006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DWT lifting scheme for image compression with cordic-enhanced operation},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CPRO: Competitive poor and rich optimizer-enabled deep
learning model and holoentropy weighted-power k-means clustering for
brain tumor classification using MRI. <em>IJPRAI</em>, <em>36</em>(4),
2252008. (<a href="https://doi.org/10.1142/S0218001422520085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A brain tumor is a collection of irregular and needless cell development in the brain region, and it is considered a life-threatening disease. Therefore, early level segmentation and brain tumor detection with Magnetic Resonance Imaging (MRI) is more important to save the patient’s life. Moreover, MRI is more effective in identifying patients with brain tumors since the recognition of this modality is moderately larger than considering other imaging modalities. The classification of brain tumors is the most important, difficult task in medical imaging systems because of size, appearance and shape variations. In this paper, Competitive Poor and Rich Optimization (CPRO)-based Deep Quantum Neural Network (Deep QNN) is proposed for brain tumor classification. Additionally, the pre-processing process assists in eradicating noises and uses image intensity to eliminate the artifacts. The significant features are extracted from pre-processed image to perform a productive classification process. The Deep QNN classifier is employed for classifying the brain tumor regions. Besides, the Deep QNN classifier is trained by the developed CPRO approach, which is newly designed by integrating Poor and Rich Optimization (PRO) and Competitive Swarm Optimizer (CSO). The developed brain tumor detection model outperformed other existing models with accuracy, sensitivity and specificity of 94.44%, 97.60% and 93.78%.},
  archive      = {J_IJPRAI},
  author       = {V. Agalya and Manivel Kandasamy and Ellappan Venugopal and Balajee Maram},
  doi          = {10.1142/S0218001422520085},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2252008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {CPRO: Competitive poor and rich optimizer-enabled deep learning model and holoentropy weighted-power K-means clustering for brain tumor classification using MRI},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Soft margin triplet-center loss for multi-view 3D shape
retrieval. <em>IJPRAI</em>, <em>36</em>(4), 2250017. (<a
href="https://doi.org/10.1142/S0218001422500173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obtaining discriminative features is one of the key problems in three-dimensional (3D) shape retrieval. Recently, deep metric learning-based 3D shape retrieval methods have attracted the researchers’ attention and have achieved better performance. The triplet-center loss can learn more discriminative features than traditional classification loss, and it has been successfully used in deep metric learning-based 3D shape retrieval task. However, it has a hard margin parameter that only leverages part of the training data in each mini-batch. Moreover, the margin parameter is often determined by experience and remains unchanged during the training process. To overcome the above limitations, we propose the soft margin triplet-center loss, which replaces the margin with the nonparametric soft margin. Furthermore, we combined the proposed soft margin triplet-center loss with the softmax loss to improve the training efficiency and the retrieval performance. Extensive experimental results on two popular 3D shape retrieval datasets have validated the effectiveness of the soft margin triplet-center loss, and our proposed 3D shape retrieval method has achieved better performance than other state-of-the-art method.},
  archive      = {J_IJPRAI},
  author       = {Ruting Cheng and Fuzhou Wang and Tianmeng Zhao and Hongmin Liu and Hui Zeng},
  doi          = {10.1142/S0218001422500173},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2250017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Soft margin triplet-center loss for multi-view 3D shape retrieval},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensemble of the deep convolutional network for multiclass of
plant disease classification using leaf images. <em>IJPRAI</em>,
<em>36</em>(4), 2250016. (<a
href="https://doi.org/10.1142/S0218001422500161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plant diseases are a major threat to agricultural production. Reduced yield due to plant diseases can lead to immeasurable economic losses. Therefore, the detection and classification of crop diseases are of great significance. Current existing classification methods based on the single convolutional neural network (CNN) are not satisfactory for plant disease classification performance in a large number of classes. In this case, a CNN-based approach named multiclass plant EnsembleNet (MCPE) is proposed to address these problems. MCFN firstly adopts a data augmentation strategy-based AutoAugment enhance dataset. Next, an EnsembleNet including four CNNs is employed to classify plant species, with a new activation function, concatenated dynamic ReLU, which has better performance than conventional ReLU in the multiclass plant disease dataset. Then, training a diseases classifier for each plant, which is used to identify the types and severity of plant diseases. Experimental results on 61 plant diseases from 10 different plant species, over 40 000 images, show that MCFN outperforms the state-of-the-art methods in multiclass plant disease recognition and achieves a good identification accuracy of 97.5%. We believe that the method described in this paper can further improve the identification efficiency of plant diseases, thus providing a basis for the identification of other plant leaf diseases.},
  archive      = {J_IJPRAI},
  author       = {Bo Li and Jinhong Tang and Yuejing Zhang and Xin Xie},
  doi          = {10.1142/S0218001422500161},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2250016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Ensemble of the deep convolutional network for multiclass of plant disease classification using leaf images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Protein structure prediction using quantile dragonfly and
structural class-based deep learning. <em>IJPRAI</em>, <em>36</em>(4),
2250015. (<a href="https://doi.org/10.1142/S021800142250015X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting three-dimensional structure of a protein in the field of computational molecular biology has received greater attention. Most of the recent research works aimed at exploring search space, however with the increasing nature and size of data, protein structure identification and prediction are still in the preliminary stage. This work is aimed at exploring search space to tackle protein structure prediction with minimum execution time and maximum accuracy by means of quantile regressive dragonfly and structural class homolog-based deep learning (QRD-SCHDL). The proposed QRD-SCHDL method consists of two distinct steps. They are protein structure identification and prediction. In the first step, protein structure identification is performed by means of QRD optimization model to identify protein structure with minimum error. Here the protein structure identification is first performed as the raw database contains sequence information and does not contain structural information. An optimization model is designed to obtain the structural information from the database. However, protein structure gives much more insight than its sequence. Therefore, to perform computational prediction of protein structure from its sequence, actual protein structure prediction is made. The second step involves the actual protein structure prediction via structural class and homolog-based deep learning. For each protein structure prediction, a scoring matrix is obtained by utilizing structural class maximum correlation coefficient. Finally, the proposed method is tested on a set of different unique numbers of protein data and compared to the state-of-the-art methods. The obtained results showed the potentiality of the proposed method in terms of metrics, error rate, protein structure prediction time, protein structure prediction accuracy, precision, specificity, recall, ROC, Kappa coefficient and F -measure, respectively. It also shows that the proposed QRD-SCHDL method attains comparable results and outperformed in certain cases, thereby signifying the efficiency of the proposed work.},
  archive      = {J_IJPRAI},
  author       = {Varanavasi Nallasamy and Malarvizhi Seshiah},
  doi          = {10.1142/S021800142250015X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2250015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Protein structure prediction using quantile dragonfly and structural class-based deep learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep recurrent encoder network and spark model for
angiographic disease risk classification. <em>IJPRAI</em>,
<em>36</em>(4), 2250010. (<a
href="https://doi.org/10.1142/S0218001422500100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysis and extraction of effective results from the medical big data is very complex due to the existence of large volume of data and it is also very difficult to classify the risk of angiographic diseases. The challenges faced by the conventional methods are complexity in classifying the data and performance degradation for a large-sized dataset. Hence, a hybrid approach named Deep Recurrent Encoder Network and Spark Model for Angiographic Disease Risk Classification (DRE-NET) is developed in this research to achieve accurate results for classifying the risk of angiographic diseases using Spark architecture. The developed Adaptive RCOA integrates Rider Optimization Algorithm (ROA) and Chicken Swarm Optimization (CSO) with the adaptive concept. The disease risk classification process is obtained by the Recurrent Neural Network (RNN) and Deep Stacked Autoencoder (DSAE) in such a way that the weights are optimally trained by the developed Adaptive RCOA. The optimal solution is obtained by evaluating the fitness function such that the fitness with minimal error value is considered the best solution. Moreover, the developed Adaptive RCOA-based RNN+DSAE attained better result with the metrics such as specificity, accuracy, and sensitivity with the values of 100%, 97.69%, and 99.19%, respectively, using the KDD Cup dataset.},
  archive      = {J_IJPRAI},
  author       = {R. Vinoth and J. P. Ananth},
  doi          = {10.1142/S0218001422500100},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2250010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep recurrent encoder network and spark model for angiographic disease risk classification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A rectal CT tumor segmentation method based on improved
u-net. <em>IJPRAI</em>, <em>36</em>(4), 2250006. (<a
href="https://doi.org/10.1142/S0218001422500069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic and accurate segmentation of tumor area from rectal CT image plays an extremely key role in the treatment and diagnosis of rectal cancer. This paper proposes the MR-U-Net network model. The improvement is that a pair of encoder and decoder is added longitudinally to the U-shaped structure, which is the network structure of the fifth layer, and a residual module is added horizontally to the encoder and decoder of each layer. This model is used to conduct targeted research on the automatic segmentation method of rectal cancer. [H. Gao et al. , Rectal tumor segmentation method based on U-Net improved model, J. Comput. Appl. 40 (8) (2020) 2392–2397] also improved U-Net and used the same dataset as this paper, but the Dice coefficient of all targets was only 83.15%, and the Dice coefficient of small targets was only 87.17%. This paper evaluates the improved MR-U-Net network model with the three indicators of precision, recall and Dice coefficient, and finds that in comparison to Ref. 4 the precision is 95.13%, 2.29% higher than the former work, recall is 94.28%, higher than the former work by 0.34%, Dice coefficient of all targets is 88.45%, increased by 5.3% compared with the former work, and the small targets Dice coefficient is increased by 1.28%, which is the best optimization state of this paper. Experiments show that for datasets with extremely skewed positive and negative samples, the MR-U-Net network structure after improving the hyperparameters in the optimizer can more accurately segment the rectal CT tumor lesion area.},
  archive      = {J_IJPRAI},
  author       = {Haowei Dong and Haifei Zhang and Fang Wu and Jianlin Qiu and Jian Zhang and Haoyu Wang},
  doi          = {10.1142/S0218001422500069},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2250006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A rectal CT tumor segmentation method based on improved U-net},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved a-star algorithm for complete coverage path
planning of unmanned ships. <em>IJPRAI</em>, <em>36</em>(3), 2259009.
(<a href="https://doi.org/10.1142/S0218001422590091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the low efficiency and high energy consumption of unmanned ships traversing the entire area, a complete coverage path planning algorithm based on the improved A-star algorithm is proposed. The positioning and vision systems of unmanned ships are used to digitize the actual water information, and the grid method is used to convert the information into an environmental map that can be planned. Compared to the trapezoidal partition of unity method and the short-side reciprocating traversal algorithm in the traversal process, experiments show that path planning is more efficient with the boustrophedon partition of unity method and the long-side reciprocating traversal algorithm. Aiming at the “dead zone”, an improved A-star algorithm is proposed on the basis of the traditional A-star algorithm, that it can shorten about 1/4 path using the proposed algorithm. Simulation shows that the improved A-star algorithm can shorten the traversal path to 40 steps but the traditional A-star algorithm needs 54 steps. Navigation test shows that the proposed algorithm can shorten the traversal path and improve traversal efficiency while ensuring the coverage of unmanned ships.},
  archive      = {J_IJPRAI},
  author       = {Bo Guo and Zhen Kuang and Juhua Guan and Mengting Hu and Lanxiang Rao and Xiaoqiang Sun},
  doi          = {10.1142/S0218001422590091},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2259009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An improved A-star algorithm for complete coverage path planning of unmanned ships},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A knowledge-based system for intelligent control model of
rice and wheat combine harvester. <em>IJPRAI</em>, <em>36</em>(3),
2259008. (<a href="https://doi.org/10.1142/S021800142259008X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intelligent regulation and control strategies for rice and wheat combine harvesters’ operation are lacking and the rule of parameter matching is fuzzy in China, around these issues. The dynamic correlation control law among the parameters of rice and wheat, cleaning operation parameters of combine harvesters, the cleaning loss rate and impurity rate, and so on are studied. The intelligent control model for the rice and wheat combine harvester is established based on case-based reasoning (CBR). According to different rice and wheat varieties, water content and other rice and wheat properties, the control scheme of cleaning fan speed, air distributor plate angle and upper sieve opening with low cleaning impurity rate and cleaning loss rate is provided. Through the development of web-based cleaning intelligent control expert system and experimental evaluation, the feasibility and effectiveness of the CBR method in the intelligent control filed of rice and wheat combine harvesters are verified.},
  archive      = {J_IJPRAI},
  author       = {Bo Li and Yanli Liu and Heng Zhang and Qing Jiang},
  doi          = {10.1142/S021800142259008X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2259008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A knowledge-based system for intelligent control model of rice and wheat combine harvester},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). VLSs: A local search algorithm for distributed constraint
optimization problems. <em>IJPRAI</em>, <em>36</em>(3), 2259006. (<a
href="https://doi.org/10.1142/S0218001422590066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local search algorithms are widely applied in solving large-scale distributed constraint optimization problem (DCOP). Distributed stochastic algorithm (DSA) is a typical local search algorithm to solve DCOP. However, DSA has some drawbacks including easily falling into local optima and the unfairness of assignment choice. This paper presents a novel local search algorithm named VLSs to solve the issues. In VLSs, sampling according to the probability corresponding to assignment is introduced to enable each agent to choose other promising values. Besides, each agent alternately performs a greedy choice among multiple parallel solutions to reduce the chance of falling into local optima and a variance adjustment mechanism to guide the search into a relatively good initial solution in a periodic manner. We give the proof of variance adjustment mechanism rationality and theoretical explanation of impact of greed among multiple parallel solutions. The experimental results show the superiority of VLSs over state-of-the-art DCOP algorithms.},
  archive      = {J_IJPRAI},
  author       = {Fukui Li and Jingyuan He and Mingliang Zhou and Bin Fang},
  doi          = {10.1142/S0218001422590066},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2259006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {VLSs: A local search algorithm for distributed constraint optimization problems},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel enhanced nonnegative matrix factorization method for
face recognition. <em>IJPRAI</em>, <em>36</em>(3), 2256006. (<a
href="https://doi.org/10.1142/S0218001422560067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative matrix factorization (NMF), distinguished from the approaches for holistic feature representation, is able to acquire meaningful basis images for parts-based representation. However, NMF does not utilize the data-label information and usually achieves undesirable performance in classification. To address the above-mentioned problem of NMF, this paper proposes a new enhanced NMF (ENMF) method for facial image representation and recognition. We seek to learn powerfully discriminative feature by a label-based regularizer which describes the relationship between the data. It is desired that minimizing the regularizer makes the data from the same class have high similarity and the data from different classes have low similarity. This good property will contribute to improving the performance of NMF. Therefore, we propose an objective function of ENMF by incorporating the label-based regularizer into the loss function. Subsequently, we find the stationary point of the constructed auxiliary function by means of Cardano’s formula and derive the update rules of our ENMF algorithm. The convergence of the proposed ENMF is both theoretically sound and empirically validated. Finally, the proposed ENMF method is successfully applied to face recognition. Four publicly available face datasets, namely AR, Caltech 101, Yale, and CMU PIE, are chosen for evaluations. Compared with the state-of-the-art NMF-based algorithms, the experimental results illustrate that the proposed ENMF algorithm achieves superior performance.},
  archive      = {J_IJPRAI},
  author       = {Wen-Sheng Chen and Haitao Chen and Binbin Pan},
  doi          = {10.1142/S0218001422560067},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2256006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel enhanced nonnegative matrix factorization method for face recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Salient regions and hierarchical indexing for crop disease
images. <em>IJPRAI</em>, <em>36</em>(3), 2256004. (<a
href="https://doi.org/10.1142/S0218001422560043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of modern agricultural facilities, crop diseases recognition, nutritional status and morphology achieved rapid growth. To avoid yield loss caused by the delay of disease detection, digital images that contain information with respect to crop growth, disease type and nutrition deficiency have been studied by some researchers. However, traditional image processing methods fail to extract typical disease features of crop images with ambiguous disease information. In this paper, a crop disease image recognition technique based on the salient region and hierarchical indexing was proposed. Improved Harris algorithm and maximum radius were used to calculate the widest salient region. In order to eliminate the effect of different salience distribution ranges between different features, a group of images in the cucumber disease image library were normalized. Experiment results indicate that the time complexity of each algorithm will go up as the size of the dataset increase. Especially when testing large datasets, nonhierarchical and nonclustering, hierarchical and nonclustering and hierarchical based on points all tend to raise the algorithm’s time complexity. Plant Village dataset and AI Challenger 2018 dataset were utilized to compare the recognition performances among the models based on machine learning, neural network, deep learning and our methods. The experiment results show that the method proposed in this paper is capable of recognizing local similar images effectively rather than global similar images, therefore, it has better recognition performance than the model learning methods in the early detection stage of crop disease.},
  archive      = {J_IJPRAI},
  author       = {Ronghua Gao and Qifeng Li and Huarui Wu and Feng Lu},
  doi          = {10.1142/S0218001422560043},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2256004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Salient regions and hierarchical indexing for crop disease images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A traffic sign detection system linking hypothesis tests and
deep learning networks. <em>IJPRAI</em>, <em>36</em>(3), 2255007. (<a
href="https://doi.org/10.1142/S0218001422550072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a computationally efficient method for traffic sign detection. Our methodology uses deep learning networks introduced for semantic image segmentation and classification of region of interests generated by image segmentation. The region of interests are detected by segmenting the road scene image dataset and hypothesis tests are applied to accept or reject the probability of being a traffic sign in the detected region of interest. For hypothesis tests, color feature, and the location of the traffic sign with respect to the segmented road information is used. The main contribution of our method is the introduction of hypothesis tests that mutually couple two deep learning networks trained by well-known datasets publicly available for benchmarking purposes. To test and evaluate our traffic sign detection system, we use the German traffic sign detection benchmark dataset with a large set of traffic signs and during its training, The cityscapes dataset offering labeled urban scenes is also leveraged by the traffic sign detection system. Our experimental results illustrate the effectiveness performance metrics are reached at 90.81%, 94.76% and 92.74% in precision, recall and F-measure, respectively. The runtime cost is around 0.4 s for an image on an ordinary laptop computer.},
  archive      = {J_IJPRAI},
  author       = {Mert Çetinkaya and Tankut Acarman},
  doi          = {10.1142/S0218001422550072},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2255007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A traffic sign detection system linking hypothesis tests and deep learning networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature projection and SVR-based model update for object
tracking. <em>IJPRAI</em>, <em>36</em>(3), 2255004. (<a
href="https://doi.org/10.1142/S0218001422550047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Siamese network-based object tracking algorithms have recently gained popularity due to continuous improvement in tracking accuracy and robustness. However, these trackers are often limited by inefficient initialization and unstable online update. The model drift accumulates as more frames are processed. To address the above issues, this paper introduced a method that combines both deep learning and conventional regression algorithms (SVR, Support Vector Regression). Specifically, we propose a feature projection algorithm, which can effectively reduce the dimension of the features extracted from deep neural networks and improve the distinguishability of them at the same time. To make the features more robust for SVR training, we further propose two feature aggregation methods at both the channel level and the spatial level. We update the SVR model online instead of the deep neural network to make the tracking process more robust. Extensive experiments on four challenging benchmarks indicate that our proposed tracker is superior to baseline methods both qualitatively and quantitatively.},
  archive      = {J_IJPRAI},
  author       = {Shoumeng Qiu and Yuzhang Gu and Xiaolin Zhang},
  doi          = {10.1142/S0218001422550047},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2255004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Feature projection and SVR-based model update for object tracking},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayes-probabilistic-based fusion method for image
inpainting. <em>IJPRAI</em>, <em>36</em>(3), 2254008. (<a
href="https://doi.org/10.1142/S0218001422540088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image inpainting removes unwanted objects from the image, signifying the original image restoration. Even though several techniques are introduced for image inpainting, but still, there are several challenging issues associated with the conventional methods regarding data loss, which are effectively handled based on the proposed approach. In this paper, we propose an effective hybrid image inpainting method that is termed as ALGDKH, which is the hybridization of Ant Lion–Gray Wolf Optimizer (ALG)-based Markov random field (MRF) modeling, deep learning, K -nearest neighbors (KNN) and the harmonic functions. The crack input image is forwarded as an input to Markov random field modeling to obtain image inpainting, where the MRF energy is minimized based on the ALG. Then, the same crack image is subjected to the Whale–MBO-based DCNN, KNN with Bhattacharya distance and Bi-harmonic function modules to obtain the inpainting results. Finally, the results from the proposed ALG-based Markov random field modeling, Whale–MBO-based DCNN, KNN with Bhattacharya distance and Bi-harmonic function modules are fused through Bayes-probabilistic fusion for the final inpainting results. The proposed method produces the maximal PSNR of 38.14 dB, maximal SDME of 75.70 dB and the maximal SSIM of 0.983.},
  archive      = {J_IJPRAI},
  author       = {Manjunath R. Hudagi and Shridevi Soma and Rajkumar L. Biradar},
  doi          = {10.1142/S0218001422540088},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2254008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Bayes-probabilistic-based fusion method for image inpainting},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Defense against adversarial attacks based on stochastic
descent sign activation networks on medical images. <em>IJPRAI</em>,
<em>36</em>(3), 2254005. (<a
href="https://doi.org/10.1142/S0218001422540052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning techniques in medical imaging systems are accurate, but minor perturbations in the data known as adversarial attacks can fool them. These attacks make the systems vulnerable to fraud and deception, and thus a significant challenge has been posed in practice. We present the gradient-free trained sign activation networks to detect and deter adversarial attacks on medical imaging AI systems. Experimental results show that a higher distortion value is required to attack our proposed model than the other existing state-of-the-art models on MRI, Chest X-ray, and Histopathology image datasets, where our model outperforms the best and is even twice superior. The average accuracy of our model in classifying the adversarial examples is 88.89%, whereas those for MLP and LeNet are 81.48%, and that of ResNet18 is 38.89%. It is concluded that the sign network is a solution to defend adversarial attacks due to high distortion and high accuracy on transferability. Our work is a significant step towards safe and secure medical AI systems.},
  archive      = {J_IJPRAI},
  author       = {Yanan Yang and Frank Y. Shih and Usman Roshan},
  doi          = {10.1142/S0218001422540052},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2254005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Defense against adversarial attacks based on stochastic descent sign activation networks on medical images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual normalization of handwritten chinese characters based
on generative adversarial networks. <em>IJPRAI</em>, <em>36</em>(3),
2253002. (<a href="https://doi.org/10.1142/S0218001422530020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with printed Chinese characters, handwritten Chinese characters are affected by writing coherence and anthropic factors, resulting in differences in stroke deformation, displacement, tilt, length, and thickness. This consequently affects the recognition of handwritten Chinese characters. A method based on generative adversarial networks (GANs) of Chinese character handwriting-to-printing font conversion is proposed herein, where Chinese handwriting-to-printing font conversion is represented as a font style conversion and regarded as the optimal state of normalization of handwritten Chinese characters. First, an encoder–decoder is integrated into a generative adversarial network, and a symmetric network extracts handwritten font multi-scale information. Subsequently, U-Net with skip connection is used to extract deep features and reduce the large amount of low-level information shared between the input and output. Furthermore, the skip connection reduces information loss during down-sampling. Finally, the integration loss measures the differences in the character structure and font style between the generated Chinese character image and the target font image by combining font style, encoding consistency, and L 1 losses. An experiment to convert Chinese character handwriting to multiple printing fonts is performed on the CASIA and CASIA-HWDB1.1 datasets, in which image pixel difference and character recognition accuracy are used as evaluation metrics. The obtained results show a more normalized visual writing style and contribute to recognition improvement, thereby verifying the effectiveness of this method.},
  archive      = {J_IJPRAI},
  author       = {Yuanping Zhu and Hongrui Zhang and Xin Huang and Zhuang Liu},
  doi          = {10.1142/S0218001422530020},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2253002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Visual normalization of handwritten chinese characters based on generative adversarial networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Temporal action detection methods based on deep learning.
<em>IJPRAI</em>, <em>36</em>(3), 2252005. (<a
href="https://doi.org/10.1142/S021800142252005X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal action detection is one of the most important and challenging tasks in video analysis. Due to its wide application prospects, it has received extensive attention in recent years. With the development of deep learning, great progress has been made in temporal behavior detection, but there are still many difficulties to be solved, such as accurate proposal generation and high computational cost. In this paper, deep learning-based temporal action detection methods are classified according to full supervision and weak supervision, and then the representative models of the two methods are summarized in detail, and the ideas, advantages and disadvantages of different models and the evolution between different models are analyzed. At the same time, the performance of different models on mainstream datasets is compared. The mainstream dataset and evaluation index used in temporal action detection are introduced in detail, and the calculation method of evaluation index is also elaborated. Finally, through in-depth analysis, the possible future research directions of temporal action detection and the whole review are summarized.},
  archive      = {J_IJPRAI},
  author       = {Junyi Shen and Ma Li and Jikai Zhang},
  doi          = {10.1142/S021800142252005X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2252005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Temporal action detection methods based on deep learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fusing attention features and contextual information for
scene recognition. <em>IJPRAI</em>, <em>36</em>(3), 2250014. (<a
href="https://doi.org/10.1142/S0218001422500148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to obtain more discriminative features in scene images and overcome the impacts of intra-class differences and inter-class similarities, the paper proposes a scene recognition method that combines attention and context information. First, we introduce the attention mechanism and build a multi-scale attention model. Discriminative information considers salient objects and regions by means of channel attention and spatial attention. Besides, the central loss function joint supervision strategy is introduced to further reduce the misjudgment of intra-class differences. Second, a model based on multi-level context information is proposed to describe the positional relationship between objects, which can effectively alleviate the influence of the similarity of objects between classes. Finally, the two models are merged to give full play to the compatibility of features, so that the final feature representation not only focuses on the effective discriminant information, but also manifests the relative position relationship between significant objects. Extensive experiments have proved that the method in this paper effectively solves the problem of insufficient feature representation in scene recognition tasks, and improves the accuracy of scene recognition.},
  archive      = {J_IJPRAI},
  author       = {Yuqing Peng and Xianzi Liu and Chenxi Wang and Tengfei Xiao and Tiejun Li},
  doi          = {10.1142/S0218001422500148},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2250014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Fusing attention features and contextual information for scene recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Aspect-level sentiment analysis with local semantic and
global syntactic features integration. <em>IJPRAI</em>, <em>36</em>(3),
2250013. (<a href="https://doi.org/10.1142/S0218001422500136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-level sentiment analysis aims to predict the sentiment polarity toward a specific aspect in a sentence. Most current approaches are based on deep learning and the attention mechanism. However, these models cannot simultaneously include the context semantic information carried by local words and the global syntactic information possibly carried by remote words. In this paper, we propose a local semantic and global syntactic integration scheme, which employs a local focus mechanism over local context words and exploits improved graph convolutional networks over dependency tree to encode global syntactic information. Moreover, multi-head attention is used to capture both the semantic information and also the interactive information between semantics and syntactic features. Experimental results on five datasets show the effectiveness of our model over a series of latest models.},
  archive      = {J_IJPRAI},
  author       = {Yifan Liu and Luwei Xiao and Yue-Cai Huang and Yun Xue and Xiaohui Hu and Haoliang Zhao and Ying Li},
  doi          = {10.1142/S0218001422500136},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2250013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Aspect-level sentiment analysis with local semantic and global syntactic features integration},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Module against power consumption attacks for trustworthiness
of vehicular AI chips in wide temperature range. <em>IJPRAI</em>,
<em>36</em>(3), 2250012. (<a
href="https://doi.org/10.1142/S0218001422500124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power consumption attacks monitoring on artificial intelligence (AI) chips play a critical role in the vehicular AI systems. However, most of the current monitoring and management methods focus on the trustworthiness of industrial equipment instead of resource-constrained edge devices. To address the above problem, a closed-loop module for monitoring and management of vehicular AI chips based on fitting and filtering to resist power consumption attacks is proposed in this paper. First, considering the characteristics of power, we propose a raw data correction approach for power monitoring to monitor abnormal power consumption. Second, we address the challenging problem of precision temperature monitoring to monitor the abnormal temperature of the chip, especially in a wide temperature range. Finally, the established method is applied to attack surveillance and transformed into a power consumption management problem solved by dynamic voltage and frequency scaling (DVFS) technology. As the experimental results reveal, compared with existing methods of power and temperature monitoring and power consumption control in wide temperature, our method can achieve significantly improved monitoring and managing performance.},
  archive      = {J_IJPRAI},
  author       = {Zongwei Zhu and Jiawei Geng and Mingliang Zhou and Bin Fang},
  doi          = {10.1142/S0218001422500124},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2250012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Module against power consumption attacks for trustworthiness of vehicular AI chips in wide temperature range},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The two-stage recognition method based on texture signals of
the heterogeneous unsteady iris. <em>IJPRAI</em>, <em>36</em>(3),
2250009. (<a href="https://doi.org/10.1142/S0218001422500094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a two-stage multi-category recognition structure based on texture features is proposed. This method can solve the problem of the decline in recognition accuracy in the scene of lightweight training samples. Besides, the problem of recognition effect different in the same recognition structure caused by the unsteady iris can also be solved. In this paper’s structure, digitized values of the edge shape in the iris texture of the image are set as the texture trend feature, while the differences between the gray values of the image obtained by convolution are set as the grayscale difference feature. Furthermore, the texture trend feature is used in the first-stage recognition. The template category that does not match the tested iris is the elimination category, and the remaining categories are uncertain categories. Whereas, in the second-stage recognition, uncertain categories are adopted to determine the iris recognition conclusion through the grayscale difference feature. Then, the experiment results using the JLU iris library show that the method in this paper can be highly efficient in multi-category heterogeneous iris recognition under lightweight training samples and unsteady state.},
  archive      = {J_IJPRAI},
  author       = {Shuai Liu and Yuanning Liu and Xiaodong Zhu and Jing Liu and Guang Huo and Zhiyong Zhou},
  doi          = {10.1142/S0218001422500094},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2250009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {The two-stage recognition method based on texture signals of the heterogeneous unsteady iris},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A low distortion mesh parameterization mapping method based
on proxy function and combined newton. <em>IJPRAI</em>, <em>36</em>(2),
2259004. (<a href="https://doi.org/10.1142/S0218001422590042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issues of low efficiencies and serious mapping distortions in current mesh parameterization methods, we present a low distortion mesh parameterization mapping method based on proxy function and combined Newton’s method in this paper. First, the proposed method calculates visual blind areas and distortion prone areas of a 3D mesh model, and generates a model slit. Afterwards, the method performs the Tutte mapping on the cut three-dimensional mesh model, measures the mapping distortion of the model, and outputs a distortion metric function and distortion values. Finally, the method sets iteration parameters, establishes a reference mesh, and finds the optimal coordinate points to get a convergent mesh model. When calculating mapping distortions, Dirichlet energy function is used to measure the isometric mapping distortion, and MIPS energy function is used to measure the conformal mapping distortion. To find the minimum value of the mapping distortion metric function, we use an optimal solution method combining proxy functions and combined Newton’s method. The experimental data show that the proposed method has high execution efficiency, fast descending speed of mapping distortion energy and stable optimal value convergence quality. When a texture mapping is performed, the texture is evenly colored, close laid and uniformly lined, which meets the standards in practical applications.},
  archive      = {J_IJPRAI},
  author       = {Xingquan Cai and Dingwei Feng and Mohan Cai and Chen Sun and Haiyan Sun},
  doi          = {10.1142/S0218001422590042},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2259004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A low distortion mesh parameterization mapping method based on proxy function and combined newton},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel leakage detection method by improved adaptive
filtering and pattern recognition based on acoustic waves.
<em>IJPRAI</em>, <em>36</em>(2), 2259001. (<a
href="https://doi.org/10.1142/S0218001422590017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pipeline leakages have plagued pipeline transportation for long time. Therefore, accurately extracting the features of leak signal in the presence of noise, and prompt identification of leak states and leak sizes is essential when leakage occurs. A novel leakage detection method based on the improved adaptive filter, whose parameters were optimized by the particle swarm optimization (PSO), was formulated and applied. The PSO-adaptive filter proved to be an effective signal processing method in contrast with variational mode decomposition (VMD). Its efficiency stems from the fact that the adaptive filter employs the noise collected from the detection environment. Therefore, the filter can adjust its parameters according to the changing situation. What is more, the application of PSO is conducive to automatically set suitable parameters for adaptive filter. After signal denoising, principal component analysis (PCA) was used for feature dimension reduction and selecting optimal features. The features after PCA proved to be more helpful in pattern recognition than the features without PCA. Furthermore, the relationship between the recognition results of leakage sizes and the measurement distance of the sensor was studied. Experimental results show that the method used in this paper can identify the leakage states with the accuracy of 100%. The identification result of leakage size reaches an accuracy of 86.75% under the influence of the measurement distance.},
  archive      = {J_IJPRAI},
  author       = {Zhaozhao Chi and Juncheng Jiang and Xu Diao and Qiang Chen and Lei Ni and Zhirong Wang and Guodong Shen},
  doi          = {10.1142/S0218001422590017},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2259001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Novel leakage detection method by improved adaptive filtering and pattern recognition based on acoustic waves},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Private data hiding system using state-switch DWT
coefficients quantization on digital signal. <em>IJPRAI</em>,
<em>36</em>(2), 2258002. (<a
href="https://doi.org/10.1142/S0218001422580022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The watermark embedded by traditional methods is easy to be lost under some attacks. To overcome this problem, this study proposes a novel method based on DWT. It adopts a digital audio watermarking state-switching system which optimizes DWT coefficients doubly. Firstly, it combines the quantization-embedding system and the weights of DWT coefficients with SNR to obtain an optimization model for watermarking. Next, the Lagrange principle, Hessian matrix, and minimum energy play three essential roles to obtain the optimal DWT coefficients and weights. Moreover, the almost invariant feature of the optimal weights holds demonstrating resistance to amplitude scaling. Compared with similar algorithms, the experimental results verify that the embedded audio in the proposed method has higher signal-to-noise ratio (SNR) and lower bit error rate (BER). At the same time, it indicates stronger robustness against various attacks, such as re-sampling, amplitude scaling, and mp3 compression.},
  archive      = {J_IJPRAI},
  author       = {Ming Zhao and Meng Li and Xindi Tong and Jie Li and Shuo-Tsung Chen},
  doi          = {10.1142/S0218001422580022},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2258002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Private data hiding system using state-switch DWT coefficients quantization on digital signal},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Person re-identification combined with style transfer and
pose generation. <em>IJPRAI</em>, <em>36</em>(2), 2256003. (<a
href="https://doi.org/10.1142/S0218001422560031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of existing person re-identification datasets is limited, and there are a series of changes such as illumination, background occlusion and pose among each dataset, which makes it difficult for the existing methods to learn robust feature representation, leading to a decline in recognition performance. To solve these problems, a person re-identification method combining style and pose generation is proposed in this paper. First with the impact of camera style differences in collecting images from different cameras, a style transformation method based on generative adversarial network is introduced into a person re-identification model, and cyclic generative adversarial networks (CycleGAN) is used to realize style transfer and reduce the influence of camera differences. Second, in view of the problem that when pedestrian pose changes greatly, easy to ignore identity-sensitive related information, AlphaPose is introduced to implement pose estimation. Combining style and posture for the first time and using improved deep convolution generative adversarial network (DCGAN) structure enrich the input sample information and generate unified style pose image; while using new synthetic data to train person re-identification network model improves the recognition performance of the model. Finally, further introducing random erasure method during data enhancement, in order to reduce the overfitting phenomena, improves the generalization ability of the network simultaneously and solves partial occlusion. The experimental results show that the proposed method outperforms typical style-based or pose-based methods. The accuracy of rank-1 and mAP on Market-1501 dataset is 90.4% and 74.5%, respectively, which are 2.28% and 5.78% higher, respectively. To a certain extent, the performance of person re-identification is improved.},
  archive      = {J_IJPRAI},
  author       = {Yan Hui and Yingyu Liang and Xiuhua Hu and Xi Wu and Huan Liu},
  doi          = {10.1142/S0218001422560031},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2256003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Person re-identification combined with style transfer and pose generation},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 2D multi-person pose estimation combined with face
detection. <em>IJPRAI</em>, <em>36</em>(2), 2256002. (<a
href="https://doi.org/10.1142/S021800142256002X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pose estimation is the basis and key of human motion recognition. In the two-dimensional human pose estimation based on image, in order to reduce the adverse effects of mutual occlusion among multiple people and improve the accuracy of motion recognition, a structurally symmetrical two-dimensional multi-person pose estimation model combined with face detection is proposed in this paper. First, transfer learning is used to initialize each sub-branch network model. Then, MTCNN is used for face detection to predict the number of people in the image. According to the number of people, the image is input into the improved two-branch OpenPose network. What is more, the double judgment algorithm is proposed to correct the false detection of MTCNN. The experimental results show that compared with TensorPose, which is the latest improved method based on OpenPose, the Average Precision (AP) (Intersection over Union (IoU) = 0 . 5 ) on the validation set is 8.8 higher. Furthermore, compared with OpenPose, the mean AP ( IoU = 0 . 5 : 0 . 9 5 ) is 1.7 higher on the validation set and is 1.3 higher on the Test-dev test set.},
  archive      = {J_IJPRAI},
  author       = {Qiming Li and Lu Xu and Xiaoyan Yang},
  doi          = {10.1142/S021800142256002X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2256002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {2D multi-person pose estimation combined with face detection},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent advances in 3D human pose estimation: From
optimization to implementation and beyond. <em>IJPRAI</em>,
<em>36</em>(2), 2255003. (<a
href="https://doi.org/10.1142/S0218001422550035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D human pose estimation describes estimating 3D articulation structure of a person from an image or a video. The technology has massive potential because it can enable tracking people and analyzing motion in real time. Recently, much research has been conducted to optimize human pose estimation, but few works have focused on reviewing 3D human pose estimation. In this paper, we offer a comprehensive survey of the state-of-the-art methods for 3D human pose estimation, referred to as pose estimation solutions, implementations on images or videos that contain different numbers of people and advanced 3D human pose estimation techniques. Furthermore, different kinds of algorithms are further subdivided into sub-categories and compared in light of different methodologies. To the best of our knowledge, this is the first such comprehensive survey of the recent progress of 3D human pose estimation and will hopefully facilitate the completion, refinement and applications of 3D human pose estimation.},
  archive      = {J_IJPRAI},
  author       = {Jielu Yan and Mingliang Zhou and Jinli Pan and Meng Yin and Bin Fang},
  doi          = {10.1142/S0218001422550035},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2255003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Recent advances in 3D human pose estimation: From optimization to implementation and beyond},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Image stripe noise removal based on compressed sensing.
<em>IJPRAI</em>, <em>36</em>(2), 2254004. (<a
href="https://doi.org/10.1142/S0218001422540040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sensors or electronic components are vulnerable to interference in the camera’s imaging process, usually leading to random directional stripes. Therefore, a method of stripe noise removal based on compressed sensing is proposed. First, the measurement matrix of the image with stripe noise is established, which makes the stripe images equivalent to the observation of the original image. Second, the relationships between the corresponding coefficients of adjacent scales are defined. On this basis, the bivariate threshold function is set in the curvelet sparse domain to represent the features of images. Finally, the Landweber iteration algorithm of alternating convex projection and filtering operation is achieved. Furthermore, to accelerate the noise removal at the initial stage of iteration and preserve the image details later, the exponential threshold function is utilized. This method does not need many samples, which is different from the current deep learning method. The experimental results show that the proposed algorithm represents excellent performance in removing the stripes and preserving the texture details. In addition, the PSNR of the denoised image has been dramatically improved compared with similar algorithms.},
  archive      = {J_IJPRAI},
  author       = {Yan Zhang and Jie Li and Xinyue Li and Bin Wang and Tiange Li},
  doi          = {10.1142/S0218001422540040},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2254004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Image stripe noise removal based on compressed sensing},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A driver drowsiness detection scheme based on 3D
convolutional neural networks. <em>IJPRAI</em>, <em>36</em>(2), 2252007.
(<a href="https://doi.org/10.1142/S0218001422520073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is an obvious fact that drivers’ drowsiness is more likely to cause traffic accidents. Recently, driver drowsiness detection has drawn considerable attention. In this paper, a novel drowsiness detection scheme is proposed, which can recognize drivers’ drowsiness actions through their facial expressions. First, a drowsiness action recognition model based on 3D-CNN is proposed, which can effectively distinguish drivers’ drowsiness actions and nondrowsiness actions. Second, a fusion algorithm of the two input streams is proposed, which can fuse gray image sequence and optical image sequence containing target motion information. Finally, the proposed model is evaluated on National Tsinghua University Driver Drowsiness Detection (NTHU-DDD) dataset. The experimental results show that the algorithm performs better than other algorithms, and its accuracy reaches 86.64%.},
  archive      = {J_IJPRAI},
  author       = {Hongyun Mao and Jingling Tang and Xiaoran Zhao and Mingwei Tang and Zhongyuan Jiang},
  doi          = {10.1142/S0218001422520073},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2252007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A driver drowsiness detection scheme based on 3D convolutional neural networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MVPO predictor: Deep learning-based tumor classification and
survival prediction of brain tumor patients with MRI using multi-verse
political optimizer. <em>IJPRAI</em>, <em>36</em>(2), 2252006. (<a
href="https://doi.org/10.1142/S0218001422520061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor is a severe nervous disorder that causes damage to health and often leads to death. Therefore, it is significant to classify the brain tumor at an early stage as it increases the survival rate of patients. One of the commonly employed imaging modalities for brain tumor classification is Magnetic Resonance Imaging (MRI). However, it is relatively complex to perform the brain tumor classification process due to the variations of type, shape, size and tumor location. To overcome such issues and classify the tumor more accurately, a deep learning classifier named Deep Maxout network is developed to classify the tumor into different grades. Based on the classification result, the features connected with the tumor grades are effectively acquired to make the survival prediction process. Deep learning is an effective and robust classifier model employed to perform the tumor classification or detection process with the MRI modality. Here, the survival prediction of tumor patients is carried out by the Deep Long Short-Term Memory (LSTM) classifier. Accordingly, the proposed method achieved higher performance using accuracy, sensitivity, specificity and prediction error with the values of 0.9434, 0.9324, 0.9202 and 0.0579.},
  archive      = {J_IJPRAI},
  author       = {R. Rajeswari and G. Neelima and Balajee Maram and Anupama Angadi},
  doi          = {10.1142/S0218001422520061},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2252006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {MVPO predictor: Deep learning-based tumor classification and survival prediction of brain tumor patients with MRI using multi-verse political optimizer},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Class highlight generative adversarial networks for strip
steel defect classification. <em>IJPRAI</em>, <em>36</em>(2), 2252004.
(<a href="https://doi.org/10.1142/S0218001422520048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the problem of dataset expansion in deep learning tasks such as image classification, this paper proposed an image generation model called Class Highlight Generative Adversarial Networks (CH-GANs). In order to highlight image categories, accelerate the convergence speed of the model and generate true-to-life images with clear categories, first, the image category labels were deconvoluted and integrated into the generator through 1 × 1 convolution. Second, a novel discriminator that cannot only judge the authenticity of the image but also the image category was designed. Finally, in order to quickly and accurately classify strip steel defects, the lightweight image classification network GhostNet was appropriately improved by modifying the number of network layers and the number of network channels, adding SE modules, etc., and was trained on the dataset expanded by CH-GAN. In the comparative experiments, the average FID of CH-GAN is 7.59; the accuracy of the improved GhostNet is 95.67% with 0.19 M parameters. The experimental results prove the effectiveness and superiority of the methods proposed in this paper in the generation and classification of strip steel defect images.},
  archive      = {J_IJPRAI},
  author       = {Jiang Chang and Shengqi Guan},
  doi          = {10.1142/S0218001422520048},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2252004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Class highlight generative adversarial networks for strip steel defect classification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design and application of handicraft recommendation system
based on improved hybrid algorithm. <em>IJPRAI</em>, <em>36</em>(2),
2250008. (<a href="https://doi.org/10.1142/S0218001422500082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of online e-commerce, traditional collaborative filtering algorithms have the disadvantages of data set reduction and sparse matrix filling cannot meet the requirements of users. This paper takes handicrafts as an example to propose the design and application of handicraft recommendation system based on an improved hybrid algorithm. Based on the theory of e-commerce system, through the traditional collaborative filtering algorithm of users, the personalized e-commerce system of hybrid algorithm is designed and analyzed. The personalized e-commerce system based on hybrid algorithm is further proposed. The component model of the business recommendation system and the specific steps of the improved hybrid algorithm based on user information are given. Finally, an experimental analysis of the improved hybrid algorithm is carried out. The results show that the algorithm can effectively improve the effectiveness and exemption of recommending handicrafts. What’s more, it can reduce the user item ratings of candidate set and improve accuracy of the forecast recommendation.},
  archive      = {J_IJPRAI},
  author       = {Yong Yang and Young Chun Ko},
  doi          = {10.1142/S0218001422500082},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2250008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Design and application of handicraft recommendation system based on improved hybrid algorithm},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Baseline correction algorithm based on catastrophe point
detection and lipschitz exponent’s analysis. <em>IJPRAI</em>,
<em>36</em>(2), 2250007. (<a
href="https://doi.org/10.1142/S0218001422500070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to quantitatively analyze the proportions of independent components in mixtures, it is necessary to extract line spectra corresponding to those components from the spectrum signal of some mixture and evaluate the amplitude of the spectral lines. Multiple factors cause the drift and tilt of a spectrum signal’s baseline, such as environment noises, instrument bias, and sample size, which affect the identification and quantitative analysis of the line spectra superimposed on the baseline. Therefore, the baseline of a spectrum signal should be removed before the line spectra are identified. A baseline correction algorithm based on Catastrophe Point detection and Lipschitz exponent’s analysis is proposed in this paper. With the algorithm, the strong spectral lines are identified and removed, and then the spectral baseline is evaluated without the interference of strong spectrum signals. First, catastrophe points are located based on the local modulus maxima theory of wavelet coefficients. Second, according to the Lipschitz exponent theory, the strong spectral peaks’ regions are identified and removed by a smoothing filter. Then the slowly varying spectrum is segmented adaptively and fitted by the least square fitting method. After the segments are attached and the boundaries are smoothed, the baseline of the spectrum is acquired and extracted finally. The algorithm is more accurate than classical ones because identifying the baseline is implemented after strong peaks are removed, so their influences to baseline extracting are eliminated. The results of experiments show that the algorithm is accurately performed for the spectrum signal of a gas mixture, S F 6 .},
  archive      = {J_IJPRAI},
  author       = {Weiliang Tao and Yan Liu},
  doi          = {10.1142/S0218001422500070},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2250007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Baseline correction algorithm based on catastrophe point detection and lipschitz exponent’s analysis},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on identification of corn disease occurrence degree
based on improved ResNeXt network. <em>IJPRAI</em>, <em>36</em>(2),
2250005. (<a href="https://doi.org/10.1142/S0218001422500057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aggregate depth residual network (ResNeXt) can not only improve the accuracy without increasing the parameter complexity, but also reduce the number of super parameters. It is one of the popular convolutional neural network models for image recognition. Maize diseases have a great impact on maize yield, quality and farmers’ income. Rapid and effective identification of the severity of maize diseases plays an important role in accurate control and accurate drug use. The general ResNeXt model has large spots in extracting image features, but the spots of corn diseases are small and the extracted features are not obvious, which affects the recognition accuracy. Therefore, an improved ResNeXt model is proposed to recognize the occurrence degree of corn diseases. First, the original data of maize disease degree are classified according to national standards. Second, the original data are extended through data enhancement. Third, the original ResNeXt101 model is improved. The first layer convolution kernel is changed to three 3 * 3 convolution kernels, and the cardinality is adjusted to 64. Finally, the improved model is verified. The recognition accuracy of corn disease degree is 89.667%, which is 0.98% higher than the original model. Through testing on 276 actually collected corn disease images, the recognition accuracy is 90.22%. Therefore, this method is feasible for the diagnosis of corn disease degree and can provide an important basis for accurate prevention and control.},
  archive      = {J_IJPRAI},
  author       = {Guowei Wang and Jiaxin Wang and Haiye Yu and Yuanyuan Sui},
  doi          = {10.1142/S0218001422500057},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2250005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Research on identification of corn disease occurrence degree based on improved ResNeXt network},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid artificial bee colony algorithm to solve a new
minimum exposure path problem with various boundary conditions for
wireless sensor networks. <em>IJPRAI</em>, <em>36</em>(2), 2159056. (<a
href="https://doi.org/10.1142/S0218001421590564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The original minimum exposure path (MEP) problem in WSNs (wireless sensor networks) requires the starting point and ending point of a moving target to be fixed, thus limiting the evaluation of coverage quality relative to the locations of these points. To resolve this issue, a minimum exposure path problem with various boundaries (VB-MEP) is proposed in this paper. Because the corresponding graph model cannot be established, the original classical methods (grid method and Voronoi diagram method) used to solve the minimum exposure path problem are no longer effective for the VB-MEP problem. This paper first transforms the problem into a hybrid optimization problem with constraint conditions and then considers the characteristics of the transformed mathematical optimization model with high dimensionality, unfixed dimensionality and high nonlinearity so that the deterministic optimization methods are no longer applicable. A hybrid artificial colony solution algorithm that incorporates the actual characteristics of the problem is designed, and a convergence analysis and a proof of the designed algorithm are given. Through simulation experiments based on large-scale node distribution scenarios, it is found that the designed hybrid optimization model with constraints and hybrid artificial bee colony solution algorithm can effectively solve the proposed VB-MEP problem.},
  archive      = {J_IJPRAI},
  author       = {Miao Ye and Yue Cai and Hongbing Qiu and Junyi Wang and Xiaofang Deng},
  doi          = {10.1142/S0218001421590564},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2159056},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A hybrid artificial bee colony algorithm to solve a new minimum exposure path problem with various boundary conditions for wireless sensor networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of cancer-related piRNAs based on network-based
stratification analysis. <em>IJPRAI</em>, <em>36</em>(1), 2259002. (<a
href="https://doi.org/10.1142/S0218001422590029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PIWI-interacting RNA (PiRNA) was discovered in 2006 and is expected to become a new biomarker for diagnosis and prognosis of various diseases. The purpose of this study is to explore functions of piRNAs and identify cancer subtypes on the basis of the pattern of transcriptome and somatic mutation data. A total of 285 510 SNPs in piRNAs and genes, which might affect piRNA biogenesis or piRNA targets binding were identified. Significant co-expression networks of piRNAs were then constructed separately for 12 major types of cancer. Finally, mutational matrices were mapped to piRNA network, propagated, and clustered for identification of cancer-related piRNAs and cancer subtypes. Findings showed that subtypes of three types of cancer (COAD, STAD and UCEC), which are significantly associated with survival were identified. Analysis of differentially expressed piRNAs in UCEC subtypes showed that piRNA function is closely related to cancer hallmarks “Enabling Replicative Immortality” and contributes to initiation of cancer.},
  archive      = {J_IJPRAI},
  author       = {Yajun Liu and Guo Xie and Aimin Li and Zongzhen He and Xinhong Hei},
  doi          = {10.1142/S0218001422590029},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2259002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Prediction of cancer-related piRNAs based on network-based stratification analysis},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved empirical mode decomposition algorithm based on
frequency rotation factor and vector operation in complex plane.
<em>IJPRAI</em>, <em>36</em>(1), 2258001. (<a
href="https://doi.org/10.1142/S0218001422580010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to overcome the phenomenon of aliasing mode in empirical mode decomposition (EMD), an improved EMD method based on frequency rotation factor and vector operation is proposed. First, fast Fourier transform (FFT) is used to determine the frequency components contained in the original signal. Second, Hilbert transform is applied to transform the real plane analysis into complex plane analysis, then the amplitude frequency product of the signal is satisfied with adaptive full decomposed by frequency inversion and vector operation. Third, the traditional EMD algorithm is used to extract the lowest frequency mode in the complex frequency domain while it is the highest frequency in the time domain (because the frequency inversion operation is performed in the previous step), and finally the original mode of the real plane is restored by forward frequency rotation and inverse vector operation, so as to complete all modal decomposition through this loop algorithm. The simulation results show that the method can effectively separate the aliasing problem and extract the useful signals with low time cost.},
  archive      = {J_IJPRAI},
  author       = {Hongqian Hu and Weifeng Shi},
  doi          = {10.1142/S0218001422580010},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2258001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An improved empirical mode decomposition algorithm based on frequency rotation factor and vector operation in complex plane},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-level two-stream fusion-based spatio-temporal
attention model for violence detection and localization.
<em>IJPRAI</em>, <em>36</em>(1), 2255002. (<a
href="https://doi.org/10.1142/S0218001422550023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of violent human behavior is necessary for public safety and monitoring. However, it demands constant human observation and attention in human-based surveillance systems, which is a challenging task. Autonomous detection of violent human behavior is therefore essential for continuous uninterrupted video surveillance. In this paper, we propose a novel method for violence detection and localization in videos using the fusion of spatio-temporal features and attention model. The model consists of Fusion Convolutional Neural Network (Fusion-CNN), spatio-temporal attention modules and Bi-directional Convolutional LSTMs (BiConvLSTM). The Fusion-CNN learns both spatial and temporal features by combining multi-level inter-layer features from both RGB and Optical flow input frames. The spatial attention module is used to generate an importance mask to focus on the most important areas of the image frame. The temporal attention part, which is based on BiConvLSTM, identifies the most significant video frames which are related to violent activity. The proposed model can also localize and discriminate prominent regions in both spatial and temporal domains, given the weakly supervised training with only video-level classification labels. Experimental results evaluated on different publicly available benchmarking datasets show the superior performance of the proposed model in comparison with the existing methods. Our model achieves the improved accuracies (ACC) of 89.1%, 99.1% and 98.15% for RWF-2000, HockeyFight and Crowd-Violence datasets, respectively. For CCTV-FIGHTS dataset, we choose the mean average precision (mAp) performance metric and our model obtained 80.7% mAp.},
  archive      = {J_IJPRAI},
  author       = {Mujtaba Asad and He Jiang and Jie Yang and Enmei Tu and Aftab A. Malik},
  doi          = {10.1142/S0218001422550023},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2255002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-level two-stream fusion-based spatio-temporal attention model for violence detection and localization},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new method for surface-to-air video detection and tracking
of airborne vehicles. <em>IJPRAI</em>, <em>36</em>(1), 2255001. (<a
href="https://doi.org/10.1142/S0218001422550011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection process of airborne targets may be thought simple because of the incompatible nature of aircraft, choppers, UAVs, and drones regarding clear sky background. When changes in the background are considered, brightness variation of the sky complicates the process. Changes in the shapes and types of clouds add another challenge to the process. Tracking process directly depends on the detection process and type of the data stream. The practical systems used for video detection and tracking of airborne targets are manual, and manual structures have some drawbacks compared to automatic structures. For video surveillance, guidance, regional security, and defense applications in dense environments, automatic detection and tracking process may be an obligation rather than preference. In this study, an automatic detection and tracking algorithm for video streams of airborne targets is proposed. A land-based moving camera captures the video data, and not only the flying objects but probably also the camera are in motion. Although the detection and tracking of moving objects via moving sensors is a relatively arduous task, this is the prevalent case in real-life scenarios. Video detection and tracking systems have one or more moving video sensors, while one or more flying air vehicles are in operation area. The proposed algorithm includes an image processing stage for detection and a tracking stage for initiation and continuation. An assessment study has been conducted for the actual video data and found that the proposed method yields successful results for detection, track formation, and continuation processes.},
  archive      = {J_IJPRAI},
  author       = {Ahmet Güngör Pakfiliz},
  doi          = {10.1142/S0218001422550011},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2255001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A new method for surface-to-air video detection and tracking of airborne vehicles},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodal image fusion method based on guided filter.
<em>IJPRAI</em>, <em>36</em>(1), 2254003. (<a
href="https://doi.org/10.1142/S0218001422540039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of multimodal image fusion, how to improve the visual effect after the image fused, while taking into account the protection of energy and the extraction of details, has attracted more and more attention in recent years. Based on the research of visual saliency and the final action-level measurement of the base layer, a multimodal image fusion method based on a guided filter is proposed in this paper. Firstly, multi-scale decomposition of a guided filter is used to decompose the two source images into a small-scale layer, large-scale layer and base layer. The fusion rule of the maximum absolute value is adopted in the small-scale layer, the weight fusion rule based on regular visual parameters is adopted in the large-scale layer and the fusion rule based on activity-level measurement is adopted in the base layer. Finally, the fused three scales are laminated into the final fused image. The experimental results show that the proposed method can improve the image edge processing and visual effect in multimodal image fusion.},
  archive      = {J_IJPRAI},
  author       = {Hui Zhang and Xinning Han and Rui Zhang},
  doi          = {10.1142/S0218001422540039},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2254003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multimodal image fusion method based on guided filter},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Semi-automatic extraction and mapping of farmlands based on
high-resolution remote sensing images. <em>IJPRAI</em>, <em>36</em>(1),
2254002. (<a href="https://doi.org/10.1142/S0218001422540027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extraction of agricultural parcels from high-resolution satellite imagery is an important task in precision agriculture. Here, we present a semi-automatic approach for agricultural parcel detection that achieves high accuracy and efficiency. Unlike the techniques presented in previous literatures, this method is pixel based, and it exploits the properties of a spectral angle mapper (SAM) to develop customized operators to accurately derive the parcels. The main steps of the method are sample selection, textural analysis, spectral homogenization, SAM, thresholding, and region growth. We have systematically evaluated the algorithm proposed on a variety of images from Gaofen-1 wide field of view (GF-1 WFV), Resource 1-02C (ZY1-02C), and Gaofen-2 (GF-2) to aerial image; the accuracies are 99.09% of GF-1 WFV, 84.42% of ZY1-02C, 96.51% and 92.18% of GF-2, and close to 100% of aerial image; these results demonstrated its accuracy and robustness.},
  archive      = {J_IJPRAI},
  author       = {Dongsheng Liu and Ling Han},
  doi          = {10.1142/S0218001422540027},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2254002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Semi-automatic extraction and mapping of farmlands based on high-resolution remote sensing images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Coastline extraction from GF-3 SAR images using LKDACM and
GMM algorithms. <em>IJPRAI</em>, <em>36</em>(1), 2254001. (<a
href="https://doi.org/10.1142/S0218001422540015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coastline detection using a Gaussian Mixture Model (GMM) applied to synthetic aperture radar (SAR) imagery is usually inaccurate due to the inherent noise of SAR data. In addition, the traditional active counter model is sensitive to the initial position of the contour line and requires a large number of iterations to converge to a solution. In this study, we first used the GMM algorithm to segment the SAR images and obtain a coarse land and sea segmentation map. This map is then used as the initial position for a subsequent active contour model. The K distribution was introduced into the local statistical active contour model to better model the SAR image. The Gaussian distribution-based local active contour model and the algorithm detailed in this paper were used to perform coastline extraction experiments on four SAR images. Four GF-3 SAR images with different modes were collected to validate the efficiency of the proposed method. The experimental results show that the coastline extraction methods from SAR images based on the GMM algorithm and the K distribution-based local statistical active contour model (LKDACM) overcame the shortcomings of the traditional active contour model to accurately and quickly detect coastlines, thus enabling the detection of coastline changes.},
  archive      = {J_IJPRAI},
  author       = {Dongsheng Liu and Ling Han},
  doi          = {10.1142/S0218001422540015},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2254001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Coastline extraction from GF-3 SAR images using LKDACM and GMM algorithms},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient handwritten digit recognition based on
convolutional neural networks with orthogonal learning strategies.
<em>IJPRAI</em>, <em>36</em>(1), 2253001. (<a
href="https://doi.org/10.1142/S0218001422530019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The predictions of characters/text/digits from the handwritten images have made the research community spotlight towards recognition. There are enormous applications and ambiguity that made prediction possible with Deep Learning (DL) approaches. Primarily, there are four necessary steps to be carried out with handwriting prediction. First, consideration of a dataset that is more appropriate for DL validation an inefficient manner. Here, Special Database 1 and Special Database 2 are used, which are combined and modified by the National Institute of Standards and Technology (NIST). Next is pre-processing of input handwritten digit recognition data by data normalization, extraction of efficient features which provides better prediction accuracy. The proposed idea uses pixel values as features with the analysis of hyper-parameters to enhance near-human performance. With SVM, non-linear and linear models are built to extract the appropriate features for further processing. The features are separate and placed over the Bag of Features (BoF), which is used by the next processing stage. Finally, a novel Convolutional Neural Network (CNN) is by built modifying the network structure with Orthogonal Learning Particle Swarm Optimization (CNN-OLPSO). This modification is adopted for evolutionarily optimizing the number of hyper-parameters. This proposed optimizer predicts the optimal values from the fitness computation and shows better efficiency when compared to various other conventional approaches. The novelty which relies on CNN adoption is to endeavor a suitable path towards digitalization and preserve the handwritten structure and help automatic feature extraction using CNN by offering better computation accuracy. The optimization approach helps to avoid over-fitting and under-fitting issues. Here, metrics like accuracy, elapsed time, recall, precision, and F -measure are evaluated. The results of CNN-OLPSO give better accuracy, reduced error rate and better execution time (s) compared to other existing methods. Thus, the proposed model shows better tradeoff in the recognition rate of handwritten digits.},
  archive      = {J_IJPRAI},
  author       = {T. Senthil and C. Rajan and J. Deepika},
  doi          = {10.1142/S0218001422530019},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2253001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An efficient handwritten digit recognition based on convolutional neural networks with orthogonal learning strategies},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Filtering deep convolutional features for image retrieval.
<em>IJPRAI</em>, <em>36</em>(1), 2252003. (<a
href="https://doi.org/10.1142/S0218001422520036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In image retrieval, highlighting target object and reducing the influence of background noise remains challenging. To address this problem, we propose a novel weighting method that aggregates deep convolutional features based on filtering, called filtering on spatial channel weighting (FSCW) factors, to represent image contents, and utilize it for image retrieval. There are three main contributions of this study. First, the designed filter can effectively remove the influence of background noise. Second, we propose a new channel selection and spatial weighting method, which can accurately distinguish target object from the background noise. Finally, we designed a new channel weighting strategy to suppress intra-image visual burstiness. Experimental results on benchmark datasets demonstrate that the proposed method effectively enhances discriminative power and outperforms some existing state-of-the-art methods in terms of the mAP metric. Furthermore, the proposed method is superior to some existing algorithms in distinguishing background noise and target object.},
  archive      = {J_IJPRAI},
  author       = {Bo-Jian Zhang and Guang-Hai Liu and Jin-Kun Hu},
  doi          = {10.1142/S0218001422520036},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2252003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Filtering deep convolutional features for image retrieval},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Antinoise learning and coalitional game GAN.
<em>IJPRAI</em>, <em>36</em>(1), 2252001. (<a
href="https://doi.org/10.1142/S0218001422520012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial learning stability has an important influence on the generated image quality and convergence process in generative adversarial networks (GANs). Training dataset (real data) noise and the balance of game players have an impact on adversarial learning stability. In the gradient backpropagation of the discriminator, the noise samples increase the gradient variance. It can increase the uncertainty in the network convergence progress and affect stability. In the two-player zero-sum game, the game ability of the generator and discriminator is unbalanced. Generally, the game ability of the generator is weaker than that of the discriminator, which affects the stability. To improve the stability, an antinoise learning and coalitional game generative adversarial network (ANL-CG GAN) is proposed, which achieves this goal through the following two strategies. (i) In the real data loss function of the discriminator, an effective antinoise learning method is designed, which can improve the gradient variance and network convergence uncertainty. (ii) In the zero-sum game, a generator coalitional game module is designed to enhance its game ability, which can improve the balance between the generator and discriminator via a coalitional game strategy. To verify the performance of this model, the generated results of the designed GAN and other GAN models in CELEBA and CIFAR10 are compared and analyzed. Experimental results show that the novel GAN can improve adversarial learning stability, generate image quality, and reduce the number of training epochs.},
  archive      = {J_IJPRAI},
  author       = {Hongyou Chen and Hongjie He and Fan Chen and Yiming Zhu},
  doi          = {10.1142/S0218001422520012},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2252001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Antinoise learning and coalitional game GAN},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Latent representation prediction networks. <em>IJPRAI</em>,
<em>36</em>(1), 2251002. (<a
href="https://doi.org/10.1142/S0218001422510028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern model-based reinforcement learning methods for high-dimensional inputs often incorporate an unsupervised learning step for dimensionality reduction. The training objective of these unsupervised learning methods often leverages only static inputs such as reconstructing observations. These representations are combined with predictor functions for simulating rollouts to navigate the environment. We advance this idea by taking advantage of the fact that we navigate dynamic environments with visual stimulus and create a representation that is specifically designed with control and actions in mind. We propose to learn a feature map that is maximally predictable for a predictor function. This results in representations that are well suited for the task of planning, where the predictor is used as a forward model. To this end, we introduce a new way of learning this representation along with the prediction function, a system we dub Latent Representation Prediction Network (LARP). The prediction function is used as a forward model for a search on a graph in a viewpoint-matching task, and the representation learned to maximize predictability is found to outperform other representations. The sample efficiency and overall performance of our approach are shown to rival standard reinforcement learning methods, and our learned representation transfers successfully to unseen environments.},
  archive      = {J_IJPRAI},
  author       = {Hlynur David Hlynsson and Merlin Schüler and Robin Schiewer and Tobias Glasmachers and Laurenz Wiskott},
  doi          = {10.1142/S0218001422510028},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2251002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Latent representation prediction networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interpreting model predictions with constrained perturbation
and counterfactual instances. <em>IJPRAI</em>, <em>36</em>(1), 2251001.
(<a href="https://doi.org/10.1142/S0218001422510016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, machine learning models have achieved magnificent success in many industrial applications, but most of them are black boxes. It is crucial to understand why such predictions are made in many critical areas such as medicine, financial markets, and auto driving. In this paper, we propose Coco , a novel interpretation method which can interpret any binary classifier by assigning each feature an importance value for a particular prediction. We first adopt MixUp method to generate reasonable perturbations, then apply these perturbations with constraints to obtain counterfactual instances and finally compute a comprehensive metric on these instances to estimate the importance of each feature. To demonstrate the effectiveness of Coco , we conduct extensive experiments on several datasets. The results show our method achieves better performance in identifying the most important features compared with the state-of-the-art interpretation methods, including Shap and Lime .},
  archive      = {J_IJPRAI},
  author       = {Jun-Peng Fang and Jun Zhou and Qing Cui and Cai-Zhi Tang and Long-Fei Li},
  doi          = {10.1142/S0218001422510016},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2251001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Interpreting model predictions with constrained perturbation and counterfactual instances},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AVS-YOLO: Object detection in aerial visual scene.
<em>IJPRAI</em>, <em>36</em>(1), 2250004. (<a
href="https://doi.org/10.1142/S0218001422500045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Difficult object detection and class imbalance in object detection are the two main challenges faced by aerial image object detection. Difficult objects include small objects, objects of scale variation and objects with serious background interference. Class imbalances come from the number of different classes of objects and sampling of positive and negative samples. Due to these challenges, conventional object detection models usually cannot effectively detect objects in aerial images, especially in the balance between network speed and accuracy. In this paper, the YOLOv3 network structure was improved and an object detection method under the aerial visual scene (AVS-YOLO) was proposed. By introducing a type of densely connected feature pyramid strategy, a scale-aware attention module was constructed, considering both residual dense network blocks and the median-frequency-balancing mechanism. On this basis, an algorithm with ideal speed and accuracy for object detection is obtained. To verify the effectiveness of the algorithm, AVS-YOLO and YOLOv3 were both used to test the VisDrone-DET2019 and UAVDT. The experimental results show that the AP of AVS-YOLO increases by 6.22% and 5.09% on the VisDrone2019 and UAVDT datasets, respectively, compared with YOLOv3. In addition, the AP of AVS-YOLO is 1.82% higher than that of YOLOv4 on the VisDrone2019 dataset. In terms of detection speed, AVS-YOLO can process 31.8 frames per second on a single Nvidia GTX 2080Ti GPU, compared with 44.1 frames per second for YOLOv3. Compared with the other one-stage network in the field of object detection, AVS-YOLO currently achieves the state-of-the-art performance with similar calculation amount on this dataset.},
  archive      = {J_IJPRAI},
  author       = {You Ma and Lin Chai and Lizuo Jin and Yafeng Yu and Jun Yan},
  doi          = {10.1142/S0218001422500045},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2250004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {AVS-YOLO: Object detection in aerial visual scene},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Siamese network object tracking algorithm combining
attention mechanism and correlation filter theory. <em>IJPRAI</em>,
<em>36</em>(1), 2250003. (<a
href="https://doi.org/10.1142/S0218001422500033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to solve the problem of tracking drift during movement, which was caused by the lack of discriminability of the feature information and the failure of a fixed template to adapt to the change of object appearance, the paper proposes an object tracking algorithm combining attention mechanism and correlation filter theory based on the framework of full convolutional Siamese neural networks. Firstly, the apparent information is processed by using the attention mechanism thought, where the object and search area features are optimized according to the spatial attention and channel attention module. At the same time, the cross-attention module is introduced to process the template branch and search area branch, respectively, which makes full use of the diversified context information of the search area. Then, the background perception correlation filter model with scale adaptation and learning rate adjustment is adopted into the model construction, using as a layer in the network model to realize the object template update. Finally, the optimal object location is determined according to the confidence map with similarity calculation. Experimental results show that the designed method in the paper can promote the object tracking performance under various challenging environments effectively; the success rate increases by 16.2%, and the accuracy rate increases by 16%.},
  archive      = {J_IJPRAI},
  author       = {Xiuhua Hu and Huan Liu and Yuan Chen and Yan Hui and Yingyu Liang and Xi Wu},
  doi          = {10.1142/S0218001422500033},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2250003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Siamese network object tracking algorithm combining attention mechanism and correlation filter theory},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Web blog content curation using fuzzy-related capsule
network-based auto encoder. <em>IJPRAI</em>, <em>36</em>(1), 2250001.
(<a href="https://doi.org/10.1142/S021800142250001X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The internet content increases exponentially day-by-day leading to the pop-up of irrelevant data while searching. Thus, the vast availability of web data requires curation to enhance the results of the search in relevance to searched topics. The proposed F-CapsNet deals with the content curation of web blog data through the novel integration of fuzzy logic with a machine learning algorithm. The input content to be curated is initially pre-processed and seven major features such as sentence position, bigrams, TF-IDF, cosine similarity, sentence length, proper noun score and numeric token are extracted. Then the fuzzy rules are applied to generate the extractive summary. After the extractive curation, the output is passed to the novel capsule network based deep auto-encoder where the abstractive summary is produced. The performance measures such as precision, recall, F1-score, accuracy and specificity are computed and the results are compared with the existing state-of-the-art methods. From the simulations performed, it has been proven that the proposed method for content curation is more efficient than any other method.},
  archive      = {J_IJPRAI},
  author       = {Harsh Khatter and Anil Ahlawat},
  doi          = {10.1142/S021800142250001X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2250001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Web blog content curation using fuzzy-related capsule network-based auto encoder},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time leaf recognition method based on image
segmentation and feature extraction. <em>IJPRAI</em>, <em>36</em>(1),
2154033. (<a href="https://doi.org/10.1142/S0218001421540331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leaf recognition has been an important research field of image recognition in the recent past. However, traditional leaf recognition methods can be easily affected by environments and cannot realize multi-leaf recognition under a complex background in real time. In this work, we present a real-time leaf recognition method based on image segmentation and feature recognition. First, we denoise the input of a leaf image, performing a leaf segmentation with an improved FCN network model, and then optimize the contour edge with a CRF algorithm to get a leaf segmentation image. Second, we extract the content features of the segmented leaf image with an Inception-V2 network model to get a feature map of the leaf image. Third, we input the feature map into an RPN network to obtain a set of regional candidate frames and then integrate the feature map and the information of candidate frames in a RoI Pooling layer, which can extract the feature map of a candidate frame area and scale it to a fixed-size feature map. Finally, we send the feature map to a fully connected layer to classify each preselection box content through the calculation of preselection feature maps, and then obtain the final accurate position of the prediction box by utilizing a bounding box regression. The experimental results show that the proposed method can achieve multi-leaf recognitions with high accuracy and fast speed under complex environments in real time.},
  archive      = {J_IJPRAI},
  author       = {Xingquan Cai and Yuqing Huo and Yunbo Chen and Mengyao Xi and Yuxin Tu and Chen Sun and Haiyan Sun},
  doi          = {10.1142/S0218001421540331},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2154033},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Real-time leaf recognition method based on image segmentation and feature extraction},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
