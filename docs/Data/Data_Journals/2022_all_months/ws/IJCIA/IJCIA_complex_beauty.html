<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJCIA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijcia---33">IJCIA - 33</h2>
<ul>
<li><details>
<summary>
(2022a). Calendar of events. <em>IJCIA</em>, <em>21</em>(4),
2282004. (<a href="https://doi.org/10.1142/S1469026822820041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIA},
  doi          = {10.1142/S1469026822820041},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2282004},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Calendar of events},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An optimized flower categorization using customized deep
learning. <em>IJCIA</em>, <em>21</em>(4), 2250029. (<a
href="https://doi.org/10.1142/S1469026822500298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Categorizing flowers is quite a challenging task as there is so much diversity in the species, and the images of the different flower species could be pretty similar. Flower categorization involves many issues like low resolution and noisy images, occluded images with the leaves and the stems of the plants and sometimes even with the insects. The traditional handcrafted features were used for extraction of the features and the machine learning algorithms were applied but with the advent of the deep neural networks. The focus of the researchers has inclined towards the use of the non-handcrafted features for the image categorization tasks because of their fast computation and efficiency. In this study, the images are pre-processed to enhance the key features and suppress the undesired information’s and the objects are localized in the image through the segmentation to extract the Region of Interest, detect the objects and perform feature extraction and the supervised classification of flowers into five categories: daisy, sunflower, dandelion, tulip and rose. First step involves the pre-processing of the images and the second step involves the feature extraction using the pre-trained models ResNet50, MobileNet, DenseNet169, InceptionV3 and VGG16 and finally the classification is done into five different categories of flowers. Ultimately, the results obtained from these proposed architectures are then analyzed and presented in the form of confusion matrices. In this study, the CNN model has been proposed to evaluate the performance of categorization of flower images, and then data augmentation is applied to the images to address the problem of overfitting. The pre-trained models ResNet50, MobileNet, DenseNet169, InceptionV3 and VGG16 are implemented on the flower dataset to perform categorization tasks. The pre-trained models are empirically implemented and assessed on the various flower datasets. Performance analysis has been done in terms of the training, validation accuracy, validation loss and training loss. The empirical assessment of these pre-trained models demonstrate that these models are quite effective for the categorization tasks. According to the performance analysis, the VGG16 outperforms all the other models and provides a training accuracy of 99.01%. Densenet169 and MobileNet also give comparable validation accuracy. ResNet50 gives the lowest training accuracy of 60.46% as compared with the rest of the pre-trained replica or models.},
  archive      = {J_IJCIA},
  author       = {Ritu Rani and Sandhya Pundhir and Amita Dev and Arun Sharma},
  doi          = {10.1142/S1469026822500298},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2250029},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {An optimized flower categorization using customized deep learning},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-stream graph convolutional networks for text
classification via representative-word document mining. <em>IJCIA</em>,
<em>21</em>(4), 2250028. (<a
href="https://doi.org/10.1142/S1469026822500286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, graph convolutional networks (GCNs) for text classification have received considerable attention in natural language processing. However, most current methods just use original documents and words in the corpus to construct the topology of graph which may lose some effective information. In this paper, we propose a Multi-Stream Graph Convolutional Network (MS-GCN) for text classification via Representative-Word Document (RWD) mining, which is implemented in PyTorch. In the proposed method, we first introduce temporary labels and mine the RWDs which are treated as additional documents in the corpus. Then, we build a heterogeneous graph based on relations among a Group of RWDs (GRWDs), words and original documents. Furthermore, we construct the MS-GCN based on multiple heterogeneous graphs according to different GRWDs. Finally, we optimize our MS-GCN model through updated mechanism of GRWDs. We evaluate the proposed approach on six text classification datasets, 20NG, R8, R52, Ohsumed, MR and Pheme. Extensive experiments on these datasets show that our proposed approach outperforms state-of-the-art methods for text classification.},
  archive      = {J_IJCIA},
  author       = {Meng Li and Shenyu Chen and Weifeng Yang and Qianying Wang},
  doi          = {10.1142/S1469026822500286},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2250028},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Multi-stream graph convolutional networks for text classification via representative-word document mining},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection and classification of skin cancer using unmanned
transfer learning based probabilistic multi-layer dense networks.
<em>IJCIA</em>, <em>21</em>(4), 2250027. (<a
href="https://doi.org/10.1142/S1469026822500274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer is one of the most dangerous cancers that may occur for different age groups of people. As a result, early identification of skin cancer has the potential to save millions of lives. In Traditional machine learning approaches, there are various drawbacks in detection and classification of skin lesions. As a result, to achieve the robust performance, initially the joint trilateral and bilateral filter (JTBF) with convolutional auto encoder and decoder (CAED)-based preprocessing method is used to enhance the skin lesion and also removes hair from lesions. Then, transfer learning-based probabilistic multi-layer dense networks (PMDN) method-based unmanned Transfer learning segmentation method is adapted for accurately detecting the cancer region on skin lesions. Further, transfer learning convolution neural network (TL-CNN) is used to extract the features from the segmented region, which extracts the detailed inter-disease-dependent (IDD) and intra-disease specific (IDS) features. Finally, Alexa Net model is trained and tested with the IDD, IDS features and classifies the eight different skin cancer types. The complexity of the transfer learning networks is optimized by the using the Adam optimizer. Finally, the simulation results show that the proposed model resulted in superior segmentation, feature extraction, and classification performances as compared to conventional approaches. Further, the proposed method achieved 99.937% segmentation accuracy, 99.47% feature extraction accuracy, and 99.27% classification accuracy on ISIC-2019 public challenge dataset.},
  archive      = {J_IJCIA},
  author       = {V. Nyemeesha and M. Kavitha and B. Mohammed Ismail},
  doi          = {10.1142/S1469026822500274},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2250027},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Detection and classification of skin cancer using unmanned transfer learning based probabilistic multi-layer dense networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Building the forecasting model for time series based on the
improved fuzzy relationship for variation of data. <em>IJCIA</em>,
<em>21</em>(4), 2250026. (<a
href="https://doi.org/10.1142/S1469026822500262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting for time series has always been of interest to statisticians and data scientists because it offers a lot of benefits in reality. This study proposes the fuzzy time series model which can both interpolate historical data, and forecast effectively for the future with the important contributions. First, we build the universal set based on the percentage of the original data variation, and divide it to clusters with the suitable number by the developed automatic algorithm. Next, the new fuzzy relationship between each element in series and the obtained clusters is established. The bigger the variation is, the more the clusters are divided. Finally, combining the two above improvements, we propose the new principle to forecast for the future. The experiments on many well-known data sets, including 3003 series of M3-competition data show that the proposed model has shown the outstanding advantage in comparing to the existing ones. Because the proposed model is established by the Matlab procedure, it can apply effectively for real series.},
  archive      = {J_IJCIA},
  author       = {Ha Che-Ngoc and Luan Nguyen-Huynh and Dan Nguyen-Thihong and Tai Vo-Van},
  doi          = {10.1142/S1469026822500262},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2250026},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Building the forecasting model for time series based on the improved fuzzy relationship for variation of data},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Investigation of the optimal PID-like fuzzy logic controller
for ball and beam system with improved quantum particle swarm
optimization. <em>IJCIA</em>, <em>21</em>(4), 2250025. (<a
href="https://doi.org/10.1142/S1469026822500250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy Logic Controllers (FLCs) are intelligent control methods, where membership functions and corresponding rules are defined to get a proper control signal. The parameters were defined for these controllers, and they are named as PID-like FLC since the input and output parameters are connected to the Fuzzy controller with integral and derivative action of the error signal to change the behavior/performance of FLC. In this research, three different rule sets for Fuzzy controllers; 3 × 3, 5 × 5, and 7 × 7 are used and parameters are optimized with; differential evolution, genetic algorithm, particle swarm optimization and quantum-behaved particle swarm optimization. In addition to these controllers, a novel algorithm named as improved quantum particle swarm optimization is proposed as a part of this research. The simulation and real-life implementation on the experimental set results of these controllers are discussed in this paper.},
  archive      = {J_IJCIA},
  author       = {O. Tolga Altinoz and A. Egemen Yilmaz},
  doi          = {10.1142/S1469026822500250},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2250025},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Investigation of the optimal PID-like fuzzy logic controller for ball and beam system with improved quantum particle swarm optimization},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Aerial image denoising using a best-so-far ABC-based
adaptive filter method. <em>IJCIA</em>, <em>21</em>(4), 2250024. (<a
href="https://doi.org/10.1142/S1469026822500249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, digital images play an increasingly important role in helping to explain phenomena and to attract people’s attention through various types of media rather than the use of text. However, the quality of digital images may be degraded due to noise that has occurred either during their recording or their transmission via a network. Therefore, removal of image noise, which is known as “image denoising”, is one of the primary required tasks in digital image processing. Various methods in earlier studies have been developed and proposed to remove the noise found in images. For example, the use of metric filters to eliminate noise has received much attention from researchers in recent literature. However, the convergence speed when searching for the optimal filter coefficient of these proposed algorithms is quite low. Previous research in the past few years has found that biologically inspired approaches are among the more promising metaheuristic methods used to find optimal solutions. In this work, an image denoising approach based on the best-so-far (BSF) ABC algorithm combined with an adaptive filter is proposed to enhance the performance of searching for the optimal filter coefficient in the denoising process. Experimental results indicate that the denoising of images employing the proposed BSF ABC technique yields good quality and the ability to remove noise while preventing the features of the image from being lost in the denoising process. The denoised image quality obtained by the proposed method achieves a 20% increase compared with other recently developed techniques in the field of biologically inspired approaches.},
  archive      = {J_IJCIA},
  author       = {Anan Banharnsakun},
  doi          = {10.1142/S1469026822500249},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2250024},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Aerial image denoising using a best-so-far ABC-based adaptive filter method},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification and filtering of web spams using a machine
learning method. <em>IJCIA</em>, <em>21</em>(4), 2250023. (<a
href="https://doi.org/10.1142/S1469026822500237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to enhance the filtering of spam on the Internet and improve the experience of Internet users, this paper proposed to convert the email text into vector features using the vector space model, constructed a two-dimensional matrix, and used a convolutional neural network (CNN) to identify spam on the Internet. The CNN was compared with other two classifiers, support vector machine (SVM), and backward-propagation neural network (BPNN), in simulation experiments. The final results showed that the spam recognition algorithm with CNN as the classifier had better recognition performance than the algorithms with SVM and BPNN classifiers and was also more advantageous in terms of recognition cost and time for spam; in addition, the CNN had the best recognition performance when the number of extracted features was 15.},
  archive      = {J_IJCIA},
  author       = {Dawei Zhang and Yanyu Liu},
  doi          = {10.1142/S1469026822500237},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2250023},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Identification and filtering of web spams using a machine learning method},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Boil-turbine system identification based on robust interval
type-2 fuzzy c-regression model. <em>IJCIA</em>, <em>21</em>(4),
2250022. (<a href="https://doi.org/10.1142/S1469026822500225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The boil-turbine system is a multivariable and strong coupling system with the characteristics of nonlinearity, time-varying parameters, and large delay. The accurate model can effectively improve the performance of turbine–boiler coordinated control system. In this paper, the boil-turbine model is established by interval type-2 (IT2) T-S fuzzy model. The premise parameters of IT2 T-S fuzzy model are identified by robust IT2 fuzzy c-regression model (RIT2-FCRM) clustering algorithm. The RIT2-FCRM is based on interval type-2 fuzzy sets (IT2FS) and applies a robust objective function, this clustering algorithm can reduce the impacts of outliers and noise points. The effectiveness and practicability of RIT2-FCRM are demonstrated by the identification results of the boiler–turbine system.},
  archive      = {J_IJCIA},
  author       = {Jianzhong Shi},
  doi          = {10.1142/S1469026822500225},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2250022},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Boil-turbine system identification based on robust interval type-2 fuzzy C-regression model},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Calendar of events. <em>IJCIA</em>, <em>21</em>(3),
2282003. (<a href="https://doi.org/10.1142/S146902682282003X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIA},
  doi          = {10.1142/S146902682282003X},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2282003},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Calendar of events},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A real-world industrial application of particle swarm
optimization: Baghouse designing. <em>IJCIA</em>, <em>21</em>(3),
2250021. (<a href="https://doi.org/10.1142/S1469026822500213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the high ability and flexibility of meta-heuristic algorithms (MAs), they can widely be used in many applications to solve different problems. Recently, real-world engineering applications of these optimization algorithms have attracted researchers’ attention. This paper applies particle swarm optimization (PSO) as an effective population-based MAs to design the baghouse (BH). BH filters are among the most commonly used devices in air pollution control systems in mining and food manufacturers and power plants. Designing the BH depends on several parameters such as its capacity or airflow (Nm 3 /h), air-to-cloth ratio ( a ∕ c ), cam velocity, and installation limitations. Generally, industrial designers select the number and length of bags and their arrangement based on the experimental observations to meet the parameters mentioned above. The minimum cost or total weight of equipment is utilized for proposing a competitive price for suppliers. In this paper, a PSO algorithm is used to minimize the total cost by finding the best possible design (the number, length, and arrangement of bags). In addition, a real example of installed BH in a pelletizing plant is given and compared with PSO results to investigate the efficiency of the proposed algorithm. The results suggest that PSO can find a better design with minimum total cost than an installed BH filter, and therefore, PSO is applicable to industrial designers.},
  archive      = {J_IJCIA},
  author       = {Pouya Bolourchi and Mohammadreza Gholami},
  doi          = {10.1142/S1469026822500213},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2250021},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A real-world industrial application of particle swarm optimization: Baghouse designing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A precise computational method for hippocampus segmentation
from MRI of brain to assist physicians in the diagnosis of alzheimer’s
disease. <em>IJCIA</em>, <em>21</em>(3), 2250020. (<a
href="https://doi.org/10.1142/S1469026822500201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hippocampus segmentation on magnetic resonance imaging is more significant for diagnosis, treatment and analyzing of neuropsychiatric disorders. Automatic segmentation is an active research field. Previous state-of-the-art hippocampus segmentation methods train their methods on healthy or Alzheimer’s disease patients from public datasets. It arises the question whether these methods are capable for recognizing the hippocampus in a different domain. Therefore, this study proposes a precise computational method for hippocampus segmentation from MRI of brain to assist physicians in the diagnosis of Alzheimer’s disease (HCS-MRI-DAD-LBP). Initially, the input images are pre-processed by Trimmed mean filter for image quality enhancement. Then the pre-processed images are given to ROI detection, ROI detection utilizes Weber’s law which determines the luminance factor of the image. In the region extraction process, Chan–Vese active contour model (ACM) and level sets are used (UACM). Finally, local binary pattern (LBP) is utilized to remove the erroneous pixel that maximizes the segmentation accuracy. The proposed model is implemented in MATLAB, and its performance is analyzed with performance metrics, like precision, recall, mean, variance, standard deviation and disc similarity coefficient. The proposed HCS-MRI-DAD-LBP method attains in OASIS dataset provides high disc similarity coefficient of 12.64%, 10.11% and 1.03% compared with the existing methods, like HCS-DAS-MLT, HCS-DAS-RNN and HCS-DAS-GMM and in ADNI dataset provides high precision of 20%, 9.09% and 1.05% compared with existing methods like HCS-MRI-DAD-CNN-ADNI, HCS-MRI-DAD-MCNN-ADNI and HCS-MRI-DAD-CNN-RNN-ADNI, respectively.},
  archive      = {J_IJCIA},
  author       = {T. Genish and S. Kavitha and S. Vijayalakshmi},
  doi          = {10.1142/S1469026822500201},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2250020},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A precise computational method for hippocampus segmentation from MRI of brain to assist physicians in the diagnosis of alzheimer’s disease},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FNN based-virtual screening using 2D pharmacophore
fingerprint for activity prediction in drug discovery. <em>IJCIA</em>,
<em>21</em>(3), 2250019. (<a
href="https://doi.org/10.1142/S1469026822500195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug discovery remains a hard field that faces from the beginning of its process to the end many difficulties and challenges in order to discover a new potential drug. The use of technology has helped a lot in achieving many goals at the lowest cost and in the shortest possible time. Machine learning methods have proven for many years their performance although their limitations in some cases. The use of deep learning for virtual screening in drug discovery allows to process efficiently the huge amount of data and gives more precise results. In this paper, we propose a procedure for virtual screening (VS) based on Feedforward Neural Network in order to predict the biological activity of a set of chemical compounds on a given receptor. we have proposed a distance interval and it divisions to describe the chemical compound by the 2D pharmacophore fingerprint. Our model was trained on a dataset of active and inactive chemical compounds on cyclin A kinase1 receptor (CDK1), a very important protein family which has a role in the regulation of the cell cycle and cancer development. The results have proven that the proposed model is efficient and comparable with some widely used machine learning methods in drug discovery.},
  archive      = {J_IJCIA},
  author       = {Seloua Hadiby and Yamina Mohamed Ben Ali},
  doi          = {10.1142/S1469026822500195},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2250019},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {FNN based-virtual screening using 2D pharmacophore fingerprint for activity prediction in drug discovery},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid grasshopper and chameleon swarm optimization
algorithm for text feature selection with density peaks clustering.
<em>IJCIA</em>, <em>21</em>(3), 2250018. (<a
href="https://doi.org/10.1142/S1469026822500183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering consists of various applications on machine learning, image segmentation, data mining and pattern recognition. The proper selection of clustering is significant in feature selection. Therefore, in this paper, a Text Feature Selection (FS) and Clustering using Grasshopper–Chameleon Swarm Optimization with Density Peaks Clustering algorithm (TFSC-G-CSOA-DPCA) is proposed. Initially, the input features are pre-processed for converting text into numerical form. These preprocessed text features are given to Grasshopper–Chameleon Swarm Optimization Algorithm, which selects important text features. In Grasshopper–Chameleon Swarm Optimization Algorithm, the Grasshopper Optimization Algorithm selects local feature from text document and Chameleon Swarm Optimization Algorithm selects the best global feature from local feature. These important features are tested using density peaks clustering algorithm to maximize the reliability and minimize the computational time cost. The performance of Grasshopper–Chameleon Swarm Optimization Algorithm is analyzed with 20 News groups dataset. Moreover, the performance metrics, like accuracy, precision, sensitivity, specificity, execution time and memory usage are analyzed. The simulation process shows that the proposed TFSC-G-CSOA-DPCA method provides better accuracy of 97.36%, 95.14%, 94.67% and 91.91% and maximum sensitivity of 96.25%, 87.25%, 93.96% and 92.59% compared to the existing methods such as TFSC-BBA-MCL, TFSC-MVO-K-Means C, TFSC-GWO-GOA-FCM and TFSC-WM-K-Means C, respectively.},
  archive      = {J_IJCIA},
  author       = {R. Purushothaman and S. Selvakumar and S. P. Rajagopalan},
  doi          = {10.1142/S1469026822500183},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2250018},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Hybrid grasshopper and chameleon swarm optimization algorithm for text feature selection with density peaks clustering},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling of drying kinetics of banana (musa spp., musaceae)
slices with the method of image processing and artificial neural
networks. <em>IJCIA</em>, <em>21</em>(3), 2250017. (<a
href="https://doi.org/10.1142/S1469026822500171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, modeling of thin banana slices dried on 316 stainless steel shelves is carried out in an oven working with serial controlled and concentric blower-resistor couple. Changes occurred in banana slices (area and color) during drying process have been recorded by a camera. Additionally, weight has been measured with a load cell which is under the shelf and energy consumption has been measured with electricity consumption meter which is tied to energy input. The main aim of the study is to conduct the drying process of banana slices according to the data obtained from camera. Besides, obtained data have been tested with a powerful modeling technique like Artificial Neural Networks (ANN), and it has been seen that drying process could be modeled according to the data obtained from camera. Energy consumption data have been added in order to increase the performance of ANN and strengthen the modeling. Thus, an automatic drying system that can learn by itself using only a camera without any other sensors will be installed. This has been caused an increase in performance. However, it is obvious that it increases cost. According to the results of modeling process, 99% of “goodness of fit” has been obtained by using the change in banana slices and the number of pixels. It has been found that the developed model performed adequately in predicting the changes of the moisture content. Thus, it has been available to control the food drying process with a digital camera.},
  archive      = {J_IJCIA},
  author       = {Semih Ozden and Faruk Kılıç},
  doi          = {10.1142/S1469026822500171},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2250017},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Modeling of drying kinetics of banana (Musa spp., musaceae) slices with the method of image processing and artificial neural networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid nature-inspired algorithm for feature selection in
alzheimer detection using brain MRI images. <em>IJCIA</em>,
<em>21</em>(3), 2250016. (<a
href="https://doi.org/10.1142/S146902682250016X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer is an irreversible neurological disorder. It impairs the memory and thinking ability of a person. Its symptoms are not known at an early stage due to which a person is deprived of receiving medication at an early stage. Dementia, a general form of Alzheimer, is difficult to diagnose and hence a proper system for detection of Alzheimer is needed. Various studies have been done for accurate classification of patients with or without Alzheimer’s disease (AD). However, accuracy of prediction is still a challenge depending on the type of data used for diagnosis. Timely identification of true positives and false negatives are critical to the diagnosis. This work focuses on extraction of optimal features using nature-inspired algorithms to enhance the accuracy of classification models. This work proposes two hybrid nature-inspired algorithms — particle swarm optimization with genetic algorithm (PSO_GA) and whale optimization algorithm with genetic algorithm, (WOA_GA) to improve prediction accuracy. The performance of proposed algorithms is evaluated with respect to various existing algorithms on the basis of accuracy and time taken. Experimental results depict that there is trade-off in time and accuracy. Results revealed that the best accuracy is achieved by PSO_GA while it takes higher time than WOA and WOA_GA. Overall WOA_GA gives better performance accuracy when compared to a majority of the compared algorithms using support vector machine (SVM) and AdaSVM classifiers.},
  archive      = {J_IJCIA},
  author       = {Parul Agarwal and Anirban Dutta and Tarushi Agrawal and Nikhil Mehra and Shikha Mehta},
  doi          = {10.1142/S146902682250016X},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2250016},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Hybrid nature-inspired algorithm for feature selection in alzheimer detection using brain MRI images},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-scale deep residual shrinkage network for atrial
fibrillation recognition. <em>IJCIA</em>, <em>21</em>(3), 2250015. (<a
href="https://doi.org/10.1142/S1469026822500158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel multi-scale deep residual shrinkage network (MS-DRSN) is proposed for signal denoising and atrial fibrillation (AF) recognition. Signal denoising is done by multi-scale threshold denoising module (MS-TDM), which consists of two parts: threshold acquisition and threshold denoising. The thresholds are automatically obtained through the global attention module constructed by the neural network. Threshold denoising chooses Garrote as the threshold function, which combines the advantages of soft and hard thresholding. The multi-scale features consist of global attention module and local attention module, and then the multi-scale features are denoised using the acquired thresholds and threshold functions, and the AF recognition task is finally completed in the Softmax layer after the superposition of multiple MS-TDMs. An adaptive synthetic sampling (ADASYN) algorithm is also used to oversample the dataset and achieve data category balancing by generating new samples, which improves the accuracy of AF recognition and alleviates the overfitting of the neural network. This method was experimented and validated on the PhysioNet2017 dataset. The experimental results show that the approach achieves an accuracy of 0.894 and an F 1 score of 0.881, which is better than current machine learning and deep learning models.},
  archive      = {J_IJCIA},
  author       = {Dayin Shi and Zhiyong Wu and Longbo Zhang and Benjia Hu and Ke Meng},
  doi          = {10.1142/S1469026822500158},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2250015},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Multi-scale deep residual shrinkage network for atrial fibrillation recognition},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Calendar of events. <em>IJCIA</em>, <em>21</em>(2),
2283002. (<a href="https://doi.org/10.1142/S1469026822830024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIA},
  doi          = {10.1142/S1469026822830024},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2283002},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Calendar of events},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparison of nitrogen dioxide predictions during a pandemic
and non-pandemic scenario in the city of madrid using a convolutional
LSTM network. <em>IJCIA</em>, <em>21</em>(2), 2250014. (<a
href="https://doi.org/10.1142/S1469026822500146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, machine learning technologies with the methods and capabilities available, combined with a geospatial dimension, can perform predictive analyzes of air quality with greater accuracy. However, air pollution is influenced by many external factors, one of which has recently been caused by the restrictions applied to curb the relentless advance of COVID-19. These sudden changes in air quality levels can negatively influence current forecasting models. This work compares air pollution forecasts during a pandemic and non-pandemic period under the same conditions. The ConvLSTM algorithm was applied to predict the concentration of nitrogen dioxide using data from the air quality and meteorological stations in Madrid. The proposed model was applied for two scenarios: pandemic (January–June 2020) and non-pandemic (January–June 2019), each with sub-scenarios based on time granularity (1-h, 12-h, 24-h and 48-h) and combination of features. The Root Mean Square Error was taken as the estimation metric, and the results showed that the proposed method outperformed a reference model, and the feature selection technique significantly improved the overall accuracy.},
  archive      = {J_IJCIA},
  author       = {Ditsuhi Iskandaryan and Francisco Ramos and Sergio Trilles},
  doi          = {10.1142/S1469026822500146},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2250014},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Comparison of nitrogen dioxide predictions during a pandemic and non-pandemic scenario in the city of madrid using a convolutional LSTM network},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-class document image classification using deep visual
and textual features. <em>IJCIA</em>, <em>21</em>(2), 2250013. (<a
href="https://doi.org/10.1142/S1469026822500134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digitalization era has brought digital documents with it, and the classification of document images has become an important need as in classical text documents. Document images, in which text documents are stored as images, contain both text and visual features, unlike images. Therefore, it is possible to use both text and visual features while classifying such data. Considering this situation, in this study, it is aimed to classify document images by using both text and visual features and to determine which feature type is more successful in classification. In the text-based approach, each document/class is labeled with the keywords associated with that document/class and the classification is realized according to whether the document contains the related key-words or not. For visual-based classification, we use four deep learning models namely CNN, NASNet-Large, InceptionV3, and EfficientNetB3. Experimental study is carried out on document images obtained from applicants of the Kocaeli University. As a result, it is seen ii that EfficientNetB3 is the most superior among all with 0.8987 F-score.},
  archive      = {J_IJCIA},
  author       = {Semih Sevim and Ekin Ekinci and Sevinç Ilhan Omurca and Eren Berk Edinç and Süleyman Eken and Türkücan Erdem and Ahmet Sayar},
  doi          = {10.1142/S1469026822500134},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2250013},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Multi-class document image classification using deep visual and textual features},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A machine learning-based approach to discriminating basaltic
tectonic settings. <em>IJCIA</em>, <em>21</em>(2), 2250012. (<a
href="https://doi.org/10.1142/S1469026822500122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The geochemical characteristics of magmatic rocks can distinguish the tectonic setting of magma formation and their geochemical signatures are discriminated by using the whole-rock geochemical data. As a new attempt of artificial intelligence technology in geochemistry, the machine learning discrimination method is gradually complementary to the classical discriminative graphical method. However, the feature selection of high-dimensional data and the determination of many unknown parameters are the two main factors affecting the classification accuracy of the algorithm. In this paper, a particle swarm optimized support vector machine (PSO-SVM) model is established to classify the tectonic environments of basaltic rocks in the GEOROC database. The model mainly relies on the powerful search capability of the particle swarm algorithm to find the best parameter combination selected by the SVM based on experience to improve the accuracy. In this study, based on the basalt samples in the database and the confusion matrix, the performance of PSO-SVM model is evaluated by simulation experiments. The results show that the model proposed in this paper is more effective in distinguishing the basaltic tectonic environments, with an accuracy of more than 90%. Therefore, compared with the traditional discriminant map method, the machine learning method based on the fusion of two algorithms performs better in the tectonic environment classification problems.},
  archive      = {J_IJCIA},
  author       = {Baoshun Liu and Junxia Shi},
  doi          = {10.1142/S1469026822500122},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2250012},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A machine learning-based approach to discriminating basaltic tectonic settings},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computer-aided heart disease diagnosis using recursive rule
extraction algorithms from neural networks. <em>IJCIA</em>,
<em>21</em>(2), 2250011. (<a
href="https://doi.org/10.1142/S1469026822500110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mortality rate due to fatal heart disease (HD) or cardiovascular disease (CVD) has increased drastically over the world in recent decades. HD is a very hazardous problem prevailing among people which is treatable if detected early. But in most of the cases, the disease is not diagnosed until it becomes severe. Hence, it is requisite to develop an effective system which can accurately diagnosis HD and provide a concise description for the underlying causes [risk factors (RFs)] of the disease, so that in future HD can be controlled only by managing the primary RFs. Recently, researchers are using various machine learning algorithms for HD diagnosis, and neural network (NN) is one among them which has attracted tons of people because of its high performance. But the main obstacle with a NN is its black-box nature, i.e., its incapability in explaining the decisions. So, as a solution to this pitfall, the rule extraction algorithms can be very effective as they can extract explainable decision rules from NNs with high prediction accuracies. Many neural-based rule extraction algorithms have been applied successfully in various medical diagnosis problems. This study assesses the performance of rule extraction algorithms for HD diagnosis, particularly those that construct rules recursively from NNs. Because they subdivide a rule’s subspace until the accuracy improves, recursive algorithms are known for delivering interpretable decisions with high accuracy. The recursive rule extraction algorithms’ efficacy in HD diagnosis is demonstrated by the results. Along with the significant data ranges for the primary RFs, a maximum accuracy of 82.59% is attained.},
  archive      = {J_IJCIA},
  author       = {Manomita Chakraborty and Saroj Kumar Biswas},
  doi          = {10.1142/S1469026822500110},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2250011},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Computer-aided heart disease diagnosis using recursive rule extraction algorithms from neural networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vegetation evolution: An optimization algorithm inspired by
the life cycle of plants. <em>IJCIA</em>, <em>21</em>(2), 2250010. (<a
href="https://doi.org/10.1142/S1469026822500109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we have observed that different types of plants in nature can use their own survival mechanisms to adapt to various living environments. A new population-based vegetation evolution (VEGE) algorithm is proposed to solve optimization problems by interactively simulating the growth and maturity periods of plants. In the growth period, individuals explore their local areas and grow in potential directions, while individuals generate many seed individuals and spread them as widely as possible in the maturity period. The main contribution of our proposed VEGE is to balance exploitation and exploration from a novel perspective, which is to perform these two periods in alternation to switch between two different search capabilities. To evaluate the performance of the proposed VEGE, we compare it with three well-known algorithms in the evolutionary computation community: differential evolution, particle swarm optimization, and enhanced fireworks algorithm — and run them on 28 benchmark functions with 2-dimensions (2D), 10D, and 30D with 30 trial runs. The experimental results show that VEGE is efficient and promising in terms of faster convergence speed and higher accuracy. In addition, we further analyze the effects of the composition of VEGE on performance, and some open topics are also given.},
  archive      = {J_IJCIA},
  author       = {Jun Yu},
  doi          = {10.1142/S1469026822500109},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2250010},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Vegetation evolution: An optimization algorithm inspired by the life cycle of plants},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RFCBF: Enhance the performance and stability of fast
correlation-based filter. <em>IJCIA</em>, <em>21</em>(2), 2250009. (<a
href="https://doi.org/10.1142/S1469026822500092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a preprocessing step that plays a crucial role in the domain of machine learning and data mining. Feature selection methods have been shown to be effective in removing redundant and irrelevant features, improving the learning algorithm’s prediction performance. Among the various methods of feature selection based on redundancy, the fast correlation-based filter (FCBF) is one of the most effective. In this paper, we developed a novel extension of FCBF, called resampling FCBF (RFCBF) that combines resampling technique to improve classification accuracy. We performed comprehensive experiments to compare the RFCBF with other state-of-the-art feature selection methods using three competitive classifiers (K-nearest neighbor, support vector machine, and logistic regression) on 12 publicly available datasets. The experimental results show that the RFCBF algorithm yields significantly better results than previous state-of-the-art methods in terms of classification accuracy and runtime.},
  archive      = {J_IJCIA},
  author       = {Xiongshi Deng and Min Li and Lei Wang and Qikang Wan},
  doi          = {10.1142/S1469026822500092},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2250009},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {RFCBF: Enhance the performance and stability of fast correlation-based filter},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hierarchical processing and completion mechanism of
foreground information for person re-identification. <em>IJCIA</em>,
<em>21</em>(2), 2250008. (<a
href="https://doi.org/10.1142/S1469026822500080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (Re-ID) arises in many applications such as video surveillance and intelligent security. Background clutter and distribution drift are two issues that cross-domain person Re-ID faces. In this research, we propose that the background clutter problem be solved by combining semantic segmentation technology with human attribute identification technology. To overcome the distribution drift problem, we propose employing MMD as a metric for distribution differences and processing methods based on feature properties. The results of the experiments reveal that our strategy yielded the best results.},
  archive      = {J_IJCIA},
  author       = {Jiajian Huang and Shihao Wang},
  doi          = {10.1142/S1469026822500080},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2250008},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A hierarchical processing and completion mechanism of foreground information for person re-identification},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient syllable-based speech segmentation model using
fuzzy and threshold-based boundary detection. <em>IJCIA</em>,
<em>21</em>(2), 2250007. (<a
href="https://doi.org/10.1142/S1469026822500079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To develop a high-quality TTS system, an appropriate segmentation of continuous speech into the syllabic units plays a vital role. The significant objective of this research work involves the implementation of an automatic syllable-based speech segmentation technique for continuous speech of the Hindi language. Here, the parameters involved in the segmentation process are optimized to segment the speech syllables. In addition to this, the proposed iterative splitting process containing the optimum parameters minimizes the deletion errors. Thus, the optimized iterative incorporation can discard more insertions without merging the frequent non-iterative incorporation. The mixture of optimized iterative and iterative incorporation provides the best accuracy with the least insertion and deletion errors. The segmentation output based on different text signals for the proposed approach and other techniques namely GA, PSO and SOM is accurately segmented. The average accuracy obtained for the proposed approach is high with 97.5% than GA, PSO and SOM. The performance of the proposed algorithm is also analyzed and gives better-segmented accuracy when compared with other state-of-the-art methods. Here, the syllable-based segmented database is suitable for the speech technology system for Hindi in the travel domain.},
  archive      = {J_IJCIA},
  author       = {Ruchika Kumari and Amita Dev and Ashwani Kumar},
  doi          = {10.1142/S1469026822500079},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2250007},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {An efficient syllable-based speech segmentation model using fuzzy and threshold-based boundary detection},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022d). Calendar of events. <em>IJCIA</em>, <em>21</em>(1),
2283001. (<a href="https://doi.org/10.1142/S1469026822830012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIA},
  doi          = {10.1142/S1469026822830012},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2283001},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Calendar of events},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fuzzy strategy to eliminate uncertainty in grading
positive tuberculosis. <em>IJCIA</em>, <em>21</em>(1), 2250006. (<a
href="https://doi.org/10.1142/S1469026822500067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sputum smear microscopic examination is an effective, fast, and low-cost technique that is highly specific in areas with a high prevalence of pulmonary tuberculosis. Since manual screening needs trained pathologist in high prevalence zones, the possibility of deploying adequate technicians during the epidemic sessions would be impractical. This condition can cause overburdening and fatigue of working technicians which may tend to reduce the potential efficiency of Tuberculosis (TB) diagnosis. Hence, automation of sputum inspection is the most appropriate aspect in TB outbreak zones to maximize the detection ability. Sputum collection, smear preparing, staining, interpreting smears, and reporting of TB severity are all part of the diagnosis of tuberculosis. This study has analyzed the risk of automating TB severity grading. According to the findings of the analysis, numerous TB-positive cases do not fit into the standard TB severity grade while applying direct rule-driven strategy. The manual investigation, on the other hand, arbitrarily labels the TB grade on those cases. To counter the risk of automation, a fuzzy-based Tuberculosis Severity Level Categorizing Algorithm (TSLCA) is introduced to eliminate uncertainty in classifying the level of TB infection. TSLCA introduces the weight factors, which are dependent on the existence of maximum number of Acid-Fast Bacilli (AFB) per microscopic Field of View (FOV). The fuzzification and defuzzification operations are carried out using the triangular membership function. In addition, the α -cut approach is used to eliminate the ambiguity in TB severity grading. Several uncertain TB microscopy screening reports are tested using the proposed TSLCA. Based on the experimental results, it is observed that the TB grading by TSLCA is consistent, error-free, significant and fits exactly into the standard criterion. As a result of the proposed TSLCA, the uncertainty of grading is eliminated and the reliability of tuberculosis diagnosis is ensured when adapting automatic diagnosis.},
  archive      = {J_IJCIA},
  author       = {R. Dinesh Jackson Samuel and B. Rajesh Kanna},
  doi          = {10.1142/S1469026822500067},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2250006},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A fuzzy strategy to eliminate uncertainty in grading positive tuberculosis},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Padeep: A patched deep learning based model for plants
recognition on small size dataset: Chenopodiaceae case study.
<em>IJCIA</em>, <em>21</em>(1), 2250005. (<a
href="https://doi.org/10.1142/S1469026822500055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large training sample is prerequisite for the successful training of each deep learning model for image classification. Collecting a large dataset is time-consuming and costly, especially for plants. When a large dataset is not available, the challenge is how to use a small or medium size dataset to train a deep model optimally. To overcome this challenge, a novel model is proposed to use the available small size plant dataset efficiently. This model focuses on data augmentation and aims to improve the learning accuracy by oversampling the dataset through representative image patches. To extract the relevant patches, ORB key points are detected in the training images and then image patches are extracted using an innovative algorithm. The extracted ORB image patches are used for dataset augmentation to avoid overfitting during the training phase. The proposed model is implemented using convolutional neural layers, where its structure is based on ResNet architecture. The proposed model is evaluated on a challenging ACHENY dataset. ACHENY is a Chenopodiaceae plant dataset, comprising 27030 images from 30 classes. The experimental results show that the patch-based strategy outperforms the classification accuracy achieved by traditional deep models by 9%.},
  archive      = {J_IJCIA},
  author       = {Ahmad Heidary-Sharifabad and Mohsen Sardari Zarchi and Gholamreza Zarei},
  doi          = {10.1142/S1469026822500055},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2250005},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Padeep: a patched deep learning based model for plants recognition on small size dataset: chenopodiaceae case study},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The augmentation data of retina image for blood vessel
segmentation using u-net convolutional neural network method.
<em>IJCIA</em>, <em>21</em>(1), 2250004. (<a
href="https://doi.org/10.1142/S1469026822500043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The retina is the most important part of the eye. By proper feature extraction, it can be the first step to detect a disease. Morphology of retina blood vessels can be used to identify and classify a disease. A step, such as segmentation and analysis of retinal blood vessels, can assist medical personnel in detecting the severity of a disease. In this paper, vascular segmentation using U-net architecture in the Convolutional Neural Network (CNN) method is proposed to train a sematic segmentation model in retinal blood vessel. In addition, the Contrast Limited Adaptive Histogram Equalization (CLAHE) method is used to increase the contrast of the grayscale and Median Filter is used to obtain better image quality. Data augmentation is also used to maximize the number of datasets owned to make more. The proposed method allows for easier implementation. In this study, the dataset used was STARE with the result of accuracy, sensitivity, specificity, precision, and F1-score that reached 97.64%, 78.18%, 99.20%, 88.77%, and 82.91%.},
  archive      = {J_IJCIA},
  author       = {Erwin and Asri Safmi and Anita Desiani and Bambang Suprihatin and Fathoni},
  doi          = {10.1142/S1469026822500043},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2250004},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {The augmentation data of retina image for blood vessel segmentation using U-net convolutional neural network method},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimized feature selection in software product lines using
discrete bat algorithm. <em>IJCIA</em>, <em>21</em>(1), 2250003. (<a
href="https://doi.org/10.1142/S1469026822500031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Product Lines (SPLs) are one of the ways to develop software products by increasing productivity and reducing cost and time in the software development process. In SPLs, each product has many features and it is necessary to consider the optimal and custom features of the products. In fact, selecting key features in SPLs is a challenging process. Feature selection in SPLs is an optimization problem and an NP-Hard problem. One way to select a feature is to use meta-heuristic algorithms modeled on nature, i.e., Bat Algorithm. By modeling bat behavior in prey hunting, a suitable meta-innovative algorithm is considered. This algorithm has important advantages that make it more accurate than conventional methods such as Genetic Algorithm (GA) and Particle Swarm Optimization (PSO) algorithm. In this paper, to select software product features, idol binary algorithm and artificial neural network are used to identify important features of software products that reduce production costs and time. The experiments in MATLAB software and datasets related to software production lines show that the rate of reduction of target performance error or feature selection cost in software production lines in the proposed method has decreased by 64.17% with increasing population.},
  archive      = {J_IJCIA},
  author       = {Hajar Sadeghi and Shohreh Ajoudanian},
  doi          = {10.1142/S1469026822500031},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2250003},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Optimized feature selection in software product lines using discrete bat algorithm},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Facial expression recognition using convolution neural
network fusion and texture descriptors representation. <em>IJCIA</em>,
<em>21</em>(1), 2250002. (<a
href="https://doi.org/10.1142/S146902682250002X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition is an interesting research direction of pattern recognition and computer vision. It has been increasingly used in artificial intelligence, human–computer interaction and security monitoring. In recent years, Convolution Neural Network (CNN) as a deep learning technique and multiple classifier combination method has been applied to gain accurate results in classifying face expressions. In this paper, we propose a multimodal classification approach based on a local texture descriptor representation and a combination of CNN to recognize facial expression. Initially, in order to reduce the influence of redundant information, the preprocessing stage is performed using face detection, face image cropping and texture descriptors of Local Binary Pattern (LBP), Local Gradient Code (LGC), Local Directional Pattern (LDP) and Gradient Direction Pattern (GDP) calculation. Second, we construct a cascade CNN architecture using the multimodal data of each descriptor (CNN LBP , CNN LGC , CNN GDP and CNN LDP ) to extract facial features and classify emotions. Finally, we apply aggregation techniques (sum and product rule) for each modality to combine the four multimodal outputs and thus obtain the final decision of our system. Experimental results using CK + and JAFFE database show that the proposed multimodal classification system achieves superior recognition performance compared to the existing studies with classification accuracy of 97, 93% and 94, 45%, respectively.},
  archive      = {J_IJCIA},
  author       = {Chebah Ouafa and Laskri Mohamed Tayeb},
  doi          = {10.1142/S146902682250002X},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2250002},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Facial expression recognition using convolution neural network fusion and texture descriptors representation},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Collaborative learning to improve the non-uniqueness of NMF.
<em>IJCIA</em>, <em>21</em>(1), 2250001. (<a
href="https://doi.org/10.1142/S1469026822500018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-negative matrix factorization (NMF) is an unsupervised algorithm for clustering where a non-negative data matrix is factorized into (usually) two matrices with the property that all the matrices have no negative elements. This factorization raises the problem of instability, which means whenever we run NMF for the same dataset, we get different factorization. In order to solve the problem of non-uniqueness and to have a more stable solution, we propose a new approach that consists on collaborating different NMF models followed by a consensus. The proposed approach was validated on several datasets and the experimental results showed the effectiveness of our approach which is based on the reducing of standard reconstruction error in NMF model.},
  archive      = {J_IJCIA},
  author       = {Kaoutar Benlamine and Younes Bennani and Basarab Matei and Nistor Grozavu and Issam Falih},
  doi          = {10.1142/S1469026822500018},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2250001},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Collaborative learning to improve the non-uniqueness of NMF},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
