<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IDA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ida---89">IDA - 89</h2>
<ul>
<li><details>
<summary>
(2022). Graph convolutional networks-based robustness optimization
for scale-free internet of things. <em>IDA</em>, <em>26</em>(6),
1683–1701. (<a href="https://doi.org/10.3233/IDA-216222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) devices have limited resources and are vulnerable to attacks, so optimizing their network topology to resist random failures and malicious attacks has become a key issue. The scale-free network model has strong resistance to random attacks, but it is very vulnerable to malicious attacks. The existing studies mostly adopt heuristic algorithms to optimize the ability of scale-free networks to resist malicious attacks, but their high computational cost cannot meet the timeliness requirements of the real IoT. Therefore, this paper proposes an intelligent topology robustness optimization model based on a graph convolutional network (ROGCN). The model extracts the onion-like structural features of the highly robust network topology from the data set through supervised learning, and on this basis, different search strategies are designed to meet the needs of different IoT scenarios. The extensive experimental results demonstrate that ROGCN can more effectively improve the robustness of scale-free IoT networks against malicious attacks compared to two existing heuristic algorithms, with a lower computational cost.},
  archive      = {J_IDA},
  author       = {Peng, Yabin and Liu, Caixia and Wu, Yiteng and Liu, Shuxin and Wang, Kai},
  doi          = {10.3233/IDA-216222},
  journal      = {Intelligent Data Analysis},
  month        = {11},
  number       = {6},
  pages        = {1683-1701},
  shortjournal = {Intell. Data Anal.},
  title        = {Graph convolutional networks-based robustness optimization for scale-free internet of things},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NetNDP: Nonoverlapping (delta, gamma)-approximate pattern
matching. <em>IDA</em>, <em>26</em>(6), 1661–1682. (<a
href="https://doi.org/10.3233/IDA-216325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pattern matching can be used to calculate the support of patterns, and is a key issue in sequential pattern mining (or sequence pattern mining). Nonoverlapping pattern matching means that two occurrences cannot use the same character in the sequence at the same position. Approximate pattern matchin g allows for some data noise, and is more general than exact pattern matching. At present, nonoverlapping approximate pattern matching is based on Hamming distance, which cannot be used to measure the local approximation between the subsequence and pattern, resulting in large deviations in matching results. To tackle this issue, we present a Nonoverlapping Delta and gamma approximate Pattern matching (NDP) scheme that employs the (δ,γ)-distance to give an approximate pattern matching, where the local and the global distances do not exceed δ and γ, respectively. We first transform the NDP problem into a local approximate Nettree and then construct an efficient algorithm, called the local approximate Nettree for NDP (NetNDP). We propose a new approach called the Minimal Root Distance which allows us to determine whether or not a node has root paths that satisfy the global constraint and to prune invalid nodes and parent-child relationships. NetNDP finds the rightmost absolute leaf of the max root, searches for the rightmost occurrence from the rightmost absolute leaf, and deletes this occurrence. We iterate the above steps until there are no new occurrences. Numerous experiments are used to verify the performance of the proposed algorithm.},
  archive      = {J_IDA},
  author       = {Wu, Youxi and Jian, Bojing and Li, Yan and Jiang, He and Wu, Xindong},
  doi          = {10.3233/IDA-216325},
  journal      = {Intelligent Data Analysis},
  month        = {11},
  number       = {6},
  pages        = {1661-1682},
  shortjournal = {Intell. Data Anal.},
  title        = {NetNDP: Nonoverlapping (delta, gamma)-approximate pattern matching},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Keyphrase extraction using deep and wide learning features.
<em>IDA</em>, <em>26</em>(6), 1643–1660. (<a
href="https://doi.org/10.3233/IDA-216091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keyphrases are important phrases that represent the theme of a document. With the help of keyphrases people can quickly find useful information from massive data. Traditional statistic-based methods for keyphrase extraction only make use of the statistical features of the words and ignore the seman tic relationship between words. Recently, the emerging methods based on deep neural network extract keyphrases by capturing the semantic contextual information without considering the statistical features. In this paper, we propose a new keyphrase extraction method based on the neural network architecture composing of deep and wide learning parts. In the deep learning part, BERT (Bidirectional Encoder Representation from Transformers) and Bi-LSTM (Bidirectional Long Short-Term Memory) models are used to capture the contextual semantic information from the word sequence while in the wide learning part several important statistical features are considered to jointly train the keyphrase extraction model. The experimental results on two public datasets show that the performance of our proposed model is better than eight commonly baseline keyphrase extraction methods.},
  archive      = {J_IDA},
  author       = {Zu, Xian and Xie, Fei},
  doi          = {10.3233/IDA-216091},
  journal      = {Intelligent Data Analysis},
  month        = {11},
  number       = {6},
  pages        = {1643-1660},
  shortjournal = {Intell. Data Anal.},
  title        = {Keyphrase extraction using deep and wide learning features},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation of end-to-end aspect-based sentiment analysis
methods employing novel benchmark dataset for aspect, and opinion review
analysis. <em>IDA</em>, <em>26</em>(6), 1617–1641. (<a
href="https://doi.org/10.3233/IDA-216252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) deals with the determination of sentiments for opinion targets. While historically this research task has been addressed with pipeline approaches, more recent works use neural networks to jointly deal with the aspect term and opinion term extraction, as well a s the polarity classification. Although learned together, most NN-based approaches and all pipeline approaches do not model correlations between the tasks. This is also based on the absence of adequate datasets which are annotated for all sub-tasks in a unified tagging scheme. We address this bottleneck and introduce the first purposely designed and annotated dataset for ABSA. The DAORA dataset covers 2,100 Tripadvisor reviews, and it is annotated on aspect terms, opinion terms, as well as aspect term polarity, using a unified tagging scheme. It was designed especially for end-to-end aspect-based sentiment analysis of real-world reviews and does not use any sentence repetition or removal. We evaluate the DAORA dataset in several experiments employing state-of-the-art models for ABSA. We set benchmarks and analyze the strengths as well as weaknesses of the data and approaches.},
  archive      = {J_IDA},
  author       = {Pecar, Samuel and Daudert, Tobias and Simko, Marian},
  doi          = {10.3233/IDA-216252},
  journal      = {Intelligent Data Analysis},
  month        = {11},
  number       = {6},
  pages        = {1617-1641},
  shortjournal = {Intell. Data Anal.},
  title        = {Evaluation of end-to-end aspect-based sentiment analysis methods employing novel benchmark dataset for aspect, and opinion review analysis},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Penalized additive neural network regression. <em>IDA</em>,
<em>26</em>(6), 1597–1616. (<a
href="https://doi.org/10.3233/IDA-216070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we develop a penalized additive regression estimation method based on a neural network architecture. An additive neural network model is constructed by using a linear combination of univariate neural networks, or equivalently functional components. We use a B-spline activation functi on, which is useful to capture local features of data, for nodes that constitute the model. A penalty function is adopted to induce sparsity in functional components and nodes on each component simultaneously. This enables us to obtain a sparse representation, which in turn improves accountability of the model. To implement the proposed estimation method, we devise an efficient iterative algorithm based on a coordinate-wise updating process. An initialization scheme specialized for the B-spline activation function is proposed. The initialization approach enables the proposed method to achieve better performance compared with random initialization scheme. Numerical studies show that the fitted functional components of our estimator adapt to local and sparse structures based on a given dataset.},
  archive      = {J_IDA},
  author       = {Shin, Jae-Kyung and Bak, Kwan-Young and Koo, Ja-Yong},
  doi          = {10.3233/IDA-216070},
  journal      = {Intelligent Data Analysis},
  month        = {11},
  number       = {6},
  pages        = {1597-1616},
  shortjournal = {Intell. Data Anal.},
  title        = {Penalized additive neural network regression},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RBSP-boosting: A shapley value-based resampling approach for
imbalanced data classification. <em>IDA</em>, <em>26</em>(6), 1579–1595.
(<a href="https://doi.org/10.3233/IDA-216092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing the problem of imbalanced data category distribution in real applications and the problem of traditional classifiers tending to ensure the accuracy of the majority class while ignoring the accuracy of the minority class when processing imbalanced data, this paper proposes a method called RBSP-Boosting for imbalanced data classification. First, RBSP-Boosting introduces the Shapley value and calculates the Shapley value for each sample of the dataset through the truncated Monte Carlo method. Moreover, the proposed method removes the noise data according to the Shapley value and undersamples the samples with Shapley values less than zero in the majority class. Then, it takes the Shapley value as the weight of the sample and oversamples the minority class according to the weight. Finally, the new dataset is trained on the classifier through the AdaBoost classifier. Experiments are conducted on nine groups of UCI and KEEL datasets, and RBSP-Boosting is compared with four sampling algorithms: Random-OverSampler, SMOTE, Borderline-SMOTE and SVM-SMOTE. Experimental results show that the RBSP-Boosting method in the three evaluation metrics of AUC, F-score and G-mean, compared with the best performance of the four comparison algorithms, increases by 4.69%, 10.3% and 7.86%, respectively. The proposed method can significantly improve the effect of imbalanced data classification.},
  archive      = {J_IDA},
  author       = {Chong, Weitu and Chen, Ningjiang and Fang, Chengyun},
  doi          = {10.3233/IDA-216092},
  journal      = {Intelligent Data Analysis},
  month        = {11},
  number       = {6},
  pages        = {1579-1595},
  shortjournal = {Intell. Data Anal.},
  title        = {RBSP-boosting: A shapley value-based resampling approach for imbalanced data classification},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Credit scoring based on a bagging-cascading boosted decision
tree. <em>IDA</em>, <em>26</em>(6), 1557–1578. (<a
href="https://doi.org/10.3233/IDA-216228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Establishing precise credit scoring models to predict the potential default probability is vital for credit risk management. Machine learning models, especially ensemble learning approaches, have shown substantial progress in the performance improvement of credit scoring. The Bagging ensemble appro ach improves the credit scoring performance by optimizing the prediction variance while boosting ensemble algorithms reduce the prediction error by controlling the prediction bias. In this study, we propose a hybrid ensemble method that combines the advantages of the Bagging ensemble strategy and boosting ensemble optimization pattern, which can well balance the tradeoff of variance-bias optimization. The proposed method considers XGBoost as a base learner, which ensures the low-bias prediction. Moreover, the Bagging strategy is introduced to train the base learner to prevent over-fitting in the proposed method. Besides, the Bagging-boosting ensemble algorithm is further assembled in a cascading way, making the proposed new hybrid ensemble algorithm a good solution to balance the tradeoff of variance bias for credit scoring. Experimental results on the Australian, German, Japanese, and Taiwan datasets show the proposed Bagging-cascading boosted decision tree provides a more accurate credit scoring result.},
  archive      = {J_IDA},
  author       = {Zou, Yao and Gao, Changchun and Xia, Meng and Pang, Congyuan},
  doi          = {10.3233/IDA-216228},
  journal      = {Intelligent Data Analysis},
  month        = {11},
  number       = {6},
  pages        = {1557-1578},
  shortjournal = {Intell. Data Anal.},
  title        = {Credit scoring based on a bagging-cascading boosted decision tree},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph structure learning based on feature and label
consistency. <em>IDA</em>, <em>26</em>(6), 1539–1555. (<a
href="https://doi.org/10.3233/IDA-216253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have achieved remarkable success in graph-related tasks by combining node features and graph topology elegantly. Most GNNs assume that the networks are homophilous, which is not always true in the real world, i.e., structure noise or disassortative graphs. Only a few wo rks focus on generalizing graph neural networks to heterophilous or low homophilous networks, where connected nodes may have different labels. In this paper, we design a simple and effective Graph Structure Learning strategy based on Feature and Label consistency (GSLFL) to increase the homophilous level of networks for generalizing any existing GNNs to heterophilous networks. Specifically, we first introduce a method to learn graph structure based on node features and then modify the graph structure based on label consistency. Further, we combine the GSLFL with three existing GNNs to learn node representations and graph structure together. And we design a self-training method to iteratively train models and modify graph structure with pseudo-labels. Finally, our empirical results on 6 public networks with homophily or heterophily, and structure attacks show that our methods outperform the state-of-the-art methods in most cases.},
  archive      = {J_IDA},
  author       = {Yuan, Jinliang and Yao, Yirong and Xu, Ming and Yu, Hualei and Xie, Junyuan and Wang, Chongjun},
  doi          = {10.3233/IDA-216253},
  journal      = {Intelligent Data Analysis},
  month        = {11},
  number       = {6},
  pages        = {1539-1555},
  shortjournal = {Intell. Data Anal.},
  title        = {Graph structure learning based on feature and label consistency},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fast method for discovering suitable number of clusters
for fuzzy clustering. <em>IDA</em>, <em>26</em>(6), 1523–1538. (<a
href="https://doi.org/10.3233/IDA-200511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One main problem of Fuzzy c-Means (FCM) is deciding on an appropriate number of clusters. Although methods have been proposed to address this, they all require clustering algorithms to be executed several times before the right number is chosen. The aim of this study was to develop a method for det ermining cluster numbers without repeated execution. We propose a new method that combines FCM and singular value decomposition. Based on the percentage of variance, this method can calculate the appropriate number of clusters. The proposed method was applied to several well-known datasets to demonstrate its effectiveness.},
  archive      = {J_IDA},
  author       = {Hsu, Ping-Yu and Nguyen, Phan-Anh-Huy},
  doi          = {10.3233/IDA-200511},
  journal      = {Intelligent Data Analysis},
  month        = {11},
  number       = {6},
  pages        = {1523-1538},
  shortjournal = {Intell. Data Anal.},
  title        = {A fast method for discovering suitable number of clusters for fuzzy clustering},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive fuzzy c-means clustering integrated with local
outlier factor. <em>IDA</em>, <em>26</em>(6), 1507–1521. (<a
href="https://doi.org/10.3233/IDA-216266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional fuzzy C-means (FCM) is sensitive to the initial cluster centers and outliers, which may cause the centers deviate from the real centers when the algorithm converges. To improve the performance of FCM, a method of initializing the cluster centers based on probabilistic suppression i s proposed and an improved local outlier factor is integrated into the model of FCM. Firstly, the probability of an object as cluster center is defined by its local density, and all initial centers are obtained by the cluster center’s probability and probability suppression function incrementally. Next, an improved local outlier factor is reconstructed according to the local distribution of an object, and its reciprocal is regarded as the contribution degree of an object to cluster center. Then, the improved local outlier factor is integrated into FCM to alleviate the negative effect caused by outliers. Finally, experiments on synthetic and real-world datasets are provided to demonstrate the clustering performance and anti-noise ability of proposed method.},
  archive      = {J_IDA},
  author       = {She, Chunyan and Zeng, Shaohua and Wang, Qi and Wang, Shuai and Xu, Yidan},
  doi          = {10.3233/IDA-216266},
  journal      = {Intelligent Data Analysis},
  month        = {11},
  number       = {6},
  pages        = {1507-1521},
  shortjournal = {Intell. Data Anal.},
  title        = {Adaptive fuzzy C-means clustering integrated with local outlier factor},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DCE-IVI: Density-based clustering ensemble by selecting
internal validity index. <em>IDA</em>, <em>26</em>(6), 1487–1506. (<a
href="https://doi.org/10.3233/IDA-216105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As each clustering algorithm cannot efficiently partition datasets with arbitrary shapes, the thought of clustering ensemble is proposed to consistently integrate clustering results to obtain better division. Most of ensemble research employs a single algorithm with different parameters to clusteri ng. And this can be easily integrated, however it is hardly to divide complex datasets. Other available methods integrate different algorithms, it can divide datasets from different aspects, but fail to take outliers into account, which produces negative effects on the partition results. In order to solve these problems, we clustering datasets with three different density-based algorithms. The innovation of this paper is described as: (1) by setting dynamic thresholds, lower frequency evidence in the co-association matrix is gradually deleted to obtain multiple reconstructed matrices; (2) these reconstructed matrices are analyzed by hierarchical clustering to obtain basic clustering results; (3) an internal validity index is designed by the compactness within clusters and the correlation between clusters, which is used to select the final clustering result. By this innovation, the clustering effect is significantly improved. Finally, a series of experiments are designed, and the results verify the improvement and effectiveness of the proposed technique (DCE-IVI).},
  archive      = {J_IDA},
  author       = {Li, Qinlu and Du, Tao and Zhang, Rui and Zhou, Jin and Qu, Shouning},
  doi          = {10.3233/IDA-216105},
  journal      = {Intelligent Data Analysis},
  month        = {11},
  number       = {6},
  pages        = {1487-1506},
  shortjournal = {Intell. Data Anal.},
  title        = {DCE-IVI: Density-based clustering ensemble by selecting internal validity index},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Collusive anomalies detection based on collaborative markov
random field. <em>IDA</em>, <em>26</em>(6), 1469–1485. (<a
href="https://doi.org/10.3233/IDA-216287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormal collusive behavior, widely existing in various fields with concealment and synergy, is particularly harmful in user-generated online reviews and hard to detect by traditional methods. With the development of network science, this problem can be solved by analyzing structure features. As a graph-based anomaly detection method, the Markov random field (MRF)-based model has been widely used to identify the collusive anomalies and shown its effectiveness. However, existing methods are mostly unable to highlight the primary synergy relationship among nodes and consider much irrelevant information, which caused poor detectability. Therefore, this paper proposes a novel MRF-based method (ACEagle), considering node-level and community-level behavior features. Our method has several advantages: (1) based on the analysis of the nodes’ local structure, the community-level behavioral features are combined to calculate the nodes’ prior probability to close the ground truth, (2) it measured the behavior’s collaborative intensity between nodes by time and weight, constructing MRF by the synergic relationship exceeding the threshold to filter irrelevant structural information, (3) it operates in a completely unsupervised fashion requiring no labeled data, while still incorporating side information if available. Through experiments in user-reviewed datasets where abnormal collusive behavior is most typical, the results show that ACEagle is significantly outperforming state-of-the-art baselines in collusive anomalies detection.},
  archive      = {J_IDA},
  author       = {Shi, Haoran and Ji, Lixin and Liu, Shuxin and Wang, Kai and Hu, Xinxin},
  doi          = {10.3233/IDA-216287},
  journal      = {Intelligent Data Analysis},
  month        = {11},
  number       = {6},
  pages        = {1469-1485},
  shortjournal = {Intell. Data Anal.},
  title        = {Collusive anomalies detection based on collaborative markov random field},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised feature extraction from multivariate time
series for outlier detection. <em>IDA</em>, <em>26</em>(6), 1451–1467.
(<a href="https://doi.org/10.3233/IDA-216128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although various feature extraction algorithms have been developed for time series data, it is still challenging to obtain a flat vector representation with incorporating both of time-wise and variable-wise association between multiple time series. Here we develop an algorithm, called Unsupervised Feature Extraction using Kernel and Stacking (UFEKS), that constructs feature vector representation for multiple time series in an unsupervised manner. UFEKS constructs a kernel matrix for the set of subsequences from each time series and horizontally concatenates all matrices. Then we can treat each row as a feature vector representation of its corresponding subsequence of times series. We examine the effectiveness of the extracted features under the unsupervised outlier detection scenario using synthetic and real-world datasets, and show its superiority compared to well-established baselines.},
  archive      = {J_IDA},
  author       = {Matsue, Kiyotaka and Sugiyama, Mahito},
  doi          = {10.3233/IDA-216128},
  journal      = {Intelligent Data Analysis},
  month        = {11},
  number       = {6},
  pages        = {1451-1467},
  shortjournal = {Intell. Data Anal.},
  title        = {Unsupervised feature extraction from multivariate time series for outlier detection},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel density-based outlier detection method using key
attributes. <em>IDA</em>, <em>26</em>(6), 1431–1449. (<a
href="https://doi.org/10.3233/IDA-216257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection has attracted extensive attention in medical, financial, telecommunications and other fields. Although many related technologies have been proposed, most of them are faced with the problems of the neighborhood size of an object is difficult to determine and the distance in high-di mensional space is unreliable. To overcome these weaknesses, we propose a novel density-based outlier detection method that introduces the concept of Minimum the Sum of Edge Set and other related definitions in key attributes space. Based on the stability of Reverse Minimum the Sum of Edge Set, the proposed method can adaptively select the parameter representing the neighborhood size. In addition, some properties of the proposed local outlier factor are derived. Experiments on synthetic and real-world datasets demonstrate that our method is more effective than the existing outlier detection approaches.},
  archive      = {J_IDA},
  author       = {Qi, Zhuang and Chen, Xiaming},
  doi          = {10.3233/IDA-216257},
  journal      = {Intelligent Data Analysis},
  month        = {11},
  number       = {6},
  pages        = {1431-1449},
  shortjournal = {Intell. Data Anal.},
  title        = {A novel density-based outlier detection method using key attributes},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Editorial. <em>IDA</em>, <em>26</em>(6), 1427–1429. (<a
href="https://doi.org/10.3233/IDA-220005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IDA},
  doi          = {10.3233/IDA-220005},
  journal      = {Intelligent Data Analysis},
  month        = {11},
  number       = {6},
  pages        = {1427-1429},
  shortjournal = {Intell. Data Anal.},
  title        = {Editorial},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust intuitionistic fuzzy clustering with bias field
estimation for noisy image segmentation. <em>IDA</em>, <em>26</em>(5),
1403–1426. (<a href="https://doi.org/10.3233/IDA-216058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of intuitionistic fuzzy set has been found to be highly useful to handle vagueness in data. Based on intuitionistic fuzzy set theory, intuitionistic fuzzy clustering algorithms are proposed and play an important role in image segmentation. However, due to the influence of initialization and the presence of noise in the image, intuitionistic fuzzy clustering algorithm cannot acquire the satisfying performance when applied to segment images corrupted by noise. In order to solve above problems, a robust intuitionistic fuzzy clustering with bias field estimation (RIFCB) is proposed for noisy image segmentation in this paper. Firstly, a noise robust intuitionistic fuzzy set is constructed to represent the image by using the neighboring information of pixels. Then, initial cluster centers in RIFCB are adaptively determined by utilizing the frequency statistics of gray level in the image. In addition, in order to offset the information loss of the image when constructing the intuitionistic fuzzy set of the image, a new objective function incorporating a bias field is designed in RIFCB. Based on the new initialization strategy, the intuitionistic fuzzy set representation, and the incorporation of bias field, the proposed method preserves the image details and is insensitive to noise. Experimental results on some Berkeley images show that the proposed method achieves satisfactory segmentation results on images corrupted by different kinds of noise in contrast to conventional fuzzy clustering algorithms.},
  archive      = {J_IDA},
  author       = {Zhao, Feng and Hao, Hao and Liu, Hanqiang},
  doi          = {10.3233/IDA-216058},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1403-1426},
  shortjournal = {Intell. Data Anal.},
  title        = {Robust intuitionistic fuzzy clustering with bias field estimation for noisy image segmentation},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel approach to energy-aware resource management: Toward
green NOMA heterogeneous networks. <em>IDA</em>, <em>26</em>(5),
1379–1402. (<a href="https://doi.org/10.3233/IDA-215929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dense deployment of small cell networks is a key feature of next generation mobile networks aimed at providing the necessary capacity increase. In order to reach an acceptable performance in such ultra-dense networks, real-time resource management is of great importance. Therefore, self-optimiz ation networking is proposed as the only viable solution to increase the networks’ utility. This paper proposed a self-optimizing model to enhance network performance and guarantee the users’ QoS requirements by considering limited resources and using effective user association, carrier scheduling and handover optimization algorithms. In order to maximize the network performance, we applied the smart backhauling technique in order to analyze the signaling to increase the validity of the decision making process. Based on the semantic information extracted from the access layer, the network decision-making center is able to adjust the network parameters and resource allocation effectively. The goal function is defined as maximizing the total energy efficiency by considering the transmission power, energy harvesting capability and the user QoS constraints so that the idle small cells are considered turned off temporarily to boost the power efficiency. Although the optimization problem is non-convex, a quadratic mixed-integer function is solved to obtain a global optimal solution. Since the actual implementation of the real-time algorithm has high computational complexity, two algorithms with different complexity levels are proposed. These algorithms use the carrier matching feature and optimal transmission power for problem-solving. The simulation results prove that, despite the increased computational complexity, effective resource allocation and optimal HO relations made the proposed approach capable to increase performance indices such as network throughput by up to 30%.},
  archive      = {J_IDA},
  author       = {Nabipour, Mohammad and Momen, Amir Reza},
  doi          = {10.3233/IDA-215929},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1379-1402},
  shortjournal = {Intell. Data Anal.},
  title        = {A novel approach to energy-aware resource management: Toward green NOMA heterogeneous networks},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generate qualified adversarial attacks and foster enhanced
models based on generative adversarial networks. <em>IDA</em>,
<em>26</em>(5), 1359–1377. (<a
href="https://doi.org/10.3233/IDA-216134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cybersecurity, intrusion detection systems (IDSes) are of vital importance, allowing different companies and their departments to identify malicious attacks from magnanimous network traffic; however, the effectiveness and stability of these artificial intelligence-based systems are challenged wh en coping with adversarial attacks. This work explores a creative framework based on a generative adversarial network (GAN) with a series of training algorithms that aims to generate instances of adversarial attacks and utilize them to help establish a new IDS based on a neural network that can replace the old IDS without knowledge of any of its parameters. Furthermore, to verify the quality of the generated attacks, a transfer mechanism is proposed for calculating the Frechet inception distance (FID). Experiments show that based on the original CICIDS2017 dataset, the proposed framework can generate four types of adversarial attacks (DDoS, DoS, Bruteforce, and Infiltration), which precipitate four types of classifiers (Decision Tree, Random Forest, Adaboost, and Deep Neural Network), set as black-box old IDSes, with low detection rates; additionally, the IDSes that the proposed framework newly establish have an average detection rate of 98% in coping with both generated adversarial and original attacks.},
  archive      = {J_IDA},
  author       = {He, Junpeng and Luo, Lei and Xiao, Kun and Fang, Xiyu and Li, Yun},
  doi          = {10.3233/IDA-216134},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1359-1377},
  shortjournal = {Intell. Data Anal.},
  title        = {Generate qualified adversarial attacks and foster enhanced models based on generative adversarial networks},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluating semantic representations for extended association
rules. <em>IDA</em>, <em>26</em>(5), 1341–1357. (<a
href="https://doi.org/10.3233/IDA-216255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we evaluate the impact of changing the semantic text representation on the performance of the AR-SVS (extended association rules in semantic vector spaces) algorithm on the sentiment polarity classification task on a paper reviews dataset. To do this, we use natural language processin g techniques in conjunction with machine learning classifiers. In particular, we report the classification performance using the F1 and accuracy metrics. The semantic representations that we used in our evaluation were chosen based on a systematic literature review, leading to an evaluation of AR-SVS with FastText, GloVe, and LDA2vec representations, with word2vec providing the baseline performance. The results of the experiments indicate that the choice of semantic text representation does not have major effects on the performance of AR-SVS for polarity classification. Furthermore, the results resemble those obtained in the original AR-SVS article, both in quantitative and qualitative terms. Thus, while direct improvements in classification performance were not found, we discuss other aspects and advantages of using different semantic representations.},
  archive      = {J_IDA},
  author       = {Gutiérrez Espinoza, Luis and Keith Norambuena, Brian},
  doi          = {10.3233/IDA-216255},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1341-1357},
  shortjournal = {Intell. Data Anal.},
  title        = {Evaluating semantic representations for extended association rules},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Influence maximization based on network representation
learning in social network. <em>IDA</em>, <em>26</em>(5), 1321–1340. (<a
href="https://doi.org/10.3233/IDA-216149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence Maximization (IM), an NP-hard central issue for social network research, aims to recognize the influential nodes in a network so that the message can spread faster and more effectively. A large number of existing studies mainly focus on the heuristic methods, which generally lead to sub-o ptimal solutions and suffer time-consuming and inapplicability for large-scale networks. Furthermore, the present community-aware random walk to analyze IM using network representation learning considers only the node’s influence or network community structures. No research has been found that surveyed both of them. Hence, the present study is designed to solve the IM problem by introducing a novel influence network embedding (NINE) approach and a novel influence maximization algorithm, namely NineIM, based on network representation learning. First, a mechanism that can capture the diffusion behavior proximity between network nodes is constructed. Second, we consider a more realistic social behavior assumption. The probability of information dissemination between network nodes (users) is different from other random walk based network representation learning. Third, the node influence is used to define the rules of random walk and then get the embedding representation of a social network. Experiments on four real-world networks indicate that our proposed NINE method outperforms four state-of-the-art network embedding baselines. Finally, the superiority of the proposed NineIM algorithm is reported by comparing four traditional IM algorithms. The code is available at https://github.com/baiyazi/NineIM.},
  archive      = {J_IDA},
  author       = {Wang, Zhibin and Chen, Xiaoliang and Li, Xianyong and Du, Yajun and Lan, Xiang},
  doi          = {10.3233/IDA-216149},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1321-1340},
  shortjournal = {Intell. Data Anal.},
  title        = {Influence maximization based on network representation learning in social network},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IMLBoost for intelligent diagnosis with imbalanced medical
records. <em>IDA</em>, <em>26</em>(5), 1303–1320. (<a
href="https://doi.org/10.3233/IDA-216050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance of medical records is a critical challenge for disease classification in intelligent diagnosis. Existing machine learning algorithms usually assign equal weights to all classes, which may reduce classification accuracy of imbalanced records. In this paper, a new Imbalance Lessened B oosting (IMLBoost) algorithm is proposed to better classify imbalanced medical records, highlighting the contribution of samples in minor classes as well as hard and boundary samples. A tailored Cost-Fitting Loss (CFL) function is proposed to assign befitting costs to these critical samples. The first and second derivations of the CFL are then derived and embedded into the classical XGBoost framework. In addition, some feature analysis skills are utilized to further improve performance of the IMLBoost, which also can speed up the model training. Experimental results on five UCI imbalanced medical datasets have demonstrated the effectiveness of the proposed algorithm. Compared with other existing classification methods, IMLBoost has improved the classification performance in terms of F1-score, G-mean and AUC.},
  archive      = {J_IDA},
  author       = {Liu, Tongtong and Chi, Xiaofan and Du, Yukun and Yang, Huan and Xi, Yongming and Guo, Jianwei},
  doi          = {10.3233/IDA-216050},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1303-1320},
  shortjournal = {Intell. Data Anal.},
  title        = {IMLBoost for intelligent diagnosis with imbalanced medical records},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). From undirected dependence to directed causality: A novel
bayesian learning approach. <em>IDA</em>, <em>26</em>(5), 1275–1302. (<a
href="https://doi.org/10.3233/IDA-216114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian network (BN) is one of the most powerful probabilistic models in the field of uncertain knowledge representation and reasoning. During the past decade, numerous approaches have been proposed to build directed acyclic graph (DAG) as the structural specification of BN. However, for most Baye sian network classifiers (BNCs) the directed edges in DAG substantially represent assertions of conditional independence rather than causal relationships although the learned joint probability distributions may fit data well, thus they cannot be applied to causal reasoning. In this paper, conditional entropy is introduced to measure causal uncertainty due to its asymmetry characteristic, and heuristic search strategy is applied to build Bayesian causal tree (BCT) by identifying significant causalities. The resulting highly scalable topology can represent causal relationship in terms of causal science, and corresponding joint probability can fit training data in terms of data science. Then ensemble learning strategy is applied to build Bayesian causal forest (BCF) with a set of BCTs, each taking different attribute as the root node to represent root cause for causality analysis. Extensive experiments performed on 32 public datasets from the UCI machine learning repository show that BCF achieves outstanding classification performance compared to state-of-the-art single-model BNCs (e.g., CFWNB), ensemble BNCs (e.g., WATAN, IWAODE, WAODE-MI and TAODE) and non-Bayesian learners (e.g., SVM, k-NN, LR).},
  archive      = {J_IDA},
  author       = {Wang, Limin and Fan, Hangqi and Kong, He},
  doi          = {10.3233/IDA-216114},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1275-1302},
  shortjournal = {Intell. Data Anal.},
  title        = {From undirected dependence to directed causality: A novel bayesian learning approach},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling the combined influence of complexity and quality in
supervised learning. <em>IDA</em>, <em>26</em>(5), 1247–1274. (<a
href="https://doi.org/10.3233/IDA-215962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data classification is a data mining task that consists of an algorithm adjusted by a training dataset that is used to predict an object’s class (unclassified) on analysis. A significant part of the performance of the classification algorithm depends on the dataset’s complexity and quality. Data Co mplexity involves the investigation of the effects of dimensionality, the overlap of descriptive attributes, and the classes’ separability. Data Quality focuses on the aspects such as noise data (outlier) and missing values. The factors Data Complexity and Data Quality are fundamental for the performance of classification. However, the literature has very few studies on the relationship between these factors and to highlight their significance. This paper applies Structural Equation Modeling and the Partial Least Squares Structural Equation Modeling (PLS-SEM) algorithm and, in an innovative manner, associates Data Complexity and Data Quality contributions to Classification Quality. Experimental analysis with 178 datasets obtained from the OpenML repository showed that the control of complexity improves the classification results more than data quality does. Additionally paper also presents a visual tool of datasets analysis about the classification performance perspective in the dimensions proposed to represent the structural model.},
  archive      = {J_IDA},
  author       = {de Ávila Mendes, Renê and da Silva, Leandro Augusto},
  doi          = {10.3233/IDA-215962},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1247-1274},
  shortjournal = {Intell. Data Anal.},
  title        = {Modeling the combined influence of complexity and quality in supervised learning},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LAMB: A novel algorithm of label collaboration based
multi-label learning. <em>IDA</em>, <em>26</em>(5), 1229–1245. (<a
href="https://doi.org/10.3233/IDA-215946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploiting label correlation is crucially important in multi-label learning, where each instance is associated with multiple labels simultaneously. Multi-label learning is more complex than single-label learning for that the labels tend to be correlated. Traditional multi-label learning algorithms learn independent classifiers for each label and employ ranking or threshold on the classification results. Most existing methods take label correlation as prior knowledge, which have worked well, but they failed to make full use of label dependency. As a result, the real relationship among labels may not be correctly characterized and the final prediction is not explicitly correlated. To address these problems, we propose a novel high-order multi-label learning algorithm of Label collAboration based Multi-laBel learning (LAMB). With regard to each label, LAMB utilizes collaboration between its own prediction and the prediction of other labels. Extensive experiments on various datasets demonstrate that our proposed LAMB algorithm achieves superior performance over existing state-of-the-art algorithms. In addition, one real-world dataset of channelrhodopsins chimeras is assessed, which would be of great value as pre-screen for membrane proteins function.},
  archive      = {J_IDA},
  author       = {Zhang, Yi and Zhang, Zhecheng and Chen, Mingyuan and Lu, Hengyang and Zhang, Lei and Wang, Chongjun},
  doi          = {10.3233/IDA-215946},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1229-1245},
  shortjournal = {Intell. Data Anal.},
  title        = {LAMB: A novel algorithm of label collaboration based multi-label learning},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multiple hierarchical clustering ensemble algorithm to
recognize clusters arbitrarily shaped. <em>IDA</em>, <em>26</em>(5),
1211–1228. (<a href="https://doi.org/10.3233/IDA-216112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a research hotspot in ensemble learning, clustering ensemble obtains robust and highly accurate algorithms by integrating multiple basic clustering algorithms. Most of the existing clustering ensemble algorithms take the linear clustering algorithms as the base clusterings. As a typical unsuperv ised learning technique, clustering algorithms have difficulties properly defining the accuracy of the findings, making it difficult to significantly enhance the performance of the final algorithm. AGglomerative NESting method is used to build base clusters in this article, and an integration strategy for integrating multiple AGglomerative NESting clusterings is proposed. The algorithm has three main steps: evaluating the credibility of labels, producing multiple base clusters, and constructing the relation among clusters. The proposed algorithm builds on the original advantages of AGglomerative NESting and further compensates for the inability to identify arbitrarily shaped clusters. It can establish the proposed algorithm’s superiority in terms of clustering performance by comparing the proposed algorithm’s clustering performance to that of existing clustering algorithms on different datasets.},
  archive      = {J_IDA},
  author       = {Sun, Yuqin and Wang, Songlei and Huang, Dongmei and Sun, Yuan and Hu, Anduo and Sun, Jinzhong},
  doi          = {10.3233/IDA-216112},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1211-1228},
  shortjournal = {Intell. Data Anal.},
  title        = {A multiple hierarchical clustering ensemble algorithm to recognize clusters arbitrarily shaped},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An approach for unsupervised contextual anomaly detection
and characterization. <em>IDA</em>, <em>26</em>(5), 1185–1209. (<a
href="https://doi.org/10.3233/IDA-215906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection has been widely explored and applied to different real-world problems. However, outlier characterization that consists in finding and understanding the outlying aspects of the anomalous observations is still challenging. In this paper, we present a new approach to simultaneously d etect subspace outliers and characterize them. We introduce the Dimension-wise Local Outlier Factor (DLOF) function to quantify the degree of outlierness of the data points in each feature dimension. The obtained DLOFs are used in an outlier ensemble so as to detect and rank the anomalous points. Subsequently, the same DLOFs are analyzed in order to characterize the detected outliers with their relevant subspace and their same-type anomalies. Experiments on various datasets show the efficacy of our method. Indeed, we demonstrate through an experimental evaluation that the proposed approach is competitive compared to the existing solutions in terms of both detection and characterization accuracy.},
  archive      = {J_IDA},
  author       = {Boukela, Lynda and Zhang, Gongxuan and Yacoub, Meziane and Bouzefrane, Samia and Baba Ahmadi, Sajjad Bagheri},
  doi          = {10.3233/IDA-215906},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1185-1209},
  shortjournal = {Intell. Data Anal.},
  title        = {An approach for unsupervised contextual anomaly detection and characterization},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improvement of FDR for edge detection by applying EM
method. <em>IDA</em>, <em>26</em>(5), 1161–1184. (<a
href="https://doi.org/10.3233/IDA-216233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In building a graphical model, accuracy in edge detection for the model structure is crucial for the quality of the model. We explored methods for improvement of false discovery rate(FDR) by devising an estimation procedure which is more data sensitive under some condition. The estimation is made b y applying an EM method where the parameters include the density function under the null hypothesis (no edge) and the location parameters of the density functions under the alternative hypothesis (presence of edge). Our method is compared favorably with a most popular FDR tool in numerical experiments. We applied our method for analysing gene data of 800 genes and built a network of vector autoregressive model for the data.},
  archive      = {J_IDA},
  author       = {Kim, Eun-Gyoung and Kim, Sung-Ho},
  doi          = {10.3233/IDA-216233},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1161-1184},
  shortjournal = {Intell. Data Anal.},
  title        = {An improvement of FDR for edge detection by applying EM method},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of informational and probabilistic
independence by adaptive thresholding. <em>IDA</em>, <em>26</em>(5),
1139–1160. (<a href="https://doi.org/10.3233/IDA-215942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The independence assumptions help Bayesian network classifier (BNC), e.g., Naive Bayes (NB), reduce structure complexity and perform surprisingly well in many real-world applications. Semi-naive Bayesian techniques seek to improve the classification performance by relaxing the attribute independenc e assumption. However, the study of dependence rather than independence has received more attention during the past decade and the validity of independence assumptions needs to be further explored. In this paper, a novel learning technique, called Adaptive Independence Thresholding (AIT), is proposed to automatically identify the informational independence and probabilistic independence. AIT can respectively tune the network topologies of BNC learned from training data and testing instance under the framework of target learning. Zero-one loss, bias, variance and conditional log likelihood are introduced to compare the classification performance in the experimental study. The extensive experimental results on a collection of 36 benchmark datasets from the UCI machine learning repository show that AIT is more effective than other learning techniques (such as structure extension, attribute weighting) and helps make the final BNCs achieve remarkable classification improvements.},
  archive      = {J_IDA},
  author       = {Li, Kuo and Wang, Aimin and Wang, Limin and Fan, Hangqi and Zhang, Shuai},
  doi          = {10.3233/IDA-215942},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1139-1160},
  shortjournal = {Intell. Data Anal.},
  title        = {Identification of informational and probabilistic independence by adaptive thresholding},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Label noise detection under the noise at random model with
ensemble filters. <em>IDA</em>, <em>26</em>(5), 1119–1138. (<a
href="https://doi.org/10.3233/IDA-215980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label noise detection has been widely studied in Machine Learning because of its importance in improving training data quality. Satisfactory noise detection has been achieved by adopting ensembles of classifiers. In this approach, an instance is assigned as mislabeled if a high proportion of member s in the pool misclassifies it. Previous authors have empirically evaluated this approach; nevertheless, they mostly assumed that label noise is generated completely at random in a dataset. This is a strong assumption since other types of label noise are feasible in practice and can influence noise detection results. This work investigates the performance of ensemble noise detection under two different noise models: the Noisy at Random (NAR), in which the probability of label noise depends on the instance class, in comparison to the Noisy Completely at Random model, in which the probability of label noise is entirely independent. In this setting, we investigate the effect of class distribution on noise detection performance since it changes the total noise level observed in a dataset under the NAR assumption. Further, an evaluation of the ensemble vote threshold is conducted to contrast with the most common approaches in the literature. In many performed experiments, choosing a noise generation model over another can lead to different results when considering aspects such as class imbalance and noise level ratio among different classes.},
  archive      = {J_IDA},
  author       = {Moura, Kecia G. and Prudêncio, Ricardo B.C. and Cavalcanti, George D.C.},
  doi          = {10.3233/IDA-215980},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1119-1138},
  shortjournal = {Intell. Data Anal.},
  title        = {Label noise detection under the noise at random model with ensemble filters},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Editorial. <em>IDA</em>, <em>26</em>(5), 1115–1117. (<a
href="https://doi.org/10.3233/IDA-220004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IDA},
  doi          = {10.3233/IDA-220004},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1115-1117},
  shortjournal = {Intell. Data Anal.},
  title        = {Editorial},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diagnosis of liver disease by computer- assisted imaging
techniques: A literature review. <em>IDA</em>, <em>26</em>(4),
1097–1114. (<a href="https://doi.org/10.3233/IDA-216379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosis of liver disease using computer-aided detection (CAD) systems is one of the most efficient and cost-effective methods of medical image diagnosis. Accurate disease detection by using ultrasound images or other medical imaging modalities depends on the physician’s or doctor’s experience and skill. CAD systems have a critical role in helping experts make accurate and right-sized assessments. There are different types of CAD systems for diagnosing different diseases, and one of the applications is in liver disease diagnosis and detection by using intelligent algorithms to detect any abnormalities. Machine learning and deep learning algorithms and models play also a big role in this area. In this article, we tried to review the techniques which are utilized in different stages of CAD systems and pursue the methods used in preprocessing, extracting, and selecting features and classification. Also, different techniques are used to segment and analyze the liver ultrasound medical images, which is still a challenging approach to how to use these techniques and their technical and clinical effectiveness as a global approach.},
  archive      = {J_IDA},
  author       = {Kalejahi, Behnam Kiani and Meshgini, Saeed and Danishvar, Sebelan and Khorram, Sara},
  doi          = {10.3233/IDA-216379},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {1097-1114},
  shortjournal = {Intell. Data Anal.},
  title        = {Diagnosis of liver disease by computer- assisted imaging techniques: A literature review},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ITeM: Independent temporal motifs to summarize and compare
temporal networks. <em>IDA</em>, <em>26</em>(4), 1071–1096. (<a
href="https://doi.org/10.3233/IDA-205698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networks are a fundamental and flexible way of representing various complex systems. Many domains such as communication, citation, procurement, biology, social media, and transportation can be modeled as a set of entities and their relationships. Temporal networks are a specialization of general ne tworks where every relationship occurs at a discrete time. The temporal evolution of such networks is as important to understand as the structure of the entities and relationships. We present the Independent Temporal Motif (ITeM) to characterize temporal graphs from different domains. ITeMs can be used to model the structure and the evolution of the graph. In contrast to existing work, ITeMs are edge-disjoint directed motifs that measure the temporal evolution of ordered edges within the motif. For a given temporal graph, we produce a feature vector of ITeM frequencies and the time it takes to form the ITeM instances. We apply this distribution to measure the similarity of temporal graphs. We show that ITeM has higher accuracy than other motif frequency-based approaches. We define various ITeM-based metrics that reveal salient properties of a temporal network. We also present importance sampling as a method to efficiently estimate the ITeM counts. We present a distributed implementation of the ITeM discovery algorithm using Apache Spark and GraphFrame. We evaluate our approach on both synthetic and real temporal networks.},
  archive      = {J_IDA},
  author       = {Purohit, Sumit and Chin, George and Holder, Lawrence B.},
  doi          = {10.3233/IDA-205698},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {1071-1096},
  shortjournal = {Intell. Data Anal.},
  title        = {ITeM: Independent temporal motifs to summarize and compare temporal networks},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Wear-free gesture recognition based on residual features of
RFID signals. <em>IDA</em>, <em>26</em>(4), 1051–1070. (<a
href="https://doi.org/10.3233/IDA-215972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, RFID is frequently used in identification and localization. In this paper, an extension application of RFID is designed to recognize gestures. Currently, gesture recognition is mainly used for feature extraction through wearable sensors and video cameras, which have shortcomings such as inconvenience to carry and interference with obstacles. This paper proposes a gesture recognition system based on radio frequency identification (RFID), where users do not need to wear devices. In the proposed model, the interference information generated by the gesture action on the tag signal is used as the fingerprint feature of the action. To obtain satisfactory recognition, the signal diversity is first increased through the tag array. Then, the RSSI and phase signal are normalized to eliminate offset and noise before training. Furthermore, a residual neural network (ResNet) is carefully built as a gesture classification model. The experimental results show that the recognition system achieves more recognition accuracy than existing methods, and the average gesture recognition accuracy reaches 95.5%.},
  archive      = {J_IDA},
  author       = {Zhao, Chuanxin and Xiong, Fei and Wang, Taochun and Wang, Yang and Chen, Fulong and Xu, Zhiqiang},
  doi          = {10.3233/IDA-215972},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {1051-1070},
  shortjournal = {Intell. Data Anal.},
  title        = {Wear-free gesture recognition based on residual features of RFID signals},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid approach for noise reduction-based optimal
classifier using genetic algorithm: A case study in plant disease
prediction. <em>IDA</em>, <em>26</em>(4), 1023–1049. (<a
href="https://doi.org/10.3233/IDA-216011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plant diseases can cause significant losses to agricultural productivity; therefore, their early prediction is much needed. So far, many machine learning-based plant disease prediction models have been recommended, but these models face a problem of noisy class label dataset that degrades the perfo rmance. Noisy class label dataset results from the improper assignment of positive class labels into negative class data samples or vice versa. Hence, a precise and noise-free plant disease model is required for a better prediction. The current study proposes noise reduction-based hybridized classifiers for plant disease prediction. One tomato and four soybean disease datasets have been selected to conduct the proposed research. The Adaptive Sampling-based Class Label Noise Reduction (AS-CLNR) method has been used along with the Support Vector Machine (SVM) approach for noise reduction. The noise-minimized datasets have been fed into the Extreme Learning Machine (ELM), Decision Tree (DT), and Random Forest (RF) classifiers whose parameters are optimized using Genetic Algorithm (GA) for developing plant disease prediction models. The performances of all these models viz. Hybrid SVM-GA-ELM, Hybrid SVM-GA-DT, and Hybrid SVM-GA-RF have been evaluated using Accuracy, Area under ROC Curve, and F1-Score metrics. Further, these classifiers have been ranked using the statistical Friedman Test in which the Hybrid SVM-GA-RF classifier performed the best. Lastly, the Nemenyi test has also been performed to find out if significant differences exist between various classifiers or not. It was found that 33.33% of the total pairs of hybrid classifiers show a remarkably different performance from one another.},
  archive      = {J_IDA},
  author       = {Bhatia, Anshul and Chug, Anuradha and Singh, Amit Prakash and Singh, Dinesh},
  doi          = {10.3233/IDA-216011},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {1023-1049},
  shortjournal = {Intell. Data Anal.},
  title        = {A hybrid approach for noise reduction-based optimal classifier using genetic algorithm: A case study in plant disease prediction},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel double-layer prediction model construction and
empirical analysis for enterprise credit assessment. <em>IDA</em>,
<em>26</em>(4), 1007–1022. (<a
href="https://doi.org/10.3233/IDA-215943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit is a part of external image of enterprises, and it directly affects interests of enterprises. Nowadays, most of researches on predictions of enterprises credit use a single algorithm model or optimize a single model to predict an enterprises credit score. The accuracy of each model is differ ent, and the generalization ability is generally weak. In order to improve generalization ability of models and accuracy of prediction results, a parallel double-layer prediction model is proposed in this paper. The model is based on Stacking and Bagging methods, which can improve generalization ability with high accuracy. Through experiments, we compare three single algorithm models, four integrated learning models with other combination strategies and parallel double-layer prediction model. Average value of four evaluation indexes are increased by 4.2349%, 63.1464%, 34.11837%, 1.26104%, 15.7862%, 10.1457% and 25.6310% respectively. The results show that the parallel double-layer prediction model is accurate and feasible.},
  archive      = {J_IDA},
  author       = {Li, Zhanli and Liu, Linchao and Zhu, Li and Deng, Fan and Zhang, Yun and Zhang, Yu},
  doi          = {10.3233/IDA-215943},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {1007-1022},
  shortjournal = {Intell. Data Anal.},
  title        = {Parallel double-layer prediction model construction and empirical analysis for enterprise credit assessment},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mining multiplex interaction relationships from usage
records in social networks. <em>IDA</em>, <em>26</em>(4), 993–1005. (<a
href="https://doi.org/10.3233/IDA-184107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks have become increasingly popular and are commonly used in everyday life. They also become the most convenient places to send information or receive advertisements. The multiplex network is an important study topic in social networks, in which many features could be appropriately rep resented in different layers. In this paper, we propose an approach to find the multiplex interaction relationships based on the action records of users on social networks. The multiplex user interactions are found and divided into three levels: high, normal and low. They are then used to check the friend and the follower relations such that users can find which friends or followers are active or not. In the experiments, the parameters are chosen based on Dunbar’s number, which is the number of social relationships that humans can have with high confidence. The results show the proposed approach is effective in helping users know the truly close friend relationships on a social network.},
  archive      = {J_IDA},
  author       = {Hong, Tzung-Pei and Kao, Chi-Cheng and Chen, Siang-Wei and Chen, Chun-Hao},
  doi          = {10.3233/IDA-184107},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {993-1005},
  shortjournal = {Intell. Data Anal.},
  title        = {Mining multiplex interaction relationships from usage records in social networks},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view hybrid recommendation model based on deep
learning. <em>IDA</em>, <em>26</em>(4), 977–992. (<a
href="https://doi.org/10.3233/IDA-215988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of technologies such as cloud computing, big data, and the Internet of Things, the scale of data continues to grow. The recommendation system has become one of the important intelligent software to help users make decisions. The recommendation model based on user rating d ata is widely studied and applied, but the data sparsity problem and the cold start problem seriously affect the recommendation quality. In this paper, Multi-view Hybrid Recommendation Model (MHRM) based on deep learning is proposed. First, we use WLDA (an improved Latent Dirichlet Allocation method) to extract the vector representation of user review text, and then apply LSTM to contextual semantic level user review sentiment analysis. At the same time, the emotion fusion method based on user score embedding is proposed. The problems such as deviations between the user score and actual interest preference, and unbalanced distribution of the score level are solved. This paper has been tested on Amazon product data and compared with various classic recommendation algorithms, using Mean Absolute Error (MAE), hit rate and standardized discount cumulative return for performance evaluation. The experimental results show that the prediction of the MHRM proposed in this paper on the 7 recommendation data and the TopN recommendation index have been significantly improved.},
  archive      = {J_IDA},
  author       = {Qiu, Gang and Song, Changjun and Jiang, Liping and Guo, Yanli},
  doi          = {10.3233/IDA-215988},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {977-992},
  shortjournal = {Intell. Data Anal.},
  title        = {Multi-view hybrid recommendation model based on deep learning},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge graph embedding with entity attributes using
hypergraph neural networks. <em>IDA</em>, <em>26</em>(4), 959–975. (<a
href="https://doi.org/10.3233/IDA-216007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding is aimed at capturing the semantic information of entities by modeling the structural information between entities. For long-tail entities which lack sufficient structural information, general knowledge graph embedding models often show relatively low performance in link p rediction. In order to solve such problems, this paper proposes a general knowledge graph embedding framework to learn the structural information as well as the attribute information of the entities simultaneously. Under this framework, a H-AKRL (Hypergraph Neural Networks based Attribute-embodied Knowledge Representation Learning) model is put forward, where the hypergraph neural network is used to model the correlation between entities and attributes at a higher level. The complementary relationship between attribute information and structural information is taken full advantage of, enabling H-AKRL to finally achieve the goal of improving link prediction performance. Experiments on multiple real-world data sets show that the H-AKRL model has significantly improved the link prediction performance, especially in the embeddings of long tail entities.},
  archive      = {J_IDA},
  author       = {Xu, You-Wei and Zhang, Hong-Jun and Cheng, Kai and Liao, Xiang-Lin and Zhang, Zi-Xuan and Li, Yun-Bo},
  doi          = {10.3233/IDA-216007},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {959-975},
  shortjournal = {Intell. Data Anal.},
  title        = {Knowledge graph embedding with entity attributes using hypergraph neural networks},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Shape classification based on solid angles by a support
vector machine. <em>IDA</em>, <em>26</em>(4), 933–957. (<a
href="https://doi.org/10.3233/IDA-215992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of computer-aided design (CAD) and three-dimensional (3D) modeling, constructive solid geometry (CSG) representations based on primitive 3D shapes and boundary representations (B-Rep) based on geometry and topology are widely used to represent complex shapes. Therefore, it is important to recognize primitive shapes such as cubes, cones, and cylinders and to accurately judge and classify the deformation of primitive shapes. For this purpose, various techniques have been studied, such as a vector-based determination method, a determination method using multiple images from various angles, and a determination method based on positional relationships between points. However, because large datasets are required to classify these shapes and it is difficult to respond to changes in shape due to rotation, the resulting recognition accuracy is not always high. In this work, we propose a method based on solid angles, which do not depend on the positional relationship of vectors, viewpoints, or changes due to rotation, as feature quantities. We demonstrate the effectiveness of primitive 3D figures using features based on solid angles. In addition, we show that the presence or absence of deformation can be determined when part of a primitive 3D figure is deformed.},
  archive      = {J_IDA},
  author       = {Kodama, Satoshi},
  doi          = {10.3233/IDA-215992},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {933-957},
  shortjournal = {Intell. Data Anal.},
  title        = {Shape classification based on solid angles by a support vector machine},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mining spatial high-average utility co-location patterns
from spatial data sets. <em>IDA</em>, <em>26</em>(4), 911–931. (<a
href="https://doi.org/10.3233/IDA-215848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spatial co-location pattern refers to a subset of non-empty spatial features whose instances are frequently located together in a spatial neighborhood. Traditional spatial co-location pattern mining is mainly based on the frequency of the pattern, and there is no difference in the importance or value of each spatial feature within the pattern. Although the spatial high utility co-location pattern mining solves this problem, it does not consider the effect of pattern length on the utility. Generally, the utility of the pattern also increases as the length of the pattern increases. Therefore, the evaluation criterion of the high utility co-location mining is unfair to the short patterns. In order to solve this problem, this paper first considers the utility and length of the co-location pattern comprehensively, and proposes a more reasonable High-Average Utility Co-location Pattern (HAUCP). Then, we propose a basic algorithm based on the extended average utility ratio of co-location patterns to mining all HAUCPs, which solves the problem that the average utility ratio of patterns does not satisfy the downward closure property. Next, an improved algorithm based on the local extended average utility ratio is developed which effectively reduces the search space of the basic algorithm and improves the mining efficiency. Finally, the practicability and robustness of the proposed method are verified based on real and synthetic data sets. Experimental results show that the proposed algorithm can effectively and efficiently find the HAUCPs from spatial data sets.},
  archive      = {J_IDA},
  author       = {Li, Jinhong and Wang, Lizhen and Chen, Hongmei and Sun, Zhengbao},
  doi          = {10.3233/IDA-215848},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {911-931},
  shortjournal = {Intell. Data Anal.},
  title        = {Mining spatial high-average utility co-location patterns from spatial data sets},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient isomorphic CNN-based prediction and decision
framework for financial time series. <em>IDA</em>, <em>26</em>(4),
893–909. (<a href="https://doi.org/10.3233/IDA-216142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial time series prediction and trading decision-making are priorities of computational intelligence for researchers in academia and the finance industry due to their broad application areas and substantial impact. However, these methods remain challenging because they retain various complex s tatistical properties, and the mechanism behind the processes is unknown to a large extent. A significant number of machine learning-based methods are proposed and demonstrate impressive results, especially deep learning-based models. Nevertheless, due to the high complexity of massive, nonlinear, and nonindependent data and the difficulties and time consumption of complicated training models of deep learning, the performance of online trading decisions is still inadequate for practical application. This paper proposes the Integrated Framework of Forecasting Based Online Trading Strategy (IFF-BOTS) to satisfy better prediction performance and dynamic decisions for real-world online trading systems. Our method adopts a novel isomorphic convolutional neural network (CNN)-based forecaster-classifier-executor architecture to exploit CNN-based price and trend integrated prediction and direct-reinforcement-learning-based trading decision-making. IFF-BOTS can also achieve better real-time performance for online trading. We empirically compare the proposed approach with state-of-the-art prediction and trading methods on real-world S&amp;P and DJI datasets. The results show that the IFF-BOTS outperforms its competitors in predicting metrics, trading profits, and real-time performance.},
  archive      = {J_IDA},
  author       = {Liu, Zhongming and Luo, Hang and Chen, Peng and Xia, Qibin and Gan, Zhihao and Shan, Wenyu},
  doi          = {10.3233/IDA-216142},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {893-909},
  shortjournal = {Intell. Data Anal.},
  title        = {An efficient isomorphic CNN-based prediction and decision framework for financial time series},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DAMGNN: Deep adaptive multi-channel graph neural networks.
<em>IDA</em>, <em>26</em>(4), 873–891. (<a
href="https://doi.org/10.3233/IDA-215958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, several studies have reported that Graph Convolutional Networks (GCN) exhibit defects in integrating node features and topological structures in graphs. Although the proposal of AMGCN compensates for the drawbacks of GCN to some extent, it still cannot solve GCN’s insufficient fusion abil ities fundamentally. Thus it is essential to find a network component with stronger fusion abilities to substitute GCN. Meanwhile, a Deep Adaptive Graph Neural Network (DAGNN) proposed by Liu et al. can adaptively aggregate information from different hops of neighborhoods, which remarkably benefits its fusion abilities. To replace GCN with DAGNN network in AMGCN model and further strengthen the fusion abilities of DAGNN network itself, we make further improvements based on DAGNN model to obtain DAGNN variant. Moreover, experimentally the fusion abilities of the DAGNN variant are verified to be far stronger than GCN. And then build on that, we propose a Deep Adaptive Multi-channel Graph Neural Network (DAMGNN). The results of lots of comparative experiments on multiple benchmark datasets show that the DAMGNN model can extract relevant information from node features and topological structures to the maximum extent for fusion, thus significantly improving the accuracy of node classification.},
  archive      = {J_IDA},
  author       = {Li, Yuqiang and Chen, Wei and Liao, Jing and Liu, Chun},
  doi          = {10.3233/IDA-215958},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {873-891},
  shortjournal = {Intell. Data Anal.},
  title        = {DAMGNN: Deep adaptive multi-channel graph neural networks},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-dimensional dynamic time warping algorithm for matrices
similarity. <em>IDA</em>, <em>26</em>(4), 859–871. (<a
href="https://doi.org/10.3233/IDA-215908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Time Warping (DTW algorithm) provides an effective method to obtain the similarity between unequal-sized signals. However, it cannot directly deal with high-dimensional samples such as matrices. Expanding a matrix to one dimensional vector as the input data of DTW will decrease the measure accuracy because of the losing of position information in the matrix. Aiming at this problem, a two-dimensional dynamic time warping algorithm (2D-DTW) is proposed in this paper to directly measure the similarity between matrices. In 2D-DTW algorithm, a three dimensional distance-cuboid is constructed, and its mapped distance matrix is defined by cutting and compressing the distance-cuboid. By introducing the dynamic programming theory to search the shortest warping path in the mapped matrix, the corresponding shortest distance can be obtained as the expected similarity measure. The experimental results suggest that the performance of 2D-DTW distance is superior to the traditional Euclidean distance and can improve the similarity accuracy between matrices by introducing the warping alignment mechanisms. 2D-DTW algorithm extends the application ranges of traditional DTW and is especially suitable for high-dimensional data.},
  archive      = {J_IDA},
  author       = {Gao, Cuifang and Li, Junjie and Shen, Wanqiang and Yin, Ping},
  doi          = {10.3233/IDA-215908},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {859-871},
  shortjournal = {Intell. Data Anal.},
  title        = {Two-dimensional dynamic time warping algorithm for matrices similarity},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unifying attentive sparse autoencoder with neural
collaborative filtering for recommendation. <em>IDA</em>,
<em>26</em>(4), 841–857. (<a
href="https://doi.org/10.3233/IDA-216049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The autoencoder network has been proven to be one of the powerful techniques for recommender systems. Currently, the ways of utilizing autoencoder in recommender systems can be divided into two categories: modeling user-item interaction rely solely on autoencoder and integrating autoencoder with ot her models. Most existing methods based on autoencoder assume that all features of model’s input are equally the same contributing to the final prediction, which can be regarded as attention weight vectors; however, this hypothesis is not reliable, especially when exploring users’ interaction frequency with different items. Moreover, combining autoencoder with traditional methods, the usual strategy is to leverage a linear kernel of the inner product of user and item vectors to predict user preferences, which will lead to insufficient expression power and hurt the performance of recommendation when facing data sparsity and cold start problems. To tackle the above two problems, we propose a novel hybrid deep learning model for top-n recommendation, called attentive stacked sparse autoencoder (A-SAERec), which can capture attention weights vector of a user for items, and then combined with the neural matrix factorization to improve the performance of recommender model. Extensive experiments on four real-world datasets show that our A-SAERec algorithm has significant improvements over state-of-the-art algorithms.},
  archive      = {J_IDA},
  author       = {Zhang, Yihao and Zhao, Chu and Yuan, Meng and Chen, Mian and Liu, Xiaoyang},
  doi          = {10.3233/IDA-216049},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {841-857},
  shortjournal = {Intell. Data Anal.},
  title        = {Unifying attentive sparse autoencoder with neural collaborative filtering for recommendation},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-label feature selection method based on an
approximation of interaction information. <em>IDA</em>, <em>26</em>(4),
823–840. (<a href="https://doi.org/10.3233/IDA-215985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional multi-label data is widespread in practical applications, which brings great challenges to the research field of pattern recognition and machine learning. Many feature selection algorithms have been proposed in recent years, among which the filtering feature selection algorithm is the most popular one because of its simplicity. Therefore, filtering feature selection has become a hot research topic, especially the multi-label feature selection algorithm based on mutual information. In the algorithm, the computation cost of high dimensional mutual information is expensive. How to approximate high order mutual information based on low order mutual information has become a major research direction. To our best knowledge, all existing feature selection algorithms that consider the label correlation will increase the computational cost greatly. Therefore, this paper proposes an approximation method of three-dimensional interaction information, which is applied to the calculation of correlation and redundancy. It can take the correlation of labels into account and don’t increase the computation cost significantly at the same time. Experiments analysis results show that the proposed method is effective.},
  archive      = {J_IDA},
  author       = {Pan, Minlan and Sun, Zhanquan and Wang, Chaoli and Cao, Gaoyu},
  doi          = {10.3233/IDA-215985},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {823-840},
  shortjournal = {Intell. Data Anal.},
  title        = {A multi-label feature selection method based on an approximation of interaction information},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Editorial. <em>IDA</em>, <em>26</em>(4), 819–821. (<a
href="https://doi.org/10.3233/IDA-220003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IDA},
  doi          = {10.3233/IDA-220003},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {819-821},
  shortjournal = {Intell. Data Anal.},
  title        = {Editorial},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ORBoost: An orthogonal AdaBoost. <em>IDA</em>,
<em>26</em>(3), 805–818. (<a
href="https://doi.org/10.3233/IDA-205705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learners and deep neural networks are state-of-the-art schemes for classification applications. However, deep networks suffer from complex structure, need large amount of samples and also require plenty of time to be converged. In contrast, ensemble learners (especially AdaBoost) are fast to be trained, can work with small and large datasets and also benefit strong mathematical background. In this paper, we have developed a new orthogonal version of AdaBoost, termed as ORBoost, in order to desensitize its performance against noisy samples as well as exploiting low number of weak learners. In ORBoost, after reweighting the distribution of each learner, the Gram-Schmidt rule updates those weights to make a new samples’ distribution to be orthogonal to the former distributions. In contrast in AdaBoost, there is no orthogonality constraint even between two successive weak learners while there is a similarity between the distributions of samples in different learners. To assess the performance of ORBoost, 16 UCI-Repository datasets along with six big datasets are deployed. The performance of ORBoost is compared to the standard AdaBoost, LogitBoost and AveBoost-II over the selected datasets. The achieved results support the significant superiority of ORBoost to the counterparts in terms of accuracy, robustness, number of exploited weak learners and generalization on most of the datasets.},
  archive      = {J_IDA},
  author       = {Bostanian, Zohreh and Boostani, Reza and Sabeti, Malihe and Mohammadi, Mokhtar},
  doi          = {10.3233/IDA-205705},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {805-818},
  shortjournal = {Intell. Data Anal.},
  title        = {ORBoost: An orthogonal AdaBoost},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling data with observers. <em>IDA</em>, <em>26</em>(3),
785–803. (<a href="https://doi.org/10.3233/IDA-215741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compact data models have become relevant due to the massive, ever-increasing generation of data. We propose Observers-based Data Modeling (ODM), a lightweight algorithm to extract low density data models (aka coresets) that are suitable for both static and stream data analysis. ODM coresets keep da ta internal structures while alleviating computational costs of machine learning during evaluation phases accounting for a O(n log n) worst-case complexity. We compare ODM with previous proposals in classification, clustering, and outlier detection. Results show the preponderance of ODM for obtaining the best trade-off in accuracy, versatility, and speed.},
  archive      = {J_IDA},
  author       = {Meghdouri, Fares and Iglesias Vázquez, Félix and Zseby, Tanja},
  doi          = {10.3233/IDA-215741},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {785-803},
  shortjournal = {Intell. Data Anal.},
  title        = {Modeling data with observers},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An integrated model based on feedforward neural network and
taylor expansion for indicator correlation elimination. <em>IDA</em>,
<em>26</em>(3), 751–783. (<a
href="https://doi.org/10.3233/IDA-215955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing correlation processing strategies make up for the defect that most evaluation algorithms do not consider the independence between indicators. However, these solutions may change the indicator system’s internal connection, affecting the final evaluation result’s interpretability and accurac y. Besides, traditional independent analysis methods cannot accurately describe the complex multivariate correlation based on the linear relationship. Aimed at these problems, we propose an indicators correlation elimination algorithm based on the feedforward neural network and Taylor expansion (NNTE). Firstly, we propose a generalized n-power correlation and a feedforward neural network to express the relationship between indicators quantitatively. Secondly, the low-order Taylor expression expanded at every sample is pointed to eliminate nonlinear relationships. Finally, to control the expansions’ accuracy, the layer-by-layer stripping method is presented to reduce the dimensionality of the correlations among multiple indicators gradually. This procedure continues to iterate until there are all simple two-dimensional correlations, eliminating multiple variables’ correlations. To compare the elimination efficiency, the ranking accuracy is proposed to measure the distance of the resulting sequence to the benchmark sequence. Under Cleveland and KDD99 two datasets, the ranking accuracy of the NNTE method is 71.64% and 96.41%, respectively. Compared with other seven common elimination methods, our proposed method’s average increase is 13.67% and 25.13%, respectively.},
  archive      = {J_IDA},
  author       = {Guo, Wei and Qiu, Han and Liu, Zimian and Zhu, Junhu and Wang, Qingxian},
  doi          = {10.3233/IDA-215955},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {751-783},
  shortjournal = {Intell. Data Anal.},
  title        = {An integrated model based on feedforward neural network and taylor expansion for indicator correlation elimination},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stock market network based on bi-dimensional histogram and
autoencoder. <em>IDA</em>, <em>26</em>(3), 723–750. (<a
href="https://doi.org/10.3233/IDA-215819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a deep learning related framework to analyze S&amp;P500 stocks using bi-dimensional histogram and autoencoder. The bi-dimensional histogram consisting of daily returns of stock price and stock trading volume is plotted for each stock. Autoencoder is applied to the bi-dimension al histogram to reduce data dimension and extract meaningful features of a stock. The histogram distance matrix for stocks are made of the extracted features of stocks, and stock market network is built by applying Planar Maximally Filtered Graph(PMFG) algorithm to the histogram distance matrix. The constructed stock market network represents the latent space of bi-dimensional histogram, and network analysis is performed to investigate the structural properties of the stock market. we discover that the structural properties of stock market network are related to the dispersion of bi-dimensional histogram. Also, we confirm that the autoencoder is effective in extracting the latent feature of the bi-dimensional histogram. Portfolios using the features of bi-dimensional histogram network are constructed and their investment performance is evaluated in comparison with other benchmark portfolios. We observe that the portfolio consisting of stocks corresponding to the peripheral nodes of bi-dimensional histogram network shows better investment performance than other benchmark stock portfolios.},
  archive      = {J_IDA},
  author       = {Choi, Sungyoon and Gwak, Dongkyu and Song, Jae Wook and Chang, Woojin},
  doi          = {10.3233/IDA-215819},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {723-750},
  shortjournal = {Intell. Data Anal.},
  title        = {Stock market network based on bi-dimensional histogram and autoencoder},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online learning agents for cost-sensitive topical data
acquisition from the web. <em>IDA</em>, <em>26</em>(3), 695–722. (<a
href="https://doi.org/10.3233/IDA-205107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Access to one of the richest data sources in the world, the web, is not possible without cost. Often, this cost is not taken into account in data acquisition processes. In this paper, we introduce the Learning Agents (LA) method for automatic topical data acquisition from the web with minimum bandw idth usage and the lowest cost. The proposed LA method uses online learning topical crawlers. The online learning capability makes the LA able to dynamically adapt to the properties of web pages during the crawling process of the target topic, and learn an effective combination of a set of link scoring criteria for that topic. That way, the LA resolves the challenge in the mechanism of combining the outputs of different criteria for computing the value of following a link, in the formerly approaches, and increases the efficiency of the crawlers. A version of the LA method is implemented that uses a collection of topical content analyzers for scoring the links. The learning ability in the implemented LA resolves the challenge of the unclear appropriate size of link contexts for pages of different topics. Using standard metrics in empirical evaluation indicates that when non-learning methods show inefficiency, the learning capability of LA significantly increases the efficiency of topical crawling, and achieves the state of the art results.},
  archive      = {J_IDA},
  author       = {Naghibi, Mahdi and Anvari, Reza and Forghani, Ali and Minaei, Behrouz},
  doi          = {10.3233/IDA-205107},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {695-722},
  shortjournal = {Intell. Data Anal.},
  title        = {Online learning agents for cost-sensitive topical data acquisition from the web},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to transfer knowledge from RDF graphs with gated
recurrent units. <em>IDA</em>, <em>26</em>(3), 679–694. (<a
href="https://doi.org/10.3233/IDA-215919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet is a vital part of today’s ecosystem. The speedy evolution of the Internet has brought up practical issues such as the problem of information retrieval. Several methods have been proposed to solve this issue. Such approaches retrieve the information by using SPARQL queries over the Res ource Description Framework (RDF) content which requires a precise match concerning the query structure and the RDF content. In this work, we propose a transfer learning-based neural learning method that helps to search RDF graphs to provide probabilistic reasoning between the queries and their results. The problem is formulated as a classification task where RDF graphs are preprocessed to abstract the N-Triples, then encode the abstracted N-triples into a transitional state that is suitable for neural transfer learning. Next, we fine-tune the neural learner to learn the semantic relationships between the N-triples. To validate the proposed approach, we employ ten-fold cross-validation. The results have shown that the anticipated approach is accurate by acquiring the average accuracy, recall, precision, and f-measure. The achieved scores are 97.52%, 96.31%, 98.45%, and 97.37%, respectively, and outperforms the baseline approaches.},
  archive      = {J_IDA},
  author       = {Soliman, Hatem and Khan, Izhar Ahmed and Hussain, Yasir},
  doi          = {10.3233/IDA-215919},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {679-694},
  shortjournal = {Intell. Data Anal.},
  title        = {Learning to transfer knowledge from RDF graphs with gated recurrent units},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-instance positive and unlabeled learning with bi-level
embedding. <em>IDA</em>, <em>26</em>(3), 659–678. (<a
href="https://doi.org/10.3233/IDA-215896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple Instance Learning (MIL) is a widely studied learning paradigm which arises from real applications. Existing MIL methods have achieved prominent performances under the premise of plenty annotation data. Nevertheless, sufficient labeled data is often unattainable due to the high labeling cos t. For example, the task in web image identification is to find similar samples among a large size of unlabeled dataset through a small number of provided target pictures. This leads to a particular scenario of Multiple Instance Learning with insufficient Positive and superabundant Unlabeled data (PU-MIL), which is a hot research topic in MIL recently. In this paper, we propose a novel method called Multiple Instance Learning with Bi-level Embedding (MILBLE) to tackle PU-MIL problem. Unlike other PU-MIL method using only simple single-level mapping, the bi-level embedding strategy are designed to customize specific mapping for positive and unlabeled data. It ensures the characteristics of key instance are not erased. Moreover, the weighting measure adopted in positive data can extracts the uncontaminated information of true positive instances without interference from negative ones. Finally, we minimize the classification error loss of mapped examples based on class-prior probability to train the optimal classifier. Experimental results show that our method has better performance than other state-of-the-art methods.},
  archive      = {J_IDA},
  author       = {Tang, Xijia and Xu, Chao and Luo, Tingjin and Hou, Chenping},
  doi          = {10.3233/IDA-215896},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {659-678},
  shortjournal = {Intell. Data Anal.},
  title        = {Multi-instance positive and unlabeled learning with bi-level embedding},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HELD: Hierarchical entity-label disambiguation in named
entity recognition task using deep learning. <em>IDA</em>,
<em>26</em>(3), 637–657. (<a
href="https://doi.org/10.3233/IDA-205720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named Entity Recognition (NER) is a challenging learning task of identifying and classifying entity mentions in texts into predefined categories. In recent years, deep learning (DL) methods empowered by distributed representations, such as word- and character-level embeddings, have been employed in NER systems. However, for information extraction in Police narrative reports, the performance of a DL-based NER approach is limited due to the presence of fine-grained ambiguous entities. For example, given the narrative report “Anna stole Ada’s car”, imagine that we intend to identify the VICTIM and the ROBBER, two sub-labels of PERSON. Traditional NER systems have limited performance in categorizing entity labels arranged in a hierarchical structure. Furthermore, it is unfeasible to obtain information from knowledge bases to give a disambiguated meaning between the entity mentions and the actual labels. This information must be extracted directly from the context dependencies. In this paper, we deal with the Hierarchical Entity-Label Disambiguation problem in Police reports without the use of knowledge bases. To tackle such a problem, we present HELD, an ensemble model that combines two components for NER: a BLSTM-CRF architecture and a NER tool. Experiments conducted on a real Police reports dataset show that HELD significantly outperforms baseline approaches.},
  archive      = {J_IDA},
  author       = {Neves Oliveira, Bárbara Stéphanie and Fernandes de Oliveira, Andreza and Monteiro de Lira, Vinicius and Linhares Coelho da Silva, Ticiana and Fernandes de Macêdo, José Antônio},
  doi          = {10.3233/IDA-205720},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {637-657},
  shortjournal = {Intell. Data Anal.},
  title        = {HELD: Hierarchical entity-label disambiguation in named entity recognition task using deep learning},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sparse non-negative matrix factorization for uncertain data
clustering. <em>IDA</em>, <em>26</em>(3), 615–636. (<a
href="https://doi.org/10.3233/IDA-205622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of clustering a set of uncertain data, where each data consists of a point-set indicating its possible locations. The objective is to identify the representative for each uncertain data and group them into k clusters so as to minimize the total clustering cost. Different fro m other models, our model does not assume that there is a probability distribution for each uncertain data. Thus, all possible locations need to be considered to determine the representative. Existing methods for this problem are either impractical or have difficulty to handle large-scale datasets due to their pairwise-distance based global search strategy and expensive optimization computation. In this paper, we propose a novel sparse Non-negative Matrix Factorization (NMF) method which measures the similarity of uncertain data by their most commonly shared features. A divide-and-conquer approach is adopted to remarkably improve the efficiency. A novel diagonal l0-constraint and its l1 relaxation are proposed to overcome the challenge of determining the representatives. We give a detailed analysis to show the correctness of our method, and provide an effective initialization and peeling strategy to enhance the ability of processing large-scale datasets. Experimental results on some benchmark datasets confirm the effectiveness of our method.},
  archive      = {J_IDA},
  author       = {Chen, Danyang and Wang, Xiangyu and Xu, Xiu and Zhong, Cheng and Xu, Jinhui},
  doi          = {10.3233/IDA-205622},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {615-636},
  shortjournal = {Intell. Data Anal.},
  title        = {Sparse non-negative matrix factorization for uncertain data clustering},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-class WHMBoost: An ensemble algorithm for multi-class
imbalanced data. <em>IDA</em>, <em>26</em>(3), 599–614. (<a
href="https://doi.org/10.3233/IDA-215874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imbalanced data problem is widespread in the real world. In the process of training machine learning models, ignoring imbalanced data problems will cause the performance of the model to deteriorate. At present, researchers have proposed many methods to deal with the imbalanced data problems, bu t these methods mainly focus on the imbalanced data problems in two-class classification tasks. Learning from multi-class imbalanced data sets is still an open problem. In this paper, an ensemble method for classifying multi-class imbalanced data sets is put forward, called multi-class WHMBoost. It is an extension of WHMBoost that we proposed earlier. We do not use the algorithm used in WHMBoost to process the data, but use random balance based on average size so as to balance the data distribution. The weak classifiers we use in the boosting algorithm are support vector machine and decision tree classifier. In the process of training the model, they participate in training with given weights in order to complement each other’s advantages. On 18 multi-class imbalanced data sets, we compared the performance of multi-class WHMBoost with state of the art ensemble algorithms using MAUC, MG-mean and MMCC as evaluation criteria. The results demonstrate that it has obvious advantages compared with state of the art ensemble algorithms and can effectively deal with multi-class imbalanced data sets.},
  archive      = {J_IDA},
  author       = {Zhao, Jiakun and Jin, Ju and Zhang, Yibo and Zhang, Ruifeng and Chen, Si},
  doi          = {10.3233/IDA-215874},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {599-614},
  shortjournal = {Intell. Data Anal.},
  title        = {Multi-class WHMBoost: An ensemble algorithm for multi-class imbalanced data},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A resistance outlier sampling algorithm for imbalanced data
prediction. <em>IDA</em>, <em>26</em>(3), 583–598. (<a
href="https://doi.org/10.3233/IDA-211519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of imbalanced data is an important challenge in current research. Sampling is an important way to solve the problem of imbalanced data classification, but some traditional sampling algorithms are susceptible to outliers. Therefore, an iF-ADASYN sampling algorithm is proposed in this paper. First, based on the ADASYN algorithm, we introduce the isolation Forest algorithm to overcome its vulnerability to outliers. Then, a calculation method of anomaly index which can delete outliers accurately of minority data is presented. The experimental results of four UCI public imbalanced datasets show that the algorithm can effectively improve the accuracy of the minority class, and increase the stability. In the real thrombus dataset, the AUC value of the iF-ADASYN algorithm is more significant than that of SMOTE and ADASYN algorithms, and the recognition rate of patients with thrombosis increased by 20%. The iF-ADASYN algorithm obtains better resistance to outliers than the original ADASYN algorithm. Meanwhile, it improves the accuracy of minority class decision boundary region division.},
  archive      = {J_IDA},
  author       = {Pan, Xiaoying and Jia, Rong and Huang, Jiahao and Wang, Hao},
  doi          = {10.3233/IDA-211519},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {583-598},
  shortjournal = {Intell. Data Anal.},
  title        = {A resistance outlier sampling algorithm for imbalanced data prediction},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Extended clustering algorithm based on cluster shape
boundary. <em>IDA</em>, <em>26</em>(3), 567–582. (<a
href="https://doi.org/10.3233/IDA-215857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the shape characteristics of the sample distribution in the clustering problem, this paper proposes an extended clustering algorithm based on cluster shape boundary (ECBSB). The algorithm automatically determines the number of clusters and classification discrimination boundaries by findin g the boundary closures of the clusters from a global perspective of the sample distribution. Since ECBSB is insensitive to local features of the sample distribution, it can accurately identify clusters on complex shape and uneven density distribution. ECBSB first detects the shape boundary points of the cluster in the sample set with edge noise points eliminated, and then generates boundary closures around the cluster based on the boundary points. Finally, the cluster labels of the boundary are propagated to the entire sample set by a nearest neighbor search. The proposed method is evaluated on multiple benchmark datasets. Exhaustive experimental results show that the proposed method achieves highly accurate and robust clustering results, and is superior to the classical clustering baselines on most of the test data.},
  archive      = {J_IDA},
  author       = {Li, Peng and Xie, Haibin and Shi, Yifei and Xu, Xin},
  doi          = {10.3233/IDA-215857},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {567-582},
  shortjournal = {Intell. Data Anal.},
  title        = {Extended clustering algorithm based on cluster shape boundary},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022d). Editorial. <em>IDA</em>, <em>26</em>(3), 563–565. (<a
href="https://doi.org/10.3233/IDA-220002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IDA},
  doi          = {10.3233/IDA-220002},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {563-565},
  shortjournal = {Intell. Data Anal.},
  title        = {Editorial},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting remaining execution time of business process
instances via auto-encoded transition system. <em>IDA</em>,
<em>26</em>(2), 543–562. (<a
href="https://doi.org/10.3233/IDA-215755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important task in business process management, remaining time prediction for business process instances has attracted extensive attentions. However, most of the traditional remaining time prediction approaches only take into account formal process models and cannot handle large-scale event lo gs in an effective manner. Although machine learning and deep learning have been recently applied to the remaining time prediction task, these approaches cannot incorporate domain knowledge naturally. To overcome these weaknesses of existing studies, we propose a remaining execution time prediction approach based on a novel auto-encoded transition system, which can enhance the complementarity of process modeling and deep learning techniques. Through auto-encoding the event-level and state-level features, the proposed approach can represent process instances in a comprehensive and compact form. Furthermore, a transfer learning strategy is proposed to train the remaining time prediction model so as to avoid overfitting and improve the accuracy of prediction. We conduct extensive experiments on four real-world datasets to verify the effectiveness of the proposed approach. The results show its superiority over several state-of-the-art approaches.},
  archive      = {J_IDA},
  author       = {Ni, Weijian and Yan, Ming and Liu, Tong and Zeng, Qingtian},
  doi          = {10.3233/IDA-215755},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {543-562},
  shortjournal = {Intell. Data Anal.},
  title        = {Predicting remaining execution time of business process instances via auto-encoded transition system},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IACN: Interactive attention capsule network for similar case
matching. <em>IDA</em>, <em>26</em>(2), 525–541. (<a
href="https://doi.org/10.3233/IDA-205632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The similar case matching task aims to detect which two cases are more similar for a given triplet. It plays a significant role in the legal industry and thus has gained much attention. Due to the rapid development of natural language processing technology, various deep learning techniques have bee n applied to similar case matching task and obtained attractive performance. Most existing researches usually focus on encoding legal documents into a continuous vector. However, a unified vector is difficult to model multiple elements of the case. In the real world, cases contain numerous elements, which are the basis for legal practitioners to judge the similarity among cases. Legal experts usually focus on whether the two cases have similar legal elements. It makes this task especially challenging. In this paper, we propose a novel model, namely Interactive Attention Capsule Network (dubbed as IACN). It attempts to simulate the process of judgment by legal experts, which captures fine-grained elements similarity to make an interpretable judgment. In other words, the IACN judges the similarity of the case pairs based on the legal elements. The more similar legal elements of a case pair, the higher the degree of similarity of the case pair. In addition, we devise an interactive dynamic routing mechanism, which can better learn the interactive representation of legal elements among cases than the vanilla dynamic routing. We conduct extensive experiments based on a real-world dataset. The experimental results consistently demonstrate the superiorities and competitiveness of our proposed model.},
  archive      = {J_IDA},
  author       = {Li, Hui and Lu, Jin and Le, Yuquan and He, Jiawei},
  doi          = {10.3233/IDA-205632},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {525-541},
  shortjournal = {Intell. Data Anal.},
  title        = {IACN: Interactive attention capsule network for similar case matching},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identifying latent variables in dynamic bayesian networks
with bootstrapping applied to type 2 diabetes complication prediction.
<em>IDA</em>, <em>26</em>(2), 501–524. (<a
href="https://doi.org/10.3233/IDA-205570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting complications associated with complex disease is a challenging task given imbalanced and highly correlated disease complications along with unmeasured or latent factors. To analyse the complications associated with complex disease, this article attempts to deal with complex imbalanced cl inical data, whilst determining the influence of latent variables within causal networks generated from the observation. This work proposes appropriate Intelligent Data Analysis methods for building Dynamic Bayesian networks with latent variables, applied to small-sized clinical data (a case of Type 2 Diabetes complications). First, it adopts a Time Series Bootstrapping approach to re-sample the rare complication class with a replacement with respect to the dynamics of disease progression. Then, a combination of the Induction Causation algorithm and Link Strength metric (which is called IC*LS approach) is applied on the bootstrapped data for incrementally identifying latent variables. The most highlighted contribution of this paper gained insight into the disease progression by interpreting the latent states (with respect to the associated distributions of complications). An exploration of inference methods along with confidence interval assessed the influences of these latent variables. The obtained results demonstrated an improvement in the prediction performance.},
  archive      = {J_IDA},
  author       = {Yousefi, Leila and Tucker, Allan},
  doi          = {10.3233/IDA-205570},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {501-524},
  shortjournal = {Intell. Data Anal.},
  title        = {Identifying latent variables in dynamic bayesian networks with bootstrapping applied to type 2 diabetes complication prediction},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving the accuracy of multiclass classification in
machine learning: A case study in a cell signaling dataset.
<em>IDA</em>, <em>26</em>(2), 481–500. (<a
href="https://doi.org/10.3233/IDA-215826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is important to make sense of the data within its context to propose a useful model to solve a problem. This domain knowledge includes information not contained in the data, but that will help us understand the data to be fed into a machine-learning algorithm and guide us on what features might help our model. Nevertheless, domain knowledge may become insufficient as the input variables increase, forcing the need to try automated feature selection techniques. In this study, we investigate whether the joint use of 1) feature selection techniques, such as Chi-square, Tree-based Feature Selection, Pearson’s Correlation, LASSO, Low Variance, and Recursive Feature Elimination, 2) outlier detection methods such as Isolation-Forest, and 3) Cross-Validation techniques lead to improving the accuracy in multiclass classification in machine learning. Specifically, we address the classification of patterns representing the activation state of cell signaling components into classes that symbolize the different cellular processes triggered in cancer cells. The results presented in this work have shown an accuracy increase with up to 80% fewer input features by only using 3 out of the 16 original descriptors.},
  archive      = {J_IDA},
  author       = {González-Pérez, Pedro Pablo and Sánchez-Gutiérrez, Máximo Eduardo},
  doi          = {10.3233/IDA-215826},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {481-500},
  shortjournal = {Intell. Data Anal.},
  title        = {Improving the accuracy of multiclass classification in machine learning: A case study in a cell signaling dataset},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TSPS: A topic based shortest path set algorithm for
influence maximization. <em>IDA</em>, <em>26</em>(2), 469–480. (<a
href="https://doi.org/10.3233/IDA-215790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the influence maximization problem in social networks, which aims to find some influence nodes that maximize the spread of information. Most existing achievements usually adopt a uniform propagation probability, without considering the topic information. Moreover, the classic Independent Cascade Model and its approximations have suffered from much running time. To overcome this limitation, this paper proposed a Topic based Shortest Path Set algorithm (TSPS). Additionally, a comprehensive set of experiments are conducted on large real-world networks, showing that our proposal provides more impressive results in the aspects of influence spread and running time.},
  archive      = {J_IDA},
  author       = {Duan, Xiuliang and Qiu, Liqing and Sun, Chengai},
  doi          = {10.3233/IDA-215790},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {469-480},
  shortjournal = {Intell. Data Anal.},
  title        = {TSPS: A topic based shortest path set algorithm for influence maximization},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A strategy to estimate the optimal low-rank in incremental
SVD-based algorithms for recommender systems. <em>IDA</em>,
<em>26</em>(2), 447–467. (<a
href="https://doi.org/10.3233/IDA-205733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems apply machine learning and data mining techniques for filtering unseen information, and they can provide an opportunity to predict whether a user would be interested in a given item. The main types of recommender systems are collaborative filtering (CF) and content-based filteri ng, which suffer from scalability and data sparsity resulting in poor quality recommendations and reduced coverage. There are two incremental algorithms based on Singular Value Decomposition (SVD) with high scalability for recommender systems which are named the incremental SVD algorithm and incremental Approximating the Singular Value Decomposition (ApproSVD) algorithm. In both mentioned methods, the estimated value of rank for approximating the recommender systems’ data matrix is chosen experimentally in the related literature. In this paper, we investigate the role of singular values for estimating a more reliable amount of rank in the mentioned dimensionality reduction techniques to improve the recommender systems’ performance. In other words, we offered a strategy for choosing the optimal rank that approximates the data matrix more accurately in incremental algorithms with the help of singular values. The numerical results illustrate that the suggested strategy improves the accuracy of the recommendations and run times of both algorithms when employs for Movielens, Netflix, and Jester dataset.},
  archive      = {J_IDA},
  author       = {Bahrkazemi, Maryam and Mohammadi, Maryam},
  doi          = {10.3233/IDA-205733},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {447-467},
  shortjournal = {Intell. Data Anal.},
  title        = {A strategy to estimate the optimal low-rank in incremental SVD-based algorithms for recommender systems},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RGCF: Refined graph convolution collaborative filtering with
concise and expressive embedding. <em>IDA</em>, <em>26</em>(2), 427–445.
(<a href="https://doi.org/10.3233/IDA-205725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolution Networks (GCNs) have attracted significant attention and have become the most popular method for learning graph representations. In recent years, many efforts have focused on integrating GCNs into recommender tasks and have made remarkable progress. At its core is to explicitly ca pture the high-order connectivities between nodes in the user-item bipartite graph. However, we found some potential drawbacks existed in the traditional GCN-based recommendation models are that the excessive information redundancy yield by the nonlinear graph convolution operation reduces the expressiveness of the resultant embeddings, and the important popularity features that are effective in sparse recommendation scenarios are not encoded in the embedding generation process. In this work, we develop a novel GCN-based recommendation model, named Refined Graph convolution Collaborative Filtering (RGCF), where a refined graph convolution structure is designed to match non-semantic ID inputs. In addition, a new fine-tuned symmetric normalization is proposed to mine node popularity characteristics and further incorporate the popularity features into the embedding learning process. Extensive experiments were conducted on three public million-size datasets, and the RGCF improved by an average of 13.45% over the state-of-the-art baseline. Further comparative experiments validated the effectiveness and rationality of each part of our proposed RGCF. We released our code at https://github.com/hfutmars/RGCF.},
  archive      = {J_IDA},
  author       = {Liu, Kang and Xue, Feng and Hong, Richang},
  doi          = {10.3233/IDA-205725},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {427-445},
  shortjournal = {Intell. Data Anal.},
  title        = {RGCF: Refined graph convolution collaborative filtering with concise and expressive embedding},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning transferable and discriminative features for
unsupervised domain adaptation. <em>IDA</em>, <em>26</em>(2), 407–425.
(<a href="https://doi.org/10.3233/IDA-215813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although achieving remarkable progress, it is very difficult to induce a supervised classifier without any labeled data. Unsupervised domain adaptation is able to overcome this challenge by transferring knowledge from a labeled source domain to an unlabeled target domain. Transferability and discri minability are two key criteria for characterizing the superiority of feature representations to enable successful domain adaptation. In this paper, a novel method called learning TransFerable and Discriminative Features for unsupervised domain adaptation (TFDF) is proposed to optimize these two objectives simultaneously. On the one hand, distribution alignment is performed to reduce domain discrepancy and learn more transferable representations. Instead of adopting Maximum Mean Discrepancy (MMD) which only captures the first-order statistical information to measure distribution discrepancy, we adopt a recently proposed statistic called Maximum Mean and Covariance Discrepancy (MMCD), which can not only capture the first-order statistical information but also capture the second-order statistical information in the reproducing kernel Hilbert space (RKHS). On the other hand, we propose to explore both local discriminative information via manifold regularization and global discriminative information via minimizing the proposed class confusion objective to learn more discriminative features, respectively. We integrate these two objectives into the Structural Risk Minimization (RSM) framework and learn a domain-invariant classifier. Comprehensive experiments are conducted on five real-world datasets and the results verify the effectiveness of the proposed method.},
  archive      = {J_IDA},
  author       = {Du, Yuntao and Zhang, Ruiting and Zhang, Xiaowen and Yao, Yirong and Lu, Hengyang and Wang, Chongjun},
  doi          = {10.3233/IDA-215813},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {407-425},
  shortjournal = {Intell. Data Anal.},
  title        = {Learning transferable and discriminative features for unsupervised domain adaptation},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A noise-resilient online learning algorithm with ramp loss
for ordinal regression. <em>IDA</em>, <em>26</em>(2), 379–405. (<a
href="https://doi.org/10.3233/IDA-205613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordinal regression has been widely used in applications, such as credit portfolio management, recommendation systems, and ecology, where the core task is to predict the labels on ordinal scales. Due to its learning efficiency, online ordinal regression using passive aggressive (PA) algorithms has g ained a much attention for solving large-scale ranking problems. However, the PA method is sensitive to noise especially in the scenario of streaming data, where the ranking of data samples may change dramatically. In this paper, we propose a noise-resilient online learning algorithm using the Ramp loss function, called PA-RAMP, to improve the performance of PA method for noisy data streams. Also, we validate the order preservation of thresholds of the proposed algorithm. Experiments on real-world data sets demonstrate that the proposed noise-resilient online ordinal regression algorithm is more robust and efficient than state-of-the-art online ordinal regression algorithms.},
  archive      = {J_IDA},
  author       = {Zhang, Maojun and Zhang, Cuiqing and Liang, Xijun and Xia, Zhonghang and Jian, Ling and Nan, Jiangxia},
  doi          = {10.3233/IDA-205613},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {379-405},
  shortjournal = {Intell. Data Anal.},
  title        = {A noise-resilient online learning algorithm with ramp loss for ordinal regression},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Augmenting data with generative adversarial networks: An
overview. <em>IDA</em>, <em>26</em>(2), 361–378. (<a
href="https://doi.org/10.3233/IDA-215735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performance of neural networks greatly depends on quality, size and balance of training dataset. In a real environment datasets are rarely balanced and training deep models over such data is one of the main challenges of deep learning. In order to reduce this problem, methods and techniques are bor rowed from the traditional machine learning. Conversely, generative adversarial networks (GAN) were created and developed, a relatively new type of generative models that are based on game theory and consist of two neural networks, a generator and a discriminator. The generator’s task is to create a sample from the input noise that is based on training data distribution and the discriminator should detect those samples as fake. This process goes through a finite number of iterations until the generator successfully fools the discriminator. When this occurs, sample becomes a part of new (augmented) dataset. Even though the original GAN creates unlabeled samples, variants that soon appeared removed that limitation. Generating artificial data through these networks appears to be a meaningful solution to the imbalance problem since it turned out that artificial samples created by GAN are difficult to differentiate from the real ones. In this manner, new samples of minority class could be created and dataset imbalance ratio lowered.},
  archive      = {J_IDA},
  author       = {Ljubić, Hrvoje and Martinović, Goran and Volarić, Tomislav},
  doi          = {10.3233/IDA-215735},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {361-378},
  shortjournal = {Intell. Data Anal.},
  title        = {Augmenting data with generative adversarial networks: An overview},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient modal-aware feature learning with application in
multimodal hashing. <em>IDA</em>, <em>26</em>(2), 345–360. (<a
href="https://doi.org/10.3233/IDA-215780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many retrieval applications can benefit from multiple modalities, for which how to represent multimodal data is the critical component. Most deep multimodal learning methods typically involve two steps to construct the joint representations: 1) learning of multiple intermediate features, with each intermediate feature corresponding to a modality, using separate and independent deep models; 2) merging the intermediate features into a joint representation using a fusion strategy. However, in the first step, these intermediate features do not have previous knowledge of each other and cannot fully exploit the information contained in the other modalities. In this paper, we present a modal-aware operation as a generic building block to capture the non-linear dependencies among the heterogeneous intermediate features, which can learn the underlying correlation structures in other multimodal data as soon as possible. The modal-aware operation consists of a kernel network and an attention network. The kernel network is utilized to learn the non-linear relationships with other modalities. The attention network finds the informative regions of these modal-aware features that are favorable for retrieval. We verify the proposed modal-aware feature learning in the multimodal hashing task. The experiments conducted on three public benchmark datasets demonstrate significant improvements in the performance of our method relative to state-of-the-art methods.},
  archive      = {J_IDA},
  author       = {Chu, Hanlu and Zeng, Haien and Lai, Hanjiang and Tang, Yong},
  doi          = {10.3233/IDA-215780},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {345-360},
  shortjournal = {Intell. Data Anal.},
  title        = {Efficient modal-aware feature learning with application in multimodal hashing},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A feature selection strategy for improving software
maintainability prediction. <em>IDA</em>, <em>26</em>(2), 311–344. (<a
href="https://doi.org/10.3233/IDA-215825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software maintainability is a significant contributor while choosing particular software. It is helpful in estimation of the efforts required after delivering the software to the customer. However, issues like imbalanced distribution of datasets, and redundant and irrelevant occurrence of various f eatures degrade the performance of maintainability prediction models. Therefore, current study applies ImpS algorithm to handle imbalanced data and extensively investigates several Feature Selection (FS) techniques including Symmetrical Uncertainty (SU), RandomForest filter, and Correlation-based FS using one open-source, three proprietaries and two commercial datasets. Eight different machine learning algorithms are utilized for developing prediction models. The performance of models is evaluated using Accuracy, G-Mean, Balance, &amp; Area under the ROC Curve. Two statistical tests, Friedman Test and Wilcoxon Signed Ranks Test are conducted for assessing different FS techniques. The results substantiate that FS techniques significantly improve the performance of various prediction models with an overall improvement of 18.58%, 129.73%, 80.00%, and 45.76% in the median values of Accuracy, G-Mean, Balance, &amp; AUC, respectively for all the datasets taken together. Friedman test advocates the supremacy of SU FS technique. Wilcoxon Signed Ranks test showcases that SU FS technique is significantly superior to the CFS technique for three out of six datasets.},
  archive      = {J_IDA},
  author       = {Gupta, Shikha and Chug, Anuradha},
  doi          = {10.3233/IDA-215825},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {311-344},
  shortjournal = {Intell. Data Anal.},
  title        = {A feature selection strategy for improving software maintainability prediction},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Topic discovery from short reviews based on data
enhancement. <em>IDA</em>, <em>26</em>(2), 295–310. (<a
href="https://doi.org/10.3233/IDA-205715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of social media and mobile Internet, short reviews, such as Weibo and Twitter, have exploded online. Discovering topics from short reviews is significant for many practical applications. It can effectively not only identify users’ attitudes and emotions but also enhance c ustomer satisfaction and shopping experience. Because reviews are relatively short, the sparsity of reviews considerably restricts the quality of topic discovery. To improve the efficiency of topic discovery, we introduce the concept of data enhancement and strengthen the data in sentences and words in short reviews based on the weight of importance. We then propose a topic model for reviews to topic discovery based on data enhancement (shorted as DE-LDA). We verify the rationality and feasibility of DE-LDA on real datasets. Results show that the proposed method outperforms benchmarks in topic discovery and also has better clustering effects.},
  archive      = {J_IDA},
  author       = {Zhu, Tingting and Liu, Yezheng and Sun, Jianshan and Sun, Chunhua},
  doi          = {10.3233/IDA-205715},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {295-310},
  shortjournal = {Intell. Data Anal.},
  title        = {Topic discovery from short reviews based on data enhancement},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anomaly repair-based approach to improve time series
forecasting. <em>IDA</em>, <em>26</em>(2), 277–294. (<a
href="https://doi.org/10.3233/IDA-215811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting has many practical applications in a variety of domains such as commerce, finance, medicine, weather, environment, and transportation. There exist so many methods developed for time series forecasting. However, most of the forecasting methods do not pay attention to anomalie s in time series even though time series are sensitive to anomalies. Anomaly patterns cause negative effects on the accuracy of time series forecasting. In this paper, we propose a novel anomaly repair-based approach to improve time series forecasting in the case of anomaly existence. In our approach, an effective time series forecasting framework, EPL_S_X, is proposed with anomaly smoothing as a pre-processing stage and any existing time series prediction algorithm X. In particular, our proposed approach consists of three steps including detecting anomalies, repairing anomalies by using our smoothing method, and forecasting time series using preprocessed time series. Experimental results on several time series datasets reveal that our proposed approach improves remarkably the accuracy of many existing time series forecasting methods. It also outperforms the two robust time series forecasting methods that are based on exponential and Holt-Winters smoothing. With such better prediction performance, our approach is not only more effective but also more useful when dealing with anomalies in time series forecasting.},
  archive      = {J_IDA},
  author       = {Thu, Thuy Huynh Thi and Tuan, Anh Duong and Ngoc, Chau Vo Thi},
  doi          = {10.3233/IDA-215811},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {277-294},
  shortjournal = {Intell. Data Anal.},
  title        = {Anomaly repair-based approach to improve time series forecasting},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial. <em>IDA</em>, <em>26</em>(2), 273–275. (<a
href="https://doi.org/10.3233/IDA-220001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IDA},
  author       = {Famili, A.},
  doi          = {10.3233/IDA-220001},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {273-275},
  shortjournal = {Intell. Data Anal.},
  title        = {Editorial},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combining pattern-based CRFs and weighted context-free
grammars. <em>IDA</em>, <em>26</em>(1), 257–272. (<a
href="https://doi.org/10.3233/IDA-205623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider two models for the sequence labeling (tagging) problem. The first one is a Pattern-Based Conditional Random Field (PB), in which the energy of a string (chain labeling) x=x1⁢…⁢xn∈Dn is a sum of terms over intervals [i,j] where each term is non-zero only if the substring xi⁢…⁢xj equals a prespecified word w∈Λ. The second model is a Weighted Context-Free Grammar (WCFG) frequently used for natural language processing. PB and WCFG encode local and non-local interactions respectively, and thus can be viewed as complementary. We propose a Grammatical Pattern-Based CRF model (GPB) that combines the two in a natural way. We argue that it has certain advantages over existing approaches such as the Hybrid model of Benedí and Sanchez that combines N-grams and WCFGs. The focus of this paper is to analyze the complexity of inference tasks in a GPB such as computing MAP. We present a polynomial-time algorithm for general GPBs and a faster version for a special case that we call Interaction Grammars.},
  archive      = {J_IDA},
  author       = {Takhanov, Rustem and Kolmogorov, Vladimir},
  doi          = {10.3233/IDA-205623},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {257-272},
  shortjournal = {Intell. Data Anal.},
  title        = {Combining pattern-based CRFs and weighted context-free grammars},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive simulated annealing and artificial fish swarm
algorithm for the optimization of multi-depot express delivery vehicle
routing. <em>IDA</em>, <em>26</em>(1), 239–256. (<a
href="https://doi.org/10.3233/IDA-205693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the Capacitated Vehicle Routing Problem (CVRP) of multi-depot express delivery is investigated based on the actual express delivery business in Beijing and driving intention-based road network. An Adaptive Simulated Annealing and Artificial Fish Swarm Algorithm (A-SAAFSA) is proposed to solve the CVRP. The basic ideas are use a “certainty” probability to accept the worst solution through the Metropolis criterion in the search process, and a strategy of adjusting the swimming direction to avoid falling into the local optimal solution. Moreover, an adaptive visual strategy, which adjusts the visual range adaptively in real time according to the current solution quality, is used to ensure the efficient searching and accuracy of the algorithm. Experimental results show that the A-SAAFSA algorithm outperforms four well-known algorithms, namely simulated annealing and artificial fish swarm algorithm, artificial fish swarm algorithm, simulated annealing algorithm, and genetic algorithm.},
  archive      = {J_IDA},
  author       = {Yuan, Mengfei and Kan, Xiu and Chi, Chihung and Cao, Le and Shu, Huisheng and Fan, Yixuan},
  doi          = {10.3233/IDA-205693},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {239-256},
  shortjournal = {Intell. Data Anal.},
  title        = {An adaptive simulated annealing and artificial fish swarm algorithm for the optimization of multi-depot express delivery vehicle routing},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DDREL: From drug-drug relationships to drug repurposing.
<em>IDA</em>, <em>26</em>(1), 221–237. (<a
href="https://doi.org/10.3233/IDA-215745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing the relationships among various drugs is an essential issue in the field of computational biology. Different kinds of informative knowledge, such as drug repurposing, can be extracted from drug-drug relationships. Scientific literature represents a rich source for the retrieval of knowledge about the relationships between biological concepts, mainly drug-drug, disease-disease, and drug-disease relationships. In this paper, we propose DDREL as a general-purpose method that applies deep learning on scientific literature to automatically extract the graph of syntactic and semantic relationships among drugs. DDREL remarkably outperforms the existing human drug network method and a random network respected to average similarities of drugs’ anatomical therapeutic chemical (ATC) codes. DDREL is able to shed light on the existing deficiency of the ATC codes in various drug groups. From the DDREL graph, the history of drug discovery became visible. In addition, drugs that had repurposing score 1 (diflunisal, pargyline, fenofibrate, guanfacine, chlorzoxazone, doxazosin, oxymetholone, azathioprine, drotaverine, demecarium, omifensine, yohimbine) were already used in additional indication. The proposed DDREL method justifies the predictive power of textual data in PubMed abstracts. DDREL shows that such data can be used to 1- Predict repurposing drugs with high accuracy, and 2- Reveal existing deficiencies of the ATC codes in various drug groups.},
  archive      = {J_IDA},
  author       = {Allahgholi, Milad and Rahmani, Hossein and Javdani, Delaram and Sadeghi-Adl, Zahra and Bender, Andreas and Módos, Dezsö and Weiss, Gerhard},
  doi          = {10.3233/IDA-215745},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {221-237},
  shortjournal = {Intell. Data Anal.},
  title        = {DDREL: From drug-drug relationships to drug repurposing},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ComIM: A community-based algorithm for influence
maximization under the weighted cascade model on social networks.
<em>IDA</em>, <em>26</em>(1), 205–220. (<a
href="https://doi.org/10.3233/IDA-205566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization (IM) is a problem of selecting k nodes from social networks to make the expected number of the active node maximum. Recently, with the popularity of Internet technology, more and more researchers have paid attention to this problem. However, the existing influence maximizatio n algorithms with high accuracy are usually difficult to be applied to the large-scale social network. To solve this problem the paper proposes a new algorithm, called community-based influence maximization (ComIM). Its core idea is “divide and conquer”. In detail, this algorithm first utilizes the Louvain algorithm to divide the large-scale networks into some small-scale networks. Afterwards, the algorithm utilizes the one-hop diffusion value (ODV) and two-hop diffusion value (TDV) functions to calculate the influence of a node and select nodes on these small-scale networks, which can improve the accuracy of our proposed algorithm. By using the above methods, the paper proposes a community influence-estimating method called CDV, which can improve the efficiency of the algorithm. Experimental results on six real-world datasets demonstrate that our proposed algorithm outperforms all comparison algorithms when comprehensively considering the accuracy and efficiency.},
  archive      = {J_IDA},
  author       = {Qiu, Liqing and Yang, Zhongqi and Zhu, Shiwei and Tian, Xiangbo and Liu, Shuqi},
  doi          = {10.3233/IDA-205566},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {205-220},
  shortjournal = {Intell. Data Anal.},
  title        = {ComIM: A community-based algorithm for influence maximization under the weighted cascade model on social networks},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Particle swarm optimization pattern recognition neural
network for transmission lines faults classification. <em>IDA</em>,
<em>26</em>(1), 189–203. (<a
href="https://doi.org/10.3233/IDA-205695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operating conditions of the transmission lines can be assessed through the information measured by the smart meters in the power supply bureau. Accurate classification of transmission line faults can be helpful to improve the maintenance strategy of smart grids. This paper analyzes the mechanis m of the voltage loss and the phase fault of the transmission line by using the operation data collected by the smart meters from three power supply bureaus (named Bureau A, B and C), where the faults are labeled by expert systems. In this work, a novel Particle Swarm Optimization Pattern Recognition Neural Network (PSO-PRNN) classifier is built to accurately categorize the faults and its classification performance is compared with the ones of traditional K-Nearest Neighbor (KNN), Decision Tree (DT), PSO-KNN and PSO-DT classifiers. The results show that the classification accuracy of PSO-PRNN outperforms traditional classifiers when being applied to the data collected from all three bureaus. In the A power supply bureau are 83.0%, 88.7%, 82.0%, 86.9% and 96.1%, and the classification accuracy rates are 55.7%, 68.7%, 56.6%, 68.7% and 82.5%, when used to process the data of the bureau B. The classification accuracy is 57.1%, 66.4%, 57.2%, 69.0% and 82.1%, when processing the data of bureau C. The results show that the PSO-PRNN classifier is superior to the others in terms of accuracy and applicability.},
  archive      = {J_IDA},
  author       = {Zhang, Liang and Zhao, Zhengang and Zhang, Dacheng and Luo, Chuan and Li, Chuan},
  doi          = {10.3233/IDA-205695},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {189-203},
  shortjournal = {Intell. Data Anal.},
  title        = {Particle swarm optimization pattern recognition neural network for transmission lines faults classification},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Temporal link prediction in directed networks based on
self-attention mechanism. <em>IDA</em>, <em>26</em>(1), 173–188. (<a
href="https://doi.org/10.3233/IDA-205524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of graph neural networks (GCN) makes it possible to learn structural features from evolving complex networks. Even though a wide range of realistic networks are directed ones, few existing works investigated the properties of directed and temporal networks. In this paper, we address the problem of temporal link prediction in directed networks and propose a deep learning model based on GCN and self-attention mechanism, namely TSAM. The proposed model adopts an autoencoder architecture, which utilizes graph attentional layers to capture the structural feature of neighborhood nodes, as well as a set of graph convolutional layers to capture motif features. A graph recurrent unit layer with self-attention is utilized to learn temporal variations in the snapshot sequence. We run comparative experiments on four realistic networks to validate the effectiveness of TSAM. Experimental results show that TSAM outperforms most benchmarks under two evaluation metrics.},
  archive      = {J_IDA},
  author       = {Li, Jinsong and Peng, Jianhua and Liu, Shuxin and Weng, Lintianran and Li, Cong},
  doi          = {10.3233/IDA-205524},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {173-188},
  shortjournal = {Intell. Data Anal.},
  title        = {Temporal link prediction in directed networks based on self-attention mechanism},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The overlapping community discovery algorithm based on the
local interaction model. <em>IDA</em>, <em>26</em>(1), 153–171. (<a
href="https://doi.org/10.3233/IDA-215757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In social networks, the traditional locally optimized overlapping community detection algorithm has a free-rider problem in community extension, which mainly relies on the structure information of nodes but ignores the node attributes. Therefore, in this paper, we redefine community based on theore tical analysis and propose an overlapping community discovery algorithm based on the local interaction model. By fusing node attributes and structural information, we first proposed an improved density peak fast search method to obtain multiple core nodes in the community. Then, according to the interaction range and interaction mode of the core node, we established a local interaction model of the core node, which converts the interaction strength or the number of common attributes between nodes in the network into the change of the distance between nodes. Finally, according to the proposed improved clustering algorithm, we obtain the community where the core node is located and merge the communities with a high degree of overlap. The experimental results show that compared with other similar community discovery algorithms, the proposed method outperforms the state-of-the-art approaches for community detections.},
  archive      = {J_IDA},
  author       = {Jia, Junjie and Liu, Pengtao and Du, Xiaojin and Yao, Yewang and Lei, Zhipeng},
  doi          = {10.3233/IDA-215757},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {153-171},
  shortjournal = {Intell. Data Anal.},
  title        = {The overlapping community discovery algorithm based on the local interaction model},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tree based ensemble for enhanced prediction (TEEP) of
epileptic seizures. <em>IDA</em>, <em>26</em>(1), 133–151. (<a
href="https://doi.org/10.3233/IDA-205534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and timely prediction of seizures can improve the quality of life of epileptic patients to a huge extent. This work presents a seizure prediction model that performs data extraction and feature engineering to enable effective demarcation of preictal signals from interictal signals. The pro posed Tree based Ensemble for Enhanced Prediction (TEEP) model is composed of three major phases; the feature extraction phase, feature selection phase and the prediction phase. The data is preprocessed, and features are extracted based on the nature of the data. This enables the prediction algorithm to perform time-based predictions. Further, statistical features are also extracted, followed by the process of feature aggregation. The resultant data is passed to the feature selection module to identify the attributes that exhibit highest correlation with the prediction variable. Incorporation of these two modules enhances the generalization capability of the TEEP model. The resultant features are passed to the boosted ensemble model for training and prediction. The TEEP model is analyzed using the Epileptic Seizure Recognition Data from University Hospital of Bonn and the NIH Seizure Prediction data from Melbourne University, Australia. Results from both the datasets indicate effective performances. Comparisons with the existing state-of-the-art models in literature exhibits the enhanced prediction levels of the TEEP model.},
  archive      = {J_IDA},
  author       = {Anandaraj, A. and Alphonse, P.J.A.},
  doi          = {10.3233/IDA-205534},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {133-151},
  shortjournal = {Intell. Data Anal.},
  title        = {Tree based ensemble for enhanced prediction (TEEP) of epileptic seizures},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contextual emotion detection on text using gaussian process
and tree based classifiers. <em>IDA</em>, <em>26</em>(1), 119–132. (<a
href="https://doi.org/10.3233/IDA-205587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is challenging for machine as well as humans to detect the presence of emotions such as sadness or disgust in a sentence without adequate knowledge about the context. Contextual emotion detection is a challenging problem in natural language processing. As the use of digital agents have increased in text messaging applications, it is essential for these agents to provide sensible responses to its users. The present work demonstrates the effectiveness of Gaussian process detecting contextual emotions present in a sentence. The results obtained are compared with Decision Tree and ensemble models such as Random Forest, AdaBoost and Gradient Boost. Out of the five models built on a small dataset with class imbalance, it has been found that Gaussian Process classifier predicts emotions better than the other classifiers. Gaussian Process classifier performs better by taking predictive variance into account.},
  archive      = {J_IDA},
  author       = {S, Angel Deborah and Rajendram, S. Milton and TT, Mirnalinee and S, Rajalakshmi},
  doi          = {10.3233/IDA-205587},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {119-132},
  shortjournal = {Intell. Data Anal.},
  title        = {Contextual emotion detection on text using gaussian process and tree based classifiers},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Clustering based on adaptive local density with evidential
assigning strategy. <em>IDA</em>, <em>26</em>(1), 101–118. (<a
href="https://doi.org/10.3233/IDA-205670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new clustering algorithm, based on Adaptive Local Density (ALD) and Evidential K-Nearest Neighbors (EKNN), is proposed here. In density peaks clustering, many other density metrics fail to detect cluster centers on multi-density datasets, however the ALD deals with the tasks very well since it ca n better utilize the local information. To assign the remaining points after detecting the cluster centers, an assigning strategy in the framework of evidential theory, named EKNN, is created. The advantage of EKNN is twofold. Firstly, by fusing the information of K-Nearest Neighbors, it can reduce the risk of a phenomenon named domino effect: the drawback of one classical clustering, i.e., clustering by fast search and find of density peaks (always named as DPC). Secondly, it can detect border and noise points simultaneously since a credal partition is derived which can mine ambiguity and uncertainty of data structure. Simulations on both synthetic and real-world datasets demonstrate the outstanding performance of ALD-EKNN compared with DPC and some of its successors.},
  archive      = {J_IDA},
  author       = {Wang, Qian and Gong, Chaoyu and Wang, Peihong},
  doi          = {10.3233/IDA-205670},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {101-118},
  shortjournal = {Intell. Data Anal.},
  title        = {Clustering based on adaptive local density with evidential assigning strategy},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent data integration from heterogeneous relational
databases containing incomplete and uncertain information. <em>IDA</em>,
<em>26</em>(1), 75–99. (<a
href="https://doi.org/10.3233/IDA-205535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of incomplete and uncertain information has emerged as a crucial issue in many application domains, including data warehousing, data mining, data analysis, and artificial intelligence. This paper proposes a novel approach of mediation-based integration for integrating these types of information from heterogeneous relational databases. We present in detail the different processes in the layered architecture of the proposed flexible mediator system. The integration process of our mediator is based on the use of fuzzy logic and semantic similarity measures for more effective integration of incomplete and uncertain information. We also define fuzzy views over the mediator’s global fuzzy schema to express incomplete and uncertain databases and specify the mappings between this global schema and these sources. Moreover, our approach provides intelligent data integration, enabling efficient generation of cooperative answers from similar ones, retrieved by queried flexible wrappers. These answers contain information that is more detailed and complete than the information contained in the initial answers. A thorough experiment verifies our approach improves the performance of data integration under various configurations.},
  archive      = {J_IDA},
  author       = {Aggoune, Aicha},
  doi          = {10.3233/IDA-205535},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {75-99},
  shortjournal = {Intell. Data Anal.},
  title        = {Intelligent data integration from heterogeneous relational databases containing incomplete and uncertain information},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust multi-class feature selection via l2,0-norm
regularization minimization. <em>IDA</em>, <em>26</em>(1), 57–73. (<a
href="https://doi.org/10.3233/IDA-205724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an important data preprocessing in data mining and machine learning, that can reduce the number of features without deteriorating model’s performance. Recently, sparse regression has received considerable attention in feature selection task due to its good performance. However, because the l2,0-norm regularization term is non-convex, this problem is hard to solve, and most of the existing methods relaxed it by l2,1-norm. Unlike the existing methods, this paper proposes a novel method to solve the l2,0-norm regularized least squares problem directly based on iterative hard thresholding, which can produce exact row-sparsity solution for weights matrix, and features can be selected more precisely. Furthermore, two homotopy strategies are derived to reduce the computational time of the optimization method, which are more practical for real-world applications. The proposed method is verified on eight biological datasets, experimental results show that our method can achieve higher classification accuracy with fewer number of selected features than the approximate convex counterparts and other state-of-the-art feature selection methods.},
  archive      = {J_IDA},
  author       = {Sun, Zhenzhen and Yu, Yuanlong},
  doi          = {10.3233/IDA-205724},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {57-73},
  shortjournal = {Intell. Data Anal.},
  title        = {Robust multi-class feature selection via l2,0-norm regularization minimization},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Information granularity-based incremental feature selection
for partially labeled hybrid data. <em>IDA</em>, <em>26</em>(1), 33–56.
(<a href="https://doi.org/10.3233/IDA-205560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection can reduce the dimensionality of data effectively. Most of the existing feature selection approaches using rough sets focus on the static single type data. However, in many real-world applications, data sets are the hybrid data including symbolic, numerical and missing features. M eanwhile, an object set in the hybrid data often changes dynamically with time. For the hybrid data, since acquiring all the decision labels of them is expensive and time-consuming, only small portion of the decision labels for the hybrid data is obtained. Therefore, in this paper, incremental feature selection algorithms based on information granularity are developed for dynamic partially labeled hybrid data with the variation of an object set. At first, the information granularity is given to measure the feature significance for partially labeled hybrid data. Then, incremental mechanisms of information granularity are proposed with the variation of an object set. On this basis, incremental feature selection algorithms with the variation of a single object and group of objects are proposed, respectively. Finally, extensive experimental results on different UCI data sets demonstrate that compared with the non-incremental feature selection algorithms, incremental feature selection algorithms can select a subset of features in shorter time without losing the classification accuracy, especially when the group of objects changes dynamically, the group incremental feature selection algorithm is more efficient.},
  archive      = {J_IDA},
  author       = {Shu, Wenhao and Yan, Zhenchao and Chen, Ting and Yu, Jianhui and Qian, Wenbin},
  doi          = {10.3233/IDA-205560},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {33-56},
  shortjournal = {Intell. Data Anal.},
  title        = {Information granularity-based incremental feature selection for partially labeled hybrid data},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improvements of bat algorithm for optimal feature selection:
A systematic literature review. <em>IDA</em>, <em>26</em>(1), 5–31. (<a
href="https://doi.org/10.3233/IDA-205455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bat Algorithm (BA) has been extensively applied as an optimal Feature Selection (FS) technique for solving a wide variety of optimization problems due to its impressive characteristics compared to other swarm intelligence methods. Nevertheless, BA still suffers from several problems such as poor ex ploration search, falling into local optima, and has many parameters that need to be controlled appropriately. Consequently, many researchers have proposed different techniques to handle such problems. However, there is a lack of systematic review on BA which could shed light on its variants. In the literature, several review papers have been reported, however, such studies were neither systematic nor comprehensive enough. Most studies did not report specifically which components of BA was modified. The range of improvements made to the BA varies, which often difficult for any enhancement to be accomplished if not properly addressed. Given such limitations, this study aims to review and analyse the recent variants of latest improvements in BA for optimal feature selection. The study has employed a standard systematic literature review method on four scientific databases namely, IEEE Xplore, ACM, Springer, and Science Direct. As a result, 147 research publications over the last ten years have been collected, investigated, and summarized. Several critical and significant findings based on the literature reviewed were reported in this paper which can be used as a guideline for the scientists in the future to do further research.},
  archive      = {J_IDA},
  author       = {Al-Dyani, Wafa Zubair and Ahmad, Farzana Kabir and Kamaruddin, Siti Sakira},
  doi          = {10.3233/IDA-205455},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {5-31},
  shortjournal = {Intell. Data Anal.},
  title        = {Improvements of bat algorithm for optimal feature selection: A systematic literature review},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022e). Editorial. <em>IDA</em>, <em>26</em>(1), 1–3. (<a
href="https://doi.org/10.3233/IDA-210005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IDA},
  doi          = {10.3233/IDA-210005},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {1-3},
  shortjournal = {Intell. Data Anal.},
  title        = {Editorial},
  volume       = {26},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
