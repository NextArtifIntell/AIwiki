<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>DINT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="dint---59">DINT - 59</h2>
<ul>
<li><details>
<summary>
(2022). About the author. <em>DINT</em>, <em>4</em>(4), 1033–1054.
(<a href="https://doi.org/10.1162/dint_x_00187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abdullahi Kawu is interested in research in Human-Computer Interaction, Digital Health and ICT4D, hence most of his works are in those domains. He is passionate about people and technology, in particular exploring their engagements with technology. He is currently a Lecturer at Ibrahim Badamasi Babangida University, Lapai, Nigeria and a PhD research fellow with TU Dublin under the Science Foundation Ireland (SFI) Centre for Research Training in Digitally-Enhanced Reality (d-real) program. Earlier on, he obtained an MSc in Advanced Computer Science (Distinction) with interest in Human-Computer Interaction from Newcastle University, UK. He has also worked as a Consultant Staff to international development organisations like Malaria Consortium, World Bank and UNDP where he had the rare opportunity to learn and apply technical, leadership, project management, and Monitoring and Evaluation (M&amp;amp;E) skills in health projects.Email address: abdullahikawu@ibbu.edu.ng ORCID: 0000-0003-2531-9539Akinyinka Tosin Akindele is an instructional Designer and eTutor at LAUTECH Open and Distance Learning (LODLC), Nigeria. He also works as eLearning Consultant for Kampala International University, Uganda. He has over 8 years’ experience and is skilled in various eLearning technologies such as administration of LMS, curriculum and course authoring, creation and editing of multimedia (videos, animations and graphics) etc. He has trained diverse stakeholders on Blended Learning and actively participating in several eLearning projects locally and internationally including Partnership for Blended Learning (PEBL) West Africa sponsored by Association of Commonwealth Universities; Carbon Literacy for Youth Employability and Job Creation by British Council; Digital Innovation Skill Hub (DISH) by Dutch Ministry of Foreign Affairs Orange Knowledge Program etc. Mr Akindele holds an MSc degree in Computer Science from LAUTECH, Nigeria and he is presently pursuing his Ph.D. He has authored several articles on Distance Education and application of Artificial Intelligence to Health, Education and other related areas.Email address: akinyinka.akindele@kiu.ac.ug ORCID: 0000-0002-7027-466XAli Mtiraoui, a graduate of the Faculty of Medicine of Sousse (MD), the University of Montreal (MSc, community health) and the Pierre and Marie Curie University of Paris (statistics applied in epidemiology), is Director of the Laboratory of research “Quality of care and management of health services”, Former President of the University of Sousse, Honorary Dean and former Director of the Department of Family and Community Medicine of the Faculty of Medicine of Sousse. The quality of services and the management of services (education and health) are at the center of his professional concerns. He has worked at all levels of Tunisia&#39;s health care system and has carried out several consultation and expertise mandates in several fields, both nationally and internationally (development of intervention plans at the regard to health problems, design of curriculum &amp;amp; training programs, management of health services &amp;amp; mobilization of human resources, strategic planning, accreditation and certification, etc.).Email address: ali.mtiraoui@gmail.com ORCID: 0000-0002-6990-955XAliya Aktau received her MSc degree in Computer Science from Leiden University, The Netherlands, in 2020. She is now a PhD candidate at Leiden University Medical Center (LUMC) and teaching Data Collection, Wrangling, Analysis and Visualization at Suleyman University, Kazakhstan. Her research interests include FAIR Data Science and FAIR Data Management. She works as a data curator for medical health research.Email address: aleka.aktau@gmail.com; a.aktau@lumc.nl ORCID: 0000-0003-4942-2725Anthony Wachira graduated from the University of Nairobi with a BSc. Honors in Mathematics and Computer Science in 1988 and an MBA in Management Information Systems and Strategic Management for the same University in 2001. His MBA project was titled Ergonomic Factors Considered in Information Systems Implemented in Kenya: A Case of Firms in Nairobi. He is currently enrolled for PhD in Healthcare Management at the Institute of Healthcare Management of the Strathmore Business School — Strathmore University. He has been deeply involved in research on the provision of ICT solutions across many sectors and at various levels, the last two being ICT Services Director, Strathmore University and GM-ICT, Kenya Airports Authority. He chaired the inter-agency committee on border security in 2007, where one of the principal outcomes was the proposed single identification source for civil registration and vital statistics for all persons within the territory of Kenya using biometric data capture with the objective of creating Big Data.Email address: anto.wash@gmail.com ORCID: 0000-0002-0344-4403António Cartaxo (1987, Lisbon) visited in 2019 a research project on HIV prevention and care in Coastal Kenya, after which he became interested in access to healthcare. Since January 2020 he has been a PhD aspirant at Leiden University within the Globalisation Accessibility Innovation and Care network. His research focuses on participation in digital health innovation and health orientations in informal settlements in Nairobi, Kenya.Email address: am.cartaxo@gmail.com ORCID: 0000-0002-1276-1179Araya Abrha Medhanyie holds a PhD and is associate professor of public health at the School of Public Health at Mekelle University, Ethiopia. He has seventeen years of work experience in teaching, research, and community service. His research interests and professional career focus mainly in Global Health and Development. He is interested and has been building his research career in multidisciplinary and implementation research that integrates health systems, maternal and newborn health, health systems leadership and governance, health policy, digital Health and social transformation. Methodologically, he is interested and keen in specializing his capacity in implementation research, diffusion of innovations and scale-up of proven health interventions. He is passionate about serving humanity through research, education and leadership. He enjoys reading and writing about social change, leadership and development. He is Country Coordinator of VODAN-Africa.Email address: araya.medhanyie@gmail.com ORCID: 0000-0002-9328-684XAwotunde Joseph Bamidele received his B.Tech. degree in Mathematics/Computer Science from Federal University of Technology, Minna, Nigeria, in 2007. M.Sc. and Ph.D. degrees in Computer Science from the University of Ilorin, Ilorin, Nigeria, in 2014 and 2019 respectively. Since 2019, he has been a Lecturer with the Department of Computer Science, University, of Ilorin, Ilorin, Nigeria. He is the author of more than 40 articles, 30 chapter in book, and more than 25 Conference Proceedings in reputable outlets like Elsevier, Springer Taylor and Francis among others. His research interests include Information Security, Cybersecurity, Bioinformatics Artificial Intelligence, Internet of Medical Things, Wireless Body Sensor Networks, Wireless Networks, Telemedicine, Medical Imaging, Software Engineering, and Biometrics. He is a member of International Association of Engineers and Computer Scientist (MIAENG), Computer Professional Registration Council of Nigeria (MCPN), Nigeria Computer Society (MNCS), and Internet Society.Email address: awotunde.jb@unilorin.edu.ng ORCID: 0000-0002-1020-4432Balyejusa Gusite is a staff member in the directorate of research, innovation, consultancy and extension of Kampala international university serving as a data communications officer. He is also a data steward (Expert) in virus outbreak data network (VODAN-A). Gusite is currently pursuing a masters of science in information systems (Msc.IS) at Kampala International University, He holds a first class Bsc. Information technology from KIU. As an information technology personnel, Gusite is a freelancer developer, with bias in automation systems, data science, deep learning, Machine learning, computer vision and security systems.Email address: gusite.balyejusa@kiu.ac.ug ORCID: 0000-0003-4515-6052Bert Meerman is the Director of the GO FAIR FOUNDATION (GFF), based in Leiden, the Netherlands. Involved in different EOSC Projects (EOSC Secretariat and EOSC Nordic). GFF focus is on the promotion, protection and the correct implementation of the FAIR Principles, next to the transfer of knowledge on the application of FAIR.Email address: b.meerman@gofairfoundation.org ORCID: 0000-0002-0071-2660Dwy Bagus earned his Master degree in Electrical Engineering and Informatics from Institut Teknologi Bandung (ITB), Indonesia, in 2018. He is now a lecturer and software architect in Politeknik Statistika STIS, Indonesia. His research interests include software engineerings such as cloud computing, blockchain, and artificial intelligence.Erik Flikkenschild was educated in the early days of computer science as an electronic engineer (innovative curriculum by TU Delft, Antony Fokker school and MTS The Hague (1974). He is now an information manager and IT architect (LUMC) and Deputy Director (Go-FAIR foundation). His computer science interest is the design of the Internet of FAIR Data Services with a focus on data protection, starting with policy (risk assessment) translating in the IT design of access control measures.Email address: e.flikkenschild@lumc.nl Alternative email: erikf@gofair.foundation ORCID: 0000-0002-7285-1651Ezekiel Ogundepo In the fields of mathematics and statistics, Ezekiel is a knowledgeable and creative professional. He holds a master&#39;s degree from the African Institute for Mathematical Sciences (AIMS), Rwanda, where he received a scholarship from MasterCard, and a first-class degree in statistics from the University of Ilorin, Nigeria. He has experience with the Rwanda Revenue Authority (RRA) and is a leading expert in advanced statistical modelling. He worked on the RRA team that developed the interactive taxpayer data portal and automated key statistical reports needed by internal and external users. Ezekiel is currently employed by 54gene (a biotechnology company) as a Data Specialist and has made contributions to the ralger web scraping R package and the Big Book of R. He is a certified instructor for Rstudio Tidyverse, a data steward at Virus Outbreak Data Network (VODAN) Africa and Asia, and an active member of the Africa R programming community.Email address: ezekiel@datasciencenigeria.ai; ogundepoezekiel@gmail.comEzra Mwesigwa Highly enthusiastic about Health Informatics and ICT for development (ICT4D). Ezra has proficiency in Information Systems Analysis, Design and Development with over 6 years’ experience delivering electronic knowledge management solutions currently working as a DevOps Engineer at Makerere University Kampala (MAK) and Kampala International University (KIU). With a Msc. and Bsc in Information Systems, Ezra has been part of local and international project establishments in and outside Uganda serving within various technical capacities. Currently part of a wider multinational VODAN-Africa team developing and piloting a FAIR data architecture in 88 facilities across 7 countries in Africa, DevOps Consultant towards responsible anti-microbial use in refugee settlements within Uganda; a project funded by Pfizer, ICT consultant working through Makerere University Climate Change and Research Initiative-MUCCRI to develop a national climate change Knowledge Management System funded by Food and Agriculture Organization among many other notable involvements.Email address: mezra@cit.ac.ug ORCID: 0000-0003-2125-1012Esther Thea Inau is a PhD student studying in the Medical Informatics Department at the Universitätsmedizin (University of Medicine) Greifswald, Germany. Her PhD studies are based on implementing and evaluating the FAIRness of data obtained from health cohort studies in Germany.Email address: inaue@uni-greifswald.de ORCID: 0000-0002-8950-2239Francisca Oladipo, is a Professor of Computer Science and pioneer Director, Quality Assurance, Federal University Lokoja (FUL), Nigeria. She is a Consultant at the Tilburg School of Humanities and Digital Sciences of Tilburg University, Netherlands, and had served previously at Kampala International University (KIU), Uganda as the Director of Research, Innovations, and International relations. She has recently been appointed the Vice-Chancellor and Chief Executive Officer of Thomas Adewumi University, Nigeria.Email address: francisca.oladipo@kiu.ac.ug ORCID: 0000-0003-0584-9145Francis Kinyua Gathua facilitates development and implementation of appropriate youth and women livelihoods strategies; self and wage employment for self sustenance and resilience in Nairobi slums. With over 10 years in non-profit sector, Francis has solid, documented experience in project cycle management, behavioural/cognitive skills development, high maturity and knowledge of working with young people, team building, strategic planning, mentorship, collaboration, monitoring and evaluation. Francis is a certified life skills facilitator/trainer and manages Kamukunji Community Empowerment Initiative&#39;s (KCEI) vulnerable youth and women enablement project. Francis Holds a B.A and MA in Sociology from University of Nairobi.Email address: kgathua@gmail.comFredrick Obwanda is a healthcare management expert from Kenya, who worked at the Ministry of Health leading institutional, and policy agenda at the National Blood Transfusion Services, in addition to being a Sub-County Hospital Manager and Linked to Tangaza University at present.Email address: fobwanda@gmail.com ORCID: 0000-0002-8275-0926Gertjan van Stam has been involved with ICT in Africa since 1987. He holds a PhD in Culture Studies from Tilburg University, an MTech in ICT from Nelson Mandela University, and an engineering degree in telecommunications. His activities focus on mechanisms at the intersection of society and technology.Email address: gertjan@vanstam.net ORCID: 0000-0003-4618-6106Getu Tadele Taye is a lecturer in the department of Health Informatics at the college of health sciences Mekelle University (MU), Ethiopia. He has worked as a software engineer for almost 3 years prior to joining MU. He is an active member of digital health research and development center at MU. Currently, he is also working as country technical lead in the project Virus Outbreak Data Network Africa and Asia (VODANA). VODANA is a Global Open Findable, Accessible, Interoperable, and Reusable (GO FAIR) Implementation Network set up to help fight the COVID-19. He has vast research experience in Medical and IT Convergence technology and participated in national and international conferences and published journal papers on prestigious peer-review journals. He is interested in the concepts and technologies in data science, data FAIRification, eHealth Architecture (eHA) and making HISs interoperable. He holds a master&#39;s degree in Medical IT Convergence Engineering from Kumoh National Institute of Technology, South Korea.Email address: getu.tadele@gmail.com; getu.tadle@mu.edu.et ORCID: 0000-0002-9965-1801Hauwa Limanko Ibrahim is a research assistant with the New and Emerging Technology Research Group (NETReg), IBB University Lapai, Nigeria. She is interested in the design and evaluation of novel interactive technologies in low resource communities.Email address: ibrahimhauwa977@gmail.com ORCID: 0000000240566442Ibrahim Abdulahi is Head of the Department of Computer Science, Ibrahim Badamasi Babangida University, Lapai. He is Director ICT and Chairman New and Emerging Technologies Research group (NETREG). Ibrahim holds a PhD in Computing, a Senior Member of the IEEE. His research interest include: Future Internet (Information-Centric Networking), Operating Systems, Algorithms, AI, Bigdata, and Digital-Health. A Lecturer of Computing and the Director of Information and Communication Technology at IBB University, Lapai. Nigeria. He is a facilitator, editor and content writer of several Learning Management System (LMS) solutions.Email address: ibrojay01@gmail.com; ibrojay01@ibbu.edu.ng ORCID: 0000-0002-3467-1203Jamilu Yahaya Maipan-uku (Mr.) received his B.Sc. in Computer Science from Ibrahim Badamasi Babangida University Lapai (IBBUL, 2010), Niger State, Nigeria. Also, holds M.Sc. in Computer Networks from Universiti Putra Malaysia (UPM, 2016), Malaysia and Ph.D. (in view) in Computer Information Systems at Near East University, Cyprus with about 15 technical and international conference papers across SCOPUS, DBLP databases. His research interest includes; Grid Computing, Cloud Computing, Cyber Security, Artificial Intelligence, Machine Learning, and Deep Learning. He is a member of Nigeria Computer Society (NCS) and Internet Society of Nigeria (ISOC).Email address: jymaipanuku@ibbu.edu.ng ORCID: 0000-0001-8071-7295Mr. Joseph Elijah (M.Eng.) is a lecturer in the Department of Computer Science, Ibrahim Badamasi Babangida University, Lapai, Nigeria. He is a member of the council for the registration of Engineers in Nigeria, a member of the association for computing machinery, and the international association of Engineers (IAENG). His current research interests include intelligent systems, cognitive radio, microstrip antenna, and digital health.Email address: ibrojay01@gmail.com ORCID: 0000-0002-9922-9029Dr Katy Wolstencroft is an Assistant Professor in Bioinformatics at Leiden University. She has a Bachelor in Biochemistry (University of Leeds) and a Master and PhD in Bioinformatics (University of Manchester. Her research focuses on data and knowledge integration in the life sciences. She is an author of the FAIR guiding principles and is instrumental in the development of several FAIR data initiatives in systems biology, bioimaging and biomedicine, in addition to her activities in VODAN.Email address: k.j.wolstencroft@liacs.leidenuniv.nl ORCID: 0000-0002-1279-5133Klara Smits works at Tilburg University as a PhD candidate on the topic of human trafficking of Eritrean refugees in the digital era. Smits is interested in forced movement, and particularly the aspects of digitalisation, in the nexus of environmental, political and social problems. She has a MSc. in Forest and Nature Conservation with a specialisation in Sustainable Development Diplomacy.Email address: klarasmits@gmail.com ORCID: 0000-0003-1713-7057Kudakwashe Chindoza received his MCom Information Systems degree in 2015 (GZU), a BSc in Information Systems in 2006 (MSU) and a Post-Graduate Diploma in Higher and Tertiary Education in 2019 (GZU), Zimbabwe. He is a technical expert of VODAN-Africa in Zimbabwe. He is a PhD student with Tilburg University.Email address: chindozak@gmail.com; kchindoza@gzu.ac.zw (Official email) ORCID: 0000-0002-8346-5211Kibrom Fekadu Berhe is a Lecturer and researcher of Public policy and Development at Mekelle University, Ethiopia. He obtained MA degree in Public Policy and Sustainable Development from University of Gondar, Ethiopia in 2013 and Masters of Environmental Management from Massey University, New Zealand in 2015. He has over 10 years of experience in teaching research and community services in higher education institutions. He is currently working in consultancy, mediation, advocacy and research in Belgium.Email address: kiblid@gmail.com ORCID: 0000-0003-1728-5076Marek Suchánek is PhD student at Czech Technical University in Prague and University of Antwerp (double-degree programme). His research topic is about connecting conceptual modelling and software implementations beyond model-driven development. He obtained both master&#39;s and bachelor&#39;s degrees at CTU in Prague in Information Systems and Management. He actively participates on various projects such as Data Stewardship Wizard or FAIR Data Point.Email address: marek.suchanek@ds-wizard.org ORCID: 0000-0001-7525-9218Mariam Basajja is currently pursuing a PhD in Computer Science at Leiden University in the Netherlands. She obtained a master&#39;s degree in Advanced Computing, machine Learning and Data mining from the University of Bristol, UK and also has a master of Science in Computational Intelligence from University of Nairobi, Kenya. She also holds a bachelors in Applied Computer Technology with a concentration in Software Engineering from United States International University Africa. Her main areas of interest are around FAIR data, big data, databases, data analytics, cloud computing, ICT Infrastructure and others.Email address: mariam.basajja@gmail.com ORCID: 0000-0001-7710-8843Mariem Ghardallou received her Medical doctor degree from the Faculty of Medicine of Sousse, Tunisia, in 2011. She is now an Associate Professor in Community and Preventive Medicine at the Faculty of Medicine of Sousse, University of Sousse, Tunisia. She is currently the vice-dean of research and valorization of expertise at the Faculty of Medicine of Sousse and the country coordinator for Tunisia of VODAN Africa.Email address: ghardallou.m@gmail.com Alternative Adress: Mariem.Ghardallou@famso.u-sousse.tn ORCID: 0000-0001-9289-722XDr. Mia Stokmans is an associate professor at Tilburg University, Tilburg School of Humanities and Digital Sciences. Between 2008 and 2010 she was involved in the EUCIM-TE Comenius project co-funded by the European Commission, DG Education and Culture within the Lifelong Learning Programme to improve the pre- and in-service training of all teachers for their work with immigrant pupils by elaborating a competence-based European Core. Between 2011 and 2012 she participated in the ARKA-project about the valorisation of human capital of migrants in the European Union. She has participated in the NWO project Cost Benefit Analysis of Social Protection on Social Economic Resilience, the NWO project Mixed Migration Ethiopia, and the ZonMW project about care processes for dementia. Her main fields of interest are the role of attitudes and emotions in human decision making, social processes for behavioral change and mixed method approaches in doing research.Email address: M.J.W.Stokmans@tilburguniversity.edu ORCID: 0000-0002-7593-9632Mirjam van Reisen is Professor International Relations, Innovation and Care at Tilburg University and Professor of FAIR Data Science at the Leiden University Medical Centre (LUMC) at Leiden University. Van Reisen is Research Leader of the Globalization, Accessibility, Innovation and Care (GAIC) network. Her teaching experience includes, among others, the University of Pavia, Tilburg University, Amsterdam University College, Leiden University and the College of Europe. Van Reisen is the Director of the organisation Research Advisors &amp;amp; Experts Europe (RAEE) in Brussels. Van Reisen is the Coordinator of the Virus Outbreak Data Network (VODAN) Africa implementation network. Van Reisen was a member of the Dutch Advisory Council on International Affairs (AIV) and Chair of the Development Assistance Committee (COS) from 2013 to 2020. Van Reisen received the Golden Image Award in 2012 by President Ellen Johnson Sirleaf.Email address: mirjamvanreisen@gmail.com ORCID: 0000-0003-0627-8014Misha Stocker is a consultant with Research Assistants and Experts Europe in Brussels. He studied European governance with a double major from the University of Konstanz, Germany, and the University of Utrecht, The Netherlands. He received his bachelor degree in Liberal Arts and Sciences with a major in political science from the University College Roosevelt from Utrecht University. He carried out his internship in the Go FAIR foundation and his thesis investigated the EU policy making on FAIR Data.Email address: mishastocker@gmail.com ORCID: 0000-0003-0347-9953Morgane Wirtz is a PhD student at Tilburg University, a freelance journalist and a researcher for EEPA. She focuses on human right abuses, security in Sahel, migration and human trafficking on the Central Mediterranean Road. Based in Tunisia, she works for Le Point Afrique, Inkyfada and Hans Lucas. She is also a documentary filmmaker.Email address: morgane.wz@gmail.com ORCID: 0000-0002-2514-5797Mouhamed Mpezamihigo born in Uganda, is Vice Chancellor of Kampala International University and leader of the programme of the Digital Innovation and Skills Hub (DISH), and Chair of the Virus Outbreak Data Network - Africa, VODAN-Africa. He is board member of the African Institute for Capacity Development (AICAD), and Executive Committee member of the Interuniversity Council for East Africa (IUCEA) among many other obligations he holds.Email address: vc@kiu.ac.ug ORCID: 0000-0002-9700-3034Munyaradzi Mawere is a double professor, being a Full Professor of African Studies at Great Zimbabwe University (GZU), Zimbabwe and a Professor Extraordinarius of Interdisciplinary Research at the University of South Africa (UNISA), South Africa. Mawere has 310 publications to his credit, including 91 books, and over 200 book chapters and peer-reviewed journal articles published with internationally acclaimed publishers.Email address: munyaradzimawerem@gmail.com ORCID: 0000-0002-3684-6089Nambobi Mutwalibi is a Vodan Expert of the Virus Outbreak Data Network (VODAN) Africa implementation network. He is also a research assistant at Motion Analysis Research Lab, Islamic University in Uganda. He was a research assistant in the Technical and Vocational Education (TVE) department at Islamic University of Technology, Bangladesh (IUT, 2018). He holds a BSc. Technical Education (Islamic University of Technology, Dhaka, Bangladesh) specializing in computer science and engineering. His research interest on Disruptive Innovations, FAIR Data, JTBD, Wargaming Strategy, Game theory, Coopetition, Blue Ocean Strategy, Blended learning, Green Skills, TVET and ICTs in developing countries. He can be reached via his website: www.nambobi.com, email: hello@nambobi.com and contact +256701044034 Email address: nambobi.mutwalibi@kiu.ac.ug ORCID: 0000-0001-6822-616XObinna Osigwe is a Digital Media Professional at Kampala International University, Uganda and the Communications Lead at Virus Outbreak Data Network Africa (VODAN-Africa). His experience and competence spans across Computer Networking, Digital Marketing, Data Analysis, Online Reputation Management, Performance Measurement and has Consulted for several organizations in Nigeria and Uganda. Obinna has a Bachelor of Science in Computer Science from Nnamdi Azikiwe University Nigeria, and is currently a Master&#39;s Student in Project Management.Email address: obinna.osigwe@kiu.ac.ug ORCID: 0000-0001-7825-3591Oluwole Olumuyiwa Afolabi has more than a decade of experience working in an international organisation and has over time built his proficiency in PHP, MySQL, JavaScript, Ajax and several other programming languages. He has proficient skills with CSS, Self-Developed Content Management System (CMS), Microsoft Office Packages, CorelDraw, and a very good understanding of design and the use of the Adobe Creative Suite. He has obtained professional certifications including; PHP OOP: Object-Oriented Programming for Beginners - Certificate of Completion from UDEMY – 2018, Online Cambridge Certified Web Publisher from Cambridge Intercontinental University-2010, and a Diploma in Advanced Web Development from ECAND Nig. Ltd-2009. He is currently working with Kampala international University as a Web Administrator.Email address: oluwole.afolabi@kiu.ac.ug ORCID: 0000-0002-4007-6363Putu Hadi received his M.Sc degree in ICT in Business and the Public Sector from Leiden University, the Netherlands, in 2021. He is a PhD student with the Leiden University Medical Center (LUMC). He is now an ICT expert in Central Bureau of Statistics, Indonesia. His research interests include data governance and principles such as FAIR and open data. He is a technical team lead in VODAN-Africa on implementation in health facilities.Email address: putu.hadi.purnama.jati@umail.leidenuniv.nl ORCID: 0000-0002-6533-3709Reginald Nalugala is a postgraduate tutor at Tangaza University, specializing in social transformation. He trains research students in the PhD and Masters programme to draw on the SDGs to foster social transformation. At VODAN Africa and Asia, he is the country lead for Kenya where he coordinates the VODAN activities in Kenya. SDG 3 highlights the importance of health and wellbeing. This situation has been made worse by the COVID-19 pandemic. Reginald and the team are studying different methodologies on how to improve livelihoods of households affected by COVID-19 pandemic.Email address: reg.nanales@gmail.com ORCID: 0000-0002-3737-9777Ruduan Plug is an associated researcher with the Leiden University Medical Center and a scientist in machine learning and artificial intelligence at monitoring &amp;amp; control services of TNO. Previously he has been named a Google Scholar for his work on OpenAI&#39;s scalable meta-learning algorithm and he has worked with CEDAR at the Stanford Center for Biomedical Informatics Research. In addition, he has acted as a technical coordinator for VODAN, is active within the interdisciplinary GAIC research group of Tilburg University and is an ambassador for FAIR data and the European Open Science Cloud (EOSC) at the GO FAIR foundation. His research primarily focuses on the application and adaptation of machine learning, artificial intelligence and the architecture of interoperable, federated and distributed computational ecosystems for data-driven applications.Email address: ruudplug@gmail.com ORCID: 0000-0001-5146-6116Samson Yohannes Amare is a lecture in the department of Software Engineering, Mekelle University (MU). He is an active member of digital health research and development center at MU doing research, teaching and software development. Samson has been involved in most of the digital health activities done in MU. He has also been working on a couple of software development projects and implementation researches. He is actively working on the project Virus Outbreak Data Network Africa and Asia (VODANA), which is a Global Open Findable, Accessible, Interoperable, and Reusable (GO FAIR) Implementation Network set up to help fight COVID-19. He has also experience on software architecture and enterprise architecture development working closely with OpenHIE and the ministry of health. He has contributed during digital health blueprint development by the ministry of health. His research interests include digital health and data science. He holds a master&#39;s degree in Informatics Engineering from University of Algarve, Portugal.Email address: samsonya@gmail.com; samson.yohannes@mu.edu.et (Official email)Sara Nodehi received her MSc degree in ICT in Business and the Public Sector from Leiden University, the Netherlands, in 2021. Immediately after graduation, she started her work as a Ph.D. candidate at the Open University, the Netherlands. Her research interests include IT governance, Business/IT alignment, Information security management, and digital transformation.Email address: sara.nodehi95@gmail.com (preferred); s.nodehi@umail. leidenuniv.nl (work address) ORCID: 0000-0002-2919-1336Sakinat Folorunso is a computer science lecturer and researcher at Olabisi Onabanjo University, Ago Iwoye, Ogun State, Nigeria. She had a B. Tech in Computer Science from the Federal University of Technology, Akure, Ondo State, Nigeria. She also had an M. Sc and PhD in Computer science for the University of Ibadan, Ibadan, Oyo State, Nigeria. She has authored many journals and conference articles in Data mining, Machine Learning and Data Science.Email address: sakinat.folorunso@oouagoiwoye.edu.ng ORCID: 0000-0002-7058-8618Tesfit Gebremeskel Gebreslassie is a lecturer of Health Informatics at the school of public health, Mekelle University (MU). He has eight years of experience in electronic Health Management Information Systems as a program implementer and consultant to the Ministry of Health in the area of eHealth and health informatics initiatives. He has been engaged in the development and implementation of different health-related electronic health system. He has been working in the areas of eHealth Architecture and interoperability in collaboration with OpenHIE. He spends most of his time in reading and practising health information and innovation related trending ideas and developments. Tesfit is head of the digital health research and development center at Mekelle University. He holds a master&#39;s degree in Biostatistics and Health Informatics.Email address: tesfitgebremeskel@gmail.com ORCID: 0000-0001-9389-5584Tigist Abtamu is an Information Science expert with a multi-disciplinary orientation and qualifications. She worked in the field of information science for more than 10 years in the Ethiopian Public Health Institute. Currently she is working as e-health coordinator at Addis Ababa University, School of Public Health, Capacity Building and Mentorship Program to support the Ministry of health initiative in the area of Health Information System development in the country by strengthening the Health information system aiming to build local capacity to transform health data quality and information use for evidence-based decision making.Email address: tigist.habtamu@aau.edu.et; tigist12@yahoo.com ORCID: 0000-0001-6082-1060William Muhadi Nandwa holds a BSc. Microbiology and Biotechnology and an MSc. Epidemiology. He has worked at Pumwani Maternity Hospital in Kenya as a data steward under USAID Afya Jijini. Currently, he is the lead data steward and Country Coordinator for the VODAN-Kenya team. He also brings together the forum of all Country Coordinators of VODAN-Africa. He has undertaken further training in data management technology under the Phillips Foundation. His research experiences has been fundamental in the development of this paper.Email address: wmnandwa77@gmail.com ORCID: 0000-0002-2994-4916Wondimu Ayele is Assistant Professor Biostatistics and Health Informatics at School of Public Health, Addis Ababa University. Assistant Professor and Director Health Information Capacity Building and Mentorship Project (Preventive medicine). He is a coordinator in the Virus Outbreak data Network - Africa. He studied at the Institute of Medicine, Epidemiology, Health Informatics and Biometer, Martin Luther University, Halle (Saale), Germany. Data manager for Ebola Response (Diseases Surveillance).Email address: wondimu.ayele@aau.edu.et; wondaay@gmail.com ORCID: 0000-0001-5899-347XWhitney Atieno Otieno is an Highway Engineering student at Kenya Institute of Highways and Building Technology. She is a community worker at Majengo, Pumwani, in Nairobi, Kenya and a leader in the Kamukunji Community Empowerment Initiative (KCEI). She developed an interest with community work for she grew up in slums. She is a women&#39;s rights activist. In 2018, she joined Kenya Women in Justice Centres group. She is a community leader and associated with the Tangaza University College initiative with the community organization KACPEN on social transformation.Email address: atienowhitney6@gmail.comYan Liang has received a double BA from University of Minnesota Morris in Economics and Statistics and a MSc in Computer Science from Leiden University. Her interests are in cloud computing and big data management and she has contributed to the core architecture of VODAN. Yan is currently active as a data engineer at KPMG in Digital Assurance &amp;amp; Innovation and is a chair at the KPMG Dani Young Board.Email address: y.liang.2@umail.leidenuniv.nl; liangyan12138@gmail.com ORCID: 0000-0002-3860-725XYi Lin received his M.Sc degree in ICT in Business and Public Sectior from Leiden University, Netherlands, in 2021. He is now a research assistant at Leiden Institute of Advanced Computer Science (LIACS), Leiden University. His research interests focus on data analysis for business insight.Email address: y.lin@liacs.leidenuniv.nl ORCID: 0000-0002-9833-3457Zohra Touati received her Professional Master&#39;s Degree in Information and Communication Technology in 2008. She is now a Professor in Computer Science at the Faculty of Medicine of Sousse, University of Sousse, Tunisia.Email address: zohra.touati@live.fr ORCID: 0000-0002-8329-706X},
  archive      = {J_DINT},
  doi          = {10.1162/dint_x_00187},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {1033-1054},
  shortjournal = {Data Intell.},
  title        = {About the author},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The impact of COVID-19 and FAIR data innovation on distance
education in africa. <em>DINT</em>, <em>4</em>(4), 1013–1032. (<a
href="https://doi.org/10.1162/dint_a_00184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Prior to the advent of the COVID-19 pandemic, distance education, a mode of education that allows teaching and learning to occur beyond the walls of traditional classrooms using electronic media and online delivery practices, was not widely embraced as a credible alternative mode of delivering education, especially in Africa. In education, the pandemic, and the measures to contain it, created a need for virtual learning/teaching and showcased the potential of distance education. This article explores the potential of distance education with an emphasis on the role played by COVID-19, the technologies employed, and the benefits, as well as how data stewardship can enhance distance education. It also describes how distance education can make learning opportunities available to the less privileged, geographically displaced, dropouts, housewives, and even workers, enabling them to partake in education while being engaged in other productive aspects of life. A case study is provided on the Dutch Organisation for Internationalisation in Education (NUFFIC) Digital Innovation Skills Hub (DISH) project, which is implemented via distance education and targeted towards marginalised individuals such as refugees and displaced persons in Ethiopia, Somalia, and other conflict zones, aiming to provide them with critical and soft skills for remote work for financial remuneration. This case study shows that distance education is the way forward in education today, as it has the capability to reach millions of learners simultaneously, educating, lifting people out of poverty, and increasing productivity and yields, while ensuring that the world is a better place for future generations.},
  archive      = {J_DINT},
  author       = {Akindele, Akinyinka Tosin and Arulogun, Oladiran Tayo and Taye, Getu Tadele and Amare, Samson Yohannes and Van Reisen, Mirjam and Berhe, Kibrom Fekadu and Gusite, Balyejusa},
  doi          = {10.1162/dint_a_00184},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {1013-1032},
  shortjournal = {Data Intell.},
  title        = {The impact of COVID-19 and FAIR data innovation on distance education in africa},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Curriculum development for FAIR data stewardship.
<em>DINT</em>, <em>4</em>(4), 991–1012. (<a
href="https://doi.org/10.1162/dint_a_00183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The FAIR Guidelines attempts to make digital data Findable, Accessible, Interoperable, and Reusable (FAIR). To prepare FAIR data, a new data science discipline known as data stewardship is emerging and, as the FAIR Guidelines gain more acceptance, an increase in the demand for data stewards is expected. Consequently, there is a need to develop curricula to foster professional skills in data stewardship through effective knowledge communication. There have been a number of initiatives aimed at bridging the gap in FAIR data management training through both formal and informal programmes. This article describes the experience of developing a digital initiative for FAIR data management training under the Digital Innovations and Skills Hub (DISH) project. The FAIR Data Management course offers 6 short on-demand certificate modules over 12 weeks. The modules are divided into two sets: FAIR data and data science. The core subjects cover elementary topics in data science, regulatory frameworks, FAIR data management, intermediate to advanced topics in FAIR Data Point installation, and FAIR data in the management of healthcare and semantic data. Each week, participants are required to devote 7–8 hours of self-study to the modules, based on the resources provided. Once they have satisfied all requirements, students are certified as FAIR data scientists and qualified to serve as both FAIR data stewards and analysts. It is expected that in-depth and focused curricula development with diverse participants will build a core of FAIR data scientists for Data Competence Centres and encourage the rapid adoption of the FAIR Guidelines for research and development.},
  archive      = {J_DINT},
  author       = {Oladipo, Francisca and Folorunso, Sakinat and Ogundepo, Ezekiel and Osigwe, Obinna and Akindele, Akinyinka},
  doi          = {10.1162/dint_a_00183},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {991-1012},
  shortjournal = {Data Intell.},
  title        = {Curriculum development for FAIR data stewardship},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FAIR machine learning model pipeline implementation of
COVID-19 data. <em>DINT</em>, <em>4</em>(4), 971–990. (<a
href="https://doi.org/10.1162/dint_a_00182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Research and development are gradually becoming data-driven and the implementation of the FAIR Guidelines (that data should be Findable, Accessible, Interoperable, and Reusable) for scientific data administration and stewardship has the potential to remarkably enhance the framework for the reuse of research data. In this way, FAIR is aiding digital transformation. The ‘FAIRification’ of data increases the interoperability and (re)usability of data, so that new and robust analytical tools, such as machine learning (ML) models, can access the data to deduce meaningful insights, extract actionable information, and identify hidden patterns. This article aims to build a FAIR ML model pipeline using the generic FAIRification workflow to make the whole ML analytics process FAIR. Accordingly, FAIR input data was modelled using a FAIR ML model. The output data from the FAIR ML model was also made FAIR. For this, a hybrid hierarchical k-means (HHK) clustering ML algorithm was applied to group the data into homogeneous subgroups and ascertain the underlying structure of the data using a Nigerian-based FAIR dataset that contains data on economic factors, healthcare facilities, and coronavirus occurrences in all the 36 states of Nigeria. The model showed that research data and the ML pipeline can be FAIRified, shared, and reused by following the proposed FAIRification workflow and implementing technical architecture.},
  archive      = {J_DINT},
  author       = {Folorunso, Sakinat and Ogundepo, Ezekiel and Basajja, Mariam and Awotunde, Joseph and Kawu, Abdullahi and Oladipo, Francisca and Ibrahim, Abdullahi},
  doi          = {10.1162/dint_a_00182},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {971-990},
  shortjournal = {Data Intell.},
  title        = {FAIR machine learning model pipeline implementation of COVID-19 data},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Expanding non-patient COVID-19 data: Towards the
FAIRification of migrants’ data in tunisia, libya and niger.
<em>DINT</em>, <em>4</em>(4), 955–970. (<a
href="https://doi.org/10.1162/dint_a_00181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This article describes the FAIRification process (which involves making data Findable, Accessible, Interoperable and Reusable—or FAIR—for both machines and humans) for data related to the impact of COVID-19 on migrants, refugees and asylum seekers in Tunisia, Libya and Niger, according to the scheme adopted by GO FAIR. This process was divided into three phases: pre-FAIRification, FAIRification and post-FAIRification. Each phase consisted of seven steps. In the first phase, 118 in-depth interviews and 565 press articles and research reports were collected by students and researchers at the University of Sousse in Tunisia and researchers in Niger. These interviews, articles and reports constitute the dataset for this research. In the second phase, the data were sorted and converted into a machine actionable format and published on a FAIR Data Point hosted at the University of Sousse. In the third phase, an assessment of the implementation of the FAIR Guidelines was undertaken. Certain barriers and challenges were faced in this process and solutions were found. For FAIR data curation, certain changes need to be made to the technical process. People need to be convinced to make these changes and that the implementation of FAIR will generate a long-term return on investment. Although the implementation of FAIR Guidelines is not straightforward, making our resources FAIR is essential to achieving better science together.},
  archive      = {J_DINT},
  author       = {Ghardallou, Mariem and Wirtz, Morgane and Folorunso, Sakinat and Touati, Zohra and Ogundepo, Ezekiel and Smits, Klara and Mtiraoui, Ali and van Reisen, Mirjam},
  doi          = {10.1162/dint_a_00181},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {955-970},
  shortjournal = {Data Intell.},
  title        = {Expanding non-patient COVID-19 data: Towards the FAIRification of migrants’ data in tunisia, libya and niger},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data access, control, and privacy protection in the
VODAN-africa architecture. <em>DINT</em>, <em>4</em>(4), 938–954. (<a
href="https://doi.org/10.1162/dint_a_00180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Virus Outbreak Data Network (VODAN)-Africa aims to contribute to the publication of Findable Accessible, Interoperable, and Reusable (FAIR) health data under well-defined access conditions. The next step in the VODAN-Africa architecture is to locally deploy the Center for Expanded Data Annotation and Retrieval (CEDAR) and arrange accessibility based on the ‘data visiting’ concept. Locally curated and reposited machine-actionable data can be visited by queries or algorithms, provided that the conditions of access are met. The goal is to enable the multiple (re)use of data with secure access functionality by clinicians (patient care), an idea aligned with the FAIR-based Personal Health Train (PHT) concept. The privacy and security requirements in relation to the FAIR Data Host and the FAIRification workspace (to produce metadata) or dashboard (for the patient) must be clear to design the IT architecture. This article describes a (first) practice, a reference implementation in development, within the VODAN-Africa and Leiden University Medical Center community.},
  archive      = {J_DINT},
  author       = {Purnama Jati, Putu Hadi and van Reisen, Mirjam and Flikkenschild, Erik and Oladipo, Fransisca and Meerman, Bert and Plug, Ruduan and Nodehi, Sara},
  doi          = {10.1162/dint_a_00180},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {938-954},
  shortjournal = {Data Intell.},
  title        = {Data access, control, and privacy protection in the VODAN-africa architecture},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Proof of concept and horizons on deployment of FAIR data
points in the COVID-19 pandemic. <em>DINT</em>, <em>4</em>(4), 917–937.
(<a href="https://doi.org/10.1162/dint_a_00179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Rapid and effective data sharing is necessary to control disease outbreaks, such as the current coronavirus pandemic. Despite the existence of data sharing agreements, data silos, lack of interoperable data infrastructures, and different institutional jurisdictions hinder data sharing and accessibility. To overcome these challenges, the Virus Outbreak Data Network (VODAN)-Africa initiative is championing an approach in which data never leaves the institution where it was generated, but, instead, algorithms can visit the data and query multiple datasets in an automated way. To make this possible, FAIR Data Points—distributed data repositories that host machine-actionable data and metadata that adhere to the FAIR Guidelines (that data should be Findable, Accessible, Interoperable and Reusable)—have been deployed in participating institutions using a dockerised bundle of tools called VODAN in a Box (ViB). ViB is a set of multiple FAIR-enabling and open-source services with a single goal: to support the gathering of World Health Organization (WHO) electronic case report forms (eCRFs) as FAIR data in a machine-actionable way, but without exposing or transferring the data outside the facility. Following the execution of a proof of concept, ViB was deployed in Uganda and Leiden University. The proof of concept generated a first query which was implemented across two continents. A SWOT (strengths, weaknesses, opportunities and threats) analysis of the architecture was carried out and established the changes needed for specifications and requirements for the future development of the solution.},
  archive      = {J_DINT},
  author       = {Basajja, Mariam and Suchanek, Marek and Taye, Getu Tadele and Amare, Samson Yohannes and Nambobi, Mutwalibi and Folorunso, Sakinat and Plug, Ruduan and Oladipo, Francisca and van Reisen, Mirjam},
  doi          = {10.1162/dint_a_00179},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {917-937},
  shortjournal = {Data Intell.},
  title        = {Proof of concept and horizons on deployment of FAIR data points in the COVID-19 pandemic},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Possibility of enhancing digital health interoperability in
uganda through FAIR data. <em>DINT</em>, <em>4</em>(4), 899–916. (<a
href="https://doi.org/10.1162/dint_a_00178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The digital health landscape in Uganda is plagued by problems with interoperability and sustainability, due to fragmentation and a lack of integrated digital health solutions. This can be partly attributed to the absence of policies on the interoperability of data, as well as the fact that there is no common goal to make digital data and data infrastructure interoperable across the data ecosystem. The promulgation of the FAIR Guidelines in 2016 brought together various data stewards and stakeholders to adopt a common vision on data management and enable greater interoperability. This article explores the potential of enhancing digital health interoperability through FAIR by analysing the digital solutions piloted in Uganda and their sustainability. It looks at the factors that are currently hindering interoperability by examining existing digital health solutions in Uganda, such as the Digital Health Atlas Uganda (DHA-U) and Uganda Digital Health Dashboard (UDHD). The level of FAIRness of the two dashboards was determined using the FAIR Evaluation Services tool. Analysis was also carried out to discover the level of FAIRness of the digital health solutions within the dashboards and the most frequently used software applications and data standards by the different digital health interventions in Uganda.},
  archive      = {J_DINT},
  author       = {Basajja, Mariam and Nambobi, Mutwalibi and Wolstencroft, Katy},
  doi          = {10.1162/dint_a_00178},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {899-916},
  shortjournal = {Data Intell.},
  title        = {Possibility of enhancing digital health interoperability in uganda through FAIR data},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Information streams in health facilities: The case of
uganda. <em>DINT</em>, <em>4</em>(4), 882–898. (<a
href="https://doi.org/10.1162/dint_a_00177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. With the prevailing COVID-19 pandemic, the lack of digitally-recorded and connected health data poses a challenge for analysing the situation. Virus outbreaks, such as the current pandemic, allow for the optimisation and reuse of data, which can be beneficial in managing future outbreaks. However, there is a general lack of knowledge about the actual flow of information in health facilities, which is also the case in Uganda. In Uganda, where this case study was conducted, there is no comprehensive knowledge about what type of data is collected or how it is collected along the journey of a patient through a health facility. This study investigates information flows of clinical patient data in health facilities in Uganda. The study found that almost all health facilities in Uganda store patient information in paper files on shelves. Hospitals in Uganda are provided with paper tools, such as reporting forms, registers and manuals, in which district data is collected as aggregate data and submitted in the form of digital reports to the Ministry of Health Resource Center. These reporting forms are not digitised and, thus, not machine-actionable. Hence, it is not easy for health facilities, researchers, and others to find and access patient and research data. It is also not easy to reuse and connect this data with other digital health data worldwide, leading to the incorrect conclusion that there is less health data in Uganda. The a FAIR architecture has the potential to solve such problems and facilitate the transition from paper to digital records in the Uganda health system.},
  archive      = {J_DINT},
  author       = {Basajja, Mariam and Nambobi, Mutwalibi},
  doi          = {10.1162/dint_a_00177},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {882-898},
  shortjournal = {Data Intell.},
  title        = {Information streams in health facilities: The case of uganda},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FAIR versus open data: A comparison of objectives and
principles. <em>DINT</em>, <em>4</em>(4), 867–881. (<a
href="https://doi.org/10.1162/dint_a_00176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This article assesses the difference between the concepts of ‘open data’ and ‘FAIR data’ in data management. FAIR data is understood as data that complies with the FAIR Guidelines—data that is Findable, Accessible, Interoperable and Reusable—while open data was born out of awareness of the need to democratise data by improving its accessibility, based on the idea that data should not have limitations that prevent people from using it. This study compared FAIR data with open data by analysing relevant documents using a coding analysis with conceptual labels based on Kingdon&#39;s theory of agenda setting. The study found that in relation to FAIR data the problem stream focuses on the complexity of data collected for research, while open data primarily emphasises giving the public access to non-confidential data. In the policy stream, the two concepts share common standpoints in terms of making data available and reusable, although different approaches are adopted in practice to accomplish these goals. In the politics stream, stakeholders with different objectives support FAIR data and from those who support open data.},
  archive      = {J_DINT},
  author       = {Jati, Putu Hadi Purnama and Lin, Yi and Nodehi, Sara and Cahyono, Dwy Bagus and van Reisen, Mirjam},
  doi          = {10.1162/dint_a_00176},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {867-881},
  shortjournal = {Data Intell.},
  title        = {FAIR versus open data: A comparison of objectives and principles},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FAIR equivalency, regulatory framework and adoption
potential of FAIR guidelines in health in kenya. <em>DINT</em>,
<em>4</em>(4), 852–866. (<a
href="https://doi.org/10.1162/dint_a_00175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This study explored the regulatory framework in Kenya that may facilitate the implementation of the FAIR Guidelines in health research, as well as the possibility of adopting the FAIR Guidelines at the national level. Fourteen key documents pivotal to the emerging digital health sector in Kenya were identified and analysed using a comprehensive coding and labelling approach based on a binary system for whether or not they mention the FAIR Guidelines or terms and vocabulary related to the FAIR Guidelines. The analysis revealed gaps in data stewardship that could be filled by the implementation of the FAIR Guidelines and, although the documents analysed do not explicitly mention the FAIR Guidelines, FAIR Equivalent terminology and practices are mentioned in varying detail. However, our analysis shows that there are still no provisions for the introduction and implementation of the FAIR Guidelines in health research in Kenya. Therefore, we recommend that the leadership be provided with a comprehensive introduction to the FAIR Guidelines, success stories about the FAIRification of data and research infrastructure in other parts of the world, and a demonstration of the steps needed for the FAIRification of health data in Kenya.},
  archive      = {J_DINT},
  author       = {Inau, Ester Thea and Nalugala, Reginald and Nandwa, William Muhadi and Obwanda, Fredrick and Wachira, Antony and Cartaxo, Antonio},
  doi          = {10.1162/dint_a_00175},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {852-866},
  shortjournal = {Data Intell.},
  title        = {FAIR equivalency, regulatory framework and adoption potential of FAIR guidelines in health in kenya},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FAIR guidelines and data regulatory framework for digital
health in nigeria. <em>DINT</em>, <em>4</em>(4), 839–851. (<a
href="https://doi.org/10.1162/dint_a_00174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Adopting the FAIR Guidelines—that data should be Findable, Accessible, Interoperable and Reusable (FAIR)—in the health data system in Nigeria will help protect data against use by unauthorised parties, while also making data more accessible to legitimate users. However, little is known about the FAIR Guidelines and their compatibility with data and health laws and policies in Nigeria. This study assesses the governance framework for digital and health/eHealth policies in Nigeria and explores the possibility of a policy window opening for the FAIR Guidelines to be adopted and implemented in Nigeria&#39;s eHealth sector. Ten Nigerian policy documents were examined for mention of the FAIR Guidelines (or FAIR Equivalent terminology) and the 15 sub-criteria or facets. The analysis found that although the FAIR Guidelines are not explicitly mentioned, 70\% of the documents contain FAIR Equivalent terminology. The Nigeria Data Protection Regulation contained the most FAIR Equivalent principles (73\%) and some of the remaining nine documents also contained some FAIR Equivalent principles (between 0–60\%). Accordingly, it can be concluded that a policy window is open for the FAIR Guidelines to be adopted and implemented in Nigeria&#39;s eHealth sector.},
  archive      = {J_DINT},
  author       = {Kawu, Abdullahi Abubakar and Elijah, Joseph and Abdullahi, Ibrahim and Maipanuku, Jamilu Yahaya and Folorunso, Sakinat and Basajja, Mariam and Oladipo, Francisca and Ibrahim, Hauwa Limanko},
  doi          = {10.1162/dint_a_00174},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {839-851},
  shortjournal = {Data Intell.},
  title        = {FAIR guidelines and data regulatory framework for digital health in nigeria},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Regulatory framework for eHealth data policies in zimbabwe:
Measuring FAIR equivalency. <em>DINT</em>, <em>4</em>(4), 827–838. (<a
href="https://doi.org/10.1162/dint_a_00173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The FAIR Guidelines—that data should be Findable, Accessible, Interoperable and Reusable (FAIR)—aim to improve the management of digital data assets for improved decision making. FAIR comprises 15 elements (called facets) that explain how data should be able to be reused by researchers and policymakers. For this research, eight policy documents were reviewed from Zimbabwe&#39;s Ministry of Health and Ministry of Information and Communication Technology (ICT) from 1999 to 2020. These were scrutinised to determine the mention of the FAIR Guidelines or FAIR Equivalent principles. The vision, mission statement and objectives of these documents were analysed relative to the 15 facets of FAIR. The research found that none of the policy documents in health/eHealth or ICT in Zimbabwe explicitly mention the FAIR Guidelines, but all contain some FAIR Equivalent principles. Hence, the regulatory framework for health/eHealth data management in Zimbabwe is aligned with the FAIR Guidelines and, therefore, a policy window is open for the adoption of FAIR Guidelines in relation to health/eHealth data management.},
  archive      = {J_DINT},
  author       = {Chindoza, Kudakwashe},
  doi          = {10.1162/dint_a_00173},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {827-838},
  shortjournal = {Data Intell.},
  title        = {Regulatory framework for eHealth data policies in zimbabwe: Measuring FAIR equivalency},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FAIR equivalency with regulatory framework for digital
health in ethiopia. <em>DINT</em>, <em>4</em>(4), 813–826. (<a
href="https://doi.org/10.1162/dint_a_00172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper investigates whether or not there is a policy window for making health data ‘Findable’, ‘Accessible’ (under well-defined conditions), ‘Interoperable’ and ‘Reusable’ (FAIR) in Ethiopia. The question is answered by studying the alignment of policies for health data in Ethiopia with the FAIR Guidelines or their ‘FAIR Equivalency’. Policy documents relating to the digitalisation of health systems in Ethiopia were examined to determine their FAIR Equivalency. Although the documents are fragmented and have no overarching governing framework, it was found that they aim to make the disparate health data systems in Ethiopia interoperable and boost the discoverability and (re)usability of data for research and better decision making. Hence, the FAIR Guidelines appear to be aligned with the regulatory frameworks for ICT and digital health in Ethiopia and, under the right conditions, a policy window could open for their adoption and implementation.},
  archive      = {J_DINT},
  author       = {Tadele Taye, Getu and Yohannes Amare, Samson and Gebremeskel G., Tesfit and Abrha Medhanyie, Araya and Ayele, Wondimu and Habtamu, Tigist and van Reisen, Mirjam},
  doi          = {10.1162/dint_a_00172},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {813-826},
  shortjournal = {Data Intell.},
  title        = {FAIR equivalency with regulatory framework for digital health in ethiopia},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FAIR equivalency in indonesia’s digital health framework.
<em>DINT</em>, <em>4</em>(4), 798–812. (<a
href="https://doi.org/10.1162/dint_a_00171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The objective of this study was to assess the regulatory framework for health data in Indonesia in order to understand the policy context and explore the possibility of expanding the adoption and implementation of the FAIR Guidelines, which state that data should be Findable, Accessible, Interoperable and Reusable (FAIR), in Indonesia. Although the FAIR Guidelines were not explicitly mentioned in any of the policy documents relevant to the Indonesian digital health sector, six out of the eight documents analysed contained FAIR Equivalent principles. In particular, Indonesia&#39;s Population Identification Number (NIK) has the potential, as a unique identifier, to support the integration and interoperability (findability) of data, which is crucial to all other aspects of the FAIR Guidelines. There is also a plan to build standards and protocols into the implementation of information systems in each ministry and government agency to improve data accessibility (accessibility), the integration of the various information systems is planned/ongoing (interoperability), and the need for a standardised arrangement for health information systems related to health data following the community standard is recognised (reusability). The documents at the core of Indonesia&#39;s digital health/eHealth policy have the highest FAIR Equivalency Score (FE-Score), showing some degree of alignment between the Indonesian digital health implementation vision and the FAIR Guidelines. This indicates that Indonesia&#39;s digital health sector is open to using the FAIR Guidelines.},
  archive      = {J_DINT},
  author       = {Purnama Jati, Putu Hadi},
  doi          = {10.1162/dint_a_00171},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {798-812},
  shortjournal = {Data Intell.},
  title        = {FAIR equivalency in indonesia&#39;s digital health framework},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FAIR equivalency with regulatory framework for digital
health in uganda. <em>DINT</em>, <em>4</em>(4), 771–797. (<a
href="https://doi.org/10.1162/dint_a_00170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This study explores the possibility of opening a policy window for the adoption of the FAIR Guidelines— that data be Findable, Accessible, Interoperable, and Reusable (FAIR)—in Uganda&#39;s eHealth sector. Although the FAIR Guidelines were not mentioned in any of the policy documents relevant to Uganda&#39;s eHealth sector, the study found that 83\% of the documents mentioned FAIR Equivalent efforts, such as the adoption of the National Identification Number (NIN) as a unique identifier in Uganda&#39;s national Electronic Health Management Information System (eHMIS) (findability), the planned/ongoing integration of various information systems (interoperability), and the alignment of various projects with international best practices/standards (reusability). A FAIR Equivalency Score (FE-Score), devised in this study as an aggregate score of the mention of the equivalent of FAIR facets in the policy documents, showed that the documents at the core of Uganda&#39;s digital health/eHealth policy have the highest score of all the documents analysed, indicating that there is a degree of alignment between Uganda&#39;s National eHealth Vision and the FAIR Guidelines. Therefore, it can be concluded that favourable conditions exist for the adoption and implementation of the FAIR Guidelines in Uganda&#39;s eHealth sector. Hence, it is recommended that the FAIR community adopt a capacity building strategy through organisations with a worldwide mandate, such as the World Health Organization, to promote the adoption of the FAIR Guidelines as part of international best practices.},
  archive      = {J_DINT},
  author       = {Basajja, Mariam and Van Reisen, Mirjam and Oladipo, Francisca},
  doi          = {10.1162/dint_a_00170},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {771-797},
  shortjournal = {Data Intell.},
  title        = {FAIR equivalency with regulatory framework for digital health in uganda},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Implementation of FAIR guidelines in selected non-western
geographies. <em>DINT</em>, <em>4</em>(4), 747–770. (<a
href="https://doi.org/10.1162/dint_a_00169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This study provides an analysis of the implementation of FAIR Guidelines in selected non-Western geographies. The analysis was based on a systematic literature review to determine if the findability, accessibility, interoperability, and reusability of data is seen as an issue, if the adoption of the FAIR Guidelines is seen as a solution, and if the climate is conducive to the implementation of the FAIR Guidelines. The results show that the FAIR Guidelines have been discussed in most of the countries studied, which have identified data sharing and the reusability of research data as an issue (e.g., Kazakhstan, Russia, countries in the Middle East), and partially introduced in others (e.g., Indonesia). In Indonesia, a FAIR equivalent system has been introduced, although certain functions need to be added for data to be entirely FAIR. In Japan, both FAIR equivalent systems and FAIR-based systems have been adopted and created, and the acceptance of FAIR-based systems is recommended by the Government of Japan. In a number of African countries, the FAIR Guidelines are in the process of being implemented and the implementation of FAIR is well supported. In conclusion, a window of opportunity for implementing the FAIR Guidelines is open in most of the countries studied, however, more awareness needs to be raised about the benefits of FAIR in Russia and Kazakhstan to place it firmly on the policy agenda.},
  archive      = {J_DINT},
  author       = {Lin, Yi and Purnama Jati, Putu Hadi and Aktau, Aliya and Ghardallou, Mariem and Nodehi, Sara and van Reisen, Mirjam},
  doi          = {10.1162/dint_a_00169},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {747-770},
  shortjournal = {Data Intell.},
  title        = {Implementation of FAIR guidelines in selected non-western geographies},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Agenda setting on FAIR guidelines in the european union and
the role of expert committees. <em>DINT</em>, <em>4</em>(4), 724–746.
(<a href="https://doi.org/10.1162/dint_a_00168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The FAIR Guidelines were conceptualised and coined as guidelines for Findable, Accessible, Interoperable and Reusable (FAIR) data at a conference held at the Lorentz Centre in Leiden in 2014. A relatively short period of time after this conference, the FAIR Guidelines made it onto the public policy agenda of the European Union. Following the concept of Kingdon, policy entrepreneurs played a critical role in creating a policy window for this idea to reach the agenda by linking it to the policy of establishing a European Open Science Cloud (EOSC). Tracing the development from idea to policy, this study highlights the critical role that expert committees play in the European Union. The permeability of the complex governance structure is increased by these committees, which allow experts to link up with the institutions and use the committees to launch new ideas. The High Level Expert Groups on the EOSC provided the platform from which the FAIR Guidelines were launched, and this culminated in the adoption of the FAIR Guidelines as a requirement for all European-funded science. As a result, the FAIR Guidelines have become an obligatory part of data management in European-funded research in 2020 and are now followed by other funders worldwide.},
  archive      = {J_DINT},
  author       = {Stocker, Misha and Stokmans, Mia and van Reisen, Mirjam},
  doi          = {10.1162/dint_a_00168},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {724-746},
  shortjournal = {Data Intell.},
  title        = {Agenda setting on FAIR guidelines in the european union and the role of expert committees},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Terminology for a FAIR framework for the virus outbreak data
network-africa. <em>DINT</em>, <em>4</em>(4), 698–723. (<a
href="https://doi.org/10.1162/dint_a_00167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The field of health data management poses unique challenges in relation to data ownership, the privacy of data subjects, and the reusability of data. The FAIR Guidelines have been developed to address these challenges. The Virus Outbreak Data Network (VODAN) architecture builds on these principles, using the European Union&#39;s General Data Protection Regulation (GDPR) framework to ensure compliance with local data regulations, while using information knowledge management concepts to further improve data provenance and interoperability. In this article we provide an overview of the terminology used in the field of FAIR data management, with a specific focus on FAIR compliant health information management, as implemented in the VODAN architecture.},
  archive      = {J_DINT},
  author       = {Plug, Ruduan and Liang, Yan and Aktau, Aliya and Basajja, Mariam and Oladipo, Francisca and van Reisen, Mirjam},
  doi          = {10.1162/dint_a_00167},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {698-723},
  shortjournal = {Data Intell.},
  title        = {Terminology for a FAIR framework for the virus outbreak data network-africa},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incomplete COVID-19 data: The curation of medical health
data by the virus outbreak data network-africa. <em>DINT</em>,
<em>4</em>(4), 673–697. (<a
href="https://doi.org/10.1162/dint_e_00166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The incompleteness of patient health data is a threat to the management of COVID-19 in Africa and globally. This has become particularly clear with the recent emergence of new variants of concern. The Virus Outbreak Data Network (VODAN)-Africa has studied the curation of patient health data in selected African countries and identified that health information flows often do not involve the use of health data at the point of care, which renders data production largely meaningless to those producing it. This modus operandi leads to disfranchisement over the control of health data, which is extracted to be processed elsewhere. In response to this problem, VODAN-Africa studied whether or not a design that makes local ownership and repositing of data central to the data curation process, would have a greater chance of being adopted. The design team based their work on the legal requirements of the European Union&#39;s General Data Protection Regulation (GDPR); the FAIR Guidelines on curating data as Findable, Accessible (under well-defined conditions), Interoperable and Reusable (FAIR); and national regulations applying in the context where the data is produced. The study concluded that the visiting of data curated as machine actionable and reposited in the locale where the data is produced and renders services has great potential for access to a wider variety of data. A condition of such innovation is that the innovation team is intradisciplinary, involving stakeholders and experts from all of the places where the innovation is designed, and employs a methodology of co-creation and capacity-building.},
  archive      = {J_DINT},
  author       = {Van Reisen, Mirjam and Oladipo, Francisca Onaolapo and Mpezamihigo, Mouhamed and Plug, Ruduan and Basajja, Mariam and Aktau, Aliya and Jati, Putu Hadi Purnama and Nalugala, Reginald and Folorunso, Sakinat and Amare, Samson Yohannes and Abdulahi, Ibrahim and Afolabi, Oluwole Olumuyiwa and Mwesigwa, Ezra and Taye, Getu Tadele and Kawu, Abdulahi and Ghardallou, Mariem and Liang, Yan and Osigwe, Obinna and Medhanyie, Araya Abrha and Mawere, Munyaradzi},
  doi          = {10.1162/dint_e_00166},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {673-697},
  shortjournal = {Data Intell.},
  title        = {Incomplete COVID-19 data: The curation of medical health data by the virus outbreak data network-africa},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Introduction to the special issue: Data intelligence on
patient health records. <em>DINT</em>, <em>4</em>(4), 671–672. (<a
href="https://doi.org/10.1162/dint_e_00165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data Intelligence is the ultimate purpose of FAIR data management. FAIR as in data that is Findable, Accessible (under well defined conditions), Interoperable and Reusable. FAIR also as in ethical data; data that fulfils the requirements of Personal Data Protection, is collected for well defined purposes and is held and curated within ownership of the location where the data is produced.In this Special Issue, we ask how more data intelligence can be derived from Medical Patient Records. All health facilities associated with the reported studies produce Medical Patient Records, and these records are highly structured and employing vocabularies that are internationally understood and used. The researchers of the Virus Outbreak Data Network-Africa were interested to understand whether these data would be a good source for FAIRification and, once FAIRified, would provide a data pipeline that can be the future of data intelligence with a global scope and at a scale that is currently lacking. The programme therefore focused on Africa, a continent with a minimum of legacy in digital health records data intelligence and therefore an excellent place to build a pioneer, novel FAIR system.The Special Issue introduces the preparatory work to establishing a workable Minimal Viable Product based on FAIR machine-actionable patient health records. The work comprised the following steps. First an exploration of the regulatory frameworks internationally and in each of the participating countries. This exploration was positive, in all of the countries the policy-framework was positively geared towards the FAIR principles.The second step was focused on the FAIRification process of the data as well as the localisation of data repositories. The outcome of this phase was positive, a data-visiting exercise across countries and even across continents, worked out. This demonstrated that the basic principles of the FAIRification process were realistic and operational.In the third step the research team set out to understand the different conditions for deployment in different places. For this purpose the team identified places that varied widely in terms of remoteness, connectedness, health services provided and conditions for operations. The result was a list of specifications and requirements providing the basis for engineering software, that could be installed and serviced locally in these widely different conditions in an African context.In a final stage the working conditions as pertaining to digital patient health records in facilities were studied, with a view to understanding the usefulness in the daily practice of the health facilities. Four parallel use-cases were identified and these were integrated in a Virtual Image that was deployed in 88 health facilities in 8 countries.The result is a data intelligent system that relates to four purposes: (i) monitoring by Ministry of Health; (ii) monitoring of data generated and stored in each of the facilities (iii) visualisation of common statistics derived from data-visited by algorithms in the health facilities and (iv) a FAIR-store of data that can be used for dynamic use-cases, based on permission granted by the facility.FAIR works in Africa and this test-case forms an excellent basis for further development and deployment —it combines data ownership with a data-visiting capacity, and this can form an ethical pipeline for innovation of ML and AI supported health systems. The lessons learned in the African setting can be of high value for implementation in other continents as well, including regions where health information systems and ICT infrastructure might be more advanced, but nevertheless not enabling FAIR based distributed analytics and learning by visiting local data. The research demonstrated that it is possible to include data from areas that are poorly connected and that quality data for ML and AI pipelines can and should include diverse data. This Special Issue documents that this is an achievable goal: the development of an inclusive, high quality, and ethical pipeline based on stewardship of data according to FAIR Guidelines of medical patient records.Mirjam Van Reisen (0000-0003-0627-8014, mirjamvanreisen@gmail.com); conceptualization, methodology, formal analysis, visualization, writing original draft preparation, writing—review and editing, supervision, project administration, funding acquisition Barend Mons (0000-0003-3934-0072, barendmons@gmail.com) conceptualization, writing—review and editing.},
  archive      = {J_DINT},
  author       = {van Reisen, Mirjam and Mons, Barend},
  doi          = {10.1162/dint_e_00165},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {671-672},
  shortjournal = {Data Intell.},
  title        = {Introduction to the special issue: Data intelligence on patient health records},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis of pioneering computable biomedical knowledge
repositories and their emerging governance structures. <em>DINT</em>,
<em>4</em>(3), 653–670. (<a
href="https://doi.org/10.1162/dint_a_00148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A growing interest in producing and sharing computable biomedical knowledge artifacts (CBKs) is increasing the demand for repositories that validate, catalog, and provide shared access to CBKs. However, there is a lack of evidence on how best to manage and sustain CBK repositories. In this paper, we present the results of interviews with several pioneering CBK repository owners. These interviews were informed by the Trusted Repositories Audit and Certification (TRAC) framework. Insights gained from these interviews suggest that the organizations operating CBK repositories are somewhat new, that their initial approaches to repository governance are informal, and that achieving economic sustainability for their CBK repositories is a major challenge. To enable a learning health system to make better use of its data intelligence, future approaches to CBK repository management will require enhanced governance and closer adherence to best practice frameworks to meet the needs of myriad biomedical science and health communities. More effort is needed to find sustainable funding models for accessible CBK artifact collections.},
  archive      = {J_DINT},
  author       = {Amara, Philip Sahr and Conte, Marisa and Flynn, Allen and Platt, Jodyn and Trinidad, Marie Grace},
  doi          = {10.1162/dint_a_00148},
  journal      = {Data Intelligence},
  number       = {3},
  pages        = {653-670},
  shortjournal = {Data Intell.},
  title        = {Analysis of pioneering computable biomedical knowledge repositories and their emerging governance structures},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparative evaluation and comprehensive analysis of machine
learning models for regression problems. <em>DINT</em>, <em>4</em>(3),
620–652. (<a href="https://doi.org/10.1162/dint_a_00155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Artificial intelligence and machine learning applications are of significant importance almost in every field of human life to solve problems or support human experts. However, the determination of the machine learning model to achieve a superior result for a particular problem within the wide real-life application areas is still a challenging task for researchers. The success of a model could be affected by several factors such as dataset characteristics, training strategy and model responses. Therefore, a comprehensive analysis is required to determine model ability and the efficiency of the considered strategies. This study implemented ten benchmark machine learning models on seventeen varied datasets. Experiments are performed using four different training strategies 60:40, 70:30, and 80:20 hold-out and five-fold cross-validation techniques. We used three evaluation metrics to evaluate the experimental results: mean squared error, mean absolute error, and coefficient of determination (R2 score). The considered models are analyzed, and each model&#39;s advantages, disadvantages, and data dependencies are indicated. As a result of performed excess number of experiments, the deep Long-Short Term Memory (LSTM) neural network outperformed other considered models, namely, decision tree, linear regression, support vector regression with a linear and radial basis function kernels, random forest, gradient boosting, extreme gradient boosting, shallow neural network, and deep neural network. It has also been shown that cross-validation has a tremendous impact on the results of the experiments and should be considered for the model evaluation in regression studies where data mining or selection is not performed.},
  archive      = {J_DINT},
  author       = {Sekeroglu, Boran and Ever, Yoney Kirsal and Dimililer, Kamil and Al-Turjman, Fadi},
  doi          = {10.1162/dint_a_00155},
  journal      = {Data Intelligence},
  number       = {3},
  pages        = {620-652},
  shortjournal = {Data Intell.},
  title        = {Comparative evaluation and comprehensive analysis of machine learning models for regression problems},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy-constrained graph pattern matching in medical
knowledge graphs. <em>DINT</em>, <em>4</em>(3), 599–619. (<a
href="https://doi.org/10.1162/dint_a_00153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The research on graph pattern matching (GPM) has attracted a lot of attention. However, most of the research has focused on complex networks, and there are few researches on GPM in the medical field. Hence, with GPM this paper is to make a breast cancer-oriented diagnosis before the surgery. Technically, this paper has firstly made a new definition of GPM, aiming to explore the GPM in the medical field, especially in Medical Knowledge Graphs (MKGs). Then, in the specific matching process, this paper introduces fuzzy calculation, and proposes a multi-threaded bidirectional routing exploration (M-TBRE) algorithm based on depth first search and a two-way routing matching algorithm based on multi-threading. In addition, fuzzy constraints are introduced in the M-TBRE algorithm, which leads to the Fuzzy-M-TBRE algorithm. The experimental results on the two datasets show that compared with existing algorithms, our proposed algorithm is more efficient and effective.},
  archive      = {J_DINT},
  author       = {Li, Lei and Du, Xun and Zhang, Zan and Tao, Zhenchao},
  doi          = {10.1162/dint_a_00153},
  journal      = {Data Intelligence},
  number       = {3},
  pages        = {599-619},
  shortjournal = {Data Intell.},
  title        = {Fuzzy-constrained graph pattern matching in medical knowledge graphs},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge representation and reasoning for complex time
expression in clinical text. <em>DINT</em>, <em>4</em>(3), 573–598. (<a
href="https://doi.org/10.1162/dint_a_00152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Temporal information is pervasive and crucial in medical records and other clinical text, as it formulates the development process of medical conditions and is vital for clinical decision making. However, providing a holistic knowledge representation and reasoning framework for various time expressions in the clinical text is challenging. In order to capture complex temporal semantics in clinical text, we propose a novel Clinical Time Ontology (CTO) as an extension from OWL framework. More specifically, we identified eight time-related problems in clinical text and created 11 core temporal classes to conceptualize the fuzzy time, cyclic time, irregular time, negations and other complex aspects of clinical time. Then, we extended Allen&#39;s and TEO&#39;s temporal relations and defined the relation concept description between complex and simple time. Simultaneously, we provided a formulaic and graphical presentation of complex time and complex time relationships. We carried out empirical study on the expressiveness and usability of CTO using real-world healthcare datasets. Finally, experiment results demonstrate that CTO could faithfully represent and reason over 93\% of the temporal expressions, and it can cover a wider range of time-related classes in clinical domain.},
  archive      = {J_DINT},
  author       = {Hu, Danyang and Wang, Meng and Gao, Feng and Xu, Fangfang and Gu, Jinguang},
  doi          = {10.1162/dint_a_00152},
  journal      = {Data Intelligence},
  number       = {3},
  pages        = {573-598},
  shortjournal = {Data Intell.},
  title        = {Knowledge representation and reasoning for complex time expression in clinical text},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bi-GRU relation extraction model based on keywords
attention. <em>DINT</em>, <em>4</em>(3), 552–572. (<a
href="https://doi.org/10.1162/dint_a_00147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Relational extraction plays an important role in the field of natural language processing to predict semantic relationships between entities in a sentence. Currently, most models have typically utilized the natural language processing tools to capture high-level features with an attention mechanism to mitigate the adverse effects of noise in sentences for the prediction results. However, in the task of relational classification, these attention mechanisms do not take full advantage of the semantic information of some keywords which have information on relational expressions in the sentences. Therefore, we propose a novel relation extraction model based on the attention mechanism with keywords, named Relation Extraction Based on Keywords Attention (REKA). In particular, the proposed model makes use of bi-directional GRU (Bi-GRU) to reduce computation, obtain the representation of sentences, and extracts prior knowledge of entity pair without any NLP tools. Besides the calculation of the entity-pair similarity, Keywords attention in the REKA model also utilizes a linear-chain conditional random field (CRF) combining entity-pair features, similarity features between entity-pair features, and its hidden vectors, to obtain the attention weight resulting from the marginal distribution of each word. Experiments demonstrate that the proposed approach can utilize keywords incorporating relational expression semantics in sentences without the assistance of any high-level features and achieve better performance than traditional methods.},
  archive      = {J_DINT},
  author       = {Zhang, Yuanyuan and Chen, Yu and Yu, Shengkang and Gu, Xiaoqin and Song, Mengqiong and Peng, Yu and Chen, Jianxia and Liu, Qi},
  doi          = {10.1162/dint_a_00147},
  journal      = {Data Intelligence},
  number       = {3},
  pages        = {552-572},
  shortjournal = {Data Intell.},
  title        = {Bi-GRU relation extraction model based on keywords attention},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensemble making few-shot learning stronger. <em>DINT</em>,
<em>4</em>(3), 529–551. (<a
href="https://doi.org/10.1162/dint_a_00144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Few-shot learning has been proposed and rapidly emerging as a viable means for completing various tasks. Many few-shot models have been widely used for relation learning tasks. However, each of these models has a shortage of capturing a certain aspect of semantic features, for example, CNN on long-range dependencies part, Transformer on local features. It is difficult for a single model to adapt to various relation learning, which results in a high variance problem. Ensemble strategy could be competitive in improving the accuracy of few-shot relation extraction and mitigating high variance risks. This paper explores an ensemble approach to reduce the variance and introduces fine-tuning and feature attention strategies to calibrate relation-level features. Results on several few-shot relation learning tasks show that our model significantly outperforms the previous state-of-the-art models.},
  archive      = {J_DINT},
  author       = {Lin, Qiang and Liu, Yongbin and Wen, Wen and Tao, Zhihua and Ouyang, Chunping and Wan, Yaping},
  doi          = {10.1162/dint_a_00144},
  journal      = {Data Intelligence},
  number       = {3},
  pages        = {529-551},
  shortjournal = {Data Intell.},
  title        = {Ensemble making few-shot learning stronger},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uncovering topics of public cultural activities: Evidence
from china. <em>DINT</em>, <em>4</em>(3), 509–528. (<a
href="https://doi.org/10.1162/dint_a_00121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this study, we uncover the topics of Chinese public cultural activities in 2020 with a two-step short text clustering (self-taught neural networks and graph-based clustering) and topic modeling approach. The dataset we use for this research is collected from 108 websites of libraries and cultural centers, containing over 17,000 articles. With the novel framework we propose, we derive 3 clusters and 8 topics from 21 provincial-level regions in China. By plotting the topic distribution of each cluster, we are able to shows unique tendencies of local cultural institutes, that is, free lessons and lectures on art and culture, entertainment and service for socially vulnerable groups, and the preservation of intangible cultural heritage respectively. The findings of our study provide decision-making support for cultural institutes, thus promoting public cultural service from a data-driven perspective.},
  archive      = {J_DINT},
  author       = {Zeng, Zixin and Hua, Bolin},
  doi          = {10.1162/dint_a_00121},
  journal      = {Data Intelligence},
  number       = {3},
  pages        = {509-528},
  shortjournal = {Data Intell.},
  title        = {Uncovering topics of public cultural activities: Evidence from china},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Faster zero-shot multi-modal entity linking via
visual-linguistic representation. <em>DINT</em>, <em>4</em>(3), 493–508.
(<a href="https://doi.org/10.1162/dint_a_00146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Multi-modal entity linking plays a crucial role in a wide range of knowledge-based modal-fusion tasks, i.e., multi-modal retrieval and multi-modal event extraction. We introduce the new ZEro-shot Multi-modal Entity Linking (ZEMEL) task, the format is similar to multi-modal entity linking, but multi-modal mentions are linked to unseen entities in the knowledge graph, and the purpose of zero-shot setting is to realize robust linking in highly specialized domains. Simultaneously, the inference efficiency of existing models is low when there are many candidate entities. On this account, we propose a novel model that leverages visuallinguistic representation through the co-attentional mechanism to deal with the ZEMEL task, considering the trade-off between performance and efficiency of the model. We also build a dataset named ZEMELD for the new task, which contains multi-modal data resources collected from Wikipedia, and we annotate the entities as ground truth. Extensive experimental results on the dataset show that our proposed model is effective as it significantly improves the precision from 68.93\% to 82.62\% comparing with baselines in the ZEMEL task.},
  archive      = {J_DINT},
  author       = {Zheng, Qiushuo and Wen, Hao and Wang, Meng and Qi, Guilin and Bai, Chaoyu},
  doi          = {10.1162/dint_a_00146},
  journal      = {Data Intelligence},
  number       = {3},
  pages        = {493-508},
  shortjournal = {Data Intell.},
  title        = {Faster zero-shot multi-modal entity linking via visual-linguistic representation},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). COKG-QA: Multi-hop question answering over COVID-19
knowledge graphs. <em>DINT</em>, <em>4</em>(3), 471–492. (<a
href="https://doi.org/10.1162/dint_a_00154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. COVID-19 evolves rapidly and an enormous number of people worldwide desire instant access to COVID-19 information such as the overview, clinic knowledge, vaccine, prevention measures, and COVID-19 mutation. Question answering (QA) has become the mainstream interaction way for users to consume the ever-growing information by posing natural language questions. Therefore, it is urgent and necessary to develop a QA system to offer consulting services all the time to relieve the stress of health services. In particular, people increasingly pay more attention to complex multi-hop questions rather than simple ones during the lasting pandemic, but the existing COVID-19 QA systems fail to meet their complex information needs. In this paper, we introduce a novel multi-hop QA system called COKG-QA, which reasons over multiple relations over large-scale COVID-19 Knowledge Graphs to return answers given a question. In the field of question answering over knowledge graph, current methods usually represent entities and schemas based on some knowledge embedding models and represent questions using pre-trained models. While it is convenient to represent different knowledge (i.e., entities and questions) based on specified embeddings, an issue raises that these separate representations come from heterogeneous vector spaces. We align question embeddings with knowledge embeddings in a common semantic space by a simple but effective embedding projection mechanism. Furthermore, we propose combining entity embeddings with their corresponding schema embeddings which served as important prior knowledge, to help search for the correct answer entity of specified types. In addition, we derive a large multi-hop Chinese COVID-19 dataset (called COKG-DATA for remembering) for COKG-QA based on the linked knowledge graph OpenKG-COVID19 launched by OpenKG①, including comprehensive and representative information about COVID-19. COKG-QA achieves quite competitive performance in the 1-hop and 2-hop data while obtaining the best result with significant improvements in the 3-hop. And it is more efficient to be used in the QA system for users. Moreover, the user study shows that the system not only provides accurate and interpretable answers but also is easy to use and comes with smart tips and suggestions.},
  archive      = {J_DINT},
  author       = {Du, Huifang and Le, Zhongwen and Wang, Haofen and Chen, Yunwen and Yu, Jing},
  doi          = {10.1162/dint_a_00154},
  journal      = {Data Intelligence},
  number       = {3},
  pages        = {471-492},
  shortjournal = {Data Intell.},
  title        = {COKG-QA: Multi-hop question answering over COVID-19 knowledge graphs},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A workflow demonstrator for processing catalysis research
data. <em>DINT</em>, <em>4</em>(2), 455–470. (<a
href="https://doi.org/10.1162/dint_a_00143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The UK Catalysis Hub (UKCH) is designing a virtual research environment to support data processing and analysis, the Catalysis Research Workbench (CRW). The development of this platform requires identifying the processing and analysis needs of the UKCH members and mapping them to potential solutions. This paper presents a proposal for a demonstrator to analyse the use of scientific workflows for large scale data processing. The demonstrator provides a concrete target to promote further discussion of the processing and analysis needs of the UKCH community. In this paper, we will discuss the main requirements for data processing elicited and the proposed adaptations that will be incorporated in the design of the CRW and how to integrate the proposed solutions with existing practices of the UKCH. The demonstrator has been used in discussion with researchers and in presentations to the UKCH community, generating increased interest and motivating further development.},
  archive      = {J_DINT},
  author       = {de la Hidalga, Abraham Nieva and Decarolis, Donato and Xu, Shaojun and Matam, Santhosh and Enciso, Willinton Yesid Hernández and Goodall, Josephine and Matthews, Brian and Catlow, C. Richard A.},
  doi          = {10.1162/dint_a_00143},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {455-470},
  shortjournal = {Data Intell.},
  title        = {A workflow demonstrator for processing catalysis research data},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A semantic approach to workflow management and reuse for
research problem solving. <em>DINT</em>, <em>4</em>(2), 439–454. (<a
href="https://doi.org/10.1162/dint_a_00142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The investigation proposes the application of an ontological semantic approach to describing workflow control patterns, research workflow step patterns, and the meaning of the workflows in terms of domain knowledge. The approach can provide wide opportunities for semantic refinement, reuse, and composition of workflows. Automatic reasoning allows verifying those compositions and implementations and provides machine-actionable workflow manipulation and problem-solving using workflows. The described approach can take into account the implementation of workflows in different workflow management systems, the organization of workflows collections in data infrastructures and the search for them, the semantic approach to the selection of workflows and resources in the research domain, the creation of research step patterns and their implementation reusing fragments of existing workflows, the possibility of automation of problemsolving based on the reuse of workflows. The application of the approach to CWFR conceptions is proposed.},
  archive      = {J_DINT},
  author       = {Skvortsov, Nikolay A. and Stupnikov, Sergey A.},
  doi          = {10.1162/dint_a_00142},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {439-454},
  shortjournal = {Data Intell.},
  title        = {A semantic approach to workflow management and reuse for research problem solving},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Realising data-centric scientific workflows with
provenance-capturing on data lakes. <em>DINT</em>, <em>4</em>(2),
426–438. (<a href="https://doi.org/10.1162/dint_a_00141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Since their introduction by James Dixon in 2010, data lakes get more and more attention, driven by the promise of high reusability of the stored data due to the schema-on-read semantics. Building on this idea, several additional requirements were discussed in literature to improve the general usability of the concept, like a central metadata catalog including all provenance information, an overarching data governance, or the integration with (high-performance) processing capabilities. Although the necessity for a logical and a physical organisation of data lakes in order to meet those requirements is widely recognized, no concrete guidelines are yet provided. The most common architecture implementing this conceptual organisation is the zone architecture, where data is assigned to a certain zone depending on the degree of processing. This paper discusses how FAIR Digital Objects can be used in a novel approach to organize a data lake based on data types instead of zones, how they can be used to abstract the physical implementation, and how they empower generic and portable processing capabilities based on a provenance-based approach.},
  archive      = {J_DINT},
  author       = {Nolte, Hendrik and Wieder, Philipp},
  doi          = {10.1162/dint_a_00141},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {426-438},
  shortjournal = {Data Intell.},
  title        = {Realising data-centric scientific workflows with provenance-capturing on data lakes},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scaling notebooks as re-configurable cloud workflows.
<em>DINT</em>, <em>4</em>(2), 409–425. (<a
href="https://doi.org/10.1162/dint_a_00140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Literate computing environments, such as the Jupyter (i.e., Jupyter Notebooks, JupyterLab, and JupyterHub), have been widely used in scientific studies; they allow users to interactively develop scientific code, test algorithms, and describe the scientific narratives of the experiments in an integrated document. To scale up scientific analyses, many implemented Jupyter environment architectures encapsulate the whole Jupyter notebooks as reproducible units and autoscale them on dedicated remote infrastructures (e.g., highperformance computing and cloud computing environments). The existing solutions are still limited in many ways, e.g., 1) the workflow (or pipeline) is implicit in a notebook, and some steps can be generically used by different code and executed in parallel, but because of the tight cell structure, all steps in the Jupyter notebook have to be executed sequentially and lack of the flexibility of reusing the core code fragments, and 2) there are performance bottlenecks that need to improve the parallelism and scalability when handling extensive input data and complex computation.In this work, we focus on how to manage the workflow in a notebook seamlessly. We 1) encapsulate the reusable cells as RESTful services and containerize them as portal components, 2) provide a composition tool for describing workflow logic of those reusable components, and 3) automate the execution on remote cloud infrastructure. Empirically, we validate the solution&#39;s usability via a use case from the Ecology and Earth Science domain, illustrating the processing of massive Light Detection and Ranging (LiDAR) data. The demonstration and analysis show that our method is feasible, but that it needs further improvement, especially on integrating distributed workflow scheduling, automatic deployment, and execution to develop as a mature approach.},
  archive      = {J_DINT},
  author       = {Wang, Yuandou and Koulouzis, Spiros and Bianchi, Riccardo and Li, Na and Shi, Yifang and Timmermans, Joris and Kissling, W. Daniel and Zhao, Zhiming},
  doi          = {10.1162/dint_a_00140},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {409-425},
  shortjournal = {Data Intell.},
  title        = {Scaling notebooks as re-configurable cloud workflows},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using a workflow management platform in textual data
management. <em>DINT</em>, <em>4</em>(2), 398–408. (<a
href="https://doi.org/10.1162/dint_a_00139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The paper gives a brief introduction about the workflow management platform, Flowable, and how it is used for textual-data management. It is relatively new with its first release on 13 October, 2016. Despite the short time on the market, it seems to be quickly well-noticed with 4.6 thousand stars on GitHub at the moment. The focus of our project is to build a platform for text analysis on a large scale by including many different text resources. Currently, we have successfully connected to four different text resources and obtained more than one million works. Some resources are dynamic, which means that they might add more data or modify their current data. Therefore, it is necessary to keep data, both the metadata and the raw data, from our side up to date with the resources. In addition, to comply with FAIR principles, each work is assigned a persistent identifier (PID) and indexed for searching purposes. In the last step, we perform some standard analyses on the data to enhance our search engine and to generate a knowledge graph. End-users can utilize our platform to search on our data or get access to the knowledge graph. Furthermore, they can submit their code for their analyses to the system. The code will be executed on a High-Performance Cluster (HPC) and users can receive the results later on. In this case, Flowable can take advantage of PIDs for digital objects identification and management to facilitate the communication with the HPC system. As one may already notice, the whole process can be expressed as a workflow. A workflow, including error handling and notification, has been created and deployed. Workflow execution can be triggered manually or after predefined time intervals. According to our evaluation, the Flowable platform proves to be powerful and flexible. Further usage of the platform is already planned or implemented for many of our projects.},
  archive      = {J_DINT},
  author       = {Doan, Triet Ho Anh and Bingert, Sven and Yahyapour, Ramin},
  doi          = {10.1162/dint_a_00139},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {398-408},
  shortjournal = {Data Intell.},
  title        = {Using a workflow management platform in textual data management},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). From a dynamic image annotation process within the
humanities to a canonical workflow. <em>DINT</em>, <em>4</em>(2),
386–397. (<a href="https://doi.org/10.1162/dint_a_00138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. One idea of the Canonical Workflow Framework for Research (CWFR) is to improve the reusability and automation in research. In this paper, we aim to deliver a concrete view on the application of CWFRs to a use case of the arts and humanities to enrich further discussions on the practical realization of canonical workflows and the benefits that come with it. This use case involves context dependent data transformation and feature extraction, ingests into multiple repositories as well as a “human-in-the-loop” workflow step, which introduces a certain complexity into the mapping to a canonical workflow.},
  archive      = {J_DINT},
  author       = {Pfeil, Andreas and Jejkal, Thomas and Tonne, Danah and Götzelmann, Germaine},
  doi          = {10.1162/dint_a_00138},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {386-397},
  shortjournal = {Data Intell.},
  title        = {From a dynamic image annotation process within the humanities to a canonical workflow},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation of application possibilities for packaging
technologies in canonical workflows. <em>DINT</em>, <em>4</em>(2),
372–385. (<a href="https://doi.org/10.1162/dint_a_00137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In Canonical Workflow Framework for Research (CWFR) “packages” are relevant in two different directions. In data science, workflows are in general being executed on a set of files which have been aggregated for specific purposes, such as for training a model in deep learning. We call this type of “package” a data collection and its aggregation and metadata description is motivated by research interests. The other type of “packages” relevant for CWFR are supposed to represent workflows in a self-describing and self-contained way for later execution. In this paper, we will review different packaging technologies and investigate their usability in the context of CWFR. For this purpose, we draw on an exemplary use case and show how packaging technologies can support its realization. We conclude that packaging technologies of different flavors help on providing inputs and outputs for workflow steps in a machine-readable way, as well as on representing a workflow and all its artifacts in a self-describing and self-contained way.},
  archive      = {J_DINT},
  author       = {Jejkal, Thomas and Chelbi, Sabrine and Pfeil, Andreas and Wittenburg, Peter},
  doi          = {10.1162/dint_a_00137},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {372-385},
  shortjournal = {Data Intell.},
  title        = {Evaluation of application possibilities for packaging technologies in canonical workflows},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Galaxy: A decade of realising CWFR concepts. <em>DINT</em>,
<em>4</em>(2), 358–371. (<a
href="https://doi.org/10.1162/dint_a_00136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Despite recent encouragement to follow the FAIR principles, the day-to-day research practices have not changed substantially. Due to new developments and the increasing pressure to apply best practices, initiatives to improve the efficiency and reproducibility of scientific workflows are becoming more prevalent. In this article, we discuss the importance of well-annotated tools and the specific requirements to ensure reproducible research with FAIR outputs. We detail how Galaxy, an open-source workflow management system with a web-based interface, has implemented the concepts that are put forward by the Canonical Workflow Framework for Research (CWFR), whilst minimising changes to the practices of scientific communities. Although we showcase concrete applications from two different domains, this approach is generalisable to any domain and particularly useful in interdisciplinary research and science-based applications.},
  archive      = {J_DINT},
  author       = {Serrano-Solano, Beatriz and Fouilloux, Anne and Eguinoa, Ignacio and Kalaš, Matúš and Grüning, Björn and Coppens, Frederik},
  doi          = {10.1162/dint_a_00136},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {358-371},
  shortjournal = {Data Intell.},
  title        = {Galaxy: A decade of realising CWFR concepts},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Making canonical workflow building blocks interoperable
across workflow languages. <em>DINT</em>, <em>4</em>(2), 342–357. (<a
href="https://doi.org/10.1162/dint_a_00135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce the concept of Canonical Workflow Building Blocks (CWBB), a methodology of describing and wrapping computational tools, in order for them to be utilised in a reproducible manner from multiple workflow languages and execution platforms. The concept is implemented and demonstrated with the BioExcel Building Blocks library (BioBB), a collection of tool wrappers in the field of computational biomolecular simulation. Interoperability across different workflow languages is showcased through a protein Molecular Dynamics setup transversal workflow, built using this library and run with 5 different Workflow Manager Systems (WfMS). We argue such practice is a necessary requirement for FAIR Computational Workflows and an element of Canonical Workflow Frameworks for Research (CWFR) in order to improve widespread adoption and reuse of computational methods across workflow language barriers.},
  archive      = {J_DINT},
  author       = {Soiland-Reyes, Stian and Bayarri, Genís and Andrio, Pau and Long, Robin and Lowe, Douglas and Niewielska, Ania and Hospital, Adam and Groth, Paul},
  doi          = {10.1162/dint_a_00135},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {342-357},
  shortjournal = {Data Intell.},
  title        = {Making canonical workflow building blocks interoperable across workflow languages},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The specimen data refinery: A canonical workflow framework
and FAIR digital object approach to speeding up digital mobilisation of
natural history collections. <em>DINT</em>, <em>4</em>(2), 320–341. (<a
href="https://doi.org/10.1162/dint_a_00134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A key limiting factor in organising and using information from physical specimens curated in natural science collections is making that information computable, with institutional digitization tending to focus more on imaging the specimens themselves than on efficiently capturing computable data about them. Label data are traditionally manually transcribed today with high cost and low throughput, rendering such a task constrained for many collection-holding institutions at current funding levels. We show how computer vision, optical character recognition, handwriting recognition, named entity recognition and language translation technologies can be implemented into canonical workflow component libraries with findable, accessible, interoperable, and reusable (FAIR) characteristics. These libraries are being developed in a cloud-based workflow platform—the ‘Specimen Data Refinery’ (SDR)—founded on Galaxy workflow engine, Common Workflow Language, Research Object Crates (RO-Crate) and WorkflowHub technologies. The SDR can be applied to specimens’ labels and other artefacts, offering the prospect of greatly accelerated and more accurate data capture in computable form. Two kinds of FAIR Digital Objects (FDO) are created by packaging outputs of SDR workflows and workflow components as digital objects with metadata, a persistent identifier, and a specific type definition. The first kind of FDO are computable Digital Specimen (DS) objects that can be consumed/produced by workflows, and other applications. A single DS is the input data structure submitted to a workflow that is modified by each workflow component in turn to produce a refined DS at the end. The Specimen Data Refinery provides a library of such components that can be used individually, or in series. To cofunction, each library component describes the fields it requires from the DS and the fields it will in turn populate or enrich. The second kind of FDO, RO-Crates gather and archive the diverse set of digital and real-world resources, configurations, and actions (the provenance) contributing to a unit of research work, allowing that work to be faithfully recorded and reproduced. Here we describe the Specimen Data Refinery with its motivating requirements, focusing on what is essential in the creation of canonical workflow component libraries and its conformance with the requirements of an emerging FDO Core Specification being developed by the FDO Forum.},
  archive      = {J_DINT},
  author       = {Hardisty, Alex and Brack, Paul and Goble, Carole and Livermore, Laurence and Scott, Ben and Groom, Quentin and Owen, Stuart and Soiland-Reyes, Stian},
  doi          = {10.1162/dint_a_00134},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {320-341},
  shortjournal = {Data Intell.},
  title        = {The specimen data refinery: A canonical workflow framework and FAIR digital object approach to speeding up digital mobilisation of natural history collections},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reproducible research publication workflow: A canonical
workflow framework and FAIR digital object approach to quality research
output. <em>DINT</em>, <em>4</em>(2), 306–319. (<a
href="https://doi.org/10.1162/dint_a_00133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we present the Reproducible Research Publication Workflow (RRPW) as an example of how generic canonical workflows can be applied to a specific context. The RRPW includes essential steps between submission and final publication of the manuscript and the research artefacts (i.e., data, code, etc.) that underlie the scholarly claims in the manuscript. A key aspect of the RRPW is the inclusion of artefact review and metadata creation as part of the publication workflow. The paper discusses a formalized technical structure around a set of canonical steps which helps codify and standardize the process for researchers, curators, and publishers. The proposed application of canonical workflows can help achieve the goals of improved transparency and reproducibility, increase FAIR compliance of all research artefacts at all steps, and facilitate better exchange of annotated and machine-readable metadata.},
  archive      = {J_DINT},
  author       = {Peer, Limor and Biniossek, Claudia and Betz, Dirk and Christian, Thu-Mai},
  doi          = {10.1162/dint_a_00133},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {306-319},
  shortjournal = {Data Intell.},
  title        = {Reproducible research publication workflow: A canonical workflow framework and FAIR digital object approach to quality research output},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Canonical workflows to make data FAIR. <em>DINT</em>,
<em>4</em>(2), 286–305. (<a
href="https://doi.org/10.1162/dint_a_00132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The FAIR principles have been accepted globally as guidelines for improving data-driven science and data management practices, yet the incentives for researchers to change their practices are presently weak. In addition, data-driven science has been slow to embrace workflow technology despite clear evidence of recurring practices. To overcome these challenges, the Canonical Workflow Frameworks for Research (CWFR) initiative suggests a large-scale introduction of self-documenting workflow scripts to automate recurring processes or fragments thereof. This standardised approach, with FAIR Digital Objects as anchors, will be a significant milestone in the transition to FAIR data without adding additional load onto the researchers who stand to benefit most from it. This paper describes the CWFR approach and the activities of the CWFR initiative over the course of the last year or so, highlights several projects that hold promise for the CWFR approaches, including Galaxy, Jupyter Notebook, and RO Crate, and concludes with an assessment of the state of the field and the challenges ahead.},
  archive      = {J_DINT},
  author       = {Wittenburg, Peter and Hardisty, Alex and Le Franc, Yann and Mozaffari, Amirpasha and Peer, Limor and Skvortsov, Nikolay A. and Zhao, Zhiming and Spinuso, Alessandro},
  doi          = {10.1162/dint_a_00132},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {286-305},
  shortjournal = {Data Intell.},
  title        = {Canonical workflows to make data FAIR},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HPC-oriented canonical workflows for machine learning
applications in climate and weather prediction. <em>DINT</em>,
<em>4</em>(2), 271–285. (<a
href="https://doi.org/10.1162/dint_a_00131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Machine learning (ML) applications in weather and climate are gaining momentum as big data and the immense increase in High-performance computing (HPC) power are paving the way. Ensuring FAIR data and reproducible ML practices are significant challenges for Earth system researchers. Even though the FAIR principle is well known to many scientists, research communities are slow to adopt them. Canonical Workflow Framework for Research (CWFR) provides a platform to ensure the FAIRness and reproducibility of these practices without overwhelming researchers. This conceptual paper envisions a holistic CWFR approach towards ML applications in weather and climate, focusing on HPC and big data. Specifically, we discuss Fair Digital Object (FDO) and Research Object (RO) in the DeepRain project to achieve granular reproducibility. DeepRain is a project that aims to improve precipitation forecast in Germany by using ML. Our concept envisages the raster datacube to provide data harmonization and fast and scalable data access. We suggest the Juypter notebook as a single reproducible experiment. In addition, we envision JuypterHub as a scalable and distributed central platform that connects all these elements and the HPC resources to the researchers via an easy-to-use graphical interface.},
  archive      = {J_DINT},
  author       = {Mozaffari, Amirpasha and Langguth, Michael and Gong, Bing and Ahring, Jessica and Campos, Adrian Rojas and Nieters, Pascal and Escobar, Otoniel José Campos and Wittenbrink, Martin and Baumann, Peter and Schultz, Martin G.},
  doi          = {10.1162/dint_a_00131},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {271-285},
  shortjournal = {Data Intell.},
  title        = {HPC-oriented canonical workflows for machine learning applications in climate and weather prediction},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enabling canonical analysis workflows documented data
harmonization on global air quality data. <em>DINT</em>, <em>4</em>(2),
259–270. (<a href="https://doi.org/10.1162/dint_a_00130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Data harmonization and documentation of the data processing are essential prerequisites for enabling Canonical Analysis Workflows. The recently revised Terabyte-scale air quality database system, which the Tropospheric Ozone Assessment Report (TOAR) created, contains one of the world&#39;s largest collections of near-surface air quality measurements and considers FAIR data principles as an integral part. A special feature of our data service is the on-demand processing and product generation of several air quality metrics directly from the underlying database. In this paper, we show that the necessary data harmonization for establishing such online analysis services goes much deeper than the obvious issues of common data formats, variable names, and measurement units, and we explore how the generation of FAIR Digital Objects (FDO) in combination with automatically generated documentation may support Canonical Analysis Workflows for air quality and related data.},
  archive      = {J_DINT},
  author       = {Schröder, Sabine and Epp, Eleonora and Mozaffari, Amirpasha and Romberg, Mathilde and Selke, Niklas and Schultz, Martin G.},
  doi          = {10.1162/dint_a_00130},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {259-270},
  shortjournal = {Data Intell.},
  title        = {Enabling canonical analysis workflows documented data harmonization on global air quality data},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SWIRRL. Managing provenance-aware and reproducible
workspaces. <em>DINT</em>, <em>4</em>(2), 243–258. (<a
href="https://doi.org/10.1162/dint_a_00129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Modern interactive tools for data analysis and visualisation are designed to expose their functionalities as a service through the Web. We present in this paper a Web API (SWIRRL) that allows Virtual Research Environments (VREs) to easily integrate such tools in their websites and re-purpose them to their users. The API deals, on behalf of the clients, with the underlying complexity of allocating and managing resources within a target cloud platform. By combining storage and containerised services, offering analysis notebooks and other visualisation software, the API creates dedicated working sessions on-demand, which can be accessed collaboratively. Thanks to the API&#39;s support for workflow execution, SWIRRL workspaces can be automatically populated with data of interest collected from external data providers. The system keeps track of updates and changes affecting the data and the tools by adopting versioning and standard provenance technologies. Users are provided with interactive controls enabling traceability and recovery actions, including the possibility of creating executable snapshots of their environments. SWIRRL is built in cooperation with two research infrastructures in the field of solid earth science and climate data modeling. We report on the particular adoptions and use cases.},
  archive      = {J_DINT},
  author       = {Spinuso, Alessandro and Veldhuizen, Mats and Bailo, Daniele and Vinciarelli, Valerio and Langeland, Tor},
  doi          = {10.1162/dint_a_00129},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {243-258},
  shortjournal = {Data Intell.},
  title        = {SWIRRL. managing provenance-aware and reproducible workspaces},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). S-ProvFlow. Storing and exploring lineage data as a service.
<em>DINT</em>, <em>4</em>(2), 226–242. (<a
href="https://doi.org/10.1162/dint_a_00128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a set of configurable Web service and interactive tools, s-ProvFlow, for managing and exploiting records tracking data lineage during workflow runs. It facilitates detailed analysis of single executions. It helps users manage complex tasks by exposing the relationships between data, people, equipment and workflow runs intended to combine productively. Its logical model extends the PROV standard to precisely record parallel data-streaming applications. Its metadata handling encourages users to capture the application context by specifying how application attributes, often using standard vocabularies, should be added. These metadata records immediately help productivity as the interactive tools support their use in selection and bulk operations. Users rapidly appreciate the power of the encoded semantics as they reap the benefits. This improves the quality of provenance for users and management. Which in turn facilitates analysis of collections of runs, enabling users to manage results and validate procedures. It fosters reuse of data and methods and facilitates diagnostic investigations and optimisations. We present S-ProvFlow&#39;s use by scientists, research engineers and managers as part of the DARE hyper-platform as they create, validate and use their data-driven scientific workflows.},
  archive      = {J_DINT},
  author       = {Spinuso, Alessandro and Atkinson, Malcolm and Magnoni, Federica},
  doi          = {10.1162/dint_a_00128},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {226-242},
  shortjournal = {Data Intell.},
  title        = {S-ProvFlow. storing and exploring lineage data as a service},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Canonical workflows in simulation-based climate sciences.
<em>DINT</em>, <em>4</em>(2), 212–225. (<a
href="https://doi.org/10.1162/dint_a_00127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we present the derivation of Canonical Workflow Modules from current workflows in simulation-based climate science in support of the elaboration of a corresponding framework for simulation-based research. We first identified the different users and user groups in simulation-based climate science based on their reasons for using the resources provided at the German Climate Computing Center (DKRZ). What is special about this is that the DKRZ provides the climate science community with resources like high performance computing (HPC), data storage and specialised services, and hosts the World Data Center for Climate (WDCC). Therefore, users can perform their entire research workflows up to the publication of the data on the same infrastructure. Our analysis shows, that the resources are used by two primary user types: those who require the HPC-system to perform resource intensive simulations to subsequently analyse them and those who reuse, build-on and analyse existing data. We then further subdivided these top-level user categories based on their specific goals and analysed their typical, idealised workflows applied to achieve the respective project goals. We find that due to the subdivision and further granulation of the user groups, the workflows show apparent differences. Nevertheless, similar “Canonical Workflow Modules” can be clearly made out. These modules are “Data and Software (Re)use”, “Compute”, “Data and Software Storing”, “Data and Software Publication”, “Generating Knowledge” and in their entirety form the basis for a Canonical Workflow Framework for Research (CWFR). It is desirable that parts of the workflows in a CWFR act as FDOs, but we view this aspect critically. Also, we reflect on the question whether the derivation of Canonical Workflow modules from the analysis of current user behaviour still holds for future systems and work processes.},
  archive      = {J_DINT},
  author       = {Anders, Ivonne and Gehlen, Karsten Peters-von and Thiemann, Hannes},
  doi          = {10.1162/dint_a_00127},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {212-225},
  shortjournal = {Data Intell.},
  title        = {Canonical workflows in simulation-based climate sciences},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pilot study on the intercalibration of a categorisation
system for FAIRer digital objects related to sensitive data in the life
sciences. <em>DINT</em>, <em>4</em>(2), 196–211. (<a
href="https://doi.org/10.1162/dint_a_00126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Sharing sensitive data is a specific challenge for research infrastructures in the field of life sciences. For that reason a toolbox has been developed, providing resources for researchers who wish to share and use sensitive data, to support the workflows for handling these kinds of digital objects. Common and community approved annotations are required to be compliant with FAIR principles (Findability, Accessibility, Interoperability, Reusability). The toolbox makes use of a tagging (categorisation) system, allowing consistent labelling and categorisation of digital objects, in terms relevant to data sharing tasks and activities. A pilot study was performed within the Horizon 2020 project EOSC-Life, in which 2 experts from 6 life sciences research infrastructures were recruited to independently assign tags to the same set of 10 to 25 resources related to sensitive data management and data sharing (in total 110). Summary statistics of agreement and observer variation per research infrastructure are provided. The pilot study has shown that experts were able to attribute tags but in most cases with a considerable observer variation between experts. In the context of CWFR (Canonical Workflow Frameworks for Research), this indicates the necessity for careful definition, evaluation and validation of parameters and processes related to workflow descriptions. The results from this pilot study were used to tackle this issue by revising the categorisation system and providing an updated version.},
  archive      = {J_DINT},
  author       = {Ohmann, Christian and David, Romain and Abadia, Mónica Cano and Bietrix, Florence and Boiten, Jan-Willem and Canham, Steve and Chiusano, Maria Luisa and Dastrù, Walter and Laroquette, Arnaud and Longo, Dario and Mayrhofer, Michaela Theresia and Panagiotopoulou, Maria and Richard, Audrey and Verde, Pablo Emilio},
  doi          = {10.1162/dint_a_00126},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {196-211},
  shortjournal = {Data Intell.},
  title        = {Pilot study on the intercalibration of a categorisation system for FAIRer digital objects related to sensitive data in the life sciences},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The integration of a canonical workflow framework with an
informatics system for disease area research. <em>DINT</em>,
<em>4</em>(2), 186–195. (<a
href="https://doi.org/10.1162/dint_a_00125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A recurring pattern of access to existing databases, data analyses, formulation of new hypotheses, use of an experimental design, institutional review board approvals, data collection, curation, and storage within trusted digital repositories is observable during clinical research work. The workflows that support the repeated nature of these activities can be ascribed as a Canonical Workflow Framework for Research (CWFR). Disease area clinical research is protocol specific, and during data collection, the electronic case report forms can use Common Data Elements (CDEs) that have precisely defined questions and are associated with the specified value(s) as responses. The CDE-based CWFR is integrated with a biomedical research informatics computing system, which consists of a complete stack of technical layers including the Protocol and Form Research Management System. The unique data dictionaries associated with the CWFR for Traumatic Brain Injury and Parkinson&#39;s Disease resulted in the development of the Federal Interagency Traumatic Brain Injury and Parkinson&#39;s Disease Biomarker systems. Due to a canonical workflow, these two systems can use similar tools, applications, and service modules to create findable, accessible, interoperable, and reusable Digital Objects. The Digital Objects for Traumatic Brain Injury and Parkinson&#39;s disease contain all relevant information needed from the time data is collected, validated, and maintained within a Storage Repository for future access. All Traumatic Brain Injury and Parkinson&#39;s Disease studies can be shared as Research Objects that can be produced by aggregating related resources as information packages and is findable on the Internet by using unique identifiers. Overall, the integration of CWFR with an informatics system has resulted in the reuse of software applications for several National Institutes of Health-supported biomedical research programs.},
  archive      = {J_DINT},
  author       = {Navale, Vivek and McAuliffe, Matthew},
  doi          = {10.1162/dint_a_00125},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {186-195},
  shortjournal = {Data Intell.},
  title        = {The integration of a canonical workflow framework with an informatics system for disease area research},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Canonical workflow for machine learning tasks.
<em>DINT</em>, <em>4</em>(2), 173–185. (<a
href="https://doi.org/10.1162/dint_a_00124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. There is a huge gap between (1) the state of workflow technology on the one hand and the practices in the many labs working with data driven methods on the other and (2) the awareness of the FAIR principles and the lack of changes in practices during the last 5 years. The CWFR concept has been defined which is meant to combine these two intentions, increasing the use of workflow technology and improving FAIR compliance. In the study described in this paper we indicate how this could be applied to machine learning which is now used by almost all research disciplines with the well-known effects of a huge lack of repeatability and reproducibility.Researchers will only change practices if they can work efficiently and are not loaded with additional tasks. A comprehensive CWFR framework would be an umbrella for all steps that need to be carried out to do machine learning on selected data collections and immediately create a comprehensive and FAIR compliant documentation. The researcher is guided by such a framework and information once entered can easily be shared and reused. The many iterations normally required in machine learning can be dealt with efficiently using CWFR methods.Libraries of components that can be easily orchestrated using FAIR Digital Objects as a common entity to document all actions and to exchange information between steps without the researcher needing to understand anything about PIDs and FDO details is probably the way to increase efficiency in repeating research workflows. As the Galaxy project indicates, the availability of supporting tools will be important to let researchers use these methods. Other as the Galaxy framework suggests, however, it would be necessary to include all steps necessary for doing a machine learning task including those that require human interaction and to document all phases with the help of structured FDOs.},
  archive      = {J_DINT},
  author       = {Blanchi, Christophe and Gebre, Binyam and Wittenburg, Peter},
  doi          = {10.1162/dint_a_00124},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {173-185},
  shortjournal = {Data Intell.},
  title        = {Canonical workflow for machine learning tasks},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Canonical workflow for experimental research. <em>DINT</em>,
<em>4</em>(2), 155–172. (<a
href="https://doi.org/10.1162/dint_a_00123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The overall expectation of introducing Canonical Workflow for Experimental Research and FAIR digital objects (FDOs) can be summarised as reducing the gap between workflow technology and research practices to make experimental work more efficient and improve FAIRness without adding administrative load on the researchers. In this document, we will describe, with the help of an example, how CWFR could work in detail and improve research procedures. We have chosen the example of “experiments with human subjects” which stretches from planning an experiment to storing the collected data in a repository. While we focus on experiments with human subjects, we are convinced that CWFR can be applied to many other data generation processes based on experiments. The main challenge is to identify repeating patterns in existing research practices that can be abstracted to create CWFR. In this document, we will include detailed examples from different disciplines to demonstrate that CWFR can be implemented without violating specific disciplinary or methodological requirements. We do not claim to be comprehensive in all aspects, since these examples are meant to prove the concept of CWFR.},
  archive      = {J_DINT},
  author       = {Betz, Dirk and Biniossek, Claudia and Blanchi, Christophe and Henninger, Felix and Lauer, Thomas and Wieder, Philipp and Wittenburg, Peter and Zünkeler, Martin},
  doi          = {10.1162/dint_a_00123},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {155-172},
  shortjournal = {Data Intell.},
  title        = {Canonical workflow for experimental research},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editors’ note: Special issue on canonical workflow
frameworks for research. <em>DINT</em>, <em>4</em>(2), 149–154. (<a
href="https://doi.org/10.1162/dint_e_00122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This special issue is on Canonical Workflow Frameworks for Research (CWFR). A workflow refers to a sequence of activities, which may be more or less computer-based, used with regularity in the research process. CWFR aim to identify common patterns in such scientifically motivated workflows and to offer libraries of components based on FAIR Digital Objects as the integrative standard. Such CWFR components can be reusable independent of particular technologies, benefitting researchers in their daily work by making recurring activities more efficient, using automated workflow methods that would immediately create FAIR compliant data without adding burden.It is the goal of this special issue to provide readers with a deep exploration of CWFR and how it relates to research driven workflows, to existing workflow technologies, and to the use of FAIR Digital Objects. This issue covers articles examining core research activities including experimentation, data processing and analysis, data management, reproducibility, and publication. The articles comment on CWFR and its relation to these workflows, either conceptually in view of the current research ecosystem and infrastructure or more practically, focusing on a specific implementation, design, tool, or context relating to CWFR.The contributing authors are experts in their area. They include researchers, data professionals, data managers and curators, IT specialists and others who are using, developing, or experimenting with the effective use of canonical workflows and workflow patterns for data intensive research. As guest editors, it has been a privilege to work with such accomplished authors.It is our hope that this issue will stimulate further exploration of this subject. The papers in this issue address timely questions such as, what are the recurring patterns of work within or across institutions and research communities? What are the core elements of workflow technologies and how can they relate to the core ideas of CWFR? How well do existing integration standards and best practices address this? What is the potential of FDOs to support the goals of CWFR? How can research be protected against the ever-changing technological fashions?Finally, we are grateful to the journal for the opportunity to publish this special issue and to Dr. Fenghong Liu, Managing Editor-in-Chief, for her skilled guidance and support.Yann Le Franc, PhD is the CEO and Scientific Director of e-Science Data Factory S.A.S.U., a French R&amp;amp;D company aiming at proposing innovative solutions for FAIR data management to accelerate growth and progress. Yann Le Franc has a PhD in Neurosciences and Pharmacology (2004). After a postdoctoral experience in the US, he worked on data management projects in Neurosciences at the University of Antwerp (Belgium) and in the context of the International Neuroinformatics Coordinating Facility (INCF) where he developed a strong expertise in ontology design and semantic web technologies. He then contributed to several Horizon 2020 Research Infrastructure projects (EUDAT, EOSC-Hub, …) as an expert on Semantic Web and ontology design. He is co-chairing the Research Data Alliance Vocabulary and Semantic Service Interest Group and the FDO Semantic Group. He is also a member of the EOSC Semantic Interoperability Task Force. He is actively involved in the FAIRification and standardization of semantic artefacts in the context of FAIRsFAIR and OntoCommons projects. In parallel, he is the technical manager of the EOSC-Pillar project for the French National Computing Center for Higher Education (CINES).},
  archive      = {J_DINT},
  author       = {Wittenburg, Peter and Hardisty, Alex and Mozzafari, Amirpasha and Peer, Limor and Skvortsov, Nikolay and Spinuso, Alessandro and Zhao, Zhiming},
  doi          = {10.1162/dint_e_00122},
  journal      = {Data Intelligence},
  number       = {2},
  pages        = {149-154},
  shortjournal = {Data Intell.},
  title        = {Editors’ note: Special issue on canonical workflow frameworks for research},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Link prediction based on tensor decomposition for the
knowledge graph of COVID-19 antiviral drug. <em>DINT</em>,
<em>4</em>(1), 134–148. (<a
href="https://doi.org/10.1162/dint_a_00117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Due to the large-scale spread of COVID-19, which has a significant impact on human health and social economy, developing effective antiviral drugs for COVID-19 is vital to saving human lives. Various biomedical associations, e.g., drug-virus and viral protein-host protein interactions, can be used for building biomedical knowledge graphs. Based on these sources, large-scale knowledge reasoning algorithms can be used to predict new links between antiviral drugs and viruses. To utilize the various heterogeneous biomedical associations, we proposed a fusion strategy to integrate the results of two tensor decomposition-based models (i.e., CP-N3 and ComplEx-N3). Sufficient experiments indicated that our method obtained high performance (MRR=0.2328). Compared with CP-N3, the mean reciprocal rank (MRR) is increased by 3.3\% and compared with ComplEx-N3, the MRR is increased by 3.5\%. Meanwhile, we explored the relationship between the performance and relationship types, which indicated that there is a negative correlation (PCC=0.446, P-value=2.26e-194) between the performance of triples predicted by our method and edge betweenness.},
  archive      = {J_DINT},
  author       = {Jia, Ting and Yang, Yuxia and Lu, Xi and Zhu, Qiang and Yang, Kuo and Zhou, Xuezhong},
  doi          = {10.1162/dint_a_00117},
  journal      = {Data Intelligence},
  number       = {1},
  pages        = {134-148},
  shortjournal = {Data Intell.},
  title        = {Link prediction based on tensor decomposition for the knowledge graph of COVID-19 antiviral drug},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Certainty-based preference completion. <em>DINT</em>,
<em>4</em>(1), 112–133. (<a
href="https://doi.org/10.1162/dint_a_00115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. As from time to time it is impractical to ask agents to provide linear orders over all alternatives, for these partial rankings it is necessary to conduct preference completion. Specifically, the personalized preference of each agent over all the alternatives can be estimated with partial rankings from neighboring agents over subsets of alternatives. However, since the agents&#39; rankings are nondeterministic, where they may provide rankings with noise, it is necessary and important to conduct the certainty-based preference completion. Hence, in this paper firstly, for alternative pairs with the obtained ranking set, a bijection has been built from the ranking space to the preference space, and the certainty and conflict of alternative pairs have been evaluated with a well-built statistical measurement Probability-Certainty Density Function on subjective probability, respectively. Then, a certainty-based voting algorithm based on certainty and conflict has been taken to conduct the certainty-based preference completion. Moreover, the properties of the proposed certainty and conflict have been studied empirically, and the proposed approach on certainty-based preference completion for partial rankings has been experimentally validated compared to state-of-arts approaches with several datasets.},
  archive      = {J_DINT},
  author       = {Li, Lei and Xue, Minghe and Zhang, Zan and Chen, Huanhuan and Wu, Xindong},
  doi          = {10.1162/dint_a_00115},
  journal      = {Data Intelligence},
  number       = {1},
  pages        = {112-133},
  shortjournal = {Data Intell.},
  title        = {Certainty-based preference completion},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting vicious cycles in urban problem knowledge graph
using inference rules. <em>DINT</em>, <em>4</em>(1), 88–111. (<a
href="https://doi.org/10.1162/dint_a_00113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Urban areas have many problems, including homelessness, graffiti, and littering. These problems are influenced by various factors and are linked to each other; thus, an understanding of the problem structure is required in order to detect and solve the root problems that generate vicious cycles. Moreover, before implementing action plans to solve these problems, local governments need to estimate cost-effectiveness when the plans are carried out. Therefore, this paper proposed constructing an urban problem knowledge graph that would include urban problems&#39; causality and the related cost information in budget sheets. In addition, this paper proposed a method for detecting vicious cycles of urban problems using SPARQL queries with inference rules from the knowledge graph. Finally, several root problems that led to vicious cycles were detected. Urban-problem experts evaluated the extracted causal relations.},
  archive      = {J_DINT},
  author       = {Egami, Shusaku and Kawamura, Takahiro and Kozaki, Kouji and Ohsuga, Akihiko},
  doi          = {10.1162/dint_a_00113},
  journal      = {Data Intelligence},
  number       = {1},
  pages        = {88-111},
  shortjournal = {Data Intell.},
  title        = {Detecting vicious cycles in urban problem knowledge graph using inference rules},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Public emotional diffusion over COVID-19 related tweets
posted by major public health agencies in the united states.
<em>DINT</em>, <em>4</em>(1), 66–87. (<a
href="https://doi.org/10.1162/dint_a_00101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Since the end of 2019, the COVID-19 outbreak worldwide has not only presented challenges for government agencies in addressing public health emergency, but also tested their capacity in dealing with public opinion on social media and responding to social emergencies. To understand the impact of COVID-19 related tweets posted by the major public health agencies in the United States on public emotion, this paper studied public emotional diffusion in the tweets network, including its process and characteristics, by taking Twitter users of four official public health systems in the United States as an example. We extracted the interactions between tweets in the COVID-19-TweetIds data set and drew the tweets diffusion network. We proposed a method to measure the characteristics of the emotional diffusion network, with which we analyzed the changes of the public emotional intensity and the proportion of emotional polarity, investigated the emotional influence of key nodes and users, and the emotional diffusion of tweets at different tweeting time, tweet topics and the tweet posting agencies. The results show that the emotional polarity of tweets has changed from negative to positive with the improvement of pandemic management measures. The public&#39;s emotional polarity on pandemic related topics tends to be negative, and the emotional intensity of management measures such as pandemic medical services turn from positive to negative to the greatest extent, while the emotional intensity of pandemic related knowledge changes the most. The tweets posted by the Centers for Disease Control and Prevention and the Food and Drug Administration of the United States have a broad impact on public emotions, and the emotional spread of tweets&#39; polarity eventually forms a very close proportion of opposite emotions.},
  archive      = {J_DINT},
  author       = {Xi, Haixu and Zhang, Chengzhi and Zhao, Yi and He, Sheng},
  doi          = {10.1162/dint_a_00101},
  journal      = {Data Intelligence},
  number       = {1},
  pages        = {66-87},
  shortjournal = {Data Intell.},
  title        = {Public emotional diffusion over COVID-19 related tweets posted by major public health agencies in the united states},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CKGSE: A prototype search engine for chinese knowledge
graphs. <em>DINT</em>, <em>4</em>(1), 41–65. (<a
href="https://doi.org/10.1162/dint_a_00118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Nowadays, with increasing open knowledge graphs (KGs) being published on the Web, users depend on open data portals and search engines to find KGs. However, existing systems provide search services and present results with only metadata while ignoring the contents of KGs, i.e., triples. It brings difficulty for users&#39; comprehension and relevance judgement. To overcome the limitation of metadata, in this paper we propose a content-based search engine for open KGs named CKGSE. Our system provides keyword search, KG snippet generation, KG profiling and browsing, all based on KGs&#39; detailed, informative contents rather than their brief, limited metadata. To evaluate its usability, we implement a prototype with Chinese KGs crawled from OpenKG.CN and report some preliminary results and findings.},
  archive      = {J_DINT},
  author       = {Wang, Xiaxia and Lin, Tengteng and Luo, Weiqing and Cheng, Gong and Qu, Yuzhong},
  doi          = {10.1162/dint_a_00118},
  journal      = {Data Intelligence},
  number       = {1},
  pages        = {41-65},
  shortjournal = {Data Intell.},
  title        = {CKGSE: A prototype search engine for chinese knowledge graphs},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrating manifold knowledge for global entity linking
with heterogeneous graphs. <em>DINT</em>, <em>4</em>(1), 20–40. (<a
href="https://doi.org/10.1162/dint_a_00116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Entity Linking (EL) aims to automatically link the mentions in unstructured documents to corresponding entities in a knowledge base (KB), which has recently been dominated by global models. Although many global EL methods attempt to model the topical coherence among all linked entities, most of them failed in exploiting the correlations among manifold knowledge helpful for linking, such as the semantics of mentions and their candidates, the neighborhood information of candidate entities in KB and the fine-grained type information of entities. As we will show in the paper, interactions among these types of information are very useful for better characterizing the topic features of entities and more accurately estimating the topical coherence among all the referred entities within the same document. In this paper, we present a novel HEterogeneous Graph-based Entity Linker (HEGEL) for global entity linking, which builds an informative heterogeneous graph for every document to collect various linking clues. Then HEGEL utilizes a novel heterogeneous graph neural network (HGNN) to integrate the different types of manifold information and model the interactions among them. Experiments on the standard benchmark datasets demonstrate that HEGEL can well capture the global coherence and outperforms the prior state-of-the-art EL methods.},
  archive      = {J_DINT},
  author       = {Chen, Zhibin and Wu, Yuting and Feng, Yansong and Zhao, Dongyan},
  doi          = {10.1162/dint_a_00116},
  journal      = {Data Intelligence},
  number       = {1},
  pages        = {20-40},
  shortjournal = {Data Intell.},
  title        = {Integrating manifold knowledge for global entity linking with heterogeneous graphs},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual entity linking via multi-modal learning.
<em>DINT</em>, <em>4</em>(1), 1–19. (<a
href="https://doi.org/10.1162/dint_a_00114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Existing visual scene understanding methods mainly focus on identifying coarse-grained concepts about the visual objects and their relationships, largely neglecting fine-grained scene understanding. In fact, many data-driven applications on the Web (e.g., news-reading and e-shopping) require accurate recognition of much less coarse concepts as entities and proper linking them to a knowledge graph (KG), which can take their performance to the next level. In light of this, in this paper, we identify a new research task: visual entity linking for fine-grained scene understanding. To accomplish the task, we first extract features of candidate entities from different modalities, i.e., visual features, textual features, and KG features. Then, we design a deep modal-attention neural network-based learning-to-rank method which aggregates all features and maps visual objects to the entities in KG. Extensive experimental results on the newly constructed dataset show that our proposed method is effective as it significantly improves the accuracy performance from 66.46\% to 83.16\% compared with baselines.},
  archive      = {J_DINT},
  author       = {Zheng, Qiushuo and Wen, Hao and Wang, Meng and Qi, Guilin},
  doi          = {10.1162/dint_a_00114},
  journal      = {Data Intelligence},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Data Intell.},
  title        = {Visual entity linking via multi-modal learning},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
