<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JRSSSC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jrsssc---89">JRSSSC - 89</h2>
<ul>
<li><details>
<summary>
(2022). Utility-based bayesian personalized treatment selection for
advanced breast cancer. <em>Journal of the Royal Statistical Society:
Series C (Applied Statistics)</em>, <em>71</em>(5), O1. (<a
href="https://doi.org/10.1111/rssc.12606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  doi     = {10.1111/rssc.12606},
  journal = {Journal of the Royal Statistical Society: Series C},
  number  = {5},
  pages   = {O1},
  title   = {Utility-based bayesian personalized treatment selection for advanced breast cancer},
  volume  = {71},
  year    = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contents of volume 71, 2022. <em>JRSSSC</em>,
<em>71</em>(5), 2038–2041. (<a
href="https://doi.org/10.1111/rssc.12605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSC},
  doi          = {10.1111/rssc.12605},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {2038-2041},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Contents of volume 71, 2022},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian modelling strategies for borrowing of information
in randomised basket trials. <em>JRSSSC</em>, <em>71</em>(5), 2014–2037.
(<a href="https://doi.org/10.1111/rssc.12602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Basket trials are an innovative precision medicine clinical trial design evaluating a single targeted therapy across multiple diseases that share a common characteristic. To date, most basket trials have been conducted in early-phase oncology settings, for which several Bayesian methods permitting information sharing across subtrials have been proposed. With the increasing interest of implementing randomised basket trials, information borrowing could be exploited in two ways; considering the commensurability of either the treatment effects or the outcomes specific to each of the treatment groups between the subtrials. In this article, we extend a previous analysis model based on distributional discrepancy for borrowing over the subtrial treatment effects (‘treatment effect borrowing’, TEB) to borrowing over the subtrial groupwise responses (‘treatment response borrowing’, TRB). Simulation results demonstrate that both modelling strategies provide substantial gains over an approach with no borrowing. TRB outperforms TEB especially when subtrial sample sizes are small on all operational characteristics, while the latter has considerable gains in performance over TRB when subtrial sample sizes are large, or the treatment effects and groupwise mean responses are noticeably heterogeneous across subtrials. Further, we notice that TRB, and TEB can potentially lead to different conclusions in the analysis of real data.},
  archive      = {J_JRSSSC},
  author       = {Ouma, Luke O. and Grayling, Michael J. and Wason, James M. S. and Zheng, Haiyan},
  doi          = {10.1111/rssc.12602},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {2014-2037},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Bayesian modelling strategies for borrowing of information in randomised basket trials},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combining cytotoxic agents with continuous dose levels in
seamless phase i-II clinical trials. <em>JRSSSC</em>, <em>71</em>(5),
1996–2013. (<a href="https://doi.org/10.1111/rssc.12598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phase I-II cancer clinical trial designs are intended to accelerate drug development. In cases where efficacy cannot be ascertained in a short period of time, it is common to divide the study in two stages: (i) a first stage in which dose is escalated based only on toxicity data and we look for the maximum tolerated dose (MTD) set and (ii) a second stage in which we search for the most efficacious dose within the MTD set. Current available approaches in the area of continuous dose levels involve fixing the MTD after stage I and discarding all collected stage I efficacy data. However, this methodology is clearly inefficient when there is a unique patient population present across stages. In this article, we propose a two-stage design for the combination of two cytotoxic agents assuming a single patient population across the entire study. In stage I, conditional escalation with overdose control is used to allocate successive cohorts of patients. In stage II, we employ an adaptive randomisation approach to allocate patients to drug combinations along the estimated MTD curve, which is constantly updated. The proposed methodology is assessed with extensive simulations in the context of a real case study.},
  archive      = {J_JRSSSC},
  author       = {Jiménez, José L. and Tighiouart, Mourad},
  doi          = {10.1111/rssc.12598},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1996-2013},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Combining cytotoxic agents with continuous dose levels in seamless phase I-II clinical trials},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian multi-level mixed-effects model for influenza
dynamics. <em>JRSSSC</em>, <em>71</em>(5), 1978–1995. (<a
href="https://doi.org/10.1111/rssc.12603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influenza A viruses (IAV) are the only influenza viruses known to cause flu pandemics. Understanding the evolution of different sub-types of IAV on their natural hosts is important for preventing and controlling the virus. We propose a mechanism-based Bayesian multi-level mixed-effects model for characterising influenza viral dynamics, described by a set of ordinary differential equations (ODE). Both strain-specific and subject-specific random effects are included for the ODE parameters. Our models can characterise the common features in the population while taking into account the variations among individuals. The random effects selection is conducted at strain level through re-parameterising the covariance parameters of the corresponding random effect distribution. Our method does not need to solve ODE directly. We demonstrate that the posterior computation can proceed via a simple and efficient Markov chain Monte Carlo algorithm. The methods are illustrated using simulated data and a real data from a study relating virus load estimates from influenza infections in ducks.},
  archive      = {J_JRSSSC},
  author       = {Huang, Hanwen},
  doi          = {10.1111/rssc.12603},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1978-1995},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Bayesian multi-level mixed-effects model for influenza dynamics},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Derivation of maternal dietary patterns accounting for
regional heterogeneity. <em>JRSSSC</em>, <em>71</em>(5), 1957–1977. (<a
href="https://doi.org/10.1111/rssc.12604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Latent class models are often used to characterise dietary patterns. Yet, when subtle variations exist across different sub-populations, overall population patterns can be masked and affect statistical inference on health outcomes. We address this concern with a flexible supervised clustering approach, introduced as Supervised Robust Profile Clustering, that identifies outcome-dependent population-based patterns, while partitioning out subpopulation pattern differences. Using dietary data from the 1997–2011 National Birth Defects Prevention Study, we determine how maternal dietary profiles associate with orofacial clefts among offspring. Results indicate mothers who consume a higher proportion of fruits and vegetables compared to land meats lower the proportion of progeny with orofacial cleft defect.},
  archive      = {J_JRSSSC},
  author       = {Stephenson, Briana J. K. and Herring, Amy H. and Olshan, Andrew F.},
  doi          = {10.1111/rssc.12604},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1957-1977},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Derivation of maternal dietary patterns accounting for regional heterogeneity},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-parametric calibration of multiple related radiocarbon
determinations and their calendar age summarisation. <em>JRSSSC</em>,
<em>71</em>(5), 1918–1956. (<a
href="https://doi.org/10.1111/rssc.12599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to fluctuations in past radiocarbon ( ⁠ 14 14 14 C) levels, calibration is required to convert 14 14 14 C determinations X i X i Xi into calendar ages θ i θ i θi ⁠ . In many studies, we wish to calibrate a set of related samples taken from the same site or context, which have calendar ages drawn from the same shared, but unknown, density f ( θ ) f ( θ ) f(θ) ⁠ . Calibration of X 1 , … , X n X 1 , … , X n X1,…,Xn can be improved significantly by incorporating the knowledge that the samples are related. Furthermore, summary estimates of the underlying shared f ( θ ) f ( θ ) f(θ) can provide valuable information on changes in population size/activity over time. Most current approaches require a parametric specification for f ( θ ) f ( θ ) f(θ) which is often not appropriate. We develop a rigorous non-parametric Bayesian approach using a Dirichlet process mixture model, with slice sampling to address the multi-modality typical within 14 14 14 C calibration. Our approach simultaneously calibrates the set of 14 14 14 C determinations and provides a predictive estimate for the underlying calendar age of a future sample. We show, in a simulation study, the improvement in calendar age estimation when jointly calibrating related samples using our approach, compared with calibration of each 14 14 14 C determination independently. We also illustrate the use of the predictive calendar age estimate to provide insight on activity levels over time using three real-life case studies.},
  archive      = {J_JRSSSC},
  author       = {Heaton, Timothy J.},
  doi          = {10.1111/rssc.12599},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1918-1956},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Non-parametric calibration of multiple related radiocarbon determinations and their calendar age summarisation},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal approximate choice designs for a two-step coffee
choice, taste and choice again experiment. <em>JRSSSC</em>,
<em>71</em>(5), 1895–1917. (<a
href="https://doi.org/10.1111/rssc.12601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work deals with consumers&#39; preferences about coffee. Firstly, a choice experiment is performed on a sample of potential consumers. Following this, a sensory test involving the tasting of two varieties of coffee is carried out with the respondents, after which the same choice experiment is supplied to them again. An innovative approach for building heterogeneous choice designs is specifically developed for the case-study, based on approximate design theory and compound design criterion. Panel Mixed Logit models are used, thereby allowing for the inclusion of correlation among consumers&#39; responses; choice-sets are supplied to a proportion of respondents according to optimal weights. The estimation results of the Panel Mixed Logit model are satisfactory, confirming the validity of the proposed approach.},
  archive      = {J_JRSSSC},
  author       = {Nikiforova, Nedka Dechkova and Berni, Rossella and López-Fidalgo, Jesús Fernando},
  doi          = {10.1111/rssc.12601},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1895-1917},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Optimal approximate choice designs for a two-step coffee choice, taste and choice again experiment},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Flexible domain prediction using mixed effects random
forests. <em>JRSSSC</em>, <em>71</em>(5), 1865–1894. (<a
href="https://doi.org/10.1111/rssc.12600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper promotes the use of random forests as versatile tools for estimating spatially disaggregated indicators in the presence of small area-specific sample sizes. Small area estimators are predominantly conceptualised within the regression-setting and rely on linear mixed models to account for the hierarchical structure of the survey data. In contrast, machine learning methods offer non-linear and non-parametric alternatives, combining excellent predictive performance and a reduced risk of model-misspecification. Mixed effects random forests combine advantages of regression forests with the ability to model hierarchical dependencies. This paper provides a coherent framework based on mixed effects random forests for estimating small area averages and proposes a non-parametric bootstrap estimator for assessing the uncertainty of the estimates. We illustrate advantages of our proposed methodology using Mexican income-data from the state Nuevo León. Finally, the methodology is evaluated in model-based and design-based simulations comparing the proposed methodology to traditional regression-based approaches for estimating small area averages.},
  archive      = {J_JRSSSC},
  author       = {Krennmair, Patrick and Schmid, Timo},
  doi          = {10.1111/rssc.12600},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1865-1894},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Flexible domain prediction using mixed effects random forests},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bayesian model for estimating sustainable development goal
indicator 4.1.2: School completion rates. <em>JRSSSC</em>,
<em>71</em>(5), 1822–1864. (<a
href="https://doi.org/10.1111/rssc.12595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating school completion is crucial for monitoring Sustainable Development Goal (SDG) 4 on education. The recently introduced SDG indicator 4.1.2, defined as the percentage of children aged 3–5 years above the expected completion age of a given level of education that have completed the respective level, differs from enrolment indicators in that it relies primarily on household surveys. This introduces a number of challenges including gaps between survey waves, conflicting estimates, age misreporting and delayed completion. We introduce the Adjusted Bayesian Completion Rates (ABCR) model to address these challenges and produce the first complete and consistent time series for SDG indicator 4.1.2, by school level and sex, for 164 countries. Validation exercises indicate that the model appears well-calibrated and offers a meaningful improvement over simpler approaches in predictive performance. The ABCR model is now used by the United Nations to monitor completion rates for all countries with available survey data.},
  archive      = {J_JRSSSC},
  author       = {Dharamshi, Ameer and Barakat, Bilal and Alkema, Leontine and Antoninis, Manos},
  doi          = {10.1111/rssc.12595},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1822-1864},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {A bayesian model for estimating sustainable development goal indicator 4.1.2: School completion rates},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient estimation of the marginal mean of recurrent
events. <em>JRSSSC</em>, <em>71</em>(5), 1787–1821. (<a
href="https://doi.org/10.1111/rssc.12586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent events are often encountered in clinical and epidemiological studies where a terminal event is also observed. With recurrent events data it is of great interest to estimate the marginal mean of the cumulative number of recurrent events experienced prior to the terminal event. The standard nonparametric estimator was suggested in Cook and Lawless and further developed in Ghosh and Lin. We here investigate the efficiency of this estimator that, surprisingly, has not been studied before. We rewrite the standard estimator as an inverse probability of censoring weighted estimator. From this representation we derive an efficient augmented estimator using efficient estimation theory for right-censored data. We show that the standard estimator is efficient in settings with no heterogeneity. In other settings with different sources of heterogeneity, we show theoretically and by simulations that the efficiency can be greatly improved when an efficient augmented estimator based on dynamic predictions is employed, at no extra cost to robustness. The estimators are applied and compared to study the mean number of catheter-related bloodstream infections in heterogeneous patients with chronic intestinal failure who can possibly die, and the efficiency gain is highlighted in the resulting point-wise confidence intervals.},
  archive      = {J_JRSSSC},
  author       = {Cortese, Giuliana and Scheike, Thomas H.},
  doi          = {10.1111/rssc.12586},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1787-1821},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Efficient estimation of the marginal mean of recurrent events},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sequential one-step estimator by sub-sampling for customer
churn analysis with massive data sets. <em>JRSSSC</em>, <em>71</em>(5),
1753–1786. (<a href="https://doi.org/10.1111/rssc.12597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customer churn is one of the most important concerns for large companies. Currently, massive data are often encountered in customer churn analysis, which bring new challenges for model computation. To cope with these concerns, sub-sampling methods are often used to accomplish data analysis tasks of large scale. To cover more informative samples in one sampling round, classic sub-sampling methods need to compute sampling probabilities for all data points. However, this method creates a huge computational burden for data sets of large scale and therefore, is not applicable in practice. In this study, we propose a sequential one-step (SOS) estimation method based on repeated sub-sampling data sets. In the SOS method, data points need to be sampled only with probabilities, and the sampling step is conducted repeatedly. In each sampling step, a new estimate is computed via one-step updating based on the newly sampled data points. This leads to a sequence of estimates, of which the final SOS estimate is their average. We theoretically show that both the bias and the standard error of the SOS estimator can decrease with increasing sub-sampling sizes or sub-sampling times. The finite sample SOS performances are assessed through simulations. Finally, we apply this SOS method to analyse a real large-scale customer churn data set in a securities company. The results show that the SOS method has good interpretability and prediction power in this real application.},
  archive      = {J_JRSSSC},
  author       = {Wang, Feifei and Huang, Danyang and Gao, Tianchen and Wu, Shuyuan and Wang, Hansheng},
  doi          = {10.1111/rssc.12597},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1753-1786},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Sequential one-step estimator by sub-sampling for customer churn analysis with massive data sets},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The saturated pairwise interaction gibbs point process as a
joint species distribution model. <em>JRSSSC</em>, <em>71</em>(5),
1721–1752. (<a href="https://doi.org/10.1111/rssc.12596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an effort to effectively model observed patterns in the spatial configuration of individuals of multiple species in nature, we introduce the saturated pairwise interaction Gibbs point process. Its main strength lies in its ability to model both attraction and repulsion within and between species, over different scales. As such, it is particularly well-suited to the study of associations in complex ecosystems. Based on the existing literature, we provide an easy to implement fitting procedure as well as a technique to make inference for the model parameters. We also prove that under certain hypotheses the point process is locally stable, which allows us to use the well-known ‘coupling from the past’ algorithm to draw samples from the model. Different numerical experiments show the robustness of the model. We study three different ecological data sets, demonstrating in each one that our model helps disentangle competing ecological effects on species&#39; distribution.},
  archive      = {J_JRSSSC},
  author       = {Flint, Ian and Golding, Nick and Vesk, Peter and Wang, Yan and Xia, Aihua},
  doi          = {10.1111/rssc.12596},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1721-1752},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {The saturated pairwise interaction gibbs point process as a joint species distribution model},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contour models for physical boundaries enclosing star-shaped
and approximately star-shaped polygons. <em>JRSSSC</em>, <em>71</em>(5),
1688–1720. (<a href="https://doi.org/10.1111/rssc.12592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boundaries on spatial fields divide regions with particular features from surrounding background areas. Methods to identify boundary lines from interpolated spatial fields are well established. Less attention has been paid to how to model sequences of connected spatial points. Such models are needed for physical boundaries. For example, in the Arctic ocean, large contiguous areas are covered by sea ice, or frozen ocean water. We define the ice edge contour as the ordered sequences of spatial points that connect to form a line around set(s) of contiguous grid boxes with sea ice present. Polar scientists need to describe how this contiguous area behaves in present and historical data and under future climate change scenarios. We introduce the Gaussian Star-shaped Contour Model (GSCM) for modelling boundaries represented as connected sequences of spatial points such as the sea ice edge. GSCMs generate sequences of spatial points via generating sets of distances in various directions from a fixed starting point. The GSCM can be applied to contours that enclose regions that are star-shaped polygons or approximately star-shaped polygons. Metrics are introduced to assess the extent to which a polygon deviates from star-shapedness. Simulation studies illustrate the performance of the GSCM in different situations.},
  archive      = {J_JRSSSC},
  author       = {Director, Hannah M. and Raftery, Adrian E.},
  doi          = {10.1111/rssc.12592},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1688-1720},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Contour models for physical boundaries enclosing star-shaped and approximately star-shaped polygons},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Score test for assessing the conditional dependence in
latent class models and its application to record linkage.
<em>JRSSSC</em>, <em>71</em>(5), 1663–1687. (<a
href="https://doi.org/10.1111/rssc.12590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Fellegi–Sunter model has been widely used in probabilistic record linkage despite its often invalid conditional independence assumption. Prior research has demonstrated that conditional dependence latent class models yield improved match performance when using the correct conditional dependence structure. With a misspecified conditional dependence structure, these models can yield worse performance. It is, therefore, critically important to correctly identify the conditional dependence structure. Existing methods for identifying the conditional dependence structure include the correlation residual plot, the log-odds ratio check, and the bivariate residual, all of which have been shown to perform inadequately. Bootstrap bivariate residual approach and score test have also been proposed and found to have better performance, with the score test having greater power and lower computational burden. In this paper, we extend the score-test-based approach to account for different conditional dependence structures. Through a simulation study, we develop practical recommendations on the utilisation of the score test and assess the match performance with conditional dependence identified by the proposed method. Performance of the proposed method is further evaluated using a real-world record linkage example. Findings show that the proposed method leads to improved matching accuracy relative to the Fellegi–Sunter model.},
  archive      = {J_JRSSSC},
  author       = {Xu, Huiping and Li, Xiaochun and Zhang, Zuoyi and Grannis, Shaun},
  doi          = {10.1111/rssc.12590},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1663-1687},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Score test for assessing the conditional dependence in latent class models and its application to record linkage},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leveraging network structure to improve pooled testing
efficiency. <em>JRSSSC</em>, <em>71</em>(5), 1648–1662. (<a
href="https://doi.org/10.1111/rssc.12594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Screening is a powerful tool for infection control, allowing for infectious individuals, whether they be symptomatic or asymptomatic, to be identified and isolated. The resource burden of regular and comprehensive screening can often be prohibitive, however. One such measure to address this is pooled testing, whereby groups of individuals are each given a composite test; should a group receive a positive diagnostic test result, those comprising the group are then tested individually. Infectious disease is spread through a transmission network, and this paper shows how assigning individuals to pools based on this underlying network can improve the efficiency of the pooled testing strategy, thereby reducing the resource burden. We designed a simulated annealing algorithm to improve the pooled testing efficiency as measured by the ratio of the expected number of correct classifications to the expected number of tests performed. We then evaluated our approach using an agent-based model designed to simulate the spread of SARS-CoV-2 in a school setting. Our results suggest that our approach can decrease the number of tests required to regularly screen the student body, and that these reductions are quite robust to assigning pools based on partially observed or noisy versions of the network.},
  archive      = {J_JRSSSC},
  author       = {Sewell, Daniel K.},
  doi          = {10.1111/rssc.12594},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1648-1662},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Leveraging network structure to improve pooled testing efficiency},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-parametric time-to-event modelling of lengths of
hospital stays. <em>JRSSSC</em>, <em>71</em>(5), 1623–1647. (<a
href="https://doi.org/10.1111/rssc.12593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Length of stay (LOS) is an essential metric for the quality of hospital care. Published works on LOS analysis have primarily focused on skewed LOS distributions and the influences of patient diagnostic characteristics. Few authors have considered the events that terminate a hospital stay: Both successful discharge and death could end a hospital stay but with completely different implications. Modelling the time to the first occurrence of discharge or death obscures the true nature of LOS. In this research, we propose a structure that simultaneously models the probabilities of discharge and death. The model has a flexible formulation that accounts for both additive and multiplicative effects of factors influencing the occurrence of death and discharge. We present asymptotic properties of the parameter estimates so that valid inference can be performed for the parametric as well as nonparametric model components. Simulation studies confirmed the good finite-sample performance of the proposed method. As the research is motivated by practical issues encountered in LOS analysis, we analysed data from two real clinical studies to showcase the general applicability of the proposed model.},
  archive      = {J_JRSSSC},
  author       = {Li, Yang and Liu, Hao and Wang, Xiaoshen and Tu, Wanzhu},
  doi          = {10.1111/rssc.12593},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1623-1647},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Semi-parametric time-to-event modelling of lengths of hospital stays},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Utility-based bayesian personalized treatment selection for
advanced breast cancer. <em>JRSSSC</em>, <em>71</em>(5), 1605–1622. (<a
href="https://doi.org/10.1111/rssc.12582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Bayesian method is proposed for personalized treatment selection in settings where data are available from a randomized clinical trial with two or more outcomes. The motivating application is a randomized trial that compared letrozole plus bevacizumab to letrozole alone as first-line therapy for hormone receptor-positive advanced breast cancer. The combination treatment arm had larger median progression-free survival time, but also a higher rate of severe toxicities. This suggests that the risk-benefit trade-off between these two outcomes should play a central role in selecting each patient&#39;s treatment, particularly since older patients are less likely to tolerate severe toxicities. To quantify the desirability of each possible outcome combination for an individual patient, we elicited from breast cancer oncologists a utility function that varied with age. The utility was used as an explicit criterion for quantifying risk-benefit trade-offs when making personalized treatment selections. A Bayesian nonparametric multivariate regression model with a dependent Dirichlet process prior was fit to the trial data. Under the fitted model, a new patient&#39;s treatment can be selected based on the posterior predictive utility distribution. For the breast cancer trial dataset, the optimal treatment depends on the patient&#39;s age, with the combination preferable for patients 70 years or younger and the single agent preferable for patients older than 70.},
  archive      = {J_JRSSSC},
  author       = {Lee, Juhee and Thall, Peter F. and Lim, Bora and Msaouel, Pavlos},
  doi          = {10.1111/rssc.12582},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1605-1622},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Utility-based bayesian personalized treatment selection for advanced breast cancer},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Measuring diachronic sense change: New models and monte
carlo methods for bayesian inference. <em>JRSSSC</em>, <em>71</em>(5),
1569–1604. (<a href="https://doi.org/10.1111/rssc.12591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a bag-of-words model, the of a word with multiple meanings, for example ‘bank’ (used either in a river-bank or an institution sense), are represented as probability distributions over context words, and sense prevalence is represented as a probability distribution over senses. Both of these may change with time. Modelling and measuring this kind of sense change are challenging due to the typically high-dimensional parameter space and sparse datasets. A recently published corpus of ancient Greek texts contains expert-annotated sense labels for selected target words. Automatic sense-annotation for the word ‘kosmos’ (meaning decoration, order or world) has been used as a test case in recent work with related generative models and Monte Carlo methods. We adapt an existing generative sense change model to develop a simpler model for the main effects of sense and time, and give Markov Chain Monte Carlo methods for Bayesian inference on all these models that are more efficient than existing methods. We carry out automatic sense-annotation of snippets containing ‘kosmos’ using our model, and measure the time-evolution of its three senses and their prevalence. As far as we are aware, ours is the first analysis of this data, within the class of generative models we consider, that quantifies uncertainty and returns credible sets for evolving sense prevalence in good agreement with those given by expert annotation.},
  archive      = {J_JRSSSC},
  author       = {Zafar, Schyan and Nicholls, Geoff K.},
  doi          = {10.1111/rssc.12591},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1569-1604},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Measuring diachronic sense change: New models and monte carlo methods for bayesian inference},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Environmental engel curves: A neural network approach.
<em>JRSSSC</em>, <em>71</em>(5), 1543–1568. (<a
href="https://doi.org/10.1111/rssc.12588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environmental Engel curves describe how households&#39; income relates to the pollution associated with the services and goods consumed. This paper estimates these curves with neural networks using the novel dataset constructed in Levinson and O&#39;Brien. We provide further statistical rigor to the empirical analysis by constructing prediction intervals obtained from novel neural network methods such as extra-neural nets and MC dropout. The application of these techniques for five different pollutants allow us to confirm statistically that Environmental Engel curves are upward sloping, have income elasticities smaller than one and shift down, becoming more concave, over time. Importantly, for the last year of the sample, we find an inverted U shape that suggests the existence of a maximum in pollution for medium-to-high levels of household income beyond which pollution flattens or decreases for top income earners.},
  archive      = {J_JRSSSC},
  author       = {Mancini, Tullio and Calvo-Pardo, Hector and Olmo, Jose},
  doi          = {10.1111/rssc.12588},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1543-1568},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Environmental engel curves: A neural network approach},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-parametric bayesian covariate-dependent multivariate
functional clustering: An application to time-series data for multiple
air pollutants. <em>JRSSSC</em>, <em>71</em>(5), 1521–1542. (<a
href="https://doi.org/10.1111/rssc.12589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air pollution is a major threat to public health. Understanding the spatial distribution of air pollution concentration is of great interest to government or local authorities, as it informs about target areas for implementing policies for air quality management. Cluster analysis has been popularly used to identify groups of locations with similar profiles of average levels of multiple air pollutants, efficiently summarising the spatial pattern. This study aimed to cluster locations based on the seasonal patterns of multiple air pollutants incorporating the location-specific characteristics such as socio-economic indicators. For this purpose, we proposed a novel non-parametric Bayesian sparse latent factor model for covariate-dependent multivariate functional clustering. Furthermore, we extend this model to conduct clustering with temporal dependency. The proposed methods are illustrated through a simulation study and applied to time-series data for daily mean concentrations of ozone ( ⁠ O 3 O 3 O3 ⁠ ), nitrogen dioxide ( ⁠ N O 2 N O 2 NO2 ⁠ ), and fine particulate matter ( ⁠ P M 2 . 5 P M 2 . 5 PM2.5 ⁠ ) collected for 25 cities in Canada in 1986–2015.},
  archive      = {J_JRSSSC},
  author       = {Yang, Daewon and Choi, Taeryon and Lavigne, Eric and Chung, Yeonseung},
  doi          = {10.1111/rssc.12589},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1521-1542},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Non-parametric bayesian covariate-dependent multivariate functional clustering: An application to time-series data for multiple air pollutants},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A model-based approach to predict employee compensation
components. <em>JRSSSC</em>, <em>71</em>(5), 1503–1520. (<a
href="https://doi.org/10.1111/rssc.12587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for official statistics at fine levels is motivating researchers to explore estimation methods that extend beyond the traditional survey-based estimation. For this work, the challenge originated with the US Bureau of Labor Statistics, who conducts the National Compensation Survey to collect compensation data from a nationwide sample of establishments. The objective is to obtain predictions of the wage and non-wage components of compensation for a large number of employment domains defined by detailed job characteristics. Survey estimates are only available for a small subset of these domains. To address the objective, we developed a bivariate hierarchical Bayes model that jointly predicts the wage and non-wage compensation components for a large number of employment domains defined by detailed job characteristics. We also discuss solutions to some practical challenges encountered in implementing small area estimation methods in large-scale settings, including methods for defining the prediction space, for constructing and selecting the information that serves as model input, and for obtaining stable survey variance and covariance estimates.},
  archive      = {J_JRSSSC},
  author       = {Erciulescu, Andreea L. and Opsomer, Jean D.},
  doi          = {10.1111/rssc.12587},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1503-1520},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {A model-based approach to predict employee compensation components},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Investigating the association of a sensitive attribute with
a random variable using the christofides generalised randomised response
design and bayesian methods. <em>JRSSSC</em>, <em>71</em>(5), 1471–1502.
(<a href="https://doi.org/10.1111/rssc.12585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In empirical studies involving sensitive topics, in addition to the problem of estimating the population proportion with a sensitive characteristic, a question arises as to whether or not there is heterogeneity in the distribution of an auxiliary random variable representing the information of subjects collected from a sensitive group and a non-sensitive group. That is, it is of interest to investigate the influence of sensitive attribute on the auxiliary random variable of interest. Finite mixture models are utilised to evaluate the association. A proposed Bayesian method through data augmentation and Markov chain Monte Carlo is applied to estimate unknown parameters of interest. Deviance information criterion and marginal likelihood are employed to select a suitable model to describe the association of the sensitive characteristic with the auxiliary random variable. Simulation and real data studies are conducted to assess the performance of and illustrate applications of the proposed methodology.},
  archive      = {J_JRSSSC},
  author       = {Lee, Shen-Ming and Le, Truong-Nhat and Tran, Phuoc-Loc and Li, Chin-Shang},
  doi          = {10.1111/rssc.12585},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1471-1502},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Investigating the association of a sensitive attribute with a random variable using the christofides generalised randomised response design and bayesian methods},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Statistical integration of heterogeneous omics data:
Probabilistic two-way partial least squares (PO2PLS). <em>JRSSSC</em>,
<em>71</em>(5), 1451–1470. (<a
href="https://doi.org/10.1111/rssc.12583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of multi-omics data has revolutionized the life sciences by creating avenues for integrated system-level approaches. Data integration links the information across datasets to better understand the underlying biological processes. However, high dimensionality, correlations and heterogeneity pose statistical and computational challenges. We propose a general framework, probabilistic two-way partial least squares (PO2PLS), that addresses these challenges. PO2PLS models the relationship between two datasets using joint and data-specific latent variables. For maximum likelihood estimation of the parameters, we propose a novel fast EM algorithm and show that the estimator is asymptotically normally distributed. A global test for the relationship between two datasets is proposed, specifically addressing the high dimensionality, and its asymptotic distribution is derived. Notably, several existing data integration methods are special cases of PO2PLS. Via extensive simulations, we show that PO2PLS performs better than alternatives in feature selection and prediction performance. In addition, the asymptotic distribution appears to hold when the sample size is sufficiently large. We illustrate PO2PLS with two examples from commonly used study designs: a large population cohort and a small case–control study. Besides recovering known relationships, PO2PLS also identified novel findings. The methods are implemented in our R-package PO2PLS .},
  archive      = {J_JRSSSC},
  author       = {el Bouhaddani, Said and Uh, Hae-Won and Jongbloed, Geurt and Houwing-Duistermaat, Jeanine},
  doi          = {10.1111/rssc.12583},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1451-1470},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Statistical integration of heterogeneous omics data: Probabilistic two-way partial least squares (PO2PLS)},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modelling time-varying rankings with autoregressive and
score-driven dynamics. <em>JRSSSC</em>, <em>71</em>(5), 1427–1450. (<a
href="https://doi.org/10.1111/rssc.12584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a new statistical model to analyse time-varying ranking data. The model can be used with a large number of ranked items, accommodates exogenous time-varying covariates and partial rankings, and is estimated via the maximum likelihood in a straightforward manner. Rankings are modelled using the Plackett–Luce distribution with time-varying worth parameters that follow a mean-reverting time series process. To capture the dependence of the worth parameters on past rankings, we utilise the conditional score in the fashion of the generalised autoregressive score models. Simulation experiments show that the small-sample properties of the maximum-likelihood estimator improve rapidly with the length of the time series and suggest that statistical inference relying on conventional Hessian-based standard errors is usable even for medium-sized samples. In an empirical study, we apply the model to the results of the Ice Hockey World Championships. We also discuss applications to rankings based on underlying indices, repeated surveys and non-parametric efficiency analysis.},
  archive      = {J_JRSSSC},
  author       = {Holý, Vladimír and Zouhar, Jan},
  doi          = {10.1111/rssc.12584},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1427-1450},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Modelling time-varying rankings with autoregressive and score-driven dynamics},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Network hawkes process models for exploring latent hierarchy
in social animal interactions. <em>JRSSSC</em>, <em>71</em>(5),
1402–1426. (<a href="https://doi.org/10.1111/rssc.12581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group-based social dominance hierarchies are of essential interest in understanding social structure (DeDeo &amp; Hobson in, Proceedings of the National Academy of Sciences 118(21), 2021). Recent animal behaviour research studies can record aggressive interactions observed over time. Models that can explore the underlying hierarchy from the observed temporal dynamics in behaviours are therefore crucial. Traditional ranking methods aggregate interactions across time into win/loss counts, equalizing dynamic interactions with the underlying hierarchy. Although these models have gleaned important behavioural insights from such data, they are limited in addressing many important questions that remain unresolved. In this paper, we take advantage of the observed interactions&#39; timestamps, proposing a series of network point process models with latent ranks. We carefully design these models to incorporate important theories on animal behaviour that account for dynamic patterns observed in the interaction data, including the winner effect, bursting and pair-flip phenomena. Through iteratively constructing and evaluating these models we arrive at the final cohort Markov-modulated Hawkes process (C-MMHP), which best characterizes all aforementioned patterns observed in interaction data. As such, inference on our model components can be readily interpreted in terms of theories on animal behaviours. The probabilistic nature of our model allows us to estimate the uncertainty in our ranking. In particular, our model is able to provide insights into the distribution of power within the hierarchy which forms and the strength of the established hierarchy. We compare all models using simulated and real data. Using statistically developed diagnostic perspectives, we demonstrate that the C-MMHP model outperforms other methods, capturing relevant latent ranking structures that lead to meaningful predictions for real data.},
  archive      = {J_JRSSSC},
  author       = {Ward, Owen G. and Wu, Jing and Zheng, Tian and Smith, Anna L. and Curley, James P.},
  doi          = {10.1111/rssc.12581},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1402-1426},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Network hawkes process models for exploring latent hierarchy in social animal interactions},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust correspondence analysis. <em>JRSSSC</em>,
<em>71</em>(5), 1381–1401. (<a
href="https://doi.org/10.1111/rssc.12580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correspondence analysis is a method for the visual display of information from two-way contingency tables. We introduce a robust form of correspondence analysis based on minimum covariance determinant estimation. This leads to the systematic deletion of outlying rows of the table and to plots of greatly increased informativeness. Our examples are trade flows of clothes and consumer evaluations of the perceived properties of cars. The robust method requires that a specified proportion of the data be used in fitting. To accommodate this requirement we provide an algorithm that uses a subset of complete rows and one row partially, both sets of rows being chosen robustly. We prove the convergence of this algorithm.},
  archive      = {J_JRSSSC},
  author       = {Riani, Marco and Atkinson, Anthony C. and Torti, Francesca and Corbellini, Aldo},
  doi          = {10.1111/rssc.12580},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1381-1401},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Robust correspondence analysis},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatiotemporal ETAS model with a renewal main-shock arrival
process. <em>JRSSSC</em>, <em>71</em>(5), 1356–1380. (<a
href="https://doi.org/10.1111/rssc.12579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a spatiotemporal point process model that enhances the classical Epidemic-Type Aftershock Sequence (ETAS) model. This is achieved with the introduction of a renewal main-shock arrival process and we call this extension the renewal ETAS (RETAS) model. This modification is similar in spirit to the renewal Hawkes (RHawkes) process but the conditional intensity process supports a spatial component. It empowers the main-shock intensity to reset upon the arrival of main-shocks. This allows for heavier clustering of main-shocks than the classical spatiotemporal ETAS model. We introduce a likelihood evaluation algorithm for parameter estimation and provide a novel procedure to evaluate the fitted model&#39;s goodness-of-fit (GOF) based on a sequential application of the Rosenblatt transformation. A simulation algorithm for the RETAS model is outlined and used to validate the numerical performance of the likelihood evaluation algorithm and GOF test procedure. We illustrate the proposed model and methods on various earthquake catalogues around the world each with distinctly different seismic activity. These catalogues demonstrate the RETAS model&#39;s additional flexibility in comparison to the classical spatiotemporal ETAS model and emphasizes the potential for superior modelling and forecasting of seismicity.},
  archive      = {J_JRSSSC},
  author       = {Stindl, Tom and Chen, Feng},
  doi          = {10.1111/rssc.12579},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1356-1380},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Spatiotemporal ETAS model with a renewal main-shock arrival process},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Specification analysis for technology use and teenager
well-being: Statistical validity and a bayesian proposal.
<em>JRSSSC</em>, <em>71</em>(5), 1330–1355. (<a
href="https://doi.org/10.1111/rssc.12578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key issue in science is assessing robustness to data analysis choices, while avoiding selective reporting and providing valid inference. Specification Curve Analysis is a tool intended to prevent selective reporting. Alas, when used for inference it can create severe biases and false positives, due to wrongly adjusting for covariates, and mask important treatment effect heterogeneity. As our motivating application, it led an influential study to conclude there is no relevant association between technology use and teenager mental well-being. We discuss these issues and propose a strategy for valid inference. Bayesian Specification Curve Analysis (BSCA) uses Bayesian Model Averaging to incorporate covariates and heterogeneous effects across treatments, outcomes and subpopulations. BSCA gives significantly different insights into teenager well-being, revealing that the association with technology differs by device, gender and who assesses well-being (teenagers or their parents).},
  archive      = {J_JRSSSC},
  author       = {Semken, Christoph and Rossell, David},
  doi          = {10.1111/rssc.12578},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1330-1355},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Specification analysis for technology use and teenager well-being: Statistical validity and a bayesian proposal},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneous graphical model for non-negative and
non-gaussian PM2.5 data. <em>JRSSSC</em>, <em>71</em>(5), 1303–1329. (<a
href="https://doi.org/10.1111/rssc.12575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies on the conditional relationships between PM 2.5 PM 2.5 PM2.5 concentrations among different regions are of great interest for the joint prevention and control of air pollution. Because of seasonal changes in atmospheric conditions, spatial patterns of PM 2.5 PM 2.5 PM2.5 may differ throughout the year. Additionally, concentration data are both non-negative and non-Gaussian. These data features pose significant challenges to existing methods. This study proposes a heterogeneous graphical model for non-negative and non-Gaussian data via the score matching loss. The proposed method simultaneously clusters multiple datasets and estimates a graph for variables with complex properties in each cluster. Furthermore, our model involves a network that indicate similarity among datasets, and this network can have additional applications. In simulation studies, the proposed method outperforms competing alternatives in both clustering and edge identification. We also analyse the PM 2.5 PM 2.5 PM2.5 concentrations&#39; spatial correlations in Taiwan&#39;s regions using data obtained in year 2019 from 67 air-quality monitoring stations. The 12 months are clustered into four groups: January–March, April, May–September and October–December, and the corresponding graphs have 153, 57, 86 and 167 edges respectively. The results show obvious seasonality, which is consistent with the meteorological literature. Geographically, the PM 2.5 PM 2.5 PM2.5 concentrations of north and south Taiwan regions correlate more respectively. These results can provide valuable information for developing joint air-quality control strategies.},
  archive      = {J_JRSSSC},
  author       = {Zhang, Jiaqi and Fan, Xinyan and Li, Yang and Ma, Shuangge},
  doi          = {10.1111/rssc.12575},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1303-1329},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Heterogeneous graphical model for non-negative and non-gaussian PM2.5 data},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bayesian spatio-temporal analysis of markets during the
finnish 1860s famine. <em>JRSSSC</em>, <em>71</em>(5), 1282–1302. (<a
href="https://doi.org/10.1111/rssc.12577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a Bayesian spatio-temporal model to study pre-industrial grain market integration during the Finnish famine of the 1860s. Our model takes into account several problematic features often present when analysing multiple spatially interdependent time series. For example, compared with the error correction methodology commonly applied in econometrics, our approach allows simultaneous modelling of multiple interdependent time series avoiding cumbersome statistical testing needed to predetermine the market leader as a point of reference. Furthermore, introducing a flexible spatio-temporal structure enables analysing detailed regional and temporal dynamics of the market mechanisms. Applying the proposed method, we detected spatially asymmetric ‘price ripples’ that spread out from the shock origin. We corroborated the existing literature on the speedier adjustment to emerging price differentials during the famine, but we observed this principally in urban markets. This hastened return to long-run equilibrium means faster and longer travel of price shocks, implying prolonged out-of-equilibrium dynamics, proliferated influence of market shocks, and, importantly, a wider spread of famine conditions.},
  archive      = {J_JRSSSC},
  author       = {Pasanen, Tiia-Maria and Voutilainen, Miikka and Helske, Jouni and Högmander, Harri},
  doi          = {10.1111/rssc.12577},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1282-1302},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {A bayesian spatio-temporal analysis of markets during the finnish 1860s famine},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nowcasting COVID-19 deaths in england by age and region.
<em>JRSSSC</em>, <em>71</em>(5), 1266–1281. (<a
href="https://doi.org/10.1111/rssc.12576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the trajectory of the daily number of COVID-19 deaths is essential to decisions on how to respond to the pandemic, but estimating this trajectory is complicated by the delay between deaths occurring and being reported. In England the delay is typically several days, but it can be weeks. This causes considerable uncertainty about how many deaths occurred in recent days. Here we estimate the deaths per day in five age strata within seven English regions, using a Bayesian model that accounts for reporting-day effects and longer-term changes in the delay distribution. We show how the model can be computationally efficiently fitted when the delay distribution is the same in multiple strata, for example, over a wide range of ages.},
  archive      = {J_JRSSSC},
  author       = {Seaman, Shaun R. and Samartsidis, Pantelis and Kall, Meaghan and De Angelis, Daniela},
  doi          = {10.1111/rssc.12576},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1266-1281},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Nowcasting COVID-19 deaths in england by age and region},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unconventional policies effects on stock market volatility:
The MAP approach. <em>JRSSSC</em>, <em>71</em>(5), 1245–1265. (<a
href="https://doi.org/10.1111/rssc.12574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taking the European Central Bank unconventional policies as a reference, we suggest a class of multiplicative error models (MEMs) tailored to analyse the impact such policies have on stock market volatility. The new set of models, called MEM with asymmetry and policy effects, keeps the base volatility dynamics separate from a component reproducing policy effects, with an increase in volatility on announcement days and a decrease unfolding implementation effects. When applied to four Eurozone markets, a model confidence set approach finds a significant improvement of the forecasting power of the proxy after the expanded asset purchase programme implementation. A multi-step ahead forecasting exercise estimates the duration of the effect; by shocking the policy variable, we are able to quantify the reduction in volatility which is more marked for debt-troubled countries.},
  archive      = {J_JRSSSC},
  author       = {Lacava, Demetrio and Gallo, Giampiero M. and Otranto, Edoardo},
  doi          = {10.1111/rssc.12574},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1245-1265},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Unconventional policies effects on stock market volatility: The MAP approach},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multilevel network item response modelling for discovering
differences between innovation and regular school systems in korea.
<em>JRSSSC</em>, <em>71</em>(5), 1225–1244. (<a
href="https://doi.org/10.1111/rssc.12569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The innovation school system in South Korea has been developed in response to the traditional high-pressure school system in South Korea, with a view to cultivate a bottom-up and student-centred educational culture. Despite its ambitious goals, questions have been raised about the success of the innovation school system. Leveraging data from the Gyeonggi Education Panel Study along with advances in the statistical analysis of network data and educational data, we compare the two school systems in more depth. We find that some schools are indeed different from others, and those differences are not detected by conventional multilevel models. Having said that, we do not find much evidence that the innovation school system differs from the regular school system in terms of self-reported mental well-being, although we do detect differences among some schools that appear to be unrelated to the school system.},
  archive      = {J_JRSSSC},
  author       = {Jin, Ick Hoon and Jeon, Minjeong and Schweinberger, Michael and Yun, Jonghyun and Lin, Lizhen},
  doi          = {10.1111/rssc.12569},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1225-1244},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Multilevel network item response modelling for discovering differences between innovation and regular school systems in korea},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stopping time detection of wood panel compression: A
functional time-series approach. <em>JRSSSC</em>, <em>71</em>(5),
1205–1224. (<a href="https://doi.org/10.1111/rssc.12572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider determining the optimal stopping time for the glue curing of wood panels in an automatic process environment. Using the near-infrared spectroscopy technology to monitor the manufacturing process ensures substantial savings in energy and time. We collect a time-series of curves from a near-infrared spectrum probe consisting of 72 spectra and aim to detect an optimal stopping time. We propose an estimation procedure to determine the optimal stopping time of wood panel compression and the estimation uncertainty associated with the estimated stopping time. Our method first divides the entire data set into a training sample and a testing sample, then iteratively computes integrated squared forecast errors based on the testing sample. We then apply a structural break detection method with one breakpoint to determine an estimated optimal stopping time from a univariate time-series of the integrated squared forecast errors. We also investigate the finite sample performance of the proposed method via a series of simulation studies.},
  archive      = {J_JRSSSC},
  author       = {Shang, Han Lin and Cao, Jiguo and Sang, Peijun},
  doi          = {10.1111/rssc.12572},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1205-1224},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Stopping time detection of wood panel compression: A functional time-series approach},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian nonparametric modelling of multiple graphs with an
application to ethnic metabolic differences. <em>JRSSSC</em>,
<em>71</em>(5), 1181–1204. (<a
href="https://doi.org/10.1111/rssc.12570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel approach to the estimation of multiple Gaussian graphical models (GGMs) to analyse patterns of association among a set of metabolites, under different conditions. Our motivating application is the SABRE (Southall And Brent REvisited) study, a triethnic cohort study conducted in the United Kingdom. Through joint modelling of pattern of association corresponding to different ethnic groups, we are able to identify potential ethnic differences in metabolite levels and associations, with the aim of gaining a better understanding of different risk of cardiometabolic disorders across ethnicities. We model the relationship between a set of metabolites and a set of covariates through a sparse seemingly unrelated regressions model and we use GGMs to represent the conditional dependence structure among metabolites. We specify a dependent generalised Dirichlet process prior on the edge inclusion probabilities to borrow strength across groups and we adopt the horseshoe prior to identify important biomarkers. Inference is performed via Markov chain Monte Carlo.},
  archive      = {J_JRSSSC},
  author       = {Molinari, Marco and Cremaschi, Andrea and De Iorio, Maria and Chaturvedi, Nishi and Hughes, Alun D. and Tillin, Therese},
  doi          = {10.1111/rssc.12570},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1181-1204},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Bayesian nonparametric modelling of multiple graphs with an application to ethnic metabolic differences},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic disease screening by joint modelling of survival and
longitudinal data. <em>JRSSSC</em>, <em>71</em>(5), 1158–1180. (<a
href="https://doi.org/10.1111/rssc.12573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential monitoring of dynamic processes is an active research area because of its broad applications in different industries and scientific research projects, including disease screening in medical research. In the literature, it has been shown that dynamic screening system (DySS) is a powerful tool for sequential monitoring of dynamic processes. To detect a disease (e.g. stroke) for a patient, existing DySS methods first estimate the regular longitudinal pattern of certain disease predictors (e.g. blood pressure, cholesterol level) from an in-control (IC) dataset that contains observations of a group of non-diseased people, and then compare the longitudinal pattern of the observed disease predictors of the given patient with the estimated regular longitudinal pattern. A signal of disease occurrence is triggered if their cumulative difference exceeds a certain level, facilitated by a built-in control chart. In practice, a dataset containing longitudinal observations of the disease predictors of both non-diseased and diseased people is often available in advance, from which it is possible to explore the relationship between the disease occurrence and the longitudinal pattern of the disease predictors. This relationship should be helpful for disease screening. In this paper, a new DySS method is suggested based on this idea. Numerical studies confirm that it can improve the existing DySS methods for disease screening.},
  archive      = {J_JRSSSC},
  author       = {Qiu, Peihua and You, Lu},
  doi          = {10.1111/rssc.12573},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1158-1180},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Dynamic disease screening by joint modelling of survival and longitudinal data},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assessing predictive discrimination performance of
biomarkers in the presence of treatment-induced dependent censoring.
<em>JRSSSC</em>, <em>71</em>(5), 1137–1157. (<a
href="https://doi.org/10.1111/rssc.12571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In medical studies, some therapeutic decisions could lead to dependent censoring for the survival outcome of interest. This is exemplified by a study of paediatric acute liver failure, where death was subject to dependent censoring due to liver transplantation. Existing methods for assessing the predictive performance of biomarkers often pose the independent censoring assumption and are thus not applicable. In this work, we propose to tackle the dependence between the failure event and dependent censoring event using auxiliary information in multiple longitudinal risk factors. We propose estimators of sensitivity, specificity and area under curve, to discern the predictive power of biomarkers for the failure event by removing the disturbance of dependent censoring. Point estimation and inferential procedures were developed by adopting the joint modelling framework. The proposed methods performed satisfactorily in extensive simulation studies. We applied them to examine the predictive value of various biomarkers and risk scores for mortality in the motivating example.},
  archive      = {J_JRSSSC},
  author       = {Zhang, Cuihong and Ning, Jing and Belle, Steven H. and Squires, Robert H. and Cai, Jianwen and Li, Ruosha},
  doi          = {10.1111/rssc.12571},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1137-1157},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Assessing predictive discrimination performance of biomarkers in the presence of treatment-induced dependent censoring},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-separable spatio-temporal models via transformed
multivariate gaussian markov random fields. <em>JRSSSC</em>,
<em>71</em>(5), 1116–1136. (<a
href="https://doi.org/10.1111/rssc.12567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models that capture spatial and temporal dynamics are applicable in many scientific fields. Non-separable spatio-temporal models were introduced in the literature to capture these dynamics. However, these models are generally complicated in construction and interpretation. We introduce a class of non-separable transformed multivariate Gaussian Markov random fields (TMGMRF) in which the dependence structure is flexible and facilitates simple interpretations concerning spatial, temporal and spatio-temporal parameters. Moreover, TMGMRF models have the advantage of allowing specialists to define any desired marginal distribution in model construction without suffering from spatio-temporal confounding. Consequently, the use of spatio-temporal models under the TMGMRF framework leads to a new class of general models, such as spatio-temporal Gamma random fields, that can be directly used to model Poisson intensity for space–time data. The proposed model was applied to identify important environmental characteristics that affect variation in the abundance of Nenia tridens , a dominant species of gastropod in a well-studied tropical ecosystem, and to characterize its spatial and temporal trends, which are particularly critical during the Anthropocene, an epoch of time characterized by human-induced environmental change associated with climate and land use.},
  archive      = {J_JRSSSC},
  author       = {Prates, Marcos O. and Azevedo, Douglas R. M. and MacNab, Ying C. and Willig, Michael R.},
  doi          = {10.1111/rssc.12567},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1116-1136},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Non-separable spatio-temporal models via transformed multivariate gaussian markov random fields},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of myocardial blood flow based on dynamic
contrast-enhanced magnetic resonance imaging using hierarchical bayesian
models. <em>JRSSSC</em>, <em>71</em>(5), 1085–1115. (<a
href="https://doi.org/10.1111/rssc.12568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) is a promising approach to assess microvascular blood flow (perfusion) within the myocardium, and the Fermi microvascular perfusion model is widely applied to extract estimates of the myocardial blood flow (MBF) from DCE-MRI data sets. The classification of myocardial tissues into normal (healthy) and hypoperfused (lesion) regions provides new opportunities for the diagnosis of coronary heart disease and for advancing our understanding of the aetiology of this highly prevalent disease. In the present paper, the Fermi model is combined with a hierarchical Bayesian model (HBM) and a Markov random fields prior to automate this classification. The proposed model exploits spatial context information to smooth the MBF estimates while sharpening the edges between lesions and healthy tissues. The model parameters are approximately sampled from the posterior distribution with Markov chain Monte Carlo (MCMC), and we demonstrate that this enables robust classification of myocardial tissue elements based on estimated MBF, along with sound uncertainty quantification. A well-established traditional method, based on a Gaussian mixture model (GMM) trained with the expectation–maximisation algorithm, is used as a benchmark for comparison.},
  archive      = {J_JRSSSC},
  author       = {Yang, Yalei and Gao, Hao and Berry, Colin and Carrick, David and Radjenovic, Aleksandra and Husmeier, Dirk},
  doi          = {10.1111/rssc.12568},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1085-1115},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Classification of myocardial blood flow based on dynamic contrast-enhanced magnetic resonance imaging using hierarchical bayesian models},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A principal stratification approach to estimating the effect
of continuing treatment after observing early outcomes. <em>JRSSSC</em>,
<em>71</em>(5), 1065–1084. (<a
href="https://doi.org/10.1111/rssc.12552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chronic diseases often require continuing care, and early response to treatment can be an important predictor of long-term efficacy. Often, an apparent lack of early efficacy may lead to discontinuation of treatment, with the decision made either by clinicians or by the patients themselves. Thus, it is important to determine whether or not a desired early outcome corresponds to a beneficial long-term effect of continuing treatment, and conversely, whether or not the absence of such an outcome corresponds to a lack of long-term benefit. However, primary clinical trials of such treatments are not commonly designed to answer such questions, for example by randomizing subjects to continue or discontinue treatment after observing early outcomes. We propose an approach to estimating the effect of continuing treatment after observing early outcomes using data from randomized controlled trials in which treatment discontinuation was not part of the design. Our approach estimates average causal effects of continuing treatment on long-term outcomes in principal strata defined by the potential early outcomes under treatment. For illustration, we estimate the effects of continuing to take gaboxadol to treat insomnia conditional on early improvement in subjective sleep quality after two nights, based on a standard parallel-arm randomized controlled trial.},
  archive      = {J_JRSSSC},
  author       = {Schnell, Patrick M. and Baumgartner, Richard and Mt-Isa, Shahrul and Svetnik, Vladimir},
  doi          = {10.1111/rssc.12552},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {5},
  pages        = {1065-1084},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {A principal stratification approach to estimating the effect of continuing treatment after observing early outcomes},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unifying framework for flexible excess hazard modelling
with applications in cancer epidemiology. <em>JRSSSC</em>,
<em>71</em>(4), 1044–1062. (<a
href="https://doi.org/10.1111/rssc.12566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Excess hazard modelling is one of the main tools in population-based cancer survival research. Indeed, this setting allows for direct modelling of the survival due to cancer even in the absence of reliable information on the cause of death, which is common in population-based cancer epidemiology studies. We propose a unifying link-based additive modelling framework for the excess hazard that allows for the inclusion of many types of covariate effects, including spatial and time-dependent effects, using any type of smoother, such as thin plate, cubic splines, tensor products and Markov random fields. In addition, this framework accounts for all types of censoring as well as left truncation. Estimation is conducted by using an efficient and stable penalized likelihood-based algorithm whose empirical performance is evaluated through extensive simulation studies. Some theoretical and asymptotic results are discussed. Two case studies are presented using population-based cancer data from patients diagnosed with breast (female), colon and lung cancers in England. The results support the presence of non-linear and time-dependent effects as well as spatial variation. The proposed approach is available in the R package GJRM.},
  archive      = {J_JRSSSC},
  author       = {Eletti, Alessia and Marra, Giampiero and Quaresma, Manuela and Radice, Rosalba and Rubio, Francisco Javier},
  doi          = {10.1111/rssc.12566},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {4},
  pages        = {1044-1062},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {A unifying framework for flexible excess hazard modelling with applications in cancer epidemiology},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A nearest-neighbour gaussian process spatial factor model
for censored, multi-depth geochemical data. <em>JRSSSC</em>,
<em>71</em>(4), 1014–1043. (<a
href="https://doi.org/10.1111/rssc.12565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the relationships between local environmental variables and the geochemical composition of the Earth in a region spanning over 26,000 km 2 in the lower South Island of New Zealand. Part of the Southland–South Otago geochemical baseline survey—a pilot study pre-empting roll-out across the country—the data comprise the measurements of 59 chemical trace elements, each at two depth prescriptions, at several hundred spatial sites. We demonstrate construction of a hierarchical spatial factor model that captures inter-depth dependency; handles imputation of left-censored readings in a statistically principled manner; and exploits sparse approximations to Gaussian processes to deliver inference. The voluminous results provide a novel impression of the underlying processes and are presented graphically via simple web-based applications. These both confirm existing knowledge and provide a basis from which new research hypotheses in geochemistry might be formed.},
  archive      = {J_JRSSSC},
  author       = {Davies, Tilman M. and Banerjee, Sudipto and Martin, Adam P. and Turnbull, Rose E.},
  doi          = {10.1111/rssc.12565},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {4},
  pages        = {1014-1043},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {A nearest-neighbour gaussian process spatial factor model for censored, multi-depth geochemical data},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reliability analysis of artificial intelligence systems
using recurrent events data from autonomous vehicles. <em>JRSSSC</em>,
<em>71</em>(4), 987–1013. (<a
href="https://doi.org/10.1111/rssc.12564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) systems have become increasingly common and the trend will continue. Examples of AI systems include autonomous vehicles (AV), computer vision, natural language processing and AI medical experts. To allow for safe and effective deployment of AI systems, the reliability of such systems needs to be assessed. Traditionally, reliability assessment is based on reliability test data and the subsequent statistical modelling and analysis. The availability of reliability data for AI systems, however, is limited because such data are typically sensitive and proprietary. The California Department of Motor Vehicles (DMV) oversees and regulates an AV testing program, in which many AV manufacturers are conducting AV road tests. Manufacturers participating in the program are required to report recurrent disengagement events to California DMV. This information is being made available to the public. In this paper, we use recurrent disengagement events as a representation of the reliability of the AI system in AV, and propose a statistical framework for modelling and analysing the recurrent events data from AV driving tests. We use traditional parametric models in software reliability and propose a new non-parametric model based on monotonic splines to describe the event process and to estimate the cumulative baseline intensity function of the event process. We develop inference procedures for selecting the best models, quantifying uncertainty and testing heterogeneity in the event process. We then analyse the recurrent events data from four AV manufacturers, and make inferences on the reliability of the AI systems in AV. We also describe how the proposed analysis can be applied to assess the reliability of other AI systems. This paper has online supplementary materials.},
  archive      = {J_JRSSSC},
  author       = {Min, Jie and Hong, Yili and King, Caleb B. and Meeker, William Q.},
  doi          = {10.1111/rssc.12564},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {4},
  pages        = {987-1013},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Reliability analysis of artificial intelligence systems using recurrent events data from autonomous vehicles},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysing cycling sensors data through ordinal logistic
regression with functional covariates. <em>JRSSSC</em>, <em>71</em>(4),
969–986. (<a href="https://doi.org/10.1111/rssc.12563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of digital sensors in sports, all cyclists can now measure many parameters during their effort, such as speed, slope, altitude, heart rate or pedalling cadence. The present work studies the effect of these parameters on the average developed power, which is the best indicator of cyclist performance. For this, a cumulative logistic model for ordinal response with functional covariate is proposed. This model is shown to outperform competitors on a benchmark study, and its application on cyclist data confirms that pedalling cadence is a key performance indicator. However, maintaining a high cadence during long effort is a typical characteristic of high-level cyclists, which is something on which amateur cyclists can work to increase their performance.},
  archive      = {J_JRSSSC},
  author       = {Jacques, Julien and Samardžić, Sanja},
  doi          = {10.1111/rssc.12563},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {4},
  pages        = {969-986},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Analysing cycling sensors data through ordinal logistic regression with functional covariates},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bayesian multi-region radial composite reservoir model for
deconvolution in well test analysis. <em>JRSSSC</em>, <em>71</em>(4),
951–968. (<a href="https://doi.org/10.1111/rssc.12562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In petroleum well test analysis, deconvolution is used to obtain information about reservoir systems, for example the presence of heterogeneities and boundaries. This information is contained in the response function, which can be estimated by solving an inverse problem in the pressure and flow rate measurements. Our Bayesian approach to this problem is based upon a parametric physical model of reservoir behaviour, derived from the solution for fluid flow in a general class of reservoirs. This permits joint parametric Bayesian inference for both the reservoir parameters and the true pressure and rate values, which is essential due to the typical observational error levels. Using sets of flexible priors for the reservoir parameters to restrict the solution space to physical behaviours, samples from the posterior are generated using Markov Chain Monte Carlo. Summaries and visualisations of the posterior, response, and true pressure and rate values can be produced, interpreted, and model selection can be performed. The method is validated through a synthetic application, and applied to a field data set. The results are comparable to the state of the art solution, but through our method we gain access to system parameters, we can incorporate prior knowledge, and we can quantify parameter uncertainty.},
  archive      = {J_JRSSSC},
  author       = {Botsas, Themistoklis and Cumming, Jonathan A. and Jermyn, Ian H.},
  doi          = {10.1111/rssc.12562},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {4},
  pages        = {951-968},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {A bayesian multi-region radial composite reservoir model for deconvolution in well test analysis},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The modelling of movement of multiple animals that share
behavioural features. <em>JRSSSC</em>, <em>71</em>(4), 932–950. (<a
href="https://doi.org/10.1111/rssc.12561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a model that can be used to infer the behaviour of multiple animals. Our proposal is defined as a set of hidden Markov models that are based on the sticky hierarchical Dirichlet process, with a shared base-measure, and a step and turn with an attractive point (STAP) emission distribution. The latent classifications are representative of the behaviour assumed by the animals, which is described by the STAP parameters. Given the latent classifications, the animals are independent. As a result of the way we formalize the distribution over the STAP parameters, the animals may share, in different behaviours, the set or a subset of the parameters, thereby allowing us to investigate the similarities between them. The hidden Markov models, based on the Dirichlet process, allow us to estimate the number of latent behaviours for each animal, as a model parameter. This proposal is motivated by a real data problem, where the global positioning system (GPS) coordinates of six Maremma Sheepdogs have been observed. Among the other results, we show that four dogs share most of the behaviour characteristics, while two have specific behaviours.},
  archive      = {J_JRSSSC},
  author       = {Mastrantonio, Gianluca},
  doi          = {10.1111/rssc.12561},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {4},
  pages        = {932-950},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {The modelling of movement of multiple animals that share behavioural features},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving cardio-mechanic inference by combining in vivo
strain data with ex vivo volume–pressure data. <em>JRSSSC</em>,
<em>71</em>(4), 906–931. (<a
href="https://doi.org/10.1111/rssc.12560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardio-mechanic models show substantial promise for improving personalised diagnosis and disease risk prediction. However, estimating the constitutive parameters from strains extracted from in vivo cardiac magnetic resonance scans can be challenging. The reason is that circumferential strains, which are comparatively easy to extract, are not sufficiently informative to uniquely estimate all parameters, while longitudinal and radial strains are difficult to extract at high precision. In the present study, we show how cardio-mechanic parameter inference can be improved by incorporating prior knowledge from population-wide ex vivo volume–pressure data. Our work is based on an empirical law known as the Klotz curve. We propose and assess two alternative methodological frameworks for integrating ex vivo data via the Klotz curve into the inference framework, using both a non-empirical and empirical prior distribution.},
  archive      = {J_JRSSSC},
  author       = {Lazarus, Alan and Gao, Hao and Luo, Xiaoyu and Husmeier, Dirk},
  doi          = {10.1111/rssc.12560},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {4},
  pages        = {906-931},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Improving cardio-mechanic inference by combining in vivo strain data with ex vivo Volume–Pressure data},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modelling the extremes of seasonal viruses and hospital
congestion: The example of flu in a swiss hospital. <em>JRSSSC</em>,
<em>71</em>(4), 884–905. (<a
href="https://doi.org/10.1111/rssc.12559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Viruses causing flu or milder coronavirus colds are often referred to as ‘seasonal viruses’ as they tend to subside in warmer months. In other words, meteorological conditions tend to impact the activity of viruses, and this infor2mation can be exploited for the operational management of hospitals. In this study, we use 3 years of daily data from one of the biggest hospitals in Switzerland and focus on modelling the extremes of hospital visits from patients showing flu-like symptoms and the number of positive flu cases. We propose employing a discrete generalized Pareto distribution for the number of positive and negative cases. Our modelling framework allows for the parameters of these distributions to be linked to covariate effects, and for outlying observations to be dealt with via a robust estimation approach. Because meteorological conditions may vary over time, we use meteorological and not calendar variations to explain hospital charge extremes, and our empirical findings highlight their significance. We propose a measure of hospital congestion and a related tool to estimate the resulting CaRe (Charge-at-Risk-estimation) under different meteorological conditions. The relevant numerical computations can be easily carried out using the freely available GJRM R package. The empirical effectiveness of the proposed method is assessed through a simulation study.},
  archive      = {J_JRSSSC},
  author       = {Ranjbar, Setareh and Cantoni, Eva and Chavez-Demoulin, Valérie and Marra, Giampiero and Radice, Rosalba and Jaton, Katia},
  doi          = {10.1111/rssc.12559},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {4},
  pages        = {884-905},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Modelling the extremes of seasonal viruses and hospital congestion: The example of flu in a swiss hospital},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multifidelity computer model emulation with high-dimensional
output: An application to storm surge. <em>JRSSSC</em>, <em>71</em>(4),
861–883. (<a href="https://doi.org/10.1111/rssc.12558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hurricane-driven storm surge is one of the most deadly and costly natural disasters, making precise quantification of the surge hazard of great importance. Surge hazard quantification is often performed through physics-based computer models of storm surges. Such computer models can be implemented with a wide range of fidelity levels, with computational burdens varying by several orders of magnitude due to the nature of the system. The threat posed by surge makes greater fidelity highly desirable, however, such models and their high-volume output tend to come at great computational cost, which can make detailed study of coastal flood hazards prohibitive. These needs make the development of an emulator combining high-dimensional output from multiple complex computer models with different fidelity levels important. We propose a parallel partial autoregressive cokriging model to predict highly accurate storm surges in a computationally efficient way over a large spatial domain. This emulator has the capability of predicting storm surges as accurately as a high-fidelity computer model given any storm characteristics over a large spatial domain.},
  archive      = {J_JRSSSC},
  author       = {Ma, Pulong and Karagiannis, Georgios and Konomi, Bledar A. and Asher, Taylor G. and Toro, Gabriel R. and Cox, Andrew T.},
  doi          = {10.1111/rssc.12558},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {4},
  pages        = {861-883},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Multifidelity computer model emulation with high-dimensional output: An application to storm surge},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian imputation of COVID-19 positive test counts for
nowcasting under reporting lag. <em>JRSSSC</em>, <em>71</em>(4),
834–860. (<a href="https://doi.org/10.1111/rssc.12557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obtaining up to date information on the number of UK COVID-19 regional infections is hampered by the reporting lag in positive test results for people with COVID-19 symptoms. In the UK, for ‘Pillar 2’ swab tests for those showing symptoms, it can take up to five days for results to be collated. We make use of the stability of the under reporting process over time to motivate a statistical temporal model that infers the final total count given the partial count information as it arrives. We adopt a Bayesian approach that provides for subjective priors on parameters and a hierarchical structure for an underlying latent intensity process for the infection counts. This results in a smoothed time-series representation nowcasting the expected number of daily counts of positive tests with uncertainty bands that can be used to aid decision making. Inference is performed using sequential Monte Carlo.},
  archive      = {J_JRSSSC},
  author       = {Jersakova, Radka and Lomax, James and Hetherington, James and Lehmann, Brieuc and Nicholson, George and Briers, Mark and Holmes, Chris},
  doi          = {10.1111/rssc.12557},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {4},
  pages        = {834-860},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Bayesian imputation of COVID-19 positive test counts for nowcasting under reporting lag},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Highly irregular functional generalized linear regression
with electronic health records. <em>JRSSSC</em>, <em>71</em>(4),
806–833. (<a href="https://doi.org/10.1111/rssc.12556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a new approach, called Multiple Imputation of Sparsely-sampled Functions at Irregular Times (MISFIT), for fitting generalized functional linear regression models with sparsely and irregularly sampled data. Current methods do not allow for consistent estimation unless one assumes that the number of observed points per curve grows sufficiently quickly with the sample size. In contrast, MISFIT is based on a multiple imputation framework, which, as we demonstrate empirically, has the potential to produce consistent estimates without such an assumption. Just as importantly, it propagates the uncertainty of not having completely observed curves, allowing for a more accurate assessment of the uncertainty of parameter estimates, something that most methods currently cannot accomplish. This work is motivated by a longitudinal study on macrocephaly, or atypically large head size, in which electronic medical records allow for the collection of a great deal of data. However, the sampling is highly variable from child to child. Using MISFIT we are able to clearly demonstrate that the development of pathologic conditions related to macrocephaly is associated with both the overall head circumference of the children as well as the velocity of their head growth.},
  archive      = {J_JRSSSC},
  author       = {Petrovich, Justin and Reimherr, Matthew and Daymont, Carrie},
  doi          = {10.1111/rssc.12556},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {4},
  pages        = {806-833},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Highly irregular functional generalized linear regression with electronic health records},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring british accents: Modelling the trap–bath split
with functional data analysis. <em>JRSSSC</em>, <em>71</em>(4), 773–805.
(<a href="https://doi.org/10.1111/rssc.12555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sound of our speech is influenced by the places we come from. Great Britain contains a wide variety of distinctive accents which are of interest to linguistics. In particular, the ‘a’ vowel in words like ‘class’ is pronounced differently in the North and the South. Speech recordings of this vowel can be represented as formant curves or as mel-frequency cepstral coefficient curves. Functional data analysis and generalised additive models offer techniques to model the variation in these curves. Our first aim was to model the difference between typical Northern and Southern vowels /æ/ and /ɑ/, by training two classifiers on the North-South Class Vowels dataset collected for this paper. Our second aim is to visualise geographical variation of accents in Great Britain. For this we use speech recordings from a second dataset, the British National Corpus (BNC) audio edition. The trained models are used to predict the accent of speakers in the BNC, and then we model the geographical patterns in these predictions using a soap film smoother. This work demonstrates a flexible and interpretable approach to modelling phonetic accent variation in speech recordings.},
  archive      = {J_JRSSSC},
  author       = {Koshy, Aranya and Tavakoli, Shahin},
  doi          = {10.1111/rssc.12555},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {4},
  pages        = {773-805},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Exploring british accents: Modelling the Trap–Bath split with functional data analysis},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Applied statistics. <em>JRSSSC</em>, <em>71</em>(4),
771–772. (<a href="https://doi.org/10.1111/rssc.12506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSC},
  doi          = {10.1111/rssc.12506},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {4},
  pages        = {771-772},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Applied statistics},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A dynamic structural equation approach to estimate the
short-term effects of air pollution on human health. <em>JRSSSC</em>,
<em>71</em>(3), 739–769. (<a
href="https://doi.org/10.1111/rssc.12554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detailed knowledge on the effects of air pollutants on human health is a prerequisite for the development of effective policies to reduce the adverse impact of ambient air pollution. However, measuring the effect of exposure on health outcomes is an extremely difficult task as the health impact of air pollution is known to vary over space and over different exposure periods. In general, standard approaches aggregate the information over space or time to simplify the study but this strategy fails to recognize important regional differences and runs into the well-known risk of confounding the effects. However, modelling directly with the original, disaggregated data requires a highly dimensional model with the curse of dimensionality making inferences unstable; in these cases, the models tend to retain many irrelevant components and most relevant effects tend to be attenuated. The situation clearly calls for an intermediate solution that does not blindly aggregate data while preserving important regional features. We propose a dimension-reduction approach based on latent factors driven by the data. These factors naturally absorb the relevant features provided by the data and establish the link between pollutants and health outcomes, instead of forcing a necessarily high-dimensional link at the observational level. The dynamic structural equation approach is particularly suited for this task. The latent factor approach also provides a simple solution to the spatial misalignment caused by using variables with different spatial resolutions and the state-space representation of the model favours the application of impulse response analysis. Our approach is discussed through the analysis of the short-term effects of air pollution on hospitalization data from Lombardia and Piemonte regions (Italy).},
  archive      = {J_JRSSSC},
  author       = {Gamerman, Dani and Ippoliti, Luigi and Valentini, Pasquale},
  doi          = {10.1111/rssc.12554},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {3},
  pages        = {739-769},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {A dynamic structural equation approach to estimate the short-term effects of air pollution on human health},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assessing seismic origin of geological features by fitting
equidistant parallel lines. <em>JRSSSC</em>, <em>71</em>(3), 723–738.
(<a href="https://doi.org/10.1111/rssc.12553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some planes in sedimentary rocks contain features that appear to lie near equally spaced parallel lines. Determining whether or not they do so can provide information on possible mechanisms for their formation. The problem is recast here in terms of circular statistics, enabling closeness of candidate sets of lines to the points to be measured by a mean resultant length. This leads to a test of goodness of fit and to estimates of the direction of the lines and of the spacing between them. Two contrasting data sets are analysed.},
  archive      = {J_JRSSSC},
  author       = {Jupp, P.E. and Goudie, I.B.J. and Batchelor, R.A. and Goudie, R.J.B.},
  doi          = {10.1111/rssc.12553},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {3},
  pages        = {723-738},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Assessing seismic origin of geological features by fitting equidistant parallel lines},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modelling clusters of corporate defaults: Regime-switching
models significantly reduce the contagion source. <em>JRSSSC</em>,
<em>71</em>(3), 698–722. (<a
href="https://doi.org/10.1111/rssc.12551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we report robust evidence that the process of corporate defaults is time-dependent and can be modelled by extending an autoregressive count time series model class via the introduction of regime-switching. That is, some of the parameters of the model depend on the regime of an unobserved Markov chain, capturing the model changes during clusters observed for count time series in corporate defaults. Thus, the process of corporate defaults is more dynamic than previously believed. Moreover, the contagion effect—that current defaults affect the probability of other firms defaulting in the future—is reduced compared to models without regime-switching, and is only present in one regime. A two-regime model drives the counts of monthly corporate defaults in the United States. To estimate the model, we introduce a novel quasi-maximum likelihood estimator by adapting the extended Hamilton–Gray algorithm for the Poisson autoregressive model.},
  archive      = {J_JRSSSC},
  author       = {Berentsen, Geir D. and Bulla, Jan and Maruotti, Antonello and Støve, Bård},
  doi          = {10.1111/rssc.12551},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {3},
  pages        = {698-722},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Modelling clusters of corporate defaults: Regime-switching models significantly reduce the contagion source},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalizing trial evidence to target populations in
non-nested designs: Applications to AIDS clinical trials.
<em>JRSSSC</em>, <em>71</em>(3), 669–697. (<a
href="https://doi.org/10.1111/rssc.12550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Comparative effectiveness evidence from randomized trials may not be directly generalizable to a target population of substantive interest when, as in most cases, trial participants are not randomly sampled from the target population. Motivated by the need to generalize evidence from two trials conducted in the AIDS Clinical Trials Group (ACTG), we consider weighting, regression and doubly robust estimators to estimate the causal effects of HIV interventions in a specified population of people living with HIV in the USA. We focus on a non-nested trial design and discuss strategies for both point and variance estimation of the target population average treatment effect. Specifically in the generalizability context, we demonstrate both analytically and empirically that estimating the known propensity score in trials does not increase the variance for each of the weighting, regression and doubly robust estimators. We apply these methods to generalize the average treatment effects from two ACTG trials to specified target populations and operationalize key practical considerations. Finally, we report on a simulation study that investigates the finite-sample operating characteristics of the generalizability estimators and their sandwich variance estimators.},
  archive      = {J_JRSSSC},
  author       = {Li, Fan and Buchanan, Ashley L. and Cole, Stephen R.},
  doi          = {10.1111/rssc.12550},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {3},
  pages        = {669-697},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Generalizing trial evidence to target populations in non-nested designs: Applications to AIDS clinical trials},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting phenotypes from brain connection structure.
<em>JRSSSC</em>, <em>71</em>(3), 639–668. (<a
href="https://doi.org/10.1111/rssc.12549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on the problem of predicting a response variable based on a network-valued predictor. Our motivation is the development of interpretable and accurate predictive models for cognitive traits and neuro-psychiatric disorders based on an individual&#39;s brain connection network (connectome). Current methods reduce the complex, high-dimensional brain network into low-dimensional pre-specified features prior to applying standard predictive algorithms. These methods are sensitive to feature choice and inevitably discard important information. Instead, we propose a nonparametric Bayes class of models that utilize the entire adjacency matrix defining brain region connections to adaptively detect predictive algorithms, while maintaining interpretability. The Bayesian Connectomics (BaCon) model class utilizes Poisson–Dirichlet processes to find a lower dimensional, bidirectional (covariate, subject) pattern in the adjacency matrix. The small n , large p problem is transformed into a ‘small n , small q ’ problem, facilitating an effective stochastic search of the predictors. A spike-and-slab prior for the cluster predictors strikes a balance between regression model parsimony and flexibility, resulting in improved inferences and test case predictions. We describe basic properties of the BaCon model and develop efficient algorithms for posterior computation. The resulting methods are found to outperform existing approaches and applied to a creative reasoning dataset.},
  archive      = {J_JRSSSC},
  author       = {Guha, Subharup and Jung, Rex and Dunson, David},
  doi          = {10.1111/rssc.12549},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {3},
  pages        = {639-668},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Predicting phenotypes from brain connection structure},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bayesian non-linear state space copula model for air
pollution in beijing. <em>JRSSSC</em>, <em>71</em>(3), 613–638. (<a
href="https://doi.org/10.1111/rssc.12548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air pollution is a serious issue that currently affects many industrial cities in the world and can cause severe illness to the population. In particular, it has been proven that extreme high levels of airborne contaminants have dangerous short-term effects on human health, in terms of increased hospital admissions for cardiovascular and respiratory diseases and increased mortality risk. For these reasons, an accurate estimation of airborne pollutant concentrations is crucial. In this paper, we propose a flexible novel approach to model hourly measurements of fine particulate matter and meteorological data collected in Beijing in 2014. We show that the standard state space model, based on Gaussian assumptions, does not correctly capture the time dynamics of the observations. Therefore, we propose a non-linear non-Gaussian state space model where both the observation and the state equations are defined by copula specifications, and we perform Bayesian inference using the Hamiltonian Monte Carlo method. The proposed copula state space approach is very flexible, since it allows us to separately model the marginal distributions and to accommodate a wide variety of dependence structures in the data dynamics. We show that the proposed approach allows us not only to accurately estimate particulate matter measurements, but also to capture unusual high levels of air pollution, which were not detected by measured effects.},
  archive      = {J_JRSSSC},
  author       = {Kreuzer, Alexander and Dalla Valle, Luciana and Czado, Claudia},
  doi          = {10.1111/rssc.12548},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {3},
  pages        = {613-638},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {A bayesian non-linear state space copula model for air pollution in beijing},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Zero-state coupled markov switching count models for
spatio-temporal infectious disease spread. <em>JRSSSC</em>,
<em>71</em>(3), 589–612. (<a
href="https://doi.org/10.1111/rssc.12547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal counts of infectious disease cases often contain an excess of zeros. With existing zero-inflated count models applied to such data it is difficult to quantify space-time heterogeneity in the effects of disease spread between areas. Also, existing methods do not allow for separate dynamics to affect the reemergence and persistence of the disease. As an alternative, we develop a new zero-state coupled Markov switching negative binomial model, under which the disease switches between periods of presence and absence in each area through a series of partially hidden nonhomogeneous Markov chains coupled between neighbouring locations. When the disease is present, an autoregressive negative binomial model generates the cases with a possible zero representing the disease being undetected. Bayesian inference and prediction is illustrated using spatio-temporal counts of dengue fever cases in Rio de Janeiro, Brazil.},
  archive      = {J_JRSSSC},
  author       = {Douwes-Schultz, Dirk and Schmidt, Alexandra M.},
  doi          = {10.1111/rssc.12547},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {3},
  pages        = {589-612},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Zero-state coupled markov switching count models for spatio-temporal infectious disease spread},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Posterior summaries of grocery retail topic models:
Evaluation, interpretability and credibility. <em>JRSSSC</em>,
<em>71</em>(3), 562–588. (<a
href="https://doi.org/10.1111/rssc.12546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the shopping motivations behind market baskets has significant commercial value for the grocery retail industry. The analysis of shopping transactions demands techniques that can cope with the volume and dimensionality of grocery transactional data while delivering interpretable outcomes. Latent Dirichlet allocation (LDA) allows processing grocery transactions and the discovering of customer behaviours. Interpretations of topic models typically exploit individual samples overlooking the uncertainty of single topics. Moreover, training LDA multiple times show topics with large uncertainty, that is, topics (dis)appear in some but not all posterior samples, concurring with various authors in the field. In response, we introduce a clustering methodology that post-processes posterior LDA draws to summarise topic distributions represented as recurrent topics. Our approach identifies clusters of topics that belong to different samples and provides associated measures of uncertainty for each group. Our proposed methodology allows the identification of an unconstrained number of customer behaviours presented as recurrent topics. We also establish a more holistic framework for model evaluation, which assesses topic models based not only on their predictive likelihood but also on quality aspects such as coherence and distinctiveness of single topics and credibility of a set of topics. Using the outcomes of a tailored survey, we set thresholds that aid in interpreting quality aspects in grocery retail data. We demonstrate that selecting recurrent topics not only improves predictive likelihood but also outperforms interpretability and credibility. We illustrate our methods with an example from a large British supermarket chain.},
  archive      = {J_JRSSSC},
  author       = {Vega Carrasco, Mariflor and Manolopoulou, Ioanna and O&#39;Sullivan, Jason and Prior, Rosie and Musolesi, Mirco},
  doi          = {10.1111/rssc.12546},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {3},
  pages        = {562-588},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Posterior summaries of grocery retail topic models: Evaluation, interpretability and credibility},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Regularized regression on compositional trees with
application to MRI analysis. <em>JRSSSC</em>, <em>71</em>(3), 541–561.
(<a href="https://doi.org/10.1111/rssc.12545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A compositional tree refers to a tree structure on a set of random variables where each random variable is a node and composition occurs at each non-leaf node of the tree. As a generalization of compositional data, compositional trees handle more complex relationships among random variables and appear in many disciplines, such as brain imaging, genomics and finance. We consider the problem of sparse regression on data that are associated with a compositional tree and propose a transformation-free tree-based regularized regression method for component selection. The regularization penalty is designed based on the tree structure and encourages a sparse tree representation. We prove that our proposed estimator for regression coefficients is both consistent and model selection consistent. In the simulation study, our method shows higher accuracy than competing methods under different scenarios. By analysing a brain imaging data set from studies of Alzheimer&#39;s disease, our method identifies meaningful associations between memory decline and volume of brain regions that are consistent with current understanding.},
  archive      = {J_JRSSSC},
  author       = {Wang, Bingkai and Caffo, Brian S. and Luo, Xi and Liu, Chin-Fu and Faria, Andreia V. and Miller, Michael I. and Zhao, Yi},
  doi          = {10.1111/rssc.12545},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {3},
  pages        = {541-561},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Regularized regression on compositional trees with application to MRI analysis},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inferring the sources of HIV infection in africa from
deep-sequence data with semi-parametric bayesian poisson flow models.
<em>JRSSSC</em>, <em>71</em>(3), 517–540. (<a
href="https://doi.org/10.1111/rssc.12544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pathogen deep-sequencing is an increasingly routinely used technology in infectious disease surveillance. We present a semi-parametric Bayesian Poisson model to exploit these emerging data for inferring infectious disease transmission flows and the sources of infection at the population level. The framework is computationally scalable in high-dimensional flow spaces thanks to Hilbert Space Gaussian process approximations, allows for sampling bias adjustments, and estimation of gender- and age-specific transmission flows at finer resolution than previously possible. We apply the approach to densely sampled, population-based HIV deep-sequence data from Rakai, Uganda, and find substantive evidence that adolescent and young women were predominantly infected through age-disparate relationships in the study period 2009–2015.},
  archive      = {J_JRSSSC},
  author       = {Xi, Xiaoyue and Spencer, Simon E. F. and Hall, Matthew and Grabowski, M. Kate and Kagaayi, Joseph and Ratmann, Oliver},
  doi          = {10.1111/rssc.12544},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {3},
  pages        = {517-540},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Inferring the sources of HIV infection in africa from deep-sequence data with semi-parametric bayesian poisson flow models},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A semi-parametric integer-valued autoregressive model with
covariates. <em>JRSSSC</em>, <em>71</em>(3), 495–516. (<a
href="https://doi.org/10.1111/rssc.12543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a low count data INAR (Integer Autoregressive Regression) model in which the arrivals are modelled non-parametrically and are allowed to contain covariates. Accommodating possible covariates is important as exogenous variability, such as seasonality, often needs to be catered for. The main challenge is to maintain the axiomatic properties of the arrivals non-parametric mass function while, at the same time, incorporating covariates directly into the associated probabilities. Compared with models that impose standard distributions such as Poisson or Negative Binomial for the arrivals, our approach is more flexible and provides a general arrival specification. The dependence structure is parametric and uses the standard binomial thinning operator. The parameters are estimated by the Maximum Likelihood. Monte Carlo simulations show that our proposed model performs very well with good finite sample results. Two empirical issues are addressed where incorporating covariates is a prerequisite for successful modelling. The first incorporates seasonal covariates into a semi-parametric model for forecasting the numbers of claimants of wage loss benefits in the logging industry in British Columbia, Canada. The second investigates if macro-economic indicators in an economy may be useful in predicting the number of bank failures in the US financial sector.},
  archive      = {J_JRSSSC},
  author       = {Rao, Yao and Harris, David and McCabe, Brendan},
  doi          = {10.1111/rssc.12543},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {3},
  pages        = {495-516},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {A semi-parametric integer-valued autoregressive model with covariates},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Erratum. <em>JRSSSC</em>, <em>71</em>(2), 491–492. (<a
href="https://doi.org/10.1111/rssc.12541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSC},
  author       = {Liu, Suyu and Yuan, Ying},
  doi          = {10.1111/rssc.12541},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {2},
  pages        = {491-492},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Erratum},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lifting scheme for streamflow data in river networks.
<em>JRSSSC</em>, <em>71</em>(2), 467–490. (<a
href="https://doi.org/10.1111/rssc.12542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new multiscale method for analysing water pollutant data located in river networks. The main idea of the proposed method is to adapt the conventional lifting scheme, reflecting the characteristics of streamflow data in the river network domain. Due to the complexity of the data domain structure, it is difficult to apply the lifting scheme to the streamflow data directly. To solve this problem, we propose a new lifting scheme algorithm for streamflow data that incorporates flow-adaptive neighbourhood selection, flow proportional weight generation and flow-length adaptive removal point selection. A nondecimated version of the proposed lifting scheme is also provided. The simulation study demonstrates that the proposed method successfully performs a multiscale analysis of streamflow data. Furthermore, we provide a real data analysis of water pollutant data observed on the Geum-River basin compared to the existing smoothing method.},
  archive      = {J_JRSSSC},
  author       = {Park, Seoncheol and Oh, Hee-Seok},
  doi          = {10.1111/rssc.12542},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {2},
  pages        = {467-490},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Lifting scheme for streamflow data in river networks},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting high-frequency spatio-temporal wind power with
dimensionally reduced echo state networks. <em>JRSSSC</em>,
<em>71</em>(2), 449–466. (<a
href="https://doi.org/10.1111/rssc.12540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast and accurate hourly forecasts of wind speed and power are crucial in quantifying and planning the energy budget in the electric grid. Modelling wind at a high resolution brings forth considerable challenges given its turbulent and highly nonlinear dynamics. In developing countries, where wind farms over a large domain are currently under construction or consideration, this is even more challenging given the necessity of modelling wind over space as well. In this work, we propose a machine learning approach to model the nonlinear hourly wind dynamics in Saudi Arabia with a domain-specific choice of knots to reduce spatial dimensionality. Our results show that for locations highlighted as wind abundant by a previous work, our approach results in an 11\% improvement in the 2-h-ahead forecasted power against operational standards in the wind energy sector, yielding a saving of nearly one million US dollars over a year under current market prices in Saudi Arabia.},
  archive      = {J_JRSSSC},
  author       = {Huang, Huang and Castruccio, Stefano and Genton, Marc G.},
  doi          = {10.1111/rssc.12540},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {2},
  pages        = {449-466},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Forecasting high-frequency spatio-temporal wind power with dimensionally reduced echo state networks},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantile mixed hidden markov models for multivariate
longitudinal data: An application to children’s strengths and
difficulties questionnaire scores. <em>JRSSSC</em>, <em>71</em>(2),
417–448. (<a href="https://doi.org/10.1111/rssc.12539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of factors associated with mental and behavioural disorders in early childhood is critical both for psychopathology research and the support of primary health care practices. Motivated by the Millennium Cohort Study, in this paper we study the effect of a comprehensive set of covariates on children&#39;s emotional and behavioural trajectories in England. To this end, we develop a quantile mixed hidden Markov model for joint estimation of multiple quantiles in a linear regression setting for multivariate longitudinal data. The novelty of the proposed approach is based on the multivariate asymmetric Laplace distribution which allows to jointly estimate the quantiles of the univariate conditional distributions of a multivariate response, accounting for possible correlation between the outcomes. Sources of unobserved heterogeneity and serial dependency due to repeated measures are modelled through the introduction of individual-specific, time-constant random coefficients and time-varying parameters evolving over time with a Markovian structure respectively. The inferential approach is carried out through the construction of a suitable expectation–maximization algorithm without parametric assumptions on the random effects distribution.},
  archive      = {J_JRSSSC},
  author       = {Merlo, Luca and Petrella, Lea and Tzavidis, Nikos},
  doi          = {10.1111/rssc.12539},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {2},
  pages        = {417-448},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Quantile mixed hidden markov models for multivariate longitudinal data: An application to children&#39;s strengths and difficulties questionnaire scores},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transformation model based regression with dependently
truncated and independently censored data. <em>JRSSSC</em>,
<em>71</em>(2), 395–416. (<a
href="https://doi.org/10.1111/rssc.12538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Truncated survival data arise when the event time is observed only if it falls within a subject specific region. The conventional risk-set adjusted Kaplan–Meier estimator or Cox model can be used for estimation of the event time distribution or regression coefficient. However, the validity of these approaches relies on the assumption of quasi-independence between truncation and event times. One model that can be used for the estimation of the survival function under dependent truncation is a structural transformation model that relates a latent, quasi-independent truncation time to the observed dependent truncation time and the event time. The transformation model approach is appealing for its simple interpretation, computational simplicity and flexibility. In this paper, we extend the transformation model approach to the regression setting. We propose three methods based on this model, in addition to a piecewise transformation model that adds greater flexibility. We investigate the performance of the proposed models through simulation studies and apply them to a study on cognitive decline in Alzheimer&#39;s disease from the National Alzheimer&#39;s Coordinating Center. We have developed an R package, tranSurv, for implementation of our method.},
  archive      = {J_JRSSSC},
  author       = {Qian, Jing and Chiou, Sy Han and Betensky, Rebecca A.},
  doi          = {10.1111/rssc.12538},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {2},
  pages        = {395-416},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Transformation model based regression with dependently truncated and independently censored data},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time prediction of severe influenza epidemics using
extreme value statistics. <em>JRSSSC</em>, <em>71</em>(2), 376–394. (<a
href="https://doi.org/10.1111/rssc.12537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Each year, seasonal influenza epidemics cause hundreds of thousands of deaths worldwide and put high loads on health care systems. A main concern for resource planning is the risk of exceptionally severe epidemics. Taking advantage of recent results on multivariate Generalized Pareto models in extreme value statistics we develop methods for real-time prediction of the risk that an ongoing influenza epidemic will be exceptionally severe and for real-time detection of anomalous epidemics and use them for prediction and detection of anomalies for influenza epidemics in France. Quality of predictions is assessed on observed and simulated data.},
  archive      = {J_JRSSSC},
  author       = {Thomas, Maud and Rootzén, Holger},
  doi          = {10.1111/rssc.12537},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {2},
  pages        = {376-394},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Real-time prediction of severe influenza epidemics using extreme value statistics},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Outcome-guided sparse k-means for disease subtype discovery
via integrating phenotypic data with high-dimensional transcriptomic
data. <em>JRSSSC</em>, <em>71</em>(2), 352–375. (<a
href="https://doi.org/10.1111/rssc.12536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discovery of disease subtypes is an essential step for developing precision medicine, and disease subtyping via omics data has become a popular approach. While promising, subtypes obtained from existing approaches are not necessarily associated with clinical outcomes. With the rich clinical data along with the omics data in modern epidemiology cohorts, it is urgent to develop an outcome-guided clustering algorithm to fully integrate the phenotypic data with the high-dimensional omics data. Hence, we extended a sparse K-means method to an outcome-guided sparse K-means (GuidedSparseKmeans) method. An unified objective function was proposed, which was comprised of (i) weighted K-means to perform sample clusterings; (ii) lasso regularizations to perform gene selection from the high-dimensional omics data; and (iii) incorporation of a phenotypic variable from the clinical dataset to facilitate biologically meaningful clustering results. By iteratively optimizing the objective function, we will simultaneously obtain a phenotype-related sample clustering results and gene selection results. We demonstrated the superior performance of the GuidedSparseKmeans by comparing with existing clustering methods in simulations and applications of high-dimensional transcriptomic data of breast cancer and Alzheimer&#39;s disease. Our algorithm has been implemented into an R package, which is publicly available on GitHub ( https://github.com/LingsongMeng/GuidedSparseKmeans ).},
  archive      = {J_JRSSSC},
  author       = {Meng, Lingsong and Avram, Dorina and Tseng, George and Huo, Zhiguang},
  doi          = {10.1111/rssc.12536},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {2},
  pages        = {352-375},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Outcome-guided sparse K-means for disease subtype discovery via integrating phenotypic data with high-dimensional transcriptomic data},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gaussian process modeling for dissolution curve comparisons.
<em>JRSSSC</em>, <em>71</em>(2), 331–351. (<a
href="https://doi.org/10.1111/rssc.12535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dissolution studies are an integral part of pharmaceutical drug development, yet standard methods for analysing dissolution data are inadequate for capturing the true underlying shapes of the dissolution curves. Methods based on similarity factors, such as the f 2 f 2 f2 statistic, have been developed to demonstrate comparability of dissolution curves, however, this inability to capture the shapes of the dissolution curves can lead to substantial bias in comparability estimators. In this article, we propose two novel semi-parametric dissolution curve modeling strategies for establishing the comparability of dissolution curves. The first method relies upon hierarchical Gaussian process regression models to construct an f 2 f 2 f2 statistic based on continuous time modeling that results in significant bias reduction. The second method uses a Bayesian model selection approach for creating a framework that does not suffer from the limitations of the f 2 f 2 f2 statistic. Overall, these two methods are shown to be superior to their comparator methods and provide feasible alternatives for similarity assessment under practical limitations. Illustrations highlighting the success of our methods are provided for two motivating real dissolution data sets from the literature, as well as extensive simulation studies.},
  archive      = {J_JRSSSC},
  author       = {Pourmohamad, Tony and Oliva Avilés, Cristian M. and Richardson, Robert},
  doi          = {10.1111/rssc.12535},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {2},
  pages        = {331-351},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Gaussian process modeling for dissolution curve comparisons},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ranking tailoring variables for constructing individualized
treatment rules: An application to schizophrenia. <em>JRSSSC</em>,
<em>71</em>(2), 309–330. (<a
href="https://doi.org/10.1111/rssc.12533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As with many chronic conditions, matching patients with schizophrenia to the best treatment option is difficult. Selecting antipsychotic medication is especially challenging because many of the medications can have burdensome side effects. Adjusting or tailoring medications based on patients’ characteristics could improve symptoms. However, it is often not known which patient characteristics are most helpful for informing treatment selection. In this paper, we address the challenge of identifying and ranking important variables for tailoring treatment decisions. We consider a value-search approach implemented through dynamic marginal structural models to estimate an optimal individualized treatment rule. We apply our methodology to the Clinical Antipsychotics Trial of Intervention and Effectiveness (CATIE) study for schizophrenia, to evaluate if some tailoring variables have greater potential than others for selecting treatments for patients with schizophrenia (Stroup et al., 2003, Schizophrenia Bulletin , 29 , 15–31).},
  archive      = {J_JRSSSC},
  author       = {Wu, Jiacheng and Galanter, Nina and Shortreed, Susan M. and Moodie, Erica E.M.},
  doi          = {10.1111/rssc.12533},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {2},
  pages        = {309-330},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Ranking tailoring variables for constructing individualized treatment rules: An application to schizophrenia},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The bayesian spatial bradley–terry model: Urban deprivation
modelling in tanzania. <em>JRSSSC</em>, <em>71</em>(2), 288–308. (<a
href="https://doi.org/10.1111/rssc.12532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying the most deprived regions of any country or city is key if policy makers are to design successful interventions. However, locating areas with the greatest need is often surprisingly challenging in developing countries. Due to the logistical challenges of traditional household surveying, official statistics can be slow to be updated; estimates that exist can be coarse, a consequence of prohibitive costs and poor infrastructures; and mass urbanization can render manually surveyed figures rapidly out-of-date. Comparative judgement models, such as the Bradley–Terry model, offer a promising solution. Leveraging local knowledge, elicited via comparisons of different areas’ affluence, such models can both simplify logistics and circumvent biases inherent to household surveys. Yet widespread adoption remains limited, due to the large amount of data existing approaches still require. We address this via development of a novel Bayesian Spatial Bradley–Terry model, which substantially decreases the number of comparisons required for effective inference. This model integrates a network representation of the city or country, along with assumptions of spatial smoothness that allow deprivation in one area to be informed by neighbouring areas. We demonstrate the practical effectiveness of this method, through a novel comparative judgement data set collected in Dar es Salaam, Tanzania.},
  archive      = {J_JRSSSC},
  author       = {Seymour, Rowland G. and Sirl, David and Preston, Simon P. and Dryden, Ian L. and Ellis, Madeleine J. A. and Perrat, Bertrand and Goulding, James},
  doi          = {10.1111/rssc.12532},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {2},
  pages        = {288-308},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {The bayesian spatial Bradley–Terry model: Urban deprivation modelling in tanzania},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bayesian spatio-network model for multiple adolescent
adverse health behaviours. <em>JRSSSC</em>, <em>71</em>(2), 271–287. (<a
href="https://doi.org/10.1111/rssc.12531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of alcohol, cigarettes and marijuana among adolescents are major public health concerns, and a number of epidemiological studies have been conducted to understand the drivers of these individual health behaviours. However, there is no literature that jointly models these health behaviours with the aim of understanding the relative importance of individual factors, friendship effects and spatial effects in determining the prevalence of alcohol, cigarette and marijuana use among adolescents. To address this gap in the literature, we propose a novel multivariate spatio-network model for jointly modelling all three of these behaviours, with inference conducted in a Bayesian setting using Markov chain Monte Carlo simulation. The model is motivated by survey data from five schools in Los Angeles, California, and the results indicate the important roles that individual factors and friendship networks play in driving the uptake of these health behaviours.},
  archive      = {J_JRSSSC},
  author       = {Gerogiannis, George and Tranmer, Mark and Lee, Duncan and Valente, Thomas},
  doi          = {10.1111/rssc.12531},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {2},
  pages        = {271-287},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {A bayesian spatio-network model for multiple adolescent adverse health behaviours},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Applied statistics. <em>JRSSSC</em>, <em>71</em>(2),
269–270. (<a href="https://doi.org/10.1111/rssc.12504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSC},
  doi          = {10.1111/rssc.12504},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {2},
  pages        = {269-270},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Applied statistics},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Second-order semi-parametric inference for multivariate log
gaussian cox processes. <em>JRSSSC</em>, <em>71</em>(1), 244–268. (<a
href="https://doi.org/10.1111/rssc.12530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new approach to inferring the second-order properties of a multivariate log Gaussian Cox process (LGCP) with a complex intensity function. We assume a semi-parametric model for the multivariate intensity function containing an unspecified complex factor common to all types of points. Given this model, we construct a second-order conditional composite likelihood to infer the pair correlation and cross pair correlation functions of the LGCP. Crucially this likelihood does not depend on the unspecified part of the intensity function. We also introduce a cross-validation method for model selection and an algorithm for regularized inference that can be used to obtain sparse models for cross pair correlation functions. The methodology is applied to simulated data as well as data examples from microscopy and criminology. This shows how the new approach outperforms existing alternatives where the intensity functions are estimated non-parametrically.},
  archive      = {J_JRSSSC},
  author       = {Hessellund, Kristian Bjørn and Xu, Ganggang and Guan, Yongtao and Waagepetersen, Rasmus},
  doi          = {10.1111/rssc.12530},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {1},
  pages        = {244-268},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Second-order semi-parametric inference for multivariate log gaussian cox processes},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiple comparison procedures for discrete uniform and
homogeneous tests. <em>JRSSSC</em>, <em>71</em>(1), 219–243. (<a
href="https://doi.org/10.1111/rssc.12529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrete uniform and homogeneous p -values often arise in applications with multiple testing. For example, this occurs in genome wide association studies whenever a non-parametric one-sample (or two-sample) test is applied throughout the gene loci. In this paper, we consider multiple comparison procedures for such scenarios based on several existing estimators for the proportion of true null hypotheses, π 0 π 0 π0 ⁠ , which take the discreteness of the p -values into account. The theoretical guarantees of the several approaches with respect to the estimation of π 0 π 0 π0 and the false discovery rate control are reviewed. The performance of the discrete procedures is investigated through intensive Monte Carlo simulations considering both independent and dependent p -values. The methods are applied to three real data sets for illustration purposes too. Since the particular estimator of π 0 π 0 π0 used to compute the q -values may influence its performance, relative advantages and disadvantages of the reviewed procedures are discussed. Practical recommendations are given.},
  archive      = {J_JRSSSC},
  author       = {Cousido-Rocha, Marta and de Uña-Álvarez, Jacobo and Döhler, Sebastian},
  doi          = {10.1111/rssc.12529},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {1},
  pages        = {219-243},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Multiple comparison procedures for discrete uniform and homogeneous tests},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pólya-gamma data augmentation and latent variable models for
multivariate binomial data. <em>JRSSSC</em>, <em>71</em>(1), 194–218.
(<a href="https://doi.org/10.1111/rssc.12528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New Zealand police has long been suspected of systematic bias against the indigenous Māori. One resource available to investigate this possibility is the annual counts of police apprehensions and prosecutions, by offence type. However, model specification/fitting is complicated as these data are constrained counts, interdependent and multivariate. For example, there are limited options for factor models beyond continuous or binary data. This is a serious limitation for in our dataset, while measurements are clustered, different individuals are measured at each variable. Focusing on principal component/factor analysis representations, we show that under the canonical logit link, latent variable models can be fitted via Gibbs sampling, to multivariate binomial data of arbitrary trial size by applying Pólya-gamma augmentation to the binomial likelihood. We demonstrate that this modelling approach, by incorporating shrinkage, will produce a fit with lower mean square error than techniques based on deviance minimization commonly employed for binary datasets. By exploring theoretical properties of the proposed models, we demonstrate a larger range of latent structures can be estimated and the presence of hidden replication improves prediction when data are multivariate binomial, which gives us greater flexibility for investigating associations between ethnicity and prosecution probability.},
  archive      = {J_JRSSSC},
  author       = {Holmes, John B. and Schofield, Matthew R. and Barker, Richard J.},
  doi          = {10.1111/rssc.12528},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {1},
  pages        = {194-218},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Pólya-gamma data augmentation and latent variable models for multivariate binomial data},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A discrete kernel stick-breaking model for detecting spatial
boundaries in hydraulic fracturing wastewater disposal well placement
across ohio. <em>JRSSSC</em>, <em>71</em>(1), 175–193. (<a
href="https://doi.org/10.1111/rssc.12527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting sharp differences, or boundaries, in areal data can uncover important biological, physical and/or social differences between spatial regions. We introduce a new discrete areal data kernel function for use in the kernel stick-breaking process framework that is shown to yield improved (i) detection of spatial boundaries, (ii) estimation of regression parameters and (iii) model fit through a simulation study and comparison with existing approaches. We use the model to analyse county-level hydraulic fracturing Class II injection well counts in Ohio, where interesting boundary patterns may exist due to the close connection between hydraulic fracturing and shale rock formations. Class II injection wells are used for disposing hydraulic fracturing liquid waste and may pose an environmental risk for surrounding communities. Counties located on the Devonian shale with increased poverty, less income equality, smaller proportion of the population that is white, and increased population density are found to contain more wells, with the relationship reversed for counties off the shale. Results suggest that the new method provides improved model fit and is robust to the exclusion of an important spatially varying covariate, while also detecting boundaries surrounding different shale rock formations. The method is implemented in the R package KSBound.},
  archive      = {J_JRSSSC},
  author       = {Warren, Joshua L. and Cai, Jiachen and Johnson, Nicholaus P. and Deziel, Nicole C.},
  doi          = {10.1111/rssc.12527},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {1},
  pages        = {175-193},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {A discrete kernel stick-breaking model for detecting spatial boundaries in hydraulic fracturing wastewater disposal well placement across ohio},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Daily mortality/morbidity and air quality: Using
multivariate time series with seasonally varying covariances.
<em>JRSSSC</em>, <em>71</em>(1), 148–174. (<a
href="https://doi.org/10.1111/rssc.12525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the associations between daily mortality and short-term variations in the ambient concentrations of fine particulate matter ( ⁠ PM 2.5 PM 2.5 PM2.5 ⁠ ), nitrogen dioxide ( ⁠ NO 2 NO 2 NO2 ⁠ ) and ozone ( ⁠ O 3 O 3 O3 ⁠ ) in four cities in Canada. First, a novel multivariate time series model within Bayesian framework is proposed for exposure assessment, where the response is a mixture of Gamma and Half-Cauchy distributions and the correlations between pollutants vary seasonally. A case-crossover design and conditional logistic regression model is used to relate exposure to disease data for each city, which then are combined to obtain a global estimate of exposure health effects allowing exposure uncertainty. The results suggest that every 10 ppb increase in O 3 O 3 O3 is associated with a 3.88\% (95\% credible interval [CI], 2.5\%, 5.18\%) increase in all-cause mortality, a 5.04\% (2.84\%, 7.43\%) increase in circulatory mortality, a 7.87\% (2.4\%, 12.9\%) increase in respiratory mortality, a 0.76\% (0.19\%, 1.35\%) increase in all-cause morbidity and a 6.6\% (0.58\%, 12.7\%) increase in respiratory morbidity. Similarly, every 10 ppb increase in NO 2 NO 2 NO2 is associated with a 2.13\% (0.42\%, 3.87\%) increase in circulatory morbidity. The health impacts of PM 2.5 PM 2.5 PM2.5 are not found to be present once other pollutants are accounted for.},
  archive      = {J_JRSSSC},
  author       = {Huang, Guowen and Brown, Patrick E. and Fu, Sze Hang and Shin, Hwashin Hyun},
  doi          = {10.1111/rssc.12525},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {1},
  pages        = {148-174},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Daily Mortality/Morbidity and air quality: Using multivariate time series with seasonally varying covariances},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of large block structured covariance matrices:
Application to “multi-omic” approaches to study seed quality.
<em>JRSSSC</em>, <em>71</em>(1), 119–147. (<a
href="https://doi.org/10.1111/rssc.12524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by an application in high-throughput genomics and metabolomics, we propose a novel and fully data-driven approach for estimating large block structured sparse covariance matrices in the case where the number of variables is much larger than the number of samples without limiting ourselves to block diagonal matrices. Our approach consists in approximating such a covariance matrix by the sum of a low-rank sparse matrix and a diagonal matrix. Our methodology also can deal with matrices for which the block structure appears only if the columns and rows are permuted according to an unknown permutation. Our technique is implemented in the R package BlockCov which is available from the Comprehensive R Archive Network (CRAN) and from GitHub. In order to illustrate the statistical and numerical performance of our package some numerical experiments are provided as well as a thorough comparison with alternative methods. Finally, our approach is applied to the use of ‘multi-omic’ approaches for studying seed quality.},
  archive      = {J_JRSSSC},
  author       = {Perrot-Dockès, M. and Lévy-Leduc, C. and Rajjou, L.},
  doi          = {10.1111/rssc.12524},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {1},
  pages        = {119-147},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Estimation of large block structured covariance matrices: Application to ‘Multi-omic’ approaches to study seed quality},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Urnings: A new method for tracking dynamically changing
parameters in paired comparison systems. <em>JRSSSC</em>,
<em>71</em>(1), 91–118. (<a
href="https://doi.org/10.1111/rssc.12523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new rating system for tracking the development of parameters based on a stream of observations that can be viewed as paired comparisons. Rating systems are applied in competitive games, adaptive learning systems and platforms for product and service reviews. We model each observation as an outcome of a game of chance that depends on the parameters of interest (e.g. the outcome of a chess game depends on the abilities of the two players). Determining the probabilities of the different game outcomes is conceptualized as an urn problem, where a rating is represented by a probability (i.e. proportion of balls in the urn). This setup allows for evaluating the standard errors of the ratings and performing statistical inferences about the development of, and relations between, parameters. Theoretical properties of the system in terms of the invariant distributions of the ratings and their convergence are derived. The properties of the rating system are illustrated with simulated examples and its potential for answering research questions is illustrated using data from competitive chess, a movie review system, and an adaptive learning system for math.},
  archive      = {J_JRSSSC},
  author       = {Bolsinova, Maria and Maris, Gunter and Hofman, Abe D. and van der Maas, Han L. J. and Brinkhuis, Matthieu J. S.},
  doi          = {10.1111/rssc.12523},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {1},
  pages        = {91-118},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Urnings: A new method for tracking dynamically changing parameters in paired comparison systems},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using social contact data to improve the overall effect
estimate of a cluster-randomized influenza vaccination program in
senegal. <em>JRSSSC</em>, <em>71</em>(1), 70–90. (<a
href="https://doi.org/10.1111/rssc.12522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study estimates the overall effect of two influenza vaccination programs consecutively administered in a cluster-randomized trial in western Senegal over the course of two influenza seasons from 2009 to 2011. We apply cutting-edge methodology combining social contact data with infection data to reduce bias in estimation arising from contamination between clusters. Our time-varying estimates reveal a reduction in seasonal influenza from the intervention and a non-significant increase in H1N1 pandemic influenza. We estimate an additive change in overall cumulative incidence (which was 6.13\% in the control arm) of -0.68 percentage points during Year 1 of the study (95\% CI: −2.53, 1.18). When H1N1 pandemic infections were excluded from analysis, the estimated change was −1.45 percentage points and was significant (95\% CI, −2.81, −0.08). Because cross-cluster contamination was low (0–3\% of contacts for most villages), an estimator assuming no contamination was only slightly attenuated (−0.65 percentage points). These findings are encouraging for studies carefully designed to minimize spillover. Further work is needed to estimate contamination – and its effect on estimation – in a variety of settings.},
  archive      = {J_JRSSSC},
  author       = {Potter, Gail E. and Carnegie, Nicole Bohme and Sugimoto, Jonathan D. and Diallo, Aldiouma and Victor, John C. and Neuzil, Kathleen M. and Elizabeth Halloran, M.},
  doi          = {10.1111/rssc.12522},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {1},
  pages        = {70-90},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Using social contact data to improve the overall effect estimate of a cluster-randomized influenza vaccination program in senegal},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonparametric k-sample test on shape spaces with
applications to mitochondrial shape analysis. <em>JRSSSC</em>,
<em>71</em>(1), 51–69. (<a
href="https://doi.org/10.1111/rssc.12521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important hypothesis in animal cell biology is that an animal’s acute exercise regimen affects some subcellular structures, for example mitochondrial morphology, in its muscle tissue. This paper investigates that hypothesis using a nonparametric metric-based energy test for comparing mitochondrial populations. It explores two shape spaces—the elastic shape space and Kendall shape space—and five corresponding shape metrics on these spaces. The results overwhelmingly point to the statistical significance of the effect of an acute exercise regimen on the shape of SS-type mitochondria. Although past studies based on specific morphological features derived from mitochondria failed to detect this significance. In this analysis, a potentially significant factor is cell membership and a k -sample generalization of the energy test—the DISCO test shows that the cell effect is indeed significant. The energy test cannot be applied directly due to the hierarchical structure of the distance matrix. We propose a compression method to remove the significant cell effect while testing for the exercise effect. With this compression, only the elastic scaled metric shows statistical significance of the exercise factor in this more complicated scenario. This result is because the elastic-scaled metric is more sensitive to subtle changes in mitochondrial shapes caused by acute exercise.},
  archive      = {J_JRSSSC},
  author       = {Zhang, Ruiyi and Ogden, R. Todd and Picard, Martin and Srivastava, Anuj},
  doi          = {10.1111/rssc.12521},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {1},
  pages        = {51-69},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Nonparametric k-sample test on shape spaces with applications to mitochondrial shape analysis},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Characteristic and necessary minutiae in fingerprints.
<em>JRSSSC</em>, <em>71</em>(1), 27–50. (<a
href="https://doi.org/10.1111/rssc.12520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fingerprints feature a ridge pattern with moderately varying ridge frequency (RF), following an orientation field (OF), which usually features some singularities. Additionally at some points, called minutiae, ridge lines end or fork and this point pattern is usually used for fingerprint identification and authentication. Whenever the OF features divergent ridge lines (e.g., near singularities), a nearly constant RF necessitates the generation of more ridge lines, originating at minutiae. We call these the necessary minutiae. It turns out that fingerprints feature additional minutiae which occur at rather arbitrary locations. We call these the random minutiae or, since they may convey fingerprint individuality beyond the OF, the characteristic minutiae. In consequence, the minutiae point pattern is assumed to be a realization of the superposition of two stochastic point processes: a Strauss point process (whose activity function is given by the divergence field) with an additional hard core, and a homogeneous Poisson point process, modelling the necessary and the characteristic minutiae, respectively. We perform Bayesian inference using an Markov-Chain-Monte-Carlo (MCMC)-based minutiae separating algorithm (MiSeal). In simulations, it provides good mixing and good estimation of underlying parameters. In application to fingerprints, we can separate the two minutiae patterns and verify by example of two different prints with similar OF that characteristic minutiae convey fingerprint individuality.},
  archive      = {J_JRSSSC},
  author       = {Wieditz, Johannes and Pokern, Yvo and Schuhmacher, Dominic and Huckemann, Stephan},
  doi          = {10.1111/rssc.12520},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {1},
  pages        = {27-50},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Characteristic and necessary minutiae in fingerprints},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimating mean lifetime from partially observed events in
nuclear physics. <em>JRSSSC</em>, <em>71</em>(1), 3–26. (<a
href="https://doi.org/10.1111/rssc.12519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mean lifetime is an important characteristic of particles to be identified in nuclear physics. State-of-the-art particle detectors can identify the arrivals of single radioactive nuclei as well as their subsequent radioactive decays (departures). Challenges arise when the arrivals and departures are unmatched and the departures are only partially observed. An inefficient solution is to run experiments where the arrival rate is set very low to allow for the matching of arrivals and departures. We propose an estimation method that works for a wide range of arrival rates. The method combines an initial estimator and a numerical bias correction technique. Simulations and examples based on data on the alpha decays of Lutetium isotope 155 demonstrate that the method produces unbiased estimates regardless of the arrival rate. As a practical benefit, the estimation method enables the use of all data collected in the particle detector, which will lead to more accurate estimates and, in some cases, to shorter experiments.},
  archive      = {J_JRSSSC},
  author       = {Karvanen, Juha and Niilo-Rämä, Mikko and Sarén, Jan and Kärkkäinen, Salme},
  doi          = {10.1111/rssc.12519},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {1},
  pages        = {3-26},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Estimating mean lifetime from partially observed events in nuclear physics},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Applied statistics. <em>JRSSSC</em>, <em>71</em>(1), 1–2.
(<a href="https://doi.org/10.1111/rssc.12503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSC},
  doi          = {10.1111/rssc.12503},
  journal      = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  number       = {1},
  pages        = {1-2},
  shortjournal = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  title        = {Applied statistics},
  volume       = {71},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
