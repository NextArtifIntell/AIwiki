<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>BIOMET_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="biomet---81">BIOMET - 81</h2>
<ul>
<li><details>
<summary>
(2022a). Correction to: “Valid sequential inference on probability
forecast performance.” <em>BIOMET</em>, <em>109</em>(4), 1181–1182. (<a
href="https://doi.org/10.1093/biomet/asac043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIOMET},
  author       = {Henzi, Alexander and Ziegel, Johanna F},
  doi          = {10.1093/biomet/asac043},
  journal      = {Biometrika},
  number       = {4},
  pages        = {1181-1182},
  shortjournal = {Biometrika},
  title        = {Correction to: ‘Valid sequential inference on probability forecast performance’},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A correlation-shrinkage prior for bayesian prediction of the
two-dimensional wishart model. <em>BIOMET</em>, <em>109</em>(4),
1173–1180. (<a href="https://doi.org/10.1093/biomet/asac006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Bayesian prediction problem for the two-dimensional Wishart model is investigated within the framework of decision theory. The loss function is the Kullback–Leibler divergence. We construct a scale-invariant and permutation-invariant prior distribution that shrinks the correlation coefficient. The prior is the geometric mean of the right invariant prior with respect to permutation of the indices, and is characterized by a uniform distribution for Fisher’s |$z$| -transformation of the correlation coefficient. The Bayesian predictive density based on the prior is shown to be minimax.},
  archive      = {J_BIOMET},
  author       = {Sei, T and Komaki, F},
  doi          = {10.1093/biomet/asac006},
  journal      = {Biometrika},
  number       = {4},
  pages        = {1173-1180},
  shortjournal = {Biometrika},
  title        = {A correlation-shrinkage prior for bayesian prediction of the two-dimensional wishart model},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Average direct and indirect causal effects under
interference. <em>BIOMET</em>, <em>109</em>(4), 1165–1172. (<a
href="https://doi.org/10.1093/biomet/asac008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a definition for the average indirect effect of a binary treatment in the potential outcomes model for causal inference under cross-unit interference. Our definition is analogous to the standard definition of the average direct effect and can be expressed without needing to compare outcomes across multiple randomized experiments. We show that the proposed indirect effect satisfies a decomposition theorem stating that in a Bernoulli trial, the sum of the average direct and indirect effects always corresponds to the effect of a policy intervention that infinitesimally increases treatment probabilities. We also consider a number of parametric models for interference and find that our nonparametric indirect effect remains a natural estimand when re-expressed in the context of these models.},
  archive      = {J_BIOMET},
  author       = {Hu, Yuchen and Li, Shuangning and Wager, Stefan},
  doi          = {10.1093/biomet/asac008},
  journal      = {Biometrika},
  number       = {4},
  pages        = {1165-1172},
  shortjournal = {Biometrika},
  title        = {Average direct and indirect causal effects under interference},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Is the mode elicitable relative to unimodal distributions?
<em>BIOMET</em>, <em>109</em>(4), 1157–1164. (<a
href="https://doi.org/10.1093/biomet/asab065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A statistical functional is said to be elicitable if there exists a loss or scoring function under which the functional is the optimal point forecast in expectation. While the mean and quantiles are elicitable, it has been shown in Heinrich (2014) that the mode is not elicitable if the true distribution can follow any Lebesgue density. We strengthen the result of Heinrich (2014) substantially, showing that the mode is not elicitable if the true distribution can be any strongly unimodal distribution with continuous Lebesgue density, i.e., a continuous density with only one local maximum. Likewise, the mode fails to be identifiable relative to this class.},
  archive      = {J_BIOMET},
  author       = {Heinrich-Mertsching, Claudio and Fissler, Tobias},
  doi          = {10.1093/biomet/asab065},
  journal      = {Biometrika},
  number       = {4},
  pages        = {1157-1164},
  shortjournal = {Biometrika},
  title        = {Is the mode elicitable relative to unimodal distributions?},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adjusting the benjamini–hochberg method for controlling the
false discovery rate in knockoff-assisted variable selection.
<em>BIOMET</em>, <em>109</em>(4), 1149–1155. (<a
href="https://doi.org/10.1093/biomet/asab066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the knockoff-based multiple testing set-up of Barber &amp; Candès (2015) . for variable selection in multiple regression. The method of Benjamini &amp; Hochberg (1995) and an adaptive version of it are adjusted to this set-up, transforming them to valid |$p$| -value-based, false discovery rate-controlling methods that do not rely on specifying the correlation structure of the explanatory variables. Simulations and real data applications show that the proposed methods are powerful competitors of the false discovery rate-controlling method of Barber &amp; Candès (2015) .},
  archive      = {J_BIOMET},
  author       = {Sarkar, Sanat K and Tang, Cheng Yong},
  doi          = {10.1093/biomet/asab066},
  journal      = {Biometrika},
  number       = {4},
  pages        = {1149-1155},
  shortjournal = {Biometrika},
  title        = {Adjusting the Benjamini–Hochberg method for controlling the false discovery rate in knockoff-assisted variable selection},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Functional hybrid factor regression model for handling
heterogeneity in imaging studies. <em>BIOMET</em>, <em>109</em>(4),
1133–1148. (<a href="https://doi.org/10.1093/biomet/asac007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a functional hybrid factor regression modelling framework to handle the heterogeneity of many large-scale imaging studies, such as the Alzheimer’s disease neuroimaging initiative study. Despite the numerous successes of those imaging studies, such heterogeneity may be caused by the differences in study environment, population, design, protocols or other hidden factors, and it has posed major challenges in integrative analysis of imaging data collected from multicentres or multistudies. We propose both estimation and inference procedures for estimating unknown parameters and detecting unknown factors under our new model. The asymptotic properties of both estimation and inference procedures are systematically investigated. The finite-sample performance of our proposed procedures is assessed by using Monte Carlo simulations and a real data example on hippocampal surface data from the Alzheimer’s disease study.},
  archive      = {J_BIOMET},
  author       = {Huang, C and Zhu, H},
  doi          = {10.1093/biomet/asac007},
  journal      = {Biometrika},
  number       = {4},
  pages        = {1133-1148},
  shortjournal = {Biometrika},
  title        = {Functional hybrid factor regression model for handling heterogeneity in imaging studies},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An approximate randomization test for the high-dimensional
two-sample behrens–fisher problem under arbitrary covariances.
<em>BIOMET</em>, <em>109</em>(4), 1117–1132. (<a
href="https://doi.org/10.1093/biomet/asac014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the problem of comparing the population means of two groups of independent observations. An approximate randomization test procedure based on the test statistic of Chen &amp; Qin (2010) is proposed. The asymptotic behaviour of the test statistic, as well as the randomized statistic, is studied under weak conditions. In our theoretical framework, observations are not assumed to be identically distributed even within groups. No condition on the eigenstructure of the covariance matrices is imposed. Furthermore, the sample sizes of the two groups are allowed to be unbalanced. Under general conditions, all possible asymptotic distributions of the test statistic are obtained. We derive the asymptotic level and local power of the approximate randomization test procedure. Our theoretical results show that the proposed test procedure can adapt to all possible asymptotic distributions of the test statistic, always has the correct test level asymptotically and has good power behaviour. Our numerical experiments show that the proposed test procedure has favourable performance compared with several alternative test procedures.},
  archive      = {J_BIOMET},
  author       = {Wang, Rui and Xu, Wangli},
  doi          = {10.1093/biomet/asac014},
  journal      = {Biometrika},
  number       = {4},
  pages        = {1117-1132},
  shortjournal = {Biometrika},
  title        = {An approximate randomization test for the high-dimensional two-sample Behrens–Fisher problem under arbitrary covariances},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sensitivity analysis for unmeasured confounding in the
estimation of marginal causal effects. <em>BIOMET</em>, <em>109</em>(4),
1101–1116. (<a href="https://doi.org/10.1093/biomet/asac018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main threats to the validity of causal effect estimates from observational data is the existence of unmeasured confounders. A plethora of methods has been proposed to quantify deviation from conditional exchangeability, which arises when confounding is not properly accounted for, with each method having its own set of limitations and underlying assumptions. Few methods both scale well with the increasing complexity of potential measured confounders and avoid making strong simplifying assumptions about the effect of the unmeasured confounder within strata of the measured confounders. For binary outcomes, we propose a quantification of the deviation from conditional exchangeability, based on standardization within levels of the exposure, which can accommodate any type of measured and unmeasured confounders or desired estimand. In the case of binary exposure, this amounts to varying two parameters across a grid of values, no matter how complex the measured confounding. We propose three methods of estimation for the causal estimand of interest under our proposed sensitivity analysis. This allows for an easily applied, easily interpreted sensitivity analysis that makes minimal assumptions about the type of unmeasured confounding and places no limits on the complexity of the potential measured confounders.},
  archive      = {J_BIOMET},
  author       = {Ciocănea-Teodorescu, I and Gabriel, E E and Sjölander, A},
  doi          = {10.1093/biomet/asac018},
  journal      = {Biometrika},
  number       = {4},
  pages        = {1101-1116},
  shortjournal = {Biometrika},
  title        = {Sensitivity analysis for unmeasured confounding in the estimation of marginal causal effects},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decomposition, identification and multiply robust estimation
of natural mediation effects with multiple mediators. <em>BIOMET</em>,
<em>109</em>(4), 1085–1100. (<a
href="https://doi.org/10.1093/biomet/asac004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural mediation effects are desirable estimands for studying causal mechanisms in a population, but complications arise in defining and estimating natural indirect effects through multiple mediators with an unspecified causal ordering. We propose a decomposition of the natural indirect effect of multiple mediators into individual components, termed exit indirect effects, and a remainder interaction term, and study the similarities to and differences from existing natural and interventional effects in the literature. We provide a set of identification assumptions for estimating all components of the proposed natural effect decomposition and derive the semiparametric efficiency bounds for the effects. The efficient influence functions contain conditional densities that are variationally dependent, which is uncommon in existing problems and may lead to model incompatibility. By ensuring model compatibility through a reparameterization based on copulas, our estimator is quadruply robust, which means that it remains consistent and asymptotically normal under four types of possible misspecification, and also is locally semiparametric efficient. We further propose a stabilized quadruply robust estimator to improve practical performance under possibly misspecified models, as well as a nonparametric extension based on sample splitting.},
  archive      = {J_BIOMET},
  author       = {Xia, Fan and Chan, Kwun Chuen Gary},
  doi          = {10.1093/biomet/asac004},
  journal      = {Biometrika},
  number       = {4},
  pages        = {1085-1100},
  shortjournal = {Biometrika},
  title        = {Decomposition, identification and multiply robust estimation of natural mediation effects with multiple mediators},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Significance testing for canonical correlation analysis in
high dimensions. <em>BIOMET</em>, <em>109</em>(4), 1067–1083. (<a
href="https://doi.org/10.1093/biomet/asab059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of testing for the presence of linear relationships between large sets of random variables based on a postselection inference approach to canonical correlation analysis. The challenge is to adjust for the selection of subsets of variables having linear combinations with maximal sample correlation. To this end, we construct a stabilized one-step estimator of the Euclidean norm of the canonical correlations maximized over subsets of variables of prespecified cardinality. This estimator is shown to be consistent for its target parameter and asymptotically normal, provided the dimensions of the variables do not grow too quickly with sample size. We also develop a greedy search algorithm to accurately compute the estimator, leading to a computationally tractable omnibus test for the global null hypothesis that there are no linear relationships between any subsets of variables having the prespecified cardinality. We further develop a confidence interval that takes the variable selection into account.},
  archive      = {J_BIOMET},
  author       = {McKeague, Ian W and Zhang, Xin},
  doi          = {10.1093/biomet/asab059},
  journal      = {Biometrika},
  number       = {4},
  pages        = {1067-1083},
  shortjournal = {Biometrika},
  title        = {Significance testing for canonical correlation analysis in high dimensions},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A proximal distance algorithm for likelihood-based sparse
covariance estimation. <em>BIOMET</em>, <em>109</em>(4), 1047–1066. (<a
href="https://doi.org/10.1093/biomet/asac011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the task of estimating a covariance matrix under a patternless sparsity assumption. In contrast to existing approaches based on thresholding or shrinkage penalties, we propose a likelihood-based method that regularizes the distance from the covariance estimate to a symmetric sparsity set. This formulation avoids unwanted shrinkage induced by more common norm penalties, and enables optimization of the resulting nonconvex objective by solving a sequence of smooth, unconstrained subproblems. These subproblems are generated and solved via the proximal distance version of the majorization-minimization principle. The resulting algorithm executes rapidly, gracefully handles settings where the number of parameters exceeds the number of cases, yields a positive-definite solution, and enjoys desirable convergence properties. Empirically, we demonstrate that our approach outperforms competing methods across several metrics, for a suite of simulated experiments. Its merits are illustrated on international migration data and a case study on flow cytometry. Our findings suggest that the marginal and conditional dependency networks for the cell signalling data are more similar than previously concluded.},
  archive      = {J_BIOMET},
  author       = {Xu, Jason and Lange, Kenneth},
  doi          = {10.1093/biomet/asac011},
  journal      = {Biometrika},
  number       = {4},
  pages        = {1047-1066},
  shortjournal = {Biometrika},
  title        = {A proximal distance algorithm for likelihood-based sparse covariance estimation},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-dimensional linear regression via implicit
regularization. <em>BIOMET</em>, <em>109</em>(4), 1033–1046. (<a
href="https://doi.org/10.1093/biomet/asac010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many statistical estimators for high-dimensional linear regression are |$M$| -estimators, formed through minimizing a data-dependent square loss function plus a regularizer. This work considers a new class of estimators implicitly defined through a discretized gradient dynamic system under overparameterization. We show that, under suitable restricted isometry conditions, overparameterization leads to implicit regularization: if we directly apply gradient descent to the residual sum of squares with sufficiently small initial values then, under some proper early stopping rule, the iterates converge to a nearly sparse rate-optimal solution that improves over explicitly regularized approaches. In particular, the resulting estimator does not suffer from extra bias due to explicit penalties, and can achieve the parametric root- |$n$| rate when the signal-to-noise ratio is sufficiently high. We also perform simulations to compare our methods with high-dimensional linear regression with explicit regularization. Our results illustrate the advantages of using implicit regularization via gradient descent after overparameterization in sparse vector estimation.},
  archive      = {J_BIOMET},
  author       = {Zhao, Peng and Yang, Yun and He, Qiao-Chu},
  doi          = {10.1093/biomet/asac010},
  journal      = {Biometrika},
  number       = {4},
  pages        = {1033-1046},
  shortjournal = {Biometrika},
  title        = {High-dimensional linear regression via implicit regularization},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient semiparametric estimation of network treatment
effects under partial interference. <em>BIOMET</em>, <em>109</em>(4),
1015–1031. (<a href="https://doi.org/10.1093/biomet/asac009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although many estimators for network treatment effects have been proposed, their optimality properties, in terms of semiparametric efficiency, have yet to be resolved. We present a simple yet flexible asymptotic framework for deriving the efficient influence function and the semiparametric efficiency lower bound for a family of network causal effects under partial interference. An important corollary of our results is that one existing estimator, that proposed by Liu et al. (2019) , is locally efficient. We also present other estimators that are efficient and discuss results on adaptive estimation. We illustrate application of the efficient estimators in a study of the direct and spillover effects of conditional cash transfer programmes in Colombia.},
  archive      = {J_BIOMET},
  author       = {Park, C and Kang, H},
  doi          = {10.1093/biomet/asac009},
  journal      = {Biometrika},
  number       = {4},
  pages        = {1015-1031},
  shortjournal = {Biometrika},
  title        = {Efficient semiparametric estimation of network treatment effects under partial interference},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graphical gaussian process models for highly multivariate
spatial data. <em>BIOMET</em>, <em>109</em>(4), 993–1014. (<a
href="https://doi.org/10.1093/biomet/asab061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For multivariate spatial Gaussian process models, customary specifications of cross-covariance functions do not exploit relational inter-variable graphs to ensure process-level conditional independence between the variables. This is undesirable, especially in highly multivariate settings, where popular cross-covariance functions, such as multivariate Matérn functions, suffer from a curse of dimensionality as the numbers of parameters and floating-point operations scale up in quadratic and cubic order, respectively, with the number of variables. We propose a class of multivariate graphical Gaussian processes using a general construction called stitching that crafts cross-covariance functions from graphs and ensures process-level conditional independence between variables. For the Matérn family of functions, stitching yields a multivariate Gaussian process whose univariate components are Matérn Gaussian processes, and which conforms to process-level conditional independence as specified by the graphical model. For highly multivariate settings and decomposable graphical models, stitching offers massive computational gains and parameter dimension reduction. We demonstrate the utility of the graphical Matérn Gaussian process to jointly model highly multivariate spatial data using simulation examples and an application to air-pollution modelling.},
  archive      = {J_BIOMET},
  author       = {Dey, Debangan and Datta, Abhirup and Banerjee, Sudipto},
  doi          = {10.1093/biomet/asab061},
  journal      = {Biometrika},
  number       = {4},
  pages        = {993-1014},
  shortjournal = {Biometrika},
  title        = {Graphical gaussian process models for highly multivariate spatial data},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fréchet sufficient dimension reduction for random objects.
<em>BIOMET</em>, <em>109</em>(4), 975–992. (<a
href="https://doi.org/10.1093/biomet/asac012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider Fréchet sufficient dimension reduction with responses being complex random objects in a metric space and high-dimensional Euclidean predictors. We propose a novel approach, called the weighted inverse regression ensemble method, for linear Fréchet sufficient dimension reduction. The method is further generalized as a new operator defined on reproducing kernel Hilbert spaces for nonlinear Fréchet sufficient dimension reduction. We provide theoretical guarantees for the new method via asymptotic analysis. Intensive simulation studies verify the performance of our proposals, and we apply our methods to analyse handwritten digit data and real-world affective face data to demonstrate its use in real applications.},
  archive      = {J_BIOMET},
  author       = {Ying, Chao and Yu, Zhou},
  doi          = {10.1093/biomet/asac012},
  journal      = {Biometrika},
  number       = {4},
  pages        = {975-992},
  shortjournal = {Biometrika},
  title        = {Fréchet sufficient dimension reduction for random objects},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distribution-on-distribution regression via optimal
transport maps. <em>BIOMET</em>, <em>109</em>(4), 957–974. (<a
href="https://doi.org/10.1093/biomet/asac005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a framework for performing regression when both covariate and response are probability distributions on a compact interval. Our regression model is based on the theory of optimal transportation, and links the conditional Fréchet mean of the response to the covariate via an optimal transport map. We define a Fréchet-least-squares estimator of this regression map, and establish its consistency and rate of convergence to the true map, under both full and partial observations of the regression pairs. Computation of the estimator is shown to reduce to a standard convex optimization problem, and thus our regression model can be implemented with ease. We illustrate our methodology using real and simulated data.},
  archive      = {J_BIOMET},
  author       = {Ghodrati, Laya and Panaretos, Victor M},
  doi          = {10.1093/biomet/asac005},
  journal      = {Biometrika},
  number       = {4},
  pages        = {957-974},
  shortjournal = {Biometrika},
  title        = {Distribution-on-distribution regression via optimal transport maps},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A global stochastic optimization particle filter algorithm.
<em>BIOMET</em>, <em>109</em>(4), 937–955. (<a
href="https://doi.org/10.1093/biomet/asab067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new online algorithm for expected loglikelihood maximization in situations where the objective function is multimodal or has saddle points. The key element underpinning the algorithm is a probability distribution that concentrates on the target parameter value as the sample size increases and can be efficiently estimated by means of a standard particle filter algorithm. This distribution depends on a learning rate, such that the faster the learning rate the quicker the distribution concentrates on the desired element of the search space, but the less likely the algorithm is to escape from a local optimum of the objective function. In order to achieve a fast convergence rate with a slow learning rate, our algorithm exploits the acceleration property of averaging, which is well known from the stochastic gradient literature. Considering several challenging estimation problems, our numerical experiments show that with high probability, the algorithm successfully finds the highest mode of the objective function and converges to the global maximizer at the optimal rate. While the focus of this work is expected loglikelihood maximization, the proposed methodology and its theory apply more generally to optimization of a function defined through an expectation.},
  archive      = {J_BIOMET},
  author       = {Gerber, M and Douc, R},
  doi          = {10.1093/biomet/asab067},
  journal      = {Biometrika},
  number       = {4},
  pages        = {937-955},
  shortjournal = {Biometrika},
  title        = {A global stochastic optimization particle filter algorithm},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Particle filter efficiency under limited communication.
<em>BIOMET</em>, <em>109</em>(4), 921–935. (<a
href="https://doi.org/10.1093/biomet/asac015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential Monte Carlo methods are typically not straightforward to implement on parallel architectures. This is because standard resampling schemes involve communication between all particles. The $$\alpha$$ -sequential Monte Carlo method was proposed recently as a potential solution to this that limits communication between particles. This limited communication is controlled through a sequence of stochastic matrices known as $$\alpha$$ matrices. We study the influence of the communication structure on the convergence and stability properties of the resulting algorithms. In particular, we quantitatively show that the mixing properties of the $$\alpha$$ matrices play an important role in the stability properties of the algorithm. Moreover, we prove that one can ensure good mixing properties by using randomized communication structures where each particle only communicates with a few neighbouring particles. The resulting algorithms converge at the usual Monte Carlo rate. This leads to efficient versions of distributed sequential Monte Carlo.},
  archive      = {J_BIOMET},
  author       = {Sen, Deborshee},
  doi          = {10.1093/biomet/asac015},
  journal      = {Biometrika},
  number       = {4},
  pages        = {921-935},
  shortjournal = {Biometrika},
  title        = {Particle filter efficiency under limited communication},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scalable and accurate variational bayes for high-dimensional
binary regression models. <em>BIOMET</em>, <em>109</em>(4), 901–919. (<a
href="https://doi.org/10.1093/biomet/asac026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern methods for Bayesian regression beyond the Gaussian response setting are often computationally impractical or inaccurate in high dimensions. In fact, as discussed in recent literature, bypassing such a trade-off is still an open problem even in routine binary regression models, and there is limited theory on the quality of variational approximations in high-dimensional settings. To address this gap, we study the approximation accuracy of routinely used mean-field variational Bayes solutions in high-dimensional probit regression with Gaussian priors, obtaining novel and practically relevant results on the pathological behaviour of such strategies in uncertainty quantification, point estimation and prediction. Motivated by these results, we further develop a new partially factorized variational approximation for the posterior distribution of the probit coefficients that leverages a representation with global and local variables but, unlike for classical mean-field assumptions, it avoids a fully factorized approximation, and instead assumes a factorization only for the local variables. We prove that the resulting approximation belongs to a tractable class of unified skew-normal densities that crucially incorporates skewness and, unlike for state-of-the-art mean-field solutions, converges to the exact posterior density as |$p \rightarrow \infty$|⁠ . To solve the variational optimization problem, we derive a tractable coordinate ascent variational inference algorithm that easily scales to |$p$| in the tens of thousands, and provably requires a number of iterations converging to |$1$| as |$p \rightarrow \infty$|⁠ . Such findings are also illustrated in extensive empirical studies where our novel solution is shown to improve the approximation accuracy of mean-field variational Bayes for any |$n$| and |$p$|⁠ , with the magnitude of these gains being remarkable in those high-dimensional |$p&gt;n$| settings where state-of-the-art methods are computationally impractical.},
  archive      = {J_BIOMET},
  author       = {Fasano, Augusto and Durante, Daniele and Zanella, Giacomo},
  doi          = {10.1093/biomet/asac026},
  journal      = {Biometrika},
  number       = {4},
  pages        = {901-919},
  shortjournal = {Biometrika},
  title        = {Scalable and accurate variational bayes for high-dimensional binary regression models},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mean decrease accuracy for random forests: Inconsistency,
and a practical solution via the sobol-MDA. <em>BIOMET</em>,
<em>109</em>(4), 881–900. (<a
href="https://doi.org/10.1093/biomet/asac017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variable importance measures are the main tools used to analyse the black-box mechanisms of random forests. Although the mean decrease accuracy is widely accepted as the most efficient variable importance measure for random forests, little is known about its statistical properties. In fact, the definition of mean decrease accuracy varies across the main random forest software. In this article, our objective is to rigorously analyse the behaviour of the main mean decrease accuracy implementations. Consequently, we mathematically formalize the various implemented mean decrease accuracy algorithms, and then establish their limits when the sample size increases. This asymptotic analysis reveals that these mean decrease accuracy versions differ as importance measures, since they converge towards different quantities. More importantly, we break down these limits into three components: the first two terms are related to Sobol indices, which are well-defined measures of a covariate contribution to the response variance, widely used in the sensitivity analysis field, as opposed to the third term, whose value increases with dependence within covariates. Thus, we theoretically demonstrate that the mean decrease accuracy does not target the right quantity to detect influential covariates in a dependent setting, a fact that has already been noticed experimentally. To address this issue, we define a new importance measure for random forests, the Sobol-mean decrease accuracy, which fixes the flaws of the original mean decrease accuracy, and consistently estimates the accuracy decrease of the forest retrained without a given covariate, but with an efficient computational cost. The Sobol-mean decrease accuracy empirically outperforms its competitors on both simulated and real data for variable selection.},
  archive      = {J_BIOMET},
  author       = {Bénard, Clément and Da Veiga, Sébastien and Scornet, Erwan},
  doi          = {10.1093/biomet/asac017},
  journal      = {Biometrika},
  number       = {4},
  pages        = {881-900},
  shortjournal = {Biometrika},
  title        = {Mean decrease accuracy for random forests: Inconsistency, and a practical solution via the sobol-MDA},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the relative efficiency of the intent-to-treat
wilcoxon–mann–whitney test in the presence of noncompliance.
<em>BIOMET</em>, <em>109</em>(3), 873–880. (<a
href="https://doi.org/10.1093/biomet/asab053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A general framework is set up to study the asymptotic properties of the intent-to-treat Wilcoxon–Mann–Whitney test in randomized experiments with nonignorable noncompliance. Under location-shift alternatives, the Pitman efficiencies of the intent-to-treat Wilcoxon–Mann–Whitney and |$t$| tests are derived. It is shown that the former is superior if the compliers are more likely to be found in high-density regions of the outcome distribution or, equivalently, if the noncompliers tend to reside in the tails. By logical extension, the relative efficiency of the two tests is sharply bounded by least and most favourable scenarios in which the compliers are segregated into regions of lowest and highest density, respectively. Such bounds can be derived analytically as a function of the compliance rate for common location families such as Gaussian, Laplace, logistic and |$t$| distributions. These results can help empirical researchers choose the more efficient test for existing data, and calculate sample size for future trials in anticipation of noncompliance. Results for nonadditive alternatives and other tests follow along similar lines.},
  archive      = {J_BIOMET},
  author       = {Mao, Lu},
  doi          = {10.1093/biomet/asab053},
  journal      = {Biometrika},
  number       = {3},
  pages        = {873-880},
  shortjournal = {Biometrika},
  title        = {On the relative efficiency of the intent-to-treat Wilcoxon–Mann–Whitney test in the presence of noncompliance},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneous coefficients, control variables and
identification of multiple treatment effects. <em>BIOMET</em>,
<em>109</em>(3), 865–872. (<a
href="https://doi.org/10.1093/biomet/asab060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-dimensional heterogeneity and endogeneity are important features of models with multiple treatments. We consider a heterogeneous coefficients model where the outcome is a linear combination of dummy treatment variables, with each variable representing a different kind of treatment. We use control variables to give necessary and sufficient conditions for identification of average treatment effects. With mutually exclusive treatments we find that, provided the heterogeneous coefficients are mean independent from treatments given the controls, a simple identification condition is that the generalized propensity scores ( Imbens, 2000 ) be bounded away from zero and that their sum be bounded away from one, with probability one. Our analysis extends to distributional and quantile treatment effects, as well as corresponding treatment effects on the treated. These results generalize the classical identification result of Rosenbaum &amp; Rubin (1983) for binary treatments.},
  archive      = {J_BIOMET},
  author       = {Newey, W K and Stouli, S},
  doi          = {10.1093/biomet/asab060},
  journal      = {Biometrika},
  number       = {3},
  pages        = {865-872},
  shortjournal = {Biometrika},
  title        = {Heterogeneous coefficients, control variables and identification of multiple treatment effects},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uniqueness and global optimality of the maximum likelihood
estimator for the generalized extreme value distribution.
<em>BIOMET</em>, <em>109</em>(3), 853–864. (<a
href="https://doi.org/10.1093/biomet/asab043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The three-parameter generalized extreme value distribution arises from classical univariate extreme value theory, and is in common use for analysing the far tail of observed phenomena, yet important asymptotic properties of likelihood-based estimation under this standard model have not been established. In this paper we prove that the maximum likelihood estimator is global and unique. An interesting secondary result entails the uniform consistency of a class of limit relations in a tight neighbourhood of the true shape parameter.},
  archive      = {J_BIOMET},
  author       = {Zhang, Likun and Shaby, Benjamin A},
  doi          = {10.1093/biomet/asab043},
  journal      = {Biometrika},
  number       = {3},
  pages        = {853-864},
  shortjournal = {Biometrika},
  title        = {Uniqueness and global optimality of the maximum likelihood estimator for the generalized extreme value distribution},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Wavelet spectra for multivariate point processes.
<em>BIOMET</em>, <em>109</em>(3), 837–851. (<a
href="https://doi.org/10.1093/biomet/asab054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wavelets provide the flexibility for analysing stochastic processes at different scales. In this article we apply them to multivariate point processes as a means of detecting and analysing unknown nonstationarity, both within and across component processes. To provide statistical tractability, a temporally smoothed wavelet periodogram is developed and shown to be equivalent to a multi-wavelet periodogram. Under a stationarity assumption, the distribution of the temporally smoothed wavelet periodogram is demonstrated to be asymptotically Wishart, with the centrality matrix and degrees of freedom readily computable from the multi-wavelet formulation. Distributional results extend to wavelet coherence, a time-scale measure of inter-process correlation. This statistical framework is used to construct a test for stationarity in multivariate point processes. The methods are applied to neural spike-train data, where it is shown to detect and characterize time-varying dependency patterns.},
  archive      = {J_BIOMET},
  author       = {Cohen, E A K and Gibberd, A J},
  doi          = {10.1093/biomet/asab054},
  journal      = {Biometrika},
  number       = {3},
  pages        = {837-851},
  shortjournal = {Biometrika},
  title        = {Wavelet spectra for multivariate point processes},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalized infinite factorization models. <em>BIOMET</em>,
<em>109</em>(3), 817–835. (<a
href="https://doi.org/10.1093/biomet/asab056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factorization models express a statistical object of interest in terms of a collection of simpler objects. For example, a matrix or tensor can be expressed as a sum of rank-one components. In practice, however, it can be challenging to infer the number of components and the relative impact of the different components. A popular idea is to include infinitely many components whose impact decreases with the component index. This article is motivated by two limitations of such existing methods: (i) lack of careful consideration of the within-component sparsity structure; and (ii) not accommodating grouped variables and other nonexchangeable structures. We propose a general class of infinite factorization models that address these limitations. Theoretical support is provided, practical gains are demonstrated in simulation studies, and an ecology application focusing on modelling bird species occurrence is discussed.},
  archive      = {J_BIOMET},
  author       = {Schiavon, L and Canale, A and Dunson, D B},
  doi          = {10.1093/biomet/asab056},
  journal      = {Biometrika},
  number       = {3},
  pages        = {817-835},
  shortjournal = {Biometrika},
  title        = {Generalized infinite factorization models},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Regression-based causal inference with factorial
experiments: Estimands, model specifications and design-based
properties. <em>BIOMET</em>, <em>109</em>(3), 799–815. (<a
href="https://doi.org/10.1093/biomet/asab051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factorial designs are widely used because of their ability to accommodate multiple factors simultaneously. Factor-based regression with main effects and some interactions is the dominant strategy for downstream analysis, delivering point estimators and standard errors simultaneously via one least-squares fit. Justification of these convenient estimators from the design-based perspective requires quantifying their sampling properties under the assignment mechanism while conditioning on the potential outcomes. To this end, we derive the sampling properties of the regression estimators under a wide range of specifications, and establish the appropriateness of the corresponding robust standard errors for Wald-type inference. The results help to clarify the causal interpretation of the coefficients in these factor-based regressions, and motivate the definition of general factorial effects to unify the definitions of factorial effects in various fields. We also quantify the bias-variance trade-off between the saturated and unsaturated regressions from the design-based perspective.},
  archive      = {J_BIOMET},
  author       = {Zhao, Anqi and Ding, Peng},
  doi          = {10.1093/biomet/asab051},
  journal      = {Biometrika},
  number       = {3},
  pages        = {799-815},
  shortjournal = {Biometrika},
  title        = {Regression-based causal inference with factorial experiments: Estimands, model specifications and design-based properties},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymptotic distribution-free changepoint detection for data
with repeated observations. <em>BIOMET</em>, <em>109</em>(3), 783–798.
(<a href="https://doi.org/10.1093/biomet/asab048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A nonparametric framework for changepoint detection, based on scan statistics utilizing graphs that represent similarities among observations, is gaining attention owing to its flexibility and good performance for high-dimensional and non-Euclidean data sequences. However, this graph-based framework faces challenges when there are repeated observations in the sequence, which is often the case for discrete data such as network data. In this article we extend the graph-based framework to solve this problem by averaging or taking the union of all possible optimal graphs resulting from repeated observations. We consider both the single-changepoint alternative and the changed-interval alternative, and derive analytical formulas to control the Type I error for the new methods, making them readily applicable to large datasets. The extended methods are illustrated on an application in detecting changes in a sequence of dynamic networks over time. All proposed methods are implemented in an |$\texttt{R}$| package |$\texttt{gSeg}$| available on CRAN.},
  archive      = {J_BIOMET},
  author       = {Song, Hoseung and Chen, Hao},
  doi          = {10.1093/biomet/asab048},
  journal      = {Biometrika},
  number       = {3},
  pages        = {783-798},
  shortjournal = {Biometrika},
  title        = {Asymptotic distribution-free changepoint detection for data with repeated observations},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Determining the number of factors in high-dimensional
generalized latent factor models. <em>BIOMET</em>, <em>109</em>(3),
769–782. (<a href="https://doi.org/10.1093/biomet/asab044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a generalization of the classical linear factor model, generalized latent factor models are useful for analysing multivariate data of different types, including binary choices and counts. This paper proposes an information criterion to determine the number of factors in generalized latent factor models. The consistency of the proposed information criterion is established under a high-dimensional setting, where both the sample size and the number of manifest variables grow to infinity, and data may have many missing values. An error bound is established for the parameter estimates, which plays an important role in establishing the consistency of the proposed information criterion. This error bound improves several existing results and may be of independent theoretical interest. We evaluate the proposed method by a simulation study and an application to Eysenck’s personality questionnaire.},
  archive      = {J_BIOMET},
  author       = {Chen, Y and Li, X},
  doi          = {10.1093/biomet/asab044},
  journal      = {Biometrika},
  number       = {3},
  pages        = {769-782},
  shortjournal = {Biometrika},
  title        = {Determining the number of factors in high-dimensional generalized latent factor models},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Risk bounds for quantile trend filtering. <em>BIOMET</em>,
<em>109</em>(3), 751–768. (<a
href="https://doi.org/10.1093/biomet/asab045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study quantile trend filtering, a recently proposed method for nonparametric quantile regression, with the goal of generalizing existing risk bounds for the usual trend-filtering estimators that perform mean regression. We study both the penalized and the constrained versions, of order |$r \geqslant 1$|⁠ , of univariate quantile trend filtering. Our results show that both the constrained and the penalized versions of order |$r \geqslant 1$| attain the minimax rate up to logarithmic factors, when the |$(r-1)$| th discrete derivative of the true vector of quantiles belongs to the class of bounded-variation signals. Moreover, we show that if the true vector of quantiles is a discrete spline with a few polynomial pieces, then both versions attain a near-parametric rate of convergence. Corresponding results for the usual trend-filtering estimators are known to hold only when the errors are sub-Gaussian. In contrast, our risk bounds are shown to hold under minimal assumptions on the error variables. In particular, no moment assumptions are needed and our results hold under heavy-tailed errors. Our proof techniques are general, and thus can potentially be used to study other nonparametric quantile regression methods. To illustrate this generality, we employ our proof techniques to obtain new results for multivariate quantile total-variation denoising and high-dimensional quantile linear regression.},
  archive      = {J_BIOMET},
  author       = {Madrid Padilla, Oscar Hernan and Chatterjee, Sabyasachi},
  doi          = {10.1093/biomet/asab045},
  journal      = {Biometrika},
  number       = {3},
  pages        = {751-768},
  shortjournal = {Biometrika},
  title        = {Risk bounds for quantile trend filtering},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lugsail lag windows for estimating time-average covariance
matrices. <em>BIOMET</em>, <em>109</em>(3), 735–750. (<a
href="https://doi.org/10.1093/biomet/asab049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lag windows are commonly used in time series analysis, econometrics, steady-state simulation and Markov chain Monte Carlo to estimate time-average covariance matrices. In the presence of positive correlation in the underlying process, estimators of this matrix almost always exhibit significant negative bias, leading to undesirable finite-sample properties. We propose a new family of lag windows specifically designed to improve finite-sample performance by offsetting this negative bias. Any existing lag window can be adapted into a lugsail equivalent with no additional assumptions. We use these lag windows in spectral variance estimators and demonstrate their advantages in a linear regression model with autocorrelated and heteroskedastic residuals. We further employ the lugsail lag windows in weighted batch means estimators because of their computational efficiency on large simulation output. We obtain bias and variance results for these multivariate estimators and significantly weaken the mixing condition on the process. Superior finite-sample properties are demonstrated in a vector autoregressive process and a Bayesian logistic regression model.},
  archive      = {J_BIOMET},
  author       = {Vats, D and Flegal, J M},
  doi          = {10.1093/biomet/asab049},
  journal      = {Biometrika},
  number       = {3},
  pages        = {735-750},
  shortjournal = {Biometrika},
  title        = {Lugsail lag windows for estimating time-average covariance matrices},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local linear graphon estimation using covariates.
<em>BIOMET</em>, <em>109</em>(3), 721–734. (<a
href="https://doi.org/10.1093/biomet/asab057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider local linear estimation of the graphon function, which determines probabilities of pairwise edges between nodes in an unlabelled network. Real-world networks are typically characterized by node heterogeneity, with different nodes exhibiting different degrees of interaction. Existing approaches to graphon estimation are limited to local constant approximations, and are not designed to estimate heterogeneity across the full network. In this paper, we show how continuous node covariates can be employed to estimate heterogeneity in the network via a local linear graphon estimator. We derive the bias and variance of an oracle-based local linear graphon estimator, and thus obtain the mean integrated squared error optimal bandwidth rule. We also provide a plug-in bandwidth selection procedure that makes local linear estimation for unlabelled networks practically feasible. The finite-sample performance of our approach is investigated in a simulation study, and the method is applied to a school friendship network and an email network to illustrate its advantages over existing methods.},
  archive      = {J_BIOMET},
  author       = {Chandna, S and Olhede, S C and Wolfe, P J},
  doi          = {10.1093/biomet/asab057},
  journal      = {Biometrika},
  number       = {3},
  pages        = {721-734},
  shortjournal = {Biometrika},
  title        = {Local linear graphon estimation using covariates},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint latent space models for network data with
high-dimensional node variables. <em>BIOMET</em>, <em>109</em>(3),
707–720. (<a href="https://doi.org/10.1093/biomet/asab063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network latent space models assume that each node is associated with an unobserved latent position in a Euclidean , and such latent variables determine the probability of two nodes connecting with each other. In many applications, nodes in the network are often observed along with high-dimensional node variables, and these node variables provide important information for understanding the network structure. However, classical network latent space models have several limitations in incorporating node variables. In this paper, we propose a joint latent space model where we assume that the latent variables not only explain the network structure, but are also informative for the multivariate node variables. We develop a projected gradient descent algorithm that estimates the latent positions using a criterion incorporating both network structure and node variables. We establish theoretical properties of the estimators and provide insights into how incorporating high-dimensional node variables could improve the estimation accuracy of the latent positions. We demonstrate the improvement in latent variable estimation and the improvements in associated downstream tasks, such as missing value imputation for node variables, by simulation studies and an application to a Facebook data example.},
  archive      = {J_BIOMET},
  author       = {Zhang, Xuefei and Xu, Gongjun and Zhu, Ji},
  doi          = {10.1093/biomet/asab063},
  journal      = {Biometrika},
  number       = {3},
  pages        = {707-720},
  shortjournal = {Biometrika},
  title        = {Joint latent space models for network data with high-dimensional node variables},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Latent space models for multiplex networks with shared
structure. <em>BIOMET</em>, <em>109</em>(3), 683–706. (<a
href="https://doi.org/10.1093/biomet/asab058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Latent space models are frequently used for modelling single-layer networks and include many popular special cases, such as the stochastic block model and the random dot product graph. However, they are not well developed for more complex network structures, which are becoming increasingly common in practice. In this article we propose a new latent space model for multiplex networks, i.e., multiple heterogeneous networks observed on a shared node set. Multiplex networks can represent a network sample with shared node labels, a network evolving over time, or a network with multiple types of edges. The key feature of the proposed model is that it learns from data how much of the network structure is shared between layers and pools information across layers as appropriate. We establish identifiability, develop a fitting procedure using convex optimization in combination with a nuclear-norm penalty, and prove a guarantee of recovery for the latent positions provided there is sufficient separation between the shared and the individual latent subspaces. We compare the model with competing methods in the literature on simulated networks and on a multiplex network describing the worldwide trade of agricultural products.},
  archive      = {J_BIOMET},
  author       = {MacDonald, P W and Levina, E and Zhu, J},
  doi          = {10.1093/biomet/asab058},
  journal      = {Biometrika},
  number       = {3},
  pages        = {683-706},
  shortjournal = {Biometrika},
  title        = {Latent space models for multiplex networks with shared structure},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Partial separability and functional graphical models for
multivariate gaussian processes. <em>BIOMET</em>, <em>109</em>(3),
665–681. (<a href="https://doi.org/10.1093/biomet/asab046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The covariance structure of multivariate functional data can be highly complex, especially if the multivariate dimension is large, making extensions of statistical methods for standard multivariate data to the functional data setting challenging. For example, Gaussian graphical models have recently been extended to the setting of multivariate functional data by applying multivariate methods to the coefficients of truncated basis expansions. However, compared with multivariate data, a key difficulty is that the covariance operator is compact and thus not invertible. This paper addresses the general problem of covariance modelling for multivariate functional data, and functional Gaussian graphical models in particular. As a first step, a new notion of separability for the covariance operator of multivariate functional data is proposed, termed partial separability, leading to a novel Karhunen–Loève-type expansion for such data. Next, the partial separability structure is shown to be particularly useful in providing a well-defined functional Gaussian graphical model that can be identified with a sequence of finite-dimensional graphical models, each of identical fixed dimension. This motivates a simple and efficient estimation procedure through application of the joint graphical lasso. Empirical performance of the proposed method for graphical model estimation is assessed through simulation and analysis of functional brain connectivity during a motor task.},
  archive      = {J_BIOMET},
  author       = {Zapata, J and Oh, S Y and Petersen, A},
  doi          = {10.1093/biomet/asab046},
  journal      = {Biometrika},
  number       = {3},
  pages        = {665-681},
  shortjournal = {Biometrika},
  title        = {Partial separability and functional graphical models for multivariate gaussian processes},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Valid sequential inference on probability forecast
performance. <em>BIOMET</em>, <em>109</em>(3), 647–663. (<a
href="https://doi.org/10.1093/biomet/asab047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probability forecasts for binary events play a central role in many applications. Their quality is commonly assessed with proper scoring rules, which assign forecasts numerical scores such that a correct forecast achieves a minimal expected score. In this paper, we construct e-values for testing the statistical significance of score differences of competing forecasts in sequential settings. E-values have been proposed as an alternative to |$p$| -values for hypothesis testing, and they can easily be transformed into conservative |$p$| -values by taking the multiplicative inverse. The e-values proposed in this article are valid in finite samples without any assumptions on the data-generating processes. They also allow optional stopping, so a forecast user may decide to interrupt evaluation, taking into account the available data at any time, and still draw statistically valid inference, which is generally not true for classical |$p$| -value-based tests. In a case study on post-processing of precipitation forecasts, state-of-the-art forecast dominance tests and e-values lead to the same conclusions.},
  archive      = {J_BIOMET},
  author       = {Henzi, Alexander and Ziegel, Johanna F},
  doi          = {10.1093/biomet/asab047},
  journal      = {Biometrika},
  number       = {3},
  pages        = {647-663},
  shortjournal = {Biometrika},
  title        = {Valid sequential inference on probability forecast performance},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A high-dimensional power analysis of the conditional
randomization test and knockoffs. <em>BIOMET</em>, <em>109</em>(3),
631–645. (<a href="https://doi.org/10.1093/biomet/asab052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many scientific applications, researchers aim to relate a response variable |$Y$| to a set of potential explanatory variables |$X = (X_1,\dots,X_p)$|⁠ , and start by trying to identify variables that contribute to this relationship. In statistical terms, this goal can be understood as trying to identify those |$X_j$| on which |$Y$| is conditionally dependent. Sometimes it is of value to simultaneously test for each |$j$|⁠ , which is more commonly known as variable selection. The conditional randomization test, CRT, and model-X knockoffs are two recently proposed methods that respectively perform conditional independence testing and variable selection by computing, for each |$X_j$|⁠ , any test statistic on the data and assessing that test statistic’s significance, by comparing it with test statistics computed on synthetic variables generated using knowledge of the distribution of |$X$|⁠ . The main contribution of this article is the analysis of the power of these methods in a high-dimensional linear model, where the ratio of the dimension |$p$| to the sample size |$n$| converges to a positive constant. We give explicit expressions for the asymptotic power of the CRT, variable selection with CRT |$p$| -values, and model-X knockoffs, each with a test statistic based on the marginal covariance, the least squares coefficient or the lasso. One useful application of our analysis is direct theoretical comparison of the asymptotic powers of variable selection with CRT |$p$| -values and model-X knockoffs; in the instances with independent covariates that we consider, the CRT probably dominates knockoffs. We also analyse the power gain from using unlabelled data in the CRT when limited knowledge of the distribution of |$X$| is available, as well as the power of the CRT when samples are collected retrospectively.},
  archive      = {J_BIOMET},
  author       = {Wang, Wenshuo and Janson, Lucas},
  doi          = {10.1093/biomet/asab052},
  journal      = {Biometrika},
  number       = {3},
  pages        = {631-645},
  shortjournal = {Biometrika},
  title        = {A high-dimensional power analysis of the conditional randomization test and knockoffs},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Searching for robust associations with a multi-environment
knockoff filter. <em>BIOMET</em>, <em>109</em>(3), 611–629. (<a
href="https://doi.org/10.1093/biomet/asab055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we develop a method based on model-X knockoffs to find conditional associations that are consistent across environments, while controlling the false discovery rate. The motivation for this problem is that large datasets may contain numerous associations that are statistically significant and yet misleading, as they are induced by confounders or sampling imperfections. However, associations replicated under different conditions may be more interesting. In fact, sometimes consistency provably leads to valid causal inferences even if conditional associations do not. Although the proposed method is widely applicable, in this paper we highlight its relevance to genome-wide association studies, in which robustness across populations with diverse ancestries mitigates confounding due to unmeasured variants. The effectiveness of this approach is demonstrated by simulations and applications to UK Biobank data.},
  archive      = {J_BIOMET},
  author       = {Li, S and Sesia, M and Romano, Y and Candès, E and Sabatti, C},
  doi          = {10.1093/biomet/asab055},
  journal      = {Biometrika},
  number       = {3},
  pages        = {611-629},
  shortjournal = {Biometrika},
  title        = {Searching for robust associations with a multi-environment knockoff filter},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Rejoinder: “Multi-scale fisher’s independence test for
multivariate dependence.” <em>BIOMET</em>, <em>109</em>(3), 605–609. (<a
href="https://doi.org/10.1093/biomet/asac034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIOMET},
  author       = {Gorsky, S and Ma, L},
  doi          = {10.1093/biomet/asac034},
  journal      = {Biometrika},
  number       = {3},
  pages        = {605-609},
  shortjournal = {Biometrika},
  title        = {Rejoinder: ‘Multi-scale fisher’s independence test for multivariate dependence’},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discussion of “multi-scale fisher’s independence test for
multivariate dependence.” <em>BIOMET</em>, <em>109</em>(3), 597–603. (<a
href="https://doi.org/10.1093/biomet/asac028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIOMET},
  author       = {Schrab, A and Jitkrittum, W and Szabó, Z and Sejdinovic, D and Gretton, A},
  doi          = {10.1093/biomet/asac028},
  journal      = {Biometrika},
  number       = {3},
  pages        = {597-603},
  shortjournal = {Biometrika},
  title        = {Discussion of ‘Multi-scale fisher’s independence test for multivariate dependence’},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discussion of “multi-scale fisher’s independence test for
multivariate dependence.” <em>BIOMET</em>, <em>109</em>(3), 593–596. (<a
href="https://doi.org/10.1093/biomet/asac025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIOMET},
  author       = {Lee, D and El-Zaatari, H and Kosorok, M R and Li, X and Zhang, K},
  doi          = {10.1093/biomet/asac025},
  journal      = {Biometrika},
  number       = {3},
  pages        = {593-596},
  shortjournal = {Biometrika},
  title        = {Discussion of ‘Multi-scale fisher’s independence test for multivariate dependence’},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discussion of “multi-scale fisher’s independence test for
multivariate dependence.” <em>BIOMET</em>, <em>109</em>(3), 589–592. (<a
href="https://doi.org/10.1093/biomet/asac023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIOMET},
  author       = {Berrett, T B},
  doi          = {10.1093/biomet/asac023},
  journal      = {Biometrika},
  number       = {3},
  pages        = {589-592},
  shortjournal = {Biometrika},
  title        = {Discussion of ‘Multi-scale fisher’s independence test for multivariate dependence’},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Multi-scale fisher’s independence test for multivariate
dependence. <em>BIOMET</em>, <em>109</em>(3), 569–587. (<a
href="https://doi.org/10.1093/biomet/asac013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying dependency in multivariate data is a common inference task that arises in numerous applications. However, existing nonparametric independence tests typically require computation that scales at least quadratically with the sample size, making it difficult to apply them in the presence of massive sample sizes. Moreover, resampling is usually necessary to evaluate the statistical significance of the resulting test statistics at finite sample sizes, further worsening the computational burden. We introduce a scalable, resampling-free approach to testing the independence between two random vectors by breaking down the task into simple univariate tests of independence on a collection of |$2\times 2$| contingency tables constructed through sequential coarse-to-fine discretization of the sample , transforming the inference task into a multiple testing problem that can be completed with almost linear complexity with respect to the sample size. To address increasing dimensionality, we introduce a coarse-to-fine sequential adaptive procedure that exploits the spatial features of dependency structures. We derive a finite-sample theory that guarantees the inferential validity of our adaptive procedure at any given sample size. We show that our approach can achieve strong control of the level of the testing procedure at any sample size without resampling or asymptotic approximation and establish its large-sample consistency. We demonstrate through an extensive simulation study its substantial computational advantage in comparison to existing approaches while achieving robust statistical power under various dependency scenarios, and illustrate how its divide-and-conquer nature can be exploited to not just test independence, but to learn the nature of the underlying dependency. Finally, we demonstrate the use of our method through analysing a dataset from a flow cytometry experiment.},
  archive      = {J_BIOMET},
  author       = {Gorsky, S and Ma, L},
  doi          = {10.1093/biomet/asac013},
  journal      = {Biometrika},
  number       = {3},
  pages        = {569-587},
  shortjournal = {Biometrika},
  title        = {Multi-scale fisher’s independence test for multivariate dependence},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Erratum. <em>BIOMET</em>, <em>109</em>(2), 567. (<a
href="https://doi.org/10.1093/biomet/asac001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIOMET},
  doi          = {10.1093/biomet/asac001},
  journal      = {Biometrika},
  number       = {2},
  pages        = {567},
  shortjournal = {Biometrika},
  title        = {Erratum},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiplicative effect modelling: The general case.
<em>BIOMET</em>, <em>109</em>(2), 559–566. (<a
href="https://doi.org/10.1093/biomet/asab064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized linear models, such as logistic regression, are widely used to model the association between a treatment and a binary outcome as a function of baseline covariates. However, the coefficients of a logistic regression model correspond to log odds ratios, while subject-matter scientists are often interested in relative risks. Although odds ratios are sometimes used to approximate relative risks, this approximation is appropriate only when the outcome of interest is rare for all levels of the covariates. Poisson regressions do measure multiplicative treatment effects including relative risks, but with a binary outcome not all combinations of parameters lead to fitted means that are between zero and one. Enforcing this constraint makes the parameters variation dependent, which is undesirable for modelling, estimation and computation. Focusing on the special case where the treatment is also binary, Richardson et al. (2017) proposed a novel binomial regression model that allows direct modelling of the relative risk. The model uses a log odds product nuisance model leading to variation-independent parameter spaces. Building on this we present general approaches to modelling the multiplicative effect of a continuous or categorical treatment on a binary outcome. Monte Carlo simulations demonstrate the desirable performance of our proposed methods. An analysis of the relationship between passenger class and survival for passengers on the Titanic further exemplifies our methods.},
  archive      = {J_BIOMET},
  author       = {Yin, J and Markes, S and Richardson, T S and Wang, L},
  doi          = {10.1093/biomet/asab064},
  journal      = {Biometrika},
  number       = {2},
  pages        = {559-566},
  shortjournal = {Biometrika},
  title        = {Multiplicative effect modelling: The general case},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the inconsistency of matching without replacement.
<em>BIOMET</em>, <em>109</em>(2), 551–558. (<a
href="https://doi.org/10.1093/biomet/asab035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper shows that matching without replacement on propensity scores produces estimators that generally are inconsistent for the average treatment effect of the treated. To achieve consistency, practitioners must either assume that no units exist with propensity scores greater than 1/2 or assume that there is no confounding among such units. The result is not driven by the use of propensity scores, and similar artifacts arise when matching on other scores as long as it is without replacement.},
  archive      = {J_BIOMET},
  author       = {Sävje, F},
  doi          = {10.1093/biomet/asab035},
  journal      = {Biometrika},
  number       = {2},
  pages        = {551-558},
  shortjournal = {Biometrika},
  title        = {On the inconsistency of matching without replacement},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing for unit roots based on sample autocovariances.
<em>BIOMET</em>, <em>109</em>(2), 543–550. (<a
href="https://doi.org/10.1093/biomet/asab034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new unit-root test for a stationary null hypothesis |$H_0$| against a unit-root alternative |$H_1$|⁠ . Our approach is nonparametric as |$H_0$| assumes only that the process concerned is |$I(0)$|⁠ , without specifying any parametric forms. The new test is based on the fact that the sample autocovariance function converges to the finite population autocovariance function for an |$I(0)$| process, but diverges to infinity for a process with unit roots. Therefore, the new test rejects |$H_0$| for large values of the sample autocovariance function. To address the technical question of how large is large, we split the sample and establish an appropriate normal approximation for the null distribution of the test statistic. The substantial discriminative power of the new test statistic is due to the fact that it takes finite values under |$H_0$| and diverges to infinity under |$H_1$|⁠ . This property allows one to truncate the critical values of the test so that it has asymptotic power 1; it also alleviates the loss of power due to the sample-splitting. The test is implemented in |$\texttt{R}$|⁠ .},
  archive      = {J_BIOMET},
  author       = {Chang, Jinyuan and Cheng, Guanghui and Yao, Qiwei},
  doi          = {10.1093/biomet/asab034},
  journal      = {Biometrika},
  number       = {2},
  pages        = {543-550},
  shortjournal = {Biometrika},
  title        = {Testing for unit roots based on sample autocovariances},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inverses of matérn covariances on grids. <em>BIOMET</em>,
<em>109</em>(2), 535–541. (<a
href="https://doi.org/10.1093/biomet/asab017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We conduct a study of the aliased spectral densities of Matérn covariance functions on a regular grid of points, elucidating the properties of a popular approximation based on stochastic partial differential equations. While other researchers have shown that this approximation can work well for the covariance function, we find that it assigns too much power at high frequencies and does not provide increasingly accurate approximations to the inverse as the grid spacing goes to zero, except in the one-dimensional exponential covariance case.},
  archive      = {J_BIOMET},
  author       = {Guinness, Joseph},
  doi          = {10.1093/biomet/asab017},
  journal      = {Biometrika},
  number       = {2},
  pages        = {535-541},
  shortjournal = {Biometrika},
  title        = {Inverses of matérn covariances on grids},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymptotics of sample tail autocorrelations for
tail-dependent time series: Phase transition and visualization.
<em>BIOMET</em>, <em>109</em>(2), 521–534. (<a
href="https://doi.org/10.1093/biomet/asab038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we develop an asymptotic theory for sample tail autocorrelations of time series data that can exhibit serial dependence in both tail and non-tail regions. Unlike with the traditional autocorrelation function, the study of tail autocorrelations requires a double asymptotic scheme to capture the tail phenomena, and our results do not impose any restrictions on the dependence structure in non-tail regions and allow processes that are not necessarily strongly mixing. The newly developed asymptotic theory reveals a previously undiscovered phase transition phenomenon, where the asymptotic behaviour of sample tail autocorrelations, including their convergence rate, can transition from one phase to another as the lag index moves past the point beyond which serial tail dependence vanishes. The phase transition discovery fills a gap in existing research on tail autocorrelations and can be used to construct the lines of significance, in analogy to the traditional autocorrelation plot, when visualizing sample tail autocorrelations to assess the existence of serial tail dependence or to identify the maximal lag of tail dependence.},
  archive      = {J_BIOMET},
  author       = {Zhang, Ting},
  doi          = {10.1093/biomet/asab038},
  journal      = {Biometrika},
  number       = {2},
  pages        = {521-534},
  shortjournal = {Biometrika},
  title        = {Asymptotics of sample tail autocorrelations for tail-dependent time series: Phase transition and visualization},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation under matrix quadratic loss and matrix
superharmonicity. <em>BIOMET</em>, <em>109</em>(2), 503–519. (<a
href="https://doi.org/10.1093/biomet/asab025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate estimation of a normal mean matrix under the matrix quadratic loss. Improved estimation under the matrix quadratic loss implies improved estimation of any linear combination of the columns under the quadratic loss. First, an unbiased estimate of risk is derived and the Efron–Morris estimator is shown to be minimax. Next, a notion of matrix superharmonicity for matrix-variate functions is introduced and shown to have properties analogous to those of the usual superharmonic functions, which may be of independent interest. Then, it is shown that the generalized Bayes estimator with respect to a matrix superharmonic prior is minimax. We also provide a class of matrix superharmonic priors that includes the previously proposed generalization of Stein’s prior. Numerical results demonstrate that matrix superharmonic priors work well for low-rank matrices.},
  archive      = {J_BIOMET},
  author       = {Matsuda, T and Strawderman, W E},
  doi          = {10.1093/biomet/asab025},
  journal      = {Biometrika},
  number       = {2},
  pages        = {503-519},
  shortjournal = {Biometrika},
  title        = {Estimation under matrix quadratic loss and matrix superharmonicity},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A minimum aberration-type criterion for selecting
space-filling designs. <em>BIOMET</em>, <em>109</em>(2), 489–501. (<a
href="https://doi.org/10.1093/biomet/asab021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space-filling designs are widely used in computer experiments. Inspired by the stratified orthogonality of strong orthogonal arrays, we propose a criterion of minimum aberration-type for assessing the space-filling properties of designs based on design stratification properties on various grids. A space-filling hierarchy principle is proposed as a basic assumption of the criterion. The new criterion provides a systematic way of classifying and ranking space-filling designs, including various types of strong orthogonal arrays and Latin hypercube designs. Theoretical results and examples are presented to show that strong orthogonal arrays of maximum strength are favourable under the proposed criterion. For strong orthogonal arrays of the same strength, the space-filling criterion can further rank them based on their space-filling patterns.},
  archive      = {J_BIOMET},
  author       = {Tian, Ye and Xu, Hongquan},
  doi          = {10.1093/biomet/asab021},
  journal      = {Biometrika},
  number       = {2},
  pages        = {489-501},
  shortjournal = {Biometrika},
  title        = {A minimum aberration-type criterion for selecting space-filling designs},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inverse moment methods for sufficient forecasting using
high-dimensional predictors. <em>BIOMET</em>, <em>109</em>(2), 473–487.
(<a href="https://doi.org/10.1093/biomet/asab037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider forecasting a single time series using a large number of predictors in the presence of a possible nonlinear forecast function. Assuming that the predictors affect the response through the latent factors, we propose to first conduct factor analysis and then apply sufficient dimension reduction on the estimated factors to derive the reduced data for subsequent forecasting. Using directional regression and the inverse third-moment method in the stage of sufficient dimension reduction, the proposed methods can capture the nonmonotone effect of factors on the response. We also allow a diverging number of factors and only impose general regularity conditions on the distribution of factors, avoiding the undesired time reversibility of the factors by the latter. These make the proposed methods fundamentally more applicable than the sufficient forecasting method of Fan et al. (2017) . The proposed methods are demonstrated both in simulation studies and an empirical study of forecasting monthly macroeconomic data from 1959 to 2016. Also, our theory contributes to the literature of sufficient dimension reduction, as it includes an invariance result, a path to perform sufficient dimension reduction under the high-dimensional setting without assuming sparsity, and the corresponding order-determination procedure.},
  archive      = {J_BIOMET},
  author       = {Luo, Wei and Xue, Lingzhou and Yao, Jiawei and Yu, Xiufan},
  doi          = {10.1093/biomet/asab037},
  journal      = {Biometrika},
  number       = {2},
  pages        = {473-487},
  shortjournal = {Biometrika},
  title        = {Inverse moment methods for sufficient forecasting using high-dimensional predictors},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Smoothed nested testing on directed acyclic graphs.
<em>BIOMET</em>, <em>109</em>(2), 457–471. (<a
href="https://doi.org/10.1093/biomet/asab041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of multiple hypothesis testing when there is a logical nested structure to the hypotheses. When one hypothesis is nested inside another, the outer hypothesis must be false if the inner hypothesis is false. We model the nested structure as a directed acyclic graph, including chain and tree graphs as special cases. Each node in the graph is a hypothesis and rejecting a node requires also rejecting all of its ancestors. We propose a general framework for adjusting node-level test statistics using the known logical constraints. Within this framework, we study a smoothing procedure that combines each node with all of its descendants to form a more powerful statistic. We prove that a broad class of smoothing strategies can be used with existing selection procedures to control the familywise error rate, false discovery exceedance rate, or false discovery rate, so long as the original test statistics are independent under the null. When the null statistics are not independent, but are derived from positively correlated normal observations, we prove control for all three error rates when the smoothing method is an arithmetic averaging of the observations. Simulations and an application to a real biology dataset demonstrate that smoothing leads to substantial power gains.},
  archive      = {J_BIOMET},
  author       = {Loper, J H and Lei, L and Fithian, W and Tansey, W},
  doi          = {10.1093/biomet/asab041},
  journal      = {Biometrika},
  number       = {2},
  pages        = {457-471},
  shortjournal = {Biometrika},
  title        = {Smoothed nested testing on directed acyclic graphs},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scalar-on-function local linear regression and beyond.
<em>BIOMET</em>, <em>109</em>(2), 439–455. (<a
href="https://doi.org/10.1093/biomet/asab027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is common to want to regress a scalar response on a random function. This paper presents results that advocate local linear regression based on a projection as a nonparametric approach to this problem. Our asymptotic results demonstrate that functional local linear regression outperforms its functional local constant counterpart. Beyond the estimation of the regression operator itself, local linear regression is also a useful tool for predicting the functional derivative of the regression operator, a promising mathematical object in its own right. The local linear estimator of the functional derivative is shown to be consistent. For both the estimator of the regression functional and the estimator of its derivative, theoretical properties are detailed. On simulated datasets we illustrate good finite-sample properties of the proposed methods. On a real data example of a single-functional index model, we indicate how the functional derivative of the regression operator provides an original, fast and widely applicable estimation method.},
  archive      = {J_BIOMET},
  author       = {Ferraty, F and NAGY, S},
  doi          = {10.1093/biomet/asab027},
  journal      = {Biometrika},
  number       = {2},
  pages        = {439-455},
  shortjournal = {Biometrika},
  title        = {Scalar-on-function local linear regression and beyond},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of genetic correlation with summary association
statistics. <em>BIOMET</em>, <em>109</em>(2), 421–438. (<a
href="https://doi.org/10.1093/biomet/asab030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genome-wide association studies have identified thousands of genetic variants that are associated with complex traits. Many complex traits are shown to share genetic etiology. Although various genetic correlation measures and their estimators have been developed, rigorous statistical analysis of their properties, including their robustness to model assumptions, is still lacking. We develop a method of moments estimator of genetic correlation between two traits in the framework of high-dimensional linear models. We show that the genetic correlation defined based on the regression coefficients and the linkage disequilibrium matrix can be decomposed into both the pleiotropic effects and correlations due to linkage disequilibrium between the causal loci of the two traits. The proposed estimator can be computed from summary association statistics when the raw genotype data are not available. Theoretical properties of the estimator in terms of consistency and asymptotic normality are provided. The proposed estimator is closely related to the estimator from the linkage disequilibrium score regression. However, our analysis reveals that the linkage disequilibrium score regression method does not make full use of the linkage disequilibrium information, and its jackknife variance estimate can be biased when the model assumptions are violated. Simulations and real data analysis results show that the proposed estimator is more robust and has better interpretability than the linkage disequilibrium score regression method under different genetic architectures.},
  archive      = {J_BIOMET},
  author       = {Wang, Jianqiao and Li, Hongzhe},
  doi          = {10.1093/biomet/asab030},
  journal      = {Biometrika},
  number       = {2},
  pages        = {421-438},
  shortjournal = {Biometrika},
  title        = {Estimation of genetic correlation with summary association statistics},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-dimensional log-error-in-variable regression with
applications to microbial compositional data analysis. <em>BIOMET</em>,
<em>109</em>(2), 405–420. (<a
href="https://doi.org/10.1093/biomet/asab020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In microbiome and genomic studies, the regression of compositional data has been a crucial tool for identifying microbial taxa or genes that are associated with clinical phenotypes. To account for the variation in sequencing depth, the classic log-contrast model is often used where read counts are normalized into compositions. However, zero read counts and the randomness in covariates remain critical issues. We introduce a surprisingly simple, interpretable and efficient method for the estimation of compositional data regression through the lens of a novel high-dimensional log-error-in-variable regression model. The proposed method provides corrections on sequencing data with possible overdispersion and simultaneously avoids any subjective imputation of zero read counts. We provide theoretical justifications with matching upper and lower bounds for the estimation error. The merit of the procedure is illustrated through real data analysis and simulation studies.},
  archive      = {J_BIOMET},
  author       = {Shi, Pixu and Zhou, Yuchen and Zhang, Anru R},
  doi          = {10.1093/biomet/asab020},
  journal      = {Biometrika},
  number       = {2},
  pages        = {405-420},
  shortjournal = {Biometrika},
  title        = {High-dimensional log-error-in-variable regression with applications to microbial compositional data analysis},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-dimensional semi-supervised learning: In search of
optimal inference of the mean. <em>BIOMET</em>, <em>109</em>(2),
387–403. (<a href="https://doi.org/10.1093/biomet/asab042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fundamental challenge in semi-supervised learning lies in the observed data’s disproportional size when compared with the size of the data collected with missing outcomes. An implicit understanding is that the dataset with missing outcomes, being significantly larger, ought to improve estimation and inference. However, it is unclear to what extent this is correct. We illustrate one clear benefit: root- |$n$| inference of the outcome’s mean is possible while only requiring a consistent estimation of the outcome, possibly at a rate slower than root |$n$|⁠ . This is achieved by a novel |$k$| -fold, cross-fitted, double robust estimator. We discuss both linear and nonlinear outcomes. Such an estimator is particularly suited for models that naturally do not admit root- |$n$| consistency, such as high-dimensional, nonparametric or semiparametric models. We apply our methods to estimating heterogeneous treatment effects.},
  archive      = {J_BIOMET},
  author       = {Zhang, Yuqian and Bradic, Jelena},
  doi          = {10.1093/biomet/asab042},
  journal      = {Biometrika},
  number       = {2},
  pages        = {387-403},
  shortjournal = {Biometrika},
  title        = {High-dimensional semi-supervised learning: In search of optimal inference of the mean},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-exact control functionals from sard’s method.
<em>BIOMET</em>, <em>109</em>(2), 351–367. (<a
href="https://doi.org/10.1093/biomet/asab036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel control variate technique is proposed for the post-processing of Markov chain Monte Carlo output, based on both Stein’s method and an approach to numerical integration due to Sard. The resulting estimators of posterior expected quantities of interest are proven to be polynomially exact in the Gaussian context, while empirical results suggest that the estimators approximate a Gaussian cubature method near the Bernstein–von Mises limit. The main theoretical result establishes a bias-correction property in settings where the Markov chain does not leave the posterior invariant. Empirical results across a selection of Bayesian inference tasks are presented.},
  archive      = {J_BIOMET},
  author       = {South, L F and Karvonen, T and Nemeth, C and Girolami, M and Oates, C J},
  doi          = {10.1093/biomet/asab036},
  journal      = {Biometrika},
  number       = {2},
  pages        = {351-367},
  shortjournal = {Biometrika},
  title        = {Semi-exact control functionals from sard’s method},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A discrete bouncy particle sampler. <em>BIOMET</em>,
<em>109</em>(2), 335–349. (<a
href="https://doi.org/10.1093/biomet/asab013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most Markov chain Monte Carlo methods operate in discrete time and are reversible with respect to the target probability. Nevertheless, it is now understood that the use of nonreversible Markov chains can be beneficial in many contexts. In particular, the recently proposed bouncy particle sampler leverages a continuous-time and nonreversible Markov process, and empirically shows state-of-the-art performance when used to explore certain probability densities; however, its implementation typically requires the computation of local upper bounds on the gradient of the log target density. We present the discrete bouncy particle sampler, a general algorithm based on a guided random walk, a partial refreshment of direction and a delayed-rejection step. We show that the bouncy particle sampler can be understood as a scaling limit of a special case of our algorithm. In contrast to the bouncy particle sampler, implementing the discrete bouncy particle sampler only requires pointwise evaluation of the target density and its gradient. We propose extensions of the basic algorithm for situations when the exact gradient of the target density is not available. In a Gaussian setting, we establish a scaling limit for the radial process as the dimension increases to infinity. We leverage this result to obtain the theoretical efficiency of the discrete bouncy particle sampler as a function of the partial-refreshment parameter, which leads to a simple and robust tuning criterion. A further analysis in a more general setting suggests that this tuning criterion applies more generally. Theoretical and empirical efficiency curves are then compared for different targets and algorithm variations.},
  archive      = {J_BIOMET},
  author       = {Sherlock, C and Thiery, A H},
  doi          = {10.1093/biomet/asab013},
  journal      = {Biometrika},
  number       = {2},
  pages        = {335-349},
  shortjournal = {Biometrika},
  title        = {A discrete bouncy particle sampler},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the power of chatterjee’s rank correlation.
<em>BIOMET</em>, <em>109</em>(2), 317–333. (<a
href="https://doi.org/10.1093/biomet/asab028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chatterjee (2021) introduced a simple new rank correlation coefficient that has attracted much attention recently. The coefficient has the unusual appeal that it not only estimates a population quantity first proposed by Dette et al. (2013) that is zero if and only if the underlying pair of random variables is independent, but also is asymptotically normal under independence. This paper compares Chatterjee’s new correlation coefficient with three established rank correlations that also facilitate consistent tests of independence, namely Hoeffding’s |$D$|⁠ , Blum–Kiefer–Rosenblatt’s |$R$|⁠ , and Bergsma–Dassios–Yanagimoto’s |$\tau^*$|⁠ . We compare the computational efficiency of these rank correlation coefficients in light of recent advances, and investigate their power against local rotation and mixture alternatives. Our main results show that Chatterjee’s coefficient is unfortunately rate-suboptimal compared to |$D$|⁠ , |$R$| and |$\tau^*$|⁠ . The situation is more subtle for a related earlier estimator of Dette et al. (2013) . These results favour |$D$|⁠ , |$R$| and |$\tau^*$| over Chatterjee’s new correlation coefficient for the purpose of testing independence.},
  archive      = {J_BIOMET},
  author       = {Shi, H and Drton, M and Han, F},
  doi          = {10.1093/biomet/asab028},
  journal      = {Biometrika},
  number       = {2},
  pages        = {317-333},
  shortjournal = {Biometrika},
  title        = {On the power of chatterjee’s rank correlation},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Confidence regions in wasserstein distributionally robust
estimation. <em>BIOMET</em>, <em>109</em>(2), 295–315. (<a
href="https://doi.org/10.1093/biomet/asab026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimators based on Wasserstein distributionally robust optimization are obtained as solutions of min-max problems in which the statistician selects a parameter minimizing the worst-case loss among all probability models within a certain distance from the underlying empirical measure in a Wasserstein sense. While motivated by the need to identify optimal model parameters or decision choices that are robust to model misspecification, these distributionally robust estimators recover a wide range of regularized estimators, including square-root lasso and support vector machines, among others. This paper studies the asymptotic normality of these distributionally robust estimators as well as the properties of an optimal confidence region induced by the Wasserstein distributionally robust optimization formulation. In addition, key properties of min-max distributionally robust optimization problems are also studied; for example, we show that distributionally robust estimators regularize the loss based on its derivative, and we also derive general sufficient conditions which show the equivalence between the min-max distributionally robust optimization problem and the corresponding max-min formulation.},
  archive      = {J_BIOMET},
  author       = {Blanchet, Jose and Murthy, Karthyek and Si, Nian},
  doi          = {10.1093/biomet/asab026},
  journal      = {Biometrika},
  number       = {2},
  pages        = {295-315},
  shortjournal = {Biometrika},
  title        = {Confidence regions in wasserstein distributionally robust estimation},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast and powerful conditional randomization testing via
distillation. <em>BIOMET</em>, <em>109</em>(2), 277–293. (<a
href="https://doi.org/10.1093/biomet/asab039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of conditional independence testing: given a response |$Y$| and covariates |$(X,Z)$|⁠ , we test the null hypothesis that |$Y {\perp\!\!\!\perp} X \mid Z$|⁠ . The conditional randomization test was recently proposed as a way to use distributional information about |$X\mid Z$| to exactly and nonasymptotically control Type-I error using any test statistic in any dimensionality without assuming anything about |$Y\mid (X,Z)$|⁠ . This flexibility, in principle, allows one to derive powerful test statistics from complex prediction algorithms while maintaining statistical validity. Yet the direct use of such advanced test statistics in the conditional randomization test is prohibitively computationally expensive, especially with multiple testing, due to the requirement to recompute the test statistic many times on resampled data. We propose the distilled conditional randomization test, a novel approach to using state-of-the-art machine learning algorithms in the conditional randomization test while drastically reducing the number of times those algorithms need to be run, thereby taking advantage of their power and the conditional randomization test’s statistical guarantees without suffering the usual computational expense. In addition to distillation, we propose a number of other tricks, like screening and recycling computations, to further speed up the conditional randomization test without sacrificing its high power and exact validity. Indeed, we show in simulations that all our proposals combined lead to a test that has similar power to most powerful existing conditional randomization test implementations, but requires orders of magnitude less computation, making it a practical tool even for large datasets. We demonstrate these benefits on a breast cancer dataset by identifying biomarkers related to cancer stage.},
  archive      = {J_BIOMET},
  author       = {Liu, Molei and Katsevich, Eugene and Janson, Lucas and Ramdas, Aaditya},
  doi          = {10.1093/biomet/asab039},
  journal      = {Biometrika},
  number       = {2},
  pages        = {277-293},
  shortjournal = {Biometrika},
  title        = {Fast and powerful conditional randomization testing via distillation},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: “Approximating posteriors with
high-dimensional nuisance parameters via integrated rotated gaussian
approximation.” <em>BIOMET</em>, <em>109</em>(1), 275. (<a
href="https://doi.org/10.1093/biomet/asab019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIOMET},
  author       = {van den Boom, W and Reeves, G and Dunson, D B},
  doi          = {10.1093/biomet/asab019},
  journal      = {Biometrika},
  number       = {1},
  pages        = {275},
  shortjournal = {Biometrika},
  title        = {Correction to: ‘Approximating posteriors with high-dimensional nuisance parameters via integrated rotated gaussian approximation’},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: “On semiparametric modelling, estimation and
inference for survival data subject to dependent censoring.”
<em>BIOMET</em>, <em>109</em>(1), 273. (<a
href="https://doi.org/10.1093/biomet/asab024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIOMET},
  author       = {Deresa, N W and Van Keilegom, I},
  doi          = {10.1093/biomet/asab024},
  journal      = {Biometrika},
  number       = {1},
  pages        = {273},
  shortjournal = {Biometrika},
  title        = {Correction to: ‘On semiparametric modelling, estimation and inference for survival data subject to dependent censoring’},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identifiability of causal effects with multiple causes and a
binary outcome. <em>BIOMET</em>, <em>109</em>(1), 265–272. (<a
href="https://doi.org/10.1093/biomet/asab016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unobserved confounding presents a major threat to causal inference in observational studies. Recently, several authors have suggested that this problem could be overcome in a shared confounding setting where multiple treatments are independent given a common latent confounder. It has been shown that under a linear Gaussian model for the treatments, the causal effect is not identifiable without parametric assumptions on the outcome model. In this note, we show that the causal effect is indeed identifiable if we assume a general binary choice model for the outcome with a non-probit link. Our identification approach is based on the incongruence between Gaussianity of the treatments and latent confounder and non-Gaussianity of a latent outcome variable. We further develop a two-step likelihood-based estimation procedure.},
  archive      = {J_BIOMET},
  author       = {Kong, Dehan and Yang, Shu and Wang, Linbo},
  doi          = {10.1093/biomet/asab016},
  journal      = {Biometrika},
  number       = {1},
  pages        = {265-272},
  shortjournal = {Biometrika},
  title        = {Identifiability of causal effects with multiple causes and a binary outcome},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed inference for the extreme value index.
<em>BIOMET</em>, <em>109</em>(1), 257–264. (<a
href="https://doi.org/10.1093/biomet/asab001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we investigate a divide-and-conquer algorithm for estimating the extreme value index when data are stored in multiple machines. The oracle property of such an algorithm based on extreme value methods is not guaranteed by the general theory of distributed inference. We propose a distributed Hill estimator and establish its asymptotic theories. We consider various cases where the number of observations involved in each machine can be either homogeneous or heterogeneous, and either fixed or varying according to the total sample size. In each case we provide a sufficient, sometimes also necessary, condition under which the oracle property holds.},
  archive      = {J_BIOMET},
  author       = {Chen, Liujun and Li, Deyuan and Zhou, Chen},
  doi          = {10.1093/biomet/asab001},
  journal      = {Biometrika},
  number       = {1},
  pages        = {257-264},
  shortjournal = {Biometrika},
  title        = {Distributed inference for the extreme value index},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of the cure rate for distributions in the gumbel
maximum domain of attraction under insufficient follow-up.
<em>BIOMET</em>, <em>109</em>(1), 243–256. (<a
href="https://doi.org/10.1093/biomet/asaa106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimators of the cured proportion from survival data which may include observations on cured subjects can only be expected to perform well when the follow-up period is sufficient. When follow-up is not sufficient, and the survival distribution of those susceptible to the event belongs to the Fréchet maximum domain of attraction, a nonparametric estimator for the cure proportion proposed by Escobar-Bach &amp; Van Keilegom (2019) incorporates an adjustment that reduces the bias in the usual estimator. Besides the Fréchet, an important class of limiting distributions for maxima is the Gumbel class. We show that a very wide class of commonly used survival distributions, the generalized Gamma distributions, are in the Gumbel domain of attraction. Extrapolation techniques from extreme value theory are then used to derive, for distributions in this class, a nonparametric estimator of the cure proportion that is consistent and asymptotically normally distributed under reasonable assumptions, and performs well in simulation studies with data where follow-up is insufficient. We illustrate its use with an application to survival data where patients with differing stages of breast cancer have varying degrees of follow-up.},
  archive      = {J_BIOMET},
  author       = {Escobar-Bach, Mikael and Maller, Ross and Van Keilegom, Ingrid and Zhao, Muzhi},
  doi          = {10.1093/biomet/asaa106},
  journal      = {Biometrika},
  number       = {1},
  pages        = {243-256},
  shortjournal = {Biometrika},
  title        = {Estimation of the cure rate for distributions in the gumbel maximum domain of attraction under insufficient follow-up},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Missing at random: A stochastic process perspective.
<em>BIOMET</em>, <em>109</em>(1), 227–241. (<a
href="https://doi.org/10.1093/biomet/asab002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We offer a natural and extensible measure-theoretic treatment of missingness at random. Within the standard missing-data framework, we give a novel characterization of the observed data as a stopping-set sigma algebra. We demonstrate that the usual missingness-at-random conditions are equivalent to requiring particular stochastic processes to be adapted to a set-indexed filtration. These measurability conditions ensure the usual factorization of likelihood ratios. We illustrate how the theory can be extended easily to incorporate explanatory variables, to describe longitudinal data in continuous time, and to admit more general coarsening of observations.},
  archive      = {J_BIOMET},
  author       = {Farewell, D M and Daniel, R M and Seaman, S R},
  doi          = {10.1093/biomet/asab002},
  journal      = {Biometrika},
  number       = {1},
  pages        = {227-241},
  shortjournal = {Biometrika},
  title        = {Missing at random: A stochastic process perspective},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sparse functional linear discriminant analysis.
<em>BIOMET</em>, <em>109</em>(1), 209–226. (<a
href="https://doi.org/10.1093/biomet/asaa107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional linear discriminant analysis provides a simple yet efficient method for classification, with the possibility of achieving perfect classification. Several methods have been proposed in the literature that mostly address the dimensionality of the problem. On the other hand, there is growing interest in interpretability of the analysis, which favours a simple and sparse solution. In this paper we propose a new approach that incorporates a type of sparsity that identifies nonzero subdomains in the functional setting, yielding a solution that is easier to interpret without compromising performance. Given the need to embed additional constraints in the solution, we reformulate functional linear discriminant analysis as a regularization problem with an appropriate penalty. Inspired by the success of |$\ell_1$| -type regularization at inducing zero coefficients for scalar variables, we develop a new regularization method for functional linear discriminant analysis that incorporates an |$L^1$| -type penalty, |$\int |f|$|⁠ , to induce zero regions. We demonstrate that our formulation has a well-defined solution that contains zero regions, achieving functional sparsity in the sense of domain selection. In addition, the misclassification probability of the regularized solution is shown to converge to the Bayes error if the data are Gaussian. Our method does not assume that the underlying function has zero regions in the domain, but it produces a sparse estimator that consistently estimates the true function whether or not the latter is sparse. Using both simulated and real data examples, we demonstrate this property of our method in finite samples through comparisons with existing methods.},
  archive      = {J_BIOMET},
  author       = {Park, Juhyun and Ahn, Jeongyoun and Jeon, Yongho},
  doi          = {10.1093/biomet/asaa107},
  journal      = {Biometrika},
  number       = {1},
  pages        = {209-226},
  shortjournal = {Biometrika},
  title        = {Sparse functional linear discriminant analysis},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Statistical inference on shape and size indexes for counting
processes. <em>BIOMET</em>, <em>109</em>(1), 195–208. (<a
href="https://doi.org/10.1093/biomet/asab008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-index models have gained increased popularity in time-to-event analysis owing to their model flexibility and advantage in dimension reduction. We propose a semiparametric framework for the rate function of a recurrent event counting process by modelling its size and shape components with single-index models. With additional monotone constraints on the two link functions for the size and shape components, the proposed model possesses the desired directional interpretability of covariate effects and encompasses many commonly used models as special cases. To tackle the analytical challenges arising from leaving the two link functions unspecified, we develop a two-step rank-based estimation procedure to estimate the regression parameters with or without informative censoring. The proposed estimators are asymptotically normal, with a root- |$n$| convergence rate. To guide model selection, we develop hypothesis testing procedures for checking shape and size independence. Simulation studies and a data example on a hematopoietic stem cell transplantation study are presented to illustrate the proposed methodology.},
  archive      = {J_BIOMET},
  author       = {Sun, Yifei and Chiou, Sy Han and Marr, Kieren A and Huang, Chiung-Yu},
  doi          = {10.1093/biomet/asab008},
  journal      = {Biometrika},
  number       = {1},
  pages        = {195-208},
  shortjournal = {Biometrika},
  title        = {Statistical inference on shape and size indexes for counting processes},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stratification and optimal resampling for sequential monte
carlo. <em>BIOMET</em>, <em>109</em>(1), 181–194. (<a
href="https://doi.org/10.1093/biomet/asab004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential Monte Carlo algorithms are widely accepted as powerful computational tools for making inference with dynamical systems. A key step in sequential Monte Carlo is resampling, which plays the role of steering the algorithm towards the future dynamics. Several strategies have been used in practice, including multinomial resampling, residual resampling, optimal resampling, stratified resampling and optimal transport resampling. In one-dimensional cases, we show that optimal transport resampling is equivalent to stratified resampling on the sorted particles, and both strategies minimize the resampling variance as well as the expected squared energy distance between the original and resampled empirical distributions. For general |$d$| -dimensional cases, we show that if the particles are first sorted using the Hilbert curve, the variance of stratified resampling is |$O(m^{-(1+2/d)})$|⁠ , an improvement over the best previously known rate of |$O(m^{-(1+1/d)})$|⁠ , where |$m$| is the number of resampled particles. We show that this improved rate is optimal for ordered stratified resampling schemes, as conjectured in Gerber et al. (2019) . We also present an almost-sure bound on the Wasserstein distance between the original and Hilbert-curve-resampled empirical distributions. In light of these results, we show that for dimension |$d&gt;1$| the mean square error of sequential quasi-Monte Carlo with |$n$| particles can be |$O(n^{-1-4/{d(d+4)}})$| if Hilbert curve resampling is used and a specific low-discrepancy set is chosen. To our knowledge, this is the first known convergence rate lower than |$o(n^{-1})$|⁠ .},
  archive      = {J_BIOMET},
  author       = {Li, Yichao and Wang, Wenshuo and Deng, K E and Liu, Jun S},
  doi          = {10.1093/biomet/asab004},
  journal      = {Biometrika},
  number       = {1},
  pages        = {181-194},
  shortjournal = {Biometrika},
  title        = {Stratification and optimal resampling for sequential monte carlo},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interpoint-ranking sign covariance for the test of
independence. <em>BIOMET</em>, <em>109</em>(1), 165–179. (<a
href="https://doi.org/10.1093/biomet/asab011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We generalize the sign covariance introduced by Bergsma &amp; Dassios (2014) to multivariate random variables and beyond. The new interpoint-ranking sign covariance is applicable to general types of random objects as long as a meaningful similarity measure can be defined, and it is shown to be zero if and only if the two random variables are independent. The test statistic is a |$U$| -statistic, whose large-sample behaviour guarantees that the proposed test is consistent against general types of alternatives. Numerical experiments and data analyses demonstrate the superior empirical performance of the proposed method.},
  archive      = {J_BIOMET},
  author       = {Moon, Haeun and Chen, Kehui},
  doi          = {10.1093/biomet/asab011},
  journal      = {Biometrika},
  number       = {1},
  pages        = {165-179},
  shortjournal = {Biometrika},
  title        = {Interpoint-ranking sign covariance for the test of independence},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). General ways to improve false coverage rate-adjusted
selective confidence intervals. <em>BIOMET</em>, <em>109</em>(1),
153–164. (<a href="https://doi.org/10.1093/biomet/asab010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Post-selection inference on thousands of parameters has attracted considerable research interest in recent years. Specifically, Benjamini &amp; Yekutieli (2005) considered constructing confidence intervals after selection. They proposed adjusting the confidence levels of marginal confidence intervals for the selected parameters to ensure control of the false coverage-statement rate. However, although Benjamini–Yekutieli confidence intervals are widely used, they are uniformly inflated. In this article, two methods for narrowing the Benjamini–Yekutieli confidence intervals are proposed. The first improves the confidence intervals by incorporating the selection event into the calculation. The second method further narrows those confidence intervals in which some parameters are selected with very small probabilities, which results in underutilization of the target level for control of the false coverage-statement rate. A breast cancer dataset is analysed to compare the methods.},
  archive      = {J_BIOMET},
  author       = {Zhao, Haibing},
  doi          = {10.1093/biomet/asab010},
  journal      = {Biometrika},
  number       = {1},
  pages        = {153-164},
  shortjournal = {Biometrika},
  title        = {General ways to improve false coverage rate-adjusted selective confidence intervals},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Backfitting tests in generalized structured models.
<em>BIOMET</em>, <em>109</em>(1), 137–152. (<a
href="https://doi.org/10.1093/biomet/asaa108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce bootstrap tests for semiparametric generalized structured models. These can be used for testing different kinds of model specifications like separability, functional forms and homogeneity of effects, or for performing variable selection in a large class of semiparametric models. The test statistics are based on the comparison of non- and semiparametric alternatives in which both the null hypothesis and the alternative are non- or semiparametric. All estimators are obtained by smooth backfitting. Simulation studies show excellent performance of the test procedures.},
  archive      = {J_BIOMET},
  author       = {Mammen, E and Sperlich, S},
  doi          = {10.1093/biomet/asaa108},
  journal      = {Biometrika},
  number       = {1},
  pages        = {137-152},
  shortjournal = {Biometrika},
  title        = {Backfitting tests in generalized structured models},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Large-scale model selection in misspecified generalized
linear models. <em>BIOMET</em>, <em>109</em>(1), 123–136. (<a
href="https://doi.org/10.1093/biomet/asab005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model selection is crucial both to high-dimensional learning and to inference for contemporary big data applications in pinpointing the best set of covariates among a sequence of candidate interpretable models. Most existing work implicitly assumes that the models are correctly specified or have fixed dimensionality, yet both model misspecification and high dimensionality are prevalent in practice. In this paper, we exploit the framework of model selection principles under the misspecified generalized linear models presented in Lv &amp; Liu (2014) , and investigate the asymptotic expansion of the posterior model probability in the setting of high-dimensional misspecified models. With a natural choice of prior probabilities that encourages interpretability and incorporates the Kullback–Leibler divergence, we suggest using the high-dimensional generalized Bayesian information criterion with prior probability for large-scale model selection with misspecification. Our new information criterion characterizes the impacts of both model misspecification and high dimensionality on model selection. We further establish the consistency of covariance contrast matrix estimation and the model selection consistency of the new information criterion in ultrahigh dimensions under some mild regularity conditions. Our numerical studies demonstrate that the proposed method enjoys improved model selection consistency over its main competitors.},
  archive      = {J_BIOMET},
  author       = {Demirkaya, Emre and Feng, Yang and Basu, Pallavi and Lv, Jinchi},
  doi          = {10.1093/biomet/asab005},
  journal      = {Biometrika},
  number       = {1},
  pages        = {123-136},
  shortjournal = {Biometrika},
  title        = {Large-scale model selection in misspecified generalized linear models},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrated conditional moment test and beyond: When the
number of covariates is divergent. <em>BIOMET</em>, <em>109</em>(1),
103–122. (<a href="https://doi.org/10.1093/biomet/asab009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical integrated conditional moment test is a promising method for model checking and its basic idea has been applied to develop several variants. However, in diverging-dimension scenarios, the integrated conditional moment test may break down and has completely different limiting properties from the fixed-dimension case. Furthermore, the related wild bootstrap approximation can also be invalid. To extend this classical test to diverging dimension settings, we propose a projected adaptive-to-model version of the integrated conditional moment test. We study the asymptotic properties of the new test under both the null and alternative hypotheses to examine if it maintains significance level, and its sensitivity to the global and local alternatives that are distinct from the null at the rate |$n^{-1/2}$|⁠ . The corresponding wild bootstrap approximation can still work for the new test in diverging-dimension scenarios. We also derive the consistency and asymptotically linear representation of the least squares estimator when the parameter diverges at the fastest possible known rate in the literature. Numerical studies show that the new test can greatly enhance the performance of the integrated conditional moment test in high-dimensional cases. We also apply the test to a real dataset for illustration.},
  archive      = {J_BIOMET},
  author       = {Tan, Falong and Zhu, Lixing},
  doi          = {10.1093/biomet/asab009},
  journal      = {Biometrika},
  number       = {1},
  pages        = {103-122},
  shortjournal = {Biometrika},
  title        = {Integrated conditional moment test and beyond: When the number of covariates is divergent},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dimension reduction for covariates in network data.
<em>BIOMET</em>, <em>109</em>(1), 85–102. (<a
href="https://doi.org/10.1093/biomet/asab006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A problem of major interest in network data analysis is to explain the strength of connections using context information. To achieve this, we introduce a novel approach, called network-supervised dimension reduction, in which covariates are projected onto low-dimensional spaces to reveal the linkage pattern without assuming a model. We propose a new loss function for estimating the parameters in the resulting linear projection, based on the notion that closer proximity in the low-dimension projection corresponds to stronger connections. Interestingly, the convergence rate of our estimator is found to depend on a network effect factor, which is the smallest number that can partition a graph in a manner similar to the graph colouring problem. Our method has interesting connections to principal component analysis and linear discriminant analysis, which we exploit for clustering and community detection. The proposed approach is further illustrated by numerical experiments and analysis of a pulsar candidates dataset from astronomy.},
  archive      = {J_BIOMET},
  author       = {Zhao, Junlong and Liu, Xiumin and Wang, Hansheng and Leng, Chenlei},
  doi          = {10.1093/biomet/asab006},
  journal      = {Biometrika},
  number       = {1},
  pages        = {85-102},
  shortjournal = {Biometrika},
  title        = {Dimension reduction for covariates in network data},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneity-aware and communication-efficient distributed
statistical inference. <em>BIOMET</em>, <em>109</em>(1), 67–83. (<a
href="https://doi.org/10.1093/biomet/asab007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multicentre research, individual-level data are often protected against sharing across sites. To overcome the barrier of data sharing, many distributed algorithms, which only require sharing aggregated information, have been developed. The existing distributed algorithms usually assume the data are homogeneously distributed across sites. This assumption ignores the important fact that the data collected at different sites may come from various subpopulations and environments, which can lead to heterogeneity in the distribution of the data. Ignoring the heterogeneity may lead to erroneous statistical inference. We propose distributed algorithms which account for the heterogeneous distributions by allowing site-specific nuisance parameters. The proposed methods extend the surrogate likelihood approach ( Wang et al. 2017 ; Jordan et al. 2018 ) to the heterogeneous setting by applying a novel density ratio tilting method to the efficient score function. The proposed algorithms maintain the same communication cost as existing communication-efficient algorithms. We establish a nonasymptotic risk bound for the proposed distributed estimator and its limiting distribution in the two-index asymptotic setting, which allows both sample size per site and the number of sites to go to infinity. In addition, we show that the asymptotic variance of the estimator attains the Cramér–Rao lower bound when the number of sites is smaller in rate than the sample size at each site. Finally, we use simulation studies and a real data application to demonstrate the validity and feasibility of the proposed methods.},
  archive      = {J_BIOMET},
  author       = {Duan, Rui and Ning, Yang and Chen, Yong},
  doi          = {10.1093/biomet/asab007},
  journal      = {Biometrika},
  number       = {1},
  pages        = {67-83},
  shortjournal = {Biometrika},
  title        = {Heterogeneity-aware and communication-efficient distributed statistical inference},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient adjustment sets in causal graphical models with
hidden variables. <em>BIOMET</em>, <em>109</em>(1), 49–65. (<a
href="https://doi.org/10.1093/biomet/asab018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the selection of adjustment sets for estimating the interventional mean under a point exposure dynamic treatment regime, that is, a treatment rule that depends on the subject’s covariates. We assume a nonparametric causal graphical model with, possibly, hidden variables and at least one adjustment set comprised of observable variables. We provide the definition of a valid adjustment set for a point exposure dynamic treatment regime, which generalizes the existing definition for a static intervention. We show that there exists an adjustment set, referred to as optimal minimal, that yields the nonparametric estimator of the interventional mean with the smallest asymptotic variance among those that are based on observable minimal adjustment sets. An observable minimal adjustment set is a valid adjustment set such that all its variables are observable and the removal of any of its variables destroys its validity. We provide similar optimality results for the class of observable minimum adjustment sets, that is, valid observable adjustment sets of minimum cardinality among the observable adjustment sets. Moreover, we show that if either no variables are hidden or if all the observable variables are ancestors of either treatment, outcome or the variables that are used to decide treatment, a globally optimal adjustment set exists. We provide polynomial-time algorithms to compute the globally optimal, optimal minimal and optimal minimum adjustment sets. Because static interventions can be viewed as a special case of dynamic regimes, all our results also apply for static interventions.},
  archive      = {J_BIOMET},
  author       = {Smucler, E and Sapienza, F and Rotnitzky, A},
  doi          = {10.1093/biomet/asab018},
  journal      = {Biometrika},
  number       = {1},
  pages        = {49-65},
  shortjournal = {Biometrika},
  title        = {Efficient adjustment sets in causal graphical models with hidden variables},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inference on the average treatment effect under minimization
and other covariate-adaptive randomization methods. <em>BIOMET</em>,
<em>109</em>(1), 33–47. (<a
href="https://doi.org/10.1093/biomet/asab015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Covariate-adaptive randomization schemes such as minimization and stratified permuted blocks are often applied in clinical trials to balance treatment assignments across prognostic factors. The existing theory for inference after covariate-adaptive randomization is mostly limited to situations where a correct model between the response and covariates can be specified or the randomization method has well-understood properties. Based on stratification with covariate levels utilized in randomization and a further adjustment for covariates not used in randomization, we propose several model-free estimators of the average treatment effect. We establish the asymptotic normality of the proposed estimators under all popular covariate-adaptive randomization schemes, including the minimization method, and we show that the asymptotic distributions are invariant with respect to covariate-adaptive randomization methods. Consistent variance estimators are constructed for asymptotic inference. Asymptotic relative efficiencies and finite-sample properties of estimators are also studied. We recommend using one of our proposed estimators for valid and model-free inference after covariate-adaptive randomization.},
  archive      = {J_BIOMET},
  author       = {Ye, Ting and Yi, Yanyao and Shao, Jun},
  doi          = {10.1093/biomet/asab015},
  journal      = {Biometrika},
  number       = {1},
  pages        = {33-47},
  shortjournal = {Biometrika},
  title        = {Inference on the average treatment effect under minimization and other covariate-adaptive randomization methods},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). More for less: Predicting and maximizing genomic variant
discovery via bayesian nonparametrics. <em>BIOMET</em>, <em>109</em>(1),
17–32. (<a href="https://doi.org/10.1093/biomet/asab012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the cost of sequencing genomes has decreased dramatically in recent years, this expense often remains nontrivial. Under a fixed budget, scientists face a natural trade-off between quantity and quality: spending resources to sequence a greater number of genomes or spending resources to sequence genomes with increased accuracy. Our goal is to find the optimal allocation of resources between quantity and quality. Optimizing resource allocation promises to reveal as many new variations in the genome as possible. We introduce a Bayesian nonparametric methodology to predict the number of new variants in a follow-up study based on a pilot study. When experimental conditions are kept constant between the pilot and follow-up, we find that our prediction is competitive with the best existing methods. Unlike current methods, though, our new method allows practitioners to change experimental conditions between the pilot and the follow-up. We demonstrate how this distinction allows our method to be used for more realistic predictions and for optimal allocation of a fixed budget between quality and quantity. We validate our method on cancer and human genomics data.},
  archive      = {J_BIOMET},
  author       = {Masoero, Lorenzo and Camerlenghi, Federico and Favaro, Stefano and Broderick, Tamara},
  doi          = {10.1093/biomet/asab012},
  journal      = {Biometrika},
  number       = {1},
  pages        = {17-32},
  shortjournal = {Biometrika},
  title        = {More for less: Predicting and maximizing genomic variant discovery via bayesian nonparametrics},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal post-selection inference for sparse signals: A
nonparametric empirical bayes approach. <em>BIOMET</em>,
<em>109</em>(1), 1–16. (<a
href="https://doi.org/10.1093/biomet/asab014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many recently developed Bayesian methods focus on sparse signal detection. However, much less work has been done on the natural follow-up question: how does one make valid inferences for the magnitude of those signals after selection? Ordinary Bayesian credible intervals suffer from selection bias, as do ordinary frequentist confidence intervals. Existing Bayesian methods for correcting this bias produce credible intervals with poor frequentist properties. Further, existing frequentist approaches require sacrificing the benefits of shrinkage typical in Bayesian methods, resulting in confidence intervals that are needlessly wide. We address this gap by proposing a nonparametric empirical Bayes approach to constructing optimal selection-adjusted confidence sets. Our method produces confidence sets that are as short as possible on average, while both adjusting for selection and maintaining exact frequentist coverage uniformly over the parameter space. We demonstrate an important consistency property of our procedure: under mild conditions, it asymptotically converges to the results of an oracle-Bayes analysis in which the prior distribution of signal sizes is known exactly. Across a series of examples, the method is found to outperform existing frequentist techniques for post-selection inference, producing confidence sets that are notably shorter, but with the same coverage guarantee.},
  archive      = {J_BIOMET},
  author       = {Woody, S and Padilla, O H M and Scott, J G},
  doi          = {10.1093/biomet/asab014},
  journal      = {Biometrika},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Biometrika},
  title        = {Optimal post-selection inference for sparse signals: A nonparametric empirical bayes approach},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
