<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>BIOSTAT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="biostat---72">BIOSTAT - 72</h2>
<ul>
<li><details>
<summary>
(2022). Estimation of sparse functional quantile regression with
measurement error: A SIMEX approach. <em>BIOSTAT</em>, <em>23</em>(4),
1218–1241. (<a
href="https://doi.org/10.1093/biostatistics/kxac017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantile regression is a semiparametric method for modeling associations between variables. It is most helpful when the covariates have complex relationships with the location, scale, and shape of the outcome distribution. Despite the method’s robustness to distributional assumptions and outliers in the outcome, regression quantiles may be biased in the presence of measurement error in the covariates. The impact of function-valued covariates contaminated with heteroscedastic error has not yet been examined previously; although, studies have investigated the case of scalar-valued covariates. We present a two-stage strategy to consistently fit linear quantile regression models with a function-valued covariate that may be measured with error. In the first stage, an instrumental variable is used to estimate the covariance matrix associated with the measurement error. In the second stage, simulation extrapolation (SIMEX) is used to correct for measurement error in the function-valued covariate. Point-wise standard errors are estimated by means of nonparametric bootstrap. We present simulation studies to assess the robustness of the measurement error corrected for functional quantile regression. Our methods are applied to National Health and Examination Survey data to assess the relationship between physical activity and body mass index among adults in the United States.},
  archive      = {J_BIOSTAT},
  author       = {Tekwe, Carmen D and Zhang, Mengli and Carroll, Raymond J and Luan, Yuanyuan and Xue, Lan and Zoh, Roger S and Carter, Stephen J and Allison, David B and Geraci, Marco},
  doi          = {10.1093/biostatistics/kxac017},
  journal      = {Biostatistics},
  month        = {10},
  number       = {4},
  pages        = {1218-1241},
  shortjournal = {Biostatistics},
  title        = {Estimation of sparse functional quantile regression with measurement error: A SIMEX approach},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-stage linked component analysis for joint decomposition
of multiple biologically related data sets. <em>BIOSTAT</em>,
<em>23</em>(4), 1200–1217. (<a
href="https://doi.org/10.1093/biostatistics/kxac005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrative analysis of multiple data sets has the potential of fully leveraging the vast amount of high throughput biological data being generated. In particular such analysis will be powerful in making inference from publicly available collections of genetic, transcriptomic and epigenetic data sets which are designed to study shared biological processes, but which vary in their target measurements, biological variation, unwanted noise, and batch variation. Thus, methods that enable the joint analysis of multiple data sets are needed to gain insights into shared biological processes that would otherwise be hidden by unwanted intra-data set variation. Here, we propose a method called two-stage linked component analysis (2s-LCA) to jointly decompose multiple biologically related experimental data sets with biological and technological relationships that can be structured into the decomposition. The consistency of the proposed method is established and its empirical performance is evaluated via simulation studies. We apply 2s-LCA to jointly analyze four data sets focused on human brain development and identify meaningful patterns of gene expression in human neurogenesis that have shared structure across these data sets.},
  archive      = {J_BIOSTAT},
  author       = {Chen, Huan and Caffo, Brian and Stein-O’Brien, Genevieve and Liu, Jinrui and Langmead, Ben and Colantuoni, Carlo and Xiao, Luo},
  doi          = {10.1093/biostatistics/kxac005},
  journal      = {Biostatistics},
  month        = {10},
  number       = {4},
  pages        = {1200-1217},
  shortjournal = {Biostatistics},
  title        = {Two-stage linked component analysis for joint decomposition of multiple biologically related data sets},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive randomization in a two-stage sequential multiple
assignment randomized trial. <em>BIOSTAT</em>, <em>23</em>(4),
1182–1199. (<a
href="https://doi.org/10.1093/biostatistics/kxab020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential multiple assignment randomized trials (SMARTs) are systematic and efficient media for comparing dynamic treatment regimes (DTRs), where each patient is involved in multiple stages of treatment with the randomization at each stage depending on the patient’s previous treatment history and interim outcomes. Generally, patients enrolled in SMARTs are randomized equally to ethically acceptable treatment options regardless of how effective those treatments were during the previous stages, which results in some undesirable consequences in practice, such as low recruitment, less retention, and lower treatment adherence. In this article, we propose a response-adaptive SMART (RA-SMART) design where the allocation probabilities are imbalanced in favor of more promising treatments based on the accumulated information on treatment efficacy from previous patients and stages. The operating characteristics of the RA-SMART design relative to SMART design, including the consistency and efficiency of estimated response rate under each DTR, the power of identifying the optimal DTR, and the number of patients treated with the optimal and the worst DTRs, are assessed through extensive simulation studies. Some practical suggestions are discussed in the conclusion.},
  archive      = {J_BIOSTAT},
  author       = {Wang, Junyao and Wu, Liwen and Wahed, Abdus S},
  doi          = {10.1093/biostatistics/kxab020},
  journal      = {Biostatistics},
  month        = {10},
  number       = {4},
  pages        = {1182-1199},
  shortjournal = {Biostatistics},
  title        = {Adaptive randomization in a two-stage sequential multiple assignment randomized trial},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hierarchical prior for generalized linear models based on
predictions for the mean response. <em>BIOSTAT</em>, <em>23</em>(4),
1165–1181. (<a
href="https://doi.org/10.1093/biostatistics/kxac022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been increased interest in using prior information in statistical analyses. For example, in rare diseases, it can be difficult to establish treatment efficacy based solely on data from a prospective study due to low sample sizes. To overcome this issue, an informative prior to the treatment effect may be elicited. We develop a novel extension of the conjugate prior of Chen and Ibrahim (2003) that enables practitioners to elicit a prior prediction for the mean response for generalized linear models, treating the prediction as random. We refer to the hierarchical prior as the hierarchical prediction prior (HPP). For independent and identically distributed settings and the normal linear model, we derive cases for which the hyperprior is a conjugate prior. We also develop an extension of the HPP in situations where summary statistics from a previous study are available. The HPP allows for discounting based on the quality of individual level predictions, and simulation results suggest that, compared to the conjugate prior and the power prior, the HPP efficiency gains (e.g., lower mean squared error) where predictions are incompatible with the data. An efficient Monte Carlo Markov chain algorithm is developed. Applications illustrate that inferences under the HPP are more robust to prior-data conflict compared to selected nonhierarchical priors.},
  archive      = {J_BIOSTAT},
  author       = {Alt, Ethan M and Psioda, Matthew A and Ibrahim, Joseph G},
  doi          = {10.1093/biostatistics/kxac022},
  journal      = {Biostatistics},
  month        = {10},
  number       = {4},
  pages        = {1165-1181},
  shortjournal = {Biostatistics},
  title        = {A hierarchical prior for generalized linear models based on predictions for the mean response},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A probabilistic gene expression barcode for annotation of
cell types from single-cell RNA-seq data. <em>BIOSTAT</em>,
<em>23</em>(4), 1150–1164. (<a
href="https://doi.org/10.1093/biostatistics/kxac021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-cell RNA sequencing (scRNA-seq) quantifies gene expression for individual cells in a sample, which allows distinct cell-type populations to be identified and characterized. An important step in many scRNA-seq analysis pipelines is the annotation of cells into known cell types. While this can be achieved using experimental techniques, such as fluorescence-activated cell sorting, these approaches are impractical for large numbers of cells. This motivates the development of data-driven cell-type annotation methods. We find limitations with current approaches due to the reliance on known marker genes or from overfitting because of systematic differences, or batch effects, between studies. Here, we present a statistical approach that leverages public data sets to combine information across thousands of genes, uses a latent variable model to define cell-type-specific barcodes and account for batch effect variation, and probabilistically annotates cell-type identity from a reference of known cell types. The barcoding approach also provides a new way to discover marker genes. Using a range of data sets, including those generated to represent imperfect real-world reference data, we demonstrate that our approach substantially outperforms current reference-based methods, particularly when predicting across studies.},
  archive      = {J_BIOSTAT},
  author       = {Grabski, Isabella N and Irizarry, Rafael A},
  doi          = {10.1093/biostatistics/kxac021},
  journal      = {Biostatistics},
  month        = {10},
  number       = {4},
  pages        = {1150-1164},
  shortjournal = {Biostatistics},
  title        = {A probabilistic gene expression barcode for annotation of cell types from single-cell RNA-seq data},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Separating and reintegrating latent variables to improve
classification of genomic data. <em>BIOSTAT</em>, <em>23</em>(4),
1133–1149. (<a
href="https://doi.org/10.1093/biostatistics/kxab046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genomic data sets contain the effects of various unobserved biological variables in addition to the variable of primary interest. These latent variables often affect a large number of features (e.g., genes), giving rise to dense latent variation. This latent variation presents both challenges and opportunities for classification. While some of these latent variables may be partially correlated with the phenotype of interest and thus helpful, others may be uncorrelated and merely contribute additional noise. Moreover, whether potentially helpful or not, these latent variables may obscure weaker effects that impact only a small number of features but more directly capture the signal of primary interest. To address these challenges, we propose the cross-residualization classifier (CRC). Through an adjustment and ensemble procedure, the CRC estimates and residualizes out the latent variation, trains a classifier on the residuals, and then reintegrates the latent variation in a final ensemble classifier. Thus, the latent variables are accounted for without discarding any potentially predictive information. We apply the method to simulated data and a variety of genomic data sets from multiple platforms. In general, we find that the CRC performs well relative to existing classifiers and sometimes offers substantial gains.},
  archive      = {J_BIOSTAT},
  author       = {Payne, Nora Yujia and Gagnon-Bartsch, Johann A},
  doi          = {10.1093/biostatistics/kxab046},
  journal      = {Biostatistics},
  month        = {10},
  number       = {4},
  pages        = {1133-1149},
  shortjournal = {Biostatistics},
  title        = {Separating and reintegrating latent variables to improve classification of genomic data},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Causal inference for semi-competing risks data.
<em>BIOSTAT</em>, <em>23</em>(4), 1115–1132. (<a
href="https://doi.org/10.1093/biostatistics/kxab049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The causal effects of Apolipoprotein E |$\epsilon4$| allele (APOE) on late-onset Alzheimer’s disease (AD) and death are complicated to define because AD may occur under one intervention but not under the other, and because AD occurrence may affect age of death. In this article, this dual outcome scenario is studied using the semi-competing risks framework for time-to-event data. Two event times are of interest: a nonterminal event time (age at AD diagnosis), and a terminal event time (age at death). AD diagnosis time is observed only if it precedes death, which may occur before or after AD. We propose new estimands for capturing the causal effect of APOE on AD and death. Our proposal is based on a stratification of the population with respect to the order of the two events. We present a novel assumption utilizing the time-to-event nature of the data, which is more flexible than the often-invoked monotonicity assumption. We derive results on partial identifiability, suggest a sensitivity analysis approach, and give conditions under which full identification is possible. Finally, we present and implement nonparametric and semiparametric estimation methods under right-censored semi-competing risks data for studying the complex effect of APOE on AD and death.},
  archive      = {J_BIOSTAT},
  author       = {Nevo, Daniel and Gorfine, Malka},
  doi          = {10.1093/biostatistics/kxab049},
  journal      = {Biostatistics},
  month        = {10},
  number       = {4},
  pages        = {1115-1132},
  shortjournal = {Biostatistics},
  title        = {Causal inference for semi-competing risks data},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluating replicability in microbiome data.
<em>BIOSTAT</em>, <em>23</em>(4), 1099–1114. (<a
href="https://doi.org/10.1093/biostatistics/kxab048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-throughput sequencing is widely used to study microbial communities. However, choice of laboratory protocol is known to affect the resulting microbiome data, which has an unquantified impact on many comparisons between communities of scientific interest. We propose a novel approach to evaluating replicability in high-dimensional data and apply it to assess the cross-laboratory replicability of signals in microbiome data using the Microbiome Quality Control Project data set. We learn distinctions between samples as measured by a single laboratory and evaluate whether the same distinctions hold in data produced by other laboratories. While most sequencing laboratories can consistently distinguish between samples (median correct classification 87% on genus-level proportion data), these distinctions frequently fail to hold in data from other laboratories (median correct classification 55% across laboratory on genus-level proportion data). As identical samples processed by different laboratories generate substantively different quantitative results, we conclude that 16S sequencing does not reliably resolve differences in human microbiome samples. However, because we observe greater replicability under certain data transformations, our results inform the analysis of microbiome data.},
  archive      = {J_BIOSTAT},
  author       = {Clausen, David S and Willis, Amy D},
  doi          = {10.1093/biostatistics/kxab048},
  journal      = {Biostatistics},
  month        = {10},
  number       = {4},
  pages        = {1099-1114},
  shortjournal = {Biostatistics},
  title        = {Evaluating replicability in microbiome data},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Individual participant data meta-analysis with mixed-effects
transformation models. <em>BIOSTAT</em>, <em>23</em>(4), 1083–1098. (<a
href="https://doi.org/10.1093/biostatistics/kxab045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-stage meta-analysis of individual participant data (IPD) poses several statistical and computational challenges. For time-to-event outcomes, the approach requires the estimation of complicated nonlinear mixed-effects models that are flexible enough to realistically capture the most important characteristics of the IPD. We present a model class that incorporates general normally distributed random effects into linear transformation models. We discuss extensions to model between-study heterogeneity in baseline risks and covariate effects and also relax the assumption of proportional hazards. Within the proposed framework, data with arbitrary random censoring patterns can be handled. The accompanying |$\textsf{R}$| package tramME utilizes the Laplace approximation and automatic differentiation to perform efficient maximum likelihood estimation and inference in mixed-effects transformation models. We compare several variants of our model to predict the survival of patients with chronic obstructive pulmonary disease using a large data set of prognostic studies. Finally, a simulation study is presented that verifies the correctness of the implementation and highlights its efficiency compared to an alternative approach.},
  archive      = {J_BIOSTAT},
  author       = {Tamási, Bálint and Crowther, Michael and Puhan, Milo Alan and Steyerberg, Ewout W and Hothorn, Torsten},
  doi          = {10.1093/biostatistics/kxab045},
  journal      = {Biostatistics},
  month        = {10},
  number       = {4},
  pages        = {1083-1098},
  shortjournal = {Biostatistics},
  title        = {Individual participant data meta-analysis with mixed-effects transformation models},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A note on median regression for complex surveys.
<em>BIOSTAT</em>, <em>23</em>(4), 1074–1082. (<a
href="https://doi.org/10.1093/biostatistics/kxab035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a great need for statistical methods for analyzing skewed responses in complex sample surveys. Quantile regression is a logical option in addressing this problem but is often accompanied by incorrect variance estimation. We show how the variance can be estimated correctly by including the survey design in the variance estimation process. In a simulation study, we illustrate that the variance of the median regression estimator has a very small relative bias with appropriate coverage probability. The motivation for our work stems from the National Health and Nutrition Examination Survey where we demonstrate the impact of our results on iodine deficiency in females compared with males adjusting for other covariates.},
  archive      = {J_BIOSTAT},
  author       = {Fraser, Raphael A and Lipsitz, Stuart R and Sinha, Debajyoti and Fitzmaurice, Garrett M},
  doi          = {10.1093/biostatistics/kxab035},
  journal      = {Biostatistics},
  month        = {10},
  number       = {4},
  pages        = {1074-1082},
  shortjournal = {Biostatistics},
  title        = {A note on median regression for complex surveys},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Marginal structural models for multilevel clustered data.
<em>BIOSTAT</em>, <em>23</em>(4), 1056–1073. (<a
href="https://doi.org/10.1093/biostatistics/kxac027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marginal structural models (MSMs), which adopt inverse probability treatment weighting in the estimating equations, are powerful tools to estimate the causal effects of time-varying exposures in the presence of time-dependent confounders. Motivated by the Conservation of Hearing Study (CHEARS) Audiology Assessment Arm (AAA) where repeated hearing measurements were clustered by study participants, time, and testing sites, we propose two methods to account for the multilevel correlation structure when fitting the MSMs. The first method directly models the covariance of the repeated outcomes when solving the weighted generalized estimating equations for MSMs, while the second two-stage analysis approach fits cluster-specific MSMs first and then combines the estimated parameters using mixed-effects meta-analysis. Finite sample simulation results suggest that our methods can obtain less biased and more efficient estimates of the parameters by accounting for the multilevel correlation. Moreover, we explore the effects of using fixed- or mixed-effects model to estimate the treatment probability on the parameter estimates of the MSMs in the presence of unmeasured cluster-level confounders. Lastly, we apply our methods to the CHEARS AAA data set, to estimate the causal effects of aspirin use on hearing loss.},
  archive      = {J_BIOSTAT},
  author       = {Wu, Yujie and Langworthy, Benjamin and Wang, Molin},
  doi          = {10.1093/biostatistics/kxac027},
  journal      = {Biostatistics},
  month        = {10},
  number       = {4},
  pages        = {1056-1073},
  shortjournal = {Biostatistics},
  title        = {Marginal structural models for multilevel clustered data},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation and false discovery control for the analysis of
environmental mixtures. <em>BIOSTAT</em>, <em>23</em>(4), 1039–1055. (<a
href="https://doi.org/10.1093/biostatistics/kxac001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of environmental mixtures is of growing importance in environmental epidemiology, and one of the key goals in such analyses is to identify exposures and their interactions that are associated with adverse health outcomes. Typical approaches utilize flexible regression models combined with variable selection to identify important exposures and estimate a potentially nonlinear relationship with the outcome of interest. Despite this surge in interest, no approaches to date can identify exposures and interactions while controlling any form of error rates with respect to exposure selection. We propose two novel approaches to estimating the health effects of environmental mixtures that simultaneously (i) estimate and provide valid inference for the overall mixture effect and (ii) identify important exposures and interactions while controlling the false discovery rate (FDR). We show that this can lead to substantial power gains to detect weak effects of environmental exposures. We apply our approaches to a study of persistent organic pollutants and find that controlling the FDR leads to substantially different conclusions.},
  archive      = {J_BIOSTAT},
  author       = {Samanta, Srijata and Antonelli, Joseph},
  doi          = {10.1093/biostatistics/kxac001},
  journal      = {Biostatistics},
  month        = {10},
  number       = {4},
  pages        = {1039-1055},
  shortjournal = {Biostatistics},
  title        = {Estimation and false discovery control for the analysis of environmental mixtures},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A spatiotemporal recommendation engine for malaria control.
<em>BIOSTAT</em>, <em>23</em>(3), 1023–1038. (<a
href="https://doi.org/10.1093/biostatistics/kxab010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malaria is an infectious disease affecting a large population across the world, and interventions need to be efficiently applied to reduce the burden of malaria. We develop a framework to help policy-makers decide how to allocate limited resources in realtime for malaria control. We formalize a policy for the resource allocation as a sequence of decisions, one per intervention decision, that map up-to-date disease related information to a resource allocation. An optimal policy must control the spread of the disease while being interpretable and viewed as equitable to stakeholders. We construct an interpretable class of resource allocation policies that can accommodate allocation of resources residing in a continuous domain and combine a hierarchical Bayesian spatiotemporal model for disease transmission with a policy-search algorithm to estimate an optimal policy for resource allocation within the pre-specified class. The estimated optimal policy under the proposed framework improves the cumulative long-term outcome compared with naive approaches in both simulation experiments and application to malaria interventions in the Democratic Republic of the Congo.},
  archive      = {J_BIOSTAT},
  author       = {Guan, Qian and Reich, Brian J and Laber, Eric B},
  doi          = {10.1093/biostatistics/kxab010},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {1023-1038},
  shortjournal = {Biostatistics},
  title        = {A spatiotemporal recommendation engine for malaria control},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian adaptive design for concurrent trials involving
biologically related diseases. <em>BIOSTAT</em>, <em>23</em>(3),
1007–1022. (<a
href="https://doi.org/10.1093/biostatistics/kxab008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a Bayesian design method for a clinical program where an investigational product is to be studied concurrently in a set of clinical trials involving related diseases with the goal of demonstrating superiority to a control in each. The approach borrows information on treatment effectiveness using correlated mixture priors using an analysis procedure that is closely related Bayesian model averaging. Mixture priors are constructed by eliciting conjugate priors based on pessimistic and enthusiastic predictions for the data to be observed for each disease and then by eliciting mixture weights for all possible configurations of the pessimistic and enthusiastic priors across the diseases to be studied. The proposed approach provides a robust framework for information borrowing in settings where the diseases may have endpoints based on different data types. We show via simulation that operating characteristics based on the proposed design framework are favorable compared to those based on information borrowing designs using the Bayesian hierarchical model which is poorly suited for information borrowing when there are different data types underpinning the endpoints across which information is to be borrowed.},
  archive      = {J_BIOSTAT},
  author       = {Psioda, Matthew A and Xia, H Amy and Jiang, Xun and Xu, Jiawei and Ibrahim, Joseph G},
  doi          = {10.1093/biostatistics/kxab008},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {1007-1022},
  shortjournal = {Biostatistics},
  title        = {Bayesian adaptive design for concurrent trials involving biologically related diseases},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structure-preserving integrated analysis for risk
stratification with application to cancer staging. <em>BIOSTAT</em>,
<em>23</em>(3), 990–1006. (<a
href="https://doi.org/10.1093/biostatistics/kxab005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To provide appropriate and practical level of health care, it is critical to group patients into relatively few strata that have distinct prognosis. Such grouping or stratification is typically based on well-established risk factors and clinical outcomes. A well-known example is the American Joint Committee on Cancer staging for cancer that uses tumor size, node involvement, and metastasis status. We consider a statistical method for such grouping based on individual patient data from multiple studies. The method encourages a common grouping structure as a basis for borrowing information, but acknowledges data heterogeneity including unbalanced data structures across multiple studies. We build on the “lasso-tree” method that is more versatile than the well-known classification and regression tree method in generating possible grouping patterns. In addition, the parametrization of the lasso-tree method makes it very natural to incorporate the underlying order information in the risk factors. In this article, we also strengthen the lasso-tree method by establishing its theoretical properties for which Lin and others (2013. Lasso tree for cancer staging with survival data. Biostatistics 14, 327–339) did not pursue. We evaluate our method in extensive simulation studies and an analysis of multiple breast cancer data sets.},
  archive      = {J_BIOSTAT},
  author       = {Wang, Tianjie and Chen, Rui and Liu, Wenshuo and Yu, Menggang},
  doi          = {10.1093/biostatistics/kxab005},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {990-1006},
  shortjournal = {Biostatistics},
  title        = {Structure-preserving integrated analysis for risk stratification with application to cancer staging},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simultaneous differential network analysis and
classification for matrix-variate data with application to brain
connectivity. <em>BIOSTAT</em>, <em>23</em>(3), 967–989. (<a
href="https://doi.org/10.1093/biostatistics/kxab007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Growing evidence has shown that the brain connectivity network experiences alterations for complex diseases such as Alzheimer’s disease (AD). Network comparison, also known as differential network analysis, is thus particularly powerful to reveal the disease pathologies and identify clinical biomarkers for medical diagnoses (classification). Data from neurophysiological measurements are multidimensional and in matrix-form. Naive vectorization method is not sufficient as it ignores the structural information within the matrix. In the article, we adopt the Kronecker product covariance matrices framework to capture both spatial and temporal correlations of the matrix-variate data while the temporal covariance matrix is treated as a nuisance parameter. By recognizing that the strengths of network connections may vary across subjects, we develop an ensemble-learning procedure, which identifies the differential interaction patterns of brain regions between the case group and the control group and conducts medical diagnosis (classification) of the disease simultaneously. Simulation studies are conducted to assess the performance of the proposed method. We apply the proposed procedure to the functional connectivity analysis of an functional magnetic resonance imaging study on AD. The hub nodes and differential interaction patterns identified are consistent with existing experimental studies, and satisfactory out-of-sample classification performance is achieved for medical diagnosis of AD.},
  archive      = {J_BIOSTAT},
  author       = {Chen, Hao and Guo, Ying and He, Yong and Ji, Jiadong and Liu, Lei and Shi, Yufeng and Wang, Yikai and Yu, Long and Zhang, Xinsheng and The Alzheimers Disease Neuroimaging Initiative},
  doi          = {10.1093/biostatistics/kxab007},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {967-989},
  shortjournal = {Biostatistics},
  title        = {Simultaneous differential network analysis and classification for matrix-variate data with application to brain connectivity},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing for similarity of binary efficacy–toxicity
responses. <em>BIOSTAT</em>, <em>23</em>(3), 949–966. (<a
href="https://doi.org/10.1093/biostatistics/kxaa058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical trials often aim to compare two groups of patients for efficacy and/or toxicity depending on covariates such as dose. Examples include the comparison of populations from different geographic regions or age classes or, alternatively, of different treatment groups. Similarity of these groups can be claimed if the difference in average outcome is below a certain margin over the entire covariate range. In this article, we consider the problem of testing for similarity in the case that efficacy and toxicity are measured as binary outcome variables. We develop a new test for the assessment of similarity of two groups for a single binary endpoint. Our approach is based on estimating the maximal deviation between the curves describing the responses of the two groups, followed by a parametric bootstrap test. Further, using a two-dimensional Gumbel-type model we develop methodology to establish similarity for (correlated) binary efficacy–toxicity outcomes. We investigate the operating characteristics of the proposed methodology by means of a simulation study and present a case study as an illustration.},
  archive      = {J_BIOSTAT},
  author       = {Möllenhoff, Kathrin and Dette, Holger and Bretz, Frank},
  doi          = {10.1093/biostatistics/kxaa058},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {949-966},
  shortjournal = {Biostatistics},
  title        = {Testing for similarity of binary efficacy–toxicity responses},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Information enhanced model selection for gaussian graphical
model with application to metabolomic data. <em>BIOSTAT</em>,
<em>23</em>(3), 926–948. (<a
href="https://doi.org/10.1093/biostatistics/kxab006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In light of the low signal-to-noise nature of many large biological data sets, we propose a novel method to learn the structure of association networks using Gaussian graphical models combined with prior knowledge. Our strategy includes two parts. In the first part, we propose a model selection criterion called structural Bayesian information criterion, in which the prior structure is modeled and incorporated into Bayesian information criterion. It is shown that the popular extended Bayesian information criterion is a special case of structural Bayesian information criterion. In the second part, we propose a two-step algorithm to construct the candidate model pool. The algorithm is data-driven and the prior structure is embedded into the candidate model automatically. Theoretical investigation shows that under some mild conditions structural Bayesian information criterion is a consistent model selection criterion for high-dimensional Gaussian graphical model. Simulation studies validate the superiority of the proposed algorithm over the existing ones and show the robustness to the model misspecification. Application to relative concentration data from infant feces collected from subjects enrolled in a large molecular epidemiological cohort study validates that metabolic pathway involvement is a statistically significant factor for the conditional dependence between metabolites. Furthermore, new relationships among metabolites are discovered which can not be identified by the conventional methods of pathway analysis. Some of them have been widely recognized in biological literature.},
  archive      = {J_BIOSTAT},
  author       = {Zhou, Jie and Hoen, Anne G and Mcritchie, Susan and Pathmasiri, Wimal and Viles, Weston D and Nguyen, Quang P and Madan, Juliette C and Dade, Erika and Karagas, Margaret R and Gui, Jiang},
  doi          = {10.1093/biostatistics/kxab006},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {926-948},
  shortjournal = {Biostatistics},
  title        = {Information enhanced model selection for gaussian graphical model with application to metabolomic data},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A greedy approach for mutual exclusivity analysis in cancer
study. <em>BIOSTAT</em>, <em>23</em>(3), 910–925. (<a
href="https://doi.org/10.1093/biostatistics/kxab004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main challenge in cancer genomics is to distinguish the driver genes from passenger or neutral genes. Cancer genomes exhibit extensive mutational heterogeneity that no two genomes contain exactly the same somatic mutations. Such mutual exclusivity (ME) of mutations has been observed in cancer data and is associated with functional pathways. Analysis of ME patterns may provide useful clues to driver genes or pathways and may suggest novel understandings of cancer progression. In this article, we consider a probabilistic, generative model of ME, and propose a powerful and greedy algorithm to select the mutual exclusivity gene sets. The greedy method includes a pre-selection procedure and a stepwise forward algorithm which can significantly reduce computation time. Power calculations suggest that the new method is efficient and powerful for one ME set or multiple ME sets with overlapping genes. We illustrate this approach by analysis of the whole-exome sequencing data of cancer types from TCGA.},
  archive      = {J_BIOSTAT},
  author       = {Fang, Hongyan and Zhang, Zeyu and Zhou, Yinsheng and Jin, Lishuai and Yang, Yaning},
  doi          = {10.1093/biostatistics/kxab004},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {910-925},
  shortjournal = {Biostatistics},
  title        = {A greedy approach for mutual exclusivity analysis in cancer study},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian biclustering for microbial metagenomic sequencing
data via multinomial matrix factorization. <em>BIOSTAT</em>,
<em>23</em>(3), 891–909. (<a
href="https://doi.org/10.1093/biostatistics/kxab002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-throughput sequencing technology provides unprecedented opportunities to quantitatively explore human gut microbiome and its relation to diseases. Microbiome data are compositional, sparse, noisy, and heterogeneous, which pose serious challenges for statistical modeling. We propose an identifiable Bayesian multinomial matrix factorization model to infer overlapping clusters on both microbes and hosts. The proposed method represents the observed over-dispersed zero-inflated count matrix as Dirichlet-multinomial mixtures on which latent cluster structures are built hierarchically. Under the Bayesian framework, the number of clusters is automatically determined and available information from a taxonomic rank tree of microbes is naturally incorporated, which greatly improves the interpretability of our findings. We demonstrate the utility of the proposed approach by comparing to alternative methods in simulations. An application to a human gut microbiome data set involving patients with inflammatory bowel disease reveals interesting clusters, which contain bacteria families Bacteroidaceae , Bifidobacteriaceae , Enterobacteriaceae , Fusobacteriaceae , Lachnospiraceae , Ruminococcaceae , Pasteurellaceae , and Porphyromonadaceae that are known to be related to the inflammatory bowel disease and its subtypes according to biological literature. Our findings can help generate potential hypotheses for future investigation of the heterogeneity of the human gut microbiome.},
  archive      = {J_BIOSTAT},
  author       = {Zhou, Fangting and He, Kejun and Li, Qiwei and Chapkin, Robert S and Ni, Yang},
  doi          = {10.1093/biostatistics/kxab002},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {891-909},
  shortjournal = {Biostatistics},
  title        = {Bayesian biclustering for microbial metagenomic sequencing data via multinomial matrix factorization},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assessing risk model calibration with missing covariates.
<em>BIOSTAT</em>, <em>23</em>(3), 875–890. (<a
href="https://doi.org/10.1093/biostatistics/kxaa060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When validating a risk model in an independent cohort, some predictors may be missing for some subjects. Missingness can be unplanned or by design, as in case-cohort or nested case–control studies, in which some covariates are measured only in subsampled subjects. Weighting methods and imputation are used to handle missing data. We propose methods to increase the efficiency of weighting to assess calibration of a risk model (i.e. bias in model predictions), which is quantified by the ratio of the number of observed events, |$\mathcal{O}$|⁠ , to expected events, |$\mathcal{E}$|⁠ , computed from the model. We adjust known inverse probability weights by incorporating auxiliary information available for all cohort members. We use survey calibration that requires the weighted sum of the auxiliary statistics in the complete data subset to equal their sum in the full cohort. We show that a pseudo-risk estimate that approximates the actual risk value but uses only variables available for the entire cohort is an excellent auxiliary statistic to estimate |$\mathcal{E}$|⁠ . We derive analytic variance formulas for |$\mathcal{O}/\mathcal{E}$| with adjusted weights. In simulations, weight adjustment with pseudo-risk was much more efficient than inverse probability weighting and yielded consistent estimates even when the pseudo-risk was a poor approximation. Multiple imputation was often efficient but yielded biased estimates when the imputation model was misspecified. Using these methods, we assessed calibration of an absolute risk model for second primary thyroid cancer in an independent cohort.},
  archive      = {J_BIOSTAT},
  author       = {Shin, Yei Eun and Gail, Mitchell H and Pfeiffer, Ruth M},
  doi          = {10.1093/biostatistics/kxaa060},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {875-890},
  shortjournal = {Biostatistics},
  title        = {Assessing risk model calibration with missing covariates},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dimension constraints improve hypothesis testing for
large-scale, graph-associated, brain-image data. <em>BIOSTAT</em>,
<em>23</em>(3), 860–874. (<a
href="https://doi.org/10.1093/biostatistics/kxab001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For large-scale testing with graph-associated data, we present an empirical Bayes mixture technique to score local false-discovery rates (FDRs). Compared to procedures that ignore the graph, the proposed Graph-based Mixture Model (GraphMM) method gains power in settings where non-null cases form connected subgraphs, and it does so by regularizing parameter contrasts between testing units. Simulations show that GraphMM controls the FDR in a variety of settings, though it may lose control with excessive regularization. On magnetic resonance imaging data from a study of brain changes associated with the onset of Alzheimer’s disease, GraphMM produces greater yield than conventional large-scale testing procedures.},
  archive      = {J_BIOSTAT},
  author       = {Vo, Tien and Mishra, Akshay and Ithapu, Vamsi and Singh, Vikas and Newton, Michael A},
  doi          = {10.1093/biostatistics/kxab001},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {860-874},
  shortjournal = {Biostatistics},
  title        = {Dimension constraints improve hypothesis testing for large-scale, graph-associated, brain-image data},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing calibration of phenotyping models using
positive-only electronic health record data. <em>BIOSTAT</em>,
<em>23</em>(3), 844–859. (<a
href="https://doi.org/10.1093/biostatistics/kxab003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Validation of phenotyping models using Electronic Health Records (EHRs) data conventionally requires gold-standard case and control labels. The labeling process requires clinical experts to retrospectively review patients’ medical charts, therefore is labor intensive and time consuming. For some disease conditions, it is prohibitive to identify the gold-standard controls because routine clinical assessments are performed for selective patients who are deemed to possibly have the condition. To build a model for phenotyping patients in EHRs, the most readily accessible data are often for a cohort consisting of a set of gold-standard cases and a large number of unlabeled patients. Hereby, we propose methods for assessing model calibration and discrimination using such “positive-only” EHR data that does not require gold-standard controls, provided that the labeled cases are representative of all cases. For model calibration, we propose a novel statistic that aggregates differences between model-free and model-based estimated numbers of cases across risk subgroups, which asymptotically follows a Chi-squared distribution. We additionally demonstrate that the calibration slope can also be estimated using such “positive-only” data. We propose consistent estimators for discrimination measures and derive their large sample properties. We demonstrate performances of the proposed methods through extensive simulation studies and apply them to Penn Medicine EHRs to validate two preliminary models for predicting the risk of primary aldosteronism.},
  archive      = {J_BIOSTAT},
  author       = {Zhang, Lingjiao and Ma, Yanyuan and Herman, Daniel and Chen, Jinbo},
  doi          = {10.1093/biostatistics/kxab003},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {844-859},
  shortjournal = {Biostatistics},
  title        = {Testing calibration of phenotyping models using positive-only electronic health record data},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Penalized model-based clustering of fMRI data.
<em>BIOSTAT</em>, <em>23</em>(3), 825–843. (<a
href="https://doi.org/10.1093/biostatistics/kxaa061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional magnetic resonance imaging (fMRI) data have become increasingly available and are useful for describing functional connectivity (FC), the relatedness of neuronal activity in regions of the brain. This FC of the brain provides insight into certain neurodegenerative diseases and psychiatric disorders, and thus is of clinical importance. To help inform physicians regarding patient diagnoses, unsupervised clustering of subjects based on FC is desired, allowing the data to inform us of groupings of patients based on shared features of connectivity. Since heterogeneity in FC is present even between patients within the same group, it is important to allow subject-level differences in connectivity, while still pooling information across patients within each group to describe group-level FC. To this end, we propose a random covariance clustering model (RCCM) to concurrently cluster subjects based on their FC networks, estimate the unique FC networks of each subject, and to infer shared network features. Although current methods exist for estimating FC or clustering subjects using fMRI data, our novel contribution is to cluster or group subjects based on similar FC of the brain while simultaneously providing group- and subject-level FC network estimates. The competitive performance of RCCM relative to other methods is demonstrated through simulations in various settings, achieving both improved clustering of subjects and estimation of FC networks. Utility of the proposed method is demonstrated with application to a resting-state fMRI data set collected on 43 healthy controls and 61 participants diagnosed with schizophrenia.},
  archive      = {J_BIOSTAT},
  author       = {Dilernia, Andrew and Quevedo, Karina and Camchong, Jazmin and Lim, Kelvin and Pan, Wei and Zhang, Lin},
  doi          = {10.1093/biostatistics/kxaa061},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {825-843},
  shortjournal = {Biostatistics},
  title        = {Penalized model-based clustering of fMRI data},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of the generation interval using pairwise
relative transmission probabilities. <em>BIOSTAT</em>, <em>23</em>(3),
807–824. (<a
href="https://doi.org/10.1093/biostatistics/kxaa059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generation interval (the time between infection of primary and secondary cases) and its often used proxy, the serial interval (the time between symptom onset of primary and secondary cases) are critical parameters in understanding infectious disease dynamics. Because it is difficult to determine who infected whom, these important outbreak characteristics are not well understood for many diseases. We present a novel method for estimating transmission intervals using surveillance or outbreak investigation data that, unlike existing methods, does not require a contact tracing data or pathogen whole genome sequence data on all cases. We start with an expectation maximization algorithm and incorporate relative transmission probabilities with noise reduction. We use simulations to show that our method can accurately estimate the generation interval distribution for diseases with different reproductive numbers, generation intervals, and mutation rates. We then apply our method to routinely collected surveillance data from Massachusetts (2010–2016) to estimate the serial interval of tuberculosis in this setting.},
  archive      = {J_BIOSTAT},
  author       = {Leavitt, Sarah V and Jenkins, Helen E and Sebastiani, Paola and Lee, Robyn S and Horsburgh, C Robert and Tibbs, Andrew M and White, Laura F},
  doi          = {10.1093/biostatistics/kxaa059},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {807-824},
  shortjournal = {Biostatistics},
  title        = {Estimation of the generation interval using pairwise relative transmission probabilities},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficiently transporting causal direct and indirect effects
to new populations under intermediate confounding and with multiple
mediators. <em>BIOSTAT</em>, <em>23</em>(3), 789–806. (<a
href="https://doi.org/10.1093/biostatistics/kxaa057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The same intervention can produce different effects in different sites. Existing transport mediation estimators can estimate the extent to which such differences can be explained by differences in compositional factors and the mechanisms by which mediating or intermediate variables are produced; however, they are limited to consider a single, binary mediator. We propose novel nonparametric estimators of transported interventional (in)direct effects that consider multiple, high-dimensional mediators and a single, binary intermediate variable. They are multiply robust, efficient, asymptotically normal, and can incorporate data-adaptive estimation of nuisance parameters. They can be applied to understand differences in treatment effects across sites and/or to predict treatment effects in a target site based on outcome data in source sites.},
  archive      = {J_BIOSTAT},
  author       = {Rudolph, Kara E and Díaz, Iván},
  doi          = {10.1093/biostatistics/kxaa057},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {789-806},
  shortjournal = {Biostatistics},
  title        = {Efficiently transporting causal direct and indirect effects to new populations under intermediate confounding and with multiple mediators},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Marginal modeling of cluster-period means and intraclass
correlations in stepped wedge designs with binary outcomes.
<em>BIOSTAT</em>, <em>23</em>(3), 772–788. (<a
href="https://doi.org/10.1093/biostatistics/kxaa056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stepped wedge cluster randomized trials (SW-CRTs) with binary outcomes are increasingly used in prevention and implementation studies. Marginal models represent a flexible tool for analyzing SW-CRTs with population-averaged interpretations, but the joint estimation of the mean and intraclass correlation coefficients (ICCs) can be computationally intensive due to large cluster-period sizes. Motivated by the need for marginal inference in SW-CRTs, we propose a simple and efficient estimating equations approach to analyze cluster-period means. We show that the quasi-score for the marginal mean defined from individual-level observations can be reformulated as the quasi-score for the same marginal mean defined from the cluster-period means. An additional mapping of the individual-level ICCs into correlations for the cluster-period means further provides a rigorous justification for the cluster-period approach. The proposed approach addresses a long-recognized computational burden associated with estimating equations defined based on individual-level observations, and enables fast point and interval estimation of the intervention effect and correlations. We further propose matrix-adjusted estimating equations to improve the finite-sample inference for ICCs. By providing a valid approach to estimate ICCs within the class of generalized linear models for correlated binary outcomes, this article operationalizes key recommendations from the CONSORT extension to SW-CRTs, including the reporting of ICCs.},
  archive      = {J_BIOSTAT},
  author       = {Li, Fan and Yu, Hengshi and Rathouz, Paul J and Turner, Elizabeth L and Preisser, John S},
  doi          = {10.1093/biostatistics/kxaa056},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {772-788},
  shortjournal = {Biostatistics},
  title        = {Marginal modeling of cluster-period means and intraclass correlations in stepped wedge designs with binary outcomes},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Treed distributed lag nonlinear models. <em>BIOSTAT</em>,
<em>23</em>(3), 754–771. (<a
href="https://doi.org/10.1093/biostatistics/kxaa051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In studies of maternal exposure to air pollution, a children’s health outcome is regressed on exposures observed during pregnancy. The distributed lag nonlinear model (DLNM) is a statistical method commonly implemented to estimate an exposure–time–response function when it is postulated the exposure effect is nonlinear. Previous implementations of the DLNM estimate an exposure–time–response surface parameterized with a bivariate basis expansion. However, basis functions such as splines assume smoothness across the entire exposure–time–response surface, which may be unrealistic in settings where the exposure is associated with the outcome only in a specific time window. We propose a framework for estimating the DLNM based on Bayesian additive regression trees. Our method operates using a set of regression trees that each assume piecewise constant relationships across the exposure–time space. In a simulation, we show that our model outperforms spline-based models when the exposure–time surface is not smooth, while both methods perform similarly in settings where the true surface is smooth. Importantly, the proposed approach is lower variance and more precisely identifies critical windows during which exposure is associated with a future health outcome. We apply our method to estimate the association between maternal exposures to PM |$_{2.5}$| and birth weight in a Colorado, USA birth cohort.},
  archive      = {J_BIOSTAT},
  author       = {Mork, Daniel and Wilson, Ander},
  doi          = {10.1093/biostatistics/kxaa051},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {754-771},
  shortjournal = {Biostatistics},
  title        = {Treed distributed lag nonlinear models},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semiparametric regression on cumulative incidence function
with interval-censored competing risks data and missing event types.
<em>BIOSTAT</em>, <em>23</em>(3), 738–753. (<a
href="https://doi.org/10.1093/biostatistics/kxaa052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Competing risk data are frequently interval-censored, that is, the exact event time is not observed but only known to lie between two examination time points such as clinic visits. In addition to interval censoring, another common complication is that the event type is missing for some study participants. In this article, we propose an augmented inverse probability weighted sieve maximum likelihood estimator for the analysis of interval-censored competing risk data in the presence of missing event types. The estimator imposes weaker than usual missing at random assumptions by allowing for the inclusion of auxiliary variables that are potentially associated with the probability of missingness. The proposed estimator is shown to be doubly robust, in the sense that it is consistent even if either the model for the probability of missingness or the model for the probability of the event type is misspecified. Extensive Monte Carlo simulation studies show good performance of the proposed method even under a large amount of missing event types. The method is illustrated using data from an HIV cohort study in sub-Saharan Africa, where a significant portion of events types is missing. The proposed method can be readily implemented using the new function ciregic_aipw in the R package intccr .},
  archive      = {J_BIOSTAT},
  author       = {Park, Jun and Bakoyannis, Giorgos and Zhang, Ying and Yiannoutsos, Constantin T},
  doi          = {10.1093/biostatistics/kxaa052},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {738-753},
  shortjournal = {Biostatistics},
  title        = {Semiparametric regression on cumulative incidence function with interval-censored competing risks data and missing event types},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A benchmark for dose-finding studies with unknown ordering.
<em>BIOSTAT</em>, <em>23</em>(3), 721–737. (<a
href="https://doi.org/10.1093/biostatistics/kxaa054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important tool to evaluate the performance of a dose-finding design is the nonparametric optimal benchmark that provides an upper bound on the performance of a design under a given scenario. A fundamental assumption of the benchmark is that the investigator can arrange doses in a monotonically increasing toxicity order. While the benchmark can be still applied to combination studies in which not all dose combinations can be ordered, it does not account for the uncertainty in the ordering. In this article, we propose a generalization of the benchmark that accounts for this uncertainty and, as a result, provides a sharper upper bound on the performance. The benchmark assesses how probable the occurrence of each ordering is, given the complete information about each patient. The proposed approach can be applied to trials with an arbitrary number of endpoints with discrete or continuous distributions. We illustrate the utility of the benchmark using recently proposed dose-finding designs for Phase I combination trials with a binary toxicity endpoint and Phase I/II combination trials with binary toxicity and continuous efficacy.},
  archive      = {J_BIOSTAT},
  author       = {Mozgunov, Pavel and Paoletti, Xavier and Jaki, Thomas},
  doi          = {10.1093/biostatistics/kxaa054},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {721-737},
  shortjournal = {Biostatistics},
  title        = {A benchmark for dose-finding studies with unknown ordering},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An optimal kernel-based multivariate u-statistic to test for
associations with multiple phenotypes. <em>BIOSTAT</em>, <em>23</em>(3),
705–720. (<a
href="https://doi.org/10.1093/biostatistics/kxaa049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Set-based analysis that jointly considers multiple predictors in a group has been broadly conducted for association tests. However, their power can be sensitive to the distribution of phenotypes, and the underlying relationships between predictors and outcomes. Moreover, most of the set-based methods are designed for single-trait analysis, making it hard to explore the pleiotropic effect and borrow information when multiple phenotypes are available. Here, we propose a kernel-based multivariate U-statistics (KMU) that is robust and powerful in testing the association between a set of predictors and multiple outcomes. We employed a rank-based kernel function for the outcomes, which makes our method robust to various outcome distributions. Rather than selecting a single kernel, our test statistics is built based on multiple kernels selected in a data-driven manner, and thus is capable of capturing various complex relationships between predictors and outcomes. The asymptotic properties of our test statistics have been developed. Through simulations, we have demonstrated that KMU has controlled type I error and higher power than its counterparts. We further showed its practical utility by analyzing a whole genome sequencing data from Alzheimer’s Disease Neuroimaging Initiative study, where novel genes have been detected to be associated with imaging phenotypes.},
  archive      = {J_BIOSTAT},
  author       = {Wen, Y and Lu, Qing},
  doi          = {10.1093/biostatistics/kxaa049},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {705-720},
  shortjournal = {Biostatistics},
  title        = {An optimal kernel-based multivariate U-statistic to test for associations with multiple phenotypes},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sine-skewed toroidal distributions and their application in
protein bioinformatics. <em>BIOSTAT</em>, <em>23</em>(3), 685–704. (<a
href="https://doi.org/10.1093/biostatistics/kxaa039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the bioinformatics field, there has been a growing interest in modeling dihedral angles of amino acids by viewing them as data on the torus. This has motivated, over the past years, new proposals of distributions on the torus. The main drawback of most of these models is that the related densities are (pointwise) symmetric, despite the fact that the data usually present asymmetric patterns. This motivates the need to find a new way of constructing asymmetric toroidal distributions starting from a symmetric distribution. We tackle this problem in this article by introducing the sine-skewed toroidal distributions. The general properties of the new models are derived. Based on the initial symmetric model, explicit expressions for the shape and dependence measures are obtained, a simple algorithm for generating random numbers is provided, and asymptotic results for the maximum likelihood estimators are established. An important feature of our construction is that no extra normalizing constant needs to be calculated, leading to more flexible distributions without increasing the complexity of the models. The benefit of employing these new sine-skewed toroidal distributions is shown on the basis of protein data, where, in general, the new models outperform their symmetric antecedents.},
  archive      = {J_BIOSTAT},
  author       = {Ameijeiras-Alonso, Jose and Ley, Christophe},
  doi          = {10.1093/biostatistics/kxaa039},
  journal      = {Biostatistics},
  month        = {7},
  number       = {3},
  pages        = {685-704},
  shortjournal = {Biostatistics},
  title        = {Sine-skewed toroidal distributions and their application in protein bioinformatics},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Corrigendum to: Fast lasso method for large-scale and
ultrahigh-dimensional cox model with applications to UK biobank.
<em>BIOSTAT</em>, <em>23</em>(2), 683. (<a
href="https://doi.org/10.1093/biostatistics/kxab019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIOSTAT},
  author       = {Li, Ruilin and Chang, Christopher and Justesen, Johanne M and Tanigawa, Yosuke and Qian, Junyang and Hastie, Trevor and Rivas, Manuel A and Tibshirani, Robert},
  doi          = {10.1093/biostatistics/kxab019},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {683},
  shortjournal = {Biostatistics},
  title        = {Corrigendum to: Fast lasso method for large-scale and ultrahigh-dimensional cox model with applications to UK biobank},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantifying diagnostic accuracy improvement of new
biomarkers for competing risk outcomes. <em>BIOSTAT</em>,
<em>23</em>(2), 666–682. (<a
href="https://doi.org/10.1093/biostatistics/kxaa048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The net reclassification improvement (NRI) and the integrated discrimination improvement (IDI) were originally proposed to characterize accuracy improvement in predicting a binary outcome, when new biomarkers are added to regression models. These two indices have been extended from binary outcomes to multi-categorical and survival outcomes. Working on an AIDS study where the onset of cognitive impairment is competing risk censored by death, we extend the NRI and the IDI to competing risk outcomes, by using cumulative incidence functions to quantify cumulative risks of competing events, and adopting the definitions of the two indices for multi-category outcomes. The “missing” category due to independent censoring is handled through inverse probability weighting. Various competing risk models are considered, such as the Fine and Gray, multistate, and multinomial logistic models. Estimation methods for the NRI and the IDI from competing risk data are presented. The inference for the NRI is constructed based on asymptotic normality of its estimator, and the bias-corrected and accelerated bootstrap procedure is used for the IDI. Simulations demonstrate that the proposed inferential procedures perform very well. The Multicenter AIDS Cohort Study is used to illustrate the practical utility of the extended NRI and IDI for competing risk outcomes.},
  archive      = {J_BIOSTAT},
  author       = {Wang, Zheng and Cheng, Yu and Seaberg, Eric C and Becker, James T},
  doi          = {10.1093/biostatistics/kxaa048},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {666-682},
  shortjournal = {Biostatistics},
  title        = {Quantifying diagnostic accuracy improvement of new biomarkers for competing risk outcomes},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dose–response modeling in high-throughput cancer drug
screenings: An end-to-end approach. <em>BIOSTAT</em>, <em>23</em>(2),
643–665. (<a
href="https://doi.org/10.1093/biostatistics/kxaa047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized cancer treatments based on the molecular profile of a patient’s tumor are an emerging and exciting class of treatments in oncology. As genomic tumor profiling is becoming more common, targeted treatments for specific molecular alterations are gaining traction. To discover new potential therapeutics that may apply to broad classes of tumors matching some molecular pattern, experimentalists and pharmacologists rely on high-throughput, in vitro screens of many compounds against many different cell lines. We propose a hierarchical Bayesian model of how cancer cell lines respond to drugs in these experiments and develop a method for fitting the model to real-world high-throughput screening data. Through a case study, the model is shown to capture nontrivial associations between molecular features and drug response, such as requiring both wild type TP53 and overexpression of MDM2 to be sensitive to Nutlin-3(a). In quantitative benchmarks, the model outperforms a standard approach in biology, with |$\approx20\%$| lower predictive error on held out data. When combined with a conditional randomization testing procedure, the model discovers markers of therapeutic response that recapitulate known biology and suggest new avenues for investigation. All code for the article is publicly available at https://github.com/tansey/deep-dose-response .},
  archive      = {J_BIOSTAT},
  author       = {Tansey, Wesley and Li, Kathy and Zhang, Haoran and Linderman, Scott W and Rabadan, Raul and Blei, David M and Wiggins, Chris H},
  doi          = {10.1093/biostatistics/kxaa047},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {643-665},
  shortjournal = {Biostatistics},
  title        = {Dose–response modeling in high-throughput cancer drug screenings: An end-to-end approach},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Principal curve approaches for inferring 3D chromatin
architecture. <em>BIOSTAT</em>, <em>23</em>(2), 626–642. (<a
href="https://doi.org/10.1093/biostatistics/kxaa046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) genome spatial organization is critical for numerous cellular processes, including transcription, while certain conformation-driven structural alterations are frequently oncogenic. Genome architecture had been notoriously difficult to elucidate, but the advent of the suite of chromatin conformation capture assays, notably Hi-C, has transformed understanding of chromatin structure and provided downstream biological insights. Although many findings have flowed from direct analysis of the pairwise proximity data produced by these assays, there is added value in generating corresponding 3D reconstructions deriving from superposing genomic features on the reconstruction. Accordingly, many methods for inferring 3D architecture from proximity data have been advanced. However, none of these approaches exploit the fact that single chromosome solutions constitute a one-dimensional (1D) curve in 3D. Rather, this aspect has either been addressed by imposition of constraints, which is both computationally burdensome and cell type specific, or ignored with contiguity imposed after the fact. Here, we target finding a 1D curve by extending principal curve methodology to the metric scaling problem. We illustrate how this approach yields a sequence of candidate solutions, indexed by an underlying smoothness or degrees-of-freedom parameter, and propose methods for selection from this sequence. We apply the methodology to Hi-C data obtained on IMR90 cells and so are positioned to evaluate reconstruction accuracy by referencing orthogonal imaging data. The results indicate the utility and reproducibility of our principal curve approach in the face of underlying structural variation.},
  archive      = {J_BIOSTAT},
  author       = {Tuzhilina, Elena and Hastie, Trevor J and Segal, Mark R},
  doi          = {10.1093/biostatistics/kxaa046},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {626-642},
  shortjournal = {Biostatistics},
  title        = {Principal curve approaches for inferring 3D chromatin architecture},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient and robust approach to mendelian randomization
with measured pleiotropic effects in a high-dimensional setting.
<em>BIOSTAT</em>, <em>23</em>(2), 609–625. (<a
href="https://doi.org/10.1093/biostatistics/kxaa045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Valid estimation of a causal effect using instrumental variables requires that all of the instruments are independent of the outcome conditional on the risk factor of interest and any confounders. In Mendelian randomization studies with large numbers of genetic variants used as instruments, it is unlikely that this condition will be met. Any given genetic variant could be associated with a large number of traits, all of which represent potential pathways to the outcome which bypass the risk factor of interest. Such pleiotropy can be accounted for using standard multivariable Mendelian randomization with all possible pleiotropic traits included as covariates. However, the estimator obtained in this way will be inefficient if some of the covariates do not truly sit on pleiotropic pathways to the outcome. We present a method that uses regularization to identify which out of a set of potential covariates need to be accounted for in a Mendelian randomization analysis in order to produce an efficient and robust estimator of a causal effect. The method can be used in the case where individual-level data are not available and the analysis must rely on summary-level data only. It can be used where there are any number of potential pleiotropic covariates up to the number of genetic variants less one. We show the results of simulation studies that demonstrate the performance of the proposed regularization method in realistic settings. We also illustrate the method in an applied example which looks at the causal effect of urate plasma concentration on coronary heart disease.},
  archive      = {J_BIOSTAT},
  author       = {Grant, Andrew J and Burgess, Stephen},
  doi          = {10.1093/biostatistics/kxaa045},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {609-625},
  shortjournal = {Biostatistics},
  title        = {An efficient and robust approach to mendelian randomization with measured pleiotropic effects in a high-dimensional setting},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian design of clinical trials using joint models for
longitudinal and time-to-event data. <em>BIOSTAT</em>, <em>23</em>(2),
591–608. (<a
href="https://doi.org/10.1093/biostatistics/kxaa044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint models for longitudinal and time-to-event data are increasingly used for the analysis of clinical trial data. However, few methods have been proposed for designing clinical trials using these models. In this article, we develop a Bayesian clinical trial design methodology focused on evaluating the treatment’s effect on the time-to-event endpoint using a flexible trajectory joint model. By incorporating the longitudinal outcome trajectory into the hazard model for the time-to-event endpoint, the joint modeling framework allows for non-proportional hazards (e.g., an increasing hazard ratio over time). Inference for the time-to-event endpoint is based on an average of a time-varying hazard ratio which can be decomposed according to the treatment’s direct effect on the time-to-event endpoint and its indirect effect, mediated through the longitudinal outcome. We propose an approach for sample size determination for a trial such that the design has high power and a well-controlled type I error rate with both operating characteristics defined from a Bayesian perspective. We demonstrate the methodology by designing a breast cancer clinical trial with a primary time-to-event endpoint and where predictive longitudinal outcome measures are also collected periodically during follow-up.},
  archive      = {J_BIOSTAT},
  author       = {Xu, Jiawei and Psioda, Matthew A and Ibrahim, Joseph G},
  doi          = {10.1093/biostatistics/kxaa044},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {591-608},
  shortjournal = {Biostatistics},
  title        = {Bayesian design of clinical trials using joint models for longitudinal and time-to-event data},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrative functional linear model for genome-wide
association studies with multiple traits. <em>BIOSTAT</em>,
<em>23</em>(2), 574–590. (<a
href="https://doi.org/10.1093/biostatistics/kxaa043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent biomedical research, genome-wide association studies (GWAS) have demonstrated great success in investigating the genetic architecture of human diseases. For many complex diseases, multiple correlated traits have been collected. However, most of the existing GWAS are still limited because they analyze each trait separately without considering their correlations and suffer from a lack of sufficient information. Moreover, the high dimensionality of single nucleotide polymorphism (SNP) data still poses tremendous challenges to statistical methods, in both theoretical and practical aspects. In this article, we innovatively propose an integrative functional linear model for GWAS with multiple traits. This study is the first to approximate SNPs as functional objects in a joint model of multiple traits with penalization techniques. It effectively accommodates the high dimensionality of SNPs and correlations among multiple traits to facilitate information borrowing. Our extensive simulation studies demonstrate the satisfactory performance of the proposed method in the identification and estimation of disease-associated genetic variants, compared to four alternatives. The analysis of type 2 diabetes data leads to biologically meaningful findings with good prediction accuracy and selection stability.},
  archive      = {J_BIOSTAT},
  author       = {Li, Yang and Wang, Fan and Wu, Mengyun and Ma, Shuangge},
  doi          = {10.1093/biostatistics/kxaa043},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {574-590},
  shortjournal = {Biostatistics},
  title        = {Integrative functional linear model for genome-wide association studies with multiple traits},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian analysis of longitudinal and multidimensional
functional data. <em>BIOSTAT</em>, <em>23</em>(2), 558–573. (<a
href="https://doi.org/10.1093/biostatistics/kxaa041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-dimensional functional data arises in numerous modern scientific experimental and observational studies. In this article, we focus on longitudinal functional data, a structured form of multidimensional functional data. Operating within a longitudinal functional framework we aim to capture low dimensional interpretable features. We propose a computationally efficient nonparametric Bayesian method to simultaneously smooth observed data, estimate conditional functional means and functional covariance surfaces. Statistical inference is based on Monte Carlo samples from the posterior measure through adaptive blocked Gibbs sampling. Several operative characteristics associated with the proposed modeling framework are assessed comparatively in a simulated environment. We illustrate the application of our work in two case studies. The first case study involves age-specific fertility collected over time for various countries. The second case study is an implicit learning experiment in children with autism spectrum disorder.},
  archive      = {J_BIOSTAT},
  author       = {Shamshoian, John and Şentürk, Damla and Jeste, Shafali and Telesca, Donatello},
  doi          = {10.1093/biostatistics/kxaa041},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {558-573},
  shortjournal = {Biostatistics},
  title        = {Bayesian analysis of longitudinal and multidimensional functional data},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation of treatment effect modification by biomarkers
measured pre- and post-randomization in the presence of non-monotone
missingness. <em>BIOSTAT</em>, <em>23</em>(2), 541–557. (<a
href="https://doi.org/10.1093/biostatistics/kxaa040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In vaccine studies, an important research question is to study effect modification of clinical treatment efficacy by intermediate biomarker-based principal strata. In settings where participants entering a trial may have prior exposure and therefore variable baseline biomarker values, clinical treatment efficacy may further depend jointly on a biomarker measured at baseline and measured at a fixed time after vaccination. This makes it important to conduct a bivariate effect modification analysis by both the intermediate biomarker-based principal strata and the baseline biomarker values. Existing research allows this assessment if the sampling of baseline and intermediate biomarkers follows a monotone pattern, i.e., if participants who have the biomarker measured post-randomization would also have the biomarker measured at baseline. However, additional complications in study design could happen in practice. For example, in a dengue correlates study, baseline biomarker values were only available from a fraction of participants who have biomarkers measured post-randomization. How to conduct the bivariate effect modification analysis in these studies remains an open research question. In this article, we propose approaches for bivariate effect modification analysis in the complicated sampling design based on an estimated likelihood framework. We demonstrate advantages of the proposed method over existing methods through numerical studies and illustrate our method with data sets from two phase 3 dengue vaccine efficacy trials.},
  archive      = {J_BIOSTAT},
  author       = {Zhuang, Yingying and Huang, Ying and Gilbert, Peter B},
  doi          = {10.1093/biostatistics/kxaa040},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {541-557},
  shortjournal = {Biostatistics},
  title        = {Evaluation of treatment effect modification by biomarkers measured pre- and post-randomization in the presence of non-monotone missingness},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Fast lasso method for large-scale and ultrahigh-dimensional
cox model with applications to UK biobank. <em>BIOSTAT</em>,
<em>23</em>(2), 522–540. (<a
href="https://doi.org/10.1093/biostatistics/kxaa038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a scalable and highly efficient algorithm to fit a Cox proportional hazard model by maximizing the |$L^1$| -regularized (Lasso) partial likelihood function, based on the Batch Screening Iterative Lasso (BASIL) method developed in Qian and others (2019) . Our algorithm is particularly suitable for large-scale and high-dimensional data that do not fit in the memory. The output of our algorithm is the full Lasso path, the parameter estimates at all predefined regularization parameters, as well as their validation accuracy measured using the concordance index (C-index) or the validation deviance. To demonstrate the effectiveness of our algorithm, we analyze a large genotype-survival time dataset across 306 disease outcomes from the UK Biobank ( Sudlow and others , 2015 ). We provide a publicly available implementation of the proposed approach for genetics data on top of the PLINK2 package and name it snpnet-Cox.},
  archive      = {J_BIOSTAT},
  author       = {Li, Ruilin and Chang, Christopher and Justesen, Johanne M and Tanigawa, Yosuke and Qian, Junyang and Hastie, Trevor and Rivas, Manuel A and Tibshirani, Robert},
  doi          = {10.1093/biostatistics/kxaa038},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {522-540},
  shortjournal = {Biostatistics},
  title        = {Fast lasso method for large-scale and ultrahigh-dimensional cox model with applications to UK biobank},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Immune correlates analysis using vaccinees from test
negative designs. <em>BIOSTAT</em>, <em>23</em>(2), 507–521. (<a
href="https://doi.org/10.1093/biostatistics/kxaa037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining the effect of vaccine-induced immune response on disease risk is an important goal of vaccinology. Typically, immune correlates analyses are conducted prospectively with immune response measured shortly after vaccination and subsequent disease status regressed on immune response. In outbreaks and rare disease settings, collecting samples from all vaccinees is not feasible. The test negative design is a retrospective design used to measure vaccine efficacy where symptomatic individuals who present at a clinic are assessed for relevant disease (cases) or some other disease (controls) and vaccination status ascertained. This article proposes that test negative vaccinees have immune response to vaccine assessed both for relevant (e.g., Ebola) and irrelevant (e.g., vector) proteins. If the latter immune response is unaffected by active (Ebola) infection, and is correlated with the relevant immune response, it can serve as a proxy for the immune response of interest proximal to infection. We show that logistic regression using imputed immune response as the covariate and case disease as outcome can estimate the prospective immune response slope and detail the assumptions needed for unbiased inference. The method is evaluated by simulation under various scenarios including constant and decaying immune response. A simulated dataset motivated by ring vaccination for an ongoing Ebola outbreak is analyzed.},
  archive      = {J_BIOSTAT},
  author       = {Follmann, Dean A and Dodd, Lori},
  doi          = {10.1093/biostatistics/kxaa037},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {507-521},
  shortjournal = {Biostatistics},
  title        = {Immune correlates analysis using vaccinees from test negative designs},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interim recruitment prediction for multi-center clinical
trials. <em>BIOSTAT</em>, <em>23</em>(2), 485–506. (<a
href="https://doi.org/10.1093/biostatistics/kxaa036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a general framework for monitoring, modeling, and predicting the recruitment to multi-center clinical trials. The work is motivated by overly optimistic and narrow prediction intervals produced by existing time-homogeneous recruitment models for multi-center recruitment. We first present two tests for detection of decay in recruitment rates, together with a power study. We then introduce a model based on the inhomogeneous Poisson process with monotonically decaying intensity, motivated by recruitment trends observed in oncology trials. The general form of the model permits adaptation to any parametric curve-shape. A general method for constructing sensible parameter priors is provided and Bayesian model averaging is used for making predictions which account for the uncertainty in both the parameters and the model. The validity of the method and its robustness to misspecification are tested using simulated datasets. The new methodology is then applied to oncology trial data, where we make interim accrual predictions, comparing them to those obtained by existing methods, and indicate where unexpected changes in the accrual pattern occur.},
  archive      = {J_BIOSTAT},
  author       = {Urbas, Szymon and Sherlock, Chris and Metcalfe, Paul},
  doi          = {10.1093/biostatistics/kxaa036},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {485-506},
  shortjournal = {Biostatistics},
  title        = {Interim recruitment prediction for multi-center clinical trials},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian sparse heritability analysis with high-dimensional
neuroimaging phenotypes. <em>BIOSTAT</em>, <em>23</em>(2), 467–484. (<a
href="https://doi.org/10.1093/biostatistics/kxaa035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heritability analysis plays a central role in quantitative genetics to describe genetic contribution to human complex traits and prioritize downstream analyses under large-scale phenotypes. Existing works largely focus on modeling single phenotype and currently available multivariate phenotypic methods often suffer from scaling and interpretation. In this article, motivated by understanding how genetic underpinning impacts human brain variation, we develop an integrative Bayesian heritability analysis to jointly estimate heritabilities for high-dimensional neuroimaging traits. To induce sparsity and incorporate brain anatomical configuration, we impose hierarchical selection among both regional and local measurements based on brain structural network and voxel dependence. We also use a nonparametric Dirichlet process mixture model to realize grouping among single nucleotide polymorphism-associated phenotypic variations, providing biological plausibility. Through extensive simulations, we show the proposed method outperforms existing ones in heritability estimation and heritable traits selection under various scenarios. We finally apply the method to two large-scale imaging genetics datasets: the Alzheimer’s Disease Neuroimaging Initiative and United Kingdom Biobank and show biologically meaningful results.},
  archive      = {J_BIOSTAT},
  author       = {Zhao, Yize and Li, Tengfei and Zhu, Hongtu},
  doi          = {10.1093/biostatistics/kxaa035},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {467-484},
  shortjournal = {Biostatistics},
  title        = {Bayesian sparse heritability analysis with high-dimensional neuroimaging phenotypes},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The role of body mass index at diagnosis of colorectal
cancer on black–white disparities in survival: A density regression
mediation approach. <em>BIOSTAT</em>, <em>23</em>(2), 449–466. (<a
href="https://doi.org/10.1093/biostatistics/kxaa034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of racial/ethnic inequalities in health is important to reduce the uneven burden of disease. In the case of colorectal cancer (CRC), disparities in survival among non-Hispanic Whites and Blacks are well documented, and mechanisms leading to these disparities need to be studied formally. It has also been established that body mass index (BMI) is a risk factor for developing CRC, and recent literature shows BMI at diagnosis of CRC is associated with survival. Since BMI varies by racial/ethnic group, a question that arises is whether differences in BMI are partially responsible for observed racial/ethnic disparities in survival for CRC patients. This article presents new methodology to quantify the impact of the hypothetical intervention that matches the BMI distribution in the Black population to a potentially complex distributional form observed in the White population on racial/ethnic disparities in survival. Our density mediation approach can be utilized to estimate natural direct and indirect effects in the general causal mediation setting under stronger assumptions. We perform a simulation study that shows our proposed Bayesian density regression approach performs as well as or better than current methodology allowing for a shift in the mean of the distribution only, and that standard practice of categorizing BMI leads to large biases when BMI is a mediator variable. When applied to motivating data from the Cancer Care Outcomes Research and Surveillance (CanCORS) Consortium, our approach suggests the proposed intervention is potentially beneficial for elderly and low-income Black patients, yet harmful for young or high-income Black populations.},
  archive      = {J_BIOSTAT},
  author       = {Devick, Katrina L and Valeri, Linda and Chen, Jarvis and Jara, Alejandro and Bind, Marie-Abèle and Coull, Brent A},
  doi          = {10.1093/biostatistics/kxaa034},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {449-466},
  shortjournal = {Biostatistics},
  title        = {The role of body mass index at diagnosis of colorectal cancer on Black–White disparities in survival: A density regression mediation approach},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive treatment strategies for chronic conditions:
Shared-parameter g-estimation with an application to rheumatoid
arthritis. <em>BIOSTAT</em>, <em>23</em>(2), 430–448. (<a
href="https://doi.org/10.1093/biostatistics/kxaa033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most estimation algorithms for adaptive treatment strategies assume that treatment rules at each decision point are independent from one another in the sense that they do not possess any common parameters. This is often unrealistic, as the same decisions may be made repeatedly over time. Sharing treatment-decision parameters across decision points offers several advantages, including estimation of fewer parameters and the clinical ease of a single, time-invariant decision to implement. We propose a new computational approach to estimation of shared-parameter G-estimation, which is efficient and shares the double robustness of the “unshared” sequential G-estimation. We use this approach to analyze data from the Scottish Early Rheumatoid Arthritis (SERA) Inception Cohort.},
  archive      = {J_BIOSTAT},
  author       = {Wang, Shouao and Moodie, Erica Em and Stephens, David A and Nijjar, Jagtar S},
  doi          = {10.1093/biostatistics/kxaa033},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {430-448},
  shortjournal = {Biostatistics},
  title        = {Adaptive treatment strategies for chronic conditions: Shared-parameter G-estimation with an application to rheumatoid arthritis},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A sparse additive model for treatment effect-modifier
selection. <em>BIOSTAT</em>, <em>23</em>(2), 412–429. (<a
href="https://doi.org/10.1093/biostatistics/kxaa032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse additive modeling is a class of effective methods for performing high-dimensional nonparametric regression. This article develops a sparse additive model focused on estimation of treatment effect modification with simultaneous treatment effect-modifier selection. We propose a version of the sparse additive model uniquely constrained to estimate the interaction effects between treatment and pretreatment covariates, while leaving the main effects of the pretreatment covariates unspecified. The proposed regression model can effectively identify treatment effect-modifiers that exhibit possibly nonlinear interactions with the treatment variable that are relevant for making optimal treatment decisions. A set of simulation experiments and an application to a dataset from a randomized clinical trial are presented to demonstrate the method.},
  archive      = {J_BIOSTAT},
  author       = {Park, Hyung and Petkova, Eva and Tarpey, Thaddeus and Ogden, R Todd},
  doi          = {10.1093/biostatistics/kxaa032},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {412-429},
  shortjournal = {Biostatistics},
  title        = {A sparse additive model for treatment effect-modifier selection},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A divide-and-conquer method for sparse risk prediction and
evaluation. <em>BIOSTAT</em>, <em>23</em>(2), 397–411. (<a
href="https://doi.org/10.1093/biostatistics/kxaa031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Divide-and-conquer (DAC) is a commonly used strategy to overcome the challenges of extraordinarily large data, by first breaking the dataset into series of data blocks, then combining results from individual data blocks to obtain a final estimation. Various DAC algorithms have been proposed to fit a sparse predictive regression model in the |$L_1$| regularization setting. However, many existing DAC algorithms remain computationally intensive when sample size and number of candidate predictors are both large. In addition, no existing DAC procedures provide inference for quantifying the accuracy of risk prediction models. In this article, we propose a screening and one-step linearization infused DAC (SOLID) algorithm to fit sparse logistic regression to massive datasets, by integrating the DAC strategy with a screening step and sequences of linearization. This enables us to maximize the likelihood with only selected covariates and perform penalized estimation via a fast approximation to the likelihood. To assess the accuracy of a predictive regression model, we develop a modified cross-validation (MCV) that utilizes the side products of the SOLID, substantially reducing the computational burden. Compared with existing DAC methods, the MCV procedure is the first to make inference on accuracy. Extensive simulation studies suggest that the proposed SOLID and MCV procedures substantially outperform the existing methods with respect to computational speed and achieve similar statistical efficiency as the full sample-based estimator. We also demonstrate that the proposed inference procedure provides valid interval estimators. We apply the proposed SOLID procedure to develop and validate a classification model for disease diagnosis using narrative clinical notes based on electronic medical record data from Partners HealthCare.},
  archive      = {J_BIOSTAT},
  author       = {Hong, Chuan and Wang, Yan and Cai, Tianxi},
  doi          = {10.1093/biostatistics/kxaa031},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {397-411},
  shortjournal = {Biostatistics},
  title        = {A divide-and-conquer method for sparse risk prediction and evaluation},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). General tests of the markov property in multi-state models.
<em>BIOSTAT</em>, <em>23</em>(2), 380–396. (<a
href="https://doi.org/10.1093/biostatistics/kxaa030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-state models for event history analysis most commonly assume the process is Markov. This article considers tests of the Markov assumption that are applicable to general multi-state models. Two approaches using existing methodology are considered; a simple method based on including time of entry into each state as a covariate in Cox models for the transition intensities and a method involving detecting a shared frailty through a stratified Commenges–Andersen test. In addition, using the principle that under a Markov process the future rate of transitions of the process at times |$t &gt; s$| should not be influenced by the state occupied at time |$s$|⁠ , a new class of general tests is developed by considering summaries from families of log-rank statistics where patients are grouped by the state occupied at varying initial time |$s$|⁠ . An extended form of the test applicable to models that are Markov conditional on observed covariates is also derived. The null distribution of the proposed test statistics are approximated by using wild bootstrap sampling. The approaches are compared in simulation and applied to a dataset on sleeping behavior. The most powerful test depends on the particular departure from a Markov process, although the Cox-based method maintained good power in a wide range of scenarios. The proposed class of log-rank statistic based tests are most useful in situations where the non-Markov behavior does not persist, or is not uniform in nature across patient time.},
  archive      = {J_BIOSTAT},
  author       = {Titman, Andrew C and Putter, Hein},
  doi          = {10.1093/biostatistics/kxaa030},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {380-396},
  shortjournal = {Biostatistics},
  title        = {General tests of the markov property in multi-state models},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Individualized multi-omic pathway deviation scores using
multiple factor analysis. <em>BIOSTAT</em>, <em>23</em>(2), 362–379. (<a
href="https://doi.org/10.1093/biostatistics/kxaa029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malignant progression of normal tissue is typically driven by complex networks of somatic changes, including genetic mutations, copy number aberrations, epigenetic changes, and transcriptional reprogramming. To delineate aberrant multi-omic tumor features that correlate with clinical outcomes, we present a novel pathway-centric tool based on the multiple factor analysis framework called padma . Using a multi-omic consensus representation, padma quantifies and characterizes individualized pathway-specific multi-omic deviations and their underlying drivers, with respect to the sampled population. We demonstrate the utility of padma to correlate patient outcomes with complex genetic, epigenetic, and transcriptomic perturbations in clinically actionable pathways in breast and lung cancer.},
  archive      = {J_BIOSTAT},
  author       = {Rau, Andrea and Manansala, Regina and Flister, Michael J and Rui, Hallgeir and Jaffrézic, Florence and Laloë, Denis and Auer, Paul L},
  doi          = {10.1093/biostatistics/kxaa029},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {362-379},
  shortjournal = {Biostatistics},
  title        = {Individualized multi-omic pathway deviation scores using multiple factor analysis},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Surrogate-guided sampling designs for classification of rare
outcomes from electronic medical records data. <em>BIOSTAT</em>,
<em>23</em>(2), 345–361. (<a
href="https://doi.org/10.1093/biostatistics/kxaa028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scalable and accurate identification of specific clinical outcomes has been enabled by machine-learning applied to electronic medical record systems. The development of classification models requires the collection of a complete labeled data set, where true clinical outcomes are obtained by human expert manual review. For example, the development of natural language processing algorithms requires the abstraction of clinical text data to obtain outcome information necessary for training models. However, if the outcome is rare then simple random sampling results in very few cases and insufficient information to develop accurate classifiers. Since large scale detailed abstraction is often expensive, time-consuming, and not feasible, more efficient strategies are needed. Under such resource constrained settings, we propose a class of enrichment sampling designs, where selection for abstraction is stratified by auxiliary variables related to the true outcome of interest. Stratified sampling on highly specific variables results in targeted samples that are more enriched with cases, which we show translates to increased model discrimination and better statistical learning performance. We provide mathematical details and simulation evidence that links sampling designs to their resulting prediction model performance. We discuss the impact of our proposed sampling on both model training and validation. Finally, we illustrate the proposed designs for outcome label collection and subsequent machine-learning, using radiology report text data from the Lumbar Imaging with Reporting of Epidemiology study.},
  archive      = {J_BIOSTAT},
  author       = {Tan, W Katherine and Heagerty, Patrick J},
  doi          = {10.1093/biostatistics/kxaa028},
  journal      = {Biostatistics},
  month        = {4},
  number       = {2},
  pages        = {345-361},
  shortjournal = {Biostatistics},
  title        = {Surrogate-guided sampling designs for classification of rare outcomes from electronic medical records data},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A decision-theoretic approach to bayesian clinical trial
design and evaluation of robustness to prior-data conflict.
<em>BIOSTAT</em>, <em>23</em>(1), 328–344. (<a
href="https://doi.org/10.1093/biostatistics/kxaa027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian clinical trials allow taking advantage of relevant external information through the elicitation of prior distributions, which influence Bayesian posterior parameter estimates and test decisions. However, incorporation of historical information can have harmful consequences on the trial’s frequentist (conditional) operating characteristics in case of inconsistency between prior information and the newly collected data. A compromise between meaningful incorporation of historical information and strict control of frequentist error rates is therefore often sought. Our aim is thus to review and investigate the rationale and consequences of different approaches to relaxing strict frequentist control of error rates from a Bayesian decision-theoretic viewpoint. In particular, we define an integrated risk which incorporates losses arising from testing, estimation, and sampling. A weighted combination of the integrated risk addends arising from testing and estimation allows moving smoothly between these two targets. Furthermore, we explore different possible elicitations of the test error costs, leading to test decisions based either on posterior probabilities, or solely on Bayes factors. Sensitivity analyses are performed following the convention which makes a distinction between the prior of the data-generating process, and the analysis prior adopted to fit the data. Simulation in the case of normal and binomial outcomes and an application to a one-arm proof-of-concept trial, exemplify how such analysis can be conducted to explore sensitivity of the integrated risk, the operating characteristics, and the optimal sample size, to prior-data conflict. Robust analysis prior specifications, which gradually discount potentially conflicting prior information, are also included for comparison. Guidance with respect to cost elicitation, particularly in the context of a Phase II proof-of-concept trial, is provided.},
  archive      = {J_BIOSTAT},
  author       = {Calderazzo, Silvia and Wiesenfarth, Manuel and Kopp-Schneider, Annette},
  doi          = {10.1093/biostatistics/kxaa027},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {328-344},
  shortjournal = {Biostatistics},
  title        = {A decision-theoretic approach to bayesian clinical trial design and evaluation of robustness to prior-data conflict},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient model-based bioequivalence testing.
<em>BIOSTAT</em>, <em>23</em>(1), 314–327. (<a
href="https://doi.org/10.1093/biostatistics/kxaa026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical approach to analyze pharmacokinetic (PK) data in bioequivalence studies aiming to compare two different formulations is to perform noncompartmental analysis (NCA) followed by two one-sided tests (TOST). In this regard, the PK parameters area under the curve (AUC) and |$C_{\max}$| are obtained for both treatment groups and their geometric mean ratios are considered. According to current guidelines by the U.S. Food and Drug Administration and the European Medicines Agency, the formulations are declared to be sufficiently similar if the |$90\%$| confidence interval for these ratios falls between |$0.8$| and |$1.25 $|⁠ . As NCA is not a reliable approach in case of sparse designs, a model-based alternative has already been proposed for the estimation of |$\rm AUC$| and |$C_{\max}$| using nonlinear mixed effects models. Here we propose another, more powerful test than the TOST and demonstrate its superiority through a simulation study both for NCA and model-based approaches. For products with high variability on PK parameters, this method appears to have closer type I errors to the conventionally accepted significance level of |$0.05$|⁠ , suggesting its potential use in situations where conventional bioequivalence analysis is not applicable.},
  archive      = {J_BIOSTAT},
  author       = {Möllenhoff, Kathrin and Loingeville, Florence and Bertrand, Julie and Nguyen, Thu Thuy and Sharan, Satish and Zhao, Liang and Fang, Lanyan and Sun, Guoying and Grosser, Stella and Mentré, France and Dette, Holger},
  doi          = {10.1093/biostatistics/kxaa026},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {314-327},
  shortjournal = {Biostatistics},
  title        = {Efficient model-based bioequivalence testing},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint modeling and multiple comparisons with the best of
data from a SMART with survival outcomes. <em>BIOSTAT</em>,
<em>23</em>(1), 294–313. (<a
href="https://doi.org/10.1093/biostatistics/kxaa025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A dynamic treatment regimen (DTR) is a sequence of decision rules that can alter treatments or doses based on outcomes from prior treatment. In the case of two lines of treatment, a DTR specifies first-line treatment, and second-line treatment for responders and treatment for non-responders to the first-line treatment. A sequential, multiple assignment, randomized trial (SMART) is one such type of trial that has been designed to assess DTRs. The primary goal of our project is to identify the treatments, covariates, and their interactions result in the best overall survival rate. Many previously proposed methods to analyze data with survival outcomes from a SMART use inverse probability weighting and provide non-parametric estimation of survival rates, but no other information. Other methods have been proposed to identify and estimate the optimal DTR, but inference issues were seldom addressed. We apply a joint modeling approach to provide unbiased survival estimates as a mechanism to quantify baseline and time-varying covariate effects, treatment effects, and their interactions within regimens. The issue of multiple comparisons at specific time points is addressed using multiple comparisons with the best method.},
  archive      = {J_BIOSTAT},
  author       = {Chao, Yan-Cheng and Tran, Qui and Tsodikov, Alex and Kidwell, Kelley M},
  doi          = {10.1093/biostatistics/kxaa025},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {294-313},
  shortjournal = {Biostatistics},
  title        = {Joint modeling and multiple comparisons with the best of data from a SMART with survival outcomes},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonparametric targeted bayesian estimation of class
proportions in unlabeled data. <em>BIOSTAT</em>, <em>23</em>(1),
274–293. (<a
href="https://doi.org/10.1093/biostatistics/kxaa022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel Bayesian estimator for the class proportion in an unlabeled dataset, based on the targeted learning framework. The procedure requires the specification of a prior (and outputs a posterior) only for the target of inference, and yields a tightly concentrated posterior. When the scientific question can be characterized by a low-dimensional parameter functional, this focus on target prior and posterior distributions perfectly aligns with Bayesian subjectivism. We prove a Bernstein–von Mises-type result for our proposed Bayesian procedure, which guarantees that the posterior distribution converges to the distribution of an efficient, asymptotically linear estimator. In particular, the posterior is Gaussian, doubly robust, and efficient in the limit, under the only assumption that certain nuisance parameters are estimated at slower-than-parametric rates. We perform numerical studies illustrating the frequentist properties of the method. We also illustrate their use in a motivating application to estimate the proportion of embolic strokes of undetermined source arising from occult cardiac sources or large-artery atherosclerotic lesions. Though we focus on the motivating example of the proportion of cases in an unlabeled dataset, the procedure is general and can be adapted to estimate any pathwise differentiable parameter in a non-parametric model.},
  archive      = {J_BIOSTAT},
  author       = {Díaz, Iván and Savenkov, Oleksander and Kamel, Hooman},
  doi          = {10.1093/biostatistics/kxaa022},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {274-293},
  shortjournal = {Biostatistics},
  title        = {Nonparametric targeted bayesian estimation of class proportions in unlabeled data},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Accounting for total variation and robustness in profiling
health care providers. <em>BIOSTAT</em>, <em>23</em>(1), 257–273. (<a
href="https://doi.org/10.1093/biostatistics/kxaa024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring outcomes of health care providers, such as patient deaths, hospitalizations, and hospital readmissions, helps in assessing the quality of health care. We consider a large database on patients being treated at dialysis facilities in the United States, and the problem of identifying facilities with outcomes that are better than or worse than expected. Analyses of such data have been commonly based on random or fixed facility effects, which have shortcomings that can lead to unfair assessments. A primary issue is that they do not appropriately account for variation between providers that is outside the providers’ control due, for example, to unobserved patient characteristics that vary between providers. In this article, we propose a smoothed empirical null approach that accounts for the total variation and adapts to different provider sizes. The linear model provides an illustration that extends easily to other non-linear models for survival or binary outcomes, for example. The empirical null method is generalized to allow for some variation being due to quality of care. These methods are examined with numerical simulations and applied to the monitoring of survival in the dialysis facility data.},
  archive      = {J_BIOSTAT},
  author       = {Xia, Lu and He, Kevin and Li, Yanming and Kalbfleisch, John},
  doi          = {10.1093/biostatistics/kxaa024},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {257-273},
  shortjournal = {Biostatistics},
  title        = {Accounting for total variation and robustness in profiling health care providers},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiway generalized canonical correlation analysis.
<em>BIOSTAT</em>, <em>23</em>(1), 240–256. (<a
href="https://doi.org/10.1093/biostatistics/kxaa010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regularized generalized canonical correlation analysis (RGCCA) is a general multiblock data analysis framework that encompasses several important multivariate analysis methods such as principal component analysis, partial least squares regression, and several versions of generalized canonical correlation analysis. In this article, we extend RGCCA to the case where at least one block has a tensor structure. This method is called multiway generalized canonical correlation analysis (MGCCA). Convergence properties of the MGCCA algorithm are studied, and computation of higher-level components are discussed. The usefulness of MGCCA is shown on simulation and on the analysis of a cognitive study in human infants using electroencephalography (EEG).},
  archive      = {J_BIOSTAT},
  author       = {Gloaguen, Arnaud and Philippe, Cathy and Frouin, Vincent and Gennari, Giulia and Dehaene-Lambertz, Ghislaine and Le Brusquet, Laurent and Tenenhaus, Arthur},
  doi          = {10.1093/biostatistics/kxaa010},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {240-256},
  shortjournal = {Biostatistics},
  title        = {Multiway generalized canonical correlation analysis},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling continuous glucose monitoring (CGM) data during
sleep. <em>BIOSTAT</em>, <em>23</em>(1), 223–239. (<a
href="https://doi.org/10.1093/biostatistics/kxaa023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a multilevel functional Beta model to quantify the blood glucose levels measured by continuous glucose monitors for multiple days in study participants with type 2 diabetes mellitus. The model estimates the subject-specific marginal quantiles, quantifies the within- and between-subject variability, and produces interpretable parameters of blood glucose dynamics as a function of time from the actigraphy-estimated sleep onset. Results are validated via simulations and by studying the association between the estimated model parameters and hemoglobin A1c, the gold standard for assessing glucose control in diabetes.},
  archive      = {J_BIOSTAT},
  author       = {Gaynanova, Irina and Punjabi, Naresh and Crainiceanu, Ciprian},
  doi          = {10.1093/biostatistics/kxaa023},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {223-239},
  shortjournal = {Biostatistics},
  title        = {Modeling continuous glucose monitoring (CGM) data during sleep},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimating diversity in networked ecological communities.
<em>BIOSTAT</em>, <em>23</em>(1), 207–222. (<a
href="https://doi.org/10.1093/biostatistics/kxaa015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Comparing ecological communities across environmental gradients can be challenging, especially when the number of different taxonomic groups in the communities is large. In this setting, community-level summaries called diversity indices are widely used to detect changes in the community ecology. However, estimation of diversity indices has received relatively little attention from the statistical community. The most common estimates of diversity are the maximum likelihood estimates of the parameters of a multinomial model, even though the multinomial model implies strict assumptions about the sampling mechanism. In particular, the multinomial model prohibits ecological networks, where taxa positively and negatively co-occur. In this article, we leverage models from the compositional data literature that explicitly account for co-occurrence networks and use them to estimate diversity. Instead of proposing new diversity indices, we estimate popular diversity indices under these models. While the methodology is general, we illustrate the approach for the estimation of the Shannon, Simpson, Bray–Curtis, and Euclidean diversity indices. We contrast our method to multinomial, low-rank, and nonparametric methods for estimating diversity indices. Under simulation, we find that the greatest gains of the method are in strongly networked communities with many taxa. Therefore, to illustrate the method, we analyze the microbiome of seafloor basalts based on a 16S amplicon sequencing dataset with 1425 taxa and 12 communities.},
  archive      = {J_BIOSTAT},
  author       = {Willis, Amy D and Martin, Bryan D},
  doi          = {10.1093/biostatistics/kxaa015},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {207-222},
  shortjournal = {Biostatistics},
  title        = {Estimating diversity in networked ecological communities},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Causal inference for recurrent event data using
pseudo-observations. <em>BIOSTAT</em>, <em>23</em>(1), 189–206. (<a
href="https://doi.org/10.1093/biostatistics/kxaa020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent event data are commonly encountered in observational studies where each subject may experience a particular event repeatedly over time. In this article, we aim to compare cumulative rate functions (CRFs) of two groups when treatment assignment may depend on the unbalanced distribution of confounders. Several estimators based on pseudo-observations are proposed to adjust for the confounding effects, namely inverse probability of treatment weighting estimator, regression model-based estimators, and doubly robust estimators. The proposed marginal regression estimator and doubly robust estimators based on pseudo-observations are shown to be consistent and asymptotically normal. A bootstrap approach is proposed for the variance estimation of the proposed estimators. Model diagnostic plots of residuals are presented to assess the goodness-of-fit for the proposed regression models. A family of adjusted two-sample pseudo-score tests is proposed to compare two CRFs. Simulation studies are conducted to assess finite sample performance of the proposed method. The proposed technique is demonstrated through an application to a hospital readmission data set.},
  archive      = {J_BIOSTAT},
  author       = {Su, Chien-Lin and Platt, Robert W and Plante, Jean-François},
  doi          = {10.1093/biostatistics/kxaa020},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {189-206},
  shortjournal = {Biostatistics},
  title        = {Causal inference for recurrent event data using pseudo-observations},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluating biomarkers for treatment selection from
reproducibility studies. <em>BIOSTAT</em>, <em>23</em>(1), 173–188. (<a
href="https://doi.org/10.1093/biostatistics/kxaa018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider evaluating new or more accurately measured predictive biomarkers for treatment selection based on a previous clinical trial involving standard biomarkers. Instead of rerunning the clinical trial with the new biomarkers, we propose a more efficient approach which requires only either conducting a reproducibility study in which the new biomarkers and standard biomarkers are both measured on a set of patient samples, or adopting replicated measures of the error-contaminated standard biomarkers in the original study. This approach is easier to conduct and much less expensive than studies that require new samples from patients randomized to the intervention. In addition, it makes it possible to perform the estimation of the clinical performance quickly, since there will be no requirement to wait for events to occur as would be the case with prospective validation. The treatment selection is assessed via a working model, but the proposed estimator of the mean restricted lifetime is valid even if the working model is misspecified. The proposed approach is assessed through simulation studies and applied to a cancer study.},
  archive      = {J_BIOSTAT},
  author       = {Song, Xiao and Dobbin, Kevin K},
  doi          = {10.1093/biostatistics/kxaa018},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {173-188},
  shortjournal = {Biostatistics},
  title        = {Evaluating biomarkers for treatment selection from reproducibility studies},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Depth importance in precision medicine (DIPM): A tree- and
forest-based method for right-censored survival outcomes.
<em>BIOSTAT</em>, <em>23</em>(1), 157–172. (<a
href="https://doi.org/10.1093/biostatistics/kxaa021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many clinical trials have been conducted to compare right-censored survival outcomes between interventions. Such comparisons are typically made on the basis of the entire group receiving one intervention versus the others. In order to identify subgroups for which the preferential treatment may differ from the overall group, we propose the depth importance in precision medicine (DIPM) method for such data within the precision medicine framework. The approach first modifies the split criteria of the traditional classification tree to fit the precision medicine setting. Then, a random forest of trees is constructed at each node. The forest is used to calculate depth variable importance scores for each candidate split variable. The variable with the highest score is identified as the best variable to split the node. The importance score is a flexible and simply constructed measure that makes use of the observation that more important variables tend to be selected closer to the root nodes of trees. The DIPM method is primarily designed for the analysis of clinical data with two treatment groups. We also present the extension to the case of more than two treatment groups. We use simulation studies to demonstrate the accuracy of our method and provide the results of applications to two real-world data sets. In the case of one data set, the DIPM method outperforms an existing method, and a primary motivation of this article is the ability of the DIPM method to address the shortcomings of this existing method. Altogether, the DIPM method yields promising results that demonstrate its capacity to guide personalized treatment decisions in cases with right-censored survival outcomes.},
  archive      = {J_BIOSTAT},
  author       = {Chen, Victoria and Zhang, Heping},
  doi          = {10.1093/biostatistics/kxaa021},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {157-172},
  shortjournal = {Biostatistics},
  title        = {Depth importance in precision medicine (DIPM): A tree- and forest-based method for right-censored survival outcomes},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New approaches for testing non-inferiority for three-arm
trials with poisson distributed outcomes. <em>BIOSTAT</em>,
<em>23</em>(1), 136–156. (<a
href="https://doi.org/10.1093/biostatistics/kxaa014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the availability of limited resources, innovation for improved statistical method for the design and analysis of randomized controlled trials (RCTs) is of paramount importance for newer and better treatment discovery for any therapeutic area. Although clinical efficacy is almost always the primary evaluating criteria to measure any beneficial effect of a treatment, there are several important other factors (e.g., side effects, cost burden, less debilitating, less intensive, etc.), which can permit some less efficacious treatment options favorable to a subgroup of patients. This leads to non-inferiority (NI) testing. The objective of NI trial is to show that an experimental treatment is not worse than an active reference treatment by more than a pre-specified margin. Traditional NI trials do not include a placebo arm for ethical reason; however, this necessitates stringent and often unverifiable assumptions. On the other hand, three-arm NI trials consisting of placebo, reference, and experimental treatment, can simultaneously test the superiority of the reference over placebo and NI of experimental treatment over the reference. In this article, we proposed both novel Frequentist and Bayesian procedures for testing NI in the three-arm trial with Poisson distributed count outcome. RCTs with count data as the primary outcome are quite common in various disease areas such as lesion count in cancer trials, relapses in multiple sclerosis, dermatology, neurology, cardiovascular research, adverse event count, etc. We first propose an improved Frequentist approach, which is then followed by it’s Bayesian version. Bayesian methods have natural advantage in any active-control trials, including NI trial when substantial historical information is available for placebo and established reference treatment. In addition, we discuss sample size calculation and draw an interesting connection between the two paradigms.},
  archive      = {J_BIOSTAT},
  author       = {Ghosh, Samiran and Paul, Erina and Chowdhury, Shrabanti and Tiwari, Ram C.},
  doi          = {10.1093/biostatistics/kxaa014},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {136-156},
  shortjournal = {Biostatistics},
  title        = {New approaches for testing non-inferiority for three-arm trials with poisson distributed outcomes},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Borrowing of information across patient subgroups in a
basket trial based on distributional discrepancy. <em>BIOSTAT</em>,
<em>23</em>(1), 120–135. (<a
href="https://doi.org/10.1093/biostatistics/kxaa019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Basket trials have emerged as a new class of efficient approaches in oncology to evaluate a new treatment in several patient subgroups simultaneously. In this article, we extend the key ideas to disease areas outside of oncology, developing a robust Bayesian methodology for randomized, placebo-controlled basket trials with a continuous endpoint to enable borrowing of information across subtrials with similar treatment effects. After adjusting for covariates, information from a complementary subtrial can be represented into a commensurate prior for the parameter that underpins the subtrial under consideration. We propose using distributional discrepancy to characterize the commensurability between subtrials for appropriate borrowing of information through a spike-and-slab prior, which is placed on the prior precision factor. When the basket trial has at least three subtrials, commensurate priors for point-to-point borrowing are combined into a marginal predictive prior, according to the weights transformed from the pairwise discrepancy measures. In this way, only information from subtrial(s) with the most commensurate treatment effect is leveraged. The marginal predictive prior is updated to a robust posterior by the contemporary subtrial data to inform decision making. Operating characteristics of the proposed methodology are evaluated through simulations motivated by a real basket trial in chronic diseases. The proposed methodology has advantages compared to other selected Bayesian analysis models, for (i) identifying the most commensurate source of information and (ii) gauging the degree of borrowing from specific subtrials. Numerical results also suggest that our methodology can improve the precision of estimates and, potentially, the statistical power for hypothesis testing.},
  archive      = {J_BIOSTAT},
  author       = {Zheng, Haiyan and Wason, James M S},
  doi          = {10.1093/biostatistics/kxaa019},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {120-135},
  shortjournal = {Biostatistics},
  title        = {Borrowing of information across patient subgroups in a basket trial based on distributional discrepancy},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Direct modeling of the crude probability of cancer death and
the number of life years lost due to cancer without the need of cause of
death: A pseudo-observation approach in the relative survival setting.
<em>BIOSTAT</em>, <em>23</em>(1), 101–119. (<a
href="https://doi.org/10.1093/biostatistics/kxaa017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In population-based cancer studies, net survival is a crucial measure for population comparison purposes. However, alternative measures, namely the crude probability of death (CPr) and the number of life years lost (LYL) due to death according to different causes, are useful as complementary measures for reflecting different dimensions in terms of prognosis, treatment choice, or development of a control strategy. When the cause of death (COD) information is available, both measures can be estimated in competing risks setting using either cause-specific or subdistribution hazard regression models or with the pseudo-observation approach through direct modeling. We extended the pseudo-observation approach in order to model the CPr and the LYL due to different causes when information on COD is unavailable or unreliable (i.e., in relative survival setting). In a simulation study, we assessed the performance of the proposed approach in estimating regression parameters and examined models with different link functions that can provide an easier interpretation of the parameters. We showed that the pseudo-observation approach performs well for both measures and we illustrated their use on cervical cancer data from the England population-based cancer registry. A tutorial showing how to implement the method in R software is also provided.},
  archive      = {J_BIOSTAT},
  author       = {Kipourou, Dimitra-Kleio and Perme, Maja Pohar and Rachet, Bernard and Belot, Aurelien},
  doi          = {10.1093/biostatistics/kxaa017},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {101-119},
  shortjournal = {Biostatistics},
  title        = {Direct modeling of the crude probability of cancer death and the number of life years lost due to cancer without the need of cause of death: A pseudo-observation approach in the relative survival setting},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Matrix decomposition for modeling lesion development
processes in multiple sclerosis. <em>BIOSTAT</em>, <em>23</em>(1),
83–100. (<a
href="https://doi.org/10.1093/biostatistics/kxaa016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our main goal is to study and quantify the evolution of multiple sclerosis lesions observed longitudinally over many years in multi-sequence structural magnetic resonance imaging (sMRI). To achieve that, we propose a class of functional models for capturing the temporal dynamics and spatial distribution of the voxel-specific intensity trajectories in all sMRI sequences. To accommodate the hierarchical data structure (observations nested within voxels, which are nested within lesions, which, in turn, are nested within study participants), we use structured functional principal component analysis. We propose and evaluate the finite sample properties of hypothesis tests of therapeutic intervention effects on lesion evolution while accounting for the multilevel structure of the data. Using this novel testing strategy, we found statistically significant differences in lesion evolution between treatment groups.},
  archive      = {J_BIOSTAT},
  author       = {Hu, Menghan and Crainiceanu, Ciprian and Schindler, Matthew K and Dewey, Blake and Reich, Daniel S and Shinohara, Russell T and Eloyan, Ani},
  doi          = {10.1093/biostatistics/kxaa016},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {83-100},
  shortjournal = {Biostatistics},
  title        = {Matrix decomposition for modeling lesion development processes in multiple sclerosis},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hidden markov modeling approach for identifying tumor
subclones in next-generation sequencing studies. <em>BIOSTAT</em>,
<em>23</em>(1), 69–82. (<a
href="https://doi.org/10.1093/biostatistics/kxaa013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Allele-specific copy number alteration (ASCNA) analysis is for identifying copy number abnormalities in tumor cells. Unlike normal cells, tumor cells are heterogeneous as a combination of dominant and minor subclones with distinct copy number profiles. Estimating the clonal proportion and identifying mainclone and subclone genotypes across the genome are important for understanding tumor progression. Several ASCNA tools have recently been developed, but they have been limited to the identification of subclone regions, and not the genotype of subclones. In this article, we propose subHMM, a hidden Markov model-based approach that estimates both subclone region and region-specific subclone genotype and clonal proportion. We specify a hidden state variable representing the conglomeration of clonal genotype and subclone status. We propose a two-step algorithm for parameter estimation, where in the first step, a standard hidden Markov model with this conglomerated state variable is fit. Then, in the second step, region-specific estimates of the clonal proportions are obtained by maximizing region-specific pseudo-likelihoods. We apply subHMM to study renal cell carcinoma datasets in The Cancer Genome Atlas. In addition, we conduct simulation studies that show the good performance of the proposed approach. The R source code is available online at https://dceg.cancer.gov/tools/analysis/subhmm . Expectation–Maximization algorithm; Forward–backward algorithm; Somatic copy number alteration; Tumor subclones.},
  archive      = {J_BIOSTAT},
  author       = {Choo-Wosoba, Hyoyoung and Albert, Paul S and Zhu, Bin},
  doi          = {10.1093/biostatistics/kxaa013},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {69-82},
  shortjournal = {Biostatistics},
  title        = {A hidden markov modeling approach for identifying tumor subclones in next-generation sequencing studies},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-part joint model for a longitudinal semicontinuous
marker and a terminal event with application to metastatic colorectal
cancer data. <em>BIOSTAT</em>, <em>23</em>(1), 50–68. (<a
href="https://doi.org/10.1093/biostatistics/kxaa012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint models for a longitudinal biomarker and a terminal event have gained interests for evaluating cancer clinical trials because the tumor evolution reflects directly the state of the disease. A biomarker characterizing the tumor size evolution over time can be highly informative for assessing treatment options and could be taken into account in addition to the survival time. The biomarker often has a semicontinuous distribution, i.e., it is zero inflated and right skewed. An appropriate model is needed for the longitudinal biomarker as well as an association structure with the survival outcome. In this article, we propose a joint model for a longitudinal semicontinuous biomarker and a survival time. The semicontinuous nature of the longitudinal biomarker is specified by a two-part model, which splits its distribution into a binary outcome (first part) represented by the positive versus zero values and a continuous outcome (second part) with the positive values only. Survival times are modeled with a proportional hazards model for which we propose three association structures with the biomarker. Our simulation studies show some bias can arise in the parameter estimates when the semicontinuous nature of the biomarker is ignored, assuming the true model is a two-part model. An application to advanced metastatic colorectal cancer data from the GERCOR study is performed where our two-part model is compared to one-part joint models. Our results show that treatment arm B (FOLFOX6/FOLFIRI) is associated to higher SLD values over time and its positive association with the terminal event leads to an increased risk of death compared to treatment arm A (FOLFIRI/FOLFOX6).},
  archive      = {J_BIOSTAT},
  author       = {Rustand, Denis and Briollais, Laurent and Tournigand, Christophe and Rondeau, Virginie},
  doi          = {10.1093/biostatistics/kxaa012},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {50-68},
  shortjournal = {Biostatistics},
  title        = {Two-part joint model for a longitudinal semicontinuous marker and a terminal event with application to metastatic colorectal cancer data},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bayesian nonparametric approach for evaluating the causal
effect of treatment in randomized trials with semi-competing risks.
<em>BIOSTAT</em>, <em>23</em>(1), 34–49. (<a
href="https://doi.org/10.1093/biostatistics/kxaa008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a Bayesian nonparametric (BNP) approach to evaluate the causal effect of treatment in a randomized trial where a nonterminal event may be censored by a terminal event, but not vice versa (i.e., semi-competing risks). Based on the idea of principal stratification, we define a novel estimand for the causal effect of treatment on the nonterminal event. We introduce identification assumptions, indexed by a sensitivity parameter, and show how to draw inference using our BNP approach. We conduct simulation studies and illustrate our methodology using data from a brain cancer trial. The R code implementing our model and algorithm is available for download at https://github.com/YanxunXu/BaySemiCompeting .},
  archive      = {J_BIOSTAT},
  author       = {Xu, Yanxun and Scharfstein, Daniel and Müller, Peter and Daniels, Michael},
  doi          = {10.1093/biostatistics/kxaa008},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {34-49},
  shortjournal = {Biostatistics},
  title        = {A bayesian nonparametric approach for evaluating the causal effect of treatment in randomized trials with semi-competing risks},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assessing the accuracy of predictive models with
interval-censored data. <em>BIOSTAT</em>, <em>23</em>(1), 18–33. (<a
href="https://doi.org/10.1093/biostatistics/kxaa011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop methods for assessing the predictive accuracy of a given event time model when the validation sample is comprised of case |$K$| interval-censored data. An imputation-based, an inverse probability weighted (IPW), and an augmented inverse probability weighted (AIPW) estimator are developed and evaluated for the mean prediction error and the area under the receiver operating characteristic curve when the goal is to predict event status at a landmark time. The weights used for the IPW and AIPW estimators are obtained by fitting a multistate model which jointly considers the event process, the recurrent assessment process, and loss to follow-up. We empirically investigate the performance of the proposed methods and illustrate their application in the context of a motivating rheumatology study in which human leukocyte antigen markers are used to predict disease progression status in patients with psoriatic arthritis.},
  archive      = {J_BIOSTAT},
  author       = {Wu, Ying and Cook, Richard J},
  doi          = {10.1093/biostatistics/kxaa011},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {18-33},
  shortjournal = {Biostatistics},
  title        = {Assessing the accuracy of predictive models with interval-censored data},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Geographically dependent individual-level models for
infectious diseases transmission. <em>BIOSTAT</em>, <em>23</em>(1),
1–17. (<a href="https://doi.org/10.1093/biostatistics/kxaa009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infectious disease models can be of great use for understanding the underlying mechanisms that influence the spread of diseases and predicting future disease progression. Modeling has been increasingly used to evaluate the potential impact of different control measures and to guide public health policy decisions. In recent years, there has been rapid progress in developing spatio-temporal modeling of infectious diseases and an example of such recent developments is the discrete-time individual-level models (ILMs). These models are well developed and provide a common framework for modeling many disease systems; however, they assume the probability of disease transmission between two individuals depends only on their spatial separation and not on their spatial locations. In cases where spatial location itself is important for understanding the spread of emerging infectious diseases and identifying their causes, it would be beneficial to incorporate the effect of spatial location in the model. In this study, we thus generalize the ILMs to a new class of geographically dependent ILMs, to allow for the evaluation of the effect of spatially varying risk factors (e.g., education, social deprivation, environmental), as well as unobserved spatial structure, upon the transmission of infectious disease. Specifically, we consider a conditional autoregressive (CAR) model to capture the effects of unobserved spatially structured latent covariates or measurement error. This results in flexible infectious disease models that can be used for formulating etiological hypotheses and identifying geographical regions of unusually high risk to formulate preventive action. The reliability of these models is investigated on a combination of simulated epidemic data and Alberta seasonal influenza outbreak data ( ⁠|$2009$|⁠ ). This new class of models is fitted to data within a Bayesian statistical framework using Markov chain Monte Carlo methods.},
  archive      = {J_BIOSTAT},
  author       = {Mahsin, M D and Deardon, Rob and Brown, Patrick},
  doi          = {10.1093/biostatistics/kxaa009},
  journal      = {Biostatistics},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Biostatistics},
  title        = {Geographically dependent individual-level models for infectious diseases transmission},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
