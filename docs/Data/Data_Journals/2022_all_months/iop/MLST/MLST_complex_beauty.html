<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MLST_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mlst---99">MLST - 99</h2>
<ul>
<li><details>
<summary>
(2022). Dark solitons in bose–einstein condensates: A dataset for
many-body physics research. <em>MLST</em>, <em>3</em>(4), 047001. (<a
href="https://doi.org/10.1088/2632-2153/ac9454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish a dataset of over 1.6\times10^4 experimental images of Bose–Einstein condensates containing solitonic excitations to enable machine learning (ML) for many-body physics research. About 33 % of this dataset has manually assigned and carefully curated labels. The remainder is automatically labeled using SolDet—an implementation of a physics-informed ML data analysis framework—consisting of a convolutional-neural-network-based classifier and object detector as well as a statistically motivated physics-informed classifier and a quality metric. This technical note constitutes the definitive reference of the dataset, providing an opportunity for the data science community to develop more sophisticated analysis tools, to further understand nonlinear many-body physics, and even advance cold atom experiments.},
  archive      = {J_MLST},
  author       = {Amilson R Fritsch and Shangjie Guo and Sophia M Koh and I B Spielman and Justyna P Zwolak},
  doi          = {10.1088/2632-2153/ac9454},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {047001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Dark solitons in Bose–Einstein condensates: A dataset for many-body physics research},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-supervised learning of materials concepts from crystal
structures via deep neural networks. <em>MLST</em>, <em>3</em>(4),
045034. (<a href="https://doi.org/10.1088/2632-2153/aca23d">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Material development involves laborious processes to explore the vast materials space. The key to accelerating these processes is understanding the structure-functionality relationships of materials. Machine learning has enabled large-scale analysis of underlying relationships between materials via their vector representations, or embeddings. However, the learning of material embeddings spanning most known inorganic materials has remained largely unexplored due to the expert knowledge and efforts required to annotate large-scale materials data. Here we show that our self-supervised deep learning approach can successfully learn material embeddings from crystal structures of over 120 000 materials, without any annotations, to capture the structure-functionality relationships among materials. These embeddings revealed the profound similarity between materials, or &#39;materials concepts&#39;, such as cuprate superconductors and lithium-ion battery materials from the unannotated structural data. Consequently, our results enable us to both draw a large-scale map of the materials space, capturing various materials concepts, and measure the functionality-aware similarities between materials. Our findings will enable more strategic approaches to material development.},
  archive      = {J_MLST},
  author       = {Yuta Suzuki and Tatsunori Taniai and Kotaro Saito and Yoshitaka Ushiku and Kanta Ono},
  doi          = {10.1088/2632-2153/aca23d},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045034},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Self-supervised learning of materials concepts from crystal structures via deep neural networks},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). No-reference perceptual CT image quality assessment based on
a self-supervised learning framework. <em>MLST</em>, <em>3</em>(4),
045033. (<a href="https://doi.org/10.1088/2632-2153/aca87d">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate image quality assessment (IQA) is crucial to optimize computed tomography (CT) image protocols while keeping the radiation dose as low as reasonably achievable. In the medical domain, IQA is based on how well an image provides a useful and efficient presentation necessary for physicians to make a diagnosis. Moreover, IQA results should be consistent with radiologists&#39; opinions on image quality, which is accepted as the gold standard for medical IQA. As such, the goals of medical IQA are greatly different from those of natural IQA. In addition, the lack of pristine reference images or radiologists&#39; opinions in a real-time clinical environment makes IQA challenging. Thus, no-reference IQA (NR-IQA) is more desirable in clinical settings than full-reference IQA (FR-IQA). Leveraging an innovative self-supervised training strategy for object detection models by detecting virtually inserted objects with geometrically simple forms, we propose a novel NR-IQA method, named deep detector IQA (D2IQA), that can automatically calculate the quantitative quality of CT images. Extensive experimental evaluations on clinical and anthropomorphic phantom CT images demonstrate that our D2IQA is capable of robustly computing perceptual image quality as it varies according to relative dose levels. Moreover, when considering the correlation between the evaluation results of IQA metrics and radiologists&#39; quality scores, our D2IQA is marginally superior to other NR-IQA metrics and even shows performance competitive with FR-IQA metrics.},
  archive      = {J_MLST},
  author       = {Wonkyeong Lee and Eunbyeol Cho and Wonjin Kim and Hyebin Choi and Kyongmin Sarah Beck and Hyun Jung Yoon and Jongduk Baek and Jang-Hwan Choi},
  doi          = {10.1088/2632-2153/aca87d},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045033},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {No-reference perceptual CT image quality assessment based on a self-supervised learning framework},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Building robust machine learning models for small chemical
science data: The case of shear viscosity of fluids. <em>MLST</em>,
<em>3</em>(4), 045032. (<a
href="https://doi.org/10.1088/2632-2153/acac01">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shear viscosity, though being a fundamental property of all fluids, is computationally expensive to calculate from equilibrium molecular dynamics simulations. Recently, machine learning (ML) methods have been used to augment molecular simulations in many contexts, thus showing promise to estimate viscosity too in a relatively inexpensive manner. However, ML methods face significant challenges—such as overfitting, when the size of the data set is small, as is the case with viscosity. In this work, we train seven ML models to predict the shear viscosity of a Lennard–Jones fluid, with particular emphasis on addressing issues arising from a small data set. Specifically, the issues related to model selection, performance estimation and uncertainty quantification were investigated. First, we show that the widely used performance estimation procedure of using a single unseen data set shows a wide variability—in estimating the errors on—small data sets. In this context, the common practice of using cross validation (CV) to select the hyperparameters (model selection) can be adapted to estimate the generalization error (performance estimation) as well. We compare two simple CV procedures for their ability to do both model selection and performance estimation, and find that k-fold CV based procedure shows a lower variance of error estimates. Also, these CV procedures naturally lead to an ensemble of trained ML models. We discuss the role of performance metrics in training and evaluation and propose a method to rank the ML models based on multiple metrics. Finally, two methods for uncertainty quantification—Gaussian process regression (GPR) and ensemble method—were used to estimate the uncertainty on individual predictions. The uncertainty estimates from GPR were also used to construct an applicability domain using which the ML models provided even more reliable predictions on an independent viscosity data set generated in this work. Overall, the procedures prescribed in this work, together, lead to robust ML models for small data sets.},
  archive      = {J_MLST},
  author       = {Nikhil V S Avula and Shivanand Kumar Veesam and Sudarshan Behera and Sundaram Balasubramanian},
  doi          = {10.1088/2632-2153/acac01},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045032},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Building robust machine learning models for small chemical science data: The case of shear viscosity of fluids},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal data generation for machine learned interatomic
potentials. <em>MLST</em>, <em>3</em>(4), 045031. (<a
href="https://doi.org/10.1088/2632-2153/ac9ae7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning interatomic potentials (MLIPs) are routinely used atomic simulations, but generating databases of atomic configurations used in fitting these models is a laborious process, requiring significant computational and human effort. A computationally efficient method is presented to generate databases of atomic configurations that contain optimal information on the small-displacement regime of the potential energy surface of bulk crystalline matter. Utilising non-diagonal supercell (Lloyd-Williams and Monserrat 2015 Phys. Rev. B 92 184301), an automatic process is suggested for ab initio data generation. MLIPs were fitted for Al, W, Mg and Si, which very closely reproduce the ab initio phonon and elastic properties. The protocol can be easily adapted to other materials and can be inserted in the workflow of any flavour of MLIP generation.},
  archive      = {J_MLST},
  author       = {Connor Allen and Albert P Bartók},
  doi          = {10.1088/2632-2153/ac9ae7},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045031},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Optimal data generation for machine learned interatomic potentials},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards a variational jordan–lee–preskill quantum algorithm.
<em>MLST</em>, <em>3</em>(4), 045030. (<a
href="https://doi.org/10.1088/2632-2153/aca06b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid developments of quantum information technology show promising opportunities for simulating quantum field theory in near-term quantum devices. In this work, we formulate the theory of (time-dependent) variational quantum simulation of the 1+1 dimensional \lambda \phi^4 quantum field theory including encoding, state preparation, and time evolution, with several numerical simulation results. These algorithms could be understood as near-term variational quantum circuit (quantum neural network) analogs of the Jordan–Lee–Preskill algorithm, the basic algorithm for simulating quantum field theory using universal quantum devices. Besides, we highlight the advantages of encoding with harmonic oscillator basis based on the Lehmann—Symanzik—Zimmermann reduction formula and several computational efficiency such as when implementing a bosonic version of the unitary coupled cluster ansatz to prepare initial states. We also discuss how to circumvent the &#39;spectral crowding&#39; problem in the quantum field theory simulation and appraise our algorithm by both state and subspace fidelities.},
  archive      = {J_MLST},
  author       = {Junyu Liu and Zimu Li and Han Zheng and Xiao Yuan and Jinzhao Sun},
  doi          = {10.1088/2632-2153/aca06b},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045030},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Towards a variational Jordan–Lee–Preskill quantum algorithm},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pixel-wise classification in graphene-detection with
tree-based machine learning algorithms. <em>MLST</em>, <em>3</em>(4),
045029. (<a href="https://doi.org/10.1088/2632-2153/aca744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical exfoliation of graphene and its identification by optical inspection is one of the milestones in condensed matter physics that sparked the field of two-dimensional materials. Finding regions of interest from the entire sample space and identification of layer number is a routine task potentially amenable to automatization. We propose supervised pixel-wise classification methods showing a high performance even with a small number of training image datasets that require short computational time without GPU. We introduce four different tree-based machine learning (ML) algorithms—decision tree, random forest, extreme gradient boost, and light gradient boosting machine. We train them with five optical microscopy images of graphene, and evaluate their performances with multiple metrics and indices. We also discuss combinatorial ML models between the three single classifiers and assess their performances in identification and reliability. The code developed in this paper is open to the public and will be released at github.com/gjung-group/Graphene_segmentation .},
  archive      = {J_MLST},
  author       = {Woon Hyung Cho and Jiseon Shin and Young Duck Kim and George J Jung},
  doi          = {10.1088/2632-2153/aca744},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045029},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Pixel-wise classification in graphene-detection with tree-based machine learning algorithms},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust and scalable uncertainty estimation with conformal
prediction for machine-learned interatomic potentials. <em>MLST</em>,
<em>3</em>(4), 045028. (<a
href="https://doi.org/10.1088/2632-2153/aca7b1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty quantification (UQ) is important to machine learning (ML) force fields to assess the level of confidence during prediction, as ML models are not inherently physical and can therefore yield catastrophically incorrect predictions. Established a-posteriori UQ methods, including ensemble methods, the dropout method, the delta method, and various heuristic distance metrics, have limitations such as being computationally challenging for large models due to model re-training. In addition, the uncertainty estimates are often not rigorously calibrated. In this work, we propose combining the distribution-free UQ method, known as conformal prediction (CP), with the distances in the neural network&#39;s latent space to estimate the uncertainty of energies predicted by neural network force fields. We evaluate this method (CP+latent) along with other UQ methods on two essential aspects, calibration, and sharpness, and find this method to be both calibrated and sharp under the assumption of independent and identically-distributed (i.i.d.) data. We show that the method is relatively insensitive to hyperparameters selected, and test the limitations of the method when the i.i.d. assumption is violated. Finally, we demonstrate that this method can be readily applied to trained neural network force fields with traditional and graph neural network architectures to obtain estimates of uncertainty with low computational costs on a training dataset of 1 million images to showcase its scalability and portability. Incorporating the CP method with latent distances offers a calibrated, sharp and efficient strategy to estimate the uncertainty of neural network force fields. In addition, the CP approach can also function as a promising strategy for calibrating uncertainty estimated by other approaches.},
  archive      = {J_MLST},
  author       = {Yuge Hu and Joseph Musielewicz and Zachary W Ulissi and Andrew J Medford},
  doi          = {10.1088/2632-2153/aca7b1},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045028},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Robust and scalable uncertainty estimation with conformal prediction for machine-learned interatomic potentials},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interaction decompositions for tensor network regression.
<em>MLST</em>, <em>3</em>(4), 045027. (<a
href="https://doi.org/10.1088/2632-2153/aca271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that tensor network regression models operate on an exponentially large feature space, but questions remain as to how effectively they are able to utilize this space. Using a polynomial featurization, we propose an interaction decomposition as a tool that can assess the relative importance of different regressors as a function of their polynomial degree. We apply this decomposition to tensor ring and tree tensor network models trained on the MNIST and Fashion MNIST datasets, and find that up to 75% of interaction degrees are contributing meaningfully to these models. We also introduce a new type of tensor network model that is explicitly trained on only a small subset of interaction degrees, and find that these models are able to match or even outperform the full models using only a fraction of the exponential feature space. This suggests that standard tensor network models utilize their polynomial regressors in an inefficient manner, with the lower degree terms being vastly under-utilized.},
  archive      = {J_MLST},
  author       = {Ian Convy and K Birgitta Whaley},
  doi          = {10.1088/2632-2153/aca271},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045027},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Interaction decompositions for tensor network regression},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Training neural networks using metropolis monte carlo and an
adaptive variant. <em>MLST</em>, <em>3</em>(4), 045026. (<a
href="https://doi.org/10.1088/2632-2153/aca6cd">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the zero-temperature Metropolis Monte Carlo (MC) algorithm as a tool for training a neural network by minimizing a loss function. We find that, as expected on theoretical grounds and shown empirically by other authors, Metropolis MC can train a neural net with an accuracy comparable to that of gradient descent (GD), if not necessarily as quickly. The Metropolis algorithm does not fail automatically when the number of parameters of a neural network is large. It can fail when a neural network&#39;s structure or neuron activations are strongly heterogenous, and we introduce an adaptive Monte Carlo algorithm (aMC) to overcome these limitations. The intrinsic stochasticity and numerical stability of the MC method allow aMC to train deep neural networks and recurrent neural networks in which the gradient is too small or too large to allow training by GD. MC methods offer a complement to gradient-based methods for training neural networks, allowing access to a distinct set of network architectures and principles.},
  archive      = {J_MLST},
  author       = {Stephen Whitelam and Viktor Selin and Ian Benlolo and Corneel Casert and Isaac Tamblyn},
  doi          = {10.1088/2632-2153/aca6cd},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045026},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Training neural networks using metropolis monte carlo and an adaptive variant},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Operationally meaningful representations of physical systems
in neural networks. <em>MLST</em>, <em>3</em>(4), 045025. (<a
href="https://doi.org/10.1088/2632-2153/ac9ae8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To make progress in science, we often build abstract representations of physical systems that meaningfully encode information about the systems. Such representations ignore redundant features and treat parameters such as velocity and position separately because they can be useful for making statements about different experimental settings. Here, we capture this notion by formally defining the concept of operationally meaningful representations. We present an autoencoder architecture with attention mechanism that can generate such representations and demonstrate it on examples involving both classical and quantum physics. For instance, our architecture finds a compact representation of an arbitrary two-qubit system that separates local parameters from parameters describing quantum correlations.},
  archive      = {J_MLST},
  author       = {Hendrik Poulsen Nautrup and Tony Metger and Raban Iten and Sofiene Jerbi and Lea M Trenkwalder and Henrik Wilming and Hans J Briegel and Renato Renner},
  doi          = {10.1088/2632-2153/ac9ae8},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045025},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Operationally meaningful representations of physical systems in neural networks},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Active particles using reinforcement learning to navigate in
complex motility landscapes. <em>MLST</em>, <em>3</em>(4), 045024. (<a
href="https://doi.org/10.1088/2632-2153/aca7b0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the length scales of the smallest technology continue to advance beyond the micron scale it becomes increasingly important to equip robotic components with the means for intelligent and autonomous decision making with limited information. With the help of a tabular Q-learning algorithm, we design a model for training a microswimmer, to navigate quickly through an environment given by various different scalar motility fields, while receiving a limited amount of local information. We compare the performances of the microswimmer, defined via time of first passage to a target, with performances of suitable reference cases. We show that the strategy obtained with our reinforcement learning model indeed represents an efficient navigation strategy, that outperforms the reference cases. By confronting the swimmer with a variety of unfamiliar environments after the finalised training, we show that the obtained strategy generalises to different classes of random fields.},
  archive      = {J_MLST},
  author       = {Paul A Monderkamp and Fabian Jan Schwarzendahl and Michael A Klatt and Hartmut Löwen},
  doi          = {10.1088/2632-2153/aca7b0},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045024},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Active particles using reinforcement learning to navigate in complex motility landscapes},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Federated data processing and learning for collaboration in
the physical sciences. <em>MLST</em>, <em>3</em>(4), 045023. (<a
href="https://doi.org/10.1088/2632-2153/aca87c">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Property analysis and prediction is a challenging topic in fields such as chemistry, nanotechnology and materials science, and often suffers from lack of data. Federated learning (FL) is a machine learning (ML) framework that encourages privacy-preserving collaborations between data owners, and potentially overcomes the need to combine data that may contain proprietary information. Combining information from different data sets within the same domain can also produce ML models with more general insight and reduce the impact of the selection bias inherent in small, individual studies. In this paper we propose using horizontal FL to mitigate these data limitation issues and explore the opportunity for data-driven collaboration under these constraints. We also propose FedRed, a new dimensionality reduction method for FL, that allows faster convergence and accounts for differences between individual data sets. The FL pipeline has been tested on a collection of eight different data sets of metallic nanoparticles, and while there are expected losses compared to a combined data set that does not preserve the privacy of the collaborators, we obtained extremely good result compared to local training on individual data sets. We conclude that FL is an effective and efficient method for the physical science domain that could hugely reduce the negative effect of insufficient data.},
  archive      = {J_MLST},
  author       = {W Huang and A S Barnard},
  doi          = {10.1088/2632-2153/aca87c},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045023},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Federated data processing and learning for collaboration in the physical sciences},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NeuralNEB—neural networks can find reaction paths fast.
<em>MLST</em>, <em>3</em>(4), 045022. (<a
href="https://doi.org/10.1088/2632-2153/aca23e">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum mechanical methods like density functional theory (DFT) are used with great success alongside efficient search algorithms for studying kinetics of reactive systems. However, DFT is prohibitively expensive for large scale exploration. Machine learning (ML) models have turned out to be excellent emulators of small molecule DFT calculations and could possibly replace DFT in such tasks. For kinetics, success relies primarily on the models&#39; capability to accurately predict the potential energy surface around transition-states and minimal energy paths. Previously this has not been possible due to scarcity of relevant data in the literature. In this paper we train equivariant graph neural network-based models on data from 10 000 elementary reactions from the recently published Transition1x dataset. We apply the models as potentials for the nudged elastic band algorithm and achieve a mean average error of 0.23 eV and root mean squared error of 0.52 eV on barrier energies on unseen reactions. We compare the results against equivalent models trained on QM9x and ANI1x. We also compare with and outperform Density Functional based Tight Binding on both accuracy and required computational resources. The implication is that ML models are now at a level where they can be applied to studying chemical reaction kinetics given a sufficient amount of data relevant to this task.},
  archive      = {J_MLST},
  author       = {Mathias Schreiner and Arghya Bhowmik and Tejs Vegge and Peter Bjørn Jørgensen and Ole Winther},
  doi          = {10.1088/2632-2153/aca23e},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045022},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {NeuralNEB—neural networks can find reaction paths fast},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constraints on parameter choices for successful time-series
prediction with echo-state networks. <em>MLST</em>, <em>3</em>(4),
045021. (<a href="https://doi.org/10.1088/2632-2153/aca1f6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echo-state networks are simple models of discrete dynamical systems driven by a time series. By selecting network parameters such that the dynamics of the network is contractive, characterized by a negative maximal Lyapunov exponent, the network may synchronize with the driving signal. Exploiting this synchronization, the echo-state network may be trained to autonomously reproduce the input dynamics, enabling time-series prediction. However, while synchronization is a necessary condition for prediction, it is not sufficient. Here, we study what other conditions are necessary for successful time-series prediction. We identify two key parameters for prediction performance, and conduct a parameter sweep to find regions where prediction is successful. These regions differ significantly depending on whether full or partial phase space information about the input is provided to the network during training. We explain how these regions emerge.},
  archive      = {J_MLST},
  author       = {L Storm and K Gustavsson and B Mehlig},
  doi          = {10.1088/2632-2153/aca1f6},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045021},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Constraints on parameter choices for successful time-series prediction with echo-state networks},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Boost invariant polynomials for efficient jet tagging.
<em>MLST</em>, <em>3</em>(4), 04LT05. (<a
href="https://doi.org/10.1088/2632-2153/aca9ca">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the vast amounts of data generated by modern particle detectors, computational efficiency is essential for many data-analysis jobs in high-energy physics. We develop a new class of physically interpretable boost invariant polynomial (BIP) features for jet tagging that achieves such efficiency. We show that, for both supervised and unsupervised tasks, integrating BIPs with conventional classification techniques leads to models achieving high accuracy on jet tagging benchmarks while being orders of magnitudes faster to train and evaluate than contemporary deep learning systems.},
  archive      = {J_MLST},
  author       = {Jose M Munoz and Ilyes Batatia and Christoph Ortner},
  doi          = {10.1088/2632-2153/aca9ca},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {04LT05},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Boost invariant polynomials for efficient jet tagging},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DIGS: Deep inference of galaxy spectra with neural posterior
estimation. <em>MLST</em>, <em>3</em>(4), 04LT04. (<a
href="https://doi.org/10.1088/2632-2153/ac98f4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of billion-galaxy surveys with complex data, the need of the hour is to efficiently model galaxy spectral energy distributions (SEDs) with robust uncertainty quantification. The combination of simulation-based inference (SBI) and amortized neural posterior estimation (NPE) has been successfully used to analyse simulated and real galaxy photometry both precisely and efficiently. In this work, we utilise this combination and build on existing literature to analyse simulated noisy galaxy spectra. Here, we demonstrate a proof-of-concept study of spectra that is (a) an efficient analysis of galaxy SEDs and inference of galaxy parameters with physically interpretable uncertainties; and (b) amortized calculations of posterior distributions of said galaxy parameters at the modest cost of a few galaxy fits with Markov chain Monte Carlo (MCMC) methods. We utilise the SED generator and inference framework Prospector to generate simulated spectra, and train a dataset of 2 × 10 6 spectra (corresponding to a five-parameter SED model) with NPE. We show that SBI—with its combination of fast and amortized posterior estimations—is capable of inferring accurate galaxy stellar masses and metallicities. Our uncertainty constraints are comparable to or moderately weaker than traditional inverse-modelling with Bayesian MCMC methods (e.g. 0.17 and 0.26 dex in stellar mass and metallicity for a given galaxy, respectively). We also find that our inference framework conducts rapid SED inference (0.9–1.2 × 10 5 galaxy spectra via SBI/NPE at the cost of 1 MCMC-based fit). With this work, we set the stage for further work that focuses of SED fitting of galaxy spectra with SBI, in the era of JWST galaxy survey programs and the wide-field Roman Space Telescope spectroscopic surveys.},
  archive      = {J_MLST},
  author       = {Gourav Khullar and Brian Nord and Aleksandra Ćiprijanović and Jason Poh and Fei Xu},
  doi          = {10.1088/2632-2153/ac98f4},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {04LT04},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {DIGS: Deep inference of galaxy spectra with neural posterior estimation},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discovering mechanisms for materials microstructure
optimization via reinforcement learning of a generative model.
<em>MLST</em>, <em>3</em>(4), 04LT03. (<a
href="https://doi.org/10.1088/2632-2153/aca004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of materials structure for optimizing functional properties and potentially, the discovery of novel behaviors is a keystone problem in materials science. In many cases microstructural models underpinning materials functionality are available and well understood. However, optimization of average properties via microstructural engineering often leads to combinatorically intractable problems. Here, we explore the use of the reinforcement learning (RL) for microstructure optimization targeting the discovery of the physical mechanisms behind enhanced functionalities. We illustrate that RL can provide insights into the mechanisms driving properties of interest in a 2D discrete Landau ferroelectrics simulator. Intriguingly, we find that non-trivial phenomena emerge if the rewards are assigned to favor physically impossible tasks, which we illustrate through rewarding RL agents to rotate polarization vectors to energetically unfavorable positions. We further find that strategies to induce polarization curl can be non-intuitive, based on analysis of learned agent policies. This study suggests that RL is a promising machine learning method for material design optimization tasks, and for better understanding the dynamics of microstructural simulations.},
  archive      = {J_MLST},
  author       = {Rama K Vasudevan and Erick Orozco and Sergei V Kalinin},
  doi          = {10.1088/2632-2153/aca004},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {04LT03},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Discovering mechanisms for materials microstructure optimization via reinforcement learning of a generative model},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variational monte carlo approach to partial differential
equations with neural networks. <em>MLST</em>, <em>3</em>(4), 04LT02.
(<a href="https://doi.org/10.1088/2632-2153/aca317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate numerical solution of partial differential equations (PDEs) is a central task in numerical analysis allowing to model a wide range of natural phenomena by employing specialized solvers depending on the scenario of application. Here, we develop a variational approach for solving PDEs governing the evolution of high dimensional probability distributions. Our approach naturally works on the unbounded continuous domain and encodes the full probability density function through its variational parameters, which are adapted dynamically during the evolution to optimally reflect the dynamics of the density. In contrast to previous works, this dynamical adaptation of the parameters is carried out using an explicit prescription avoiding iterative gradient descent. For the considered benchmark cases we observe excellent agreement with numerical solutions as well as analytical solutions for tasks that are challenging for traditional computational approaches.},
  archive      = {J_MLST},
  author       = {Moritz Reh and Martin Gärttner},
  doi          = {10.1088/2632-2153/aca317},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {04LT02},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Variational monte carlo approach to partial differential equations with neural networks},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incompleteness of graph neural networks for points clouds in
three dimensions. <em>MLST</em>, <em>3</em>(4), 045020. (<a
href="https://doi.org/10.1088/2632-2153/aca1f8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNN) are very popular methods in machine learning and have been applied very successfully to the prediction of the properties of molecules and materials. First-order GNNs are well known to be incomplete, i.e. there exist graphs that are distinct but appear identical when seen through the lens of the GNN. More complicated schemes have thus been designed to increase their resolving power. Applications to molecules (and more generally, point clouds), however, add a geometric dimension to the problem. The most straightforward and prevalent approach to construct graph representation for molecules regards atoms as vertices in a graph and draws a bond between each pair of atoms within a chosen cutoff. Bonds can be decorated with the distance between atoms, and the resulting &#39;distance graph NNs&#39; (dGNN) have empirically demonstrated excellent resolving power and are widely used in chemical ML, with all known indistinguishable configurations being resolved in the fully-connected limit, which is equivalent to infinite or sufficiently large cutoff. Here we present a counterexample that proves that dGNNs are not complete even for the restricted case of fully-connected graphs induced by 3D atom clouds. We construct pairs of distinct point clouds whose associated graphs are, for any cutoff radius, equivalent based on a first-order Weisfeiler-Lehman (WL) test. This class of degenerate structures includes chemically-plausible configurations, both for isolated structures and for infinite structures that are periodic in 1, 2, and 3 dimensions. The existence of indistinguishable configurations sets an ultimate limit to the expressive power of some of the well-established GNN architectures for atomistic machine learning. Models that explicitly use angular or directional information in the description of atomic environments can resolve this class of degeneracies.},
  archive      = {J_MLST},
  author       = {Sergey N Pozdnyakov and Michele Ceriotti},
  doi          = {10.1088/2632-2153/aca1f8},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045020},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Incompleteness of graph neural networks for points clouds in three dimensions},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Coot optimization based enhanced global pyramid network for
3D hand pose estimation. <em>MLST</em>, <em>3</em>(4), 045019. (<a
href="https://doi.org/10.1088/2632-2153/ac9fa5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its importance in various applications that need human-computer interaction (HCI), the field of 3D hand pose estimation (HPE) has recently got a lot of attention. The use of technological developments, such as deep learning networks has accelerated the development of reliable 3D HPE systems. Therefore, in this paper, a 3D HPE based on Enhanced Global Pyramid Network (EGPNet) is proposed. Initially, feature extraction is done by backbone model of DetNetwork with improved EGPNet. The EGPNet is enhanced by the Smish activation function. After the feature extraction, the HPE is performed based on 3D pose correction network. Additionally, to enhance the estimation performance, Coot optimization algorithm is used to optimize the error between estimated and ground truth hand pose. The effectiveness of the proposed method is experimented on Bharatanatyam, yoga, Kathakali and sign language datasets with different networks in terms of area under the curve, median end-point-error (EPE) and mean EPE. The Coot optimization is also compared with existing optimization algorithms.},
  archive      = {J_MLST},
  author       = {Pallavi Malavath and Nagaraju Devarakonda},
  doi          = {10.1088/2632-2153/ac9fa5},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045019},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Coot optimization based enhanced global pyramid network for 3D hand pose estimation},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Atomic structure generation from reconstructing structural
fingerprints. <em>MLST</em>, <em>3</em>(4), 045018. (<a
href="https://doi.org/10.1088/2632-2153/aca1f7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven machine learning methods have the potential to dramatically accelerate the rate of materials design over conventional human-guided approaches. These methods would help identify or, in the case of generative models, even create novel crystal structures of materials with a set of specified functional properties to then be synthesized or isolated in the laboratory. For crystal structure generation, a key bottleneck lies in developing suitable atomic structure fingerprints or representations for the machine learning model, analogous to the graph-based or SMILES representations used in molecular generation. However, finding data-efficient representations that are invariant to translations, rotations, and permutations, while remaining invertible to the Cartesian atomic coordinates remains an ongoing challenge. Here, we propose an alternative approach to this problem by taking existing non-invertible representations with the desired invariances and developing an algorithm to reconstruct the atomic coordinates through gradient-based optimization using automatic differentiation. This can then be coupled to a generative machine learning model which generates new materials within the representation space, rather than in the data-inefficient Cartesian space. In this work, we implement this end-to-end structure generation approach using atom-centered symmetry functions as the representation and conditional variational autoencoders as the generative model. We are able to successfully generate novel and valid atomic structures of sub-nanometer Pt nanoparticles as a proof of concept. Furthermore, this method can be readily extended to any suitable structural representation, thereby providing a powerful, generalizable framework towards structure-based generation.},
  archive      = {J_MLST},
  author       = {Victor Fung and Shuyi Jia and Jiaxin Zhang and Sirui Bi and Junqi Yin and P Ganesh},
  doi          = {10.1088/2632-2153/aca1f7},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045018},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Atomic structure generation from reconstructing structural fingerprints},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unified representation of molecules and crystals for machine
learning. <em>MLST</em>, <em>3</em>(4), 045017. (<a
href="https://doi.org/10.1088/2632-2153/aca005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate simulations of atomistic systems from first principles are limited by computational cost. In high-throughput settings, machine learning can reduce these costs significantly by accurately interpolating between reference calculations. For this, kernel learning approaches crucially require a representation that accommodates arbitrary atomistic systems. We introduce a many-body tensor representation that is invariant to translations, rotations, and nuclear permutations of same elements, unique, differentiable, can represent molecules and crystals, and is fast to compute. Empirical evidence for competitive energy and force prediction errors is presented for changes in molecular structure, crystal chemistry, and molecular dynamics using kernel regression and symmetric gradient-domain machine learning as models. Applicability is demonstrated for phase diagrams of Pt-group/transition-metal binary systems.},
  archive      = {J_MLST},
  author       = {Haoyan Huo and Matthias Rupp},
  doi          = {10.1088/2632-2153/aca005},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045017},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Unified representation of molecules and crystals for machine learning},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comparative study of different machine learning methods
for dissipative quantum dynamics. <em>MLST</em>, <em>3</em>(4), 045016.
(<a href="https://doi.org/10.1088/2632-2153/ac9a9d">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been recently shown that supervised machine learning (ML) algorithms can accurately and efficiently predict long-time population dynamics of dissipative quantum systems given only short-time population dynamics. In the present article we benchmarked 22 ML models on their ability to predict long-time dynamics of a two-level quantum system linearly coupled to harmonic bath. The models include uni- and bidirectional recurrent, convolutional, and fully-connected feedforward artificial neural networks (ANNs) and kernel ridge regression (KRR) with linear and most commonly used nonlinear kernels. Our results suggest that KRR with nonlinear kernels can serve as inexpensive yet accurate way to simulate long-time dynamics in cases where the constant length of input trajectories is appropriate. Convolutional gated recurrent unit model is found to be the most efficient ANN model.},
  archive      = {J_MLST},
  author       = {Luis E Herrera Rodríguez and Arif Ullah and Kennet J Rueda Espinosa and Pavlo O Dral and Alexei A Kananenka},
  doi          = {10.1088/2632-2153/ac9a9d},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045016},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A comparative study of different machine learning methods for dissipative quantum dynamics},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AugLiChem: Data augmentation library of chemical structures
for machine learning. <em>MLST</em>, <em>3</em>(4), 045015. (<a
href="https://doi.org/10.1088/2632-2153/ac9c84">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) has demonstrated the promise for accurate and efficient property prediction of molecules and crystalline materials. To develop highly accurate ML models for chemical structure property prediction, datasets with sufficient samples are required. However, obtaining clean and sufficient data of chemical properties can be expensive and time-consuming, which greatly limits the performance of ML models. Inspired by the success of data augmentations in computer vision and natural language processing, we developed AugLiChem: the data augmentation library for chemical structures. Augmentation methods for both crystalline systems and molecules are introduced, which can be utilized for fingerprint-based ML models and graph neural networks (GNNs). We show that using our augmentation strategies significantly improves the performance of ML models, especially when using GNNs. In addition, the augmentations that we developed can be used as a direct plug-in module during training and have demonstrated the effectiveness when implemented with different GNN models through the AugliChem library. The Python-based package for our implementation of Auglichem: Data augmentation library for chemical structures, is publicly available at: https://github.com/BaratiLab/AugLiChem .},
  archive      = {J_MLST},
  author       = {Rishikesh Magar and Yuyang Wang and Cooper Lorsung and Chen Liang and Hariharan Ramasubramanian and Peiyuan Li and Amir Barati Farimani},
  doi          = {10.1088/2632-2153/ac9c84},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045015},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {AugLiChem: Data augmentation library of chemical structures for machine learning},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine-learning accelerated identification of exfoliable
two-dimensional materials. <em>MLST</em>, <em>3</em>(4), 045014. (<a
href="https://doi.org/10.1088/2632-2153/ac9bca">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-dimensional (2D) materials have been a central focus of recent research because they host a variety of properties, making them attractive both for fundamental science and for applications. It is thus crucial to be able to identify accurately and efficiently if bulk three-dimensional (3D) materials are formed by layers held together by a weak binding energy that, thus, can be potentially exfoliated into 2D materials. In this work, we develop a machine-learning (ML) approach that, combined with a fast preliminary geometrical screening, is able to efficiently identify potentially exfoliable materials. Starting from a combination of descriptors for crystal structures, we work out a subset of them that are crucial for accurate predictions. Our final ML model, based on a random forest classifier, has a very high recall of 98%. Using a SHapely Additive exPlanations analysis, we also provide an intuitive explanation of the five most important variables of the model. Finally, we compare the performance of our best ML model with a deep neural network architecture using the same descriptors. To make our algorithms and models easily accessible, we publish an online tool on the Materials Cloud portal that only requires a bulk 3D crystal structure as input. Our tool thus provides a practical yet straightforward approach to assess whether any 3D compound can be exfoliated into 2D layers.},
  archive      = {J_MLST},
  author       = {Mohammad Tohidi Vahdat and Kumar Varoon Agrawal and Giovanni Pizzi},
  doi          = {10.1088/2632-2153/ac9bca},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045014},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine-learning accelerated identification of exfoliable two-dimensional materials},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving breast cancer diagnosis by incorporating raw
ultrasound parameters into machine learning. <em>MLST</em>,
<em>3</em>(4), 045013. (<a
href="https://doi.org/10.1088/2632-2153/ac9bcc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The improved diagnostic accuracy of ultrasound breast examinations remains an important goal. In this study, we propose a biophysical feature-based machine learning method for breast cancer detection to improve the performance beyond a benchmark deep learning algorithm and to furthermore provide a color overlay visual map of the probability of malignancy within a lesion. This overall framework is termed disease-specific imaging. Previously, 150 breast lesions were segmented and classified utilizing a modified fully convolutional network and a modified GoogLeNet, respectively. In this study multiparametric analysis was performed within the contoured lesions. Features were extracted from ultrasound radiofrequency, envelope, and log-compressed data based on biophysical and morphological models. The support vector machine with a Gaussian kernel constructed a nonlinear hyperplane, and we calculated the distance between the hyperplane and each feature&#39;s data point in multiparametric space. The distance can quantitatively assess a lesion and suggest the probability of malignancy that is color-coded and overlaid onto B-mode images. Training and evaluation were performed on in vivo patient data. The overall accuracy for the most common types and sizes of breast lesions in our study exceeded 98.0% for classification and 0.98 for an area under the receiver operating characteristic curve, which is more precise than the performance of radiologists and a deep learning system. Further, the correlation between the probability and Breast Imaging Reporting and Data System enables a quantitative guideline to predict breast cancer. Therefore, we anticipate that the proposed framework can help radiologists achieve more accurate and convenient breast cancer classification and detection.},
  archive      = {J_MLST},
  author       = {Jihye Baek and Avice M O’Connell and Kevin J Parker},
  doi          = {10.1088/2632-2153/ac9bcc},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045013},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Improving breast cancer diagnosis by incorporating raw ultrasound parameters into machine learning},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). “Flux+mutability”: A conditional generative approach to
one-class classification and anomaly detection. <em>MLST</em>,
<em>3</em>(4), 045012. (<a
href="https://doi.org/10.1088/2632-2153/ac9bcb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly Detection is becoming increasingly popular within the experimental physics community. At experiments such as the Large Hadron Collider, anomaly detection is growing in interest for finding new physics beyond the Standard Model. This paper details the implementation of a novel Machine Learning architecture, called Flux+Mutability, which combines cutting-edge conditional generative models with clustering algorithms. In the &#39;flux&#39; stage we learn the distribution of a reference class. The &#39;mutability&#39; stage at inference addresses if data significantly deviates from the reference class. We demonstrate the validity of our approach and its connection to multiple problems spanning from one-class classification to anomaly detection. In particular, we apply our method to the isolation of neutral showers in an electromagnetic calorimeter and show its performance in detecting anomalous dijets events from standard QCD background. This approach limits assumptions on the reference sample and remains agnostic to the complementary class of objects of a given problem. We describe the possibility of dynamically generating a reference population and defining selection criteria via quantile cuts. Remarkably this flexible architecture can be deployed for a wide range of problems, and applications like multi-class classification or data quality control are left for further exploration.},
  archive      = {J_MLST},
  author       = {C Fanelli and J Giroux and Z Papandreou},
  doi          = {10.1088/2632-2153/ac9bcb},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045012},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {‘Flux+Mutability’: A conditional generative approach to one-class classification and anomaly detection},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time semantic segmentation on FPGAs for autonomous
vehicles with hls4ml. <em>MLST</em>, <em>3</em>(4), 045011. (<a
href="https://doi.org/10.1088/2632-2153/ac9cb5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate how field programmable gate arrays can serve as hardware accelerators for real-time semantic segmentation tasks relevant for autonomous driving. Considering compressed versions of the ENet convolutional neural network architecture, we demonstrate a fully-on-chip deployment with a latency of 4.9 ms per image, using less than 30% of the available resources on a Xilinx ZCU102 evaluation board. The latency is reduced to 3 ms per image when increasing the batch size to ten, corresponding to the use case where the autonomous vehicle receives inputs from multiple cameras simultaneously. We show, through aggressive filter reduction and heterogeneous quantization-aware training, and an optimized implementation of convolutional layers, that the power consumption and resource utilization can be significantly reduced while maintaining accuracy on the Cityscapes dataset.},
  archive      = {J_MLST},
  author       = {Nicolò Ghielmetti and Vladimir Loncar and Maurizio Pierini and Marcel Roed and Sioni Summers and Thea Aarrestad and Christoffer Petersson and Hampus Linander and Jennifer Ngadiuba and Kelvin Lin and Philip Harris},
  doi          = {10.1088/2632-2153/ac9cb5},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045011},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Real-time semantic segmentation on FPGAs for autonomous vehicles with hls4ml},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). How robust are modern graph neural network potentials in
long and hot molecular dynamics simulations? <em>MLST</em>,
<em>3</em>(4), 045010. (<a
href="https://doi.org/10.1088/2632-2153/ac9955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have emerged as a powerful machine learning approach for the prediction of molecular properties. In particular, recently proposed advanced GNN models promise quantum chemical accuracy at a fraction of the computational cost. While the capabilities of such advanced GNNs have been extensively demonstrated on benchmark datasets, there have been few applications in real atomistic simulations. Here, we therefore put the robustness of GNN interatomic potentials to the test, using the recently proposed GemNet architecture as a testbed. Models are trained on the QM7-x database of organic molecules and used to perform extensive molecular dynamics simulations. We find that low test set errors are not sufficient for obtaining stable dynamics and that severe pathologies sometimes only become apparent after hundreds of ps of dynamics. Nonetheless, highly stable and transferable GemNet potentials can be obtained with sufficiently large training sets.},
  archive      = {J_MLST},
  author       = {Sina Stocker and Johannes Gasteiger and Florian Becker and Stephan Günnemann and Johannes T Margraf},
  doi          = {10.1088/2632-2153/ac9955},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045010},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {How robust are modern graph neural network potentials in long and hot molecular dynamics simulations?},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BenchML: An extensible pipelining framework for benchmarking
representations of materials and molecules at scale. <em>MLST</em>,
<em>3</em>(4), 040501. (<a
href="https://doi.org/10.1088/2632-2153/ac4d11">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a machine-learning (ML) framework for high-throughput benchmarking of diverse representations of chemical systems against datasets of materials and molecules. The guiding principle underlying the benchmarking approach is to evaluate raw descriptor performance by limiting model complexity to simple regression schemes while enforcing best ML practices, allowing for unbiased hyperparameter optimization, and assessing learning progress through learning curves along series of synchronized train-test splits. The resulting models are intended as baselines that can inform future method development, in addition to indicating how easily a given dataset can be learnt. Through a comparative analysis of the training outcome across a diverse set of physicochemical, topological and geometric representations, we glean insight into the relative merits of these representations as well as their interrelatedness.},
  archive      = {J_MLST},
  author       = {Carl Poelking and Felix A Faber and Bingqing Cheng},
  doi          = {10.1088/2632-2153/ac4d11},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {040501},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {BenchML: An extensible pipelining framework for benchmarking representations of materials and molecules at scale},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Chemical transformer compression for accelerating both
training and inference of molecular modeling. <em>MLST</em>,
<em>3</em>(4), 045009. (<a
href="https://doi.org/10.1088/2632-2153/ac99ba">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer models have been developed in molecular science with excellent performance in applications including quantitative structure-activity relationship (QSAR) and virtual screening (VS). Compared with other types of models, however, they are large and need voluminous data for training, which results in a high hardware requirement to abridge time for both training and inference processes. In this work, cross-layer parameter sharing (CLPS), and knowledge distillation (KD) are used to reduce the sizes of transformers in molecular science. Both methods not only have competitive QSAR predictive performance as compared to the original BERT model, but also are more parameter efficient. Furthermore, by integrating CLPS and KD into a two-state chemical network, we introduce a new deep lite chemical transformer model, DeLiCaTe. DeLiCaTe accomplishes 4 × faster rate for training and inference, due to a 10- and 3-times reduction of the number of parameters and layers, respectively. Meanwhile, the integrated model achieves comparable performance in QSAR and VS, because of capturing general-domain (basic structure) and task-specific knowledge (specific property prediction). Moreover, we anticipate that the model compression strategy provides a pathway to the creation of effective generative transformer models for organic drugs and material design.},
  archive      = {J_MLST},
  author       = {Yi Yu and Karl Börjesson},
  doi          = {10.1088/2632-2153/ac99ba},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045009},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Chemical transformer compression for accelerating both training and inference of molecular modeling},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Training-free hyperparameter optimization of neural networks
for electronic structures in matter. <em>MLST</em>, <em>3</em>(4),
045008. (<a href="https://doi.org/10.1088/2632-2153/ac9956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A myriad of phenomena in materials science and chemistry rely on quantum-level simulations of the electronic structure in matter. While moving to larger length and time scales has been a pressing issue for decades, such large-scale electronic structure calculations are still challenging despite modern software approaches and advances in high-performance computing. The silver lining in this regard is the use of machine learning to accelerate electronic structure calculations—this line of research has recently gained growing attention. The grand challenge therein is finding a suitable machine-learning model during a process called hyperparameter optimization. This, however, causes a massive computational overhead in addition to that of data generation. We accelerate the construction of neural network models by roughly two orders of magnitude by circumventing excessive training during the hyperparameter optimization phase. We demonstrate our workflow for Kohn–Sham density functional theory, the most popular computational method in materials science and chemistry.},
  archive      = {J_MLST},
  author       = {Lenz Fiedler and Nils Hoffmann and Parvez Mohammed and Gabriel A Popoola and Tamar Yovell and Vladyslav Oles and J Austin Ellis and Sivasankaran Rajamanickam and Attila Cangi},
  doi          = {10.1088/2632-2153/ac9956},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045008},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Training-free hyperparameter optimization of neural networks for electronic structures in matter},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Twin neural network regression is a semi-supervised
regression algorithm. <em>MLST</em>, <em>3</em>(4), 045007. (<a
href="https://doi.org/10.1088/2632-2153/ac9885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twin neural network regression (TNNR) is trained to predict differences between the target values of two different data points rather than the targets themselves. By ensembling predicted differences between the targets of an unseen data point and all training data points, it is possible to obtain a very accurate prediction for the original regression problem. Since any loop of predicted differences should sum to zero, loops can be supplied to the training data, even if the data points themselves within loops are unlabelled. Semi-supervised training improves TNNR performance, which is already state of the art, significantly.},
  archive      = {J_MLST},
  author       = {Sebastian J Wetzel and Roger G Melko and Isaac Tamblyn},
  doi          = {10.1088/2632-2153/ac9885},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045007},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Twin neural network regression is a semi-supervised regression algorithm},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gradients should stay on path: Better estimators of the
reverse- and forward KL divergence for normalizing flows. <em>MLST</em>,
<em>3</em>(4), 045006. (<a
href="https://doi.org/10.1088/2632-2153/ac9455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show how to use the path-wise derivative estimator for both the forward reverse Kullback–Leibler divergence for any practically invertible normalizing flow. The resulting path-gradient estimators are straightforward to implement, have lower variance, and lead not only to faster convergence of training but also to better overall approximation results compared to standard total gradient estimators. We also demonstrate that path-gradient training is less susceptible to mode-collapse. In light of our results, we expect that path-gradient estimators will become the new standard method to train normalizing flows for variational inference.},
  archive      = {J_MLST},
  author       = {Lorenz Vaitl and Kim A Nicoli and Shinichi Nakajima and Pan Kessel},
  doi          = {10.1088/2632-2153/ac9455},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045006},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Gradients should stay on path: Better estimators of the reverse- and forward KL divergence for normalizing flows},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Physics-based representations for machine learning
properties of chemical reactions. <em>MLST</em>, <em>3</em>(4), 045005.
(<a href="https://doi.org/10.1088/2632-2153/ac8f1a">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-based representations constructed using only atomic positions and nuclear charges (also known as quantum machine learning, QML) allow for the reliable and efficient inference of molecular properties from training data. Chemistry is a science rooted in chemical reactions, naturally involving multiple molecular species. Here, we extend QML&#39;s capabilities to include the prediction of reaction properties by defining reaction representations : representations taking as input multiple molecules participating in a reaction, each represented by their corresponding atomic charges and three-dimensional coordinates. Several reaction representations are constructed from established molecular ones and benchmarked on four datasets representative of thermodynamic or kinetic reaction properties. One of these, the Hydroform-22-TS dataset (2350 energy barriers), is introduced as part of this work. The relevant ingredients for a high-performing reaction representation are extracted and used to construct the Bond-Based Reaction Representation ( B^2R^2 ) for the prediction of quantum-chemical properties of chemical reactions. Finally, variations of B^2R^2 with varying representation size vs. performance are provided.},
  archive      = {J_MLST},
  author       = {Puck van Gerwen and Alberto Fabrizio and Matthew D Wodrich and Clemence Corminboeuf},
  doi          = {10.1088/2632-2153/ac8f1a},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045005},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Physics-based representations for machine learning properties of chemical reactions},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Near-optimal control of dynamical systems with neural
ordinary differential equations. <em>MLST</em>, <em>3</em>(4), 045004.
(<a href="https://doi.org/10.1088/2632-2153/ac92c3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal control problems naturally arise in many scientific applications where one wishes to steer a dynamical system from an initial state x 0 to a desired target state \mathbf{x}^* in finite time T . Recent advances in deep learning and neural network–based optimization have contributed to the development of numerical methods that can help solve control problems involving high-dimensional dynamical systems. In particular, the framework of neural ordinary differential equations (neural ODEs) provides an efficient means to iteratively approximate continuous-time control functions associated with analytically intractable and computationally demanding control tasks. Although neural ODE controllers have shown great potential in solving complex control problems, the understanding of the effects of hyperparameters such as network structure and optimizers on learning performance is still very limited. Our work aims at addressing some of these knowledge gaps to conduct efficient hyperparameter optimization. To this end, we first analyze how truncated and non-truncated backpropagation through time affect both runtime performance and the ability of neural networks to learn optimal control functions. Using analytical and numerical methods, we then study the role of parameter initializations, optimizers, and neural-network architecture. Finally, we connect our results to the ability of neural ODE controllers to implicitly regularize control energy.},
  archive      = {J_MLST},
  author       = {Lucas Böttcher and Thomas Asikis},
  doi          = {10.1088/2632-2153/ac92c3},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045004},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Near-optimal control of dynamical systems with neural ordinary differential equations},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient data acquisition and training of
collisional-radiative model artificial neural network surrogates through
adaptive parameter space sampling. <em>MLST</em>, <em>3</em>(4), 045003.
(<a href="https://doi.org/10.1088/2632-2153/ac93e7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective plasma transport modeling of magnetically confined fusion devices relies on having an accurate understanding of the ion composition and radiative power losses of the plasma. Generally, these quantities can be obtained from solutions of a collisional-radiative (CR) model at each time step within a plasma transport simulation. However, even compact, approximate CR models can be computationally onerous to evaluate, and in-situ evaluation of these models within a larger plasma transport code can lead to a rigid bottleneck. As a way to bypass this bottleneck, we propose deploying artificial neural network (ANN) surrogates to allow rapid evaluation of the necessary plasma quantities. However, one issue with training an accurate ANN surrogate is the reliance on a sufficiently large and representative training and validation data set, which can be time-consuming to generate. In this work we explore a data-driven active learning and training routine to allow autonomous adaptive sampling of the problem parameter space to ensure a sufficiently large and meaningful set of training data is assembled for the network training. As a result, we can demonstrate approximately order-of-magnitude savings in required training data samples to produce an accurate surrogate.},
  archive      = {J_MLST},
  author       = {Nathan A Garland and Romit Maulik and Qi Tang and Xian-Zhu Tang and Prasanna Balaprakash},
  doi          = {10.1088/2632-2153/ac93e7},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045003},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Efficient data acquisition and training of collisional-radiative model artificial neural network surrogates through adaptive parameter space sampling},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Shift-curvature, SGD, and generalization. <em>MLST</em>,
<em>3</em>(4), 045002. (<a
href="https://doi.org/10.1088/2632-2153/ac92c4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A longstanding debate surrounds the related hypotheses that low-curvature minima generalize better, and that stochastic gradient descent (SGD) discourages curvature. We offer a more complete and nuanced view in support of both hypotheses. First, we show that curvature harms test performance through two new mechanisms, the shift-curvature and bias-curvature, in addition to a known parameter-covariance mechanism. The shift refers to the difference between train and test local minima, and the bias and covariance are those of the parameter distribution. These three curvature-mediated contributions to test performance are reparametrization-invariant even though curvature itself is not. Although the shift is unknown at training time, the shift-curvature as well as the other mechanisms can still be mitigated by minimizing overall curvature. Second, we derive a new, explicit SGD steady-state distribution showing that SGD optimizes an effective potential related to but different from train loss, and that SGD noise mediates a trade-off between low-loss versus low-curvature regions of this effective potential. Third, combining our test performance analysis with the SGD steady state shows that for small SGD noise, the shift-curvature is the dominant of the three mechanisms. Our experiments demonstrate the significant impact of shift-curvature on test loss, and further explore the relationship between SGD noise and curvature.},
  archive      = {J_MLST},
  author       = {Arwen V Bradley and Carlos A Gomez-Uribe and Manish Reddy Vuyyuru},
  doi          = {10.1088/2632-2153/ac92c4},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045002},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Shift-curvature, SGD, and generalization},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Laplace HypoPINN: Physics-informed neural network for
hypocenter localization and its predictive uncertainty. <em>MLST</em>,
<em>3</em>(4), 045001. (<a
href="https://doi.org/10.1088/2632-2153/ac94b3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several techniques have been proposed over the years for automatic hypocenter localization. While those techniques have pros and cons that trade-off computational efficiency and the susceptibility of getting trapped in local minima, an alternate approach is needed that allows robust localization performance and holds the potential to make the elusive goal of real-time microseismic monitoring possible. Physics-informed neural networks (PINNs) have appeared on the scene as a flexible and versatile framework for solving partial differential equations (PDEs) along with the associated initial or boundary conditions. We develop HypoPINN —a PINN-based inversion framework for hypocenter localization and introduce an approximate Bayesian framework for estimating its predictive uncertainties. This work focuses on predicting the hypocenter locations using HypoPINN and investigates the propagation of uncertainties from the random realizations of HypoPINN&#39;s weights and biases using the Laplace approximation. We train HypoPINN to obtain the optimized weights for predicting hypocenter location. Next, we approximate the covariance matrix at the optimized HypoPINN&#39;s weights for posterior sampling with the Laplace approximation. The posterior samples represent various realizations of HypoPINN&#39;s weights. Finally, we predict the locations of the hypocenter associated with those weights&#39; realizations to investigate the uncertainty propagation that comes from those realizations. We demonstrate the features of this methodology through several numerical examples, including using the Otway velocity model based on the Otway project in Australia.},
  archive      = {J_MLST},
  author       = {Muhammad Izzatullah and Isa Eren Yildirim and Umair Bin Waheed and Tariq Alkhalifah},
  doi          = {10.1088/2632-2153/ac94b3},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Laplace HypoPINN: Physics-informed neural network for hypocenter localization and its predictive uncertainty},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Physics-AI symbiosis. <em>MLST</em>, <em>3</em>(4), 041001.
(<a href="https://doi.org/10.1088/2632-2153/ac9215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The phenomenal success of physics in explaining nature and engineering machines is predicated on low dimensional deterministic models that accurately describe a wide range of natural phenomena. Physics provides computational rules that govern physical systems and the interactions of the constituents therein. Led by deep neural networks, artificial intelligence (AI) has introduced an alternate data-driven computational framework, with astonishing performance in domains that do not lend themselves to deterministic models such as image classification and speech recognition. These gains, however, come at the expense of predictions that are inconsistent with the physical world as well as computational complexity, with the latter placing AI on a collision course with the expected end of the semiconductor scaling known as Moore&#39;s Law. This paper argues how an emerging symbiosis of physics and AI can overcome such formidable challenges, thereby not only extending AI&#39;s spectacular rise but also transforming the direction of engineering and physical science.},
  archive      = {J_MLST},
  author       = {Bahram Jalali and Yiming Zhou and Achuta Kadambi and Vwani Roychowdhury},
  doi          = {10.1088/2632-2153/ac9215},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {4},
  pages        = {041001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Physics-AI symbiosis},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-centric machine learning in quantum information
science. <em>MLST</em>, <em>3</em>(4), 04LT01. (<a
href="https://doi.org/10.1088/2632-2153/ac9036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a series of data-centric heuristics for improving the performance of machine learning systems when applied to problems in quantum information science. In particular, we consider how systematic engineering of training sets can significantly enhance the accuracy of pre-trained neural networks used for quantum state reconstruction without altering the underlying architecture. We find that it is not always optimal to engineer training sets to exactly match the expected distribution of a target scenario, and instead, performance can be further improved by biasing the training set to be slightly more mixed than the target. This is due to the heterogeneity in the number of free variables required to describe states of different purity, and as a result, overall accuracy of the network improves when training sets of a fixed size focus on states with the least constrained free variables. For further clarity, we also include a &#39;toy model&#39; demonstration of how spurious correlations can inadvertently enter synthetic data sets used for training, how the performance of systems trained with these correlations can degrade dramatically, and how the inclusion of even relatively few counterexamples can effectively remedy such problems.},
  archive      = {J_MLST},
  author       = {Sanjaya Lohani and Joseph M Lukens and Ryan T Glasser and Thomas A Searles and Brian T Kirby},
  doi          = {10.1088/2632-2153/ac9036},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {4},
  pages        = {04LT01},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Data-centric machine learning in quantum information science},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving parametric neural networks for high-energy physics
(and beyond). <em>MLST</em>, <em>3</em>(3), 035017. (<a
href="https://doi.org/10.1088/2632-2153/ac917c">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signal-background classification is a central problem in high-energy physics, that plays a major role for the discovery of new fundamental particles. A recent method—the parametric neural network (pNN)—leverages multiple signal mass hypotheses as an additional input feature to effectively replace a whole set of individual classifiers, each providing (in principle) the best response for the corresponding mass hypothesis. In this work we aim at deepening the understanding of pNNs in light of real-world usage. We discovered several peculiarities of parametric networks, providing intuition, metrics, and guidelines to them. We further propose an alternative parametrization scheme, resulting in a new parametrized neural network architecture: the AffinePNN; along with many other generally applicable improvements, like the balanced training procedure. Finally, we extensively and empirically evaluate our models on the HEPMASS dataset, along its imbalanced version (called HEPMASS-IMB ) we provide here for the first time, to further validate our approach. Provided results are in terms of the impact of the proposed design decisions, classification performance, and interpolation capability, as well.},
  archive      = {J_MLST},
  author       = {Luca Anzalone and Tommaso Diotalevi and Daniele Bonacorsi},
  doi          = {10.1088/2632-2153/ac917c},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {3},
  pages        = {035017},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Improving parametric neural networks for high-energy physics (and beyond)},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fully bayesian estimation of virtual brain parameters with
self-tuning hamiltonian monte carlo. <em>MLST</em>, <em>3</em>(3),
035016. (<a href="https://doi.org/10.1088/2632-2153/ac9037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual brain models are data-driven patient-specific brain models integrating individual brain imaging data with neural mass modeling in a single computational framework, capable of autonomously generating brain activity and its associated brain imaging signals. Along the example of epilepsy, we develop an efficient and accurate Bayesian methodology estimating the parameters linked to the extent of the epileptogenic zone. State-of-the-art advances in Bayesian inference using Hamiltonian Monte Carlo (HMC) algorithms have remained elusive for large-scale differential-equations based models due to their slow convergence. We propose appropriate priors and a novel reparameterization to facilitate efficient exploration of the posterior distribution in terms of computational time and convergence diagnostics. The methodology is illustrated for in-silico dataset and then, applied to infer the personalized model parameters based on the empirical stereotactic electroencephalography recordings of retrospective patients. This improved methodology may pave the way to render HMC methods sufficiently easy and efficient to use, thus applicable in personalized medicine.},
  archive      = {J_MLST},
  author       = {Jayant Jha and Meysam Hashemi and Anirudh Nihalani Vattikonda and Huifang Wang and Viktor Jirsa},
  doi          = {10.1088/2632-2153/ac9037},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035016},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Fully bayesian estimation of virtual brain parameters with self-tuning hamiltonian monte carlo},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Metric learning for kernel ridge regression: Assessment of
molecular similarity. <em>MLST</em>, <em>3</em>(3), 035015. (<a
href="https://doi.org/10.1088/2632-2153/ac8e4f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised and unsupervised kernel-based algorithms widely used in the physical sciences depend upon the notion of similarity . Their reliance on pre-defined distance metrics—e.g. the Euclidean or Manhattan distance—are problematic especially when used in combination with high-dimensional feature vectors for which the similarity measure does not well-reflect the differences in the target property. Metric learning is an elegant approach to surmount this shortcoming and find a property-informed transformation of the feature space. We propose a new algorithm for metric learning specifically adapted for kernel ridge regression (KRR): metric learning for kernel ridge regression (MLKRR). It is based on the Metric Learning for Kernel Regression framework using the Nadaraya-Watson estimator, which we show to be inferior to the KRR estimator for typical physics-based machine learning tasks. The MLKRR algorithm allows for superior predictive performance on the benchmark regression task of atomisation energies of QM9 molecules, as well as generating more meaningful low-dimensional projections of the modified feature space.},
  archive      = {J_MLST},
  author       = {Raimon Fabregat and Puck van Gerwen and Matthieu Haeberle and Friedrich Eisenbrand and Clémence Corminboeuf},
  doi          = {10.1088/2632-2153/ac8e4f},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035015},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Metric learning for kernel ridge regression: Assessment of molecular similarity},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Numerical metrics for complete intersection and
kreuzer–skarke calabi–yau manifolds. <em>MLST</em>, <em>3</em>(3),
035014. (<a href="https://doi.org/10.1088/2632-2153/ac8e4e">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce neural networks (NNs) to compute numerical Ricci-flat Calabi–Yau (CY) metrics for complete intersection and Kreuzer–Skarke (KS) CY manifolds at any point in Kähler and complex structure moduli space, and introduce the package cymetric which provides computation realizations of these techniques. In particular, we develop and computationally realize methods for point-sampling on these manifolds. The training for the NNs is carried out subject to a custom loss function. The Kähler class is fixed by adding to the loss a component which enforces the slopes of certain line bundles to match with topological computations. Our methods are applied to various manifolds, including the quintic manifold, the bi-cubic manifold and a KS manifold with Picard number two. We show that volumes and line bundle slopes can be reliably computed from the resulting Ricci-flat metrics. We also apply our results to compute an approximate Hermitian–Yang–Mills connection on a specific line bundle on the bi-cubic.},
  archive      = {J_MLST},
  author       = {Magdalena Larfors and Andre Lukas and Fabian Ruehle and Robin Schneider},
  doi          = {10.1088/2632-2153/ac8e4e},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035014},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Numerical metrics for complete intersection and Kreuzer–Skarke Calabi–Yau manifolds},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Subaging in underparametrized deep neural networks.
<em>MLST</em>, <em>3</em>(3), 035013. (<a
href="https://doi.org/10.1088/2632-2153/ac8f1b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a simple classification problem to show that the dynamics of finite–width Deep Neural Networks in the underparametrized regime gives rise to effects similar to those associated with glassy systems, namely a slow evolution of the loss function and aging. Remarkably, the aging is sublinear in the waiting time (subaging) and the power–law exponent characterizing it is robust to different architectures under the constraint of a constant total number of parameters. Our results are maintained in the more complex scenario of the MNIST database. We find that for this database there is a unique exponent ruling the subaging behavior in the whole phase.},
  archive      = {J_MLST},
  author       = {Carolina Herrera Segura and Edison Montoya and Diego Tapias},
  doi          = {10.1088/2632-2153/ac8f1b},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035013},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Subaging in underparametrized deep neural networks},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning tree structures from leaves for particle decay
reconstruction. <em>MLST</em>, <em>3</em>(3), 035012. (<a
href="https://doi.org/10.1088/2632-2153/ac8de0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a neural approach to reconstructing rooted tree graphs describing hierarchical interactions, using a novel representation we term the lowest common ancestor generations (LCAG) matrix. This compact formulation is equivalent to the adjacency matrix, but enables learning a tree&#39;s structure from its leaves alone without the prior assumptions required if using the adjacency matrix directly. Employing the LCAG therefore enables the first end-to-end trainable solution which learns the hierarchical structure of varying tree sizes directly, using only the terminal tree leaves to do so. In the case of high-energy particle physics, a particle decay forms a hierarchical tree structure of which only the final products can be observed experimentally, and the large combinatorial space of possible trees makes an analytic solution intractable. We demonstrate the use of the LCAG as a target in the task of predicting simulated particle physics decay structures using both a Transformer encoder and a neural relational inference encoder graph neural network. With this approach, we are able to correctly predict the LCAG purely from leaf features for a maximum tree-depth of 8 in 92.5\% of cases for trees up to 6 leaves (including) and 59.7\% for trees up to 10 in our simulated dataset.},
  archive      = {J_MLST},
  author       = {James Kahn and Ilias Tsaklidis and Oskar Taubert and Lea Reuter and Giulio Dujany and Tobias Boeckh and Arthur Thaller and Pablo Goldenzweig and Florian Bernlochner and Achim Streit and Markus Götz},
  doi          = {10.1088/2632-2153/ac8de0},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035012},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Learning tree structures from leaves for particle decay reconstruction},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FINETUNA: Fine-tuning accelerated molecular simulations.
<em>MLST</em>, <em>3</em>(3), 03LT01. (<a
href="https://doi.org/10.1088/2632-2153/ac8fe0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Progress towards the energy breakthroughs needed to combat climate change can be significantly accelerated through the efficient simulation of atomistic systems. However, simulation techniques based on first principles, such as density functional theory (DFT), are limited in their practical use due to their high computational expense. Machine learning approaches have the potential to approximate DFT in a computationally efficient manner, which could dramatically increase the impact of computational simulations on real-world problems. However, they are limited by their accuracy and the cost of generating labeled data. Here, we present an online active learning framework for accelerating the simulation of atomic systems efficiently and accurately by incorporating prior physical information learned by large-scale pre-trained graph neural network models from the Open Catalyst Project. Accelerating these simulations enables useful data to be generated more cheaply, allowing better models to be trained and more atomistic systems to be screened. We also present a method of comparing local optimization techniques on the basis of both their speed and accuracy. Experiments on 30 benchmark adsorbate-catalyst systems show that our method of transfer learning to incorporate prior information from pre-trained models accelerates simulations by reducing the number of DFT calculations by 91%, while meeting an accuracy threshold of 0.02 eV 93% of the time. Finally, we demonstrate a technique for leveraging the interactive functionality built in to Vienna ab initio Simulation Package (VASP) to efficiently compute single point calculations within our online active learning framework without the significant startup costs. This allows VASP to work in tandem with our framework while requiring 75% fewer self-consistent cycles than conventional single point calculations. The online active learning implementation, and examples using the VASP interactive code, are available in the open source FINETUNA package on Github.},
  archive      = {J_MLST},
  author       = {Joseph Musielewicz and Xiaoxiao Wang and Tian Tian and Zachary Ulissi},
  doi          = {10.1088/2632-2153/ac8fe0},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {03LT01},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {FINETUNA: Fine-tuning accelerated molecular simulations},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A duality connecting neural network and cosmological
dynamics. <em>MLST</em>, <em>3</em>(3), 035011. (<a
href="https://doi.org/10.1088/2632-2153/ac87e9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We demonstrate that the dynamics of neural networks (NNs) trained with gradient descent and the dynamics of scalar fields in a flat, vacuum energy dominated Universe are structurally profoundly related. This duality provides the framework for synergies between these systems, to understand and explain NN dynamics and new ways of simulating and describing early Universe models. Working in the continuous-time limit of NNs, we analytically match the dynamics of the mean background and the dynamics of small perturbations around the mean field, highlighting potential differences in separate limits. We perform empirical tests of this analytic description and quantitatively show the dependence of the effective field theory parameters on hyperparameters of the NN. As a result of this duality, the cosmological constant is matched inversely to the learning rate in the gradient descent update.},
  archive      = {J_MLST},
  author       = {Sven Krippendorf and Michael Spannowsky},
  doi          = {10.1088/2632-2153/ac87e9},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035011},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A duality connecting neural network and cosmological dynamics},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A biology-informed similarity metric for simulated patches
of human cell membrane. <em>MLST</em>, <em>3</em>(3), 035010. (<a
href="https://doi.org/10.1088/2632-2153/ac8523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex scientific inquiries rely increasingly upon large and autonomous multiscale simulation campaigns, which fundamentally require similarity metrics to quantify &#39;sufficient&#39; changes among data and/or configurations. However, subject matter experts are often unable to articulate similarity precisely or in terms of well-formulated definitions, especially when new hypotheses are to be explored, making it challenging to design a meaningful metric. Furthermore, the key to practical usefulness of such metrics to enable autonomous simulations lies in in situ inference, which requires generalization to possibly substantial distributional shifts in unseen, future data. Here, we address these challenges in a cancer biology application and develop a meaningful similarity metric for &#39;patches&#39; —regions of simulated human cell membrane that express interactions between certain proteins of interest and relevant lipids. In the absence of well-defined conditions for similarity, we leverage several biology-informed notions about data and the underlying simulations to impose inductive biases on our metric learning framework, resulting in a suitable similarity metric that also generalizes well to significant distributional shifts encountered during the deployment. We combine these intuitions to organize the learned embedding space in a multiscale manner, which makes the metric robust to incomplete and even contradictory intuitions. Our approach delivers a metric that not only performs well on the conditions used for its development and other relevant criteria, but also learns key spatiotemporal relationships without ever being exposed to any such information during training.},
  archive      = {J_MLST},
  author       = {Harsh Bhatia and Jayaraman J Thiagarajan and Rushil Anirudh and T S Jayram and Tomas Oppelstrup and Helgi I Ingólfsson and Felice C Lightstone and Peer-Timo Bremer},
  doi          = {10.1088/2632-2153/ac8523},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035010},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A biology-informed similarity metric for simulated patches of human cell membrane},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RG-flow: A hierarchical and explainable flow model based on
renormalization group and sparse prior. <em>MLST</em>, <em>3</em>(3),
035009. (<a href="https://doi.org/10.1088/2632-2153/ac8393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flow-based generative models have become an important class of unsupervised learning approaches. In this work, we incorporate the key ideas of renormalization group (RG) and sparse prior distribution to design a hierarchical flow-based generative model, RG-Flow, which can separate information at different scales of images and extract disentangled representations at each scale. We demonstrate our method on synthetic multi-scale image datasets and the CelebA dataset, showing that the disentangled representations enable semantic manipulation and style mixing of the images at different scales. To visualize the latent representations, we introduce receptive fields for flow-based models and show that the receptive fields of RG-Flow are similar to those of convolutional neural networks. In addition, we replace the widely adopted isotropic Gaussian prior distribution by the sparse Laplacian distribution to further enhance the disentanglement of representations. From a theoretical perspective, our proposed method has O(\log L) complexity for inpainting of an image with edge length L , compared to previous generative models with O(L^2) complexity.},
  archive      = {J_MLST},
  author       = {Hong-Ye Hu and Dian Wu and Yi-Zhuang You and Bruno Olshausen and Yubei Chen},
  doi          = {10.1088/2632-2153/ac8393},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035009},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {RG-flow: A hierarchical and explainable flow model based on renormalization group and sparse prior},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Curiosity in exploring chemical spaces: Intrinsic rewards
for molecular reinforcement learning. <em>MLST</em>, <em>3</em>(3),
035008. (<a href="https://doi.org/10.1088/2632-2153/ac7ddc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer aided design of molecules has the potential to disrupt the field of drug and material discovery. Machine learning and deep learning in particular, made big strides in recent years and promises to greatly benefit computer aided methods. Reinforcement learning is a particularly promising approach since it enables de novo molecule design, that is molecular design, without providing any prior knowledge. However, the search space is vast, and therefore any reinforcement learning agent needs to perform efficient exploration. In this study, we examine three versions of intrinsic motivation to aid efficient exploration. The algorithms are adapted from intrinsic motivation in the literature that were developed in other settings, predominantly video games. We show that the curious agents finds better performing molecules on two of three benchmarks. This indicates an exciting new research direction for reinforcement learning agents that can explore the chemical space out of their own motivation. This has the potential to eventually lead to unexpected new molecular designs no human has thought about so far.},
  archive      = {J_MLST},
  author       = {Luca A Thiede and Mario Krenn and AkshatKumar Nigam and Alán Aspuru-Guzik},
  doi          = {10.1088/2632-2153/ac7ddc},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035008},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Curiosity in exploring chemical spaces: Intrinsic rewards for molecular reinforcement learning},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DeepAdversaries: Examining the robustness of deep learning
models for galaxy morphology classification. <em>MLST</em>,
<em>3</em>(3), 035007. (<a
href="https://doi.org/10.1088/2632-2153/ac7f1a">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With increased adoption of supervised deep learning methods for work with cosmological survey data, the assessment of data perturbation effects (that can naturally occur in the data processing and analysis pipelines) and the development of methods that increase model robustness are increasingly important. In the context of morphological classification of galaxies, we study the effects of perturbations in imaging data. In particular, we examine the consequences of using neural networks when training on baseline data and testing on perturbed data. We consider perturbations associated with two primary sources: (a) increased observational noise as represented by higher levels of Poisson noise and (b) data processing noise incurred by steps such as image compression or telescope errors as represented by one-pixel adversarial attacks. We also test the efficacy of domain adaptation techniques in mitigating the perturbation-driven errors. We use classification accuracy, latent space visualizations, and latent space distance to assess model robustness in the face of these perturbations. For deep learning models without domain adaptation, we find that processing pixel-level errors easily flip the classification into an incorrect class and that higher observational noise makes the model trained on low-noise data unable to classify galaxy morphologies. On the other hand, we show that training with domain adaptation improves model robustness and mitigates the effects of these perturbations, improving the classification accuracy up to 23% on data with higher observational noise. Domain adaptation also increases up to a factor of {\approx}2.3 the latent space distance between the baseline and the incorrectly classified one-pixel perturbed image, making the model more robust to inadvertent perturbations. Successful development and implementation of methods that increase model robustness in astronomical survey pipelines will help pave the way for many more uses of deep learning for astronomy.},
  archive      = {J_MLST},
  author       = {Aleksandra Ćiprijanović and Diana Kafkes and Gregory Snyder and F Javier Sánchez and Gabriel Nathan Perdue and Kevin Pedro and Brian Nord and Sandeep Madireddy and Stefan M Wild},
  doi          = {10.1088/2632-2153/ac7f1a},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035007},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {DeepAdversaries: Examining the robustness of deep learning models for galaxy morphology classification},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-dimensional encryption in optical fibers using spatial
modes of light and machine learning. <em>MLST</em>, <em>3</em>(3),
035006. (<a href="https://doi.org/10.1088/2632-2153/ac7f1b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to engineer the spatial wavefunction of photons has enabled a variety of quantum protocols for communication, sensing, and information processing. These protocols exploit the high dimensionality of structured light enabling the encoding of multiple bits of information in a single photon, the measurement of small physical parameters, and the achievement of unprecedented levels of security in schemes for cryptography. Unfortunately, the potential of structured light has been restrained to free-space platforms in which the spatial profile of photons is preserved. Here, we make an important step forward to using structured light for fiber optical communication. We introduce a classical encryption protocol in which the propagation of high-dimensional spatial modes in multimode fibers is used as a natural mechanism for encryption. This provides a secure communication channel for data transmission. The information encoded in spatial modes is retrieved using artificial neural networks, which are trained from the intensity distributions of experimentally detected spatial modes. Our on-fiber communication platform allows us to use single spatial modes for information encoding as well as the high-dimensional superposition modes for bit-by-bit and byte-by-byte encoding respectively. This protocol enables one to recover messages and images with almost perfect accuracy. Our classical smart protocol for high-dimensional encryption in optical fibers provides a platform that can be adapted to address increased per-photon information capacity at the quantum level, while maintaining the fidelity of information transfer. This is key for quantum technologies relying on structured fields of light, particularly those that are challenged by free-space propagation.},
  archive      = {J_MLST},
  author       = {Michelle L J Lollie and Fatemeh Mostafavi and Narayan Bhusal and Mingyuan Hong and Chenglong You and Roberto de J León-Montiel and Omar S Magaña-Loaiza and Mario A Quiroz-Juárez},
  doi          = {10.1088/2632-2153/ac7f1b},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035006},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {High-dimensional encryption in optical fibers using spatial modes of light and machine learning},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning via message passing algorithms based on belief
propagation. <em>MLST</em>, <em>3</em>(3), 035005. (<a
href="https://doi.org/10.1088/2632-2153/ac7d3b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Message-passing algorithms based on the belief propagation (BP) equations constitute a well-known distributed computational scheme. They yield exact marginals on tree-like graphical models and have also proven to be effective in many problems defined on loopy graphs, from inference to optimization, from signal processing to clustering. The BP-based schemes are fundamentally different from stochastic gradient descent (SGD), on which the current success of deep networks is based. In this paper, we present and adapt to mini-batch training on GPUs a family of BP-based message-passing algorithms with a reinforcement term that biases distributions towards locally entropic solutions. These algorithms are capable of training multi-layer neural networks with performance comparable to SGD heuristics in a diverse set of experiments on natural datasets including multi-class image classification and continual learning, while being capable of yielding improved performances on sparse networks. Furthermore, they allow to make approximate Bayesian predictions that have higher accuracy than point-wise ones.},
  archive      = {J_MLST},
  author       = {Carlo Lucibello and Fabrizio Pittorino and Gabriele Perugini and Riccardo Zecchina},
  doi          = {10.1088/2632-2153/ac7d3b},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035005},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Deep learning via message passing algorithms based on belief propagation},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantum neural networks force fields generation.
<em>MLST</em>, <em>3</em>(3), 035004. (<a
href="https://doi.org/10.1088/2632-2153/ac7d3c">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate molecular force fields are of paramount importance for the efficient implementation of molecular dynamics techniques at large scales. In the last decade, machine learning (ML) methods have demonstrated impressive performances in predicting accurate values for energy and forces when trained on finite size ensembles generated with ab initio techniques. At the same time, quantum computers have recently started to offer new viable computational paradigms to tackle such problems. On the one hand, quantum algorithms may notably be used to extend the reach of electronic structure calculations. On the other hand, quantum ML is also emerging as an alternative and promising path to quantum advantage. Here we follow this second route and establish a direct connection between classical and quantum solutions for learning neural network (NN) potentials. To this end, we design a quantum NN architecture and apply it successfully to different molecules of growing complexity. The quantum models exhibit larger effective dimension with respect to classical counterparts and can reach competitive performances, thus pointing towards potential quantum advantages in natural science applications via quantum ML.},
  archive      = {J_MLST},
  author       = {Oriel Kiss and Francesco Tacchino and Sofia Vallecorsa and Ivano Tavernelli},
  doi          = {10.1088/2632-2153/ac7d3c},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035004},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Quantum neural networks force fields generation},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Particle-based fast jet simulation at the LHC with
variational autoencoders. <em>MLST</em>, <em>3</em>(3), 035003. (<a
href="https://doi.org/10.1088/2632-2153/ac7c56">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study how to use deep variational autoencoders (VAEs) for a fast simulation of jets of particles at the Large Hadron Collider. We represent jets as a list of constituents, characterized by their momenta. Starting from a simulation of the jet before detector effects, we train a deep VAE to return the corresponding list of constituents after detection. Doing so, we bypass both the time-consuming detector simulation and the collision reconstruction steps of a traditional processing chain, speeding up significantly the events generation workflow. Through model optimization and hyperparameter tuning, we achieve state-of-the-art precision on the jet four-momentum, while providing an accurate description of the constituents momenta, and an inference time comparable to that of a rule-based fast simulation.},
  archive      = {J_MLST},
  author       = {Mary Touranakou and Nadezda Chernyavskaya and Javier Duarte and Dimitrios Gunopulos and Raghav Kansal and Breno Orzari and Maurizio Pierini and Thiago Tomei and Jean-Roch Vlimant},
  doi          = {10.1088/2632-2153/ac7c56},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035003},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Particle-based fast jet simulation at the LHC with variational autoencoders},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting the thermal sunyaev–zel’dovich field using
modular and equivariant set-based neural networks. <em>MLST</em>,
<em>3</em>(3), 035002. (<a
href="https://doi.org/10.1088/2632-2153/ac78c2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Theoretical uncertainty limits our ability to extract cosmological information from baryonic fields such as the thermal Sunyaev–Zel&#39;dovich (tSZ) effect. Being sourced by the electron pressure field, the tSZ effect depends on baryonic physics that is usually modeled by expensive hydrodynamic simulations. We train neural networks on the IllustrisTNG-300 cosmological simulation to predict the continuous electron pressure field in galaxy clusters from gravity-only simulations. Modeling clusters is challenging for neural networks as most of the gas pressure is concentrated in a handful of voxels and even the largest hydrodynamical simulations contain only a few hundred clusters that can be used for training. Instead of conventional convolutional neural net (CNN) architectures, we choose to employ a rotationally equivariant DeepSets architecture to operate directly on the set of dark matter particles. We argue that set-based architectures provide distinct advantages over CNNs. For example, we can enforce exact rotational and permutation equivariance, incorporate existing knowledge on the tSZ field, and work with sparse fields as are standard in cosmology. We compose our architecture with separate, physically meaningful modules, making it amenable to interpretation. For example, we can separately study the influence of local and cluster-scale environment, determine that cluster triaxiality has negligible impact, and train a module that corrects for mis-centering. Our model improves by 70 \% on analytic profiles fit to the same simulation data. We argue that the electron pressure field, viewed as a function of a gravity-only simulation, has inherent stochasticity, and model this property through a conditional-VAE extension to the network. This modification yields further improvement by 7 \% , it is limited by our small training set however. We envision that our method will prove useful in problems beyond the specific one considered here 5 .},
  archive      = {J_MLST},
  author       = {Leander Thiele and Miles Cranmer and William Coulton and Shirley Ho and David N Spergel},
  doi          = {10.1088/2632-2153/ac78c2},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035002},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Predicting the thermal Sunyaev–Zel’dovich field using modular and equivariant set-based neural networks},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural network training with highly incomplete medical
datasets. <em>MLST</em>, <em>3</em>(3), 035001. (<a
href="https://doi.org/10.1088/2632-2153/ac7b69">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network training and validation rely on the availability of large high-quality datasets. However, in many cases only incomplete datasets are available, particularly in health care applications, where each patient typically undergoes different clinical procedures or can drop out of a study. Since the data to train the neural networks need to be complete, most studies discard the incomplete datapoints, which reduces the size of the training data, or impute the missing features, which can lead to artifacts. Alas, both approaches are inadequate when a large portion of the data is missing. Here, we introduce GapNet, an alternative deep-learning training approach that can use highly incomplete datasets without overfitting or introducing artefacts. First, the dataset is split into subsets of samples containing all values for a certain cluster of features. Then, these subsets are used to train individual neural networks. Finally, this ensemble of neural networks is combined into a single neural network whose training is fine-tuned using all complete datapoints. Using two highly incomplete real-world medical datasets, we show that GapNet improves the identification of patients with underlying Alzheimer&#39;s disease pathology and of patients at risk of hospitalization due to Covid-19. Compared to commonly used imputation methods, this improvement suggests that GapNet can become a general tool to handle incomplete medical datasets.},
  archive      = {J_MLST},
  author       = {Yu-Wei Chang and Laura Natali and Oveis Jamialahmadi and Stefano Romeo and Joana B Pereira and Giovanni Volpe and for the Alzheimer’s Disease Neuroimaging Initiative},
  doi          = {10.1088/2632-2153/ac7b69},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Neural network training with highly incomplete medical datasets},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lightweight jet reconstruction and identification as an
object detection task. <em>MLST</em>, <em>3</em>(2), 025016. (<a
href="https://doi.org/10.1088/2632-2153/ac7a02">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We apply object detection techniques based on deep convolutional blocks to end-to-end jet identification and reconstruction tasks encountered at the CERN large hadron collider (LHC). Collision events produced at the LHC and represented as an image composed of calorimeter and tracker cells are given as an input to a Single Shot Detection network. The algorithm, named PFJet-SSD performs simultaneous localization, classification and regression tasks to cluster jets and reconstruct their features. This all-in-one single feed-forward pass gives advantages in terms of execution time and an improved accuracy w.r.t. traditional rule-based methods. A further gain is obtained from network slimming, homogeneous quantization, and optimized runtime for meeting memory and latency constraints of a typical real-time processing environment. We experiment with 8-bit and ternary quantization, benchmarking their accuracy and inference latency against a single-precision floating-point. We show that the ternary network closely matches the performance of its full-precision equivalent and outperforms the state-of-the-art rule-based algorithm. Finally, we report the inference latency on different hardware platforms and discuss future applications.},
  archive      = {J_MLST},
  author       = {Adrian Alan Pol and Thea Aarrestad and Ekaterina Govorkova and Roi Halily and Anat Klempner and Tal Kopetz and Vladimir Loncar and Jennifer Ngadiuba and Maurizio Pierini and Olya Sirkin and Sioni Summers},
  doi          = {10.1088/2632-2153/ac7a02},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {2},
  pages        = {025016},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Lightweight jet reconstruction and identification as an object detection task},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explainability for deep learning in mammography image
quality assessment. <em>MLST</em>, <em>3</em>(2), 025015. (<a
href="https://doi.org/10.1088/2632-2153/ac7a03">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of deep learning has recently been proposed for the assessment of image quality in mammography. It was demonstrated in a proof-of-principle study that the proposed approach can be more efficient than currently applied automated conventional methods. However, in contrast to conventional methods, the deep learning approach has a black-box nature and, before it can be recommended for the routine use, it must be understood more thoroughly. For this purpose, we propose and apply a new explainability method: the oriented, modified integrated gradients (OMIG) method. The design of this method is inspired by the integrated gradientsmethod but adapted considerably to the use case at hand. To further enhance this method, an upsampling technique is developed that produces high-resolution explainability maps for the downsampled data used by the deep learning approach. Comparison with established explainability methods demonstrates that the proposed approach yields substantially more expressive and informative results for our specific use case. Application of the proposed explainability approach generally confirms the validity of the considered deep learning-based mammography image quality assessment (IQA) method. Specifically, it is demonstrated that the predicted image quality is based on a meaningful mapping that makes successful use of certain geometric structures of the images. In addition, the novel explainability method helps us to identify the parts of the employed phantom that have the largest impact on the predicted image quality, and to shed some light on cases in which the trained neural networks fail to work as expected. While tailored to assess a specific approach from deep learning for mammography IQA, the proposed explainability method could also become relevant in other, similar deep learning applications based on high-dimensional images.},
  archive      = {J_MLST},
  author       = {N Amanova and J Martin and C Elster},
  doi          = {10.1088/2632-2153/ac7a03},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {2},
  pages        = {025015},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Explainability for deep learning in mammography image quality assessment},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hadrons, better, faster, stronger. <em>MLST</em>,
<em>3</em>(2), 025014. (<a
href="https://doi.org/10.1088/2632-2153/ac7848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the computational limitations of simulating interactions of particles in highly-granular detectors, there exists a concerted effort to build fast and exact machine-learning-based shower simulators. This work reports progress on two important fronts. First, the previously investigated Wasserstein generative adversarial network and bounded information bottleneck autoencoder generative models are improved and successful learning of hadronic showers initiated by charged pions in a segment of the hadronic calorimeter of the International Large Detector is demonstrated for the first time. Second, we consider how state-of-the-art reconstruction software applied to generated shower energies affects the obtainable energy response and resolution. While many challenges remain, these results constitute an important milestone in using generative models in a realistic setting.},
  archive      = {J_MLST},
  author       = {Erik Buhmann and Sascha Diefenbacher and Daniel Hundhausen and Gregor Kasieczka and William Korcari and Engin Eren and Frank Gaede and Katja Krüger and Peter McKeown and Lennart Rustige},
  doi          = {10.1088/2632-2153/ac7848},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {2},
  pages        = {025014},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Hadrons, better, faster, stronger},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A method for finding the background potential of quantum
devices from scanning gate microscopy data using machine learning.
<em>MLST</em>, <em>3</em>(2), 025013. (<a
href="https://doi.org/10.1088/2632-2153/ac6ec7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inverse problem of estimating the background potential from measurements of the local density of states is a challenging issue in quantum mechanics. Even more difficult is to do this estimation using approximate methods such as scanning gate microscopy (SGM). Here, we propose a machine-learning-based solution by exploiting adaptive cellular neural networks (CNNs). In the paradigmatic setting of a quantum point contact, the training data consist of potential-SGM functional relations represented by image pairs. These are generated by the recursive Green&#39;s function method. We demonstrate that the CNN-based machine learning framework can predict the background potential corresponding to the experimental image data. This is confirmed by analyzing the estimated potential with image processing techniques based on the comparison between the charge densities and those obtained using different techniques. Correlation analysis of the images suggests the possibility of estimating different contributions to the background potential. In particular, our results indicate that both charge puddles and fixed impurities contribute to the spatial patterns found in the SGM data. Our work represents a timely contribution to the rapidly evolving field of exploiting machine learning to solve difficult problems in physics.},
  archive      = {J_MLST},
  author       = {Carlo R da Cunha and Nobuyuki Aoki and David K Ferry and Ying-Cheng Lai},
  doi          = {10.1088/2632-2153/ac6ec7},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025013},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A method for finding the background potential of quantum devices from scanning gate microscopy data using machine learning},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pile-up mitigation using attention. <em>MLST</em>,
<em>3</em>(2), 025012. (<a
href="https://doi.org/10.1088/2632-2153/ac7198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle production from secondary proton-proton collisions, commonly referred to as pile-up, impair the sensitivity of both new physics searches and precision measurements at large hadron collider (LHC) experiments. We propose a novel algorithm, Puma , for modeling pile-up with the help of deep neural networks based on sparse transformers. These attention mechanisms were developed for natural language processing but have become popular in other applications. In a realistic detector simulation, our method outperforms classical benchmark algorithms for pile-up mitigation in key observables. It provides a perspective for mitigating the effects of pile-up in the high luminosity era of the LHC, where up to 200 proton-proton collisions are expected to occur simultaneously.},
  archive      = {J_MLST},
  author       = {B Maier and S M Narayanan and G de Castro and M Goncharov and Ch Paus and M Schott},
  doi          = {10.1088/2632-2153/ac7198},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025012},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Pile-up mitigation using attention},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-fidelity molecular dynamics trajectory reconstruction
with bi-directional neural networks. <em>MLST</em>, <em>3</em>(2),
025011. (<a href="https://doi.org/10.1088/2632-2153/ac6ec6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular dynamics (MD) simulations are a cornerstone in science, enabling the investigation of a system&#39;s thermodynamics all the way to analyzing intricate molecular interactions. In general, creating extended molecular trajectories can be a computationally expensive process, for example, when running ab-initio simulations. Hence, repeating such calculations to either obtain more accurate thermodynamics or to get a higher resolution in the dynamics generated by a fine-grained quantum interaction can be time- and computational resource-consuming. In this work, we explore different machine learning methodologies to increase the resolution of MD trajectories on-demand within a post-processing step. As a proof of concept, we analyse the performance of bi-directional neural networks (NNs) such as neural ODEs, Hamiltonian networks, recurrent NNs and long short-term memories, as well as the uni-directional variants as a reference, for MD simulations (here: the MD17 dataset). We have found that Bi-LSTMs are the best performing models; by utilizing the local time-symmetry of thermostated trajectories they can even learn long-range correlations and display high robustness to noisy dynamics across molecular complexity. Our models can reach accuracies of up to 10 −4 Å in trajectory interpolation, which leads to the faithful reconstruction of several unseen high-frequency molecular vibration cycles. This renders the comparison between the learned and reference trajectories indistinguishable. The results reported in this work can serve (1) as a baseline for larger systems, as well as (2) for the construction of better MD integrators.},
  archive      = {J_MLST},
  author       = {Ludwig Winkler and Klaus-Robert Müller and Huziel E Sauceda},
  doi          = {10.1088/2632-2153/ac6ec6},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025011},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {High-fidelity molecular dynamics trajectory reconstruction with bi-directional neural networks},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Noise enhanced neural networks for analytic continuation.
<em>MLST</em>, <em>3</em>(2), 025010. (<a
href="https://doi.org/10.1088/2632-2153/ac6f44">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analytic continuation maps imaginary-time Green&#39;s functions obtained by various theoretical/numerical methods to real-time response functions that can be directly compared with experiments. Analytic continuation is an important bridge between many-body theories and experiments but is also a challenging problem because such mappings are ill-conditioned. In this work, we develop a neural network (NN)-based method for this problem. The training data is generated either using synthetic Gaussian-type spectral functions or from exactly solvable models where the analytic continuation can be obtained analytically. Then, we applied the trained NN to the testing data, either with synthetic noise or intrinsic noise in Monte Carlo simulations. We conclude that the best performance is always achieved when a proper amount of noise is added to the training data. Moreover, our method can successfully capture multi-peak structure in the resulting response function for the cases with the best performance. The method can be combined with Monte Carlo simulations to compare with experiments on real-time dynamics.},
  archive      = {J_MLST},
  author       = {Juan Yao and Ce Wang and Zhiyuan Yao and Hui Zhai},
  doi          = {10.1088/2632-2153/ac6f44},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025010},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Noise enhanced neural networks for analytic continuation},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Normalizing flows for atomic solids. <em>MLST</em>,
<em>3</em>(2), 025009. (<a
href="https://doi.org/10.1088/2632-2153/ac6b16">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a machine-learning approach, based on normalizing flows, for modelling atomic solids. Our model transforms an analytically tractable base distribution into the target solid without requiring ground-truth samples for training. We report Helmholtz free energy estimates for cubic and hexagonal ice modelled as monatomic water as well as for a truncated and shifted Lennard-Jones system, and find them to be in excellent agreement with literature values and with estimates from established baseline methods. We further investigate structural properties and show that the model samples are nearly indistinguishable from the ones obtained with molecular dynamics. Our results thus demonstrate that normalizing flows can provide high-quality samples and free energy estimates without the need for multi-staging.},
  archive      = {J_MLST},
  author       = {Peter Wirnsberger and George Papamakarios and Borja Ibarz and Sébastien Racanière and Andrew J Ballard and Alexander Pritzel and Charles Blundell},
  doi          = {10.1088/2632-2153/ac6b16},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025009},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Normalizing flows for atomic solids},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). InClass nets: Independent classifier networks for
nonparametric estimation of conditional independence mixture models and
unsupervised classification. <em>MLST</em>, <em>3</em>(2), 025008. (<a
href="https://doi.org/10.1088/2632-2153/ac6483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional independence mixture models (CIMMs) are an important class of statistical models used in many fields of science. We introduce a novel unsupervised machine learning technique called the independent classifier networks (InClass nets) technique for the nonparameteric estimation of CIMMs. InClass nets consist of multiple independent classifier neural networks (NNs), which are trained simultaneously using suitable cost functions. Leveraging the ability of NNs to handle high-dimensional data, the conditionally independent variates of the model are allowed to be individually high-dimensional, which is the main advantage of the proposed technique over existing non-machine-learning-based approaches. Two new theorems on the nonparametric identifiability of bivariate CIMMs are derived in the form of a necessary and a (different) sufficient condition for a bivariate CIMM to be identifiable. We use the InClass nets technique to perform CIMM estimation successfully for several examples. We provide a public implementation as a Python package called RainDancesVI.},
  archive      = {J_MLST},
  author       = {Konstantin T Matchev and Prasanth Shyamsundar},
  doi          = {10.1088/2632-2153/ac6483},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025008},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {InClass nets: Independent classifier networks for nonparametric estimation of conditional independence mixture models and unsupervised classification},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-task graph neural networks for simultaneous prediction
of global and atomic properties in ferromagnetic systems *.
<em>MLST</em>, <em>3</em>(2), 025007. (<a
href="https://doi.org/10.1088/2632-2153/ac6a51">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a multi-tasking graph convolutional neural network, HydraGNN, to simultaneously predict both global and atomic physical properties and demonstrate with ferromagnetic materials. We train HydraGNN on an open-source ab initio density functional theory (DFT) dataset for iron-platinum with a fixed body centered tetragonal lattice structure and fixed volume to simultaneously predict the mixing enthalpy (a global feature of the system), the atomic charge transfer, and the atomic magnetic moment across configurations that span the entire compositional range. By taking advantage of underlying physical correlations between material properties, multi-task learning (MTL) with HydraGNN provides effective training even with modest amounts of data. Moreover, this is achieved with just one architecture instead of three, as required by single-task learning (STL). The first convolutional layers of the HydraGNN architecture are shared by all learning tasks and extract features common to all material properties. The following layers discriminate the features of the different properties, the results of which are fed to the separate heads of the final layer to produce predictions. Numerical results show that HydraGNN effectively captures the relation between the configurational entropy and the material properties over the entire compositional range. Overall, the accuracy of simultaneous MTL predictions is comparable to the accuracy of the STL predictions. In addition, the computational cost of training HydraGNN for MTL is much lower than the original DFT calculations and also lower than training separate STL models for each property.},
  archive      = {J_MLST},
  author       = {Massimiliano Lupo Pasini and Pei Zhang and Samuel Temple Reeve and Jong Youl Choi},
  doi          = {10.1088/2632-2153/ac6a51},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025007},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Multi-task graph neural networks for simultaneous prediction of global and atomic properties in ferromagnetic systems *},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Extending the relative seriality formalism for interpretable
deep learning of normal tissue complication probability models.
<em>MLST</em>, <em>3</em>(2), 024001. (<a
href="https://doi.org/10.1088/2632-2153/ac6932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We formally demonstrate that the relative seriality (RS) model of normal tissue complication probability (NTCP) can be recast as a simple neural network with one convolutional and one pooling layer. This approach enables us to systematically construct deep relative seriality networks (DRSNs), a new class of mechanistic generalizations of the RS model with radiobiologically interpretable parameters amenable to deep learning. To demonstrate the utility of this formulation, we analyze a simplified example of xerostomia due to irradiation of the parotid gland during alpha radiopharmaceutical therapy. Using a combination of analytical calculations and numerical simulations, we show for both the RS and DRSN cases that the ability of the neural network to generalize without overfitting is tied to &#39;stiff&#39; and &#39;sloppy&#39; directions in the parameter space of the mechanistic model. These results serve as proof-of-concept for radiobiologically interpretable deep learning of NTCP, while simultaneously yielding insight into how such techniques can robustly generalize beyond the training set despite uncertainty in individual parameters.},
  archive      = {J_MLST},
  author       = {Tahir I Yusufaly},
  doi          = {10.1088/2632-2153/ac6932},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {024001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Extending the relative seriality formalism for interpretable deep learning of normal tissue complication probability models},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simulation-based inference with approximately correct
parameters via maximum entropy. <em>MLST</em>, <em>3</em>(2), 025006.
(<a href="https://doi.org/10.1088/2632-2153/ac6286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring the input parameters of simulators from observations is a crucial challenge with applications from epidemiology to molecular dynamics. Here we show a simple approach in the regime of sparse data and approximately correct models, which is common when trying to use an existing model to infer latent variables with observed data. This approach is based on the principle of maximum entropy (MaxEnt) and provably makes the smallest change in the latent joint distribution to fit new data. This method requires no likelihood or model derivatives and its fit is insensitive to prior strength, removing the need to balance observed data fit with prior belief. The method requires the ansatz that data is fit in expectation, which is true in some settings and may be reasonable in all settings with few data points. The method is based on sample reweighting, so its asymptotic run time is independent of prior distribution dimension. We demonstrate this MaxEnt approach and compare with other likelihood-free inference methods across three systems: a point particle moving in a gravitational field, a compartmental model of epidemic spread and molecular dynamics simulation of a protein.},
  archive      = {J_MLST},
  author       = {Rainier Barrett and Mehrad Ansari and Gourab Ghoshal and Andrew D White},
  doi          = {10.1088/2632-2153/ac6286},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025006},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Simulation-based inference with approximately correct parameters via maximum entropy},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ARTS: Autonomous research topic selection system using word
embeddings and network analysis. <em>MLST</em>, <em>3</em>(2), 025005.
(<a href="https://doi.org/10.1088/2632-2153/ac61eb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The materials science research process has become increasingly autonomous due to the remarkable progress in artificial intelligence. However, autonomous research topic selection (ARTS) has not yet been fully explored due to the difficulty of estimating its promise and the lack of previous research. This paper introduces an ARTS system that autonomously selects potential research topics that are likely to reveal new scientific facts yet have not been the subject of much previous research by analyzing vast numbers of articles. Potential research topics are selected by analyzing the difference between two research concept networks constructed from research information in articles: one that represents the promise of research topics and is constructed from word embeddings, and one that represents known facts and past research activities and is constructed from statistical information on the appearance patterns of research concepts. The ARTS system is also equipped with functions to search and visualize information about selected research topics to assist in the final determination of a research topic by a scientist. We developed the ARTS system using approximately 100 00 articles published in the Computational Materials Science journal. The results of our evaluation demonstrated that research topics studied after 2016 could be generated autonomously from an analysis of the articles published before 2015. This suggests that potential research topics can be effectively selected by using the ARTS system.},
  archive      = {J_MLST},
  author       = {Eri Teruya and Tadashi Takeuchi and Hidekazu Morita and Takayuki Hayashi and Kanta Ono},
  doi          = {10.1088/2632-2153/ac61eb},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025005},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {ARTS: Autonomous research topic selection system using word embeddings and network analysis},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the capacity and superposition of minima in neural
network loss function landscapes. <em>MLST</em>, <em>3</em>(2), 025004.
(<a href="https://doi.org/10.1088/2632-2153/ac64e6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minima of the loss function landscape (LFL) of a neural network are locally optimal sets of weights that extract and process information from the input data to make outcome predictions. In underparameterised networks, the capacity of the weights may be insufficient to fit all the relevant information. We demonstrate that different local minima specialise in certain aspects of the learning problem, and process the input information differently. This effect can be exploited using a meta-network in which the predictive power from multiple minima of the LFL is combined to produce a better classifier. With this approach, we can increase the area under the receiver operating characteristic curve by around 20\% for a complex learning problem. We propose a theoretical basis for combining minima and show how a meta-network can be trained to select the representative that is used for classification of a specific data item. Finally, we present an analysis of symmetry-equivalent solutions to machine learning problems, which provides a systematic means to improve the efficiency of this approach.},
  archive      = {J_MLST},
  author       = {Maximilian P Niroomand and John W R Morgan and Conor T Cafolla and David J Wales},
  doi          = {10.1088/2632-2153/ac64e6},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025004},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {On the capacity and superposition of minima in neural network loss function landscapes},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-body renormalization group limit cycles based on
unsupervised feature learning. <em>MLST</em>, <em>3</em>(2), 025003. (<a
href="https://doi.org/10.1088/2632-2153/ac579b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both the three-body system and the inverse square potential carry a special significance in the study of renormalization group limit cycles. In this work, we pursue an exploratory approach and address the question which two-body interactions lead to limit cycles in the three-body system at low energies, without imposing any restrictions upon the scattering length. For this, we train a boosted ensemble of variational autoencoders, that not only provide a severe dimensionality reduction, but also allow to generate further synthetic potentials, which is an important prerequisite in order to efficiently search for limit cycles in low-dimensional latent space. We do so by applying an elitist genetic algorithm to a population of synthetic potentials that minimizes a specially defined limit-cycle-loss. The resulting fittest individuals suggest that the inverse square potential is the only two-body potential that minimizes this limit cycle loss independent of the hyperangle.},
  archive      = {J_MLST},
  author       = {Bastian Kaspschak and Ulf-G Meißner},
  doi          = {10.1088/2632-2153/ac579b},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025003},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Three-body renormalization group limit cycles based on unsupervised feature learning},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving newton’s equations of motion with large timesteps
using recurrent neural networks based operators. <em>MLST</em>,
<em>3</em>(2), 025002. (<a
href="https://doi.org/10.1088/2632-2153/ac5f60">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classical molecular dynamics simulations are based on solving Newton&#39;s equations of motion. Using a small timestep, numerical integrators such as Verlet generate trajectories of particles as solutions to Newton&#39;s equations. We introduce operators derived using recurrent neural networks that accurately solve Newton&#39;s equations utilizing sequences of past trajectory data, and produce energy-conserving dynamics of particles using timesteps up to 4000 times larger compared to the Verlet timestep. We demonstrate significant speedup in many example problems including 3D systems of up to 16 particles.},
  archive      = {J_MLST},
  author       = {J C S Kadupitiya and Geoffrey C Fox and Vikram Jadhao},
  doi          = {10.1088/2632-2153/ac5f60},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025002},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Solving newton’s equations of motion with large timesteps using recurrent neural networks based operators},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Source-agnostic gravitational-wave detection with recurrent
autoencoders. <em>MLST</em>, <em>3</em>(2), 025001. (<a
href="https://doi.org/10.1088/2632-2153/ac5435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an application of anomaly detection techniques based on deep recurrent autoencoders (AEs) to the problem of detecting gravitational wave (GW) signals in laser interferometers. Trained on noise data, this class of algorithms could detect signals using an unsupervised strategy, i.e. without targeting a specific kind of source. We develop a custom architecture to analyze the data from two interferometers. We compare the obtained performance to that obtained with other AE architectures and with a convolutional classifier. The unsupervised nature of the proposed strategy comes with a cost in terms of accuracy, when compared to more traditional supervised techniques. On the other hand, there is a qualitative gain in generalizing the experimental sensitivity beyond the ensemble of pre-computed signal templates. The recurrent AE outperforms other AEs based on different architectures. The class of recurrent AEs presented in this paper could complement the search strategy employed for GW detection and extend the discovery reach of the ongoing detection campaigns.},
  archive      = {J_MLST},
  author       = {Eric A Moreno and Bartlomiej Borzyszkowski and Maurizio Pierini and Jean-Roch Vlimant and Maria Spiropulu},
  doi          = {10.1088/2632-2153/ac5435},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Source-agnostic gravitational-wave detection with recurrent autoencoders},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Suppressing simulation bias in multi-modal data using
transfer learning. <em>MLST</em>, <em>3</em>(1), 015035. (<a
href="https://doi.org/10.1088/2632-2153/ac5e3e">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many problems in science and engineering require making predictions based on few observations. To build a robust predictive model, these sparse data may need to be augmented with simulated data, especially when the design space is multi-dimensional. Simulations, however, often suffer from an inherent bias. Estimation of this bias may be poorly constrained not only because of data sparsity, but also because traditional predictive models fit only one type of observed outputs, such as scalars or images, instead of all available output data modalities, which might have been acquired and simulated at great cost. To break this limitation and open up the path for multi-modal calibration, we propose to combine a novel, transfer learning technique for suppressing the bias with recent developments in deep learning, which allow building predictive models with multi-modal outputs. First, we train an initial neural network model on simulated data to learn important correlations between different output modalities and between simulation inputs and outputs. Then, the model is partially retrained, or transfer learned, to fit the experiments; a method that has never been implemented in this type of architecture. Using fewer than 10 inertial confinement fusion experiments for training, transfer learning systematically improves the simulation predictions while a simple output calibration, which we design as a baseline, makes the predictions worse. We also offer extensive cross-validation with real and carefully designed synthetic data. The method described in this paper can be applied to a wide range of problems that require transferring knowledge from simulations to the domain of experiments.},
  archive      = {J_MLST},
  author       = {Bogdan Kustowski and Jim A Gaffney and Brian K Spears and Gemma J Anderson and Rushil Anirudh and Peer-Timo Bremer and Jayaraman J Thiagarajan and Michael K G Kruse and Ryan C Nora},
  doi          = {10.1088/2632-2153/ac5e3e},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015035},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Suppressing simulation bias in multi-modal data using transfer learning},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Qsun: An open-source platform towards practical quantum
machine learning applications. <em>MLST</em>, <em>3</em>(1), 015034. (<a
href="https://doi.org/10.1088/2632-2153/ac5997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, quantum hardware is restrained by noises and qubit numbers. Thus, a quantum virtual machine (QVM) that simulates operations of a quantum computer on classical computers is a vital tool for developing and testing quantum algorithms before deploying them on real quantum computers. Various variational quantum algorithms (VQAs) have been proposed and tested on QVMs to surpass the limitations of quantum hardware. Our goal is to exploit further the VQAs towards practical applications of quantum machine learning (QML) using state-of-the-art quantum computers. In this paper, we first introduce a QVM named Qsun, whose operation is underlined by quantum state wavefunctions. The platform provides native tools supporting VQAs. Especially using the parameter-shift rule, we implement quantum differentiable programming essential for gradient-based optimization. We then report two tests representative of QML: quantum linear regression and quantum neural network.},
  archive      = {J_MLST},
  author       = {Quoc Chuong Nguyen and Le Bin Ho and Lan Nguyen Tran and Hung Q Nguyen},
  doi          = {10.1088/2632-2153/ac5997},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015034},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Qsun: An open-source platform towards practical quantum machine learning applications},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Photon detection probability prediction using
one-dimensional generative neural network. <em>MLST</em>, <em>3</em>(1),
015033. (<a href="https://doi.org/10.1088/2632-2153/ac58e2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photon detection is important for liquid argon detectors for direct dark matter searches or neutrino property measurements. Precise simulation of photon transport is widely used to understand the probability of photon detection in liquid argon detectors. Traditional photon transport simulation, which tracks every photon using the Geant4 simulation toolkit, is a major computational challenge for kilo-tonne-scale liquid argon detectors and GeV-level energy depositions. In this work, we propose a one-dimensional generative model which efficiently generates features using an \mathrm{OuterProduct} -layer. This model bypasses photon transport simulation and predicts the number of photons detected by particular photon detectors at the same level of detail as the Geant4 simulation. The application to simulating photon detection systems in kilo-tonne-scale liquid argon detectors demonstrates this novel generative model is able to reproduce Geant4 simulation with good accuracy and 20 to 50 times faster. This generative model can be used to quickly predict photon detection probability in huge liquid argon detectors like ProtoDUNE or DUNE.},
  archive      = {J_MLST},
  author       = {Wei Mu and Alexander I Himmel and Bryan Ramson},
  doi          = {10.1088/2632-2153/ac58e2},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015033},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Photon detection probability prediction using one-dimensional generative neural network},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Kernel charge equilibration: Efficient and accurate
prediction of molecular dipole moments with a machine-learning enhanced
electron density model. <em>MLST</em>, <em>3</em>(1), 015032. (<a
href="https://doi.org/10.1088/2632-2153/ac568d">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art machine learning (ML) interatomic potentials use local representations of atomic environments to ensure linear scaling and size-extensivity. This implies a neglect of long-range interactions, most prominently related to electrostatics. To overcome this limitation, we herein present a ML framework for predicting charge distributions and their interactions termed kernel charge equilibration (kQEq). This model is based on classical charge equilibration (QEq) models expanded with an environment-dependent electronegativity. In contrast to previously reported neural network models with a similar concept, kQEq takes advantage of the linearity of both QEq and Kernel Ridge Regression to obtain a closed-form linear algebra expression for training the models. Furthermore, we avoid the ambiguity of charge partitioning schemes by using dipole moments as reference data. As a first application, we show that kQEq can be used to generate accurate and highly data-efficient models for molecular dipole moments.},
  archive      = {J_MLST},
  author       = {Carsten G Staacke and Simon Wengert and Christian Kunkel and Gábor Csányi and Karsten Reuter and Johannes T Margraf},
  doi          = {10.1088/2632-2153/ac568d},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015032},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Kernel charge equilibration: Efficient and accurate prediction of molecular dipole moments with a machine-learning enhanced electron density model},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic differentiation to simultaneously identify
nonlinear dynamics and extract noise probability distributions from
data. <em>MLST</em>, <em>3</em>(1), 015031. (<a
href="https://doi.org/10.1088/2632-2153/ac567a">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sparse identification of nonlinear dynamics (SINDy) is a regression framework for the discovery of parsimonious dynamic models and governing equations from time-series data. As with all system identification methods, noisy measurements compromise the accuracy and robustness of the model discovery procedure. In this work we develop a variant of the SINDy algorithm that integrates automatic differentiation and recent time-stepping constrained motivated by Rudy et al (2019 J. Computat. Phys. 396 483–506) for simultaneously (1) denoising the data, (2) learning and parametrizing the noise probability distribution, and (3) identifying the underlying parsimonious dynamical system responsible for generating the time-series data. Thus within an integrated optimization framework, noise can be separated from signal, resulting in an architecture that is approximately twice as robust to noise as state-of-the-art methods, handling as much as 40% noise on a given time-series signal and explicitly parametrizing the noise probability distribution. We demonstrate this approach on several numerical examples, from Lotka-Volterra models to the spatio-temporal Lorenz 96 model. Further, we show the method can learn a diversity of probability distributions for the measurement noise, including Gaussian, uniform, Gamma, and Rayleigh distributions.},
  archive      = {J_MLST},
  author       = {Kadierdan Kaheman and Steven L Brunton and J Nathan Kutz},
  doi          = {10.1088/2632-2153/ac567a},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015031},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Automatic differentiation to simultaneously identify nonlinear dynamics and extract noise probability distributions from data},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Probing transfer learning with a model of synthetic
correlated datasets. <em>MLST</em>, <em>3</em>(1), 015030. (<a
href="https://doi.org/10.1088/2632-2153/ac4f3f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning can significantly improve the sample efficiency of neural networks, by exploiting the relatedness between a data-scarce target task and a data-abundant source task. Despite years of successful applications, transfer learning practice often relies on ad-hoc solutions, while theoretical understanding of these procedures is still limited. In the present work, we re-think a solvable model of synthetic data as a framework for modeling correlation between data-sets. This setup allows for an analytic characterization of the generalization performance obtained when transferring the learned feature map from the source to the target task. Focusing on the problem of training two-layer networks in a binary classification setting, we show that our model can capture a range of salient features of transfer learning with real data. Moreover, by exploiting parametric control over the correlation between the two data-sets, we systematically investigate under which conditions the transfer of features is beneficial for generalization.},
  archive      = {J_MLST},
  author       = {Federica Gerace and Luca Saglietti and Stefano Sarao Mannelli and Andrew Saxe and Lenka Zdeborová},
  doi          = {10.1088/2632-2153/ac4f3f},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015030},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Probing transfer learning with a model of synthetic correlated datasets},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decoupled coordinates for machine learning-based molecular
fragment linking. <em>MLST</em>, <em>3</em>(1), 015029. (<a
href="https://doi.org/10.1088/2632-2153/ac50fc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent developments in machine learning-based molecular fragment linking have demonstrated the importance of informing the generation process with structural information specifying the relative orientation of the fragments to be linked. However, such structural information has so far not been provided in the form of a complete relative coordinate system. We present a decoupled coordinate system consisting of bond lengths, bond angles and torsion angles, and show that it is complete. By incorporating this set of coordinates in a linker generation framework, we show that it has a significant impact on the quality of the generated linkers. To elucidate the advantages of such a coordinate system, we investigate the amount of reliable information within the different types of degrees of freedom using both detailed ablation studies and an information-theoretical analysis. The presented benefits suggest the application of a complete and decoupled relative coordinate system as a standard good practice in linker design.},
  archive      = {J_MLST},
  author       = {Markus Fleck and Michael Müller and Noah Weber and Christopher Trummer},
  doi          = {10.1088/2632-2153/ac50fc},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015029},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Decoupled coordinates for machine learning-based molecular fragment linking},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Chemistry-informed macromolecule graph representation for
similarity computation, unsupervised and supervised learning.
<em>MLST</em>, <em>3</em>(1), 015028. (<a
href="https://doi.org/10.1088/2632-2153/ac545e">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The near-infinite chemical diversity of natural and artificial macromolecules arises from the vast range of possible component monomers, linkages, and polymers topologies. This enormous variety contributes to the ubiquity and indispensability of macromolecules but hinders the development of general machine learning methods with macromolecules as input. To address this, we developed a chemistry-informed graph representation of macromolecules that enables quantifying structural similarity, and interpretable supervised learning for macromolecules. Our work enables quantitative chemistry-informed decision-making and iterative design in the macromolecular chemical space.},
  archive      = {J_MLST},
  author       = {Somesh Mohapatra and Joyce An and Rafael Gómez-Bombarelli},
  doi          = {10.1088/2632-2153/ac545e},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015028},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Chemistry-informed macromolecule graph representation for similarity computation, unsupervised and supervised learning},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-perturbative renormalization for the neural network-QFT
correspondence. <em>MLST</em>, <em>3</em>(1), 015027. (<a
href="https://doi.org/10.1088/2632-2153/ac4f69">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a recent work (Halverson et al 2021 Mach. Learn.: Sci. Technol. 2 035002), Halverson, Maiti and Stoner proposed a description of neural networks (NNs) in terms of a Wilsonian effective field theory. The infinite-width limit is mapped to a free field theory while finite N corrections are taken into account by interactions (non-Gaussian terms in the action). In this paper, we study two related aspects of this correspondence. First, we comment on the concepts of locality and power-counting in this context. Indeed, these usual space-time notions may not hold for NNs (since inputs can be arbitrary), however, the renormalization group (RG) provides natural notions of locality and scaling. Moreover, we comment on several subtleties, for example, that data components may not have a permutation symmetry: in that case, we argue that random tensor field theories could provide a natural generalization. Second, we improve the perturbative Wilsonian renormalization from Halverson et al (2021 Mach. Learn.: Sci. Technol. 2 035002) by providing an analysis in terms of the non-perturbative RG using the Wetterich-Morris equation. An important difference with usual non-perturbative RG analysis is that only the effective infrared 2-point function is known, which requires setting the problem with care. Our aim is to provide a useful formalism to investigate NNs behavior beyond the large-width limit (i.e. far from Gaussian limit) in a non-perturbative fashion. A major result of our analysis is that changing the standard deviation of the NN weight distribution can be interpreted as a renormalization flow in the space of networks. We focus on translations invariant kernels and provide preliminary numerical results.},
  archive      = {J_MLST},
  author       = {H Erbin and V Lahoche and D Ousmane Samary},
  doi          = {10.1088/2632-2153/ac4f69},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015027},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Non-perturbative renormalization for the neural network-QFT correspondence},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inverse dirichlet weighting enables reliable training of
physics informed neural networks. <em>MLST</em>, <em>3</em>(1), 015026.
(<a href="https://doi.org/10.1088/2632-2153/ac3712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We characterize and remedy a failure mode that may arise from multi-scale dynamics with scale imbalances during training of deep neural networks, such as physics informed neural networks (PINNs). PINNs are popular machine-learning templates that allow for seamless integration of physical equation models with data. Their training amounts to solving an optimization problem over a weighted sum of data-fidelity and equation-fidelity objectives. Conflicts between objectives can arise from scale imbalances, heteroscedasticity in the data, stiffness of the physical equation, or from catastrophic interference during sequential training. We explain the training pathology arising from this and propose a simple yet effective inverse Dirichlet weighting strategy to alleviate the issue. We compare with Sobolev training of neural networks, providing the baseline of analytically ε -optimal training. We demonstrate the effectiveness of inverse Dirichlet weighting in various applications, including a multi-scale model of active turbulence, where we show orders of magnitude improvement in accuracy and convergence over conventional PINN training. For inverse modeling using sequential training, we find that inverse Dirichlet weighting protects a PINN against catastrophic forgetting.},
  archive      = {J_MLST},
  author       = {Suryanarayana Maddu and Dominik Sturm and Christian L Müller and Ivo F Sbalzarini},
  doi          = {10.1088/2632-2153/ac3712},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015026},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Inverse dirichlet weighting enables reliable training of physics informed neural networks},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variational quantum reinforcement learning via evolutionary
optimization. <em>MLST</em>, <em>3</em>(1), 015025. (<a
href="https://doi.org/10.1088/2632-2153/ac4559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in classical reinforcement learning (RL) and quantum computation point to a promising direction for performing RL on a quantum computer. However, potential applications in quantum RL are limited by the number of qubits available in modern quantum devices. Here, we present two frameworks for deep quantum RL tasks using gradient-free evolutionary optimization. First, we apply the amplitude encoding scheme to the Cart-Pole problem, where we demonstrate the quantum advantage of parameter saving using amplitude encoding. Second, we propose a hybrid framework where the quantum RL agents are equipped with a hybrid tensor network-variational quantum circuit (TN-VQC) architecture to handle inputs of dimensions exceeding the number of qubits. This allows us to perform quantum RL in the MiniGrid environment with 147-dimensional inputs. The hybrid TN-VQC architecture provides a natural way to perform efficient compression of the input dimension, enabling further quantum RL applications on noisy intermediate-scale quantum devices.},
  archive      = {J_MLST},
  author       = {Samuel Yen-Chi Chen and Chih-Min Huang and Chia-Wei Hsing and Hsi-Sheng Goan and Ying-Jer Kao},
  doi          = {10.1088/2632-2153/ac4559},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015025},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Variational quantum reinforcement learning via evolutionary optimization},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards automating structural discovery in scanning
transmission electron microscopy *. <em>MLST</em>, <em>3</em>(1),
015024. (<a href="https://doi.org/10.1088/2632-2153/ac3844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scanning transmission electron microscopy is now the primary tool for exploring functional materials on the atomic level. Often, features of interest are highly localized in specific regions in the material, such as ferroelectric domain walls, extended defects, or second phase inclusions. Selecting regions to image for structural and chemical discovery via atomically resolved imaging has traditionally proceeded via human operators making semi-informed judgements on sampling locations and parameters. Recent efforts at automation for structural and physical discovery have pointed towards the use of &#39;active learning&#39; methods that utilize Bayesian optimization with surrogate models to quickly find relevant regions of interest. Yet despite the potential importance of this direction, there is a general lack of certainty in selecting relevant control algorithms and how to balance a priori knowledge of the material system with knowledge derived during experimentation. Here we address this gap by developing the automated experiment workflows with several combinations to both illustrate the effects of these choices and demonstrate the tradeoffs associated with each in terms of accuracy, robustness, and susceptibility to hyperparameters for structural discovery. We discuss possible methods to build descriptors using the raw image data and deep learning based semantic segmentation, as well as the implementation of variational autoencoder based representation. Furthermore, each workflow is applied to a range of feature sizes including NiO pillars within a La:SrMnO 3 matrix, ferroelectric domains in BiFeO 3 , and topological defects in graphene. The code developed in this manuscript is open sourced and will be released at github.com/nccreang/AE_Workflows .},
  archive      = {J_MLST},
  author       = {Nicole Creange and Ondrej Dyck and Rama K Vasudevan and Maxim Ziatdinov and Sergei V Kalinin},
  doi          = {10.1088/2632-2153/ac3844},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015024},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Towards automating structural discovery in scanning transmission electron microscopy *},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph neural network-based resource allocation strategies
for multi-object spectroscopy. <em>MLST</em>, <em>3</em>(1), 015023. (<a
href="https://doi.org/10.1088/2632-2153/ac4d12">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource allocation problems are often approached with linear programming techniques. But many concrete allocation problems in the experimental and observational sciences cannot or should not be expressed in the form of linear objective functions. Even if the objective is linear, its parameters may not be known beforehand because they depend on the results of the experiment for which the allocation is to be determined. To address these challenges, we present a bipartite graph neural network (GNN) architecture for trainable resource allocation strategies. Items of value and constraints form the two sets of graph nodes, which are connected by edges corresponding to possible allocations. The GNN is trained on simulations or past problem occurrences to maximize any user-supplied, scientifically motivated objective function, augmented by an infeasibility penalty. The amount of feasibility violation can be tuned in relation to any available slack in the system. We apply this method to optimize the astronomical target selection strategy for the highly multiplexed Subaru Prime Focus Spectrograph instrument, where it shows superior results to direct gradient descent optimization and extends the capabilities of the currently employed solver which uses linear objective functions. The development of this method enables fast adjustment and deployment of allocation strategies, statistical analyses of allocation patterns, and fully differentiable, science-driven solutions for resource allocation problems.},
  archive      = {J_MLST},
  author       = {Tianshu Wang and Peter Melchior},
  doi          = {10.1088/2632-2153/ac4d12},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015023},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Graph neural network-based resource allocation strategies for multi-object spectroscopy},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Physics makes the difference: Bayesian optimization and
active learning via augmented gaussian process. <em>MLST</em>,
<em>3</em>(1), 015003. (<a
href="https://doi.org/10.1088/2632-2153/ac4baa">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both experimental and computational methods for the exploration of structure, functionality, and properties of materials often necessitate the search across broad parameter spaces to discover optimal experimental conditions and regions of interest in the image space or parameter space of computational models. The direct grid search of the parameter space tends to be extremely time-consuming, leading to the development of strategies balancing exploration of unknown parameter spaces and exploitation towards required performance metrics. However, classical Bayesian optimization (BO) strategies based on the Gaussian process (GP) do not readily allow for the incorporation of the known physical behaviors or past knowledge. Here we explore a hybrid optimization/exploration algorithm created by augmenting the standard GP with a structured probabilistic model of the expected system&#39;s behavior. This approach balances the flexibility of the non-parametric GP approach with a rigid structure of physical knowledge encoded into the parametric model. The fully Bayesian treatment of the latter allows additional control over the optimization via the selection of priors for the model parameters. The method is demonstrated for a noisy version of a standard univariate test function used to evaluate optimization algorithms and further extended to physical lattice models. This methodology is expected to be universally suitable for injecting prior knowledge in the form of physical models and past data in the BO framework.},
  archive      = {J_MLST},
  author       = {Maxim A Ziatdinov and Ayana Ghosh and Sergei V Kalinin},
  doi          = {10.1088/2632-2153/ac4baa},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015003},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Physics makes the difference: Bayesian optimization and active learning via augmented gaussian process},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Chemformer: A pre-trained transformer for computational
chemistry. <em>MLST</em>, <em>3</em>(1), 015022. (<a
href="https://doi.org/10.1088/2632-2153/ac3ffb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer models coupled with a simplified molecular line entry system (SMILES) have recently proven to be a powerful combination for solving challenges in cheminformatics. These models, however, are often developed specifically for a single application and can be very resource-intensive to train. In this work we present the Chemformer model—a Transformer-based model which can be quickly applied to both sequence-to-sequence and discriminative cheminformatics tasks. Additionally, we show that self-supervised pre-training can improve performance and significantly speed up convergence on downstream tasks. On direct synthesis and retrosynthesis prediction benchmark datasets we publish state-of-the-art results for top-1 accuracy. We also improve on existing approaches for a molecular optimisation task and show that Chemformer can optimise on multiple discriminative tasks simultaneously. Models, datasets and code will be made available after publication.},
  archive      = {J_MLST},
  author       = {Ross Irwin and Spyridon Dimitriadis and Jiazhen He and Esben Jannik Bjerrum},
  doi          = {10.1088/2632-2153/ac3ffb},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015022},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Chemformer: A pre-trained transformer for computational chemistry},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to discover: Expressive gaussian mixture models for
multi-dimensional simulation and parameter inference in the physical
sciences. <em>MLST</em>, <em>3</em>(1), 015021. (<a
href="https://doi.org/10.1088/2632-2153/ac4a3b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that density models describing multiple observables with (1) hard boundaries and (2) dependence on external parameters may be created using an auto-regressive Gaussian mixture model. The model is designed to capture how observable spectra are deformed by hypothesis variations, and is made more expressive by projecting data onto a configurable latent space. It may be used as a statistical model for scientific discovery in interpreting experimental observations, for example when constraining the parameters of a physical model or tuning simulation parameters according to calibration data. The model may also be sampled for use within a Monte Carlo simulation chain, or used to estimate likelihood ratios for event classification. The method is demonstrated on simulated high-energy particle physics data considering the anomalous electroweak production of a Z boson in association with a dijet system at the Large Hadron Collider, and the accuracy of inference is tested using a realistic toy example. The developed methods are domain agnostic; they may be used within any field to perform simulation or inference where a dataset consisting of many real-valued observables has conditional dependence on external parameters.},
  archive      = {J_MLST},
  author       = {Stephen B Menary and Darren D Price},
  doi          = {10.1088/2632-2153/ac4a3b},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015021},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Learning to discover: Expressive gaussian mixture models for multi-dimensional simulation and parameter inference in the physical sciences},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Differentiable programming of isometric tensor networks.
<em>MLST</em>, <em>3</em>(1), 015020. (<a
href="https://doi.org/10.1088/2632-2153/ac48a2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentiable programming is a new programming paradigm which enables large scale optimization through automatic calculation of gradients also known as auto-differentiation. This concept emerges from deep learning, and has also been generalized to tensor network optimizations. Here, we extend the differentiable programming to tensor networks with isometric constraints with applications to multiscale entanglement renormalization ansatz (MERA) and tensor network renormalization (TNR). By introducing several gradient-based optimization methods for the isometric tensor network and comparing with Evenbly–Vidal method, we show that auto-differentiation has a better performance for both stability and accuracy. We numerically tested our methods on 1D critical quantum Ising spin chain and 2D classical Ising model. We calculate the ground state energy for the 1D quantum model and internal energy for the classical model, and scaling dimensions of scaling operators and find they all agree with the theory well.},
  archive      = {J_MLST},
  author       = {Chenhua Geng and Hong-Ye Hu and Yijian Zou},
  doi          = {10.1088/2632-2153/ac48a2},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015020},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Differentiable programming of isometric tensor networks},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Characterising the area under the curve loss function
landscape. <em>MLST</em>, <em>3</em>(1), 015019. (<a
href="https://doi.org/10.1088/2632-2153/ac49a9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most common metrics to evaluate neural network classifiers is the area under the receiver operating characteristic curve (AUC). However, optimisation of the AUC as the loss function during network training is not a standard procedure. Here we compare minimising the cross-entropy (CE) loss and optimising the AUC directly. In particular, we analyse the loss function landscape (LFL) of approximate AUC (appAUC) loss functions to discover the organisation of this solution space. We discuss various surrogates for AUC approximation and show their differences. We find that the characteristics of the appAUC landscape are significantly different from the CE landscape. The approximate AUC loss function improves testing AUC, and the appAUC landscape has substantially more minima, but these minima are less robust, with larger average Hessian eigenvalues. We provide a theoretical foundation to explain these results. To generalise our results, we lastly provide an overview of how the LFL can help to guide loss function analysis and selection.},
  archive      = {J_MLST},
  author       = {Maximilian P Niroomand and Conor T Cafolla and John W R Morgan and David J Wales},
  doi          = {10.1088/2632-2153/ac49a9},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015019},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Characterising the area under the curve loss function landscape},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast prediction of distances between synthetic routes with
deep learning. <em>MLST</em>, <em>3</em>(1), 015018. (<a
href="https://doi.org/10.1088/2632-2153/ac4a91">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We expand the recent work on clustering of synthetic routes and train a deep learning model to predict the distances between arbitrary routes. The model is based on a long short-term memory representation of a synthetic route and is trained as a twin network to reproduce the tree edit distance (TED) between two routes. The machine learning approach is approximately two orders of magnitude faster than the TED approach and enables clustering many more routes from a retrosynthesis route prediction. The clusters have a high degree of similarity to the clusters given by the TED-based approach and are accordingly intuitive and explainable. We provide the developed model as open-source.},
  archive      = {J_MLST},
  author       = {Samuel Genheden and Ola Engkvist and Esben Bjerrum},
  doi          = {10.1088/2632-2153/ac4a91},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015018},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Fast prediction of distances between synthetic routes with deep learning},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mutual information scaling for tensor network machine
learning. <em>MLST</em>, <em>3</em>(1), 015017. (<a
href="https://doi.org/10.1088/2632-2153/ac44a9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor networks have emerged as promising tools for machine learning, inspired by their widespread use as variational ansatze in quantum many-body physics. It is well known that the success of a given tensor network ansatz depends in part on how well it can reproduce the underlying entanglement structure of the target state, with different network designs favoring different scaling patterns. We demonstrate here how a related correlation analysis can be applied to tensor network machine learning, and explore whether classical data possess correlation scaling patterns similar to those found in quantum states, which might indicate the best network to use for a given dataset. We utilize mutual information (MI) as measure of correlations in classical data, and show that it can serve as a lower-bound on the entanglement needed for a probabilistic tensor network classifier. We then develop a logistic regression algorithm to estimate the MI between bipartitions of data features, and verify its accuracy on a set of Gaussian distributions designed to mimic different correlation patterns. Using this algorithm, we characterize the scaling patterns in the Modified National Institute of Standards and Technology and Tiny Images datasets, and find clear evidence of boundary-law scaling in the latter. This quantum-inspired classical analysis offers insight into the design of tensor networks that are best suited for specific learning tasks.},
  archive      = {J_MLST},
  author       = {Ian Convy and William Huggins and Haoran Liao and K Birgitta Whaley},
  doi          = {10.1088/2632-2153/ac44a9},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015017},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Mutual information scaling for tensor network machine learning},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inferring dark matter substructure with astrometric lensing
beyond the power spectrum. <em>MLST</em>, <em>3</em>(1), 01LT03. (<a
href="https://doi.org/10.1088/2632-2153/ac494a">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Astrometry—the precise measurement of positions and motions of celestial objects—has emerged as a promising avenue for characterizing the dark matter population in our Galaxy. By leveraging recent advances in simulation-based inference and neural network architectures, we introduce a novel method to search for global dark matter-induced gravitational lensing signatures in astrometric datasets. Our method based on neural likelihood-ratio estimation shows significantly enhanced sensitivity to a cold dark matter population and more favorable scaling with measurement noise compared to existing approaches based on two-point correlation statistics. We demonstrate the real-world viability of our method by showing it to be robust to non-trivial modeled as well as unmodeled noise features expected in astrometric measurements. This establishes machine learning as a powerful tool for characterizing dark matter using astrometric data.},
  archive      = {J_MLST},
  author       = {Siddharth Mishra-Sharma},
  doi          = {10.1088/2632-2153/ac494a},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {01LT03},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Inferring dark matter substructure with astrometric lensing beyond the power spectrum},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Easy representation of multivariate functions with
low-dimensional terms via gaussian process regression kernel design:
Applications to machine learning of potential energy surfaces and
kinetic energy densities from sparse data. <em>MLST</em>, <em>3</em>(1),
01LT02. (<a href="https://doi.org/10.1088/2632-2153/ac4949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that Gaussian process regression (GPR) allows representing multivariate functions with low-dimensional terms via kernel design. When using a kernel built with high-dimensional model representation (HDMR), one obtains a similar type of representation as the previously proposed HDMR-GPR scheme while being faster and simpler to use. We tested the approach on cases where highly accurate machine learning is required from sparse data by fitting potential energy surfaces and kinetic energy densities.},
  archive      = {J_MLST},
  author       = {Sergei Manzhos and Eita Sasaki and Manabu Ihara},
  doi          = {10.1088/2632-2153/ac4949},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {01LT02},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Easy representation of multivariate functions with low-dimensional terms via gaussian process regression kernel design: Applications to machine learning of potential energy surfaces and kinetic energy densities from sparse data},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
