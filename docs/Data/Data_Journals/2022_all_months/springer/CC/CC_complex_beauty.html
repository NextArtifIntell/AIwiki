<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="cc---143">CC - 143</h2>
<ul>
<li><details>
<summary>
(2022). Music-CRN: An efficient content-based music classification
and recommendation network. <em>CC</em>, <em>14</em>(6), 2306–2316. (<a
href="https://doi.org/10.1007/s12559-022-10039-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For human beings, music is generally perceived, categorized, and enjoyed based on its attributes, such as rhythm, pitch, timbre, and harmony. In recent years, due to their high performances, content-based music classification and recommendation systems have attracted much attention from both the music industry and research community. However, on the one hand, deep music classification models are still very rare, and on the other hand, the collaborative filtering approach, which has the cold start problem, still dominates the music recommendation applications. In this paper, we propose Music-CRN (short for music classification and recommendation network), a simple yet effective model that facilitates music classification and recommendation with learning the audio content features of music. Specifically, to extract the content features of music, the audio is converted into spectrogram “images” by Fourier transformation. Music-CRN can be applied on the spectrograms as similar as natural images to effectively extract music content features. Additionally, we collect a new dataset containing nearly 200,000 music spectrogram slices. To the best of our knowledge, this is the first publicly available music spectrogram dataset, which is at https://github.com/YX-Mao/Music-spectrum-image-data . We compare Music-CRN to previous content-based music classification and recommendation models on the collected dataset. Experimental results show that Music-CRN achieves state-of-the-art performance on music classification and recommendation tasks, demonstrating its superiority over previous methods.},
  archive      = {J_CC},
  author       = {Mao, Yuxu and Zhong, Guoqiang and Wang, Haizhen and Huang, Kaizhu},
  doi          = {10.1007/s12559-022-10039-x},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2306-2316},
  shortjournal = {Cogn. Comput.},
  title        = {Music-CRN: An efficient content-based music classification and recommendation network},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Atten-GAN: Pedestrian trajectory prediction with GAN based
on attention mechanism. <em>CC</em>, <em>14</em>(6), 2296–2305. (<a
href="https://doi.org/10.1007/s12559-022-10029-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting pedestrian trajectories in dynamic scenarios is extremely challenging due to the mobility and flexibility of pedestrian motion. However, most existing methods cannot fully extract the interaction information between pedestrians. In this paper, a generative adversarial network model-based attention mechanism (Atten-GAN) was proposed to model social relationships of the interaction information between pedestrians. The Atten-GAN is composed of a generator and a discriminator. The generator predicts multiple possible future trajectories according to the past trajectories of pedestrians. The discriminator scores the trajectories according to the trajectories input, determines whether the trajectories are ground-truth or generated by the generator, and then facilitates the generator to generate trajectories in line with social norms. Atten-GAN introduces an attention pooling module to allocate the influence weight of pedestrians in the scene, which can fully extract pedestrian interaction information. In addition, to solve the problem associated with how the GAN network gradient is easy to disappear and difficult to train, the noise decreasing with time is introduced into the loss function of the discriminator during the training. The comparison experiments on ETH and UCY datasets showed that Atten-GAN could not only provide a variety of socially acceptable prediction trajectories in accordance with the social norms but was also was superior to the existing generative model-based methods in the prediction accuracy. The Atten-GAN model had a significant improvement in prediction accuracy and improved the training effects.},
  archive      = {J_CC},
  author       = {Fang, Fang and Zhang, Pengpeng and Zhou, Bo and Qian, Kun and Gan, Yahui},
  doi          = {10.1007/s12559-022-10029-z},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2296-2305},
  shortjournal = {Cogn. Comput.},
  title        = {Atten-GAN: Pedestrian trajectory prediction with GAN based on attention mechanism},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature selection based on modified bio-inspired atomic
orbital search using arithmetic optimization and opposite-based
learning. <em>CC</em>, <em>14</em>(6), 2274–2295. (<a
href="https://doi.org/10.1007/s12559-022-10022-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) has the largest influence on the performance of machine learning methods. FS can remove the irrelevant and redundancy features from the data while preserving the same quality of increasing it. However, the traditional FS methods are time-consuming and can be stuck in local optima. So, the metaheuristic (MH) techniques are used to avoid these limitations since they have several operators that explore and exploit the search domain better than traditional methods. Besides these behaviors of MH, we present an improved atomic orbital search (IAOS) algorithm using a global search strategy that uses the operators of arithmetic optimization algorithm (AOA), which has proven a good exploration ability to provide a promising candidate solution. The opposite-based learning (OBL) is applied to enhance the initial population, which leads to enhancing the convergence rate towards the optimal solution. In addition, a dynamic photon rate is used to enhance the balance between exploration and exploitation. Finally, the sequential backward selection (SBS) is used as a local search strategy to improve the best solution, and this leads to obtaining a set of relevant features that increase the classification accuracy. To evaluate the performance of the presented IAOS-SBS as an FS method, a set of twenty UCI datasets is used; also, it is compared with other well-known FS methods. The results show the superiority of IAOS-SBS among the performance measures. Finally, it is concluded that IAOS-SBS can select fewer features with achieving high classification accuracy for most of the datasets utilized in the study. This indicates the use of OBL and SBS leads to enhancing the original AOS.},
  archive      = {J_CC},
  author       = {Abd Elaziz, Mohamed and Ouadfel, Salima and Abd El-Latif, Ahmed A. and Ali Ibrahim, Rehab},
  doi          = {10.1007/s12559-022-10022-6},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2274-2295},
  shortjournal = {Cogn. Comput.},
  title        = {Feature selection based on modified bio-inspired atomic orbital search using arithmetic optimization and opposite-based learning},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An approach to emotion recognition using brain rhythm
sequencing and asymmetric features. <em>CC</em>, <em>14</em>(6),
2260–2273. (<a
href="https://doi.org/10.1007/s12559-022-10053-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion can be influenced during self-isolation, and to avoid severe mood swings, emotional regulation is meaningful. To achieve this, efficiently recognizing emotion is a vital step, which can be realized by electroencephalography signals. Previously, inspired by the knowledge of sequencing in bioinformatics, a method termed brain rhythm sequencing that analyzes electroencephalography as the sequence consisting of the dominant rhythm has been proposed for seizure detection. In this work, with the help of similarity measure methods, the asymmetric features are extracted from the sequences generated by different channel data. After evaluating all asymmetric features for emotion recognition, the optimal feature that yields remarkable accuracy is identified. Therefore, the classification task can be accomplished through a small amount of channel data. From a music emotion recognition experiment and a public DEAP dataset, the classification accuracies of various test sets are approximately 80–85% when employing an optimal feature extracted from one pair of symmetrical channels. Such performances are impressive when using fewer resources is a concern. Further investigation revealed that emotion recognition shows strongly individual characteristics, so an appropriate solution is to include the subject-dependent properties. Compared to the existing works, this method benefits from the design of a portable emotion-aware device used during self-isolation, as fewer scalp sensors are needed. Hence, it would provide a novel way to realize emotional applications in the future.},
  archive      = {J_CC},
  author       = {Li, Jia Wen and Chen, Rong Jun and Barma, Shovan and Chen, Fei and Pun, Sio Hang and Mak, Peng Un and Wang, Lei Jun and Zeng, Xian Xian and Ren, Jin Chang and Zhao, Hui Min},
  doi          = {10.1007/s12559-022-10053-z},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2260-2273},
  shortjournal = {Cogn. Comput.},
  title        = {An approach to emotion recognition using brain rhythm sequencing and asymmetric features},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptable global network for whole-brain segmentation with
symmetry consistency loss. <em>CC</em>, <em>14</em>(6), 2246–2259. (<a
href="https://doi.org/10.1007/s12559-022-10011-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmenting the whole brain into a large number (for example, $$\ge 100$$ ) of regions is challenging due to the complexity of the brain and the lack of annotated data. Deep neural network-based segmentation methods have shown promise, but due to the limitation of graphics processing unit (GPU) memory, they cannot fully exploit the brain structure information contained in 3D data. This paper proposes a memory-efficient framework to exploit the global brain structure for whole-brain segmentation. In this framework, upon extracting the brain region by using a skull-stripping subnetwork, a global modeling subnetwork is used to learn a global brain representation for segmentation, while an adaptable segmentation subnetwork is used to optimize the global representation during training and directly segment the whole brain during testing. This framework enables the representation to be learned from the global structure with reduced memory consumption, and segmentation is performed without splitting the brain into patches. To overcome the lack of annotated data, we also propose a semi-supervised method based on a symmetry consistency loss and a prior knowledge-based pseudolabel generation strategy. Extensive experiments on four datasets demonstrate that our method outperforms previously developed methods and achieves state-of-the-art performance. The method is computationally efficient in that segmenting a raw magnetic resonance imaging (MRI) image requires less than 2 s on a TITAN X GPU; our approach is much faster than multiatlas-based methods and previously proposed 3D deep learning methods. The code is publicly available at https://github.com/ZYX-MLer/AGNetwork .},
  archive      = {J_CC},
  author       = {Zhao, Yuan-Xing and Zhang, Yan-Ming and Song, Ming and Liu, Cheng-Lin},
  doi          = {10.1007/s12559-022-10011-9},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2246-2259},
  shortjournal = {Cogn. Comput.},
  title        = {Adaptable global network for whole-brain segmentation with symmetry consistency loss},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling tweet dependencies with graph convolutional
networks for sentiment analysis. <em>CC</em>, <em>14</em>(6), 2234–2245.
(<a href="https://doi.org/10.1007/s12559-021-09986-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, individuals spend significant time on online social networks and microblogging websites, consuming news and expressing their opinions and viewpoints on various topics. It is an excellent source of data for various data mining applications, such as sentiment analysis. Mining this type of data presents several challenges, including the posts’ short length and informal language. On the other hand, microblog posts contain a high degree of interdependence, which can help to improve sentiment classification based on text. This data can be represented as a graph, with nodes representing posts and edges representing the various relationships between them. By using recently developed deep learning models for graph structures, this approach enables efficient sentiment analysis of microblog posts. This paper utilizes graphs to represent microblog posts and their various relationships, such as user, friendship, hashtag, sentimental similarity, textual similarity, and common friends. It then employs graph neural networks to perform context-aware sentiment analysis. To make use of the knowledge contained in multiple graphs, we propose a stacking model that simultaneously employs multiple graph types. The findings demonstrate the relevance of sociological theories to the analysis of social media. Experimental results on HCR (a real-world Twitter sentiment analysis dataset), indicate that the proposed approach outperforms baselines and state-of-the-art models.},
  archive      = {J_CC},
  author       = {Keramatfar, Abdalsamad and Amirkhani, Hossein and Bidgoly, Amir Jalaly},
  doi          = {10.1007/s12559-021-09986-8},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2234-2245},
  shortjournal = {Cogn. Comput.},
  title        = {Modeling tweet dependencies with graph convolutional networks for sentiment analysis},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep transfer learning on the aggregated dataset for face
presentation attack detection. <em>CC</em>, <em>14</em>(6), 2223–2233.
(<a href="https://doi.org/10.1007/s12559-022-10037-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presentation attacks are becoming a serious threat to one of the most common biometric applications, namely face recognition (FR). In recent years, numerous methods have been presented to detect and identify these attacks using publicly available datasets. However, such datasets are often collected in controlled environments and are focused on one specific type of attack. We hypothesise that a model’s accurate performance on one or more public datasets does not necessarily guarantee generalisation across other, unseen face presentation attacks. To verify our hypothesis, in this paper, we present an experimental framework where the generalisation ability of pre-trained deep models is assessed using four popular and commonly used public datasets. Extensive experiments were carried out using various combinations of these datasets. Results show that, in some circumstances, a slight improvement in model performance can be achieved by combining different datasets for training purposes. However, even with a combination of public datasets, models still could not be trained to generalise to unseen attacks. Moreover, models could not necessarily generalise to a learned format of attack over different datasets. The work and results presented in this paper suggest that more diverse datasets are needed to drive this research as well as the need for devising new methods capable of extracting spoof-specific features which are independent of specific datasets.},
  archive      = {J_CC},
  author       = {Abdullakutty, Faseela and Elyan, Eyad and Johnston, Pamela and Ali-Gombe, Adamu},
  doi          = {10.1007/s12559-022-10037-z},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2223-2233},
  shortjournal = {Cogn. Comput.},
  title        = {Deep transfer learning on the aggregated dataset for face presentation attack detection},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving zero-shot learning baselines with commonsense
knowledge. <em>CC</em>, <em>14</em>(6), 2212–2222. (<a
href="https://doi.org/10.1007/s12559-022-10044-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning — the problem of training and testing on a completely disjoint set of classes — relies greatly on its ability to transfer knowledge from train classes to test classes. Traditionally semantic embeddings consisting of human-defined attributes or distributed word embeddings are used to facilitate this transfer by improving the association between visual and semantic embeddings. In this paper, we take advantage of explicit relations between nodes defined in ConceptNet, a commonsense knowledge graph, to generate commonsense embeddings of the class labels by using a graph convolution network-based autoencoder. Our experiments performed on three standard benchmark datasets surpass the strong baselines when we fuse our commonsense embeddings with existing semantic embeddings, i.e., human-defined attributes and distributed word embeddings. This work paves the path to more brain-inspired approaches to zero-short learning.},
  archive      = {J_CC},
  author       = {Roy, Abhinaba and Ghosal, Deepanway and Cambria, Erik and Majumder, Navonil and Mihalcea, Rada and Poria, Soujanya},
  doi          = {10.1007/s12559-022-10044-0},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2212-2222},
  shortjournal = {Cogn. Comput.},
  title        = {Improving zero-shot learning baselines with commonsense knowledge},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep cognitive venetian blinds system for automatic
estimation of slat orientation. <em>CC</em>, <em>14</em>(6), 2203–2211.
(<a href="https://doi.org/10.1007/s12559-022-10054-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shading devices are used to control solar radiations that penetrate into the occupied environment through the windows with the aim of ensuring visual comfort and saving the building’s energy consumption. Venetian blinds are commonly employed for the practicality and ease of application. However, occupants often do not change slat orientation causing unnecessary consumption and discomfort. Hence, automatic shading control systems can enhance the energy performance and make the environment more comfortable. In this context, a cognitive venetian blinds system, denoted to as CogVBS and based on a deep feed-forward neural network, is proposed for automatic estimation of slat angle. Here, the EnergyPlus software is employed to simulate the test environment. Experimental results demonstrate the promising performance of the proposed deep CogVBS, reporting a root mean square error (RMSE) and correlation coefficient (r) of 0.1018±0.0015 and 0.9319±0.0020, respectively. The achieved outcomes encourage the use of the proposed cognitive system in realistic environments.},
  archive      = {J_CC},
  author       = {Ieracitano, Cosimo and Nicoletti, Francesco and Arcuri, Natale and Ruggeri, Giuseppe and Versaci, Mario and Morabito, Francesco Carlo and Mammone, Nadia},
  doi          = {10.1007/s12559-022-10054-y},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2203-2211},
  shortjournal = {Cogn. Comput.},
  title        = {A deep cognitive venetian blinds system for automatic estimation of slat orientation},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Personalized spiking neural network models of clinical and
environmental factors to predict stroke. <em>CC</em>, <em>14</em>(6),
2187–2202. (<a
href="https://doi.org/10.1007/s12559-021-09975-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high incidence of stroke occurrence necessitates the understanding of its causes and possible ways for early prediction and prevention. In this respect, statistical methods offer the “big picture,” but they have a weak predictive ability at an individual level. This research proposes a new personalized modeling method based on computational spiking neural networks (SNN) for the identification of causal associations between clinical and environmental time series data that can be used to predict individual stroke events. The method is tested on 804 stroke patients. Given a clinical data set of patients who experienced a stroke in the past and the corresponding environmental time-series data for a selected time-window before the stroke event, the method identifies the clusters of individuals with a high risk for stroke under similar conditions. The methodology involves a pipeline of processes when creating a personalized model for an individual $$x$$ : (1) selecting a group of individuals $$Gx$$ with similar personal records to $$x$$ ; (2) training a personalized SNN $$x$$ model of several days of environmental data related to the $$Gx$$ group to predict the risk of stroke for $$x$$ at least one day earlier; (3) model interpretability through 3D visualization; (4) discovery of personalized predictive markers. The results are twofold, first proposing a new computational methodology and second presenting new findings. It is found that certain environmental factors, such as SO2, PM10, CO, and PM2.5, increase the risk of stroke if an individual $$x$$ belongs to a certain cluster of people, characterized by a combination of family history of stroke and diabetes, overweight, vascular/heart disease, age, and other. For the used population data, the proposed method can predict accurately individual risk of stroke before the day of the stroke. The paper presents a new methodology for personalized machine learning methods to define subgroups of the population with a high risk of stroke and to predict early individual risk of the stroke event. This makes the proposed cognitive computation method useful to reduce morbidity and mortality in society. The method is broadly applicable for predicting individual risk of other diseases and mental health conditions.},
  archive      = {J_CC},
  author       = {Doborjeh, Maryam and Doborjeh, Zohreh and Merkin, Alexander and Krishnamurthi, Rita and Enayatollahi, Reza and Feigin, Valery and Kasabov, Nikola},
  doi          = {10.1007/s12559-021-09975-x},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2187-2202},
  shortjournal = {Cogn. Comput.},
  title        = {Personalized spiking neural network models of clinical and environmental factors to predict stroke},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cognitive computing in mental healthcare: A review of
methods and technologies for detection of mental disorders. <em>CC</em>,
<em>14</em>(6), 2169–2186. (<a
href="https://doi.org/10.1007/s12559-022-10042-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mental disorders are closely related to deficits in cognitive control. Such cognitive impairments may result in aberrations in mood, thinking, work, body functions, emotions, social engagements and general behaviour. Mental disorders may affect the phenotypic behaviour like eye movements, facial expressions and speech. Furthermore, a close association has been observed within mental disorders and physiological responses emanating from the brain, muscles, heart, eyes, skin, etc. Mental disorders disrupt higher cognitive function, social cognition, control of complex behaviours and regulation of emotion. Cognitive computation may help understand such disruptions for improved decision-making with the help of computers. This study presents a systematic literature review to promulgate state of art computational methods and technologies facilitating automated detection of mental disorders. For this survey, the relevant literature between 2010 and 2021 has been studied. Recommendations of Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) model were adopted for identification, screening, validating and inclusion of research literature. The self-diagnosis tools for detection of mental disorders like questionnaires and rating scales are inconsistent and static in nature. They cannot encompass the diversity of mental disorders, inter-individual variability and impact of emotional state of an individual. Furthermore, there are no standard baselines for mental disorders. This situation mandates a multi-faceted approach which may utilise data from physiological signals, behavioural patterns and even data obtained from various online portals like social media to efficiently and effectively detect the prevalence, type and severity of mental disorders.},
  archive      = {J_CC},
  author       = {Singh, Jaiteg and Hamid, Mir Aamir},
  doi          = {10.1007/s12559-022-10042-2},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2169-2186},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitive computing in mental healthcare: A review of methods and technologies for detection of mental disorders},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-way decision models of cognitive computing in
pythagorean fuzzy environments. <em>CC</em>, <em>14</em>(6), 2153–2168.
(<a href="https://doi.org/10.1007/s12559-021-09867-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loss functions, commonly believed to be the cost of cognitive computing, are a key element in decision-making, and three-way decisions can be regarded as a cognitive computing method that seeks to minimize the overall risks involved in the decision-making process. Recently, many studies on loss functions have been conducted based on fuzzy sets, intuitionistic fuzzy sets, and interval intuitionistic fuzzy sets. However, most of these studies draw conclusions based on two descriptions, which may fail to capture the whole picture of decision-making. In this paper, in order to improve the accuracy of decision-making, we propose loss functions based on three descriptions, adding a hesitation description to the Pythagorean fuzzy environment. Then, we redefine the expected loss functions, which allow people to make a decision with more uncertainty. Subsequently, on the basis of the Bayesian minimum risk decision theory, four strategies for dealing with expected losses are proposed, and three-way decision models are established. Finally, group decision models are discussed. Three-way decision models of real value loss functions and Pythagorean fuzzy loss functions based on three descriptions are proposed, and data analyses of different parameters show the feasibility of the three-way decision models.},
  archive      = {J_CC},
  author       = {Zhang, Shao-Pu and Sun, Pin and Mi, Ju-Sheng and Feng, Tao},
  doi          = {10.1007/s12559-021-09867-0},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2153-2168},
  shortjournal = {Cogn. Comput.},
  title        = {Three-way decision models of cognitive computing in pythagorean fuzzy environments},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodal emotion distribution learning. <em>CC</em>,
<em>14</em>(6), 2141–2152. (<a
href="https://doi.org/10.1007/s12559-021-09927-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition is an interesting and challenging problem and has attracted much attention in recent years. To more accurately express emotions, emotion distribution learning (EDL) introduces the emotion description degree to form an emotion distribution at a fine granularity, which is used to describe the fusion of multiple basic emotions at different levels. Existing EDL research has shown a strong representation ability on emotion recognition, but all studies are based on unimodal information, meaning the results may be one-sided. As the first pioneering investigation of multimodal emotion distribution learning, we present a corresponding learning method named MEDL. First, for each modality, we learn an emotion distribution and obtain the corresponding label correlation matrix. Second, we constrain the consistency of label correlation matrices between different modalities to utilize modal complementarity. Finally, the final emotion distribution is achieved based on a simple decision fusion strategy. The experimental results demonstrate that our proposal performs better than some state-of-the-art multimodal emotion recognition methods and unimodal emotion distribution learning methods.},
  archive      = {J_CC},
  author       = {Jia, Xiuyi and Shen, Xiaoxia},
  doi          = {10.1007/s12559-021-09927-5},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2141-2152},
  shortjournal = {Cogn. Comput.},
  title        = {Multimodal emotion distribution learning},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mining knowledge of respiratory rate quantification and
abnormal pattern prediction. <em>CC</em>, <em>14</em>(6), 2120–2140. (<a
href="https://doi.org/10.1007/s12559-021-09908-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The described application of granular computing is motivated because cardiovascular disease (CVD) remains a major killer globally. There is increasing evidence that abnormal respiratory patterns might contribute to the development and progression of CVD. Consequently, a method that would support a physician in respiratory pattern evaluation should be developed. Group decision-making, tri-way reasoning, and rough set–based analysis were applied to granular computing. Signal attributes and anthropomorphic parameters were explored to develop prediction models to determine the percentage contribution of periodic-like, intermediate, and normal breathing patterns in the analyzed signals. The proposed methodology was validated employing k-nearest neighbor (k-NN) and UMAP (uniform manifold approximation and projection). The presented approach applied to respiratory pattern evaluation shows that median accuracies in a considerable number of cases exceeded 0.75. Overall, parameters related to signal analysis are indicated as more important than anthropomorphic features. It was also found that obesity characterized by a high WHR (waist-to-hip ratio) and male sex were predisposing factors for the occurrence of periodic-like or intermediate patterns of respiration. It may be among the essential findings derived from this study. Based on classification measures, it may be observed that a physician may use such a methodology as a respiratory pattern evaluation-aided method.},
  archive      = {J_CC},
  author       = {Szczuko, Piotr and Kurowski, Adam and Odya, Piotr and Czyżewski, Andrzej and Kostek, Bożena and Graff, Beata and Narkiewicz, Krzysztof},
  doi          = {10.1007/s12559-021-09908-8},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2120-2140},
  shortjournal = {Cogn. Comput.},
  title        = {Mining knowledge of respiratory rate quantification and abnormal pattern prediction},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Granule description of incomplete data: A cognitive
viewpoint. <em>CC</em>, <em>14</em>(6), 2108–2119. (<a
href="https://doi.org/10.1007/s12559-021-09918-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granule description is one of the main challenges to realize explainable AI technologies through information granules. Specifically, granule description of incomplete data is still an open, interesting and important topic. In this study, this problem is studied systematically based on extent–intent view. Concretely, at first we define stable concepts and evanescent concepts in an incomplete formal context and propose their acquisition approaches, respectively. And then, we classify granules into two categories, i.e., basic granules and indefinable granules. After that, we present the descriptions of basic granules via stable concepts and evanescent concepts. Finally, we make some discussions on how to describe indefinable granules. The main contribution as well as the significant feature of this study is granule description of incomplete data based on ordinary formal concepts rather than approximate concepts. The analysis shows that the ordinary concept-based granule description is more concise and less complex than the approximate concept-based granule description, and meanwhile, the ordinary concept-based method can also maintain the same recall of granule description as that of the latter method. Our work will provide cognitive research method to the description of incomplete formal context with the help of concept cognition units.},
  archive      = {J_CC},
  author       = {Zhi, Huilai and Li, Jinhai},
  doi          = {10.1007/s12559-021-09918-6},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2108-2119},
  shortjournal = {Cogn. Comput.},
  title        = {Granule description of incomplete data: A cognitive viewpoint},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cognitive computing and rule extraction in generalized
one-sided formal contexts. <em>CC</em>, <em>14</em>(6), 2087–2107. (<a
href="https://doi.org/10.1007/s12559-021-09868-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective tool for analyzing human behavior and social cognition, rule extraction is a key issue in cognitive computing. However, the existing association rules state whether an attribute is possessed only without considering the order relation of attribute values. In this paper, we propose a novel method for quantitative association rule mining based on a generalized one-sided context and solid cognitive foundations. The extracted rule indicates the order relation of the attribute values and the structure of truth values for different attributes. We also propose specific algorithms to extract generalized one-sided quantitative association rules and non-redundant generalized one-sided quantitative association rules. The scale of data also needs to be considered by cognitive computing. An object may possess different values for the same attribute according to different measuring scales. The relationship between generalized one-sided quantitative association rules at different scales is also discussed. Rather than converting the multi-valued formal context into a binary formal context, the generalized one-sided quantitative association rule is extracted directly in a multi-valued formal context. The experimental results show the presented algorithms reduce both time and space complexity compared with the classical quantitative association rule-mining algorithm.},
  archive      = {J_CC},
  author       = {Hu, Zhiyong and Shao, Mingwen and Liu, Huan and Mi, Jvsheng},
  doi          = {10.1007/s12559-021-09868-z},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2087-2107},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitive computing and rule extraction in generalized one-sided formal contexts},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-way image classification with evidential deep
convolutional neural networks. <em>CC</em>, <em>14</em>(6), 2074–2086.
(<a href="https://doi.org/10.1007/s12559-021-09869-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The farfetched certain classification of uncertain data suffers serious risks. Three-Way Decision (3WD) theory is utilized to implement uncertain data classification methods. Three-way uncertain data classification methods facilitate reducing decision risk and involving human–machine coordination through finding out uncertain cases for abstaining identification. Due to the limitation of traditional classifiers in feature learning, most existing three-way uncertain data classification methods are not good at handling the unstructural data of digital images. This shortage hinders the applications of three-way uncertain data classification in image-based decision support systems, such as the medical decision support systems based on radiographs. In this paper, we adopt deep convolutional neural networks (DCNNs) for feature learning and Dempster–Shafer (D-S) evidence theory as uncertainty measure to implement a three-way method for image classification. We utilize evidence theory to measure the uncertainty of the predictions produced by DCNNs and construct a novel evidential deep convolutional neural network (EviDCNN). Based on this, we propose a Three-Way Classification method with EviDCNN (EviDCNN-3WC). The experiments on massive medical image data sets validate that the proposed three-way classification method with EviDCNN is effective to identify uncertain images and reduce the risk in image classification. The superiorities of the proposed method facilitate its applications in image-based medical decision support systems.},
  archive      = {J_CC},
  author       = {Yue, Xiaodong and Chen, Yufei and Yuan, Bin and Lv, Ying},
  doi          = {10.1007/s12559-021-09869-y},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2074-2086},
  shortjournal = {Cogn. Comput.},
  title        = {Three-way image classification with evidential deep convolutional neural networks},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-way decision making based on data envelopment analysis
with interval data. <em>CC</em>, <em>14</em>(6), 2054–2073. (<a
href="https://doi.org/10.1007/s12559-021-09964-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision (3WD) is an extensively used decision theory, and it is inspired by a special way of human cognition known as thinking in three. For this reason, three-way decision has attracted the attention of many scholars. In recent years, research on the methodology and application of 3WD has been widely developed. During the decision process, decision-making units (DMUs) are usually divided as efficient and inefficient in data envelopment analysis (DEA), while the decision losses of individual DMUs are not regarded. Therefore, we introduce 3WD to DEA and propose a novel three-way DEA model to supplement the drawbacks of the traditional DEA model. First, we establish a hybrid matrix by combining the matrix of input and output indicators of DEA and the loss function table of 3WD. Afterward, a new method for obtaining the conditional probability of DMUs is presented. Next, optimistic, pessimistic and neutral strategies are developed to calculate the expected losses of three actions: acceptance, deferment and rejection. Finally, the corresponding three-way decision rules are generated. Illustrative examples are presented to demonstrate the application of our proposed model, and a series of comparative analyses are presented. Our study not only expands the application of three-way decision, but also extends the semantic interpretation of 3WD.},
  archive      = {J_CC},
  author       = {Chen, Qinxia and Liu, Dun and Zhang, Lu},
  doi          = {10.1007/s12559-021-09964-0},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2054-2073},
  shortjournal = {Cogn. Comput.},
  title        = {Three-way decision making based on data envelopment analysis with interval data},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-way conflict analysis: Alliance, conflict, and
neutrality reducts of three-valued situation tables. <em>CC</em>,
<em>14</em>(6), 2040–2053. (<a
href="https://doi.org/10.1007/s12559-021-09905-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a three-valued situation table, there are different levels of importance for different issues with respect to the alliance, conflict, and neutrality relations, and it is necessary to distinguish all issues as reducible and irreducible elements to filter out the key issues for solving conflicts. However, we have not observed studies of issue reduction for three-valued situation tables in three-way conflict analysis. In this paper, first, we give the matrix representations of alliance, conflict, and neutrality relations and reveal the relationship between two agents in the framework of a matrix. Then, we propose the concepts of alliance, conflict, and neutrality reducts of three-valued situation tables and define reducible and irreducible elements with respect to the alliance, conflict, and neutrality relations. Additionally, we design sequential forward and backward heuristic algorithms for constructing the alliance, conflict, and neutrality reducts. Finally, we give discernibility matrices for computing the sets of all alliance, conflict, and neutrality reducts, and we employ several examples to illustrate how to construct all alliance, conflict, and neutrality reducts. We provide an application of issue reduction to help the government of Gansu Province make a development plan for next year.},
  archive      = {J_CC},
  author       = {Lang, Guangming},
  doi          = {10.1007/s12559-021-09905-x},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2040-2053},
  shortjournal = {Cogn. Comput.},
  title        = {Three-way conflict analysis: Alliance, conflict, and neutrality reducts of three-valued situation tables},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-way bayesian confirmation in classifications.
<em>CC</em>, <em>14</em>(6), 2020–2039. (<a
href="https://doi.org/10.1007/s12559-021-09924-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian confirmation provides a practical approach to reasoning about the truth of hypotheses based on the observation of evidence. It has been applied in many topics closely related to cognitive computing, such as decision makings and problem solving, especially those involving learning and reasoning based on the descriptions of objects. This paper investigates the application of Bayesian confirmation into classification which is a basis in many cognitive computing topics. Bayesian confirmation measures are adopted to evaluate the degree to which a description of objects (i.e., a piece of evidence) confirms the belongingness of the objects to a given class (i.e., a hypothesis). Accordingly, a description space is divided into three regions of confirmatory, disconfirmatory, and neutral descriptions, formulating a three-way Bayesian confirmation model. Based on a sequence of description spaces induced by either attributes or attribute–value pairs, the neutral regions can be further refined, which leads to a sequential model. Furthermore, with a discussion on constructing meaningful trisections of attributes or attribute–value pairs according to their utility, we present a three-level three-way Bayesian confirmation framework where each level focuses on one set in a trisection. Due to their different utility levels, the three sets in a trisection are used in different appropriate ways in constructing the three levels. Bayesian confirmation provides a meaningful perspective of evaluating descriptions in the context of classifications. This work may bring new insights into research on related topics such as decision makings, three-level analysis, rough set theory, and concept analysis.},
  archive      = {J_CC},
  author       = {Hu, Mengjun},
  doi          = {10.1007/s12559-021-09924-8},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2020-2039},
  shortjournal = {Cogn. Comput.},
  title        = {Three-way bayesian confirmation in classifications},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Isomorphic relationship between <span
class="math display"><strong>L</strong></span> -three-way concept
lattices. <em>CC</em>, <em>14</em>(6), 1997–2019. (<a
href="https://doi.org/10.1007/s12559-021-09902-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The three-way decision (3WD) creates a new perspective for decision-making by adding a third option in addition to acceptance and rejection. The decision cost, caused by the yes-or-no decision pattern, is avoided. The 3WD is a human-cognition-inspired problem-solving pattern which offers new theories, models, and tools for cognitive analytics. Formal concept analysis, as a method proposed to mine hidden patterns in data, can only deal with binary-valued data when it appeared. To process more types of data, $$\mathbf {L}$$ -concept analysis, where $$\mathbf {L}$$ represents a truth-value structure, is presented with the generation of various $$\mathbf {L}$$ -two-way ( $$\mathbf {L}$$ 2W) and $$\mathbf {L}$$ -three-way ( $$\mathbf {L}$$ 3W) concept lattices. The aim in this study is to explore the relationship between various $$\mathbf {L}$$ 3W concept lattices that have not been represented by any existing theorems. To fulfill this goal, first, the relationship between $$\mathbf {L}$$ 2W concept lattices is examined, and then, the relationship between $$\mathbf {L}$$ 3W concept lattices is analysed. Finally, the relationship between the $$\mathbf {L}$$ 2W and $$\mathbf {L}$$ 3W concepts is revealed. The results show that the eight types of $$\mathbf {L}$$ 2W concept lattices form two isomorphic groups. The four types of $$\mathbf {L}$$ -object-induced three-way concept lattices, as well as the four types of $$\mathbf {L}$$ -attribute-induced three-way concept lattices, are isomorphic respectively. In addition, the equivalent relationship between $$\mathbf {L}$$ 3W concepts and $$\mathbf {L}$$ 2W concepts provides a way to construct $$\mathbf {L}$$ 3W concept lattices based on $$\mathbf {L}$$ 2W concept lattices.},
  archive      = {J_CC},
  author       = {Zhao, Xuerong and Miao, Duoqian},
  doi          = {10.1007/s12559-021-09902-0},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1997-2019},
  shortjournal = {Cogn. Comput.},
  title        = {Isomorphic relationship between $$\mathbf {L}$$ -three-way concept lattices},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving incremental nonnegative matrix factorization
method for recommendations based on three-way decision making.
<em>CC</em>, <em>14</em>(6), 1978–1996. (<a
href="https://doi.org/10.1007/s12559-021-09897-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative matrix factorization is comprehensively used in recommendation systems. In an effort to reduce the recommended cost of newly added samples, incremental nonnegative matrix factorization and its variants have been extensively studied in recommendation systems. However, the recommendation performance is incapable of particular applications in terms of data sparsity and sample diversity. In this paper, we propose a new incremental recommend algorithm by improving incremental nonnegative matrix factorization based on three-way decision, called Three-way Decision Recommendations Based on Incremental Non-negative Matrix Factorization (3WD-INMF), in which the concept of positive, negative, and boundary regions are employed to update the new coming samples’ features. Finally, experiments on six public data sets demonstrate the error induced by 3WD-INMF is decreasing as the addition of new samples and deliver state-of-the-art performance compared with existing recommendation algorithms. The results indicate our method is more reasonable and efficient by leveraging the idea of three-way decision to perform the recommendation decision process.},
  archive      = {J_CC},
  author       = {Zhang, Xiaoxia and Chen, Lu and Wang, Ye and Wang, Guoyin},
  doi          = {10.1007/s12559-021-09897-8},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1978-1996},
  shortjournal = {Cogn. Comput.},
  title        = {Improving incremental nonnegative matrix factorization method for recommendations based on three-way decision making},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constructing robust fuzzy rough set models based on
three-way decisions. <em>CC</em>, <em>14</em>(6), 1955–1977. (<a
href="https://doi.org/10.1007/s12559-021-09863-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy rough sets are an effective tool for dealing with uncertainty information. The theory of three-way decisions provides a method of decision-making, when a two-way decision may be difficult to make. In this paper, we investigate the combination of fuzzy rough sets and three-way decisions, and construct robust fuzzy rough set models from a three-way decision perspective. In fuzzy rough sets, by introducing a pair of thresholds, we propose three-way approximations of the fuzzy similarity degree, and we construct three-way lower and upper approximations based on the idea of a three-way decision. Furthermore, we discuss the special cases of three-way approximations about of both the fuzzy similarity degree and dual approximations. Sixteen fuzzy rough set models are constructed for under different special cases. Among them, three improved models and the original model are selected to be compared as examples. Finally, for the four fuzzy rough set models, including one model based on three-way decisions, two models based on two-way decisions, and one original model, we design the experiments by introducing two types of data noise to test the robustness of the models. The results verify the better performance of the improved model based on three-way approximations in comparison with the two-way and original models.},
  archive      = {J_CC},
  author       = {Yang, Jilin and Zhang, Xianyong and Qin, Keyun},
  doi          = {10.1007/s12559-021-09863-4},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1955-1977},
  shortjournal = {Cogn. Comput.},
  title        = {Constructing robust fuzzy rough set models based on three-way decisions},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel functional network based on three-way decision for
link prediction in signed social networks. <em>CC</em>, <em>14</em>(6),
1942–1954. (<a
href="https://doi.org/10.1007/s12559-021-09873-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to reveal the potential relationships between users, link prediction has been considered as a fundamental research issue in signed social networks. The key of the link prediction is to measure the similarity between users. Many existing researches use connections between users and their common neighbors to measure the similarities, and these methods rely too much on the structure of social networks. Most of them use the deep neural network to enhance the prediction accuracy. However, the complete structure of the huge social network cannot be captured easily, and the models learnt by the deep neural network are unexplainable and uncontrolled. As an explainable model, functional network is a recent replacement for standard neural network. Therefore, we revise the traditional strategy of functional network and propose a novel functional network framework. Firstly, the attributes are preprocessed through the cloud model to define their importance before inputting them into the functional network. Then the association algorithm is used to do aggregate computation in computing neurons for defining the connections between neurons well. Finally, we use three-way decisions to process the samples in the boundary to optimize the performance of model. Experiments executed on six real datasets show that our method has significantly higher link prediction precision than the state-of-the-art works. From our discussions, the improved functional network can be a valid replacement for neural networks in some fields.},
  archive      = {J_CC},
  author       = {Liu, Qun and Chen, Ying and Zhang, Gangqiang and Wang, Guoyin},
  doi          = {10.1007/s12559-021-09873-2},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1942-1954},
  shortjournal = {Cogn. Comput.},
  title        = {A novel functional network based on three-way decision for link prediction in signed social networks},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-criteria three-way decision making method in a
picture fuzzy probabilistic decision system. <em>CC</em>,
<em>14</em>(6), 1924–1941. (<a
href="https://doi.org/10.1007/s12559-021-09900-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision is a decision-making method based on human cognitive process, and its basic idea is to divide a universal set into three pair-wise disjoint regions to cognitive information processing. As the complexity of decision-making environment, cognitive information about alternatives given by decision-makers is uncertain and inconsistent. Picture fuzzy point operator (PFPO) is an effective tool to handle this information. In order to obtain more reasonable and effective decision results, this paper proposes three-way decision models and develops a multi-attribute three-way decision method. Then, we use the proposed method to solve a project investment problem. We define new operators on picture fuzzy numbers by a monotonically increasing binary function and a monotonically decreasing unary function. Then, we build three-way decision models based on PFPO and these new operators. Further, we fully consider the relationship between attributes and the classification of alternatives, and present a multi-criteria three-way decision method. In addition, we compare the proposed method with the existing methods by a project investment problem. We show that PFPO can handle inconsistent and changing cognitive information more accurately through an example. In a project investment problem, the decision results obtained by using the proposed method are the same as those obtained by the existing methods, which shows that the method is effective. By the analysis and comparison with these methods, it is proved that the proposed method is very suitable for dealing with multi-attribute decision-making problem with changing picture fuzzy information and consistent with human cognition.},
  archive      = {J_CC},
  author       = {Zhao, Ruirui and Ma, Lina and Li, Shenggang and Luo, Minxia},
  doi          = {10.1007/s12559-021-09900-2},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1924-1941},
  shortjournal = {Cogn. Comput.},
  title        = {A multi-criteria three-way decision making method in a picture fuzzy probabilistic decision system},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3W-AlignNet: A feature alignment framework for person search
with three-way decision theory. <em>CC</em>, <em>14</em>(6), 1913–1923.
(<a href="https://doi.org/10.1007/s12559-021-09898-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person search aims to locate and recognize a specified person from a gallery of uncropped scene images, which combines pedestrian detection and person re-identification (re-ID). Existing methods based on Faster R-CNN have been widely used to tackle the two sub-tasks jointly, but they ignore the feature misalignment problem, i.e., re-ID feature localization is not fully aligned with the detected bounding boxes (BBoxes). Due to the fine-grained property of re-ID, it is crucial to extract accurate appearance features. In addition, the granularity of BBoxes detected from gallery images is quite different, and it is defective to treat gallery boxes with different granularity as equal in estimating their similarities with the query. Three-way decision methods are fields of research on human-inspired computation. Inspired by them, we propose a three-way-based feature alignment framework (3W-AlignNet) to optimize the re-ID feature localization. The framework is implemented by iteratively generating new BBoxes and features from previous BBoxes. The three-way decision theory is applied to avoid the mismatch problem caused by increasing Intersection over Union (IoU). We further propose a Granularity Weighted Similarity (GWS) algorithm to relieve the granularity mismatch problem. Extensive experiments show that our method outperforms all other state-of-the-art end-to-end methods on two widely used person search datasets, CUHK-SYSU and PRW.},
  archive      = {J_CC},
  author       = {Yang, Yuting and Miao, Duoqian and Zhang, Hongyun},
  doi          = {10.1007/s12559-021-09898-7},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1913-1923},
  shortjournal = {Cogn. Comput.},
  title        = {3W-AlignNet: A feature alignment framework for person search with three-way decision theory},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3-way concept analysis based on 3-valued formal contexts.
<em>CC</em>, <em>14</em>(6), 1900–1912. (<a
href="https://doi.org/10.1007/s12559-021-09899-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the basic form of data presentation, formal contexts play an elementary and important role in formal concept analysis and in 3-way concept analysis. In fact, many data tables are similar in form to formal contexts. Therefore, these data tables can be studied collectively in a similar framework, and such a study can be significant in knowledge discovery. We propose the notion of 3-valued formal contexts after analyzing the shared characteristics of different data forms such as incomplete formal contexts, conflict situations and other similar cases. After close studies of 3-valued formal contexts, this paper adopts 3-way concept analysis to define 3-valued operators and construct 3-valued concept lattices and finally interpret the meaning of 3-valued operators and discuss the relationship between 3-valued lattices and existing approximation concept lattices. The essence of this method is to present, via 3-way concept analysis, potential information and structure. And 3-way concept analysis shows the common properties of the objects, jointly possessed or jointly not possessed, positive or negative, even the uncertain information. So, this paper actually provides a new model for cognition. Apart from the universal applicability, 3-valued contexts can also be fixed into formal concept analysis. That is, many problems can be studied in the framework of formal concept analysis.},
  archive      = {J_CC},
  author       = {Qi, Jianjun and Wei, Ling and Ren, Ruisi},
  doi          = {10.1007/s12559-021-09899-6},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1900-1912},
  shortjournal = {Cogn. Comput.},
  title        = {3-way concept analysis based on 3-valued formal contexts},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tri-partition state alphabet-based sequential pattern for
multivariate time series. <em>CC</em>, <em>14</em>(6), 1881–1899. (<a
href="https://doi.org/10.1007/s12559-021-09871-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the advancement of cognitive computing and three-way decisions has enabled in-depth sequential pattern understanding through temporal association analysis. The main challenge is to obtain concise patterns that express richer semantics for multivariate time series (MTS) analysis. In this paper, we propose a tri-partition state alphabet-based sequential pattern (Tri-SASP) for MTSs. First, a tri-wildcard gap inserted between each pair of adjacent states enhances the flexibility of the method. Second, a given set of states is partitioned into positive (POS), negative (NEG) and boundary (BND) regions. The states in POS can only be used to construct a Tri-SASP, the states in NEG can only be matched by a tri-wildcard gap, and the states in BND can be used in both ways. Finally, horizontal and vertical algorithms are proposed to obtain frequent Tri-SASPs in a breadth-first manner. The experimental results on four real-world datasets show that (1) the discovered Tri-SASPs and temporal rules can enrich human cognition; (2) the two tri-partition strategies can bring us very meaningful and varied Tri-SASPs; and (3) the two algorithms are effective and scalable.},
  archive      = {J_CC},
  author       = {Zhang, Zhi-Heng and Min, Fan and Chen, Gong-Suo and Shen, Shao-Peng and Wen, Zuo-Cheng and Zhou, Xiang-Bing},
  doi          = {10.1007/s12559-021-09871-4},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1881-1899},
  shortjournal = {Cogn. Comput.},
  title        = {Tri-partition state alphabet-based sequential pattern for multivariate time series},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-way decision models based on multi-granulation rough
intuitionistic hesitant fuzzy sets. <em>CC</em>, <em>14</em>(6),
1859–1880. (<a
href="https://doi.org/10.1007/s12559-021-09956-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practice, people may hesitate to evaluate uncertain things. As an extension of fuzzy sets, intuitionistic hesitant fuzzy sets use multiple membership and non-membership degrees to express uncertain evaluations. Multi-granulation rough set theory is utilized to deal with information in an intuitionistic hesitant fuzzy decision information system, and three-way decision models are established to make decisions. First, rough intuitionistic hesitant fuzzy sets and four multi-granulation rough intuitionistic hesitant fuzzy set models are proposed, and their properties are discussed. Second, we define the combination formula for the upper and lower approximations of multi-granulation rough intuitionistic hesitant fuzzy sets, and present a new intuitionistic hesitant fuzzy cross-entropy. Then, the conditional probabilities under four cases are calculated by the TOPSIS approach. Third, the thresholds in intuitionistic hesitant fuzzy decision-theoretic rough sets are calculated, and corresponding three-way decision rules are given. Finally, four kinds of three-way decision models based on the proposed multi-granulation rough intuitionistic hesitant fuzzy sets are constructed. Furthermore, the decision rule extraction algorithm is designed. The example proved that the four kinds of three-way decision models can evaluate objects with different attitudes and provide decision-making solutions, which demonstrates the feasibility and effectiveness of the proposed algorithm.},
  archive      = {J_CC},
  author       = {Xue, Zhanao and Sun, Bingxin and Hou, Haodong and Pang, Wenli and Zhang, Yanna},
  doi          = {10.1007/s12559-021-09956-0},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1859-1880},
  shortjournal = {Cogn. Comput.},
  title        = {Three-way decision models based on multi-granulation rough intuitionistic hesitant fuzzy sets},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal granule combination selection based on
multi-granularity triadic concept analysis. <em>CC</em>, <em>14</em>(6),
1844–1858. (<a
href="https://doi.org/10.1007/s12559-021-09934-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The thinking mode based on granule structure in granular computing essentially simulates the pattern of human thinking to solve problem. Such thinking for the study of knowledge discovery is also of significant importance in cognitive computing. Under such circumstances, the theory of multi-granularity formal concept analysis (MG-FCA) was proposed. But MG-FCA has not been applied to the analysis of three-dimensional data. Because three-dimensional data is very common and an important type of data in the real world, multi-granularity and knowledge discovery of three-dimensional data are two meaningful topics. In this paper, in order to solve the problem of three-dimensional data granularity, the idea of granularity of attributes is first introduced into triadic contexts on the basis of the relationship between triadic concept analysis and formal concept analysis. Moreover, the definition of multi-granularity triadic context is proposed, and some useful properties are studied. Then, for the purpose of realizing cross-granularity knowledge discovery in multi-granularity triadic contexts, two kinds of triadic contexts are given. As a matter of fact, for a specific problem, people often only need a solution to meet their needs. Thus, the problem of optimal granule combination selection is investigated, and the corresponding algorithms are explored. At last, for better understanding, an example with certain semantics is used to explain the proposed methods for multi-granularity triadic contexts. The main contribution as well as the significant feature of this study is to construct multi-level three-dimensional data structure and realize cross-granularity knowledge discovery. Our work will provide multi-granularity cognitive research method based on three-dimensional data.},
  archive      = {J_CC},
  author       = {Wan, Qing and Li, Jinhai and Wei, Ling},
  doi          = {10.1007/s12559-021-09934-6},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1844-1858},
  shortjournal = {Cogn. Comput.},
  title        = {Optimal granule combination selection based on multi-granularity triadic concept analysis},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-granular intuitionistic fuzzy three-way decision model
based on the risk preference outranking relation. <em>CC</em>,
<em>14</em>(6), 1826–1843. (<a
href="https://doi.org/10.1007/s12559-021-09888-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important extension of decision-theoretic rough sets, three-way decision theory provides a new perspective for people to deal with uncertain problems. However, the traditional multi-granularity decision-theoretic rough sets model has limited ability in describing the risk preferences of decision-makers and the processing of intuitionistic fuzzy information. In addition, as far as we know, most of the risk loss functions in existing studies are based on utility theory. However, the complete compensability between attributes is not always true, and this fact may lead to inconsistencies between the final calculated results and the actual situation. We propose a multi-granular intuitionistic fuzzy three-way decision model based on the risk preference outranking relation. In this scenario, we first define the outranking relation on the intuitionistic fuzzy set and fuse it for the purpose of risk preference calculation. Next, starting from the single granularity, the relations between the membership outranking relation class, the nonmembership outranking relation class, and the rough approximation are analyzed, and the related properties are proven. Then, the single granularity is extended to construct the multi-granular intuitionistic fuzzy decision-theoretic rough sets and their corresponding three-way decision model. Furthermore, by systematically studying the decision loss costs of optimistic and pessimistic states, three-way decision rules are induced. The rationality and effectiveness of our proposed model are verified through a case study analysis and comparisons with existing methods. The results show that our proposed model can quantitatively analyze and calculate the uncertainty of decision-makers’ cognitive risk preferences, achieve global control of the decision-making process, and reduce the loss of decision-making costs.},
  archive      = {J_CC},
  author       = {Xin, Xian-wei and Song, Ji-hua and Xue, Zhan-ao and Sun, Jing-bo and Peng, Wei-ming},
  doi          = {10.1007/s12559-021-09888-9},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1826-1843},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-granular intuitionistic fuzzy three-way decision model based on the risk preference outranking relation},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attribute reduction algorithms determined by invariants for
decision tables. <em>CC</em>, <em>14</em>(6), 1818–1825. (<a
href="https://doi.org/10.1007/s12559-021-09887-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set theory is a field of research pertaining to human-inspired computation. Attribute reduction is an important component of rough set theory and has been extensively studied. The reduction invariant is a key concept for an attribute reduction and finding new reduction invariants is an important task of attribute reduction. This paper explores the effect of different reduction invariants on the same attribute reduction types. The aim of this paper was to elucidate the mathematical structure of attribute reduction, thereby facilitating the use of new reduction invariants and their corresponding algorithms for positive region reduction and relative reduction in decision tables. New reduction invariants provide the opportunity to design significantly improved reduction algorithms. Two main reduction algorithms are used to identify reducts. One is a heuristic algorithm and the other is a discernibility matrix-based algorithm. Mathematically, the latter is far more complicated than the former. Although the discernibility matrix-based algorithm has a high time complexity, it remains the only approach to identify all reducts. This paper uses the discernibility matrix-based methods to study the attribute reduction problem. We focus on the mathematical structures of attribute reduction with respect to invariants and provide different algorithms to solve the same reduction problem. This research on reduction invariants provides a new perspective for attribute reduction. Positive region reduction and relative reduction are two frequently used types of reduction for decision tables. We provide three invariants for positive region reduction. Based on these invariants, we derive the corresponding discernibility matrix-based reduction algorithms that yield the same reduction results. For relative reduction, we also obtain similar results regarding invariants and algorithms. The shortcoming of this work is that we do not offer a simpler algorithm than the heuristic algorithm. However, the presented mathematical framework unifies previous work on the subject and is conducive to simplifying the associated decision tables for identifying all of the reducts.},
  archive      = {J_CC},
  author       = {Liu, Guilong},
  doi          = {10.1007/s12559-021-09887-w},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1818-1825},
  shortjournal = {Cogn. Comput.},
  title        = {Attribute reduction algorithms determined by invariants for decision tables},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-granularity information-based method for learning
high-dimensional bayesian network structures. <em>CC</em>,
<em>14</em>(6), 1805–1817. (<a
href="https://doi.org/10.1007/s12559-021-09891-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of structure learning is to construct a qualitative relationship of Bayesian networks. Bayesian network with interpretability and logicality is widely applied in a lot of fields. With the extensive development of high-dimensional and low sample size data in some applications, structure learning of Bayesian networks for high dimension and low sample size data becomes a challenging problem. To handle this problem, we propose a method for learning high-dimensional Bayesian network structures based on multi-granularity information. First, an undirected independence graph construction method containing global structure information is designed to optimize the search space of network structure. Then, an improved agglomerative hierarchical clustering method is presented to cluster variables into sub-granules, which reduces the complexity of structure learning by considering the variable community characteristic in high-dimensional data. Finally, the corresponding sub-graphs are formed by learning the internal structure of sub-granules, and the final network structure is constructed based on the proposed construct link graph algorithm. To verify the proposed method, we conduct two types of comparison experiments: comparison experiment and embedded comparison experiment. The results of the experiments show that our approach is superior to the competitors. The results indicate that our method can not only learn structures of Bayesian network from high-dimensional data efficiently but also improve the efficiency and accuracy of network structure generated by other algorithms for high-dimensional data.},
  archive      = {J_CC},
  author       = {He, Chaofan and Yu, Hong and Gu, Songen and Zhang, Wei},
  doi          = {10.1007/s12559-021-09891-0},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1805-1817},
  shortjournal = {Cogn. Comput.},
  title        = {A multi-granularity information-based method for learning high-dimensional bayesian network structures},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Granular computing and three-way decisions for cognitive
analytics. <em>CC</em>, <em>14</em>(6), 1801–1804. (<a
href="https://doi.org/10.1007/s12559-022-10028-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Yao, JingTao and Yao, Yiyu and Ciucci, Davide and Huang, Kaizhu},
  doi          = {10.1007/s12559-022-10028-0},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1801-1804},
  shortjournal = {Cogn. Comput.},
  title        = {Granular computing and three-way decisions for cognitive analytics},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated detection approaches to autism spectrum disorder
based on human activity analysis: A review. <em>CC</em>, <em>14</em>(5),
1773–1800. (<a
href="https://doi.org/10.1007/s12559-021-09895-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism Spectrum Disorder (ASD) is a neuro-developmental disorder that limits social and cognitive abilities. ASD has no cure so early diagnosis is important for reducing its impact. The current behavioral observation-based subjective-diagnosis systems (e.g., DSM-5 or ICD-10) frequently misdiagnose subjects. Therefore, researchers are attempting to develop automated diagnosis systems with minimal human intervention, quicker screening time, and better outreach. This paper is a PRISMA-based systematic review examining the potential of automated autism detection system with Human Activity Analysis (HAA) to look for distinctive ASD characteristics such as repetitive behavior, abnormal gait and visual saliency. The literature from 2011 onward is qualitatively and quantitatively analyzed to investigate whether HAA can identify the features of ASD, the level of its classification accuracy, the degree of human intervention, and screening time. Based on these findings, we discuss the approaches, challenges, resources, and future directions in this area. According to our quantitative assessment of the dataset Zunino et al. (IEEE: 3421–3426, 2018 [1]), Inception v3 and LSTM Zunino et al. (IEEE: 3421–3426, 2018 [1]) give the highest accuracy (89%) for repetitive behavior. For abnormal gait-based approach, the multilayer perceptron gives 98% accuracy based on 18 features from dataset Abdulrahman et al. (COMPUSOFT: An International Journal of Advanced Computer Technology 9(8):3791–3797, 2020 [2]). For gaze pattern, a saliency-metric feature-based learning Rahman et al. (Int Conf Pattern Recognit, 2020 [3]) gives 99% accuracy on dataset Duan et al. (Proceedings of the 10th ACM Multimedia Systems Conference: 255–260, 2019 [4]), while an algorithm involving statistical features and Decision Trees yields an accuracy of 76% on dataset Yaneva et al. (Proceedings of the Internet of Accessible Things. W4A ’18, Association for Computing Machinery, New York, NY, USA, 1–10, 2018 [5]). In terms of the state of the art, fully automated HAA systems for ASD diagnosis show promise but are still in developmental stages. However, this is an active research field, and HAA has good prospects for helping to diagnose ASD objectively in less time with better accuracy.},
  archive      = {J_CC},
  author       = {Rahman, Sejuti and Ahmed, Syeda Faiza and Shahid, Omar and Arrafi, Musabbir Ahmed and Ahad, M. A. R.},
  doi          = {10.1007/s12559-021-09895-w},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1773-1800},
  shortjournal = {Cogn. Comput.},
  title        = {Automated detection approaches to autism spectrum disorder based on human activity analysis: A review},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning for reliable classification of COVID-19, MERS,
and SARS from chest x-ray images. <em>CC</em>, <em>14</em>(5),
1752–1772. (<a
href="https://doi.org/10.1007/s12559-021-09955-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novel coronavirus disease (COVID-19) is an extremely contagious and quickly spreading coronavirus infestation. Severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS), which outbreak in 2002 and 2011, and the current COVID-19 pandemic are all from the same family of coronavirus. This work aims to classify COVID-19, SARS, and MERS chest X-ray (CXR) images using deep convolutional neural networks (CNNs). To the best of our knowledge, this classification scheme has never been investigated in the literature. A unique database was created, so-called QU-COVID-family, consisting of 423 COVID-19, 144 MERS, and 134 SARS CXR images. Besides, a robust COVID-19 recognition system was proposed to identify lung regions using a CNN segmentation model (U-Net), and then classify the segmented lung images as COVID-19, MERS, or SARS using a pre-trained CNN classifier. Furthermore, the Score-CAM visualization method was utilized to visualize classification output and understand the reasoning behind the decision of deep CNNs. Several deep learning classifiers were trained and tested; four outperforming algorithms were reported: SqueezeNet, ResNet18, InceptionV3, and DenseNet201. Original and preprocessed images were used individually and all together as the input(s) to the networks. Two recognition schemes were considered: plain CXR classification and segmented CXR classification. For plain CXRs, it was observed that InceptionV3 outperforms other networks with a 3-channel scheme and achieves sensitivities of 99.5%, 93.1%, and 97% for classifying COVID-19, MERS, and SARS images, respectively. In contrast, for segmented CXRs, InceptionV3 outperformed using the original CXR dataset and achieved sensitivities of 96.94%, 79.68%, and 90.26% for classifying COVID-19, MERS, and SARS images, respectively. The classification performance degrades with segmented CXRs compared to plain CXRs. However, the results are more reliable as the network learns from the main region of interest, avoiding irrelevant non-lung areas (heart, bones, or text), which was confirmed by the Score-CAM visualization. All networks showed high COVID-19 detection sensitivity (&gt; 96%) with the segmented lung images. This indicates the unique radiographic signature of COVID-19 cases in the eyes of AI, which is often a challenging task for medical doctors.},
  archive      = {J_CC},
  author       = {Tahir, Anas M. and Qiblawey, Yazan and Khandakar, Amith and Rahman, Tawsifur and Khurshid, Uzair and Musharavati, Farayi and Islam, M. T. and Kiranyaz, Serkan and Al-Maadeed, Somaya and Chowdhury, Muhammad E. H.},
  doi          = {10.1007/s12559-021-09955-1},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1752-1772},
  shortjournal = {Cogn. Comput.},
  title        = {Deep learning for reliable classification of COVID-19, MERS, and SARS from chest X-ray images},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dense tissue pattern characterization using deep neural
network. <em>CC</em>, <em>14</em>(5), 1728–1751. (<a
href="https://doi.org/10.1007/s12559-021-09970-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast tumors are from the common infections among women around the world. Classifying the various types of breast tumors contribute to treating breast tumors more efficiently. However, this classification task is often hindered by dense tissue patterns captured in mammograms. The present study has been proposed a dense tissue pattern characterization framework using deep neural network. A total of 322 mammograms belonging to the mini-MIAS dataset and 4880 mammograms from DDSM dataset have been taken, and an ROI of fixed size 224 × 224 pixels from each mammogram has been extracted. In this work, tedious experimentation has been executed using different combinations of training and testing sets using different activation function with AlexNet, ResNet-18 model. Data augmentation has been used to create a similar type of virtual image for proper training of the DL model. After that, the testing set is applied on the trained model to validate the proposed model. During experiments, four different activation functions ‘sigmoid’, ‘tanh’, ‘ReLu’, and ‘leakyReLu’ are used, and the outcome for each function has been reported. It has been found that activation function ‘ReLu’ perform always outstanding with respect to others. For each experiment, classification accuracy and kappa coefficient have been computed. The obtained accuracy and kappa value for MIAS dataset using ResNet-18 model is 91.3% and 0.803, respectively. For DDSM dataset, the accuracy of 92.3% and kappa coefficient value of 0.846 are achieved. After the combination of both dataset images, the achieved accuracy is 91.9%, and kappa coefficient value is 0.839 using ResNet-18 model. Finally, it has been concluded that the ResNet-18 model and ReLu activation function yield outstanding performance for the task.},
  archive      = {J_CC},
  author       = {Kumar, Indrajeet and Kumar, Abhishek and Kumar, V D Ambeth and Kannan, Ramani and Vimal, Vrince and Singh, Kamred Udham and Mahmud, Mufti},
  doi          = {10.1007/s12559-021-09970-2},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1728-1751},
  shortjournal = {Cogn. Comput.},
  title        = {Dense tissue pattern characterization using deep neural network},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning approach for early detection of alzheimer’s
disease. <em>CC</em>, <em>14</em>(5), 1711–1727. (<a
href="https://doi.org/10.1007/s12559-021-09946-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is a chronic, irreversible brain disorder, no effective cure for it till now. However, available medicines can delay its progress. Therefore, the early detection of AD plays a crucial role in preventing and controlling its progression. The main objective is to design an end-to-end framework for early detection of Alzheimer’s disease and medical image classification for various AD stages. A deep learning approach, specifically convolutional neural networks (CNN), is used in this work. Four stages of the AD spectrum are multi-classified. Furthermore, separate binary medical image classifications are implemented between each two-pair class of AD stages. Two methods are used to classify the medical images and detect AD. The first method uses simple CNN architectures that deal with 2D and 3D structural brain scans from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset based on 2D and 3D convolution. The second method applies the transfer learning principle to take advantage of the pre-trained models for medical image classifications, such as the VGG19 model. Due to the COVID-19 pandemic, it is difficult for people to go to hospitals periodically to avoid gatherings and infections. As a result, Alzheimer’s checking web application is proposed using the final qualified proposed architectures. It helps doctors and patients to check AD remotely. It also determines the AD stage of the patient based on the AD spectrum and advises the patient according to its AD stage. Nine performance metrics are used in the evaluation and the comparison between the two methods. The experimental results prove that the CNN architectures for the first method have the following characteristics: suitable simple structures that reduce computational complexity, memory requirements, overfitting, and provide manageable time. Besides, they achieve very promising accuracies, 93.61% and 95.17% for 2D and 3D multi-class AD stage classifications. The VGG19 pre-trained model is fine-tuned and achieved an accuracy of 97% for multi-class AD stage classifications.},
  archive      = {J_CC},
  author       = {Helaly, Hadeer A. and Badawy, Mahmoud and Haikal, Amira Y.},
  doi          = {10.1007/s12559-021-09946-2},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1711-1727},
  shortjournal = {Cogn. Comput.},
  title        = {Deep learning approach for early detection of alzheimer’s disease},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comparison of deep learning techniques for arterial blood
pressure prediction. <em>CC</em>, <em>14</em>(5), 1689–1710. (<a
href="https://doi.org/10.1007/s12559-021-09910-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous vital signal monitoring is becoming more relevant in preventing diseases that afflict a large part of the world’s population; for this reason, healthcare equipment should be easy to wear and simple to use. Non-intrusive and non-invasive detection methods are a basic requirement for wearable medical devices, especially when these are used in sports applications or by the elderly for self-monitoring. Arterial blood pressure (ABP) is an essential physiological parameter for health monitoring. Most blood pressure measurement devices determine the systolic and diastolic arterial blood pressure through the inflation and the deflation of a cuff. This technique is uncomfortable for the user and may result in anxiety, and consequently affect the blood pressure and its measurement. The purpose of this paper is the continuous measurement of the ABP through a cuffless, non-intrusive approach. The approach of this paper is based on deep learning techniques where several neural networks are used to infer ABP, starting from photoplethysmogram (PPG) and electrocardiogram (ECG) signals. The ABP was predicted first by utilizing only PPG and then by using both PPG and ECG. Convolutional neural networks (ResNet and WaveNet) and recurrent neural networks (LSTM) were compared and analyzed for the regression task. Results show that the use of the ECG has resulted in improved performance for every proposed configuration. The best performing configuration was obtained with a ResNet followed by three LSTM layers: this led to a mean absolute error (MAE) of 4.118 mmHg on and 2.228 mmHg on systolic and diastolic blood pressures, respectively. The results comply with the American National Standards of the Association for the Advancement of Medical Instrumentation. ECG, PPG, and ABP measurements were extracted from the MIMIC database, which contains clinical signal data reflecting real measurements. The results were validated on a custom dataset created at Neuronica Lab, Politecnico di Torino.},
  archive      = {J_CC},
  author       = {Paviglianiti, Annunziata and Randazzo, Vincenzo and Villata, Stefano and Cirrincione, Giansalvo and Pasero, Eros},
  doi          = {10.1007/s12559-021-09910-0},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1689-1710},
  shortjournal = {Cogn. Comput.},
  title        = {A comparison of deep learning techniques for arterial blood pressure prediction},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantum machine learning architecture for COVID-19
classification based on synthetic data generation using conditional
adversarial neural network. <em>CC</em>, <em>14</em>(5), 1677–1688. (<a
href="https://doi.org/10.1007/s12559-021-09926-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 is a novel virus that affects the upper respiratory tract, as well as the lungs. The scale of the global COVID-19 pandemic, its spreading rate, and deaths are increasing regularly. Computed tomography (CT) scans can be used carefully to detect and analyze COVID-19 cases. In CT images/scans, ground-glass opacity (GGO) is found in the early stages of infection. While in later stages, there is a superimposed pulmonary consolidation. This research investigates the quantum machine learning (QML) and classical machine learning (CML) approaches for the analysis of COVID-19 images. The recent developments in quantum computing have led researchers to explore new ideas and approaches using QML. The proposed approach consists of two phases: in phase I, synthetic CT images are generated through the conditional adversarial network (CGAN) to increase the size of the dataset for accurate training and testing. In phase II, the classification of COVID-19/healthy images is performed, in which two models are proposed: CML and QML. The proposed model achieved 0.94 precision (Pn), 0.94 accuracy (Ac), 0.94 recall (Rl), and 0.94 F1-score (Fe) on POF Hospital dataset while 0.96 Pn, 0.96 Ac, 0.95 Rl, and 0.96 Fe on UCSD-AI4H dataset. The proposed method achieved better results when compared to the latest published work in this domain.},
  archive      = {J_CC},
  author       = {Amin, Javaria and Sharif, Muhammad and Gul, Nadia and Kadry, Seifedine and Chakraborty, Chinmay},
  doi          = {10.1007/s12559-021-09926-6},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1677-1688},
  shortjournal = {Cogn. Comput.},
  title        = {Quantum machine learning architecture for COVID-19 classification based on synthetic data generation using conditional adversarial neural network},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel approach for tuning of fluidic resistance in
deterministic lateral displacement array for enhanced separation of
circulating tumor cells. <em>CC</em>, <em>14</em>(5), 1660–1676. (<a
href="https://doi.org/10.1007/s12559-021-09904-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deterministic lateral displacement (DLD) is evolving as an effective passive technique for seclusion of circulating tumor cells (CTCs) functioning based on nonuniform splitting of laminar flow moving through an array of micropillars. In this research work, an unconventional approach has been presented to alter the fluidic resistance between micropillars in asymmetric DLD array for better separation of CTCs in a blood sample. This paper is aimed at introducing an innovative approach using electrical network analogy for tuning of fluidic resistance resulting in enhanced seclusion of CTCs from WBCs implementing the concept of asymmetric DLD array. The paper also describes the computational analysis of a microfluidic device using tuned asymmetric DLD array technique. A cognitive clinical decision support system for identification of CTCs based on the model is also illustrated. In this paper, computational fluid dynamics approach has been used through simulation of the microfluidic device in COMSOL Multiphysics 5.4 software to effectively regulate the trajectory of differently sized CTCs and WBCs. A novel mathematical fluidic resistance tuning approach has been introduced to design the DLD array for effective segregation of different varieties of CTCs realized by computational visualization of trajectory working on Navier–Stokes equation. The proposed design of microfluidic device isolates three distinct CTCs, i.e., lung cancer CTCs, prostate cancer CTCs, and breast cancer CTCs of diameters 22.5 µm, 10.64 µm, and 13.1 µm, respectively, from tiny WBCs of diameter 12 µm with separation efficiencies above 90% at a high sample flow rate of 20 × 10−6 kg/s, thereby offering higher throughput. The tuning model of fluidic resistances between micropillars has been shown to offer minimal resistive effect to the required CTC trajectory while maintaining uniform pressure distribution around micropillars.},
  archive      = {J_CC},
  author       = {Bhattacharjee, Rituraj and Kumar, R. and Al-Turjman, Fadi},
  doi          = {10.1007/s12559-021-09904-y},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1660-1676},
  shortjournal = {Cogn. Comput.},
  title        = {A novel approach for tuning of fluidic resistance in deterministic lateral displacement array for enhanced separation of circulating tumor cells},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel probabilistic-based deep neural network: Toward the
selection of wart treatment. <em>CC</em>, <em>14</em>(5), 1643–1659. (<a
href="https://doi.org/10.1007/s12559-021-09882-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In clinical research, adequate use of gathered information to provide an intelligent framework to assist the doctors is a great challenge for the current biomedical research community. This study proposed a probabilistic deep neural network (PDNN) to select wart treatment method, where the layered structure of artificial neurons plays a crucial role in generating the optimal feature space. However, the probabilistic and thresholding technique is used to minimize the false negative and false positive instances. In the existing approaches, prediction accuracy and biasedness are major concerns in identifying the best wart treatment method. The benchmark dataset consists of 180 patients toward the selection of immunotherapy and cryotherapy treatment methods. Based on the feature descriptors about the wart, the baseline classifiers such as Naïve Bayes (NB), logistic regression and ensemble (LR), support vector machine (SVM), decision tree (DT), bagging, random forest (RF), and eXtreme Gradient Boosting (XGB) along with the developed PDNN was constructed by taking splitting ratio criteria into account. The standard statistical measures such as the measure of accuracy (MoA), error rate, sensitivity, specificity, and area under the curve (AUC) were considered to evaluate the predictive behavior. The proposed PDNN approach obtained promising results: moA, error rate, sensitivity, specificity, and measure of AUC as 0.9778, 0.0222, 0.9762, 0.9792, and 0.9818 while selecting immunotherapy and 0.9889, 0.0111, 1.0000, 0.9796, and 0.9970 in case of cryotherapy. The developed PDNN outperforms baseline classifiers and existing state-of-the-art wart treatment expert systems. The proposed model will improve the success rate and saves the diagnosing time. PDNN-based wart treatment identification system can be implemented in real time after consulting with a domain specialist.},
  archive      = {J_CC},
  author       = {Mishra, Abinash and Uyyala, Srinivasulu Reddy and A, Venkataswamy Reddy},
  doi          = {10.1007/s12559-021-09882-1},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1643-1659},
  shortjournal = {Cogn. Comput.},
  title        = {A novel probabilistic-based deep neural network: Toward the selection of wart treatment},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep transfer learning for improved detection of keratoconus
using corneal topographic maps. <em>CC</em>, <em>14</em>(5), 1627–1642.
(<a href="https://doi.org/10.1007/s12559-021-09880-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical keratoconus (KCN) detection is a challenging and time-consuming task. In the diagnosis process, ophthalmologists must revise demographic and clinical ophthalmic examinations. The latter include slit-lamb, corneal topographic maps, and Pentacam indices (PI). We propose an Ensemble of Deep Transfer Learning (EDTL) based on corneal topographic maps. We consider four pretrained networks, SqueezeNet (SqN), AlexNet (AN), ShuffleNet (SfN), and MobileNet-v2 (MN), and fine-tune them on a dataset of KCN and normal cases, each including four topographic maps. We also consider a PI classifier. Then, our EDTL method combines the output probabilities of each of the five classifiers to obtain a decision based on the fusion of probabilities. Individually, the classifier based on PI achieved 93.1% accuracy, whereas the deep classifiers reached classification accuracies over 90% only in isolated cases. Overall, the average accuracy of the deep networks over the four corneal maps ranged from 86% (SfN) to 89.9% (AN). The classifier ensemble increased the accuracy of the deep classifiers based on corneal maps to values ranging (92.2% to 93.1%) for SqN and (93.1% to 94.8%) for AN. Including in the ensemble-specific combinations of corneal maps’ classifiers and PI increased the accuracy to 98.3%. Moreover, visualization of first learner filters in the networks and Grad-CAMs confirmed that the networks had learned relevant clinical features. This study shows the potential of creating ensembles of deep classifiers fine-tuned with a transfer learning strategy as it resulted in an improved accuracy while showing learnable filters and Grad-CAMs that agree with clinical knowledge. This is a step further towards the potential clinical deployment of an improved computer-assisted diagnosis system for KCN detection to help ophthalmologists to confirm the clinical decision and to perform fast and accurate KCN treatment.},
  archive      = {J_CC},
  author       = {Al-Timemy, Ali H. and Ghaeb, Nebras H. and Mosa, Zahraa M. and Escudero, Javier},
  doi          = {10.1007/s12559-021-09880-3},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1627-1642},
  shortjournal = {Cogn. Comput.},
  title        = {Deep transfer learning for improved detection of keratoconus using corneal topographic maps},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel IoT-fog-cloud-based healthcare system for monitoring
and preventing encephalitis. <em>CC</em>, <em>14</em>(5), 1609–1626. (<a
href="https://doi.org/10.1007/s12559-021-09856-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 2019, the outbreak of Acute Encephalitis Syndrome (AES) outbreak occurred in the Bihar region of India. AES, a viral infection that affects the immune system of the human, is recognized as public health concern globally. The objective of this study is to monitor and prevent the spread of Encephalitis (ENCPH). Spatio-temporal-based Temporal-Recurrent Neural Network (T-RNN) prediction model is used to control the outbreak and generate an alarming signal to the medical caregiver in case of abnormality. T-RNN model is appended with novel Self-Organized Mapping (SOM) technique for outbreak visualization geographically. The current work presents a Tri-logical IoT-fog-cloud (TIFC) model to collect AES data for monitoring, and controlling the outbreak over the Spatio-temporal manner. Different events are correlated over the Spatio-temporal patterns in the form of a time-series granule at a different timestamps. Fuzzy C-Means (FCM) classifier is used to analyze the category of a patient based on health-related data parameters. Henceforth, for effective health-oriented decision-making and information deliverance to the user, a prediction model based on Spatio-temporal is used to manage the medical resources. For validation purposes, numerous simulations have been performed over real-data sets, and the results are compared with different state-of-the-art prediction models. Based on simulations, it can be concluded that the proposed system has outperformed other decision models in terms of statistical parameters including accuracy, f-measure, and reliability. Future research needs to focus on the security aspect for prevention and control for infectious viruses.},
  archive      = {J_CC},
  author       = {Bhatia, Munish and Kumari, Sapna},
  doi          = {10.1007/s12559-021-09856-3},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1609-1626},
  shortjournal = {Cogn. Comput.},
  title        = {A novel IoT-fog-cloud-based healthcare system for monitoring and preventing encephalitis},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic detection of melanins and sebums from skin images
using a generative adversarial network. <em>CC</em>, <em>14</em>(5),
1599–1608. (<a
href="https://doi.org/10.1007/s12559-021-09870-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Melanins and sebums are two important criteria for the quality evaluation of skin, and they are capable of providing customized suggestions for skin care. Currently, their detection is heavily relied on manual process performed by specialists in laboratory. Although efficient, such a manual detection is an expensive and labor-intensive procedure, and hence, there has been great interest in developing computational models for automatic detection of melanins and sebums from skin images. In this work, we propose an automatic detection algorithm, namely DAME, to identify these two kinds of substances based on a generative adversarial network (GAN). To do so, DAME makes use of a variant of GAN, i.e., pix2pix, due to its strength in image generation by learning the structural and contextual information of melanins and sebums observed from skin images. With these additional augmented images, a robust U-Net model can be learned for automatically detecting and marking melanins and sebums. To evaluate the performance of DAME, we have conducted a series of experiments by comparing it with several existing algorithms on real image datasets, and the results have demonstrated that DAME yields a substantially better detection accuracy than previously published algorithms in terms of several independent evaluation metrics. Moreover, DAME is believed to be more robust than other algorithms, as it obtains the smallest variance for each metric. Hence, DAME makes it possible to automatically detect melanins and sebums with a promising performance. Due to the strong learning ability of GAN, DAME is also able to identify melanins and sebums that are possibly ignored by specialists. The source codes of DAME and datasets used in the experiments are available at https://github.com/reBioco-der/DAME .},
  archive      = {J_CC},
  author       = {Hu, Lun and Chen, Qiang and Qiao, Liyuan and Du, Le and Ye, Rui},
  doi          = {10.1007/s12559-021-09870-5},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1599-1608},
  shortjournal = {Cogn. Comput.},
  title        = {Automatic detection of melanins and sebums from skin images using a generative adversarial network},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). What you say or how you say it? Depression detection through
joint modeling of linguistic and acoustic aspects of speech.
<em>CC</em>, <em>14</em>(5), 1585–1598. (<a
href="https://doi.org/10.1007/s12559-020-09808-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression is one of the most common mental health issues. (It affects more than 4% of the world’s population, according to recent estimates.) This article shows that the joint analysis of linguistic and acoustic aspects of speech allows one to discriminate between depressed and nondepressed speakers with an accuracy above 80%. The approach used in the work is based on networks designed for sequence modeling (bidirectional Long-Short Term Memory networks) and multimodal analysis methodologies (late fusion, joint representation and gated multimodal units). The experiments were performed over a corpus of 59 interviews (roughly 4 hours of material) involving 29 individuals diagnosed with depression and 30 control participants. In addition to an accuracy of 80%, the results show that multimodal approaches perform better than unimodal ones owing to people’s tendency to manifest their condition through one modality only, a source of diversity across unimodal approaches. In addition, the experiments show that it is possible to measure the “confidence” of the approach and automatically identify a subset of the test data in which the performance is above a predefined threshold. It is possible to effectively detect depression by using unobtrusive and inexpensive technologies based on the automatic analysis of speech and language.},
  archive      = {J_CC},
  author       = {Aloshban, Nujud and Esposito, Anna and Vinciarelli, Alessandro},
  doi          = {10.1007/s12559-020-09808-3},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1585-1598},
  shortjournal = {Cogn. Comput.},
  title        = {What you say or how you say it? depression detection through joint modeling of linguistic and acoustic aspects of speech},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cascade regression-based face frontalization for dynamic
facial expression analysis. <em>CC</em>, <em>14</em>(5), 1571–1584. (<a
href="https://doi.org/10.1007/s12559-021-09843-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition has seen rapid development in recent years due to its wide range of applications such as human–computer interaction, health care, and social robots. Although significant progress has been made in this field, it is still challenging to recognize facial expressions with occlusions and large head-poses. To address these issues, this paper presents a cascade regression-based face frontalization (CRFF) method, which aims to immediately reconstruct a clean, frontal and expression-aware face given an in-the-wild facial image. In the first stage, a frontal facial shape is predicted by developing a cascade regression model to learn the pairwise spatial relation between non-frontal face-shape and its frontal counterpart. Unlike most existing shape prediction methods that used single-step regression, the cascade model is a multi-step regressor that gradually aligns non-frontal shape to its frontal view. We employ several different regressors and make a ensemble decision to boost prediction performance. For facial texture reconstruction, active appearance model instantiation is employed to warp the input face to the predicted frontal shape and generate a clean face. To remove occlusions, we train this generative model on manually selected clean-face sets, which ensures generating a clean face as output regardless of whether the input face involves occlusions or not. Unlike the existing face reconstruction methods that are computational expensive, the proposed method works in real time, so it is suitable for dynamic analysis of facial expression. The experimental validation shows that the ensembling cascade model has improved frontal shape prediction accuracy for an average of 5% and the proposed method has achieved superior performance on both static and dynamic recognition of facial expressions over the state-of-the-art approaches. The experimental results demonstrate that the proposed method has achieved expression-preserving frontalization, de-occlusion and has improved performance of facial expression recognition.},
  archive      = {J_CC},
  author       = {Wang, Yiming and Dong, Xinghui and Li, Gongfa and Dong, Junyu and Yu, Hui},
  doi          = {10.1007/s12559-021-09843-8},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1571-1584},
  shortjournal = {Cogn. Comput.},
  title        = {Cascade regression-based face frontalization for dynamic facial expression analysis},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TraMiner: Vision-based analysis of locomotion traces for
cognitive assessment in smart-homes. <em>CC</em>, <em>14</em>(5),
1549–1570. (<a
href="https://doi.org/10.1007/s12559-020-09816-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid increase in the senior population is posing serious challenges to national healthcare systems. Hence, innovative tools are needed to early detect health issues, including cognitive decline. Several clinical studies show that it is possible to identify cognitive impairment based on the locomotion patterns of the elderly. In this work, we investigate the use of sensor data and deep learning to recognize those patterns in instrumented smart-homes. In order to get rid of the noise introduced by indoor constraints and activity execution, we introduce novel visual feature extraction methods for locomotion data. Our solution relies on locomotion trace segmentation, image-based extraction of salient features from locomotion segments, and vision-based deep learning. We carried out extensive experiments with a large dataset acquired in a smart-home test bed from 153 seniors, including people with cognitive diseases. Results show that our system can accurately recognize the cognitive status of the senior, reaching a macro- $$F_1$$ score of 0.873 for the three categories that we target: cognitive health, mild cognitive impairment, and dementia. Moreover, an experimental comparison shows that our system outperforms state-of-the-art methods.},
  archive      = {J_CC},
  author       = {Zolfaghari, Samaneh and Khodabandehloo, Elham and Riboni, Daniele},
  doi          = {10.1007/s12559-020-09816-3},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1549-1570},
  shortjournal = {Cogn. Comput.},
  title        = {TraMiner: Vision-based analysis of locomotion traces for cognitive assessment in smart-homes},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Clustering ensemble based on sample’s
certainty. <em>CC</em>, <em>14</em>(4), 1548. (<a
href="https://doi.org/10.1007/s12559-021-09957-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Ji, Xia and Liu, Shuaishuai and Zhao, Peng and Li, Xuejun and Liu, Qiong},
  doi          = {10.1007/s12559-021-09957-z},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1548},
  shortjournal = {Cogn. Comput.},
  title        = {Correction to: Clustering ensemble based on sample’s certainty},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Testing an explicit method for
multi‑compartment neuron model simulation on a GPU. <em>CC</em>,
<em>14</em>(4), 1547. (<a
href="https://doi.org/10.1007/s12559-022-10005-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Kobayashi, Taira and Kuriyama, Rin and Yamazaki, Tadashi},
  doi          = {10.1007/s12559-022-10005-7},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1547},
  shortjournal = {Cogn. Comput.},
  title        = {Correction to: Testing an explicit method for multi‑compartment neuron model simulation on a GPU},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mine microseismic time series data integrated classification
based on improved wavelet decomposition and ELM. <em>CC</em>,
<em>14</em>(4), 1526–1546. (<a
href="https://doi.org/10.1007/s12559-022-09997-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coal mine accidents induced by large energy microseisms are frequent and common. Classification of mine microseismic events is an important part of accident treatment and post-disaster recovery production. With the wide application of microseismic monitoring systems, they always generate a large number of microseismic monitoring time series data. Because of microseismic time series, data usually contain a large amount of random environmental noises, and different types of microseismic events have greatly different influences on mining work. So that, to effectively classify microseismic time series data is a key and difficult problem. Aiming at these characters of microseismic data, existing classification methods still have some problems, such as low noise reduction efficiency, low classification accuracy, and poor stability. In terms of these questions, this paper proposes an integrated classification model wavelet dynamic particle swarm optimization random technology extreme learning machine, named WA-DPSO-RTELM. In view of wavelet threshold functions defect with discontinuity and error, firstly, this paper proposes an improved wavelet threshold denoising method and realizes the effective denoising of data and proposes a PSO algorithm with dynamic adjustment factor to realize adaptive denoising. Secondly, this paper proposes a weighted integrate classification method to classify data. In terms of randomness of ELM parameters and uncertainly of the number of ELM hidden nodes leading to the poor classification performance, this paper proposes an ELM’s weight construction method and uses improved ELM-based classifiers to make up for the differences between classifiers and makes the classification results more stable. Finally, in terms of experimental results, the effectiveness of denoising method and integrated classification method is verified by experimental tests. First, in terms of denoising, the proposed method is compared with EMD, Kalman filtering, and DF-CNN methods, and the signal-to-noise ratio (SNR) and mean square deviation (MSE) are improved by about 1.04 and 0.16 on average. Second, it is compared with other advanced methods in classification, and the accuracy and recall are improved by about 1.36 and 1.15 on average. Effective classification of microseismic time series data is becoming more and more important in people’s daily life. This paper combines the advantages of wavelet denoising method and improves threshold function to realize adaptive wavelet coefficients to effectively remove the noise and uses the weighted integrated classification method of microseismic time series data based on ELM to realize the effective classification of time series data. Experimental results show that the proposed WA-DPSO-RTELM model has better classification performance for microseismic time series data set and UCR time series data set compared with state-of-the-art methods. In the future, we will combine the distributed processing framework to process microseismic data and carry out experimental verification in the distributed environment and continue to explore more types of microseismic events that will become a research trend.},
  archive      = {J_CC},
  author       = {Ding, Linlin and Chen, Ze and Pan, Yishan and Song, Baoyan},
  doi          = {10.1007/s12559-022-09997-z},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1526-1546},
  shortjournal = {Cogn. Comput.},
  title        = {Mine microseismic time series data integrated classification based on improved wavelet decomposition and ELM},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reconstruction of 3D images from human activity by a
compound reconstruction model. <em>CC</em>, <em>14</em>(4), 1509–1525.
(<a href="https://doi.org/10.1007/s12559-022-09992-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing visual stimuli from brain activity measured by functional magnetic resonance imaging (fMRI) is challenging for fMRI-based decoding. Some previous studies reconstructed 2D visual stimuli by using a voxel-wise encoding model and decoding model. Because nonlinear feature mappings were used in most previous studies, complicated nonlinear decoding methods, such as Bayesian model or deep learning methods, were needed to reconstruct 2D images and could increase the computation complexity and time cost. Although our previous study proposed contrast-disparity local decoding model to reconstruct 3D images from brain activity, the time cost of local decoding models increased with the size of images. In this study, we proposed a novel fast compound reconstruction model that combined the linear encoding–decoding model and the disparity decoding model to reconstruct 3D visual images from the fMRI responses. The results demonstrated that the linear encoding–decoding model successfully reconstructed the 2D contrasts of 3D images from the early visual regions while it failed to reconstruct 3D images directly. The proposed compound reconstruction model successfully reconstructed 3D images by combining the reconstructed 2D contrasts from the early visual region (V1) and the decoded disparities from the dorsal visual region (V3A and V7). In contrast to the contrast-disparity local decoding model, the compound reconstruction model showed significantly better reconstruction performance and much faster training speed. The successful reconstruction of the compound reconstruction model possibly suggested that the contrasts and disparity were firstly processed in two different visual pathways (early and dorsal) separately and the two pathways finally worked together to represent 3D images.},
  archive      = {J_CC},
  author       = {Zheng, Hongna and Yao, Li and Long, Zhiying},
  doi          = {10.1007/s12559-022-09992-4},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1509-1525},
  shortjournal = {Cogn. Comput.},
  title        = {Reconstruction of 3D images from human activity by a compound reconstruction model},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual-LiDAR SLAM based on unsupervised multi-channel deep
neural networks. <em>CC</em>, <em>14</em>(4), 1496–1508. (<a
href="https://doi.org/10.1007/s12559-022-10010-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning techniques have been applied to solve visual or light detection and ranging (LiDAR) simultaneous localization and mapping (SLAM) problems. Supervised deep learning SLAM methods need ground truth data for training, but collecting such data is costly and labour-intensive. Unsupervised training strategies have been adopted by some visual or LiDAR SLAM methods. However, these methods only exploit the potential of single-sensor modalities, which do not take the complementary advantages of LiDAR and visual data. In this paper, we propose a novel unsupervised multi-channel visual-LiDAR SLAM method (MVL-SLAM) which can fuse visual and LiDAR data together. Our SLAM system consists of an unsupervised multi-channel visual-LiDAR odometry (MVLO) component, a deep learning–based loop closure detection component, and a 3D mapping component. The visual-LiDAR odometry component adopts a multi-channel recurrent convolutional neural network (RCNN). Its input consists of front, left, and right view depth images generated from $$360^{\circ }$$ 3D LiDAR data and RGB images. We use the features from a deep convolutional neural network (CNN) for the loop closure detection component. Our SLAM method does not require ground truth data for training and can directly construct environmental 3D maps from the 3D mapping component. Experiments conducted on the KITTI odometry dataset have shown the rotation and translation errors are lower than some of the other unsupervised methods, including UnMono, SfmLearner, DeepSLAM, and UnDeepVO. Experimental results show that our methods have good performance. By fusing visual and LiDAR data, MVL-SLAM has higher accuracy and robustness of the pose estimation compared with other single-modal SLAM systems.},
  archive      = {J_CC},
  author       = {An, Yi and Shi, Jin and Gu, Dongbing and Liu, Qiang},
  doi          = {10.1007/s12559-022-10010-w},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1496-1508},
  shortjournal = {Cogn. Comput.},
  title        = {Visual-LiDAR SLAM based on unsupervised multi-channel deep neural networks},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Course recommendation based on sequences: An evolutionary
search of emerging sequential patterns. <em>CC</em>, <em>14</em>(4),
1474–1495. (<a
href="https://doi.org/10.1007/s12559-022-10015-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To provide a good study plan is key to avoid students’ failure. Academic advising based on student’s preferences, complexity of the semester, or even background knowledge is usually considered to reduce the dropout rate. This article aims to provide a good course index to recommend courses to students based on the sequence of courses already taken by each student. Hence, unlike existing long-term course planning methods, it is based on graduate students to model the course and not on external factors that might introduce some bias in the process. The proposal includes a novel sequential pattern mining algorithm, called (ES) $$^2$$ P (Evolutionary Search of Emerging Sequential Patterns), that properly identifies paths followed by good students and not followed by not so good students, as a long-term course planning approach. A major feature of the proposed (ES) $$^2$$ P algorithm is its ability to extract the best k solutions, that is, those with a best recommendation index score instead of returning the whole set of solutions above a predefined threshold. A real study case is performed including more than 13,000 students belonging to 13 faculties to demonstrate the usefulness of the proposal not only to recommend study plans but also to give advices at different stages of the students’ learning process.},
  archive      = {J_CC},
  author       = {Al-Twijri, Mohammed Ibrahim and Luna, José María and Herrera, Francisco and Ventura, Sebastián},
  doi          = {10.1007/s12559-022-10015-5},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1474-1495},
  shortjournal = {Cogn. Comput.},
  title        = {Course recommendation based on sequences: An evolutionary search of emerging sequential patterns},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Text classification with attention gated graph neural
network. <em>CC</em>, <em>14</em>(4), 1464–1473. (<a
href="https://doi.org/10.1007/s12559-022-10017-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification is a fundamental and important task in natural language processing. There have been many graph-based neural networks for this task with the capacity of learning complicated relational information between word nodes. However, existing approaches are potentially insufficient in capturing semantic relationships between the words. In this paper, to address the above issue, we propose a novel graph-based model where every document is represented as a text graph. Specifically, we devise an attention gated graph neural network (AGGNN) to propagate and update the semantic information of each word node from their 1-hop neighbors. Keyword nodes with discriminative semantic information are extracted via our proposed attention-based text pooling layer (TextPool), which also aggregates the document embedding. In this case, text classification is transformed into a graph classification task. Extensive experiments on four benchmark datasets demonstrate that the proposed model outperforms other previous text classification approaches.},
  archive      = {J_CC},
  author       = {Deng, Zhaoyang and Sun, Chenxiang and Zhong, Guoqiang and Mao, Yuxu},
  doi          = {10.1007/s12559-022-10017-3},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1464-1473},
  shortjournal = {Cogn. Comput.},
  title        = {Text classification with attention gated graph neural network},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Extended picture fuzzy MULTIMOORA method based on prospect
theory for medical institution selection. <em>CC</em>, <em>14</em>(4),
1446–1463. (<a
href="https://doi.org/10.1007/s12559-022-10006-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picture fuzzy numbers (PFNs) with three degrees of memberships can be used to accurately describe the uncertainty of cognitive information. However, picture fuzzy multi-criteria decision-making (MCDM) methods need to be further studied. This paper describes an extended picture fuzzy multi-objective optimization by ratio analysis and a full multiplicative form (MULTIMOORA) method based on the prospect theory (PT) to handle MCDM. By adopting this process, decision-makers (DMs) can provide fuzzy linguistic terms to evaluate relevant criteria. The evaluation information can be transformed into PFNs based on transformation scales. Then, the corresponding weights of criteria can be calculated according to picture fuzzy entropy. Moreover, the PT, which is considered an important tool for describing the psychological cognition of DMs, can be used to obtain a prospect decision matrix. Here, the MULTIMOORA method, which involves the simultaneous application of the picture fuzzy ratio system, the picture fuzzy reference point, and the picture fuzzy multiplicative form methods, was utilized to determine the final rankings of candidate alternatives. We hence propose an extended picture fuzzy MULTIMOORA method based on the PT, the MULTIMOORA method, and picture fuzzy Dice distance measures, which can be applied to MCDM problems where weight information is completely unknown. The feasibility and validity of the proposed method were verified by applying it to medical institution selection. Sensitivity and comparative analyses demonstrated the superiority of this method compared to the existing ones.},
  archive      = {J_CC},
  author       = {Tian, Chao and Peng, Juan-juan and Long, Qing-qi and Wang, Jian-qiang and Goh, Mark},
  doi          = {10.1007/s12559-022-10006-6},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1446-1463},
  shortjournal = {Cogn. Comput.},
  title        = {Extended picture fuzzy MULTIMOORA method based on prospect theory for medical institution selection},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MVVA-net: A video aesthetic quality assessment network with
cognitive fusion of multi-type feature–based strong generalization.
<em>CC</em>, <em>14</em>(4), 1435–1445. (<a
href="https://doi.org/10.1007/s12559-021-09947-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of short videos on various social media platforms, there is a great challenge for evaluating the aesthetic quality of these videos. In this paper, we first construct a large-scale and properly annotated short video aesthetics (SVA) dataset. We further propose a cognitive multi-type feature fusion network (MVVA-Net) for video aesthetic quality assessment. MVVA-Net consists of two branches: intra-frame aesthetics branch and inter-frame aesthetics branch. These two branches take different types of video frames as input. The inter-frame aesthetic branch extracts the inter-frame aesthetic features based on the sequential frames extracted at fixed intervals, and the intra-frame aesthetic branch extracts the intra-frame aesthetic features based on the key frames extracted by the inter-frame difference method. Through the adaptive fusion of inter-frame aesthetic features and intra-frame aesthetic features, the video aesthetic quality can be effectively evaluated. At the same time, MVVA-Net has no fixed number of input frames, which greatly enhances the generalization ability of the model. We performed quantitative comparison and ablation studies. The experimental results show that the two branches of MVVA-Net can effectively extract the intra-frame aesthetic features and inter-frame aesthetic features of different videos. Through the adaptive fusion of intra-frame aesthetic features and inter-frame aesthetic features for video aesthetic quality assessment, MVVA-Net achieves better classification performance and stronger generalization ability than other methods. In this paper, we construct a dataset of 6900 video shots and propose a video aesthetic quality assessment method based on non-fixed model input strategy and multi-type features. Experimental results show that the model has a strong generalization ability and achieved a good performance on different datasets.},
  archive      = {J_CC},
  author       = {Li, Min and Wang, Zheng and Ren, Jinchang and Sun, Meijun},
  doi          = {10.1007/s12559-021-09947-1},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1435-1445},
  shortjournal = {Cogn. Comput.},
  title        = {MVVA-net: A video aesthetic quality assessment network with cognitive fusion of multi-type Feature–Based strong generalization},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bio-inspired multi-sensory pathway network for change
detection. <em>CC</em>, <em>14</em>(4), 1421–1434. (<a
href="https://doi.org/10.1007/s12559-021-09968-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change detection is a significantly important task in the field of remote sensing and can be widely used in the urban construction planning, disaster survey, resource management, etc. Previous studies have shown that most of the state-of-the-art change detection methods are based on the deep learning networks. However, the problem of change detection still cannot be effectively solved due to the variations in illumination, resolution, quality, scale, location, etc. The robust methods for change detection need to be further investigated. This study aimed to address the insufficient robustness problem of the change detection between the multi-temporal images. The biological mechanism of parallel processing architecture in visual pathways gives us an inspiration to design a sensory framework with multi-sensory pathways. We propose a new framework named multi-sensory pathway network (MSPN). This framework is inspired by the parallel processing mechanism of the human visual information. Specifically, the framework utilizes three diverse but related sensory pathways: sensory pathway-1, sensory pathway-2, and sensory pathway-3. The three sensory pathways of the proposed framework are not simply parallel processing, but with some related connections. The sensory pathway-1 adopts the early fusion strategy to learn the changed information. The sensory pathway-2 uses the middle concatenation strategy to learn the changed information, while the sensory pathway-3 utilizes the middle difference strategy to learn the change information. Two fusion strategies, namely average fusion and maximum fusion, are designed for the framework. The experimental datasets consists of BCDD, LEVIR-CD, and CDD. Four metrics including overall accuracy (OA), precision, recall, and F1 are used to evaluate the competitive algorithms. The primary metric is F1. The proposed method, respectively, achieves the best F1 scores with 84.55%, 88.14%, and 85.11% on the three experimental datasets. The quantitative ablation results show the effectiveness of multi-sensory pathways on the BCDD, LEVIR-CD, and CDD. The qualitative ablation results demonstrate that different sensory pathways perform different perception mechanisms, though they belong to the united framework. The comprehensive results of MSPN-AF on the BCDD and MSPN-MF on the LEVIR-CD and CDD are superior to other methods. The experimental results demonstrate the effectiveness and robustness of the proposed method, both qualitatively and quantitatively. The proposed MSPN can promote the technology exploration of the bionic and explainable neural network.},
  archive      = {J_CC},
  author       = {Liu, Kang and Li, Xuelong},
  doi          = {10.1007/s12559-021-09968-w},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1421-1434},
  shortjournal = {Cogn. Comput.},
  title        = {Bio-inspired multi-sensory pathway network for change detection},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Understanding laughter in dialog. <em>CC</em>,
<em>14</em>(4), 1405–1420. (<a
href="https://doi.org/10.1007/s12559-022-10013-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores laughter within a corpus of three-party, task-based dialogs with native and non-native speakers of English, each consisting of two players and a facilitator, in relation to whether the laughter is perceived as serving discourse functions or rather as genuinely mirthful according to a small number of annotators’ (2) inspection of a substantical multimodal dialog corpus (18 interactions of approximately 10 min each). We test the hypothesis that those different types of laughter have occurrence patterns that relate in different ways to the topical structure of the conversations, with discourse laughter showing a stronger tendency to occur at topic termination points. All laughter events (569) are assigned to one of three values, discourse, mirthful or ambiguous, and are studied with respect to their distribution across the dialog topic sections. The analysis explores interactions among laughter type and section type, also with respect to other variables such as the facilitators’ feedback and the speakers’ conversational role and gender. Discourse laughter is more frequent at topic termination points than at topic beginnings, also in comparison to mirthful laughter. Discourse laughter is also highly associated with facilitators’ feedback type, especially at topic ends. Finally, there are few distinctive effects of gender, and an interaction among speaker role and laughter type. The results strengthen the hypothesis of the discourse function of laughter, indicating a systematicity in discourse laughter, in that it is more predictable and highly associated with the dialog topic termination points, and, on the contrary, a less systematic distribution of mirthful laughter, which shows no particular pattern in relation to topic boundaries.},
  archive      = {J_CC},
  author       = {Koutsombogera, Maria and Vogel, Carl},
  doi          = {10.1007/s12559-022-10013-7},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1405-1420},
  shortjournal = {Cogn. Comput.},
  title        = {Understanding laughter in dialog},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning-based approach for the automatic
quantification of epicardial adipose tissue from non-contrast CT.
<em>CC</em>, <em>14</em>(4), 1392–1404. (<a
href="https://doi.org/10.1007/s12559-022-10036-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epicardial adipose tissue (EAT) is contiguous with arteries and myocardium. An increase in the volume of EAT may lead to adverse cardiovascular events. Therefore, quantification of EAT is necessary. The purpose of this paper is to employ a more than helpful algorithm for EAT segmentation and quantification. First, we used a simple convolutional neural network to select EAT slices, which significantly reduced oversegmentation. Then, we employed multiscale residual attention Unet (MRA-Unet) to achieve EAT segmentation based on the selected slices. Finally, we calculated the segmented volume to quantify EAT. We used 33/103 patients to test the model. The average Dice score for EAT segmentation was 0.883. For EAT quantification, the Pearson and concordance correlation coefficients reached 0.973 and 0.971, respectively. The results showed that our algorithm had strong agreement and consistency with expert. Our method performed efficient quantification and had strong consistency and agreement with the volume manually marked by experts. This algorithm can be used as a tool to assist in the clinical quantification of EAT. By combining different measurements to predict adverse cardiovascular and heart disease events, it has the potential to be applied for clinical use in the future.},
  archive      = {J_CC},
  author       = {Qu, Junda and Chang, Yuting and Sun, Liwei and Li, Yutang and Si, Qian and Yang, Min-Fu and Li, Chunlin and Zhang, Xu},
  doi          = {10.1007/s12559-022-10036-0},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1392-1404},
  shortjournal = {Cogn. Comput.},
  title        = {Deep learning-based approach for the automatic quantification of epicardial adipose tissue from non-contrast CT},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Imbalanced heart sound signal classification based on
two-stage trained DsaNet. <em>CC</em>, <em>14</em>(4), 1378–1391. (<a
href="https://doi.org/10.1007/s12559-022-10009-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many deaths are caused by heart disease. A phonocardiogram (PCG) reflects the general rule of heart movement, so the analysis of heart sound signals is particularly important. In this paper, we propose a new deep neural network termed DsaNet, which is mainly constructed by depthwise separable convolution and the attention module. DsaNet can directly classify PCG signals without complicated feature engineering processes. To address the long-tail distribution problem in the PCG dataset, we adopt a novel imbalanced learning approach (two-stage training) to train our DsaNet. Specifically, we propose a random cropping operation to increase the amount and diversity of the data in the training stage. We also combine random cropping with the idea of integration to improve test accuracy in the testing stage. Moreover, we study the effectiveness of several attention modules and data balancing methods for improving the performance of DsaNet. To verify the performance of DsaNet, we compare our proposed DsaNet with 7 different baseline models on the public 2016 PhysioNet/CinC Challenge dataset. The experimental results show that the proposed DsaNet can achieve competitive performance for imbalanced PCG signal classification with relatively few parameters and computations. Results obtained prove that our model is effective and efficient. In addition, two-stage training significantly improved the generalization performance of DsaNet.},
  archive      = {J_CC},
  author       = {Tian, Guangyang and Lian, Cheng and Zeng, Zhigang and Xu, Bingrong and Su, Yixin and Zang, Junbin and Zhang, Zhidong and Xue, Chenyang},
  doi          = {10.1007/s12559-022-10009-3},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1378-1391},
  shortjournal = {Cogn. Comput.},
  title        = {Imbalanced heart sound signal classification based on two-stage trained DsaNet},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MXT: A new variant of pyramid vision transformer for
multi-label chest x-ray image classification. <em>CC</em>,
<em>14</em>(4), 1362–1377. (<a
href="https://doi.org/10.1007/s12559-022-10032-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the global COVID-19 situation is still serious, and the new mutant virus Delta has already spread all over the world. The chest X-ray is one of the most common radiological examinations for screening catheters and diagnosis of many lung diseases, which plays an important role in assisting clinical diagnosis during the outbreak. This study considers the problem of multi-label catheters and thorax disease classification on chest X-ray images based on computer vision. Therefore, we propose a new variant of pyramid vision Transformer for multi-label chest X-ray image classification, named MXT, which can capture both short and long-range visual information through self-attention. Especially, downsampling spatial reduction attention can reduce the resource consumption of using Transformer. Meanwhile, multi-layer overlap patch (MLOP) embedding is used to tokenize images and dynamic position feed forward with zero paddings can encode position instead of adding a positional mask. Furthermore, class token Transformer block and multi-label attention (MLA) are utilized to offer more effective processing of multi-label classification. We evaluate our MXT on Chest X-ray14 dataset which has 14 disease pathologies and Catheter dataset containing 11 types of catheter placement. Each image is labeled one or more categories. Compared with some state-of-the-art baselines, our MXT can yield the highest mean AUC score of 83.0% on the Chest X-ray14 dataset and 94.6% on the Catheter dataset. According to the ablation study, we can obtain the following results: (1) The proposed MLOP embedding has a better performance than overlap patch (OP) embedding layer and non-overlap patch (N-OP) embedding layer that the mean AUC score is improved 0.6% and 0.4%, respectively. (2) Our demonstrate dynamic position feed forward can replace the traditional position mask which can learn the position information, and the mean AUC increased by 0.6%. (3) The mean AUC score by the designed MLA is more 0.2% and 0.6% than using the class token and calculating the mean scores of all tokens. The comprehensive experiments on two datasets demonstrate the effectiveness of the proposed method for multi-label chest X-ray image classification. Hence, our MXT can assist radiologists in diagnoses of lung diseases and check the placement of catheters, which can reduce the work pressure of medical staff.},
  archive      = {J_CC},
  author       = {Jiang, Xiaoben and Zhu, Yu and Cai, Gan and Zheng, Bingbing and Yang, Dawei},
  doi          = {10.1007/s12559-022-10032-4},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1362-1377},
  shortjournal = {Cogn. Comput.},
  title        = {MXT: A new variant of pyramid vision transformer for multi-label chest X-ray image classification},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel fuzzy distance-based minimum spanning tree
clustering algorithm for face detection. <em>CC</em>, <em>14</em>(4),
1350–1361. (<a
href="https://doi.org/10.1007/s12559-022-10002-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving a clustering algorithm can usually be simplified into an optimization problem. Using relevant knowledge in graph theory, many optimization problems can be transformed into solving minimum spanning tree problems. Minimal spanning trees are also widely used in areas closely related to cognitive computing such as for face recognition by face cognition and gene data analysis by gene cognition. However, the minimum spanning tree has the shortcoming of the distance between neighbours because of which the minimum spanning tree algorithm cannot cluster unbalanced data. Thus, the face recognition rate is low, and facial expression cognition is difficult. In this paper, a minimum spanning tree algorithm based on fuzzy distance is proposed for the shortcomings of the minimum spanning tree (FCP). First, a relative neighbourhood distance measure is proposed by introducing neighbourhood rough set theory; the neighbourhood matrix is obtained based on the distance. Second, the minimum spanning tree is solved by the prim algorithm and the neighbourhood matrix. Finally, the minimum spanning tree is partitioned to realize clustering of the minimum spanning tree. In this paper, the UCI dataset and Olivetti face database are selected to verify the performance of the algorithm, and the algorithm is evaluated by three evaluation criteria. The experimental results show that the proposed algorithm can not only cluster data of any shape but also deal with unbalanced data containing noise points. Especially in face cognitive computing, the values of ACC, AMI, and ARI can reach 0.852, 0.843, and 0.782, respectively. In this study, the algorithm can obtain very good clustering results for data with good geometric structure, and the overall performance is better than other algorithms. In face recognition detection, the improved cognitive computing of faces makes it possible to accurately recognize different expressions from the same person.},
  archive      = {J_CC},
  author       = {Li, Yang and Zhou, Wenju},
  doi          = {10.1007/s12559-022-10002-w},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1350-1361},
  shortjournal = {Cogn. Comput.},
  title        = {A novel fuzzy distance-based minimum spanning tree clustering algorithm for face detection},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Concept formation and quantum-like probability from
nonlocality in cognition. <em>CC</em>, <em>14</em>(4), 1328–1349. (<a
href="https://doi.org/10.1007/s12559-022-09995-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human decision-making is relevant for concept formation and cognitive illusions. Cognitive illusions can be explained by quantum probability, while the reason for introducing quantum mechanics is based on ad hoc bounded rationality (BR). Concept formation can be explained in a set-theoretic way, although such explanations have not been extended to cognitive illusions. We naturally expand the idea of BR to incomplete BR and introduce the key notion of nonlocality in cognition without any attempts on quantum theory. We define incomplete bounded rationality and nonlocality as a binary relation, construct a lattice from the relation by using a rough-set technique, and define probability in concept formation. By using probability defined in concept formation, we describe various cognitive illusions, such as the guppy effect, conjunction fallacy, order effect, and so on. It implies that cognitive illusions can be explained by changes in the probability space relevant to concept formation.},
  archive      = {J_CC},
  author       = {Gunji, Yukio-Pegio and Haruna, Taichi},
  doi          = {10.1007/s12559-022-09995-1},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1328-1349},
  shortjournal = {Cogn. Comput.},
  title        = {Concept formation and quantum-like probability from nonlocality in cognition},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generator-based domain adaptation method with knowledge free
for cross-subject EEG emotion recognition. <em>CC</em>, <em>14</em>(4),
1316–1327. (<a
href="https://doi.org/10.1007/s12559-022-10016-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing approaches for cross-subject electroencephalogram (EEG) emotion recognition learn the universal features between different subjects with the neurological findings. The performance of these methods may be sub-optimal due to the inadequate investigation of the relationships between the brain and the emotion. Hence, in case of insufficient neurological findings, it is essential to develop a domain adaptation method for EEG data. In this paper, we propose a generator-based domain adaptation method with knowledge free (GDAKF) mechanism for the cross-subject EEG emotion recognition. Specifically, the feature distribution of the source domain is transformed into a feature distribution of the target domain via adversarial learning between the generator and the discriminator. Additionally, the transformation process is constrained by the EEG content regression loss and emotion information loss to maintain the emotional information during the feature alignment. To evaluate the effectiveness and performance of GDAKF, many experiments are carried out on the benchmark dataset, DEAP. The experimental result shows that GDAKF achieves excellent performance with 63.85% mean accuracy in low/high valence, which shows that the proposed method is comparable to the EEG cross-subject emotion recognition methods in the literature. This paper provides a novel idea for addressing cross-subject EEG emotion recognition, and it can also be applied to cross-session and cross-device emotion recognition tasks.},
  archive      = {J_CC},
  author       = {Huang, Dongmin and Zhou, Sijin and Jiang, Dazhi},
  doi          = {10.1007/s12559-022-10016-4},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1316-1327},
  shortjournal = {Cogn. Comput.},
  title        = {Generator-based domain adaptation method with knowledge free for cross-subject EEG emotion recognition},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid high-order brain functional networks for
schizophrenia-aided diagnosis. <em>CC</em>, <em>14</em>(4), 1303–1315.
(<a href="https://doi.org/10.1007/s12559-022-10014-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram technology provides a reference for the study of schizophrenia. Constructing brain functional networks using electroencephalogram technology is one of the important methods to analyze the human brain. Current methods to construct brain functional networks often ignore the deeper interactions between brain regions and the phenomenons that the connectivity patterns of brain change over time. Therefore, for the aided diagnosis of schizophrenia, a hybrid high-order brain functional network model is proposed, the model characterizing more complex functional interactions of brain includes static low-order multilayer brain functional networks and dynamic high-order multilayer brain functional networks. The results show that the classification method based on the proposed model is effective and efficient, with an accuracy of 94.05%, a sensitivity of 95.56% and a specificity of 92.31%. Experimental results on the schizophrenia dataset show that the proposed method has satisfied performances; the complementarity between low-order and high-order multilayer brain functional networks could better capture brain functional interactions. The findings which suggest the importance of improved relationships between brain regions and temporal features of connectivities in the brain bring new biologically inspired implications.},
  archive      = {J_CC},
  author       = {Xin, Junchang and Zhou, Keqi and Wang, Zhongyang and Wang, Zhiqiong and Chen, Jinyi and Wang, Xinlei and Chen, Qi},
  doi          = {10.1007/s12559-022-10014-6},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1303-1315},
  shortjournal = {Cogn. Comput.},
  title        = {Hybrid high-order brain functional networks for schizophrenia-aided diagnosis},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FF-UNet: A u-shaped deep convolutional neural network for
multimodal biomedical image segmentation. <em>CC</em>, <em>14</em>(4),
1287–1302. (<a
href="https://doi.org/10.1007/s12559-022-10038-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic multimodal image segmentation is considered a challenging research area in the biomedical field. U-shaped models have led to an enormous breakthrough in a large domain of medical image segmentation in recentyears. The receptive field plays an essential role in convolutionalneural networks because too small a receptive field limits context information, and too large loses localization accuracy. Despite outstanding overall performance in biomedical segmenting, classical UNet architecture uses a fixed receptive field in convolutions operations. This study proposes a few modifications in classical UNet architecture by adjusting the receptive field via feature-fused module and attention gate mechanism. Compared with baseline UNet, the numerical parameters of FF-UNet (3.94 million) is 51% of classical UNet architecture (7.75 million). Furthermore, we extended our model performance by introducing post-processing schemes. The tri-threshold fuzzy intensification-based contrast enhancement technique is utilized to improve the contrast of biomedical datasets. In the second tier, the black top-hat filtering-based method is employed to remove hair-like artifacts from the ISIC 2018 skin lesion dataset, which may create a barrier to correctly segmenting the images. The proposed models have been trained using fivefold cross-validation on five publicly available biomedical datasets and achieved the dice coefficients of 0.860, 0.932, 0.932, 0.925, and 0.894 on ETIS-LaribPolypDB, CVC-ColonDB, CVC-ClinicDB, DSB 2018, and ISIC 2018 datasets, respectively. To further verify our claims, comparative analysis based on dice results is conducted, proving the proposed model effectiveness. The FF-UNet implementation models and pre-trained weights are freely publicly available: https://github.com/ahmedeqbal/FF-UNet .},
  archive      = {J_CC},
  author       = {Iqbal, Ahmed and Sharif, Muhammad and Khan, Muhammad Attique and Nisar, Wasif and Alhaisoni, Majed},
  doi          = {10.1007/s12559-022-10038-y},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1287-1302},
  shortjournal = {Cogn. Comput.},
  title        = {FF-UNet: A U-shaped deep convolutional neural network for multimodal biomedical image segmentation},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). QAOVDetect: A novel syllogistic model with quantized and
anchor optimized approach to assist visually impaired for animal
detection using 3D vision. <em>CC</em>, <em>14</em>(4), 1269–1286. (<a
href="https://doi.org/10.1007/s12559-022-10020-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In developing countries, stray animals can be frequently encountered on the roads, pathways, campuses, and other places. Due to this, the visually impaired (VI) are at more risk than the sighted ones. To gain more security and safety, they need a solution to deal with their problem. This experimentation aims to develop a hardware–software integrated solution that can detect stray animals. Along with the detection, the solution should also provide the distance of those objects from the user and alert them if it is getting closer. To put this experiment together, Jetson NANO and ZED mini camera have been chosen for processing and image capturing to make the solution mobile and accurate as they are leading hardware devices. A novel approach involving quantization and anchor-optimization has been proposed using Single-Shot Detector (SSD) Resnet 50 FPN as the base model. The model has been compressed by quantization to reduce the inference time, and anchor optimization has been done to compensate for the accuracy loss faced during quantization. We have performed experimentation by training the original model, anchor-optimized model, and quantization plus anchor-optimized model using batch sizes 64 and 8. This experimentation has been done to understand the effect of anchor-optimization and quantization on the base model and the effect of the batch size used for training on different model versions. The performance of all the models with applied quantization and anchor-optimization for both batch sizes 64 and 8 has been noted in mAP. The mAP of the quantized plus anchor-optimized model trained using batch size 64 was the highest, i.e. 93.5%. It can also be concluded that we can achieve the light-weight model with the best performance by balancing quantization and anchor-optimization to make it suitable for an edge device using batch size 64.},
  archive      = {J_CC},
  author       = {Manjari, Kanak and Verma, Madhushi and Singal, Gaurav and Kumar, Neeraj},
  doi          = {10.1007/s12559-022-10020-8},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1269-1286},
  shortjournal = {Cogn. Comput.},
  title        = {QAOVDetect: A novel syllogistic model with quantized and anchor optimized approach to assist visually impaired for animal detection using 3D vision},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient deep neural networks for classification of
alzheimer’s disease and mild cognitive impairment from scalp EEG
recordings. <em>CC</em>, <em>14</em>(4), 1247–1268. (<a
href="https://doi.org/10.1007/s12559-022-10033-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The early diagnosis of subjects with mild cognitive impairment (MCI) is an effective appliance of prognosis of Alzheimer’s disease (AD). Electroencephalogram (EEG) has many advantages compared to other methods in the analysis of AD in an early stage. In this paper, two different deep learning (DL) architectures, including modified convolutional (CNN) and convolutional autoencoder (Conv-AE) neural networks (NNs), are proposed for classifying subjects into AD, mild cognitive impairment (MCI), and healthy control (HC) data based on scalp EEG recordings. The database includes 19-channel EEG recorded from 61 healthy control, 56 MCI, and 63 AD subjects. Time–frequency representation (TFR) is used to extract desirable features from EEG signals. Continuous wavelet transform (CWT) with Mexican hat function (MHf) as its mother wavelet is used for the selected TFR. The average accuracy obtained for the modified convolutional network and the convolutional auto-encoder network are 92% and 89%, respectively. The proposed networks in this study have superiority over those in similar studies not only by providing 10% increase in classification accuracy but also by improving the number of classes for similar data. In addition, the obtained accuracy of our networks was significantly higher than that of conventional machine learning methods. We believe the results illustrate DL architectures to be a good tool to handle EEG analysis, because of the ability to deal directly with inaccurate, inconsistent, and Para complete data, thereby providing a practical analysis.},
  archive      = {J_CC},
  author       = {Fouladi, Saman and Safaei, Ali A. and Mammone, Nadia and Ghaderi, Foad and Ebadi, M. J.},
  doi          = {10.1007/s12559-022-10033-3},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1247-1268},
  shortjournal = {Cogn. Comput.},
  title        = {Efficient deep neural networks for classification of alzheimer’s disease and mild cognitive impairment from scalp EEG recordings},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparative analytical survey on cognitive agents with
emotional intelligence. <em>CC</em>, <em>14</em>(4), 1223–1246. (<a
href="https://doi.org/10.1007/s12559-022-10007-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the past decade, social interaction in computer systems has attracted wide attention from the human-computer interaction and robotics communities. One of the essential objectives of artificial intelligence and human-machine interaction is to develop cognitive agents that can interact with others naturally in social situations. Emotional intelligence has a fundamental role in social communication. Emotional intelligence is the capacity of human beings to precisely assess their emotional states as well as emotions pertinent to others and subsequently utilize the acquired information to manage and conduct thoughts and actions and regulate their emotions for adaptation to environments. This critical role of emotional intelligence in social contexts fuels interest in developing computational models of emotions. Therefore, computational models of emotions enhance the behaviors associated with cognitive agents. The main objective of this paper is to present a more holistic view of cognitive agents with emotional intelligence for providing a confident route to the researchers in this literature. This paper offers a comprehensive study of all aspects of emotionally cognitive agents, including definitions, features, applications, and challenges. Subsequently, state-of-the-art computational models of emotions in affective computing literature utilized in cognitive agents are investigated. Also, the general framework is proposed for emotion modeling in cognitive agents. The proposed general framework leverages four main components: emotion generation, emotion experience, emotion regulation, and emotional modulation. These components occur intertwined within an emotional episode. Given our proposed framework, we investigate the components implemented in each computational model of emotions. Due to challenges in assessing agents with emotional intelligence, we present a classification of the evaluation manners leveraged in various studies. Then, we categorize and discuss challenges that necessitate being addressed for further studies. The main contribution of the paper is to provide insight and extensive resources for researchers on the cognitive agents with emotional intelligence literature.},
  archive      = {J_CC},
  author       = {Zall, Raziyeh and Kangavari, Mohammad Reza},
  doi          = {10.1007/s12559-022-10007-5},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1223-1246},
  shortjournal = {Cogn. Comput.},
  title        = {Comparative analytical survey on cognitive agents with emotional intelligence},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint adaptive graph learning and discriminative analysis
for unsupervised feature selection. <em>CC</em>, <em>14</em>(3),
1211–1221. (<a
href="https://doi.org/10.1007/s12559-021-09875-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature selection plays a dominant role in the process of high-dimensional and unlabeled data. Conventional spectral-based unsupervised feature selection methods always learn the subspace based on the predefined graph which constructed by the original features. Therefore, if the data is corrupted by the noise or redundancy existing in the high-dimensional, then the graph will be incorrect and further degrade the performance of downstream tasks. In this paper, we propose a new unsupervised feature selection method, in which the graph is self-adjusting by the original graph and learned subspace, so as to be the optimal one. Besides, the uncorrelated constraint is added to enhance the discriminability of the model. To optimize the model, we propose an alternative iterative algorithm and provide strict convergence proof. Extensive experiments are conducted to evaluate the performance of our method in comparison with other SOTA methods. The proposed adaptive graph learning strategy can learn a high-quality graph with the information of data structure more accurate. Besides, the uncorrelated constraint extremely ensures the discriminability of selected features.},
  archive      = {J_CC},
  author       = {Zhao, Haifeng and Li, Qi and Wang, Zheng and Nie, Feiping},
  doi          = {10.1007/s12559-021-09875-0},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1211-1221},
  shortjournal = {Cogn. Comput.},
  title        = {Joint adaptive graph learning and discriminative analysis for unsupervised feature selection},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A possible explanation for the generation of habit in
navigation: A striatal behavioral learning model. <em>CC</em>,
<em>14</em>(3), 1189–1210. (<a
href="https://doi.org/10.1007/s12559-021-09950-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient behavioral learning is a great challenge to an autonomous mobile robot. During navigation, animals can improve their behavioral learning ability by constantly interacting with the environment and gradually realize efficient navigation. Although habitual behavior in animal navigation is relatively well known, understanding of the brain’s habit-generation mechanism remains limited. In this study, we propose a striatal behavioral learning model, composed of the striosome and a matrix model, to possibly explain the generation of habitual behavior in animal navigation. The model’s bionic mechanism is characterized as follows: (1) in the striosome model, orientation information updates constantly based on the operant conditioning mechanism, leading to the generation of habitual behavior, and (2) a matrix model with an improved ε-greedy algorithm chooses actions by adjusting the utilization of learned habits, balancing the relationship between exploration and exploitation in an agent’s navigation. We test our model in Morris square dry maze tasks. Results indicate the effectiveness of the model in explaining habit-related behavior. Besides, we compare our model with the widely used striatal temporal difference learning model. Results show that our model is more efficient and robust than the contrast model. We can conclude that it can successfully solve navigation tasks with habits while showing key neural characteristics of the striatum, which may be significant to the bionic navigation of robots. The proposed model confirms and builds a relationship among habit generation, the striatum, and operant conditioning, which may help explain the mechanism underlying habit generation in animal navigation.},
  archive      = {J_CC},
  author       = {Chai, Jie and Ruan, Xiaogang and Huang, Jing},
  doi          = {10.1007/s12559-021-09950-6},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1189-1210},
  shortjournal = {Cogn. Comput.},
  title        = {A possible explanation for the generation of habit in navigation: A striatal behavioral learning model},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MvInf: Social influence prediction with multi-view graph
attention learning. <em>CC</em>, <em>14</em>(3), 1182–1188. (<a
href="https://doi.org/10.1007/s12559-021-09822-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The potential impact of social influence prediction has become a hot topic in the current graph data mining area. This paper proposes a deep learning framework named Multi-view Influence prediction network (MvInf) which combines multi-view learning and graph attention neural network together to address the problem of social influence prediction. MvInf takes different attribute features of users as the input of graph attention network and uses the complementarity and consistency between different views to enhance learning performance and thus to better predict user behavior. Experiments performed on four standard datasets (Open Academic Graph, Twitter, Weibo, and Digg) demonstrate that the proposed MvInf model can obtain better performance than previous single view-based approach.},
  archive      = {J_CC},
  author       = {Xu, Huifang and Jiang, Bo and Ding, Chris},
  doi          = {10.1007/s12559-021-09822-z},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1182-1188},
  shortjournal = {Cogn. Comput.},
  title        = {MvInf: Social influence prediction with multi-view graph attention learning},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Separable reversible data hiding based on integer mapping
and MSB prediction for encrypted 3D mesh models. <em>CC</em>,
<em>14</em>(3), 1172–1181. (<a
href="https://doi.org/10.1007/s12559-021-09919-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reversible data hiding in encrypted domain (RDH-ED) technology can embed data into cover media without exposing the original content to third parties. In addition, the recipient can recover the cover media losslessly after extracting the embedded data. Image-based RDH-ED has been widely studied, but RDH-ED based on 3D meshes has obtained few research results due to the complex data structure and irregular geometric structure of 3D meshes. With the widespread application of 3D meshes, the research on 3D meshes has attracted extensive research from researchers in recent years. In this paper, we propose a reversible data hiding for encrypted 3D meshes based on integer mapping and most significant bit (MSB) prediction. The content owner divides all vertices into “embedded” sets and “reference” sets and then maps floating-point coordinates to integers. After calculating the MSB prediction error of the “embedded” sets, the encryption technology is performed. Then, additional data can be embedded through the MSB replacement strategy. According to different permissions, legal recipients can obtain the original meshes, the additional data or both of them by using the proposed separable method. Higher embedding capacity is achieved by adopting MSB embedding strategy, and perfect recovery of the original meshes is achieved by using ring prediction scheme. The experimental results show that the proposed method has greater embedding capacity compared with the state-of-the-art method.},
  archive      = {J_CC},
  author       = {Xu, Na and Tang, Jin and Luo, Bin and Yin, Zhaoxia},
  doi          = {10.1007/s12559-021-09919-5},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1172-1181},
  shortjournal = {Cogn. Comput.},
  title        = {Separable reversible data hiding based on integer mapping and MSB prediction for encrypted 3D mesh models},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised multi-modal hashing for cross-modal retrieval.
<em>CC</em>, <em>14</em>(3), 1159–1171. (<a
href="https://doi.org/10.1007/s12559-021-09847-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosive growth of multimedia data on the Internet has magnified the challenge of information retrieval. Multimedia data usually emerges in different modalities, such as image, text, video, and audio. Unsupervised cross-modal hashing techniques that support searching among multi-modal data have gained importance in large-scale retrieval tasks because of the advantage of low storage cost and high efficiency. Current methods learn the hash functions by transforming high-dimensional data into discrete hash codes. However, the original manifold structure and semantic correlation are not preserved well in compact hash codes. We propose a novel unsupervised cross-modal hashing method to cope with this problem from two perspectives. On the one hand, the semantic correlation in textual space and the locally geometric structure in the visual space are reconstructed by unified hashing features seamlessly and simultaneously. On the other hand, the $$\ell _{2,1}$$ -norm penalties are imposed on the projection matrices separately to learn the relevant and discriminative hash codes. The experimental results indicate that our proposed method achieves an improvement of 1%, 6%, 9%, and 2% over the best comparison method on the four publicly available datasets (WiKi, PASCAL-VOC, UCI Handwritten Digit, and NUS-WIDE), respectively. In conclusion, the proposed framework which combines hash functions learning and multimodal graph embedding is effective in learning hash codes and achieves superior retrieval performance compared to state-of-the-art methods.},
  archive      = {J_CC},
  author       = {Yu, Jun and Wu, Xiao-Jun and Zhang, Donglin},
  doi          = {10.1007/s12559-021-09847-4},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1159-1171},
  shortjournal = {Cogn. Comput.},
  title        = {Unsupervised multi-modal hashing for cross-modal retrieval},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SETransformer: Speech enhancement transformer. <em>CC</em>,
<em>14</em>(3), 1152–1158. (<a
href="https://doi.org/10.1007/s12559-020-09817-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech enhancement is a fundamental way to improve speech perception quality in adverse environment where the received speech is seriously corrupted by noise. In this paper, we propose a cognitive computing based speech enhancement model termed SETransformer which can improve the speech quality in unkown noisy environments. The proposed SETransformer takes advantages of LSTM and multi-head attention mechanism, both of which are inspired by the auditory perception principle of human beings. Specifically, the SETransformer pocesses the ability of characterizing the local structure implicated in the speech spectrum and has more lower computation complexity due to its distinctive parallelization perfermance. Experimental results show that, compared with the standard Transformer and the LSTM model, the proposed SETransformer model can consistently achieve better denoising performance in terms of speech quality (PESQ) and speech intelligibility (STOI) under unseen noise conditions.},
  archive      = {J_CC},
  author       = {Yu, Weiwei and Zhou, Jian and Wang, HuaBin and Tao, Liang},
  doi          = {10.1007/s12559-020-09817-2},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1152-1158},
  shortjournal = {Cogn. Comput.},
  title        = {SETransformer: Speech enhancement transformer},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dual attention with the self-attention alignment for
efficient video super-resolution. <em>CC</em>, <em>14</em>(3),
1140–1151. (<a
href="https://doi.org/10.1007/s12559-021-09874-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By selectively enhancing the features extracted from convolution networks, the attention mechanism has shown its effectiveness for low-level visual tasks, especially for image super-resolution (SR). However, due to the spatiotemporal continuity of video sequences, simply applying image attention to a video does not seem to obtain good SR results. At present, there is still a lack of suitable attention structure to achieve efficient video SR. In this work, building upon the dual attention, i.e., position attention and channel attention, we proposed deep dual attention, underpinned by self-attention alignment (DASAA), for video SR. Specifically, we start by constructing a dual attention module (DAM) to strengthen the acquired spatiotemporal features and adopt a self-attention structure with the morphological mask to achieve attention alignment. Then, on top of the attention features, we utilize the up-sampling operation to reconstruct the super-resolved video images and introduce the LSTM (long short-time memory) network to guarantee the coherent consistency of the generated video frames both temporally and spatially. Experimental results and comparisons on the actual Youku-VESR dataset and the typical benchmark dataset-Vimeo-90 k demonstrate that our proposed approach achieves the best video SR effect while taking the least amount of computation. Specifically, in the Youku-VESR dataset, our proposed approach achieves a test PSNR of 35.290db and a SSIM of 0.939, respectively. In the Vimeo-90 k dataset, the PSNR/SSIM indexes of our approach are 32.878db and 0.774. Moreover, the FLOPS (float-point operations per second) of our approach is as low as 6.39G. The proposed DASAA method surpasses all video SR algorithms in the comparison. It is also revealed that there is no linear relationship between positional attention and channel attention. It suggests that our DASAA with LSTM coherent consistency architecture may have great potential for many low-level vision video applications.},
  archive      = {J_CC},
  author       = {Chu, Yuezhong and Qiao, Yunan and Liu, Heng and Han, Jungong},
  doi          = {10.1007/s12559-021-09874-1},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1140-1151},
  shortjournal = {Cogn. Comput.},
  title        = {Dual attention with the self-attention alignment for efficient video super-resolution},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multistage model for robust face alignment using deep neural
networks. <em>CC</em>, <em>14</em>(3), 1123–1139. (<a
href="https://doi.org/10.1007/s12559-021-09846-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to generalize unconstrained conditions such as severe occlusions and large pose variations remains a challenging goal to achieve in face alignment. In this paper, a multistage model based on deep neural networks is proposed which takes advantage of spatial transformer networks, hourglass networks and exemplar-based shape constraints. First, a spatial transformer-generative adversarial network which consists of convolutional layers and residual units is utilized to solve the initialization issues caused by face detectors, such as rotation and scale variations, to obtain improved face bounding boxes for face alignment. Then, stacked hourglass network is employed to obtain preliminary locations of landmarks as well as their corresponding scores. In addition, an exemplar-based shape dictionary is designed to determine landmarks with low scores based on those with high scores. By incorporating face shape constraints, misaligned landmarks caused by occlusions or cluttered backgrounds can be considerably improved. Extensive experiments based on challenging benchmark datasets are performed to demonstrate the superior performance of the proposed method over other state-of-the-art methods.},
  archive      = {J_CC},
  author       = {Wang, Huabin and Cheng, Rui and Zhou, Jian and Tao, Liang and Kwan, Hon Keung},
  doi          = {10.1007/s12559-021-09846-5},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1123-1139},
  shortjournal = {Cogn. Comput.},
  title        = {Multistage model for robust face alignment using deep neural networks},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local enhancement and bidirectional feature refinement
network for single-shot detector. <em>CC</em>, <em>14</em>(3),
1107–1122. (<a
href="https://doi.org/10.1007/s12559-020-09814-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefit from multi-scale feature pyramid methods, recently single-stage object detectors have achieved promising accuracy and fast inference speed. However, the majority of existing feature pyramid detection techniques only simply describe complex contextual relationships from different scales. Not only are there no effective modules that adaptively extend appropriate semantic information from deeper layers, but the finer spatial localization cues from lower layers are often ignored. In this paper, we present a Local Enhancement and Bidirectional Feature Refinement Network (LFBFR), which includes two optimization methods to achieve remarkable improvements in detection accuracy. Firstly, to make the backbone more suitable for detection task, we modify the pre-trained classification backbone to mitigate the loss of details in small objects due to consecutive decrease of the image resolution. Then we propose a Bidirectional Feature Refinement Pyramid, which can effectively utilize the inter-channel relationship of higher-level features and fine appearance cues from lower-level features by using the attention residual refinement module and the feature reuse module. Ultimately, to assess the performance of the proposed LFBFR, we design a powerful end-to-end single-stage detector called LFBFR-SSD by embedding it into the framework of SSD. Extensive experiments on the PASCAL VOC and MS COCO verify that our LFBFR-SSD outperforms a lot of state-of-the-art detectors while maintaining a real-time speed.},
  archive      = {J_CC},
  author       = {Ouyang, Pengxiang and Zhu, Jiaqi and Fan, Chaogang and Niu, Zhao and Zhan, Shu},
  doi          = {10.1007/s12559-020-09814-5},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1107-1122},
  shortjournal = {Cogn. Comput.},
  title        = {Local enhancement and bidirectional feature refinement network for single-shot detector},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An ensemble of complementary models for deep tracking.
<em>CC</em>, <em>14</em>(3), 1096–1106. (<a
href="https://doi.org/10.1007/s12559-021-09864-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have shown favorable performance in recent tracking benchmark datasets. Some methods extract different levels of features based on pre-trained CNNs to deal with various challenging scenarios. Despite demonstrated successes for visual tracking, utilizing features from the same network might suffer from the suboptimal performance due to limitations of CNN architecture itself. We observe that different CNNs usually have complementary characteristics in representing target objects. Therefore, we propose to leverage the complementary properties of different CNNs for visual tracking in this paper. The importances of different CNNs are identified by a joint inference of candidate location, predicted location and confidence score. The prediction scores of all CNNs are adaptively fused to obtain robust tracking performance. Moreover, we introduce the attention mechanism to highlight discriminative features in each CNN. Experimental results on OTB2013 and OTB2015 datasets show that the proposed method performs favorably compared with some state-of-the-art methods. We conclude that combination of complementary models can better track objects in terms of accuracy and robustness.},
  archive      = {J_CC},
  author       = {Kong, Qiuyu and Tang, Jin and Li, Chenglong and Wang, Xin and Zhang, Jian},
  doi          = {10.1007/s12559-021-09864-3},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1096-1106},
  shortjournal = {Cogn. Comput.},
  title        = {An ensemble of complementary models for deep tracking},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Action recognition with a multi-view temporal attention
network. <em>CC</em>, <em>14</em>(3), 1082–1095. (<a
href="https://doi.org/10.1007/s12559-021-09951-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action recognition is a fundamental and challenging task in computer vision. In recent years, optical flow, as the auxiliary information of frames in a video, has been widely applied to action recognition because of its advantage of utilizing the motion information of video data. However, existing methods only fuse the score of classification probabilities of the two streams; they do not consider the interaction between the image frames and the optical flows. In addition, the other important challenges lie in capturing significant motion information to be able to recognize the action. To overcome these problems, an action recognition model based on a multi-view temporal attention mechanism is proposed in this paper. Specifically, global temporal attention pooling is first designed to fuse multiple frame image features, where more attention is given to discriminative frames. Second, considering the complementarity of the image frame and optical flow, feature-level multi-view fusion methods are proposed. Experiments on three widely used benchmark datasets on action recognition show that our method outperforms other existing state-of-the-art methods. In addition, the effectiveness of the proposed method is extensively demonstrated under different factors, such as the temporal attention pooling strategy, multi-view feature fusion and network architecture. The promising experimental results demonstrate that introducing the temporal attention layer and feature-level multi-view fusion methods is of great effectiveness and overcomes the shortcomings of classical two-stream networks to some extent. Specifically, the proposed method has the following advantages. First, the temporal attention layer can accurately capture key frames that are more conducive to recognizing actions. Second, two kinds of features from image frames and optical flows are combined to make full use of their complementarity. Finally, a variety of fusion methods are employed for feature-level fusion instead of straightforward score fusion.},
  archive      = {J_CC},
  author       = {Sun, Dengdi and Su, Zhixiang and Ding, Zhuanlian and Luo, Bin},
  doi          = {10.1007/s12559-021-09951-5},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1082-1095},
  shortjournal = {Cogn. Comput.},
  title        = {Action recognition with a multi-view temporal attention network},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Special issue on recent advances in cognitive
learning and data analysis. <em>CC</em>, <em>14</em>(3), 1080–1081. (<a
href="https://doi.org/10.1007/s12559-022-10019-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Luo, Bin and Tang, Jin and Liu, Cheng-Lin},
  doi          = {10.1007/s12559-022-10019-1},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1080-1081},
  shortjournal = {Cogn. Comput.},
  title        = {Editorial: Special issue on recent advances in cognitive learning and data analysis},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Medical named entity recognition using weakly supervised
learning. <em>CC</em>, <em>14</em>(3), 1068–1079. (<a
href="https://doi.org/10.1007/s12559-022-10003-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic medical record named entity recognition can extract important clinical information from unstructured text, which is helpful for clinical diagnosis and medical decision-making. However, due to the particularity of the medical field, it is difficult for researchers to obtain sufficient labeled electronic medical records. Models trained using traditional supervised learning methods with insufficient data are not promising. To solve this problem, this paper proposes two weakly supervised learning methods, sampling-based active learning and parameter-based transfer learning, to achieve better performance. In sampling-based active learning, two uncertainty sampling strategies, least confidence sampling and entropy sampling, are used to select data from unlabeled dataset for retraining. In parameter-based transfer learning, the parameters of word representation layer and encoding layer in the source domain are initialized to the corresponding layer of the target domain, and the objective is to learn generalized linguistic knowledge from the source domain. Finally, we use a voting mechanism to ensemble these individual models to get better prediction results. Experiment on the CCKS2017 official test set shows that our system for MER achieves 0.8972 F1 score and gets better performance than the supervised methods, which obtains 0.8921 F1 score and proves the effectiveness of our approaches. The experimental results show that the weakly supervised learning methods proposed in this paper achieve the satisfactory performance as the supervised methods under comparable conditions.},
  archive      = {J_CC},
  author       = {Ma, Long-Long and Yang, Jie and An, Bo and Liu, Shuaikang and Huang, Gaijuan},
  doi          = {10.1007/s12559-022-10003-9},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1068-1079},
  shortjournal = {Cogn. Comput.},
  title        = {Medical named entity recognition using weakly supervised learning},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cognitive knowledge-aware social recommendation via
group-enhanced ranking model. <em>CC</em>, <em>14</em>(3), 1055–1067.
(<a href="https://doi.org/10.1007/s12559-022-10001-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive inspired recommendation systems have attracted increasing attention in recent years, aiming at fitting user ratings on certain items. However, the performance of recommendation approaches has been limited due to the sparsity and ambiguity of cognitive knowledge user-item ratings. Top-k recommendation has therefore been addressed and has become one of the most popular research areas. The goal of top-k recommendation is to capture the relative preferences of users and fit the optimal ranking list of items. Meanwhile, the development of social networks provides a new way to model user preferences to improve the accuracy and interpretation ability of cognition-aware recommendation models. To integrate user social information into top-k recommendation, we propose a group-enhanced ranking method based on matrix factorization. In our method, we first compute trust values between users based on user trust relationships. Then, we incorporate a trust matrix into the loss function with a social-based penalty term that reduces the distances between preference vectors of trusted users. Experimental results on two real datasets from Epinions and BaiduMovies show that the proposed method outperforms several state-of-the-art methods in terms of the normalized discounted cumulative gain (NDCG) value. Our model effectively improves the accuracy of social recommendations. We propose a novel cognitive knowledge-aware group-enhanced social recommendation method for item recommendation. The model modifies the loss function by considering the user trust relationship and group-enhanced ranking and significantly improves the performance of social recommendations.},
  archive      = {J_CC},
  author       = {Xu, Bo and Lin, Hongfei and Yang, Liang and Lin, Yuan and Xu, Kan},
  doi          = {10.1007/s12559-022-10001-x},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1055-1067},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitive knowledge-aware social recommendation via group-enhanced ranking model},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Social media sentiment analysis based on dependency graph
and co-occurrence graph. <em>CC</em>, <em>14</em>(3), 1039–1054. (<a
href="https://doi.org/10.1007/s12559-022-10004-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, research of social text sentiment analysis has progressed rapidly, but the existing methods usually use the single feature for text representation and fail to make full use of potential features in social texts. Such sparse feature limits the improvement of sentiment analysis performance. Intuitively, besides the plain text feature, the features that reveal grammatical rules and semantic associations all have a positive effect on the performance of sentiment analysis. This article takes diverse structural information, part of speech, and position association information into consideration simultaneously, and proposes a brain-inspired multi-feature hierarchical graph attention model (MH-GAT) based on co-occurrence and syntactic dependency graphs for sentiment analysis. It mainly includes multi-feature fusion and bi-graph hierarchical attention. Specifically, we first design an input layer involving multiple features, such as part of speech, position, syntactic dependency, and co-occurrence information, to make up for the information lacking in conventional sentiment analysis methods. As for the bi-graph hierarchical attention mechanism, we build hierarchical graphs for each text and use a graph attention network with extraordinary aggregation ability to learn the inherent rules of language expression. Compared to the latest Att-BLSTM, Text-Level-GNN, and TextING, the sentiment analysis accuracy of the proposed model has increased by an average of 5.17% on the Chinese Weibo dataset and English SST2 dataset. The proposed MH-GAT model can effectively improve the classification performance of social short texts.},
  archive      = {J_CC},
  author       = {Jin, Zhigang and Tao, Manyue and Zhao, Xiaofang and Hu, Yi},
  doi          = {10.1007/s12559-022-10004-8},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1039-1054},
  shortjournal = {Cogn. Comput.},
  title        = {Social media sentiment analysis based on dependency graph and co-occurrence graph},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of plan-based approaches for dialogue management.
<em>CC</em>, <em>14</em>(3), 1019–1038. (<a
href="https://doi.org/10.1007/s12559-022-09996-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue systems deliver a more natural mean of communication between humans and machines when compared to traditional systems. Beyond input/output components that understand and generate natural language utterances, the core of a dialogue system is the dialogue manager. The aim of the dialogue manager is to mimic all cognitive aspects related to a natural conversation and it is responsible for identifying the current state of the dialogue and for deciding the next action to be taken by a dialogue system. Artificial intelligence (AI) planning is one of the techniques available in the literature for dialogue management. In a dialogue system, AI planning deals with the action selection problem by treating each utterance as an action and by choosing the actions that get closer to the dialogue goal. This work aims to provide a systematic literature review (SLR) that investigates recent contributions to plan-based dialogue management. This SLR aims at answering research questions concerning: (i) the types of AI planning exploited for dialogue management; (ii) the planning characteristics that justify its adoption in dialogue system; (iii) and, the challenges posed on the development of plan-based dialogue managers. The present SLR was performed by querying four scientific repositories, followed by a manual search on works from the most eminent authors in the field. Further works that were cited by the retrieved papers were also considered for inclusion. Our final corpus is composed of forty works, including only works published since 2014. The results indicate that AI planning is still an emerging strategy for dialogue management. Although AI planning can offer a strong contribution to dialogue systems, especially to those that require predictability, some relevant challenges might still limit its adoption. Our results contributed to discussions in the field and they highlight some research gaps to be addressed in future studies.},
  archive      = {J_CC},
  author       = {Santos Teixeira, Milene and Dragoni, Mauro},
  doi          = {10.1007/s12559-022-09996-0},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1019-1038},
  shortjournal = {Cogn. Comput.},
  title        = {A review of plan-based approaches for dialogue management},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Measure effectiveness of change-based three-way decision
using utility theory. <em>CC</em>, <em>14</em>(3), 1009–1018. (<a
href="https://doi.org/10.1007/s12559-022-09999-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The trisecting–acting–outcome (TAO) model of three-way decision plays a crucial role in solving complex problems. It comprises three components: trisecting, acting, and outcome. Trisecting means dividing an entire set into three relatively small parts based on an evaluation function, and acting means designing the corresponding action to apply to these three parts. The outcome denotes evaluation effectiveness based on the first two steps. Several previous investigations have measured effects from a coarse-grained perspective. Still, they have not considered the impact of fine-grained changes in objects and have not devised the method of selecting a strategy-constructed tripartition for a given expected outcome. The present study aimed to explore the outcome measure from the view of fine-grained changes in objects named change-based three-way decision. It also provides a novel approach to quantifying outcomes using utility theory. Specifically, we conducted the study using two perspectives: top-down and bottom-up, depending on the decision demands. The object is first divided into three regions based on changes corresponding to different utilities from the top-down view. Then, the overall utility is aggregated based on the particular utility metrics representing different satisfaction levels in the three regions. From the bottom-up perspective, we derive a pair of thresholds based on the desired utility of the decision-maker and thus obtain three parts whose changes can make by some action to achieve these effects. The principal conclusions of this exploration are that outcomes can be better ranked using objects’ changes using utility theory and that strategies can be better acting to achieve corresponding variations based on the expected utility of the decision-maker. We describe the specific steps and procedures of the proposed method through several examples. The findings presented in this paper add to our understanding of the outcome measure for the three-way decision.},
  archive      = {J_CC},
  author       = {Jiang, Chunmao and Guo, Doudou and Duan, Ying},
  doi          = {10.1007/s12559-022-09999-x},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1009-1018},
  shortjournal = {Cogn. Comput.},
  title        = {Measure effectiveness of change-based three-way decision using utility theory},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bibliometric study and science mapping research of
intelligent decision. <em>CC</em>, <em>14</em>(3), 989–1008. (<a
href="https://doi.org/10.1007/s12559-022-09993-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent decision (ID) has received a great deal of attention and has been integrated into various fields, such as machine learning, fuzzy inference system, and natural language processing. The advanced technologies have become hot topics and have been made great development and innovations in academic documents. This paper is a comprehensive review in the field of ID based on bibliometric analysis and strategic analysis. First, the descriptive statistics and results are presented, including database, annual publications, research directions, and hotspots. Based on the visualization tools (including VOS viewer, CiteSpace, Bibexcel, and GPS visualizer), from the perspective of the author keyword, the current research topics, and the development evolution are presented. Some bibliometric analysis methods are applied, such as co-occurrence analysis, timeline view analysis, and burst detection analysis. Then, this paper identifies the most influential countries/regions, institutions, and authors. Next, some important themes are further discussed by strategic analysis and overlapping analysis. This paper helps scholars with understanding the development trajectory and statistical model of ID research to promote in-depth exploration.},
  archive      = {J_CC},
  author       = {Li, Bo and Xu, Zeshui and Hong, Nan and Hussain, Amir},
  doi          = {10.1007/s12559-022-09993-3},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {989-1008},
  shortjournal = {Cogn. Comput.},
  title        = {A bibliometric study and science mapping research of intelligent decision},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust dynamic semi-supervised picture fuzzy clustering with
KL divergence and local information. <em>CC</em>, <em>14</em>(3),
970–988. (<a href="https://doi.org/10.1007/s12559-021-09988-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust image segmentation is a research hot point in recent years, and the segmentation of images corrupted by high noise is a challenging topic in this field. Picture fuzzy clustering is a novel potent computation intelligence method for pattern analysis and machine intelligence. Motivated by these, this paper aims to present a robust dynamic semi-supervised picture fuzzy clustering algorithm with spatial information constraints to meet the need for segmenting images with high noise. To explore the study, this paper firstly constructs a weighted square Euclidean distance by combining the current pixel with its neighborhood spatial information to measure the difference between the current pixel and the clustering center. Secondly, inspired by the idea of semi-supervised clustering, the weighted local membership information of the current pixel is embedded into the picture fuzzy clustering through KL divergence, and a novel dynamic semi-supervised fuzzy clustering is obtained. Thirdly, for further enhancement of the anti-noise ability of semi-supervised fuzzy clustering, a picture fuzzy local information factor is constructed by fusing picture fuzzy partition information with weighted square Euclidean distance and introduced into dynamic semi-supervised fuzzy clustering to form a robust picture fuzzy clustering-related algorithm for image segmentation in the presence of high noise. The experiments on a series of synthetic images, medical images, remote sensing images, and standard datasets illustrate how our proposed algorithm works. This proposed algorithm has excellent segmentation performance and anti-noise robustness and outperforms eight state-of-the-art fuzzy or picture fuzzy clustering-related algorithms on four standard datasets in the presence of high noise.},
  archive      = {J_CC},
  author       = {Wu, Chengmao and Zhang, Jiajia and Huang, Congcong and Guo, Xiaokang},
  doi          = {10.1007/s12559-021-09988-6},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {970-988},
  shortjournal = {Cogn. Comput.},
  title        = {Robust dynamic semi-supervised picture fuzzy clustering with KL divergence and local information},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel biologically inspired approach for clustering and
multi-level image thresholding: Modified harris hawks optimizer.
<em>CC</em>, <em>14</em>(3), 955–969. (<a
href="https://doi.org/10.1007/s12559-022-09998-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biologically inspired computing deals with complex real-world problems using elegantly modeled techniques motivated by the behaviors of creatures in nature. Harris hawks optimizer (HHO), motivated by the cooperative behavior and hunting style of Harris’ hawks, is a nature-inspired optimization paradigm. As an eminent swarm intelligence method, HHO has established strong performance. However, the original HHO may face difficulties when handling practical multimodal and composition problems. To overcome these challenges, this paper investigates an improved HHO, which considers nonlinear decay energy, introduces the grey wolf optimizer (GWO) as a competitive method to modify conventional HHO, and improves the balance between its exploration and exploitation. The proposed approach combines different cognitive hunting behaviors of Harris’ hawks and grey wolf packs. The main idea of the proposed method can be described as follows: First, we generate a set of candidate solutions and then divide them into two halves. The improved HHO is employed to update the solutions in the first half, while the search phase of GWO is introduced to update the solutions in the second half. Second, we choose the best solutions for the union subpopulations and continue to conduct the iteration procedure. Furthermore, the new approach is utilized to solve the clustering problem and determine the optimal threshold values for multi-level image segmentation problems. Experimental results on 11 benchmark functions illustrate the effectiveness of the proposed approach. Extensive results on clustering and multi-level image segmentation demonstrate the efficiency of the proposed algorithm.},
  archive      = {J_CC},
  author       = {Cai, Jia and Luo, Tianhua and Xu, Guanglong and Tang, Yi},
  doi          = {10.1007/s12559-022-09998-y},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {955-969},
  shortjournal = {Cogn. Comput.},
  title        = {A novel biologically inspired approach for clustering and multi-level image thresholding: Modified harris hawks optimizer},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary multitask optimization: A methodological
overview, challenges, and future research directions. <em>CC</em>,
<em>14</em>(3), 927–954. (<a
href="https://doi.org/10.1007/s12559-022-10012-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider multitasking in the context of solving multiple optimization problems simultaneously by conducting a single search process. The principal goal when dealing with this scenario is to dynamically exploit the existing complementarities among the problems (tasks) being optimized, helping each other through the exchange of valuable knowledge. Additionally, the emerging paradigm of evolutionary multitasking tackles multitask optimization scenarios by using biologically inspired concepts drawn from swarm intelligence and evolutionary computation. The main purpose of this survey is to collect, organize, and critically examine the abundant literature published so far in evolutionary multitasking, with an emphasis on the methodological patterns followed when designing new algorithmic proposals in this area (namely, multifactorial optimization and multipopulation-based multitasking). We complement our critical analysis with an identification of challenges that remain open to date, along with promising research directions that can leverage the potential of biologically inspired algorithms for multitask optimization. Our discussions held throughout this manuscript are offered to the audience as a reference of the general trajectory followed by the community working in this field in recent times, as well as a self-contained entry point for newcomers and researchers interested to join this exciting research avenue.},
  archive      = {J_CC},
  author       = {Osaba, Eneko and Del Ser, Javier and Martinez, Aritz D. and Hussain, Amir},
  doi          = {10.1007/s12559-022-10012-8},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {927-954},
  shortjournal = {Cogn. Comput.},
  title        = {Evolutionary multitask optimization: A methodological overview, challenges, and future research directions},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bio-inspired multi-population-based adaptive backtracking
search algorithm. <em>CC</em>, <em>14</em>(2), 900–925. (<a
href="https://doi.org/10.1007/s12559-021-09984-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backtracking search algorithm (BSA) is a nature-based optimization technique extensively used to solve various real-world global optimization problems for the past few years. The present work aims to introduce an improved BSA (ImBSA) based on a multi-population approach and modified control parameter settings to apprehend an ensemble of various mutation strategies. In the proposed ImBSA, a new mutation strategy is suggested to enhance the algorithm’s performance. Also, for all mutation strategies, the control parameters are updated adaptively during the algorithm’s execution. Extensive experiments have been performed on CEC2014 and CEC2017 single-objective benchmark functions, and the results are compared with several state-of-the-art algorithms, improved BSA variants, efficient differential evolution (DE) variants, particle swarm optimization (PSO) variants, and some other hybrid variants. The nonparametric Friedman rank test has been conducted to examine the efficiency of the proposed algorithm statistically. Moreover, six real-world engineering design problems have been solved to examine the problem-solving ability of ImBSA. The experimental results, statistical analysis, convergence graphs, complexity analysis, and the results of real-world applications confirm the superior performance of the suggested ImBSA.},
  archive      = {J_CC},
  author       = {Nama, Sukanta and Saha, Apu Kumar},
  doi          = {10.1007/s12559-021-09984-w},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {900-925},
  shortjournal = {Cogn. Comput.},
  title        = {A bio-inspired multi-population-based adaptive backtracking search algorithm},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A calibration-free approach to implementing p300-based
brain–computer interface. <em>CC</em>, <em>14</em>(2), 887–899. (<a
href="https://doi.org/10.1007/s12559-021-09971-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: As a direct bridge between the brain and the outer world, brain–computer interface (BCI) is expected to replace, restore, enhance, supplement, or improve the natural output of brain. The prospect of BCI serving humans is very broad. However, the extensive applications of BCI have not been fully achieved. One of reasons is that the cost of calibration reduces the convenience and usability of BCI. Methods: In this study, we proposed a calibration-free approach, which is based on the ideas of reinforcement learning and transfer learning, for P300-based BCI. This approach, composed of two algorithms: P300 linear upper confidence bound (PLUCB) and transferred PLUCB (TPLUCB), is able to learn during the usage by exploration and exploitation and allows P300-based BCI to start working without any calibration. Results: We tested the performances of PLUCB and TPLUCB using stepwise linear discriminant analysis (SWLDA), a commonly used method that needs calibration, as a baseline in simulated online experiments. The results showed the merits of PLUCB and TPLUCB. PLUCB can quickly increase the accuracies to the level of SWLDA. TPLUCB has surpassed SWLDA in the sample accuracy since it starts running. Both PLUCB and TPLUCB have the ability to keep improving the classification performance during the process. The overall sample accuracies ( $$73.6\pm 4.8\%$$ , $$73.1\pm 4.9\%$$ ), overall symbol accuracies ( $$80.4\pm 12.8\%$$ , $$79.6\pm 14.0\%$$ ), F-measures ( $$0.45\pm 0.06$$ , $$0.44\pm 0.06$$ ) and information transfer ratios (ITR) ( $$36.4\pm 9.1$$ , $$35.5\pm 9.8$$ ) of PLUCB and TPLUCB are significantly better than those of SWLDA (overall sample accuracy: $$58.8\pm 3.8\%$$ , overall symbol accuracy: $$69.0\pm 18.3\%$$ , F-measure: $$0.38\pm 0.04$$ , ITR: $$28.7\pm 10.7$$ ). Conclusions: The proposed approach, which does not need calibration but outperform SWLDA, is a very good option for the implementation of P300-based BCI.},
  archive      = {J_CC},
  author       = {Huang, Zhihua and Guo, Jiannan and Zheng, Wenming and Wu, Yingjie and Lin, Zhixiong and Zheng, Huiru},
  doi          = {10.1007/s12559-021-09971-1},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {887-899},
  shortjournal = {Cogn. Comput.},
  title        = {A calibration-free approach to implementing p300-based brain–computer interface},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FFNet: Feature fusion network for few-shot semantic
segmentation. <em>CC</em>, <em>14</em>(2), 875–886. (<a
href="https://doi.org/10.1007/s12559-021-09990-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation aims at assigning a category label to each pixel in an image. Deep neural networks have achieved many breakthrough research achievements on this task. Nevertheless, there exist two critical bottleneck problems to be solved. First, deep neural networks usually need to be trained on large-scale labeled datasets, which are expensive to obtain or label. Second, traditional semantic segmentation methods are difficult to predict unseen classes after training. To address these problems, few-shot semantic segmentation is proposed, and recent methods have achieved impressive performance. However, many of the existing approaches ignore the semantic correlation between data and fail to generate discriminative features for the semantic segmentation. In this paper, to address the above issue, we propose a feature fusion network (FFNet) for few-shot semantic segmentation to enhance the discriminative ability of the learned data representations. Specifically, a task attention module is devised to learn the semantic correlation between data. Then, a multi-scale feature fusion module is trained to adaptively fuse the contextual information at multiple scale, thus capturing multi-scale object information. To the end, the proposed FFNet experiments conducted on the PASCAL- $$5^i$$ and COCO- $$20^i$$ datasets demonstrate the superiority of our proposed FFNet and show its advantage over existing approaches.},
  archive      = {J_CC},
  author       = {Wang, Ya-Nan and Tian, Xiangtao and Zhong, Guoqiang},
  doi          = {10.1007/s12559-021-09990-y},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {875-886},
  shortjournal = {Cogn. Comput.},
  title        = {FFNet: Feature fusion network for few-shot semantic segmentation},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HAKE: An unsupervised approach to automatic keyphrase
extraction for multiple domains. <em>CC</em>, <em>14</em>(2), 852–874.
(<a href="https://doi.org/10.1007/s12559-021-09979-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keyphrases capture the main content of a free text document. The task of automatic keyphrase extraction (AKPE) plays a significant role in retrieving and summarizing valuable information from several documents with different domains. Various techniques have been proposed for this task. However, supervised AKPE requires large annotated data and depends on the tested domain. An alternative solution is to consider a new independent domain method that can be applied to several domains (such as medical, social). In this paper, we tackle keyphrase extraction from single documents with HAKE, a novel unsupervised method that takes full advantage of mining linguistic, statistical, structural, and semantic text features simultaneously to select the most relevant keyphrases in a text. HAKE achieves higher F-scores than the unsupervised state-of-the-art systems on standard datasets and is suitable for real-time processing of large amounts of Web and text data across different domains. With HAKE, we also explicitly increase coverage and diversity among the selected keyphrases by introducing a novel technique (based on a parse tree approach, part of speech tagging, and filtering) for candidate keyphrase identification and extraction. This technique allows us to generate a comprehensive and meaningful list of candidate keyphrases and reduce the candidate set’s size without increasing the computational complexity. HAKE’s effectiveness is compared to twelve state-of-the-art and recent unsupervised approaches, as well as to some other supervised approaches. Experimental analysis is conducted to validate the proposed method using five of the top available benchmark corpora from different domains and shows that HAKE significantly outperforms both the existing unsupervised and supervised methods. Our method does not require training on a particular set of documents, nor does it depend on external corpora, dictionaries, domain, or text size. Our experiments confirm that HAKE’s candidate selection model and its ranking model are effective.},
  archive      = {J_CC},
  author       = {Merrouni, Zakariae Alami and Frikh, Bouchra and Ouhbi, Brahim},
  doi          = {10.1007/s12559-021-09979-7},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {852-874},
  shortjournal = {Cogn. Comput.},
  title        = {HAKE: An unsupervised approach to automatic keyphrase extraction for multiple domains},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel multiple feature-based engine knock detection system
using sparse bayesian extreme learning machine. <em>CC</em>,
<em>14</em>(2), 828–851. (<a
href="https://doi.org/10.1007/s12559-021-09945-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automotive engine knock is an abnormal combustion phenomenon that affects engine performance and lifetime expectancy, but it is difficult to detect. Collecting engine vibration signals from an engine cylinder block is an effective way to detect engine knock. This paper proposes an intelligent engine knock detection system based on engine vibration signals. First, filtered signals are obtained by utilizing variational mode decomposition (VMD), which decomposes the original time domain signals into a series of intrinsic mode functions (IMFs). Moreover, the values of the balancing parameter and the number of IMF modes are optimized using genetic algorithm (GA). IMFs with sample entropy higher than the mean are then selected as sensitive subcomponents for signal reconstruction and subsequently removed. A multiple feature learning approach that considers time domain statistical analysis (TDSA), multi-fractal detrended fluctuation analysis (MFDFA) and alpha stable distribution (ASD) simultaneously, is utilized to extract features from the denoised signals. Finally, the extracted features are trained by sparse Bayesian extreme learning machine (SBELM) to overcome the sensitivity of hyperparameters in conventional machine learning algorithms. A test rig is designed to collect the raw engine data. Compared with other technology combinations, the optimal scheme from signal processing to feature classification is obtained, and the classification accuracy of the proposed integrated engine knock detection method can achieve 98.27%. We successfully propose and test a universal intelligence solution for the detection task.},
  archive      = {J_CC},
  author       = {Yang, Zhao-Xu and Rong, Hai-Jun and Wong, Pak Kin and Angelov, Plamen and Vong, Chi Man and Chiu, Chi Wai and Yang, Zhi-Xin},
  doi          = {10.1007/s12559-021-09945-3},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {828-851},
  shortjournal = {Cogn. Comput.},
  title        = {A novel multiple feature-based engine knock detection system using sparse bayesian extreme learning machine},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Observer and command-filter-based adaptive neural network
control algorithms for nonlinear multi-agent systems with input delay.
<em>CC</em>, <em>14</em>(2), 814–827. (<a
href="https://doi.org/10.1007/s12559-021-09959-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last decades, many researchers have investigated the distributed adaptive consensus tacking control algorithm of multi-agent systems (MASs). Nevertheless, the existing works involving the command-filter-based adaptive consensus problem for nonlinear multi-agent systems subjected to the unmeasurable states are relatively few. Besides that, the immeasurable states and the input delay will bring few challenging in dealing with the consensus problem for MASs. (1) The radial basis function neural networks (RBF NNs) are utilized to approximate the unknown nonlinear functions and the NN-based observer is established to copy with the unmeasurable states. (2) The backstepping design method of distributed adaptive consensus control is put forward on basis of the command filtering method, which overcomes the complexity explosion problem and eliminates errors by introducing compensation signals. (3) The Pade approximation approach is served to remove the obstacle originating from the input delay. This paper addresses the observer and command-filter-based adaptive tracking control problem for nonlinear multi-agent systems with the unmeasurable states and input delay under the directed graph. The Lyapunov stability theory is utilized to prove that the proposed approach can ensure that all signals in the closed-loop system reach cooperatively semi-globally uniformly ultimately bounded (CSUUB). The simulation result is presented, and it further manifests that the effectiveness of this scheme.},
  archive      = {J_CC},
  author       = {Ma, Lidan and Wang, Xin and Zhou, Yuhao},
  doi          = {10.1007/s12559-021-09959-x},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {814-827},
  shortjournal = {Cogn. Comput.},
  title        = {Observer and command-filter-based adaptive neural network control algorithms for nonlinear multi-agent systems with input delay},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stability analysis of stochastic delayed differential
systems with state-dependent-delay impulses: Application of neural
networks. <em>CC</em>, <em>14</em>(2), 805–813. (<a
href="https://doi.org/10.1007/s12559-021-09967-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The previously studied stochastic delayed nonlinear systems with constant delayed or time-varying delayed impulsive controller, while we study stochastic delayed nonlinear systems under state-dependent-delayed impulsive controller. The difficulty is how to determine the time of impulses occurrence. Employing the Halanay differential inequality, Itô’s formula, the average impulsive interval, impulsive control theory, comparison properties, several effective conditions ensuring stability of stochastic delayed nonlinear systems under state-dependent delayed impulsive controller are derived. This paper contributed to the stability analysis of delayed impulsive nonlinear systems with stochastic perturbation, which the impulsive involved delay is state dependent. We have developed exponential stability of delayed nonlinear systems with state-dependent-delay impulses and stochastic disturbance in this paper. In the future, more new methods should also be proposed. At the same time, we will consider the nonlinear systems with unbounded delays.},
  archive      = {J_CC},
  author       = {Zhang, Wei and Huang, Junjian},
  doi          = {10.1007/s12559-021-09967-x},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {805-813},
  shortjournal = {Cogn. Comput.},
  title        = {Stability analysis of stochastic delayed differential systems with state-dependent-delay impulses: Application of neural networks},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PS-net: Progressive selection network for salient object
detection. <em>CC</em>, <em>14</em>(2), 794–804. (<a
href="https://doi.org/10.1007/s12559-021-09952-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-level features contain abundant details and high-level features have rich semantic information. Integrating multi-scale features in an appropriate way is significant for salient object detection. However, direct concatenation or addition taken by most methods ignores the distinctions of contribution among multi-scale features. Besides, most salient object detection models fail to dynamically adjust receptive fields to fit objects of various sizes. To tackle these problems, we propose a Progressive Selection Network (PS-Net). Specifically, PS-Net dynamically extracts high-level features and encourages high-level features to guide low-level features to suppress the background response of the original features. We proposed a salient model PS-Net that selects features progressively at multiply levels. First, we propose a Pyramid Feature Dynamic Extraction module to dynamically select appropriate receptive fields to extract high-level features by Feature Dynamic Extraction modules step by step. Besides, a Self-Interaction Attention module is designed to extract detailed information for low-level features. Finally, we design a Scale Aware Fusion module to fuse these multiple features for adequate exploitation of high-level features to refine low-level features gradually. Compared with 19 start-of-the-art methods on 6 public benchmark datasets, the proposed method achieves remarkable performance in both quantitative and qualitative evaluation. We performed a lot of ablation studies, and more discussions to demonstrate the effectiveness and superiority of our proposed method. In this paper, we propose a PS-Net for effective salient object detection. Extensive experiments on 6 datasets validate that the proposed model outperforms 19 state-of-the-art methods under different evaluation metrics.},
  archive      = {J_CC},
  author       = {Ren, Jianyi and Wang, Zheng and Ren, Jinchang},
  doi          = {10.1007/s12559-021-09952-4},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {794-804},
  shortjournal = {Cogn. Comput.},
  title        = {PS-net: Progressive selection network for salient object detection},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Road segmentation from high-fidelity remote sensing images
using a context information capture network. <em>CC</em>,
<em>14</em>(2), 780–793. (<a
href="https://doi.org/10.1007/s12559-021-09980-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic extraction of roads or buildings from remote sensing imagery plays a significant role in many urban applications. Recently, due to the impressive performance of deep learning, various road segmentation methods based on the fully convolutional network (FCN) have been proposed for optical remote sensing images. However, the existing FCN-based high-fidelity remote sensing image segmentation methods still have some limitations. As the repeated convolution and pooling operations employed in an FCN reduce the feature resolution and lose some detailed information, FCNs have a limited capacity to mine long-range dependencies among features. To address this issue, a context information capture network (CM-FCN) for road segmentation is proposed. To capture and aggregate multiscale contextual information, a dilated convolution module is designed. Furthermore, to boost the long-range dependencies of features for road detection, two attention modules employing the attention mechanism to adaptively combine local features with their global dependencies are designed. The context features extracted from the dilated convolution module are then fused into the attention modules to further improve the segmentation performance. The proposed model is evaluated on three challenging remote sensing image road segmentation datasets and one building segmentation dataset, including a dataset with our own manual labels. Comparisons demonstrate the effectiveness of our proposed method. We conclude that our proposed CM-FCN has the potential to automatically segment roads and buildings from high-resolution remote sensing images with an accuracy that renders it a useful tool for practical application scenarios.},
  archive      = {J_CC},
  author       = {Zhu, Yuting and Long, Lihong and Wang, Jinjie and Yan, Jingwen and Wang, Xiaoqing},
  doi          = {10.1007/s12559-021-09980-0},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {780-793},
  shortjournal = {Cogn. Comput.},
  title        = {Road segmentation from high-fidelity remote sensing images using a context information capture network},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LightAdam: Towards a fast and accurate adaptive momentum
online algorithm. <em>CC</em>, <em>14</em>(2), 764–779. (<a
href="https://doi.org/10.1007/s12559-021-09985-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive optimization algorithms enjoy fast convergence and have been widely exploited in pattern recognition and cognitively-inspired machine learning. These algorithms may however be of high computational cost and low generalization ability due to their projection steps. Such limitations make them difficult to be applied in big data analytics, which may typically be seen in cognitively inspired learning, e.g. deep learning tasks. In this paper, we propose a fast and accurate adaptive momentum online algorithm, called LightAdam, to alleviate the drawbacks of projection steps for the adaptive algorithms. The proposed algorithm substantially reduces computational cost for each iteration step by replacing high-order projection operators with one-dimensional linear searches. Moreover, we introduce a novel second-order momentum and engage dynamic learning rate bounds in the proposed algorithm, thereby obtaining a higher generalization ability than other adaptive algorithms. We theoretically analyze that our proposed algorithm has a guaranteed convergence bound, and prove that our proposed algorithm has better generalization capability as compared to Adam. We conduct extensive experiments on three public datasets for image pattern classification, and validate the computational benefit and accuracy performance of the proposed algorithm in comparison with other state-of-the-art adaptive optimization algorithms},
  archive      = {J_CC},
  author       = {Zhou, Yangfan and Huang, Kaizhu and Cheng, Cheng and Wang, Xuguang and Liu, Xin},
  doi          = {10.1007/s12559-021-09985-9},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {764-779},
  shortjournal = {Cogn. Comput.},
  title        = {LightAdam: Towards a fast and accurate adaptive momentum online algorithm},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Embeddings evaluation using a novel measure of semantic
similarity. <em>CC</em>, <em>14</em>(2), 749–763. (<a
href="https://doi.org/10.1007/s12559-021-09987-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lexical taxonomies and distributional representations are largely used to support a wide range of NLP applications, including semantic similarity measurements. Recently, several scholars have proposed new approaches to combine those resources into unified representation preserving distributional and knowledge-based lexical features. In this paper, we propose and implement TaxoVec, a novel approach to selecting word embeddings based on their ability to preserve taxonomic similarity. In TaxoVec, we first compute the pairwise semantic similarity between taxonomic words through a new measure we previously developed, the Hierarchical Semantic Similarity (HSS), which we show outperforms previous measures on several benchmark tasks. Then, we train several embedding models on a text corpus and select the best model, that is, the model that maximizes the correlation between the HSS and the cosine similarity of the pair of words that are in both the taxonomy and the corpus. To evaluate TaxoVec, we repeat the embedding selection process using three other semantic similarity benchmark measures. We use the vectors of the four selected embeddings as machine learning model features to perform several NLP tasks. The performances of those tasks constitute an extrinsic evaluation of the criteria for the selection of the best embedding (i.e. the adopted semantic similarity measure). Experimental results show that (i) HSS outperforms state-of-the-art measures for measuring semantic similarity in taxonomy on a benchmark intrinsic evaluation and (ii) the embedding selected through TaxoVec achieves a clear victory against embeddings selected by the competing measures on benchmark NLP tasks. We implemented the HSS, together with other benchmark measures of semantic similarity, as a full-fledged Python package called TaxoSS, whose documentation is available at https://pypi.org/project/TaxoSS .},
  archive      = {J_CC},
  author       = {Giabelli, Anna and Malandri, Lorenzo and Mercorio, Fabio and Mezzanzanica, Mario and Nobani, Navid},
  doi          = {10.1007/s12559-021-09987-7},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {749-763},
  shortjournal = {Cogn. Comput.},
  title        = {Embeddings evaluation using a novel measure of semantic similarity},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vector symbolic architectures for context-free grammars.
<em>CC</em>, <em>14</em>(2), 733–748. (<a
href="https://doi.org/10.1007/s12559-021-09974-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vector symbolic architectures (VSA) are a viable approach for the hyperdimensional representation of symbolic data, such as documents, syntactic structures, or semantic frames. We present a rigorous mathematical framework for the representation of phrase structure trees and parse trees of context-free grammars (CFG) in Fock space, i.e. infinite-dimensional Hilbert space as being used in quantum field theory. We define a novel normal form for CFG by means of term algebras. Using a recently developed software toolbox, called FockBox, we construct Fock space representations for the trees built up by a CFG left-corner (LC) parser. We prove a universal representation theorem for CFG term algebras in Fock space and illustrate our findings through a low-dimensional principal component projection of the LC parser state. Our approach could leverage the development of VSA for explainable artificial intelligence (XAI) by means of hyperdimensional deep neural computation.},
  archive      = {J_CC},
  author       = {Graben, Peter beim and Huber, Markus and Meyer, Werner and Römer, Ronald and Wolff, Matthias},
  doi          = {10.1007/s12559-021-09974-y},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {733-748},
  shortjournal = {Cogn. Comput.},
  title        = {Vector symbolic architectures for context-free grammars},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bifurcation study for fractional-order three-layer neural
networks involving four time delays. <em>CC</em>, <em>14</em>(2),
714–732. (<a href="https://doi.org/10.1007/s12559-021-09939-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the past several decades, many scholars deal with the stability behavior and Hopf bifurcation phenomenon of fractional-order delayed neural networks. However, the literature involving the stability issue and Hopf bifurcation behavior of fractional-order neural networks with multiple time delays is relatively scarce. This article is principally concerned with the stability problem and of Hopf bifurcation behavior of fractional-order three-layer neural networks involving multiple time delays. Variable substitution, Laplace transform, bifurcation principle of fractional-order dynamical system and computer simulation skill are employed. The delay-independent stability criterion and the sufficient condition of onset of Hopf bifurcation of three-layer neural networks are set up. It shows that if the sum of both different delays passes a key value, then the system loses its stability and the Hopf bifurcation phenomenon will take place. The study manifests that delay plays a most momentous part in stabilizing system and controlling bifurcation behavior for the fractional-order delayed three-layer neural networks. The researchful results of this article are an important theoretical cornerstone in controlling and adjusting neural networks. The obtained conclusions are completely novel and complement the earlier research results.},
  archive      = {J_CC},
  author       = {Xu, Changjin and Zhang, Wei and Liu, Zixin and Li, Peiluan and Yao, Lingyun},
  doi          = {10.1007/s12559-021-09939-1},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {714-732},
  shortjournal = {Cogn. Comput.},
  title        = {Bifurcation study for fractional-order three-layer neural networks involving four time delays},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CSA6D: Channel-spatial attention networks for 6D object pose
estimation. <em>CC</em>, <em>14</em>(2), 702–713. (<a
href="https://doi.org/10.1007/s12559-021-09966-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {6D object pose estimation plays a crucial role in robotic manipulation and grasping tasks. The aim to estimate the 6D object pose from RGB or RGB-D images is to detect objects and estimate their orientations and translations relative to the given canonical models. RGB-D cameras provide two sensory modalities: RGB and depth images, which could benefit the estimation accuracy. But the exploitation of two different modality sources remains a challenging issue. In this paper, inspired by recent works on attention networks that could focus on important regions and ignore unnecessary information, we propose a novel network: Channel-Spatial Attention Network (CSA6D) to estimate the 6D object pose from RGB-D camera. The proposed CSA6D includes a pre-trained 2D network to segment the interested objects from RGB image. Then it uses two separate networks to extract appearance and geometrical features from RGB and depth images for each segmented object. Two feature vectors for each pixel are stacked together as a fusion vector which is refined by an attention module to generate a aggregated feature vector. The attention module includes a channel attention block and a spatial attention block which can effectively leverage the concatenated embeddings into accurate 6D pose prediction on known objects. We evaluate proposed network on two benchmark datasets YCB-Video dataset and LineMod dataset and the results show it can outperform previous state-of-the-art methods under ADD and ADD-S metrics. Also, the attention map demonstrates our proposed network searches for the unique geometry information as the most likely features for pose estimation. From experiments, we conclude that the proposed network can accurately estimate the object pose by effectively leveraging multi-modality features.},
  archive      = {J_CC},
  author       = {Chen, Tao and Gu, Dongbing},
  doi          = {10.1007/s12559-021-09966-y},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {702-713},
  shortjournal = {Cogn. Comput.},
  title        = {CSA6D: Channel-spatial attention networks for 6D object pose estimation},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Short-term airline passenger flow prediction based on the
attention mechanism and gated recurrent unit model. <em>CC</em>,
<em>14</em>(2), 693–701. (<a
href="https://doi.org/10.1007/s12559-021-09991-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pressure of civil aviation traffic is increasing with the prosperity of economy. The accurate forecast of civil aviation flow not only effectively improves the operation efficiency of airlines, but also brings considerable profits to airlines. However, the existing aviation flow forecasting methods generally have the problem of poor forecasting accuracy. Inaccurate traffic prediction models not only fail to bring benefits, but also waste resources of airlines to a certain extent. Therefore, a high-precision forecast of aviation flow is necessary. On the basis of attention mechanism, a high-precision aviation flow model is constructed. First, the deep belief network is used to reduce the dimension of the data. Then, the Gated Recurrent Unit model is used to extract the time series features of the reduced dimension data. Finally, the attention mechanism is used to preserve the key features to achieve high-precision prediction. By analyzing historical data, the model which we proposed can accurately perceive the evolution process of civil aviation traffic and realize the high-precision prediction of short-term passenger flow. Experimental results show that the prediction accuracy of the model in this paper is significantly higher than other existing models, and the application of this model will bring considerable benefits to airlines.},
  archive      = {J_CC},
  author       = {Yu, Jiangni},
  doi          = {10.1007/s12559-021-09991-x},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {693-701},
  shortjournal = {Cogn. Comput.},
  title        = {Short-term airline passenger flow prediction based on the attention mechanism and gated recurrent unit model},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Frontal intrinsic connectivity networks support
contradiction identification during inductive and deductive reasoning.
<em>CC</em>, <em>14</em>(2), 677–692. (<a
href="https://doi.org/10.1007/s12559-021-09982-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deductive and inductive reasoning are fundamental logical processes critical to the solution of common practical problems in daily life. We used functional magnetic resonance imaging (fMRI) to investigate the brain networks involved in Contradictory, Deductive, and Inductive judgments. The experimental paradigm was based on categorical propositions of the Aristotelian Square of Opposition (ASoO). In a full factorial design, identical sentences were combined into premise–conclusion pairs. Each sentence started with ‘every’ or ‘some’. The order of the two propositions in the pair created two types of logical operators (every→some: deductive, or some→every: inductive). The descriptive attributes of the category could be Contradictory or non-Contradictory. Imaging data was analyzed using Group Independent component analysis of fMRI Toolbox (GIFT). Connectivity of nodes within four intrinsic connectivity networks (ICNs) was sensitive to attribute manipulation (Contradiction): the anterior default mode network (aDMN), and the language and cerebellum networks were more involved in Contradictory than non-Contradictory statements, while the anterior salience network (aSN) showed the opposite pattern. Five networks were associated with logical operator manipulation. Stronger positive associations with Inductive than Deductive reasoning were observed in the dorsal and ventral parts of the aDMN, aSN, and orbitofrontal networks (OFN). A stronger negative association with deductive than inductive reasoning was observed in the executive control (ExCN) and dorsal attention (DAN) networks. Differences in the fractional amplitude of low‐frequency fluctuation of the BOLD signal in aDMN, ExCN, and OFN explained 67% of the variance of the behavioural cost of inductive relative to deductive reasoning. The results suggest that different ICNs support logical reasoning and conflict identification. Finally, the magnitude of the differences was positively correlated with behavioural cost.},
  archive      = {J_CC},
  author       = {Mansi, Silvia Angela and Teresa, Medaglia Maria and Seri, Stefano and Tonin, Paolo and Rotshtein, Pia and Porcaro, Camillo},
  doi          = {10.1007/s12559-021-09982-y},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {677-692},
  shortjournal = {Cogn. Comput.},
  title        = {Frontal intrinsic connectivity networks support contradiction identification during inductive and deductive reasoning},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An integrated deep learning and belief rule base intelligent
system to predict survival of COVID-19 patient under uncertainty.
<em>CC</em>, <em>14</em>(2), 660–676. (<a
href="https://doi.org/10.1007/s12559-021-09978-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novel Coronavirus-induced disease COVID-19 is the biggest threat to human health at the present time, and due to the transmission ability of this virus via its conveyor, it is spreading rapidly in almost every corner of the globe. The unification of medical and IT experts is required to bring this outbreak under control. In this research, an integration of both data and knowledge-driven approaches in a single framework is proposed to assess the survival probability of a COVID-19 patient. Several neural networks pre-trained models: Xception, InceptionResNetV2, and VGG Net, are trained on X-ray images of COVID-19 patients to distinguish between critical and non-critical patients. This prediction result, along with eight other significant risk factors associated with COVID-19 patients, is analyzed with a knowledge-driven belief rule-based expert system which forms a probability of survival for that particular patient. The reliability of the proposed integrated system has been tested by using real patient data and compared with expert opinion, where the performance of the system is found promising.},
  archive      = {J_CC},
  author       = {Ahmed, Tawsin Uddin and Jamil, Mohammad Newaj and Hossain, Mohammad Shahadat and Islam, Raihan Ul and Andersson, Karl},
  doi          = {10.1007/s12559-021-09978-8},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {660-676},
  shortjournal = {Cogn. Comput.},
  title        = {An integrated deep learning and belief rule base intelligent system to predict survival of COVID-19 patient under uncertainty},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic assessment of motor impairments in autism spectrum
disorders: A systematic review. <em>CC</em>, <em>14</em>(2), 624–659.
(<a href="https://doi.org/10.1007/s12559-021-09940-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) is mainly described as a disorder of communication and socialization. However, motor abnormalities are also common in ASD. New technologies may offer quantitative and automatic metrics to measure movement difficulties. We sought to identify computational methods to automatize the assessment of motor impairments in ASD. We systematically searched for the terms ’autism’, ’movement’, ’automatic’, ’computational’ and ’engineering’ in IEEE (Institute of Electrical and Electronics Engineers), Medline and Scopus databases and reviewed the literature from inception to 2018. We included all articles discussing: (1) automatic assessment/new technologies, (2) motor behaviours and (3) children with ASD. We excluded studies that included patient’s or parent’s reported outcomes as online questionnaires that focused on computational models of movement, but also eye tracking, facial emotion or sleep. In total, we found 53 relevant articles that explored static and kinetic equilibrium, like posture, walking, fine motor skills, motor synchrony and movements during social interaction that can be impaired in individuals with autism. Several devices were used to capture relevant motor information such as cameras, 3D cameras, motion capture systems, accelerometers. Interestingly, since 2012, the number of studies increased dramatically as technologies became less invasive, more precise and more affordable. Open-source software has enabled the extraction of relevant data. In a few cases, these technologies have been implemented in serious games, like “Pictogram Room”, to measure the motor status and the progress of children with ASD. Movement computing opens new perspectives for patient assessment in ASD research, enabling precise characterizations in experimental and at-home settings, and a better understanding of the role of sensorimotor disturbances in the development of social cognition and ASD. These methods would likely enable researchers and clinicians to better distinguish ASD from other motors disorders while facilitating an improved monitoring of children’s progress in more ecological settings (i.e. at home or school).},
  archive      = {J_CC},
  author       = {Gargot, Thomas and Archambault, Dominique and Chetouani, Mohamed and Cohen, David and Johal, Wafa and Anzalone, Salvatore Maria},
  doi          = {10.1007/s12559-021-09940-8},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {624-659},
  shortjournal = {Cogn. Comput.},
  title        = {Automatic assessment of motor impairments in autism spectrum disorders: A systematic review},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Centroid coordinate ranking of pythagorean fuzzy numbers and
its application in group decision making. <em>CC</em>, <em>14</em>(2),
602–623. (<a href="https://doi.org/10.1007/s12559-021-09976-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive computing contains different cognitive characteristics, especially when dealing with group decision-making problems, it is considered as a cognitive-based human behavior, in which collecting and processing data from multiple resources is an important stage. Intuitionistic fuzzy number (IFN) and Pythagorean fuzzy number (PFN) are the most reliable tools to deal with fuzzy information by utilizing membership and non-membership, where the distance measure and similarity of IFNs or PFNs play an important role in dealing with incomplete information in order to achieve the final decision and PFN is a generalization of IFN. Motivated by these, some important concepts for PFNs are proposed by geometric methods to deal with group decision-making problems in this paper. Through counter examples, it is pointed out that the score function and accuracy function of PFNs are inconsistent with the traditional ranking rules of IFNs, the concepts of the centroid coordinate and hesitation factor are proposed by geometric distance. In addition, Pythagorean fuzzy distance measure (PFDM) through the centroid coordinate and hesitation factor are introduced, and proved the distance measure satisfies the axiomatic conditions of distance, a calculation example is given in the form of tables. A unified ranking method for IFNs and PFNs is given by comparing with the smallest PFN (0,1). The weight vector, positive or negative ideal solution is calculated by aggregating centroid coordinate matrices, a new TOPSIS method is given by using Pythagorean fuzzy weighted distance (PFWD) and relative closeness. These results show that the decision matrix and positive (negative) ideal solutions represented by the centroid coordinate and hesitation factor can reflect the fuzzy information more comprehensively. The proposed method not only has a wide range of application, but also reduces the loss of information and is easier to be implemented. It is only applied to the multi criteria decision making problem for the first time, it also has some other good properties that need to be further explored and supplemented. This provides a theoretical basis for studying the wide application of Pythagorean fuzzy sets.},
  archive      = {J_CC},
  author       = {Sun, Gang and Wang, Mingxin and Li, Xiaoping},
  doi          = {10.1007/s12559-021-09976-w},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {602-623},
  shortjournal = {Cogn. Comput.},
  title        = {Centroid coordinate ranking of pythagorean fuzzy numbers and its application in group decision making},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Resonating minds—emergent collaboration through hierarchical
active inference. <em>CC</em>, <em>14</em>(2), 581–601. (<a
href="https://doi.org/10.1007/s12559-021-09960-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Working together on complex collaborative tasks requires agents to coordinate their actions. Doing this explicitly or completely prior to the actual interaction is not always possible nor sufficient. Agents also need to continuously understand the current actions of others and quickly adapt their own behavior appropriately. Here we investigate how efficient, automatic coordination processes at the level of mental states (intentions, goals), which we call belief resonance, can lead to collaborative situated problem-solving. We present a model of hierarchical active inference for collaborative agents (HAICA). It combines efficient Bayesian Theory of Mind processes with a perception–action system based on predictive processing and active inference. Belief resonance is realized by letting the inferred mental states of one agent influence another agent’s predictive beliefs about its own goals and intentions. This way, the inferred mental states influence the agent’s own task behavior without explicit collaborative reasoning. We implement and evaluate this model in the Overcooked domain, in which two agents with varying degrees of belief resonance team up to fulfill meal orders. Our results demonstrate that agents based on HAICA achieve a team performance comparable to recent state-of-the-art approaches, while incurring much lower computational costs. We also show that belief resonance is especially beneficial in settings where the agents have asymmetric knowledge about the environment. The results indicate that belief resonance and active inference allow for quick and efficient agent coordination and thus can serve as a building block for collaborative cognitive agents.},
  archive      = {J_CC},
  author       = {Pöppel, Jan and Kahl, Sebastian and Kopp, Stefan},
  doi          = {10.1007/s12559-021-09960-4},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {581-601},
  shortjournal = {Cogn. Comput.},
  title        = {Resonating Minds—Emergent collaboration through hierarchical active inference},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive three-way c-means clustering based on the cognition
of distance stability. <em>CC</em>, <em>14</em>(2), 563–580. (<a
href="https://doi.org/10.1007/s12559-021-09965-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft clustering can be regarded as a cognitive computing method that seeks to deal with the clustering with fuzzy boundary. As a classical soft clustering algorithm, rough k-means (RKM) has yielded various extensions. However, some challenges remain in existing RKM extensions. On the one hand, the user-defined cutoff threshold is subjective and cannot be changed during iteration. On the other hand, the weight of the object to the cluster center is calculated by membership grade and a subjective parameter, that is, the fuzzifier, which complicates the issue and reduces the robustness of the algorithm. In this paper, inspired by human cognition of distance stability, an adaptive three-way c-means algorithm is proposed. First, in human cognition, objects are clustered according to the stability of their distance to the clusters, and variance is an effective way to measure the stability of data. Based on this, an adaptive cutoff threshold is introduced by determining the maximum increment between the variances of distance. Second, based on the cognition that distance is inversely proportional to weight, the weight equation is defined by distance without introducing any subjective parameters. Then, combined with the adaptive cutoff threshold and weight equation, A-3WCM is proposed. The experimental results show that A-3WCM exhibits excellent performance and outperforms five representative algorithms related to RKM on nine popular datasets.},
  archive      = {J_CC},
  author       = {Shen, Qiuping and Zhang, Qinghua and Zhao, Fan and Wang, Guoyin},
  doi          = {10.1007/s12559-021-09965-z},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {563-580},
  shortjournal = {Cogn. Comput.},
  title        = {Adaptive three-way C-means clustering based on the cognition of distance stability},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance evaluation of human resources based on
linguistic neutrosophic maclaurin symmetric mean operators. <em>CC</em>,
<em>14</em>(2), 547–562. (<a
href="https://doi.org/10.1007/s12559-021-09963-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For corporates, the performance evaluation of human resources is always a significant strategic activity based on cognitive information. This study aims to develop a novel decision-making method with the computation of cognitive information to make assessments of human resources. First, the cognitive information is described by means of linguistic neutrosophic numbers (LNNs) to capture aspects of indeterminacy and fuzziness. Then, as the Maclaurin symmetric mean (MSM) operators can reflect the interrelations among multiple inputs, several extended MSM operators are proposed to aggregate cognitive information in the linguistic neutrosophic environments. Meanwhile, some important properties of these operators are justified. Thereafter, a linguistic neutrosophic decision-making method based on MSM operators is introduced to address qualitative evaluation problems during cognitive processes. Finally, the validity of our method is revealed by presenting a case study of selecting the best employee in a company. Moreover, the advantages of the proposed method are highlighted by the discussion of the effect of the parameter existing in aggregation operators and the comparison with other methods. The results show that the proposed method is feasible and the study can provide guidelines for the performance evaluation and management of human resources. The utilization of LNNs enriches the expression of cognitive information. Furthermore, the proposed method can be regarded as a potential choice for disposing of cognitive computation.},
  archive      = {J_CC},
  author       = {Luo, Sui-zhi and Xing, Li-ning and Ren, Teng},
  doi          = {10.1007/s12559-021-09963-1},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {547-562},
  shortjournal = {Cogn. Comput.},
  title        = {Performance evaluation of human resources based on linguistic neutrosophic maclaurin symmetric mean operators},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fuzzy collaborative intelligence approach to group
decision-making: A case study of post-COVID-19 restaurant
transformation. <em>CC</em>, <em>14</em>(2), 531–546. (<a
href="https://doi.org/10.1007/s12559-021-09989-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a fuzzy group decision-making task, when decision makers lack consensus, existing methods either ignore this fact or force a decision maker to modify his/her judgment. However, these actions may be unreasonable. In this study, a fuzzy collaborative intelligence approach that seeks the consensus among experts in a novel way is proposed. Fuzzy collaborative intelligence is the application of biologically inspired fuzzy logic to a group task. The proposed methodology is based on the fact that a decision maker must make a choice even if he/she is uncertain. As a result, the decision maker’s fuzzy judgment matrix may not be able to represent his/her judgment. To solve such a problem, the fuzzy judgment matrix of each decision maker is decomposed into several fuzzy judgment submatrices. From the fuzzy judgment submatrices of all decision makers, a consensus can be easily identified. The proposed fuzzy collaborative intelligence approach and several existing methods have been applied to the case of the post-COVID-19 transformation of a Japanese restaurant in Taiwan. Because such transformation was beyond the expectation of the Japanese restaurant, the employees lacked consensus if existing methods were applied to identify their consensus. The proposed methodology solved this problem. The optimal transformation plan involved increasing the distance between tables, erecting screens between tables, and improving air circulation. In a fuzzy group decision-making task, an acceptable decision cannot be made without the consensus among decision makers. Ignoring this or forcing decision makers to modify their preferences is unreasonable. Identifying the consensus among experts from another point of view is a viable treatment.},
  archive      = {J_CC},
  author       = {Chen, Toly and Chiu, Min-Chi},
  doi          = {10.1007/s12559-021-09989-5},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {531-546},
  shortjournal = {Cogn. Comput.},
  title        = {A fuzzy collaborative intelligence approach to group decision-making: A case study of post-COVID-19 restaurant transformation},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cognitively inspired multi-attribute decision-making methods
under uncertainty: A state-of-the-art survey. <em>CC</em>,
<em>14</em>(2), 511–530. (<a
href="https://doi.org/10.1007/s12559-021-09916-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decades, the art and science of multi-attribute decision-making (MADM) have witnessed significant developments and have found applications in many active areas. A lot of research has demonstrated the ability of cognitive techniques in dealing with complex and uncertain decision information. The purpose of representing human cognition in the decision-making process encourages the integration of cognitive psychology and multi-attribute decision-making theory. Due to the emergence of research on cognitively inspired MADM methods, we make a comprehensive overview of published papers in this field and their applications. This paper has been grouped into five parts: we first conduct some statistical analyses of academic papers from two angles: the development trends and the distribution of related publications. To illustrate the basic process of cognitively inspired MADM methods, we present some underlying ideas and the systematic structure of this kind of method. Then, we make a review of cognitively inspired MADM methods from different perspectives. Applications of these methods are further reviewed. Finally, some challenges and future trends are summarized. This paper highlights the benefits of the synergistic approach that is developed based on cognitive techniques and MADM methods and identifies the frontiers in this field.},
  archive      = {J_CC},
  author       = {Wu, Hangyao and Xu, Zeshui},
  doi          = {10.1007/s12559-021-09916-8},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {511-530},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitively inspired multi-attribute decision-making methods under uncertainty: A state-of-the-art survey},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Differential privacy in cognitive radio networks: A
comprehensive survey. <em>CC</em>, <em>14</em>(2), 475–510. (<a
href="https://doi.org/10.1007/s12559-021-09969-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating cognitive radio (CR) with traditional wireless networks is helping solve the problem of spectrum scarcity in an efficient manner. The opportunistic and dynamic spectrum access features of CR provide the functionality to its unlicensed users to utilize the underutilized spectrum at the time of need because CR nodes can sense vacant bands of spectrum and can also access them to carry out communication. Various capabilities of CR nodes depend upon efficient and continuous reporting of data with each other and centralized base stations, which in turn can cause leakage in privacy. Experimental studies have shown that the privacy of CR users can be compromised easily during the cognition cycle, because they are knowingly or unknowingly sharing various personally identifiable information (PII), such as location, device ID, signal status, etc. In order to preserve this privacy leakage, various privacy preserving strategies have been developed by researchers, and according to us differential privacy is the most significant among them. In this article, we provide a thorough survey on how differential privacy can play an active role in preserving privacy of cognitive radio networks (CRN). Firstly, we provide a thorough comparison of our work with other similar studies to show its novelty and contribution, and afterwards, we provide a thorough analysis from the perspective of various CR scenarios which can cause privacy leakage. After that, we carry out an in-depth assessment from the perspective of integration of differential privacy at different levels of CRN. Then, we discuss various parameters which should be considered while integrating differential privacy in CRN alongside providing a comprehensive discussion about all integrations of differential privacy carried out till date. Finally, we provide discussion about prospective applications, challenges, and future research directions. The discussion about integration of differential privacy in different CR scenarios indicates that differential privacy is one of the most viable mechanisms to preserve privacy of CRN in modern day scenarios. From the discussion in the article, it is evident that the proposed integration of differential privacy can pave the way for futuristic CRN in which CR users will be able to share information during the cognition cycle without the risk of losing their private information.},
  archive      = {J_CC},
  author       = {Ul Hassan, Muneeb and Rehmani, Mubashir Husain and Rehan, Maaz and Chen, Jinjun},
  doi          = {10.1007/s12559-021-09969-9},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {475-510},
  shortjournal = {Cogn. Comput.},
  title        = {Differential privacy in cognitive radio networks: A comprehensive survey},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Single and cross-disorder detection for autism and
schizophrenia. <em>CC</em>, <em>14</em>(1), 461–473. (<a
href="https://doi.org/10.1007/s12559-021-09834-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of mental disorders from textual input is an emerging field for applied machine and deep learning methods. Here, we explore the limits of automated detection of autism spectrum disorder (ASD) and schizophrenia (SCZ). We compared the performance of: (1) dedicated diagnostic tools that involve collecting textual data, (2) automated methods applied to the data gathered by these tools, and (3) psychiatrists. Our article tests the effectiveness of several baseline approaches, such as bag of words and dictionary-based vectors, followed by a machine learning model. We employed two more refined Sentic text representations using affective features and concept-level analysis on texts. Further, we applied selected state-of-the-art deep learning methods for text representation and inference, as well as experimented with transfer and zero-shot learning. Finally, we also explored few-shot methods dedicated to low data size scenarios, which is a typical problem for the clinical setting. The best breed of automated methods outperformed human raters (psychiatrists). Cross-dataset approaches turned out to be useful (only from SCZ to ASD) despite different data types. The few-shot learning methods revealed promising results on the SCZ dataset. However, more effort is needed to explore the approaches to efficiently training models, given the very limited amounts of labeled clinical data. Psychiatry is one of the few medical fields in which the diagnosis of most disorders is based on the subjective assessment of a psychiatrist. Therefore, the introduction of objective tools supporting diagnostics seems to be pivotal. This paper is a step in this direction.},
  archive      = {J_CC},
  author       = {Wawer, Aleksander and Chojnicka, Izabela and Okruszek, Lukasz and Sarzynska-Wawer, Justyna},
  doi          = {10.1007/s12559-021-09834-9},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {461-473},
  shortjournal = {Cogn. Comput.},
  title        = {Single and cross-disorder detection for autism and schizophrenia},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatically building financial sentiment lexicons while
accounting for negation. <em>CC</em>, <em>14</em>(1), 442–460. (<a
href="https://doi.org/10.1007/s12559-021-09833-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial investors make trades based on available information. Previous research has proved that microblogs are a useful source for supporting stock market decisions. However, the financial domain lacks specific sentiment lexicons that could be utilized to extract the sentiment from these microblogs. In this research, we investigate automatic approaches that can be used to build financial sentiment lexicons. We introduce weighted versions of the Pointwise Mutual Information approaches to build sentiment lexicons automatically. Furthermore, existing sentiment lexicons often neglect negation while building the sentiment lexicons. In this research, we also propose two methods (Negated Word and Flip Sentiment) to extend the sentiment building approaches to take into account negation when constructing a sentiment lexicon. We build the financial sentiment lexicons by leveraging 200,000 messages from StockTwits. We evaluate the constructed financial sentiment lexicons in two different sentiment classification tasks (unsupervised and supervised). In addition, the created financial sentiment lexicons are compared with each other and with other existing sentiment lexicons. The best performing financial sentiment lexicon is built by combining our Weighted Normalized Pointwise Mutual Information approach with the Negated Word approach. It outperforms all the other sentiment lexicons in the two sentiment classification tasks. In the unsupervised sentiment classification task, it has, on average, a balanced accuracy of 69.4%, and in the supervised setting, a balanced accuracy of 75.1%. Moreover, the various sentiment classification tasks confirm that the sentiment lexicons could be improved by taking into account negation while building the sentiment lexicons. The improvement could be made by using one of the proposed methods to incorporate negation in the sentiment lexicon construction process.},
  archive      = {J_CC},
  author       = {Bos, Thomas and Frasincar, Flavius},
  doi          = {10.1007/s12559-021-09833-w},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {442-460},
  shortjournal = {Cogn. Comput.},
  title        = {Automatically building financial sentiment lexicons while accounting for negation},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incremental word vectors for time-evolving sentiment lexicon
induction. <em>CC</em>, <em>14</em>(1), 425–441. (<a
href="https://doi.org/10.1007/s12559-021-09831-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A sentiment lexicon is a list of expressions annotated according to affect categories such as positive, negative, anger and fear. Lexicons are widely used in sentiment classification of tweets, especially when labeled messages are scarce. Sentiment lexicons are prone to obsolescence due to: 1) the arrival of new sentiment-conveying expressions such as #trumpwall and #PrayForParis and 2) temporal changes in sentiment patterns of words (e.g., a scandal associated with an entity). In this paper, we propose a methodology for automatically inducing continuously updated sentiment lexicons from Twitter streams by training incremental word sentiment classifiers from time-evolving distributional word vectors. We experiment with various sketching techniques for efficiently building incremental word context matrices and study how the lexicon adapts to drastic changes in the sentiment pattern. Change is simulated by randomly picking some words from a testing partition of words and swapping their context with the context of words exhibiting the opposite sentiment. Our experimental results show that our approach allows for successfully tracking of the sentiment of words over time even when drastic change is induced.},
  archive      = {J_CC},
  author       = {Bravo-Marquez, Felipe and Khanchandani, Arun and Pfahringer, Bernhard},
  doi          = {10.1007/s12559-021-09831-y},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {425-441},
  shortjournal = {Cogn. Comput.},
  title        = {Incremental word vectors for time-evolving sentiment lexicon induction},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distant supervised construction and evaluation of a novel
dataset of emotion-tagged social media comments in spanish. <em>CC</em>,
<em>14</em>(1), 407–424. (<a
href="https://doi.org/10.1007/s12559-020-09800-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tagged language resources are an essential requirement for developing machine-learning text-based classifiers. However, manual tagging is extremely time consuming and the resulting datasets are rather small, containing only a few thousand samples. Basic emotion datasets are particularly difficult to classify manually because categorization is prone to subjectivity, and thus, redundant classification is required to validate the assigned tag. Even though, in recent years, the amount of emotion-tagged text datasets in Spanish has been growing, it cannot be compared with the number, size, and quality of the datasets in English. Quality is a particularly concerning issue, as not many datasets in Spanish included a validation step in the construction process. In this article, a dataset of social media comments in Spanish is compiled, selected, filtered, and presented. A sample of the dataset is reclassified by a group of psychologists and validated using the Fleiss Kappa interrater agreement measure. Error analysis is performed by using the Sentic Computing tool BabelSenticNet. Results indicate that the agreement between the human raters and the automatically acquired tag is moderate, similar to other manually tagged datasets, with the advantages that the presented dataset contains several hundreds of thousands of tagged comments and it does not require extensive manual tagging. The agreement measured between human raters is very similar to the one between human raters and the original tag. Every measure presented is in the moderate agreement zone and, as such, suitable for training classification algorithms in sentiment analysis field.},
  archive      = {J_CC},
  author       = {Tessore, Juan Pablo and Esnaola, Leonardo Martín and Lanzarini, Laura and Baldassarri, Sandra},
  doi          = {10.1007/s12559-020-09800-x},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {407-424},
  shortjournal = {Cogn. Comput.},
  title        = {Distant supervised construction and evaluation of a novel dataset of emotion-tagged social media comments in spanish},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Words, tweets, and reviews: Leveraging affective knowledge
between multiple domains. <em>CC</em>, <em>14</em>(1), 388–406. (<a
href="https://doi.org/10.1007/s12559-021-09923-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three popular application domains of sentiment and emotion analysis are: 1) the automatic rating of movie reviews, 2) extracting opinions and emotions on Twitter, and 3) inferring sentiment and emotion associations of words. The textual elements of these domains differ in their length, i.e., movie reviews are usually longer than tweets and words are obviously shorter than tweets, but they also share the property that they can be plausibly annotated according to the same affective categories (e.g., positive, negative, anger, joy). Moreover, state-of-the-art models for these domains are all based on the approach of training supervised machine learning models on manually annotated examples. This approach suffers from an important bottleneck: Manually annotated examples are expensive and time-consuming to obtain and not always available. In this paper, we propose a method for transferring affective knowledge between words, tweets, and movie reviews using two representation techniques: Word2Vec static embeddings and BERT contextualized embeddings. We build compatible representations for movie reviews, tweets, and words, using these techniques, and train and evaluate supervised models on all combinations of source and target domains. Our experimental results show that affective knowledge can be successfully transferred between our three domains, that contextualized embeddings tend to outperform their static counterparts, and that better transfer learning results are obtained when the source domain has longer textual units than the target domain.},
  archive      = {J_CC},
  author       = {Bravo-Marquez, Felipe and Tamblay, Cristián},
  doi          = {10.1007/s12559-021-09923-9},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {388-406},
  shortjournal = {Cogn. Comput.},
  title        = {Words, tweets, and reviews: Leveraging affective knowledge between multiple domains},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Does twitter affect stock market decisions? Financial
sentiment analysis during pandemics: A comparative study of the H1N1 and
the COVID-19 periods. <em>CC</em>, <em>14</em>(1), 372–387. (<a
href="https://doi.org/10.1007/s12559-021-09819-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investors are constantly aware of the behaviour of stock markets. This affects their emotions and motivates them to buy or sell shares. Financial sentiment analysis allows us to understand the effect of social media reactions and emotions on the stock market and vice versa. In this research, we analyse Twitter data and important worldwide financial indices to answer the following question: How does the polarity generated by Twitter posts influence the behaviour of financial indices during pandemics? This study is based on the financial sentiment analysis of influential Twitter accounts and its relationship with the behaviour of important financial indices. To carry out this analysis, we used fundamental and technical financial analysis combined with a lexicon-based approach on financial Twitter accounts. We calculated the correlations between the polarities of financial market indicators and posts on Twitter by applying a date shift on tweets. In addition, correlations were identified days before and after the existing posts on financial Twitter accounts. Our findings show that the markets reacted 0 to 10 days after the information was shared and disseminated on Twitter during the COVID-19 pandemic and 0 to 15 days after the information was shared and disseminated on Twitter during the H1N1 pandemic. We identified an inverse relationship: Twitter accounts presented reactions to financial market behaviour within a period of 0 to 11 days during the H1N1 pandemic and 0 to 6 days during the COVID-19 pandemic. We also found that our method is better at detecting highly shifted correlations by using SenticNet compared with other lexicons. With SenticNet, it is possible to detect correlations even on the same day as the Twitter posts. The most influential Twitter accounts during the period of the pandemic were The New York Times, Bloomberg, CNN News and Investing.com, presenting a very high correlation between sentiments on Twitter and stock market behaviour. The combination of a lexicon-based approach is enhanced by a shifted correlation analysis, as latent or hidden correlations can be found in data.},
  archive      = {J_CC},
  author       = {Valle-Cruz, David and Fernandez-Cortez, Vanessa and López-Chau, Asdrúbal and Sandoval-Almazán, Rodrigo},
  doi          = {10.1007/s12559-021-09819-8},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {372-387},
  shortjournal = {Cogn. Comput.},
  title        = {Does twitter affect stock market decisions? financial sentiment analysis during pandemics: A comparative study of the H1N1 and the COVID-19 periods},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). To BAN or not to BAN: Bayesian attention networks for
reliable hate speech detection. <em>CC</em>, <em>14</em>(1), 353–371.
(<a href="https://doi.org/10.1007/s12559-021-09826-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hate speech is an important problem in the management of user-generated content. To remove offensive content or ban misbehaving users, content moderators need reliable hate speech detectors. Recently, deep neural networks based on the transformer architecture, such as the (multilingual) BERT model, have achieved superior performance in many natural language classification tasks, including hate speech detection. So far, these methods have not been able to quantify their output in terms of reliability. We propose a Bayesian method using Monte Carlo dropout within the attention layers of the transformer models to provide well-calibrated reliability estimates. We evaluate and visualize the results of the proposed approach on hate speech detection problems in several languages. Additionally, we test whether affective dimensions can enhance the information extracted by the BERT model in hate speech classification. Our experiments show that Monte Carlo dropout provides a viable mechanism for reliability estimation in transformer networks. Used within the BERT model, it offers state-of-the-art classification performance and can detect less trusted predictions.},
  archive      = {J_CC},
  author       = {Miok, Kristian and Škrlj, Blaž and Zaharie, Daniela and Robnik-Šikonja, Marko},
  doi          = {10.1007/s12559-021-09826-9},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {353-371},
  shortjournal = {Cogn. Comput.},
  title        = {To BAN or not to BAN: Bayesian attention networks for reliable hate speech detection},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Emotionally informed hate speech detection: A multi-target
perspective. <em>CC</em>, <em>14</em>(1), 322–352. (<a
href="https://doi.org/10.1007/s12559-021-09862-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hate Speech and harassment are widespread in online communication, due to users&#39; freedom and anonymity and the lack of regulation provided by social media platforms. Hate speech is topically focused (misogyny, sexism, racism, xenophobia, homophobia, etc.), and each specific manifestation of hate speech targets different vulnerable groups based on characteristics such as gender (misogyny, sexism), ethnicity, race, religion (xenophobia, racism, Islamophobia), sexual orientation (homophobia), and so on. Most automatic hate speech detection approaches cast the problem into a binary classification task without addressing either the topical focus or the target-oriented nature of hate speech. In this paper, we propose to tackle, for the first time, hate speech detection from a multi-target perspective. We leverage manually annotated datasets, to investigate the problem of transferring knowledge from different datasets with different topical focuses and targets. Our contribution is threefold: (1) we explore the ability of hate speech detection models to capture common properties from topic-generic datasets and transfer this knowledge to recognize specific manifestations of hate speech; (2) we experiment with the development of models to detect both topics (racism, xenophobia, sexism, misogyny) and hate speech targets, going beyond standard binary classification, to investigate how to detect hate speech at a finer level of granularity and how to transfer knowledge across different topics and targets; and (3) we study the impact of affective knowledge encoded in sentic computing resources (SenticNet, EmoSenticNet) and in semantically structured hate lexicons (HurtLex) in determining specific manifestations of hate speech. We experimented with different neural models including multitask approaches. Our study shows that: (1) training a model on a combination of several (training sets from several) topic-specific datasets is more effective than training a model on a topic-generic dataset; (2) the multi-task approach outperforms a single-task model when detecting both the hatefulness of a tweet and its topical focus in the context of a multi-label classification approach; and (3) the models incorporating EmoSenticNet emotions, the first level emotions of SenticNet, a blend of SenticNet and EmoSenticNet emotions or affective features based on Hurtlex, obtained the best results. Our results demonstrate that multi-target hate speech detection from existing datasets is feasible, which is a first step towards hate speech detection for a specific topic/target when dedicated annotated data are missing. Moreover, we prove that domain-independent affective knowledge, injected into our models, helps finer-grained hate speech detection.},
  archive      = {J_CC},
  author       = {Chiril, Patricia and Pamungkas, Endang Wahyu and Benamara, Farah and Moriceau, Véronique and Patti, Viviana},
  doi          = {10.1007/s12559-021-09862-5},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {322-352},
  shortjournal = {Cogn. Comput.},
  title        = {Emotionally informed hate speech detection: A multi-target perspective},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mood of the planet: Challenging visions of big data in the
arts. <em>CC</em>, <em>14</em>(1), 310–321. (<a
href="https://doi.org/10.1007/s12559-020-09766-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mood of the Planet is an interactive physical-digital sculpture that has as its center-piece a large “arch” or “doorway” that emits colored light and sound as a form of visualization and sonification of the changing, live emotions expressed by people all around the Earth. It is the product of several disciplines, including the arts, computer science, linguistics and psychology. In particular, we use artificial intelligence to collect and analyze social media data and extract emotions from these using a brain-inspired and psychologically motivated emotion categorization model. Such emotions are then translated into colors and sounds that the audience can experience while passing through the arch. Feedback from the audience proved the Mood of the Planet to provide a more accurate, personal and tangible experience about the data-emotions dichotomy.},
  archive      = {J_CC},
  author       = {Sorensen, Vibeke and Lansing, John Stephen and Thummanapalli, Nagaraju and Cambria, Erik},
  doi          = {10.1007/s12559-020-09766-w},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {310-321},
  shortjournal = {Cogn. Comput.},
  title        = {Mood of the planet: Challenging visions of big data in the arts},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Context aware sentiment link prediction in heterogeneous
social network. <em>CC</em>, <em>14</em>(1), 300–309. (<a
href="https://doi.org/10.1007/s12559-021-09830-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People often express opinions towards others in a social network, causing sentiment links to form among users. To develop effective methods for discovering implicit sentiment links among users, the extraction and exploitation of structural semantic information from heterogeneous social networks are of great importance. We propose a novel heterogeneous social network embedding-based approach for sentiment link prediction that takes both global structural information with multi-dimensional relations and heterogeneous context information into consideration to leverage rich and intrinsic association information. Specifically, the attributed heterogeneous social network and Sentic LSTM-based sentiment link network are employed to incorporate various explicit context knowledge and implicit multi-dimensional user interaction association knowledge into representation learning and sentiment link prediction. The experimental results on a real-world dataset show that the proposed approach has advantages over the state-of-the-art baselines. The results show the effectiveness of incorporating social relations and profile context information into sentiment link prediction, especially in cold-start scenarios. The learned embedding representation that incorporates both structural information with multi-dimensional relations and context information from heterogeneous social networks can improve sentiment link prediction performance. The proposed approach is effective and feasible for detecting unobserved sentiment links from online social networks and outperforms the state-of-the-art baselines in sentiment link prediction tasks.},
  archive      = {J_CC},
  author       = {Zhao, Anping and Yu, Yu},
  doi          = {10.1007/s12559-021-09830-z},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {300-309},
  shortjournal = {Cogn. Comput.},
  title        = {Context aware sentiment link prediction in heterogeneous social network},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Affective concept-based encoding of patient narratives via
sentic computing and neural networks. <em>CC</em>, <em>14</em>(1),
274–299. (<a href="https://doi.org/10.1007/s12559-021-09903-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic generation of features without human intervention is the most critical task for biomedical sentiment analysis. Regarding the high dynamicity of shared patient narrative data, the lack of formal medical language sentiment dictionaries prevents retrieval of the appropriate sentiment, which is unapproachable and can be prone to annotator bias. We propose a novel affective biomedical concept-based encoding via sentic computing and neural networks. The main contributions include four aspects. First, a biomedical embedding, in which a medical entity is defined, normalized, and synthesized from a text, is built using online patient narratives after being combined with label propagation from a widely used comprehensive biomedical vocabulary. Second, considering the dependence on biomedical definitions, drug reaction sample selection based on general matching is suggested. These feature settings are then used to build and recognize affective semantics and sentics based on an extreme learning machine. Finally, a semisupervised LSTM-BiLSTM model for biomedical sentiment analysis is constructed. There was a massive influx of patient self-reports related to the COVID-19 pandemic. A study was conducted in this direction, and we tested the validity, medical language familiarity, and transferability of our approach by analyzing millions of COVID-19 tweets. Comparisons to affective lexicons also indicate that integrating extreme learning machine cognitive capabilities has advantages over biomedical sentiment analysis. By considering sentics vectors on top of the formed embeddings, our semisupervised LSTM-BiLSTM achieved an accuracy of 87.5%. The evaluations of unsupervised learning approximated the results of the previous model when dealing with a serious loss of biomedical data. In this paper, we demonstrate the effectiveness of integrating deep-learning-based cognitive capabilities for both enhancing distributed biomedical definitions and inferring sentiment compositions from many patient self-reports on social networks. The relevant encoding of affective information conveyed regarding medication subjects clearly reveals defined roles and expectations that can have a positive impact on public health.},
  archive      = {J_CC},
  author       = {Grissette, Hanane and Nfaoui, El Habib},
  doi          = {10.1007/s12559-021-09903-z},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {274-299},
  shortjournal = {Cogn. Comput.},
  title        = {Affective concept-based encoding of patient narratives via sentic computing and neural networks},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design and deployment of an image polarity detector with
visual attention. <em>CC</em>, <em>14</em>(1), 261–273. (<a
href="https://doi.org/10.1007/s12559-021-09829-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding the ability of sentiment analysis in smart devices is especially challenging because sentiment analysis relies on deep neural networks, in particular, convolutional neural networks. The paper presents a novel hardware-friendly detector of image polarity, enhanced with the ability of saliency detection. The approach stems from a hardware-oriented design process, which trades off prediction accuracy and computational resources. The eventual solution combines lightweight deep-learning architectures and post-training quantization. Experimental results on standard benchmarks confirmed that the design strategy can infer automatically the salient parts and the polarity of an image with high accuracy. Saliency-based solutions in the literature prove impractical due to their considerable computational costs; the paper shows that the novel design strategy can deploy and perform successfully on a variety of commercial smartphones, yielding real-time performances.},
  archive      = {J_CC},
  author       = {Ragusa, Edoardo and Apicella, Tommaso and Gianoglio, Christian and Zunino, Rodolfo and Gastaldo, Paolo},
  doi          = {10.1007/s12559-021-09829-6},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {261-273},
  shortjournal = {Cogn. Comput.},
  title        = {Design and deployment of an image polarity detector with visual attention},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards sentiment-aware multi-modal dialogue policy
learning. <em>CC</em>, <em>14</em>(1), 246–260. (<a
href="https://doi.org/10.1007/s12559-020-09769-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creation of task-oriented dialog/virtual agent (VA) capable of managing complex domain-specific user queries pertaining to multiple intents is difficult since the agent must deal with several subtasks simultaneously. Most end-to-end dialogue systems, however, only provide user semantics as inputs from texts into the learning process and neglect other useful user behaviour and information from other modalities such as images. This stresses the benefit of incorporating multi-modal inputs for eliciting user preference in the task. Also, sentiment of the user plays a significant role in achieving maximum user/customer satisfaction during the conversation. Thus, it is also important to incorporate users’ sentiments during policy learning, especially when serving user’s composite goals. For the creation of multi-modal VA aided with sentiment for conversations encompassing multi-intents, this paper introduces a new dataset, named Vis-SentiVA: Visual and Sentiment aided VA created from open-accessed conversational dataset. We present a hierarchical reinforcement learning (HRL) typically options-based VA to learn policies for serving multi-intent dialogues. Multi-modal information (texts and images) extraction to identify user’s preference is incorporated in the learning framework. A combination of task-based and sentiment-based rewards is integrated in the hierarchical value functions for the VA to be user adaptive. Empirically, we show that all these aspects induced together in the learning framework play a vital role in acquiring higher dialogue task success and increased user contentment in the process of creating composite-natured VAs. This is the first effort in integrating sentiment-aware rewards in the multi-modal HRL framework. The paper highlights that it is indeed essential to include other modes of information extraction such as images and behavioural cues of the user such as sentiment to secure greater user contentment. This also helps in improving success of composite-natured VAs serving task-oriented dialogues.},
  archive      = {J_CC},
  author       = {Saha, Tulika and Saha, Sriparna and Bhattacharyya, Pushpak},
  doi          = {10.1007/s12559-020-09769-7},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {246-260},
  shortjournal = {Cogn. Comput.},
  title        = {Towards sentiment-aware multi-modal dialogue policy learning},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic expansion of domain-specific affective models for
web intelligence applications. <em>CC</em>, <em>14</em>(1), 228–245. (<a
href="https://doi.org/10.1007/s12559-021-09839-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentic computing relies on well-defined affective models of different complexity—polarity to distinguish positive and negative sentiment, for example, or more nuanced models to capture expressions of human emotions. When used to measure communication success, even the most granular affective model combined with sophisticated machine learning approaches may not fully capture an organisation’s strategic positioning goals. Such goals often deviate from the assumptions of standardised affective models. While certain emotions such as Joy and Trust typically represent desirable brand associations, specific communication goals formulated by marketing professionals often go beyond such standard dimensions. For instance, the brand manager of a television show may consider fear or sadness to be desired emotions for its audience. This article introduces expansion techniques for affective models, combining common and commonsense knowledge available in knowledge graphs with language models and affective reasoning, improving coverage and consistency as well as supporting domain-specific interpretations of emotions. An extensive evaluation compares the performance of different expansion techniques: (i) a quantitative evaluation based on the revisited Hourglass of Emotions model to assess performance on complex models that cover multiple affective categories, using manually compiled gold standard data, and (ii) a qualitative evaluation of a domain-specific affective model for television programme brands. The results of these evaluations demonstrate that the introduced techniques support a variety of embeddings and pre-trained models. The paper concludes with a discussion on applying this approach to other scenarios where affective model resources are scarce.},
  archive      = {J_CC},
  author       = {Weichselbraun, Albert and Steixner, Jakob and Braşoveanu, Adrian M.P. and Scharl, Arno and Göbel, Max and Nixon, Lyndon J. B.},
  doi          = {10.1007/s12559-021-09839-4},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {228-245},
  shortjournal = {Cogn. Comput.},
  title        = {Automatic expansion of domain-specific affective models for web intelligence applications},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multitask learning for complaint identification and
sentiment analysis. <em>CC</em>, <em>14</em>(1), 212–227. (<a
href="https://doi.org/10.1007/s12559-021-09844-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s competitive business world, customer service is often at the heart of businesses that can help strengthen their brands. Resolution of customers’ complaints in a timely and efficient manner is key to improving customer satisfaction. Moreover, customers’ complaints play an important role in identifying their requirements which offer a starting point for effective and efficient planning of companies’ overall R&amp;D and new product or service development activities. Having said that, organizations encounter challenges towards automatically identifying complaints buried deep in massive online content. Our current work centers around learning two closely related tasks, viz. complaint identification and sentiment classification. We leverage weak supervision to annotate the corpus with sentiment labels. We propose a deep multitask framework that features a knowledge element that uses AffectiveSpace to infuse commonsense knowledge specific features into the learning process. The framework models complaint identification (the primary task) and sentiment classification (supplementary task) simultaneously. Experimental results show that our proposed multitask system obtains the highest cross-validation accuracy of 83.73 +/- 1.52 % for the complaint identification task and 69.01 +/- 1.74 % for the sentiment classification task. Our proposed multitask system outperforms the single-task systems indicating a strong correlation between sentiment analysis and complaint classification tasks, thus benefiting from each other when learned concurrently.},
  archive      = {J_CC},
  author       = {Singh, Apoorva and Saha, Sriparna and Hasanuzzaman, Md. and Dey, Kuntal},
  doi          = {10.1007/s12559-021-09844-7},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {212-227},
  shortjournal = {Cogn. Comput.},
  title        = {Multitask learning for complaint identification and sentiment analysis},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ordered weighted averaging for emotion-driven polarity
detection. <em>CC</em>, <em>14</em>(1), 194–211. (<a
href="https://doi.org/10.1007/s12559-021-09837-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The overall rating of an opinion can generally be considered as the aggregation of the individual ratings of all features of that opinion. Nevertheless, there are cases in which the overall rating differs substantially from the mean or weighted mean of the ratings of the individual features. These cases can be explained in terms of user mood. To address this problem, this study introduces a fuzzy framework for computing user mood based on SenticNet and sentic patterns, which are used to guide an ordered weighted averaging operator. This operator allows the aggregation to be computed in such a way as to provide an understanding of why some positive or negative aspects are considered to a greater or lesser extent. The performance and advantages of this proposal are illustrated in depth via a variety of scenarios applied to real data. The results show a promising framework applicable to other tools, such as customized recommender systems or decision support systems.},
  archive      = {J_CC},
  author       = {Serrano-Guerrero, Jesus and Romero, Francisco P. and Olivas, Jose A.},
  doi          = {10.1007/s12559-021-09837-6},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {194-211},
  shortjournal = {Cogn. Comput.},
  title        = {Ordered weighted averaging for emotion-driven polarity detection},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid deep learning models for thai sentiment analysis.
<em>CC</em>, <em>14</em>(1), 167–193. (<a
href="https://doi.org/10.1007/s12559-020-09770-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many people use social media in their daily life for entertainment, business, personal communication, and catching up with friends. In social media marketing, sentiment analysis is one of the most popular research topics because it can be employed to perform brand or market research monitoring and to keep an eye on the competitors. Machine learning algorithms have been utilized to carry out the task. In addition, sentiment analysis is essential in cognitive computing. Currently, there are still a limited number of Thai sentiment analysis research. This paper proposes a framework for sentiment analysis in Thai along with Thai-SenticNet5 corpus. The framework employs different types of features, namely, word embedding, part-of-speech, sentic features, and all combinations of these features. Furthermore, we fused deep learning algorithms—convolutional neural network (CNN) and bidirectional long short-term memory (BLSTM)—in different ways and compare it to several other fused combinations. Three datasets in Thai were used in this work: ThaiTales, ThaiEconTwitter, and Wisesight datasets. The experimental results show that combining all three features and fusing deep learning algorithms were able to improve overall performance. The best hybrid deep learning was BLSTM-CNN that achieved F1-scores of 0.7436, 0.7707, and 0.5521, on ThaiTales, ThaiEconTwitter, and Wisesight datasets, respectively. According to the experimental results, we conclude that feature combination and hybrid deep learning algorithms can improve the overall performances.},
  archive      = {J_CC},
  author       = {Pasupa, Kitsuchart and Seneewong Na Ayutthaya, Thititorn},
  doi          = {10.1007/s12559-020-09770-0},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {167-193},
  shortjournal = {Cogn. Comput.},
  title        = {Hybrid deep learning models for thai sentiment analysis},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stock price prediction incorporating market style
clustering. <em>CC</em>, <em>14</em>(1), 149–166. (<a
href="https://doi.org/10.1007/s12559-021-09820-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Market style analysis is critical when designing a stock price prediction framework. Under different market styles, stocks may show quite different behaviors; thus, predictions will vary. Consequently, incorporating market styles into stock price predictions should help improve the prediction performance. In this paper, we investigate how to characterize market styles to improve stock prediction performance under varying market styles. First, stock time series data are divided into windows of different lengths. The windows are summarized and represented by technical indicators and news sentiment features. Second, hierarchical clustering is employed to cluster the windows and categorize their market styles; the window lengths and number of market styles are carefully tuned to achieve the best clustering results. Third, a distance measurement is proposed to distinguish among rotating patterns within the market styles to verify the usability of the market styles. Finally, a stock price prediction framework is constructed to predict future stock price trends based on data belonging to the same market styles. The experiments are conducted with five years of real Hong Kong Stock Exchange data that includes both stock prices and corresponding news. Two famous sentiment dictionaries (i.e., SenticNet 5 and the Loughran-McDonald financial sentiment dictionary 2018) are employed to analyze the news sentiments. Predictive models are compared both with and without incorporating market styles. The results demonstrate that the approach incorporating market styles outperforms the baseline, which does not incorporate market styles. There is a maximum 9 percent improvement in terms of accuracy and F1-score. Moreover, backtesting results show that incorporating market styles into trading signals earns trading strategies more profits on most stocks.},
  archive      = {J_CC},
  author       = {Li, Xiaodong and Wu, Pangjing},
  doi          = {10.1007/s12559-021-09820-1},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {149-166},
  shortjournal = {Cogn. Comput.},
  title        = {Stock price prediction incorporating market style clustering},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sentic computing for aspect-based opinion summarization
using multi-head attention with feature pooled pointer generator
network. <em>CC</em>, <em>14</em>(1), 130–148. (<a
href="https://doi.org/10.1007/s12559-021-09835-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural sequence to sequence models have achieved superlative performance in summarizing text. But they tend to generate generic summaries that under-represent the opinion-sensitive aspects of the document. Additionally, the sequence to sequence models are prone to test-train discrepancy (exposure-bias) arising from the differential summary decoding processes in the training and testing phases. The models use ground truth summary words in the decoder training phase and predicted outputs in the testing phase. This inconsistency leads to error accumulation and substandard performance. To address these gaps, a cognitive aspect-based opinion summarizer, Feature Pooled Pointer Generator Network (FP2GN), is proposed which selectively attends to thematic and contextual cues to generate sentiment-aware review summaries. This study augments the pointer generator framework with opinion feature extraction, feature pooling, and mutual attention mechanism for opinion summarization. The proposed model FP2GN identifies the aspect terms in review text using sentic computing (SenticNet 5 and concept frequency-inverse opinion frequency) and statistical feature engineering. These aspect terms are encoded into context embeddings using weighted average feature pooling, which is processed in a pointer-generator framework inspired stacked Bi-LSTM encoder–decoder model with multi-head self-attention. The decoder system uses temporal and mutual attention mechanisms to ensure the appropriate representation of input-sequence. The study also proffers the use of teacher forcing ratio to curtail the exposure-bias-related error-accumulation. The model achieves ROUGE-1 score of 86.04% and ROUGE-L score of 88.51% on the Amazon Fine Foods dataset. An average gain of 2% over other methods is observed. The proposed model reinforces pointer generator network architecture with opinion feature extraction, feature pooling, and mutual attention mechanism to generate human-readable opinion summaries. Empirical analysis substantiates that the proposed model is better than the baseline opinion summarizers.},
  archive      = {J_CC},
  author       = {Kumar, Akshi and Seth, Simran and Gupta, Shivam and Maini, Shivam},
  doi          = {10.1007/s12559-021-09835-8},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {130-148},
  shortjournal = {Cogn. Comput.},
  title        = {Sentic computing for aspect-based opinion summarization using multi-head attention with feature pooled pointer generator network},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multitask framework to detect depression, sentiment and
multi-label emotion from suicide notes. <em>CC</em>, <em>14</em>(1),
110–129. (<a href="https://doi.org/10.1007/s12559-021-09828-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant rise in suicides is a major cause of concern in public health domain. Depression plays a major role in increasing suicide ideation among the individuals. Although most of the suicides can be avoided with prompt intercession and early diagnosis, it has been a serious challenge to detect the at-risk individuals. Our current work focuses on learning three closely related tasks, viz. depression detection, sentiment citation, and to investigate their impact in analysing the mental state of the victims. We extend the existing standard emotion annotated corpus of suicide notes in English, CEASE, with additional 2539 sentences collected from 120 new notes. We annotate the consolidated corpus with appropriate depression labels and multi-label emotion classes. We further leverage weak supervision to annotate the corpus with sentiment labels. We propose a deep multitask framework that features a knowledge module that uses SenticNet’s IsaCore and AffectiveSpace vector-spaces to infuse external knowledge specific features into the learning process. The system models emotion recognition (the primary task), depression detection and sentiment classification (the secondary tasks) simultaneously. Experiments show that our proposed multitask system obtains the highest cross-validation MR of 56.47 %. Evaluation results show that all our multitask models perform better than their single-task variants indicating that the secondary tasks (depression detection and sentiment classification) improve the performance of the primary task (emotion recognition) when all tasks are learned jointly.},
  archive      = {J_CC},
  author       = {Ghosh, Soumitra and Ekbal, Asif and Bhattacharyya, Pushpak},
  doi          = {10.1007/s12559-021-09828-7},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {110-129},
  shortjournal = {Cogn. Comput.},
  title        = {A multitask framework to detect depression, sentiment and multi-label emotion from suicide notes},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CAT-BiGRU: Convolution and attention with bi-directional
gated recurrent unit for self-deprecating sarcasm detection.
<em>CC</em>, <em>14</em>(1), 91–109. (<a
href="https://doi.org/10.1007/s12559-021-09821-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sarcasm detection has been a well-studied problem for the computational linguistic researchers. However, research related to different categories of sarcasm has still not gained much attention. Self-Deprecating Sarcasm (SDS) is a special category of sarcasm in which users apply sarcasm over themselves, and it is extensively used in social media platforms, mainly as an advertising tool for the brand endorsement, product campaign, and digital marketing with an aim to increase the sales volume. In this paper, we present a deep learning approach for detecting SDS on Twitter. We propose a novel Convolution and Attention with Bi-directional Gated Recurrent Unit (CAT-BiGRU) model, which consists of an input, embedding, convolutional, Bi-directional Gated Recurrent Unit (BiGRU), and two attention layers. The convolutional layer extracts SDS-based syntactic and semantic features from the embedding layer, BiGRU layer retrieves contextual information from the extracted features in both preceding and succeeding directions, and attention layers are used to retrieve SDS-based comprehensive context representation from the input texts. Finally, sigmoid function is employed to classify the input texts as a self-deprecating or non-self-deprecating sarcasm. Experiments are conducted over seven Twitter datasets to evaluate the proposed (CAT-BiGRU) model using standard evaluation metrics. The experimental results are impressive and significantly better than many neural network-based baselines and state-of-the-art methods. In this paper, we have highlighted biologically inspired and psychologically motivated basis of the proposed approach to examine its affective capabilities with respect to SenticNet. The efficacy of the proposed model is evaluated on two SenticNet-based sentic computing resources—Amazon word embedding and AffectiveSpace. Based on the experimental results, we conclude that deep learning-based approaches have potential to detect SDS in social media texts accurately.},
  archive      = {J_CC},
  author       = {Kamal, Ashraf and Abulaish, Muhammad},
  doi          = {10.1007/s12559-021-09821-0},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {91-109},
  shortjournal = {Cogn. Comput.},
  title        = {CAT-BiGRU: Convolution and attention with bi-directional gated recurrent unit for self-deprecating sarcasm detection},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An effective sarcasm detection approach based on sentimental
context and individual expression habits. <em>CC</em>, <em>14</em>(1),
78–90. (<a href="https://doi.org/10.1007/s12559-021-09832-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sarcasm is common in social media, and people use it to express their opinions with stronger emotions indirectly. Although it belongs to a branch of sentiment analysis, traditional sentiment analysis methods cannot identify the rhetoric of irony as it requires a significant amount of background knowledge. Existing sarcasm detection approaches mainly focus on analyzing the text content of sarcasm using various natural language processing techniques. It is argued herein that the essential issue for detecting sarcasm is examining its context, including sentiments of texts that reply to the target text and user’s expression habit. A dual-channel convolutional neural network is proposed that analyzes not only the semantics of the target text, but also its sentimental context. In addition, SenticNet is used to add common sense to the long short-term memory (LSTM) model. The attention mechanism is then applied to take the user’s expression habits into account. A series of experiments were carried out on several public datasets, the results of which show that the proposed approach can significantly improve the performance of sarcasm detection tasks.},
  archive      = {J_CC},
  author       = {Du, Yu and Li, Tong and Pathan, Muhammad Salman and Teklehaimanot, Hailay Kidu and Yang, Zhen},
  doi          = {10.1007/s12559-021-09832-x},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {78-90},
  shortjournal = {Cogn. Comput.},
  title        = {An effective sarcasm detection approach based on sentimental context and individual expression habits},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DomainSenticNet: An ontology and a methodology enabling
domain-aware sentic computing. <em>CC</em>, <em>14</em>(1), 62–77. (<a
href="https://doi.org/10.1007/s12559-021-09825-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, SenticNet and OntoSenticNet have represented important developments in the novel interdisciplinary field of research known as sentic computing, enabling the development of a variety of Sentic applications. In this paper, we propose an extension of the OntoSenticNet ontology, named DomainSenticNet, and contribute an unsupervised methodology to support the development of domain-aware Sentic applications. We developed an unsupervised methodology that, for each concept in OntoSenticNet, mines semantically related concepts from WordNet and Probase knowledge bases and computes domain distributional information from the entire collection of Kickstarter domain-specific crowdfunding campaigns. Subsequently, we applied DomainSenticNet to a prototype tool for Kickstarter campaign authoring and success prediction, demonstrating an improvement in the interpretability of sentiment intensities. DomainSenticNet is an extension of the OntoSenticNet ontology that integrates each of the 100,000 concepts included in OntoSenticNet with a set of semantically related concepts and domain distributional information. The defined unsupervised methodology is highly replicable and can be easily adapted to build similar domain-aware resources from different domain corpora and external knowledge bases. Used in combination with OntoSenticNet, DomainSenticNet may favor the development of novel hybrid aspect-based sentiment analysis systems and support further research on sentic computing in domain-aware applications.},
  archive      = {J_CC},
  author       = {Distante, Damiano and Faralli, Stefano and Rittinghaus, Steve and Rosso, Paolo and Samsami, Nima},
  doi          = {10.1007/s12559-021-09825-w},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {62-77},
  shortjournal = {Cogn. Comput.},
  title        = {DomainSenticNet: An ontology and a methodology enabling domain-aware sentic computing},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An ensemble method for radicalization and hate speech
detection online empowered by sentic computing. <em>CC</em>,
<em>14</em>(1), 48–61. (<a
href="https://doi.org/10.1007/s12559-021-09845-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dramatic growth of the Web has motivated researchers to extract knowledge from enormous repositories and to exploit the knowledge in myriad applications. In this study, we focus on natural language processing (NLP) and, more concretely, the emerging field of affective computing to explore the automation of understanding human emotions from texts. This paper continues previous efforts to utilize and adapt affective techniques into different areas to gain new insights. This paper proposes two novel feature extraction methods that use the previous sentic computing resources AffectiveSpace and SenticNet. These methods are efficient approaches for extracting affect-aware representations from text. In addition, this paper presents a machine learning framework using an ensemble of different features to improve the overall classification performance. Following the description of this approach, we also study the effects of known feature extraction methods such as TF-IDF and SIMilarity-based sentiment projectiON (SIMON). We perform a thorough evaluation of the proposed features across five different datasets that cover radicalization and hate speech detection tasks. To compare the different approaches fairly, we conducted a statistical test that ranks the studied methods. The obtained results indicate that combining affect-aware features with the studied textual representations effectively improves performance. We also propose a criterion considering both classification performance and computational complexity to select among the different methods.},
  archive      = {J_CC},
  author       = {Araque, Oscar and Iglesias, Carlos A.},
  doi          = {10.1007/s12559-021-09845-6},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {48-61},
  shortjournal = {Cogn. Comput.},
  title        = {An ensemble method for radicalization and hate speech detection online empowered by sentic computing},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A decade of sentic computing: Topic modeling and
bibliometric analysis. <em>CC</em>, <em>14</em>(1), 24–47. (<a
href="https://doi.org/10.1007/s12559-021-09861-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on sentic computing has received intensive attention in recent years, as indicated by the increased availability of academic literature. However, despite the growth in literature and researchers’ interests, there are no reviews on this topic. This study comprehensively explores the current research progress and tendencies, particularly the thematic structure of sentic computing, to provide insights into the issues addressed during the past decade and the potential future of sentic computing. We combined bibliometric analysis and structural topic modeling to examine sentic computing literature in various aspects, including the tendency of annual article count, top journals, countries/regions, institutions, and authors, the scientific collaborations between major contributors, as well as the major topics and their tendencies. We obtained interesting and meaningful findings. For example, sentic computing has attracted growing interest in academia. In addition, Cognitive Computation and Nanyang Technological University were found to be the most productive journal and institution in publishing sentic computing studies, respectively. Moreover, important issues such as cyber issues and public opinion, deep neural networks and personality, financial applications and user profiles, and affective and emotional computing have been commonly addressed by authors focusing on sentic computing. Our study provides a thorough overview of sentic computing, reveals major concerns among scholars during the past decade, and offers insights into the future directions of sentic computing research.},
  archive      = {J_CC},
  author       = {Chen, Xieling and Xie, Haoran and Cheng, Gary and Li, Zongxi},
  doi          = {10.1007/s12559-021-09861-6},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {24-47},
  shortjournal = {Cogn. Comput.},
  title        = {A decade of sentic computing: Topic modeling and bibliometric analysis},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ten years of sentic computing. <em>CC</em>, <em>14</em>(1),
5–23. (<a href="https://doi.org/10.1007/s12559-021-09824-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentic computing is a multi-disciplinary approach to sentiment analysis at the crossroads between affective computing and commonsense computing, which exploits both computer and social sciences to better recognize, interpret, and process opinions and sentiments over the Web. In the last ten years, many different models (such as the Hourglass of Emotions and Sentic Patterns), resources (such as AffectiveSpace and SenticNet), algorithms (such as Sentic LDA and Sentic LSTM), and applications (such as Sentic PROMs and Sentic Album) have been developed under the umbrella of sentic computing. In this paper, we review all such models, resources, algorithms, and applications together with the key shifts and tasks introduced by sentic computing in the context of affective computing and sentiment analysis. We also discuss future directions in these fields.},
  archive      = {J_CC},
  author       = {Susanto, Yosephine and Cambria, Erik and Ng, Bee Chin and Hussain, Amir},
  doi          = {10.1007/s12559-021-09824-x},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {5-23},
  shortjournal = {Cogn. Comput.},
  title        = {Ten years of sentic computing},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Guest editorial: A decade of sentic computing. <em>CC</em>,
<em>14</em>(1), 1–4. (<a
href="https://doi.org/10.1007/s12559-021-09972-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Cambria, Erik and Hussain, Amir},
  doi          = {10.1007/s12559-021-09972-0},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {1-4},
  shortjournal = {Cogn. Comput.},
  title        = {Guest editorial: A decade of sentic computing},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
