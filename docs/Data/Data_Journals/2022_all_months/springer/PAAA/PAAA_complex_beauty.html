<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>PAAA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="paaa---70">PAAA - 70</h2>
<ul>
<li><details>
<summary>
(2022). Arctangent entropy: A new fast threshold segmentation
entropy for light colored character image on semiconductor chip surface.
<em>PAAA</em>, <em>25</em>(4), 1075–1090. (<a
href="https://doi.org/10.1007/s10044-022-01079-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When using the Tsallis entropy method to segment light colored character images on the semiconductor chip surface, it consumes relatively long CPU time. In order to reduce the consumption of CPU time, a new threshold segmentation entropy is proposed on the basis of the Tsallis entropy, called arctangent entropy (Arctangent entropy).It introduces the arctangent operator and constructs a mathematical model that can effectively adjust the foreground entropy and background entropy. The foreground entropy and background entropy of the image are adjusted by adjusting the parameter k. Experiments show that compared with the Tsallis entropy, Kapur entropy, Renyi entropy, Minimum error threshold (MET) and Iterative threshold (IT),the CPU time consumed by the arctangent entropy is lowest. The total CPU time average consumed by the Kapur entropy is approximately 14.4 times that of the Arctangent entropy. The total CPU time average consumed by the MET is approximately 4.6 times that of the Arctangent entropy. The total CPU time average consumed by the Tsallis entropy, IT and Renyi entropy are approximately 2.7, 2.6, 2.5 times that of the Arctangent entropy, respectively. The arctangent entropy has the best segmentation effect on light colored character images.},
  archive      = {J_PAAA},
  author       = {Liu, Jianxun and Shi, Jinfei and Hao, Fei and Dai, Min and Zhang, Zhisheng},
  doi          = {10.1007/s10044-022-01079-y},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1075-1090},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Arctangent entropy: A new fast threshold segmentation entropy for light colored character image on semiconductor chip surface},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Segmentation based 6D pose estimation using integrated shape
pattern and RGB information. <em>PAAA</em>, <em>25</em>(4), 1055–1073.
(<a href="https://doi.org/10.1007/s10044-022-01078-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud is currently the most typical representation in describing the 3D world. However, recognizing objects as well as the poses from point clouds is still a great challenge due to the property of disordered 3D data arrangement. In this paper, a unified deep learning framework for 3D scene segmentation and 6D object pose estimation is proposed. In order to accurately segment foreground objects, a novel shape pattern aggregation module called PointDoN is proposed, which could learn meaningful deep geometric representations from both Difference of Normals (DoN) and the initial spatial coordinates of point cloud. Our PointDoN is flexible to be applied to any convolutional networks and shows improvements in the popular tasks of point cloud classification and semantic segmentation. Once the objects are segmented, the range of point clouds for each object in the entire scene could be specified, which enables us to further estimate the 6D pose for each object within local region of interest. To acquire good estimate, we propose a new 6D pose estimation approach that incorporates both 2D and 3D features generated from RGB images and point clouds, respectively. Specifically, 3D features are extracted via a CNN-based architecture where the input is XYZ map converted from the initial point cloud. Experiments showed that our method could achieve satisfactory results on the publicly available point cloud datasets in both tasks of segmentation and 6D pose estimation.},
  archive      = {J_PAAA},
  author       = {Gu, Chaochen and Feng, Qi and Lu, Changsheng and Zhao, Shuxin and Xu, Rui},
  doi          = {10.1007/s10044-022-01078-z},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1055-1073},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Segmentation based 6D pose estimation using integrated shape pattern and RGB information},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid loss balancing algorithm based on gradient
equilibrium and sample loss for understanding of road scenes at
basic-level. <em>PAAA</em>, <em>25</em>(4), 1041–1053. (<a
href="https://doi.org/10.1007/s10044-022-01068-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is indispensable to visual environment sensing at basic-level. During that detection there are imbalance between the losses of multi-task and multi-object in state-of-the-art algorithms, resulting in the slowdown of training process and low precision. To address this issue, a hybrid loss balancing (HLB) algorithm combined a loss balancing strategy based on gradient equilibrium (LBGE) with a multi-sample loss balancing (MSLB) strategy is proposed. The LBGE strategy increases the accuracy of the Basic network by 3.38% on VOC dataset and by 4.22% on KITTI dataset by updating the weight of each loss during the training iteration. The MSLB strategy with the optimal super-parameter value 200 can improve the accuracy of the basic network by 2.51% on VOC dataset and by 6.62% on KITTI dataset by assigning larger weights to the proposal regions which are more difficult to train. With both strategies working together, the proposed HLB algorithm improves the accuracy by 3.88% on VOC and by 7.24% on KITTI, enhancing robustness to the cross-domain datasets than single strategy. Moreover, the proposed HLB loss function obtains the highest accuracy at 84.02%, a 2.39% higher than that of original loss and other loss functions on average. In a word, the HLB algorithm with the LBGE and MSLB strategies have better understanding ability of basic-level road scenes than Basic network on VOC and KITTI dataset, and can also accelerate the early training speed of the Basic network.},
  archive      = {J_PAAA},
  author       = {Su, Tao and Shi, Ying and Xie, Changjun and Luo, Wenguang and Ye, Hongtao and Xu, Lamei},
  doi          = {10.1007/s10044-022-01068-1},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1041-1053},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A hybrid loss balancing algorithm based on gradient equilibrium and sample loss for understanding of road scenes at basic-level},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online multi-label stream feature selection based on
neighborhood rough set with missing labels. <em>PAAA</em>,
<em>25</em>(4), 1025–1039. (<a
href="https://doi.org/10.1007/s10044-022-01067-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection has been essential in many big data applications and plays a significant role in processing high-dimensional data. However, the existing online stream feature selection methods ignore the existence of missing labels. Inspired by the neighborhood rough set that does not require prior knowledge of the feature space, we propose a novel online multi-label stream feature selection algorithm called OFS-Mean. We define a neighborhood relationship that can automatically select an appropriate number of neighbors. Without any prior space and parameters, the algorithm’s performance of the algorithm is improved by real-time online prediction of missing labels based on the similarity between the instance and its neighbors. The proposed OFS-Mean divides the feature selection process into two stages: online feature importance evaluation and online redundancy update to screen important features. With the support of neighborhood rough set, the proposed OFS-Mean can adapt to various types of datasets, improving the algorithm generalization ability. In the experiment, the similarity test is used to verify the prediction results; the comparison with the traditional semi-supervised feature selection method under the condition of selecting the same number of features has achieved ideal results.},
  archive      = {J_PAAA},
  author       = {Liang, Shunpan and Liu, Ze and You, Dianlong and Pan, Weiwei},
  doi          = {10.1007/s10044-022-01067-2},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1025-1039},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Online multi-label stream feature selection based on neighborhood rough set with missing labels},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodal biometric crypto system for human authentication
using ear and palm print. <em>PAAA</em>, <em>25</em>(4), 1015–1024. (<a
href="https://doi.org/10.1007/s10044-022-01058-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fuzzy vault structure, which is a biometric pattern safety process in which the biometric traits are represented as an unordered group, is an example of a biometric cryptosystem. A Hybrid Fuzzy Vault-Cuckoo Search algorithm is proposed in this article to provide the best recognition when compared to the existing approach. The module&#39;s methods include preprocessing, characteristic elimination, creating characteristic vectors, synthesis, and reformation. The proposed approach&#39;s performance is assessed using evaluation metrics.},
  archive      = {J_PAAA},
  author       = {Kandasamy, Mariyappan},
  doi          = {10.1007/s10044-022-01058-3},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1015-1024},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multimodal biometric crypto system for human authentication using ear and palm print},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bilingual text detection from natural scene images using
faster r-CNN and extended histogram of oriented gradients.
<em>PAAA</em>, <em>25</em>(4), 1001–1013. (<a
href="https://doi.org/10.1007/s10044-022-01066-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today&#39;s world, scene text detection is important for a wide range of scientific and industrial processes. Compared with text detection in documents, text detection in natural scenes is challenging since they are subjected to different orientations, scaling, brightness variations, and complex backgrounds. Further scenes can contain multiple scripts which limits the performance of detection algorithms. In this paper, we propose a state-of-the-art algorithm for text detection for a bilingual natural scene dataset. The framework consists of (a) Faster R-CNN employed to extract probable text regions within the scene images, (b) rearrangement of the text region as consecutive frames along the time axis and extraction of global and local shape features from the three orthogonal planes and (c) use of simple and effective classifier to predict the features extracted from regions as text or non-text region. The proposed frame when compared to other text detection techniques improves the overall text detection accuracy. The validity of the algorithm is verified on the bilingual text detection dataset MSRA-TD500, and a promising F1 score of 0.70 is reported.},
  archive      = {J_PAAA},
  author       = {Joseph Raj, Alex Noel and Junmin, Chen and Nersisson, Ruban and Mahesh, Vijayalakshmi G. V. and Zhuang, Zhemin},
  doi          = {10.1007/s10044-022-01066-3},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1001-1013},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Bilingual text detection from natural scene images using faster R-CNN and extended histogram of oriented gradients},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive method for chinese new word detection based on
hypothesis testing. <em>PAAA</em>, <em>25</em>(4), 993–999. (<a
href="https://doi.org/10.1007/s10044-022-01087-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New word detection is a significant problem in Chinese information processing, which is also the basis of Chinese word segmentation, automatic translation and semantic analysis. To address the problem of new word detection, this paper first analyzes the features of Chinese new words, and then proposes a hypothesis-testing-based detection approach for Chinese new words. To simulate how people identify new words, three modules are included: the non-accidental testing is to identify strings that are obviously occurring in given texts, the correlation testing is to evaluate the internal correlation between adjacent characters, and common grammar rules are used for garbage string filtering after the testing. This hypothesis-testing-based detection approach avoids the subjective selection of thresholds of new words statistical features and can set thresholds adaptively according to general frequency information. Its implementation does not require large-scale corpus for training and can eliminate the influence of using different corpus on the recognition results. Comparison experimental results show that this method has good performance on both detection time and F-score.},
  archive      = {J_PAAA},
  author       = {Jiang, Dongchen and Jiang, Aoyuan and Tang, Shuai},
  doi          = {10.1007/s10044-022-01087-y},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {993-999},
  shortjournal = {Pattern Anal. Appl.},
  title        = {An adaptive method for chinese new word detection based on hypothesis testing},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual attention-based deepfake video forgery detection.
<em>PAAA</em>, <em>25</em>(4), 981–992. (<a
href="https://doi.org/10.1007/s10044-022-01083-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prime goal of creating synthetic digital data is to generate something very closer to real ones when the original data are scarce. However, the trustworthiness of such digital content is dipping potentially in society owing to malicious users. Deepfake method that uses computer graphics and computer vision techniques to replace the face of one person with the face of a different person is becoming an area of big concern. Such techniques can easily be used to hide the identity of a person. Therefore, a method is needed to verify the originality of such face images/videos. To this end, we design a deep learning model enhanced with visual attention technique to differentiate manipulated videos/images (generated by deepfake methods) from real ones. At first, we extract the face region from video frames and then pass the same through the pre-trained Xception model to obtain the feature maps. Next, with the help of the visual attention mechanism, we mainly try to focus on the deepfake video manipulation leftover artifacts. We evaluate our model on two publicly available datasets, namely FaceForensics++ and Celeb-DF (V2), and our model outperforms many state-of-the-art methods tested on these two datasets. Source code of the proposed method can be found at: https://github.com/tre3x/Deepfake-Video-Forgery-Detection .},
  archive      = {J_PAAA},
  author       = {Ganguly, Shreyan and Mohiuddin, Sk and Malakar, Samir and Cuevas, Erik and Sarkar, Ram},
  doi          = {10.1007/s10044-022-01083-2},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {981-992},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Visual attention-based deepfake video forgery detection},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel matrix factorization-based collaborative sparsity
and smooth prior for estimating missing values in multidimensional data.
<em>PAAA</em>, <em>25</em>(4), 963–980. (<a
href="https://doi.org/10.1007/s10044-022-01082-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parallel matrix factorization has recently emerged as a powerful tool for low-rank tensor recovery problems. However, using only the low-rank property is often not sufficient for recovering valuable details in images. Generally, incorporating additional prior knowledge shows significant improvement in the recovered results. Therefore, smooth matrix factorization has been introduced for tensor completion in which the smoothness of its spectral factor over the third mode has been recently considered. However, these models may not efficiently characterize the smoothness of the target tensor. Thus, in this work, we are interested in boosting the piecewise smoothness by using the third-mode smoothness of the underlying tensor combined with spectral sparsity of the third factor of the factorization. Therefore, we propose in this paper a parallel matrix factorization-based sparsity constraint with a smoothness prior to the third mode of the target tensor. We develop a multi-block proximal alternating minimization algorithm for solving the proposed model. Theoretically, we show that the generated sequence globally converges to a critical point. The superiority of our model over other tensor completion methods in terms of several evaluation metrics is reported via extensive experiments conducted on real data such as videos, hyperspectral images, and MRI data.},
  archive      = {J_PAAA},
  author       = {Mohaoui, Souad and Hakim, Abdelilah and Raghay, Said},
  doi          = {10.1007/s10044-022-01082-3},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {963-980},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Parallel matrix factorization-based collaborative sparsity and smooth prior for estimating missing values in multidimensional data},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An outstanding adaptive multi-feature fusion YOLOv3
algorithm for the small target detection in remote sensing images.
<em>PAAA</em>, <em>25</em>(4), 951–962. (<a
href="https://doi.org/10.1007/s10044-022-01072-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based target detection for optical remote sensing images is a significant research direction in the field of image processing. Different from natural images, remote sensing images are characterized by complex backgrounds, similarity of characteristics between various classes and diverse target scales. In this paper, we propose an adaptive multi-feature fusion YOLOv3 remote sensing small target detection algorithm to cope with these features. In the proposed algorithm, the shallow semantic information is extracted by the accessory feature extraction network, and fused with the deep features extracted by Darknet-53 down-sampling to enrich the semantic and spatial information of the feature layers on the auxiliary network. In addition, the shallow features are filtered using the adaptive feature selection module to refine the effective feature information. A cross-layer feature fusion module is proposed to fuse different feature layers to enhance the connection between the semantic information of feature contexts to obtain more information about the characteristics of small targets. To test the effectiveness of the proposed algorithm, it is validated on the Pascal voc2007 dataset. The experimental results show that the detection accuracy of the proposed algorithm could achieve 88.3%, and evidently superior to the original YOLOv3 algorithm. Finally, the proposed algorithm is applied to detect the small target in remote sensing images. The detection results show that compared with the original YOLOv3 algorithm, the mean average precision(mAP) of the proposed algorithm is improved by 2.6%, which can effectively detect more small targets and significantly improve the detection accuracy of small targets than other classical algorithms.},
  archive      = {J_PAAA},
  author       = {Li, Guoqiang and Hao, Xinyu and Zha, Linlin and Chen, Anbang},
  doi          = {10.1007/s10044-022-01072-5},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {951-962},
  shortjournal = {Pattern Anal. Appl.},
  title        = {An outstanding adaptive multi-feature fusion YOLOv3 algorithm for the small target detection in remote sensing images},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Infrared and visible image fusion via multi-scale
multi-layer rolling guidance filter. <em>PAAA</em>, <em>25</em>(4),
933–950. (<a href="https://doi.org/10.1007/s10044-022-01073-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The desire of infrared (IR) and visible (VIS) image fusion is to bring out an admixture image to augment the target information from IR image and to retain the texture details from VIS image. In this paper, we put forward a multi-scale multi-layer rolling guidance filter (MSML_RGF)-based IR and VIS image fusion. The fused image is the improved version of the source images with more significant features. Fundamentally, the IR and VIS source images are decomposed into three layers by the proposed algorithm namely micro-scale, macro-scale and base layers. Second, according to their characteristics, unique fusion rules are used to combine these three layers. Micro-scale layers are integrated by using phase congruency (PC)-based fusion rule, macro-scale layers are combined by absolute maximum based consistency verification fusion rule and the base layers are combined by weighted energy related fusion. At last, the fused image is acquired by summating the fused micro-scale, macro-scale and base layer outputs. Proposed method is evaluated both subjectively and objectively with comparisons to other five fusion methods on a publicly available database. The proposed method can well preserve the background and target information from both the source images visually and quantitatively without pseudo and blurred edges compared to the conventional methods.},
  archive      = {J_PAAA},
  author       = {Prema, G. and Arivazhagan, S.},
  doi          = {10.1007/s10044-022-01073-4},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {933-950},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Infrared and visible image fusion via multi-scale multi-layer rolling guidance filter},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A score-based preprocessing technique for class imbalance
problems. <em>PAAA</em>, <em>25</em>(4), 913–931. (<a
href="https://doi.org/10.1007/s10044-022-01084-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In classification, one of the common problems is the class imbalance problem. This phenomenon that is growing significance emerges in most real fields and occurs when data samples are distributed among classes unevenly. This means that most of the data are in the larger class, and there are fewer data in the smaller class. Since standard classifiers do not consider the distribution of imbalanced class, they indicate undesirable behavior in facing them. Many techniques have been proposed to solve the problem of class imbalance. Among these methods, a group called preprocessing techniques tries to create a balance between training sets. These methods balance the classes’ distribution by removing redundant samples from the larger class or creating new samples for the smaller one. The first group is known as under-sampling, and the second one is known as over-sampling techniques. In this paper, we propose a score-based preprocessing technique based on both under-sampling and over-sampling to overcome the weakness of classifiers in class imbalance problems. For this purpose, we apply the sharing strategy in both stages to determine more suitable samples based on their importance in the feature space. In the over-sampling stage, the smaller class’s synthetic samples are generated by interpolating between more sparse samples. After that, in the under-sampling stage, denser samples of the larger class are selected to be removed. We use the binary tournament selection operator in both stages to perform over-sampling and under-sampling based on probabilities. In experiments, the support vector machine (SVM) is employed to train a classification model from the balanced training sets obtained by different preprocessing methods. Besides, F-measure and AUC measures are considered as evaluation tools. At the last step, we compare all methods in terms of the classification model’s complexity. According to the results obtained from 44 standard imbalanced datasets, the proposed method’s superiority and effectiveness compared to other methods have been revealed.},
  archive      = {J_PAAA},
  author       = {Mirzaei, Behzad and Rahmati, Farshad and Nezamabadi-pour, Hossein},
  doi          = {10.1007/s10044-022-01084-1},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {913-931},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A score-based preprocessing technique for class imbalance problems},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced deep-joint segmentation with deep learning networks
of glioma tumor for multi-grade classification using MR images.
<em>PAAA</em>, <em>25</em>(4), 891–911. (<a
href="https://doi.org/10.1007/s10044-022-01064-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The crucial imaging modality employed in medicinal diagnostic tools to detect the tumors is magnetic resonance image (MRI). Based on the glioma anatomical structures, MRI poses the capability to provide detailed information. Anyhow, in the MRI classification the foremost problem is the semantic gap between optical information at the low level, which is attained from the MRI machine, whereas information at the high level is alleged by a clinician. In this research, Tunicate-Exponential weighted moving average (TEWMA)-based deep convolutional neural Network (TEWMA-deep CNN) is devised for multi-grade classification. In this method, the preprocessing is employed to eradicate the artifacts present in the image. Moreover, deep-joint segmentation is modified with the weighted Euclidean and Levenshtein distance measures, which are effectively used for segmenting the tumor regions. Then, the classification is done from the image-segmented areas by deep CNN to determine gliomas, meningioma, pituitary, and others, which is tuned by developed TEWMA. The experimentation of the devised approach is performed by three datasets, such as BRATS 2015, figshare, and BRATS 2020 dataset. The developed TEWMA is designed by incorporating Tunicate swarm algorithm (TSA) and exponentially weighted moving average (EWMA) algorithm, with the highest specificity of 99%, highest accuracy of 98.76%, highest sensitivity of 98.88%, maximal precision of 94.76%, maximal F1-measure of 98.46%, and minimal time of 7.24 s using dataset-1 for classification. Also, the proposed method attains average specificity, accuracy, sensitivity, precision, F-measure, and time of 91.09, 93.79, 95.46, 92.33, 94.30%, and 6.23 s, respectively, using dataset-1.},
  archive      = {J_PAAA},
  author       = {Divya, S and Padma Suresh, L and John, A},
  doi          = {10.1007/s10044-022-01064-5},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {891-911},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Enhanced deep-joint segmentation with deep learning networks of glioma tumor for multi-grade classification using MR images},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Consistent auto-weighted multi-view subspace clustering.
<em>PAAA</em>, <em>25</em>(4), 879–890. (<a
href="https://doi.org/10.1007/s10044-022-01085-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because the data in practical applications usually satisfy the assumption of mixing subspaces and contain multiple features, multi-view subspace clustering has attracted extensive attention in recent years. In previous work, multi-view information can be utilized comprehensively by considering consistency. However, they often treat the information from different views equally. Because it is difficult to ensure that the information of all views is well mined, difficult view will reduce the performance. In this paper, we propose a novel multi-view subspace clustering method named consistent auto-weighted multi-view subspace clustering (CAMVSC) to overcome the above limitation by weighting automatically the representation matrices of each view. In our model, the density and sparsity are both considered to ensure the learning effect of each view. Although simultaneously using the self-representation and the auto-weighting strategy will bring difficulties to solve the model, we successfully design a special updating scheme to obtain the numerical algorithm, and prove its convergence theoretically. Extensive experimental results demonstrate the effectiveness of our proposed method.},
  archive      = {J_PAAA},
  author       = {Tang, Kewei and Cao, Liying and Zhang, Nan and Jiang, Wei},
  doi          = {10.1007/s10044-022-01085-0},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {879-890},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Consistent auto-weighted multi-view subspace clustering},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel video saliency estimation method in the compressed
domain. <em>PAAA</em>, <em>25</em>(4), 867–878. (<a
href="https://doi.org/10.1007/s10044-022-01081-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel compressed domain saliency estimation method based on analyzing block motion vectors and transform residuals extracted from the bitstream of H.264/AVC compressed videos. Block motion vectors are analyzed by modeling their orientation values utilizing Dual Cross Patterns, a feature descriptor that earlier found applications in face recognition to obtain the motion saliency map. The transform residuals are analyzed by utilizing lifting wavelet transform on the luminance component of the macro-blocks to obtain the spatial saliency map. The motion saliency map and the spatial saliency map are fused utilizing the Dempster–Shafer combination rule to generate the final saliency map. It is shown through our experiments that Dual Cross Patterns and lifting wavelet transform features fused via Dempster–Shafer rule are superior in predicting fixations as compared to the existing state-of-the-art saliency models.},
  archive      = {J_PAAA},
  author       = {Sandula, Pavan and Okade, Manish},
  doi          = {10.1007/s10044-022-01081-4},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {867-878},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A novel video saliency estimation method in the compressed domain},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A single-shot model for traffic-related pedestrian
detection. <em>PAAA</em>, <em>25</em>(4), 853–865. (<a
href="https://doi.org/10.1007/s10044-022-01076-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic-related pedestrian detection is important for advanced driving-assistant systems and autonomous driving. In addition to pedestrian detection, traffic-related pedestrian detection involves the challenge of detecting small-target pedestrians from large input images. Recently, deep-learning-based methods, including convolution neural networks, have been applied to problems of pedestrian detection. In this study, we propose a single-shot multibox detector (SSD)-based method called E-SSD to increase the accuracy and speed of detecting traffic-related pedestrians. This method includes a deconvolutional feature-fusion module to provide shallow layers with additional contextual information, which is beneficial for detecting small-sized objects. Additionally, we included an attention layer designed to exploit channel attention and spatial attention in order to utilize the most valuable information for detecting target pedestrians. Furthermore, we built a traffic-related pedestrian dataset (UCAR pedestrian) specific for Beijing. Evaluation results on the UCAR dataset demonstrated that E-SSD was more effective than a baseline SSD model at detecting small-target pedestrians. Evaluation of E-SSD on the Caltech pedestrian, COCO Persons and INRIA pedestrian datasets demonstrated that its performance was comparable with state-of-the-art methods.},
  archive      = {J_PAAA},
  author       = {Sun, Chang and Ai, Yibo and Qi, Xing and Wang, Sheng and Zhang, Weidong},
  doi          = {10.1007/s10044-022-01076-1},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {853-865},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A single-shot model for traffic-related pedestrian detection},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An alignment-free non-invertible transformation-based method
for generating the cancellable fingerprint template. <em>PAAA</em>,
<em>25</em>(4), 837–852. (<a
href="https://doi.org/10.1007/s10044-022-01080-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since long time fingerprint has been the most compelling biometric due to its permanence, universality, acceptability, and collectability. However, fingerprint recognition raises some privacy concerns. A stolen fingerprint template from the reference database could be used by an antagonist to gain a unauthorized access of the system. Therefore, the fingerprint needs to be secured from being compromised. In this paper, a non-invertible transformation function-based method for generating the cancellable fingerprint template is proposed. The transformation matrix is governed by the user key which is in the form of a randomly generated binary string. An alignment-free approach is proposed in which the fingerprint template is stored in the form of a polar histogram that contains the information about location of neighbouring minutiae around each detected minutia point. The matching score is obtained by computing the Chi-square distance between two templates. The pre-requisites for being the secured template are satisfied by conducting series of experiments on DB1 and DB2 datasets of FVC2000, FVC2002, FVC2004, and FVC2006 databases. The performance is evaluated in both non-transformed and transformed domains by computing error rates based on the receiver operating characteristic (ROC) of the fingerprint recognition system.},
  archive      = {J_PAAA},
  author       = {Agarwal, Diwakar and Bansal, Atul},
  doi          = {10.1007/s10044-022-01080-5},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {837-852},
  shortjournal = {Pattern Anal. Appl.},
  title        = {An alignment-free non-invertible transformation-based method for generating the cancellable fingerprint template},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sensitivity analysis of feature weighting for
classification. <em>PAAA</em>, <em>25</em>(4), 819–835. (<a
href="https://doi.org/10.1007/s10044-022-01077-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature weighting is a well-known approach for improving the performance of machine learning algorithms that has been gaining a lot of traction recently. It rescales the feature space such that models of learning algorithms fit better. Although it helps in obtaining high performance in numerous applications, the sensitivity of machine learning algorithms to the weighting, which depends upon their learning mechanisms, has not been explored yet. Such analysis is essential for the practical use of weighting in boosting performance. Therefore, this work presents a empirical assessment of four popular machine learning algorithms which are sensitive to the changes in the feature space. This assessment determines the improvements in performance with weighted features compared to unweighted ones and also identifies the best learning algorithms. The wrapper approach utilizing whale optimization algorithm is used to search for the best feature weights and the parameters of classifiers. The outcomes of experiments combined with the learning mechanism of classifiers show the high sensitivity with k-NN, MLP, and SVM with RBF kernel classifiers while the NB classifier shows the least sensitivity. In terms of practical use, k-NN and SVM-RBF are the best choices for applications demanding accurate predictions, whereas Naive Bayes is the best choice for applications requiring minimal time.},
  archive      = {J_PAAA},
  author       = {Singh, Dalwinder and Singh, Birmohan},
  doi          = {10.1007/s10044-022-01077-0},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {819-835},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Sensitivity analysis of feature weighting for classification},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Symmetric nonnegative matrix factorization with elastic-net
regularized block-wise weighted representation for clustering.
<em>PAAA</em>, <em>25</em>(4), 807–817. (<a
href="https://doi.org/10.1007/s10044-022-01062-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In unsupervised learning, symmetric nonnegative matrix factorization (NMF) has proven its efficacy for various clustering tasks in recent years, considering both linearly and nonlinearly separable data. On the other hand, block-wise weighted sparse representation-based classification (BW-SRC), a recently proposed sparse representation technique improved sparse coding features for supervised classification. In this work, we take advantage of both techniques to device a new unsupervised image clustering algorithm. A disadvantage of symmetric NMF is its computational burden associated to the quadratic growth of its similarity matrix. We reduce this computation by first working with sub-sampled data and then by working with the full data samples in a second stage elastic-net coefficient estimation problem with previously learned block-wise weights. This decreases both the computational time and the memory requirements when solving for symmetric NMF, but at the same time allows to cluster the full data samples in a robust way. We either outperform or achieve highly competitive results with previous matrix factorization clustering methods on seven benchmark image datasets.},
  archive      = {J_PAAA},
  author       = {Rodríguez-Domínguez, Ulises and Dalmau, Oscar},
  doi          = {10.1007/s10044-022-01062-7},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {807-817},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Symmetric nonnegative matrix factorization with elastic-net regularized block-wise weighted representation for clustering},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Harmonic image inpainting using the charge simulation
method. <em>PAAA</em>, <em>25</em>(4), 795–806. (<a
href="https://doi.org/10.1007/s10044-022-01074-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It was recently reported that harmonic inpainting or Laplace interpolation when used in the context of image compression can yield impressive reconstruction results if the encoded pixels were carefully selected. Mathematically, the problem translates into a mixed Dirichlet–Neumann boundary value problem with Dirichlet data coming from the known observations and reflecting conditions being imposed on the image physical boundary. Classical numerical solutions depend on finite difference schemes, which often induce instabilities and rely heavily on the choice of a convenient regularization parameter. In this paper, we propose an alternative numerical method, which is able to provide a robust harmonic reconstruction without requiring neither numerical integration nor discretization of the inpainting domain or its boundary. In fact, our approach is connected with the charge simulation method powered with the fast multipole method. Thereby, we approximate the harmonic reconstruction by a linear combination of the fundamental solutions of the Laplace equation. The experimental results on standard test images using uniformly, randomly and optimally distributed masks of different densities demonstrate the superior performance of our numerical approach over the finite difference method in terms of both reconstruction quality and speed.},
  archive      = {J_PAAA},
  author       = {Kalmoun, El Mostafa and Nasser, Mohamed M. S.},
  doi          = {10.1007/s10044-022-01074-3},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {795-806},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Harmonic image inpainting using the charge simulation method},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mutual neighborhood and modified majority voting based KNN
classifier for multi-categories classification. <em>PAAA</em>,
<em>25</em>(4), 773–793. (<a
href="https://doi.org/10.1007/s10044-022-01069-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, two techniques for improving the performance of the k-Nearest Neighbors (KNN) based classifiers are proposed: mutual neighborhood (MN) for searching the neighbors of the query sample, and two-stage modified majority voting (MMV) based decision. In MN, two samples are the neighbors of each other, if each of them exists in the k-neighborhood of the other. Selecting the MN-based neighbors depends on the data distribution and makes to select the data with the same category and/or more similarity. Also, the number of neighbors is variable in MN. Moreover, a two-stage method is proposed to improve majority voting based classifiers which we call it modified majority voting. In MMV, if there is any ambiguous, the mean vectors of each category with majority voting are computed and then the decision is made based on the minimum Euclidean distance of the mean vectors from the query sample. By the proposed techniques, some new and extended KNN-based classifiers are defined. Two different kinds of databases are used in our experiments: eight datasets of UCI machine learning repository and fifteen datasets of UCR time series classification archive. The results exhibit the proposed techniques increase the recognition rates of the KNN-based classifies. In some cases, the rate of improvement is more than 10%.},
  archive      = {J_PAAA},
  author       = {Hajizadeh, Rassoul and Aghagolzadeh, Ali and Ezoji, Mehdi},
  doi          = {10.1007/s10044-022-01069-0},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {773-793},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Mutual neighborhood and modified majority voting based KNN classifier for multi-categories classification},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Saliency detection based on hybrid artificial bee colony and
firefly optimization. <em>PAAA</em>, <em>25</em>(4), 757–772. (<a
href="https://doi.org/10.1007/s10044-022-01063-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Saliency detection is one of the challenging problems still tackled by image processing and computer vision research communities. Although not very numerous, recent studies reveal that optimization-based methods provide relatively accurate and fast solutions for such problems. This paper presents a novel unsupervised hybrid optimization method that aims to propose reasonable solution to saliency detection problem by combining the familiar artificial bee colony and firefly algorithms. The proposed method, HABCFA, is based on creating hybrid-personality individuals behaving like both bees and fireflies. A superpixel-based method is used to obtain better background intensity values in the saliency detection process, providing a better precision in extracting the salient regions. HABCFA algorithm is capable of achieving an optimum saliency map without requiring any extra mask or training step. HABCFA has produced superior performance against its basis algorithms, artificial bee colony, and firefly on four known benchmark problems regarding convergence rate and iteration count. On the other hand, the experimental results on four commonly used datasets, including MSRA-1000, ECSSD, ICOSEG, and DUTOMRON, demonstrate that HABCFA is adequately robust and effective in terms of accuracy, precision, and speed in comparison with the eleven state-of-the-art methods.},
  archive      = {J_PAAA},
  author       = {Yelmenoglu, Elif Deniz and Celebi, Numan and Tasci, Tugrul},
  doi          = {10.1007/s10044-022-01063-6},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {757-772},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Saliency detection based on hybrid artificial bee colony and firefly optimization},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Accurate quaternion fractional-order pseudo-jacobi–fourier
moments. <em>PAAA</em>, <em>25</em>(4), 731–755. (<a
href="https://doi.org/10.1007/s10044-022-01071-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pseudo-Jacobi–Fourier moments (PJFMs) are a set of orthogonal moments which have been successfully applied in the fields of image processing and pattern recognition. In this paper, we present a new set of quaternion fractional-order orthogonal moments for color images, named accurate quaternion fractional-order pseudo-Jacobi–Fourier moments (AQFPJFMs). We initially propose a fast and accurate algorithm for the PJFMs computation of an image using new recursive approach and polar pixel tiling scheme. Then, we define a new set of orthogonal moments, named accurate fractional-order pseudo-Jacobi–Fourier moments, which is characterized by the generic nature and time–frequency analysis capability. We finally extend the gray-level fractional-order PJFMs to color images and present the quaternion fractional-order pseudo-Jacobi–Fourier moments. In addition, we develop a new color image representation for enhancing simultaneously the discriminability and robustness, called mixed low-order moments feature. We conduct extensive experiments to evaluate the performance of the proposed AQFPJFMs, in which the encouraging results demonstrate the efficacy and superiority of the proposed scheme.},
  archive      = {J_PAAA},
  author       = {Wang, Xiangyang and Zhang, Yuyang and Tian, Jialin and Niu, Panpan and Yang, Hongying},
  doi          = {10.1007/s10044-022-01071-6},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {731-755},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Accurate quaternion fractional-order pseudo-Jacobi–Fourier moments},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiple regularization and analysis of deep capsule
network. <em>PAAA</em>, <em>25</em>(4), 711–729. (<a
href="https://doi.org/10.1007/s10044-022-01070-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase of layers in deep capsule networks, the overfitting problem also becomes more serious. Capsule-based regularization methods are important to solve this problem. However, little attention has been paid to this field. To fill this gap, we propose five regularization methods from the following aspects. In capsules represented by vectors, two methods are proposed to modify the existence and properties of their activation vectors by disturbing the length and orientation of the vectors. In capsules represented by tensors, capsule-based layer normalization is proposed to improve dynamic routing. In the training strategy, a warm restart learning rate with probability is used to improve the efficiency of training. In reconstruction, a novel image decoder provides a better regularization effect by using multiscale information of images. These regularization methods are investigated on CIFAR10, CIFAR100, and SVHN. Experiments show that using these regularization methods can effectively improve the generalization performance.},
  archive      = {J_PAAA},
  author       = {Sun, Kun and Xu, Haixia and Yuan, Liming and Wen, Xianbin},
  doi          = {10.1007/s10044-022-01070-7},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {711-729},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multiple regularization and analysis of deep capsule network},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic clustering based on dynamic parameters harmony
search optimization algorithm. <em>PAAA</em>, <em>25</em>(4), 693–709.
(<a href="https://doi.org/10.1007/s10044-022-01065-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a typical unsupervised learning technique, clustering has been widely applied. However, in many cases, prior information about the number of clusters is unknown, so how to determine it automatically in clustering is getting more attention. In this article, a method named automatic clustering based on dynamic parameters harmony search optimization algorithm, i.e., AC-DPHS, is proposed to solve this problem. By improving the basic harmony search (HS), the dynamic parameters harmony search (DPHS) is devised, which makes the parameters change dynamically without pre-definition. The AC-DPHS takes advantage of the merits of both DPHS and K-means clustering and can determine the optimal number of clusters automatically. A comprehensive experiment is carried out to evaluate the performance of AC-DPHS. The results illustrate that the AC-DPHS generated by using the PBM validity index as its fitness function is relatively superior, and it performs over other approaches developed recently in real-life data clustering as well as grayscale images segmentation. Consequently, the method explained in this article is effectiveness and practical, which can be considered as a new automatic clustering scheme.},
  archive      = {J_PAAA},
  author       = {Zhu, Qidan and Tang, Xiangmeng and Elahi, Ahsan},
  doi          = {10.1007/s10044-022-01065-4},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {693-709},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Automatic clustering based on dynamic parameters harmony search optimization algorithm},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). JSE: Joint semantic encoder for zero-shot gesture learning.
<em>PAAA</em>, <em>25</em>(3), 679–692. (<a
href="https://doi.org/10.1007/s10044-021-00992-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning (ZSL) is a transfer learning paradigm that aims to recognize unseen categories just by having a high-level description of them. While deep learning has greatly pushed the limits of ZSL for object classification, ZSL for gesture recognition (ZSGL) remains largely unexplored. Previous attempts to address ZSGL were focused on the creation of gesture attributes and algorithmic improvements, and there is little or no research concerned with feature selection for ZSGL. It is indisputable that deep learning has obviated the need for feature engineering for problems with large datasets. However, when the data are scarce, it is critical to leverage the domain information to create discriminative input features. The main goal of this work is to study the effect of three different feature extraction techniques (velocity, heuristical and latent features) on the performance of ZSGL. In addition, we propose a bilinear auto-encoder approach, referred to as Joint Semantic Encoder (JSE), for ZSGL that jointly minimizes the reconstruction, semantic and classification losses. We conducted extensive experiments to compare and contrast the feature extraction techniques and to evaluate the performance of JSE with respect to existing ZSL methods. For attribute-based classification scenario, irrespective of the feature type, results showed that JSE outperforms other approaches by 5% (p&lt;0.01). When JSE is trained with heuristical features in across-category condition, we showed that JSE significantly outperforms other methods by 5% (p&lt;0.01)).},
  archive      = {J_PAAA},
  author       = {Madapana, Naveen and Wachs, Juan},
  doi          = {10.1007/s10044-021-00992-y},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {679-692},
  shortjournal = {Pattern Anal. Appl.},
  title        = {JSE: Joint semantic encoder for zero-shot gesture learning},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep transfer learning in human–robot interaction for
cognitive and physical rehabilitation purposes. <em>PAAA</em>,
<em>25</em>(3), 653–677. (<a
href="https://doi.org/10.1007/s10044-021-00988-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the extraction of the emotional signals from traumatic brain-injured (TBI) patients through the analysis of facial features and implementation of the effective emotion-recognition model through the Pepper robot to assist in the rehabilitation process. The identification of emotional cues from TBI patients is very challenging due to unique and diverse psychological, physiological, and behavioral challenges such as non-cooperation, facial/body paralysis, upper or lower limb impairments, cognitive, motor, and hearing skills inhibition. It is essential to read subtle changes in the emotional cues of TBI patients for effective communication and the development of affect-based systems. To analyze the variations of the emotional signal in TBI patients, a new database is collected in a natural and unconstrained environment from eleven residents of a neurological center in three different modalities, RGB, thermal and depth in three specified scenarios performing physical, cognitive and social communication rehabilitation activities. Due to the lack of labeled data, a deep transfer learning method is applied to efficiently classify emotions. The emotion classification model is tested through closed-field study and installment of a Pepper robot equipped with the trained model. Our deep trained and fine-tuned emotional recognition model composed of CNN-LSTM has improved the performance by 1.47% on MMI, and 4.96% on FER2013 validation data set. In addition, use of temporal information and transfer learning techniques to overcome TBI-data limitations has increased the performance efficacy on challenging dataset of neurologically impaired people. Findings that emerged from the study illustrate the noticeable effectiveness of SoftBank Pepper robot equipped with deep trained emotion recognition model in developing rehabilitation strategies by monitoring the TBI patient’s emotions. This research article presents the technical solution for real therapeutic robot interaction to rehabilitate patients with standard monitoring, assessment, and feedback in the neuro centers.},
  archive      = {J_PAAA},
  author       = {Ilyas, Chaudhary Muhammad Aqdus and Rehm, Matthias and Nasrollahi, Kamal and Madadi, Yeganeh and Moeslund, Thomas B. and Seydi, Vahid},
  doi          = {10.1007/s10044-021-00988-8},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {653-677},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Deep transfer learning in human–robot interaction for cognitive and physical rehabilitation purposes},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assessing facial symmetry and attractiveness using augmented
reality. <em>PAAA</em>, <em>25</em>(3), 635–651. (<a
href="https://doi.org/10.1007/s10044-021-00975-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial symmetry is a key component in quantifying the perception of beauty. In this paper, we propose a set of facial features computed from facial landmarks which can be extracted at a low computational cost. We quantitatively evaluated the proposed features for predicting perceived attractiveness from human portraits on four benchmark datasets (SCUT-FBP, SCUT-FBP5500, FACES and Chicago Face Database). Experimental results showed that the performance of the proposed features is comparable to those extracted from a set with much denser facial landmarks. The computation of facial features was also implemented as an augmented reality (AR) app developed on Android OS. The app overlays four types of measurements and guidelines over a live video stream, while the facial measurements are computed from the tracked facial landmarks at run time. The developed app can be used to assist plastic surgeons in assessing facial symmetry when planning reconstructive facial surgeries.},
  archive      = {J_PAAA},
  author       = {Wei, Wei and Ho, Edmond S. L. and McCay, Kevin D. and Damaševičius, Robertas and Maskeliūnas, Rytis and Esposito, Anna},
  doi          = {10.1007/s10044-021-00975-z},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {635-651},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Assessing facial symmetry and attractiveness using augmented reality},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic estimation of clothing insulation rate and
metabolic rate for dynamic thermal comfort assessment. <em>PAAA</em>,
<em>25</em>(3), 619–634. (<a
href="https://doi.org/10.1007/s10044-021-00961-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing heating, ventilation, and air-conditioning systems have difficulties in considering occupants’ dynamic thermal needs, thus resulting in overheating or overcooling with huge energy waste. This situation emphasizes the importance of occupant-oriented microclimate control where dynamic individual thermal comfort assessment is the key. Therefore, in this paper, a vision-based approach to estimate individual clothing insulation rate ( $$I_{\rm{cl}}$$ ) and metabolic rate (M), the two critical factors to assess personal thermal comfort level, is proposed. Specifically, with a thermal camera as the input source, a convolutional neural network (CNN) is implemented to recognize an occupant’s clothes type and activity type simultaneously. The clothes type then helps to differentiate the skin region from the clothing-covered region, allowing to calculate the skin temperature and the clothes temperature. With the two recognized types and the two computed temperatures, $$I_{\rm{cl}}$$ and M can be estimated effectively. In the experimental phase, a novel thermal dataset is introduced, which allows evaluations of the CNN-based recognizer module, the skin and clothes temperatures acquisition module, as well as the $$I_{\rm{cl}}$$ and M estimation module, proving the effectiveness and automation of the proposed approach.},
  archive      = {J_PAAA},
  author       = {Liu, Jinsong and Foged, Isak Worre and Moeslund, Thomas B.},
  doi          = {10.1007/s10044-021-00961-5},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {619-634},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Automatic estimation of clothing insulation rate and metabolic rate for dynamic thermal comfort assessment},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Age and gender effects on the human’s ability to decode
posed and naturalistic emotional faces. <em>PAAA</em>, <em>25</em>(3),
589–617. (<a href="https://doi.org/10.1007/s10044-021-01049-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a systematic approach to investigate the impact of factors such as the gender and age of participants and gender, and age of faces on the decoding accuracy of emotional expressions of disgust, anger, sadness, fear, happiness, and neutrality. The emotional stimuli consisted of 76 posed and 76 naturalistic faces, differently aged (young, middle-aged, and older) selected from FACES and SFEW databases. Either a posed or naturalistic faces’ decoding task was administered. The posed faces’ decoding task involved three differently aged groups (young, middle-aged, and older adults). The naturalistic faces’ decoding task involved two groups of older adults. For the posed decoding task, older adults were found significantly less accurate than middle-aged and young participants, and middle-aged significantly less accurate than young participants. Old faces were significantly less accurately decoded than young and middle-aged faces of disgust, and anger, and young faces of fear, and neutrality. Female faces were significantly more accurately decoded than male faces of anger and sadness, significantly less accurately decoded than male faces of neutrality. For the naturalistic decoding task, older adults were significantly less accurate in decoding naturalistic rather than posed faces of disgust, fear, and neutrality, contradicting an older adults’ emended support from a prior naturalistic emotional experience. Young faces were more accurately decoded than old and middle-aged faces of disgust and anger and old faces of neutrality. Female faces were significantly more accurately decoded than male faces of fear, and significantly less accurately decoded than male faces of anger. Significant effects and significant interdependencies were observed among the age of participants, emotional categories, age, and gender of faces, and type of stimuli (naturalistic vs. posed), not allowing to distinctly isolate the effects of each involved variable. Nevertheless, the data collected in this paper weakens both the assumptions on women enhanced ability to display and decode emotions and participants enhanced ability to decode faces closer to their own age (“own age bias” theory). Considerations are made on how these data would guide the development of assessment tools and preventive interventions and the design of emotionally and socially believable virtual agents and robots to assists and coach emotionally vulnerable people in their daily routines.},
  archive      = {J_PAAA},
  author       = {Esposito, Anna and Amorese, Terry and Cuciniello, Marialucia and Riviello, Maria Teresa and Cordasco, Gennaro},
  doi          = {10.1007/s10044-021-01049-w},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {589-617},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Age and gender effects on the human’s ability to decode posed and naturalistic emotional faces},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Probabilistic elderly person’s mood analysis based on its
activities of daily living using smart facilities. <em>PAAA</em>,
<em>25</em>(3), 575–588. (<a
href="https://doi.org/10.1007/s10044-021-01034-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The world&#39;s population is aging, and eldercare services that use smart facilities such as smart homes are widely common in societies now. With the aid of smart facilities, the present study aimed at understanding an elder&#39;s moods based on the person’s activities of daily living (ADLs). With this end in view, an explainable probabilistic graphical modeling approach, applying the Bayesian network (BN), was proposed. The proposed BN-based model was capable of defining the relationship between the elder&#39;s ADLs and moods in three different levels: Activity-based Feature (AbF), Category of Activity (CoA), and the mood state. The model also allowed us to explain the transformations among the different levels/nodes on the defined BNs. A framework featured with smart facilities, including a smart home, a smartphone, and a wristband, was utilized to assess the model. The smart home was an elderly woman&#39;s house, equipped with a set of binary-based sensors. For about five months, the ADLs&#39; data have been recorded through daily behavioral-based information, registered by experts using a defined questionnaire. The obtained results proved that the proposed BN-based model of the current study could promisingly estimate the elder&#39;s moods and CoA states. Moreover, in contrast to the machine learning techniques that behave like a black box, the effect of each feature from the lower levels to the higher levels of information of the BNs can be traced. Implications of the findings for future diagnosis and treatment of the elderly are considered.},
  archive      = {J_PAAA},
  author       = {Falah Rad, Mohsen and Shakeri, Mojtaba and Khoshhal Roudposhti, Kamrad and Shakerinia, Iraj},
  doi          = {10.1007/s10044-021-01034-3},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {575-588},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Probabilistic elderly person’s mood analysis based on its activities of daily living using smart facilities},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pain detection from facial expressions using domain
adaptation technique. <em>PAAA</em>, <em>25</em>(3), 567–574. (<a
href="https://doi.org/10.1007/s10044-021-01025-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pain management is gaining the attention of clinical practitioners to relieve patients from pain in an effective manner. Pain management is primarily dependent on pain measurement. Researchers have proposed various techniques to measure pain from facial expressions improving the accuracy and efficiency of the traditional pain measurement such as self-reporting and visual analog scale. Developments in the field of deep learning have further enhanced the pain assessment technique. Despite of the state of the art performance of deep learning algorithms, adaptation to new subjects is still a problem due to availability of a few samples of the same. Authors have addressed this issue by employing a model agnostic meta-learning algorithm for pain detection and fast adaptation of the trained algorithm for new subjects using only a few labeled images. The model is pre-trained with labeled images of subjects with five pain levels to acquire meta-knowledge in the presented work. This meta-knowledge is then used to adapt the model to a new learning task in the form of a new subject. The proposed model is evaluated on a benchmark dataset, i.e., UNBC McMaster pain archive database. Experimental results show that the model can be very easily adapted to new subjects with the accuracy of $$96\%$$ and $$98\%$$ for 1-shot and 5-shot learning respectively, proving the potential of the proposed algorithm for clinical use.},
  archive      = {J_PAAA},
  author       = {Rathee, Neeru and Pahal, Sudesh and Sheoran, Poonam},
  doi          = {10.1007/s10044-021-01025-4},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {567-574},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Pain detection from facial expressions using domain adaptation technique},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Facial action unit detection methodology with application in
brazilian sign language recognition. <em>PAAA</em>, <em>25</em>(3),
549–565. (<a href="https://doi.org/10.1007/s10044-021-01024-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign Language is the linguistic system adopted by the Deaf to communicate. The lack of fully-fledged Automatic Sign Language (ASLR) technologies contributes to the numerous difficulties that deaf individuals face in the absence of an interpreter, such as in private health appointments or in emergency situations. A challenging problem in the development of reliable ASLR systems is that sign languages do not rely only on manual gestures but also on facial expressions and other non-manual markers. This paper proposes to adopt Facial Action Coding System to encode sign language facial expressions. However, the state-of-the-art of Action Unit (AU) recognition models is mostly targeted to classify two dozen of AUs, typically related to the expression of emotions. We adopted Brazilian Sign Language (Libras) as our case study and we identified more than one hundred of AUs (with a great intersection with other sign languages). We then implemented and evaluated a novel AU recognition model architecture that combines SqueezeNet and geometric-based features. Our model obtained 88% of accuracy for 119 classes. Combined with the state-of-the-art of gesture recognition, our model is ready to improve sign disambiguation and to advance ASLR.},
  archive      = {J_PAAA},
  author       = {da Silva, Emely Pujólli and Costa, Paula Dornhofer Paro and Kumada, Kate Mamhy Oliveira and De Martino, José Mario},
  doi          = {10.1007/s10044-021-01024-5},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {549-565},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Facial action unit detection methodology with application in brazilian sign language recognition},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Harnessing emotions for depression detection. <em>PAAA</em>,
<em>25</em>(3), 537–547. (<a
href="https://doi.org/10.1007/s10044-021-01020-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human emotions using textual cues, speech patterns, and facial expressions can give insight into their mental state. Although there are several uni-modal datasets for emotion recognition, there are very few labeled datasets for multi-modal depression detection. Uni-modal emotion recognition datasets can be harnessed, using the technique of transfer learning, for multi-modal binary emotion detection through video, audio, and text. We propose emotion transfer for mood indication framework based on deep learning to address the task of binary classification of depression using a one-of-three scheme: If the prediction from the network for at least one modality is of the depressed class, we consider the final output as depressed. Such a scheme is beneficial since it will detect an abnormality in any of the modalities and will alert a user to seek help well in advance. Long short-term memory is used to combine the temporal aspects of the audio and the video modalities, and the context of the text. This is followed by fine-tuning the network on a binary dataset for depression detection that has been independently labeled by a standard questionnaire used by psychologists. Data augmentation techniques are used for the generalization of data and to resolve the class imbalance. Our experiments show that our method for binary depression classification (using an ensemble of three modalities) on the Distress Analysis Interview Corpus—Wizard of Oz dataset has higher accuracy in comparison with other benchmark methods.},
  archive      = {J_PAAA},
  author       = {Prabhu, Sahana and Mittal, Himangi and Varagani, Rajesh and Jha, Sweccha and Singh, Shivendra},
  doi          = {10.1007/s10044-021-01020-9},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {537-547},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Harnessing emotions for depression detection},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Automatic stress analysis from facial videos based on deep
facial action units recognition. <em>PAAA</em>, <em>25</em>(3), 521–535.
(<a href="https://doi.org/10.1007/s10044-021-01012-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stress conditions are manifested in different human body’s physiological processes and the human face. Facial expressions are modelled consistently through the Facial Action Coding System (FACS) using the facial Action Units (AU) parameters. This paper focuses on the automated recognition and analysis of AUs in videos as quantitative indices to discriminate between neutral and stress states. A novel deep learning pipeline for automatic recognition of facial action units is proposed, relying on two publicly available annotated facial datasets for training, the UNBC and the BOSPHORUS datasets. Two types of descriptive facial features are extracted from the input images, geometric features (non-rigid 3D facial deformations due to facial expressions) and appearance features (deep facial appearance features). The extracted facial features are then fed to deep fully connected layers that regress AU intensities and robustly perform AU classification. The proposed algorithm is applied to the SRD’15 stress dataset, which contains neutral and stress states related to four types of stressors. We present thorough experimental results and comparisons, which indicate that the proposed methodology yields particularly promising performance in terms of both AU detection and stress recognition accuracy. Furthermore, the AUs relevant to stress were experimentally identified, providing evidence that their intensity is significantly increased during stress, which leads to a more expressive human face as compared to neutral states.},
  archive      = {J_PAAA},
  author       = {Giannakakis, Giorgos and Koujan, Mohammad Rami and Roussos, Anastasios and Marias, Kostas},
  doi          = {10.1007/s10044-021-01012-9},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {521-535},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Automatic stress analysis from facial videos based on deep facial action units recognition},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SL-animals-DVS: Event-driven sign language animals dataset.
<em>PAAA</em>, <em>25</em>(3), 505–520. (<a
href="https://doi.org/10.1007/s10044-021-01011-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-intrusive visual-based applications supporting the communication of people employing sign language for communication are always an open and attractive research field for the human action recognition community. Automatic sign language interpretation is a complex visual recognition task where motion across time distinguishes the sign being performed. In recent years, the development of robust and successful deep-learning techniques has been accompanied by the creation of a large number of databases. The availability of challenging datasets of Sign Language (SL) terms and phrases helps to push the research to develop new algorithms and methods to tackle their automatic recognition. This paper presents ‘SL-Animals-DVS’, an event-based action dataset captured by a Dynamic Vision Sensor (DVS). The DVS records non-fluent signers performing a small set of isolated words derived from SL signs of various animals as a continuous spike flow at very low latency. This is especially suited for SL signs which are usually made at very high speeds. We benchmark the recognition performance on this data using three state-of-the-art Spiking Neural Networks (SNN) recognition systems. SNNs are naturally compatible to make use of the temporal information that is provided by the DVS where the information is encoded in the spike times. The dataset has about 1100 samples of 59 subjects performing 19 sign language signs in isolation at different scenarios, providing a challenging evaluation platform for this emerging technology.},
  archive      = {J_PAAA},
  author       = {Vasudevan, Ajay and Negri, Pablo and Di Ielsi, Camila and Linares-Barranco, Bernabe and Serrano-Gotarredona, Teresa},
  doi          = {10.1007/s10044-021-01011-w},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {505-520},
  shortjournal = {Pattern Anal. Appl.},
  title        = {SL-animals-DVS: Event-driven sign language animals dataset},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodal temporal machine learning for bipolar disorder
and depression recognition. <em>PAAA</em>, <em>25</em>(3), 493–504. (<a
href="https://doi.org/10.1007/s10044-021-01001-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mental disorder is a serious public health concern that affects the life of millions of people throughout the world. Early diagnosis is essential to ensure timely treatment and to improve the well-being of those affected by a mental disorder. In this paper, we present a novel multimodal framework to perform mental disorder recognition from videos. The proposed approach employs a combination of audio, video and textual modalities. Using recurrent neural network architectures, we incorporate the temporal information in the learning process and model the dynamic evolution of the features extracted for each patient. For multimodal fusion, we propose an efficient late fusion strategy based on a simple feed-forward neural network that we call adaptive nonlinear judge classifier. We evaluate the proposed framework on two mental disorder datasets. On both, the experimental results demonstrate that the proposed framework outperforms the state-of-the-art approaches. We also study the importance of each modality for mental disorder recognition and infer interesting conclusions about the temporal nature of each modality. Our findings demonstrate that careful consideration of the temporal evolution of each modality is of crucial importance to accurately perform mental disorder recognition.},
  archive      = {J_PAAA},
  author       = {Ceccarelli, Francesco and Mahmoud, Marwa},
  doi          = {10.1007/s10044-021-01001-y},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {493-504},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multimodal temporal machine learning for bipolar disorder and depression recognition},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Guest editorial: Special issue on computer vision and
machine learning for healthcare applications. <em>PAAA</em>,
<em>25</em>(3), 489–492. (<a
href="https://doi.org/10.1007/s10044-022-01075-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_PAAA},
  author       = {Palmero, Cristina and Torres, Maria Inés and Esposito, Anna and Escalera, Sergio},
  doi          = {10.1007/s10044-022-01075-2},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {489-492},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Guest editorial: Special issue on computer vision and machine learning for healthcare applications},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Correction to: Automatic stress analysis from facial videos
based on deep facial action units recognition. <em>PAAA</em>,
<em>25</em>(2), 487–488. (<a
href="https://doi.org/10.1007/s10044-022-01060-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A correction to this paper has been published: 10.1007/s10044-021-01012-9},
  archive      = {J_PAAA},
  author       = {Giannakakis, Giorgos and Koujan, Mohammad Rami and Roussos, Anastasios and Marias, Kostas},
  doi          = {10.1007/s10044-022-01060-9},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {487-488},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Correction to: Automatic stress analysis from facial videos based on deep facial action units recognition},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Action recognition by key trajectories.
<em>PAAA</em>, <em>25</em>(2), 485. (<a
href="https://doi.org/10.1007/s10044-022-01061-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_PAAA},
  author       = {Camarena, Fernando and Chang, Leonardo and Gonzalez‑Mendoza, Miguel and Cuevas‑Ascencio, Ricardo J.},
  doi          = {10.1007/s10044-022-01061-8},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {485},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Correction to: Action recognition by key trajectories},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Correction to: Probabilistic elderly person’s mood analysis
based on its activities of daily living using smart facilities.
<em>PAAA</em>, <em>25</em>(2), 483. (<a
href="https://doi.org/10.1007/s10044-021-01056-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_PAAA},
  author       = {Falah Rad, Mohsen and Shakeri, Mojtaba and Khoshhal Roudposhti, Kamrad and Shakerinia, Iraj},
  doi          = {10.1007/s10044-021-01056-x},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {483},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Correction to: Probabilistic elderly person’s mood analysis based on its activities of daily living using smart facilities},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Object-based hyperspectral image classification using a new
latent block model based on hidden markov random fields. <em>PAAA</em>,
<em>25</em>(2), 467–481. (<a
href="https://doi.org/10.1007/s10044-021-01050-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient high-dimensional analyses of hyperspectral datasets and their utilization within classification algorithms is a popular topic in the field of data analytics. A powerful tool for summarizing a large array of datasets is the latent block model (LBM), which finds homogeneous blocks within the data using the finite mixture model (FMM). In this study, for the first time, LBM was modified by replacing the hidden Markov random field (HMRF) instead of using FMM to consider the spatial relationship between pixels and, thus, to develop a new object-based classification algorithm. The proposed clustering algorithm was named LBMHMRF and was used along with the support vector machine (SVM) algorithm to classify land cover/land use (LCLU) categories using two hyperspectral datasets. Unlike LBM, HMRF, and MultiHMRF, the LBMHMRF algorithm allows for the use of more spectral information without estimating a large number of parameters and produces a model with high computation costs saving feature. Additionally, the segmentation results are produced in a shorter period of time compared to the above-mentioned algorithms. It was observed that the proposed object-based classification algorithm (i.e., LBMHMRF + SVM) had the highest potential in terms of visual and statistical accuracies as well as computation time compared to the pixel-based SVM, object-based HMRF + SVM, and MultiHMRF + SVM. The average overall classification accuracies considering the different datasets and cases investigated in this study were 93.1%, 94.6%, 95.7%, and 96.4% for SVM, HMRF + SVM, MultiHMRF + SVM, and LBMHMRF + SVM, respectively.},
  archive      = {J_PAAA},
  author       = {Fatemighomi, Hamideh Sadat and Golalizadeh, Mousa and Amani, Meisam},
  doi          = {10.1007/s10044-021-01050-3},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {467-481},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Object-based hyperspectral image classification using a new latent block model based on hidden markov random fields},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fully automated age-weighted expression classification using
real and apparent age. <em>PAAA</em>, <em>25</em>(2), 451–466. (<a
href="https://doi.org/10.1007/s10044-021-01044-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After decades of research, automatic facial expression recognition (AFER) has been shown to work well when restricted to subjects with a limited range of ages. Expression recognition in subjects having a large range of ages is harder as it has been shown that ageing, health, and lifestyle affect facial expression. In this paper, we present a discriminative system that explicitly predicts expression across a large range of ages, which we show to perform better than an equivalent system which ignores age. In our system, we first build a fully automatic facial feature point detector (FFPD) using random forest regression voting in a constrained local mode (RFRV-CLM) framework (Cootes et al., in: European conference on computer vision, Springer, Berlin, 2012) which we use to automatically detect the location of key facial points, study the effect of ageing on the accuracy of point localization task. Second, a set of age group estimator and age-specific expression recognizers are trained from the extracted features that include shape, texture, appearance and a fusion of shape with texture, to analyse the effect of ageing on the face features and subsequently on the performance of AFER. We then propose a simple and effective method to recognize the expression across a large range of ages through using a weighted combination rule of a set of age group estimator and age specific expression recognizers (one for each age group), where the age information is used as prior knowledge to the expression classification. The advantage of using the weighted combination of all the classifiers is that more information about the classification can be obtained and subjects whose apparent age puts them in the wrong chronological age group will be dealt with more effectively. The performance of the proposed system was evaluated using three age-expression databases of static and dynamic images for deliberate and spontaneous expressions: FACES (Ebner et al., in Behav Res Methods 42:351–362, 2010) (2052 images), Lifespan (Minear and Park in Behav Res Methods Instrum Comput 36:630–633, 2004) (844 images) and NEMO (Dibeklioğlu et al., in: European conference on computer vision, Springer, Berlin, 2012) (1,243 videos). The results show the system to be accurate and robust against a wide variety of expressions and the age of the subject. Evaluation of point localization, age group estimation and expression recognition against ground truth data was obtained and compared with the existing results of alternative approaches tested on the same data. The quantitative results with 2.1% error rates (using manual points) and 3.0% error rates (fully automatic) of expression classification demonstrated that the results of our novel system were encouraging in comparison with the state-of-the-art systems which ignore age and alternative models recently applied to the problem.},
  archive      = {J_PAAA},
  author       = {Al-Garaawi, Nora and Morris, Tim and Cootes, Timothy F.},
  doi          = {10.1007/s10044-021-01044-1},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {451-466},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Fully automated age-weighted expression classification using real and apparent age},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of winter road friction coefficient based on
multi-task distillation attention network. <em>PAAA</em>,
<em>25</em>(2), 441–449. (<a
href="https://doi.org/10.1007/s10044-022-01059-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road friction coefficient estimation is an important task in the perception system of autonomous driving vehicles. It enables the vehicle to perceive upcoming road friction conditions and helps the decision-making system to adjust the driving styles accordingly in case of potential traffic accidents caused by tire slip. However, to our knowledge, there is currently no recognized image benchmark dataset in this field with enough weather diversity for this task. And many existing methods are measured under different standards. In this work, we present a road friction coefficient estimation dataset that includes all-weather traffic conditions, which is called the winter road friction (WRF) dataset. Then, a novel friction coefficient estimation model based on multi-task distillation attention network (MDAN) is proposed to solve this task in an end-to-end way. The proposed model surpasses existing methods in this field and reaches 86.53% Acc on the WRF dataset. The WRF dataset will be made publicly available at https://github.com/blackholeLFL/The-WRF-dataset soon.},
  archive      = {J_PAAA},
  author       = {Liu, Feilin and Wu, Yan and Yang, Xinneng and Mo, Yujian and Liao, Yujun},
  doi          = {10.1007/s10044-022-01059-2},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {441-449},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Identification of winter road friction coefficient based on multi-task distillation attention network},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structured classifier-based dictionary pair learning for
pattern classification. <em>PAAA</em>, <em>25</em>(2), 425–440. (<a
href="https://doi.org/10.1007/s10044-021-01046-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The supervised dictionary learning methods have made considerable achievements in the field of pattern recognition. In order to make the learned coefficients have intraclass similarity and interclass incoherence, many dictionary learning methods have been proposed using different structured constraints. However, these constraints often have the disadvantages of complexity, time-consuming, and poor interpretability. More importantly, the existing dictionary learning often ignores the inherent structure of the label matrix. In this paper, we propose a dictionary pair learning based on the structured classifier and perform classifier learning and structured coefficients learning simultaneously. Our main idea is to use the extended label matrix and the invertible constraints on the classification transformation matrix to utilize the structure of the label matrix to impose structured constraints on coefficients. Moreover, the $$l_{21}$$ -norm is added to force the analysis dictionary to focus on more important features. Experimental results on multiple databases prove that our proposed method has better classification performance than several state-of-the-art dictionary learning methods.},
  archive      = {J_PAAA},
  author       = {Cai, Yu-Hong and Wu, Xiao-Jun and Chen, Zhe and Xu, Tian-Yang},
  doi          = {10.1007/s10044-021-01046-z},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {425-440},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Structured classifier-based dictionary pair learning for pattern classification},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Action recognition by key trajectories. <em>PAAA</em>,
<em>25</em>(2), 409–423. (<a
href="https://doi.org/10.1007/s10044-021-01054-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action recognition is an active field of research that intends to explain what a subject is doing in an input video. Deep learning architectures serve as the foundation for cutting-edge approaches. Recent research, on the other hand, indicates that hand-crafted characteristics are complementary and, when combined, can enhance classification accuracy. Cutting-edge approaches are based on deep learning architectures. Recent research, however, indicates that hand-crafted features complement each other and can help boost classification accuracy when combined. We introduce the key trajectories approach that is based on the popular, hand-crafted method, improved dense trajectories. Our work explores how pose estimation can be used to find meaningful key points to reduce computational time, undesired noise, and to guarantee a stable frame processing rate. Furthermore, we tested how feature-tracking behaves with dense inverse search and with a frame to frame subject key point estimation. Our proposal was tested on the KTH and UCF11 datasets employing Bag-of-words and on the UCF50 and HMDB datasets using Fisher Vector, where we got an accuracy performance of 95.71, 84.88, 92.9, and 81.3%, respectively. Also, our proposal can recognize subject actions in video eight times faster compared to its dense counterpart. To maximize the bag-of-words classification performance, we illustrate how the hyperparameters affect both accuracy and computation time. Precisely, we present an exploration of the vocabulary size, the SVM hyperparameter, the descriptor’s distinctiveness, and the subject body key points.},
  archive      = {J_PAAA},
  author       = {Camarena, Fernando and Chang, Leonardo and Gonzalez-Mendoza, Miguel and Cuevas-Ascencio, Ricardo J},
  doi          = {10.1007/s10044-021-01054-z},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {409-423},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Action recognition by key trajectories},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finger knuckle pattern person authentication system based on
monogenic and LPQ features. <em>PAAA</em>, <em>25</em>(2), 395–407. (<a
href="https://doi.org/10.1007/s10044-021-01047-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contemporary biometrics is a swiftly broad field of research. Nowadays, biometrics is predominantly being deployed as a personal identification system in diver&#39;s real-world applications. Despite remarkable progress, their performance remains insufficient for security applications. To date, Finger Knuckle Print (FKP) has been explored as a potential biometric characteristic to attain acceptable accuracy and security. This paper presents a novel and efficient scheme to extract features from FKP images, namely Monogenic Local Phase Quantization (M-LPQ), for FKP recognition. First, the monogenic filters are applied to decompose the ROI of FKP images into three complementary parts: the band pass, vertical and horizontal band pass components. Next, we compute the local energy, phase, and local orientation. At that point, LPQ descriptor is endeavoring to encode these complementary parts to compute histograms. These histograms’ sequences are concatenated together in the subsequent stage to build an enormous feature vector. To reduce the dimension of the M-LQP features vectors for FKP recognition, Principal Component Analysis and Linear Discriminant Analysis are employed. Ultimately, the Mahalanobis Cosine Distance is used to determine the person&#39;s identity. Exploratory outputs show that the introduced framework strikingly achieved lower error rates and yield played out the cutting edge strategies. As a consequence, we were able to get good outcomes by fusing all combinations of four fingers with 99.90 percent Recognition Rate and 0.01 percent EER value.},
  archive      = {J_PAAA},
  author       = {Lakshmanan, Sathiya and Velliyan, Palanisamy and Attia, Abdelouahab and Chalabi, Nour Elhouda},
  doi          = {10.1007/s10044-021-01047-y},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {395-407},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Finger knuckle pattern person authentication system based on monogenic and LPQ features},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Directional filter bank-based fingerprint image quality.
<em>PAAA</em>, <em>25</em>(2), 379–393. (<a
href="https://doi.org/10.1007/s10044-021-01042-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fingerprint image quality ensures that only the high-quality fingerprints containing a good amount of features are used for verification. Fingerprint matching accuracy depends heavily on the quality of the fingerprints. In this paper, we have proposed a new fingerprint image quality method based on the Directional Filter Banks (DFB). The fingerprint image is decomposed into subbands using the DFB. The similarity between the different subbands is used to calculate the fingerprint image quality. We have compared the performance of the proposed method with the ten existing fingerprint quality estimation methods with special emphasis on widely used fingerprint quality metrics NFIQ and NFIQ 2.0. The experimental results on the top three high-quality fingerprints in the FVC 2004 DB2A dataset show an equal error rate (EER) of 5.59% for the proposed method as compared with 5.74% and 7.95% for NFIQ 2.0 and NFIQ, respectively. Ranked EER, ROC, and error-reject curves show that DFB-based method is a good predictor of matching performance, and it outperforms the existing fingerprint quality methods. We have also analyzed the effect of the partial fingerprints on the fingerprint recognition system using the FVC 2004 DB1A dataset. The presence of partial fingerprints has an adverse effect on the recognition system. The equal error rate increases from 2.34 to 13.93% in partial fingerprint recognition. The proposed DFB-based method rightly assigns low-quality values to partial fingerprints.},
  archive      = {J_PAAA},
  author       = {Hendre, Manik and Patil, Suraj and Abhyankar, Aditya},
  doi          = {10.1007/s10044-021-01042-3},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {379-393},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Directional filter bank-based fingerprint image quality},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Image interpolation based on 2D-DWT and HDP-HMM.
<em>PAAA</em>, <em>25</em>(2), 361–377. (<a
href="https://doi.org/10.1007/s10044-022-01057-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a nonparametric approach with the purpose of estimating discrete wavelet transform (DWT) sub-band coefficients for high performance image interpolation. The number of clusters of defined statistical model that represents wavelet coefficients during the learning process is not fixed. The interpolating method is based on Hierarchical Dirichlet Process (HDP) where it uses the Blocked Gibbs Sampling method to obtain the optimum final values. The proposed HDP-HMM exploits statistical inter-scale, and intra-scale dependencies of image sub-bands of three-level decomposed 2D-DWT. It derives sub-bands of low resolution (LR) image, to obtain sub-bands of desired high resolution (HR) image. This research implements Hidden Markov model (HMM) to model the wavelet coefficients, and HDP to model the observations. It uses a very small size dataset that contains both LR and HR images of the dataset. The sophisticated statistical model introduced of the paper has excellent results in terms of Peak-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), Feature Similarity Index (FSIM), and Edge PSNR (EPSNR). It also has a great capability of repressing disturbing artifact, due to ability to model statistical dependencies of distant pixels. This method, and other compared state-of-the-art methods, have implemented on eighteen test-benches, with different statistical properties.},
  archive      = {J_PAAA},
  author       = {Khalili Sadaghiani, AbdolVahab and Forouzandeh, Behjat},
  doi          = {10.1007/s10044-022-01057-4},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {361-377},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Image interpolation based on 2D-DWT and HDP-HMM},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A local mean-based distance measure for spectral clustering.
<em>PAAA</em>, <em>25</em>(2), 351–359. (<a
href="https://doi.org/10.1007/s10044-021-01040-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering has become very popular in recent years, due to the simplicity of its implementation and good performance in clustering non-convex data. Constructing a similarity graph based on an appropriate distance measure for modeling the local neighborhood relations among data samples is crucial for achieving an acceptable performance in spectral clustering. In this paper, we propose a fuzzy spectral clustering algorithm for poorly separated data with arbitrary shapes. Distinguishing poorly separated clusters is a challenging issue since a border point of a cluster may be more similar to the border points of the adjacent cluster than to the points in its own cluster. We propose a local mean-based distance measure which helps in separating points in cluster borders. The distance between a pair of points, in the proposed distance measure, is defined as the distance between the mean of their k nearest neighbors. We also propose a new transitive-based method for computing the membership degrees of points to clusters. Our evaluation results on both artificial and real data show that both the proposed local mean-based distance measure and the proposed membership computation method have significant impacts in obtaining performance improvement over the existing methods.},
  archive      = {J_PAAA},
  author       = {Motallebi, Hassan and Nasihatkon, Rabeeh and Jamshidi, Mina},
  doi          = {10.1007/s10044-021-01040-5},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {351-359},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A local mean-based distance measure for spectral clustering},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gram regularization for sparse and disentangled
representation. <em>PAAA</em>, <em>25</em>(2), 337–349. (<a
href="https://doi.org/10.1007/s10044-021-01033-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relationship between samples is often ignored when training neural networks for classification tasks. If properly utilized, such information can bring many benefits for the trained models. On the one hand, neural networks trained ignoring similarities between samples may represent different samples closely even if they belong to different classes, which undermines discrimination abilities of the trained models. On the other hand, regularizing inter-class and intra-class similarities in the feature space during training can effectively disentangle the representation between classes and make the representation sparse. To achieve this, a new regularization method is proposed to penalize positive inter-class similarities and negative intra-class similarities in the feature space. Experimental results show that the proposed method can not only obtain sparse and disentangled representation but also improve the performance of the trained models on many datasets.},
  archive      = {J_PAAA},
  author       = {Gao, Zhentao and Chen, Yuanyuan and Guo, Quan and Yi, Zhang},
  doi          = {10.1007/s10044-021-01033-4},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {337-349},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Gram regularization for sparse and disentangled representation},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explainable image classification with evidence
counterfactual. <em>PAAA</em>, <em>25</em>(2), 315–335. (<a
href="https://doi.org/10.1007/s10044-021-01055-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity of state-of-the-art modeling techniques for image classification impedes the ability to explain model predictions in an interpretable way. A counterfactual explanation highlights the parts of an image which, when removed, would change the predicted class. Both legal scholars and data scientists are increasingly turning to counterfactual explanations as these provide a high degree of human interpretability, reveal what minimal information needs to be changed in order to come to a different prediction and do not require the prediction model to be disclosed. Our literature review shows that existing counterfactual methods for image classification have strong requirements regarding access to the training data and the model internals, which often are unrealistic. Therefore, SEDC is introduced as a model-agnostic instance-level explanation method for image classification that does not need access to the training data. As image classification tasks are typically multiclass problems, an additional contribution is the introduction of the SEDC-T method that allows specifying a target counterfactual class. These methods are experimentally tested on ImageNet data, and with concrete examples, we illustrate how the resulting explanations can give insights in model decisions. Moreover, SEDC is benchmarked against existing model-agnostic explanation methods, demonstrating stability of results, computational efficiency and the counterfactual nature of the explanations.},
  archive      = {J_PAAA},
  author       = {Vermeire, Tom and Brughmans, Dieter and Goethals, Sofie and de Oliveira, Raphael Mazzine Barbossa and Martens, David},
  doi          = {10.1007/s10044-021-01055-y},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {315-335},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Explainable image classification with evidence counterfactual},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive target tracking based on channel attention and
multi-hierarchical convolutional features. <em>PAAA</em>,
<em>25</em>(2), 305–313. (<a
href="https://doi.org/10.1007/s10044-021-01043-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In most existing hierarchical convolution feature-based trackers, the extracted target features are redundant or insufficient to achieve accurate and robust tracking. To cope with this issue, we propose an adaptive target tracking based on channel attention and hierarchical convolutional features. First, we extract multi-layer features using VGG-M network to represent the different semantic information of the target. Channel attention module is introduced to obtain the weights of each channel for ensuring adaptation of our method to the target deformation. Then, we train the correlation filters of each layer online and compute the response map independently. To better overcome feature excessiveness, we fuse the corresponding responses by an adaptive fusion scheme. Finally, the exhaustive experimental analysis on public datasets OTB2015 and VOT2017 shows that the proposed algorithm outperforms several state-of-the-art algorithms and can track the target stably even in the case of disturbance.},
  archive      = {J_PAAA},
  author       = {Wang, Huisan and Zhang, Hongying},
  doi          = {10.1007/s10044-021-01043-2},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {305-313},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Adaptive target tracking based on channel attention and multi-hierarchical convolutional features},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Single-target visual tracking using color compression and
spatially weighted generalized gaussian mixture models. <em>PAAA</em>,
<em>25</em>(2), 285–304. (<a
href="https://doi.org/10.1007/s10044-021-01051-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual tracking is a challenging task in computer vision, which intends to estimate the motion state of the target of interest in subsequent video frames. In that context, it is well-known that the rapid movement and rotation of the target affects the tracking results. This article proposes a novel single-target tracking algorithm based on the spatially weighted generalized Gaussian mixture model framework. The clustering method for color compression in preprocessing is considered to modify the frames to make them have sharper distributions. Then, the mixture models are built to express the color statistical features of the aimed area and context. The segmentation weights obtained from the responsivity of the pixels in the candidate ellipse to the target and background will guide the update of the target position and size in a heuristic way. The adjustment of models will depend on the aspect ratio change of the bounding ellipse. The performance of the proposed approach is verified on public datasets and compared with other algorithms. The experimental results show that our method achieved more accurate and robust tracking.},
  archive      = {J_PAAA},
  author       = {Ge, Bingwei and Bouguila, Nizar and Fan, Wentao},
  doi          = {10.1007/s10044-021-01051-2},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {285-304},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Single-target visual tracking using color compression and spatially weighted generalized gaussian mixture models},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A visual tool for monitoring and detecting anomalies in
robot performance. <em>PAAA</em>, <em>25</em>(2), 271–283. (<a
href="https://doi.org/10.1007/s10044-021-01053-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robotic systems, both software and hardware components are equally important. However, scant attention has been devoted until now in order to detect anomalies/failures affecting the software component of robots while many proposals exist aimed at detecting physical anomalies. To bridge this gap, the present paper focuses on the study of anomalies affecting the software performance of a robot by using a novel visualization tool. Unsupervised visualization methods from the machine learning field are applied in order to upgrade the recently proposed Hybrid Unsupervised Exploratory Plots (HUEPs). Furthermore, Curvilinear Component Analysis and t-distributed stochastic neighbor embedding are added to the original HUEPs formulation and comprehensively compared. Furthermore, all the different combinations of HUEPs are validated in a real-life scenario. Thanks to this intelligent visualization of robot status, interesting conclusions can be obtained to improve anomaly detection in robot performance.},
  archive      = {J_PAAA},
  author       = {Basurto, Nuño and Cambra, Carlos and Herrero, Álvaro},
  doi          = {10.1007/s10044-021-01053-0},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {271-283},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A visual tool for monitoring and detecting anomalies in robot performance},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FGAAM: A fast and resizable genetic algorithm with
aggressive mutation for feature selection. <em>PAAA</em>,
<em>25</em>(2), 253–269. (<a
href="https://doi.org/10.1007/s10044-021-01000-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper introduces a modified version of a genetic algorithm with aggressive mutation (GAAM) called fGAAM (fast GAAM) that significantly decreases the time needed to find feature subsets of a satisfactory classification accuracy. To demonstrate the time gains provided by fGAAM both algorithms were tested on eight datasets containing different number of features, classes, and examples. The fGAAM was also compared with four reference methods: the Holland GA with and without penalty term, Culling GA, and NSGA II. Results: (i) The fGAAM processing time was about 35% shorter than that of the original GAAM. (ii) The fGAAM was also 20 times quicker than two Holland GAs and 50 times quicker than NSGA II. (iii) For datasets of different number of features, classes, and examples, another number of individuals, stored for further processing, provided the highest acceleration. On average, the best results were obtained when individuals from the last 10 populations were stored (time acceleration: 36.39%) or when the number of individuals to be stored was calculated by the algorithm itself (time acceleration: 35.74%). (iv) The fGAAM was able to process all datasets used in the study, even those that, because of their high number of features, could not be processed by the two Holland GAs and NSGA II.},
  archive      = {J_PAAA},
  author       = {Rejer, Izabela and Jankowski, Jarosław},
  doi          = {10.1007/s10044-021-01000-z},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {253-269},
  shortjournal = {Pattern Anal. Appl.},
  title        = {FGAAM: A fast and resizable genetic algorithm with aggressive mutation for feature selection},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning applied to emerald gemstone grading:
Framework proposal and creation of a public dataset. <em>PAAA</em>,
<em>25</em>(1), 241–251. (<a
href="https://doi.org/10.1007/s10044-021-01041-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The grading of gemstones is currently a manual procedure performed by gemologists. A popular approach uses reference stones, where those are visually inspected by specialists that decide which one of the available reference stone is the most similar to the inspected stone. This procedure is very subjective as different specialists may end up with different grading choices. This work proposes a complete framework that entails the image acquisition and goes up to the final stone categorization. The proposal is able to automate the entire process apart from including the stone in the created chamber for the image acquisition. It discards the subjective decisions made by specialists. This is the first work to propose a machine learning approach coupled with image processing techniques for emerald grading. The proposed framework achieves 98% of accuracy (correctly categorized stones), outperforming a deep learning approach. Furthermore, we also create and publish the used dataset that contains 192 images of emerald stones along with their extracted and pre-processed features.},
  archive      = {J_PAAA},
  author       = {Pena, F. B. and Crabi, D. and Izidoro, S. C. and Rodrigues, É. O. and Bernardes, G.},
  doi          = {10.1007/s10044-021-01041-4},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {241-251},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Machine learning applied to emerald gemstone grading: Framework proposal and creation of a public dataset},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-objective vibrating particle system algorithm for
data clustering. <em>PAAA</em>, <em>25</em>(1), 209–239. (<a
href="https://doi.org/10.1007/s10044-021-01052-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is an important data mining technique described as unsupervised learning. Till date, many single-objective clustering algorithms have been developed on the basis of swarm intelligence and evolutionary techniques. It is noticed that these clustering algorithms provide better solutions for clustering problems, but sometimes, these solutions seem to be biased and also not appropriate for the problem with geometrical shapes datasets. In turn, performance of the clustering algorithms can be degraded. One of the possible solutions is to adopt multi-objective approach instead of single objective. In multi-objective approach, more than one objective functions can be considered for solving the clustering problems and these functions are conflicted in nature. Further, in multi-objective approach, Pareto-optimal solutions can be generated for improving the clustering performance. Hence, this paper presents a multi-objective clustering algorithm based on vibrating particle system (VPS) for effective cluster analysis, called MOVPS. This work considers intra-cluster variance and connectedness as objective functions, and VPS algorithm is used for optimizing the aforementioned objectives to obtain good clustering results. The performance of MOVPS algorithm is tested over a set of benchmark datasets and validated by comparing clustering results with various multi-objective and single-objective clustering algorithms from the literature. The simulation results illustrate the effectiveness of the MOVPS algorithm based on F-measure, coverage, distribution, convergence, non-dominating vector generation and intra-cluster distance measures. The simulation results showed that the proposed MOVPS algorithm enhances the clustering results significantly in comparison with existing multi-objective and single-objective clustering algorithms.},
  archive      = {J_PAAA},
  author       = {Kaur, Arvinder and Kumar, Yugal},
  doi          = {10.1007/s10044-021-01052-1},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {209-239},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A multi-objective vibrating particle system algorithm for data clustering},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LineSeg: Line segmentation of scanned newspaper documents.
<em>PAAA</em>, <em>25</em>(1), 189–208. (<a
href="https://doi.org/10.1007/s10044-021-01031-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation is a significant stage for the recognition of old newspapers. Text-line extraction in the documents like newspaper pages which have very complex layouts poses a significant challenge. Old newspaper documents printed in Gurumukhi script present several forms of hurdles in segmentation due to noise, degradation, bleed-through of ink, multiple font styles and sizes, little space between neighboring text lines, overlapping of lines, etc. Because of the low quality and the complexity of these documents, automatic text line segmentation remains an open research field. Very few researches are available in the literature to segment news articles in Gurumukhi script. This is one of the first few attempts to recognize Gurumukhi newspaper text. The goal of this paper is to present a new methodology for text-line extraction by integrating median calculation and strip height calculation techniques. Non-suitability of existing techniques to segment newspaper text lines have also been discussed with results in the article. The efficiency of the proposed algorithm is demonstrated by experimentation directed on two diverse own made datasets: (a) on the data set of single-column documents with headlines block (b) on the dataset of multi-column documents with headlines block.},
  archive      = {J_PAAA},
  author       = {Kaur, Rupinder Pal and Jindal, M. K. and Kumar, Munish and Jindal, Simpel Rani and Tuteja, Shikha},
  doi          = {10.1007/s10044-021-01031-6},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {189-208},
  shortjournal = {Pattern Anal. Appl.},
  title        = {LineSeg: Line segmentation of scanned newspaper documents},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel fully parallel skeletonization algorithm.
<em>PAAA</em>, <em>25</em>(1), 169–188. (<a
href="https://doi.org/10.1007/s10044-021-01039-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Skeleton that is extracted by a skeletonization algorithm from a binary image is useful for object description, matching, recognition and compression. The parallel thinning algorithm, one of the skeletonization algorithms is well known to have computational effciency. The main contribution of this paper is that we proposed a novel fully parallel thinning algorithm based on a comprehensive investigation of the well-known Zhang-Suen (ZS)-series algorithms and the one-pass thinning algorithm (OPTA)-series algorithms, which not only has good performance in terms of (8,4) connectivity preservation and single-pixel thickness, but also has the following qualities: it is more robust to the boundary noise than the OPTA-series algorithms and it is faster than the ZS-series algorithms in terms of thinning speed, as confirmed by the experiments presented in this paper.},
  archive      = {J_PAAA},
  author       = {Ma, Jun and Ren, Xunhuan and Tsviatkou, Viktar Yurevich and Kanapelka, Valery Kanstantinavich},
  doi          = {10.1007/s10044-021-01039-y},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {169-188},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A novel fully parallel skeletonization algorithm},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3D hand pose estimation from a single RGB image through
semantic decomposition of VAE latent space. <em>PAAA</em>,
<em>25</em>(1), 157–167. (<a
href="https://doi.org/10.1007/s10044-021-01048-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the disentanglement representation learning theory and the cross-modal variational autoencoder (VAE) model, we derive a “Single Input Multiple Output” (SIMO) disentangled model $${\text{cmSIMO} - \beta \,\text{VAE}}$$ . With the guidance of this derived model, we design a new VAE network, named da-VAE, for the challenging task of 3D hand pose estimation from a single RGB image. The designed da-VAE network has a multi-head encoder with the attention modules. Cooperating with the specific supervisions, the latent space is decomposed into subspaces with explicit semantics, which are relevant to the generative factors of hand pose, shape, appearance and others. The performance of the proposed da-VAE network is evaluated on RHD and STB dataset. The experimental results show competitive accuracies with the state-of-the-art methods.},
  archive      = {J_PAAA},
  author       = {Guo, Xinru and Xu, Song and Lin, Xiangbo and Sun, Yi and Ma, Xiaohong},
  doi          = {10.1007/s10044-021-01048-x},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {157-167},
  shortjournal = {Pattern Anal. Appl.},
  title        = {3D hand pose estimation from a single RGB image through semantic decomposition of VAE latent space},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Maxmin distance sort heuristic-based initial centroid method
of partitional clustering for big data mining. <em>PAAA</em>,
<em>25</em>(1), 139–156. (<a
href="https://doi.org/10.1007/s10044-021-01045-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The revolution of digital and communication technologies is producing an enormous amount of data. Therefore, the nature of classical data changes into big data, and mining techniques have to face high computation cost, performance and scalability-related challenges. The K-means (KM) algorithm is the most widely used partitional clustering approach that depends on K clusters, initial centroid, distance measures and central tendency statistical approaches. The initial centroid determines the computational effectiveness, efficiency and local optima issues in big data clustering due to the gradient descent nature of the KM algorithm. The existing centroid initialization algorithm has achieved low cluster quality with high computational complexity due to iterations, distance computation, data and result comparison. To overcome these deficiencies, this paper presents the Maxmin Distance Sort Heuristic (MDSH) algorithm for big data clustering through a stratified sampling process. The performance of the MDSHKM algorithm is compared with the KM and KM++  algorithms through R square, Root-Mean-Square Standard Deviation, Davies–Bouldin score, Calinski Harabasz score, Silhouette Coefficient, Number of Iterations and CPU time validation indices using eight real datasets. The experimental evaluation shows that the MDSHKM algorithm achieves better cluster quality, computing cost, efficiency and stable convergence than the KM and KM++ algorithms.},
  archive      = {J_PAAA},
  author       = {Pandey, Kamlesh Kumar and Shukla, Diwakar},
  doi          = {10.1007/s10044-021-01045-0},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {139-156},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Maxmin distance sort heuristic-based initial centroid method of partitional clustering for big data mining},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Degraded document image preprocessing using local adaptive
sharpening and illumination compensation. <em>PAAA</em>, <em>25</em>(1),
125–137. (<a href="https://doi.org/10.1007/s10044-021-01038-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preprocessing for degraded document images can improve their binarization result. Sharpening and illumination compensation are effective methods in preprocessing. We find the degree of sharpening has different effects on the different stroke width. As the degree of sharpening increases, the thin strokes retained more information in the binarization results, while the thick strokes gradually appear to be broken. Aiming at this problem, we propose a local adaptive sharpening method. The stroke width estimation algorithm is utilized to estimate the stroke width in the local region. Local adaptive sharpening is performed to solve the problem of thick stroke fracture and retain more information of thin strokes. In addition, comparing with the weakly illuminated document images, the sharpening effects on strongly illuminated document images are more prominent, and the binarization result is better. Therefore, appropriate illumination compensation is used for weakly illuminated document images. We further propose a preprocessing method for degraded document image using local adaptive sharpening and illumination compensation. The experimental results show that our proposed method restores more detail information and keeps the thick stroke information in binarization result. Our method outperforms U-Net without preprocessing by 0.36% FM scores on DIBCO2016, 1.09% FM scores on DIBCO2017 and 1.42% FM scores on DIBCO2018. U-Net, Sauvola and OTSU combined with our LASIC outperform themselves by 1.42%, 0.29% and 5.41% FM scores on DIBCO2018. And our LASIC method outperforms other preprocessing methods by 0.1% to 1.05% FM scores on DIBCO2016-DIBCO2018.},
  archive      = {J_PAAA},
  author       = {Wang, Hong Xia and Song, Bang and Chen, Jian and Yang, Yi},
  doi          = {10.1007/s10044-021-01038-z},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {125-137},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Degraded document image preprocessing using local adaptive sharpening and illumination compensation},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Grafted and vanishing random subspaces. <em>PAAA</em>,
<em>25</em>(1), 89–124. (<a
href="https://doi.org/10.1007/s10044-021-01029-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The random subspace method (RSM) is an ensemble procedure in which each constituent learner is constructed using a randomly chosen subset of the data features. Regression trees are ideal candidate learners in RSM ensembles. By constructing trees upon different feature subsets, RSM reduces correlation between trees resulting in a stronger ensemble. Furthermore, it lessens computational burden by only considering a subset of the features when building each tree. Despite its apparent advantages, RSM has a notable drawback. In some instances a randomly chosen subspace may lack informative features. This is especially true in situations in which the number of truly informative variables is small relative to the total number of variables. Trees that are constructed using feature subsets lacking informative features can be damaging to the ensemble. Here we present grafted random subspace (GRS) and vanishing random subspace (VRS), two novel ensemble procedures designed to remedy the aforementioned drawback by reusing information across trees. Both techniques borrow from RSM by growing individual trees on randomly selected feature subsets. For each tree in a GRS ensemble, the most important variable is identified and guaranteed inclusion into the next q feature subsets. This allows GRS to recycle a promising feature from one tree across several successive trees, effectively grafting the variable into the next q active subsets. In the VRS procedure the least important feature is guaranteed exclusion from the next q feature subsets. This creates a more enriched pool of candidate variables from which the successive feature subsets are drawn.},
  archive      = {J_PAAA},
  author       = {Corsetti, Matthew A. and Love, Tanzy M.},
  doi          = {10.1007/s10044-021-01029-0},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {89-124},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Grafted and vanishing random subspaces},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Extraction and reconstruction of a beetle forewing
cross-section point set and its curvature characteristics.
<em>PAAA</em>, <em>25</em>(1), 77–87. (<a
href="https://doi.org/10.1007/s10044-021-01037-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To develop lightweight and high-strength curved beetle elytron plates (CBEPs), an algorithm to extract a cross-section point set based on three-dimensional point cloud data measured from a beetle forewing and to reconstruct its outer surface was designed. This approach was used to study three beetle species. The curve fitting method and the curvature distribution characteristics of the corresponding forewings during the reconstruction were investigated. (1) Two algorithms, namely, the median surface separation method and segmented microstrip method, were established. (2) Two types of fitting methods were proposed: judging the consistency of the curvature curve peaks to determine higher-degree polynomials (clusters) and implementing k-fold cross-validation to determine the optimal engineering fitting curve. The optimal fitting curves for the cross-section point sets of the various beetle forewings involved in this paper were discovered to be elliptic equations. (3) The curvature characteristics of the forewing cross-sections vary depending on the type of fitting curve used; accordingly, researchers can choose the most appropriate fitting curve. For the research and development of CBEPs, elliptic equations can be used to establish the required bionic structure model, the important structural parameters of which include not only the long and short axes of the ellipse but also the position and length of the segment. This paper, therefore, lays a foundation for the development of CBEPs.},
  archive      = {J_PAAA},
  author       = {Song, Yiheng and Chen, Jiashun and Chen, Jinxiang and Qin, Weihong and Liu, Diyou and Chen, Jie},
  doi          = {10.1007/s10044-021-01037-0},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {77-87},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Extraction and reconstruction of a beetle forewing cross-section point set and its curvature characteristics},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new approach for <span
class="math display"><em>H</em><sub>∞</sub></span> deconvolution
filtering of 2D systems described by the fornasini–marchesini and
discrete moments. <em>PAAA</em>, <em>25</em>(1), 63–76. (<a
href="https://doi.org/10.1007/s10044-021-01030-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a new approach of $$H_{\infty }$$ deconvolution filtering of 2D system described by Fornasini–Marchesini model and Tchebichef moments. The challenge of this method is to generate an unknown 2D signal by transmission channel. This canal is mobilized by convolution system and deconvolution filter to rebuild the output signal. To resolve this problem, firstly, we use the Tchebichef moments to extract the feature vectors of a medicinal Cannabis sativa plant for generating the input system with the minimum information. Next, we implement the system with the model of Fornasini–Marchesini for convolution and deconvolution. However, the free matrix variables are used to eliminate coupling between Lyapunov matrix and system matrices to obtain sufficient conditions in linear matrix inequality form to ensure the desired stability and performance of the error systems. Experimental results show that the new approach for $$H_{\infty }$$ deconvolution filtering of 2D systems described by the Fornasini–Marchesini model and Tchebichef moments achieves good performance than the recent works.},
  archive      = {J_PAAA},
  author       = {BOUKILI, Bensalem and EL MALLAHI, Mostafa and AMRANI, Abderrahim and ZOUHRI, Amal and BOUMHIDI, Ismail and HMAMED, Abdelaziz},
  doi          = {10.1007/s10044-021-01030-7},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {63-76},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A new approach for $$H_{\infty }$$ deconvolution filtering of 2D systems described by the Fornasini–Marchesini and discrete moments},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Content authentication and tampering detection of arabic
text: An approach based on zero-watermarking and natural language
processing. <em>PAAA</em>, <em>25</em>(1), 47–62. (<a
href="https://doi.org/10.1007/s10044-021-01032-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rapid increase in exchange of text information via internet network, the security and the reliability of the digital content has become a major research issue. The main challenges faced by researchers are content authentication, integrity verification and tampering detection of digital contents. In this paper, these issues are addressed with great emphasis on text information, which is natural language dependent. Hence, a novel intelligent zero-watermarking approach is proposed for content authentication and tampering detection of Arabic text contents. In the proposed approach, both the embedding and extracting of the watermark are logically implemented, which causes no change on the digital text. This is achieved by using fourth-level-order and alphanumeric mechanism of Markov model as a soft computing technique for the analysis of Arabic text to obtain the features of the given text which is considered as the digital watermark. This digital watermark is later used for the detection of any tampering attack on the received Arabic text. An extensive set of experiments using four datasets of varying lengths proves the effectiveness of the proposed approach in terms of robustness, effectiveness and applicability under multiple random locations of insertion, reorder and deletion attacks. Compared with baseline approaches, the proposed approach has improved performance regarding watermark robustness and tampering detection accuracy.},
  archive      = {J_PAAA},
  author       = {Hilal, Anwer Mustafa and Al-Wesabi, Fahd N. and Hamza, Manar Ahmed and Medani, Mohammed and Mahmood, Khalid and Mahzari, Mohammad},
  doi          = {10.1007/s10044-021-01032-5},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {47-62},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Content authentication and tampering detection of arabic text: An approach based on zero-watermarking and natural language processing},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Influence of heterogeneous edge weights on assortative
mixing patterns in military personnel networks. <em>PAAA</em>,
<em>25</em>(1), 35–46. (<a
href="https://doi.org/10.1007/s10044-021-01036-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A toy model to examine the effect of a heterogeneous edge weight structure on assortative mixing patterns is developed. This model is used as a benchmark to assess assortative mixing patterns in a real military personnel network describing occupation changes among recruits to the Canadian Armed Forces. Mixing patterns on the network suggest a strong tendency for members to transfer between different occupation groups; possible areas on which to focus retention strategies are identified.},
  archive      = {J_PAAA},
  author       = {McDonald, Chris},
  doi          = {10.1007/s10044-021-01036-1},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {35-46},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Influence of heterogeneous edge weights on assortative mixing patterns in military personnel networks},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A dual encoder DAE neural network for imbalanced binary
classification based on NSGA-III and GAN. <em>PAAA</em>, <em>25</em>(1),
17–34. (<a href="https://doi.org/10.1007/s10044-021-01035-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world datasets, the number of samples in each class is often imbalanced, which results in the classifier’s suboptimal performance. Presently, the imbalanced binary classification approach based on deep learning has achieved good results and gets more attention constantly. In this study, we present a dual encoder (Denoising Auto-Encoder) DAE neural network based on non-dominated sorting genetic algorithm (NSGA-III) and generative adversarial network (GAN) to address the imbalanced binary classification problem. The primary aim of our approach is to increase the separability between the reconstruction error of minority class latent features and the reconstruction error of majority class latent features. For this purpose, we first create a dual encoder DAE network to obtain the reconstruction error of latent features of training data. Second, when training the neural network, we introduced GAN to perform a layer-wise training which can improve the training effect of the model. Third, in order to increase the separability of the reconstruction error of minority class and majority class, we utilize NSGA-III to optimize the parameters of the second encoder. Then, we can obtain a set of non-dominated solutions. Finally, based on the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) method, we can get the best solution, which is the most appropriate parameter set of the second encoder to distinguish the minority class and the majority class. The experiment results on both benchmark datasets and a real-world dataset for communication anomaly detection demonstrate the superiority of the proposed approach in imbalanced binary classification problem.},
  archive      = {J_PAAA},
  author       = {Qu, Jiantao and Liu, Feng and Ma, Yuxiang},
  doi          = {10.1007/s10044-021-01035-2},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {17-34},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A dual encoder DAE neural network for imbalanced binary classification based on NSGA-III and GAN},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature definition and comprehensive analysis on the robust
identification of intraretinal cystoid regions using optical coherence
tomography images. <em>PAAA</em>, <em>25</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s10044-021-01028-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, optical coherence tomography is one of the most used medical imaging modalities, offering cross-sectional representations of the studied tissues. This image modality is specially relevant for the analysis of the retina, since it is the internal part of the human body that allows an almost direct examination without invasive techniques. One of the most representative cases of use of this medical imaging modality is for the identification and characterization of intraretinal fluid accumulations, critical for the diagnosis of one of the main causes of blindness in developed countries: the Diabetic Macular Edema. The study of these fluid accumulations is particularly interesting, both from the point of view of pattern recognition and from the different branches of health sciences. As these fluid accumulations are intermingled with retinal tissues, they present numerous variants according to their severity, and change their appearance depending on the configuration of the device; they are a perfect subject for an in-depth research, as they are considered to be a problem without a strict solution. In this work, we propose a comprehensive and detailed analysis of the patterns that characterize them. We employed a pool of 11 different texture and intensity feature families (giving a total of 510 markers) which we have analyzed using three different feature selection strategies and seven complementary classification algorithms. By doing so, we have been able to narrow down and explain the factors affecting this kind of accumulations and tissue lesions by means of machine learning techniques with a pipeline specially designed for this purpose.},
  archive      = {J_PAAA},
  author       = {de Moura, Joaquim and Vidal, Plácido L. and Novo, Jorge and Rouco, José and Penedo, Manuel G. and Ortega, Marcos},
  doi          = {10.1007/s10044-021-01028-1},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Feature definition and comprehensive analysis on the robust identification of intraretinal cystoid regions using optical coherence tomography images},
  volume       = {25},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
