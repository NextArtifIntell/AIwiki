<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJCIS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijcis---50">IJCIS - 50</h2>
<ul>
<li><details>
<summary>
(2022). Analysis and prediction of gestational diabetes mellitus by
the ensemble learning method. <em>IJCIS</em>, <em>15</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s44196-022-00110-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gestational diabetes mellitus (GDM) is the most common disease in pregnancy and can cause a series of maternal and infant complications. A new study shows that GDM affects one in six deliveries. Identifying and screening for risk factors for GDM can effectively help intervene and improve the condition of women and their children. Therefore, the aim of this paper is to determine the risk factors for GDM and to use the ensemble learning method to judge whether pregnant women suffer from GDM more accurately. First, this study involves six commonly used machine learning algorithms to analyze the GDM data from the Tianchi competition, selects the risk factors according to the ranking of each model, and uses the Shapley additive interpreter method to determine the importance of the selected risk factors. Second, the combined weighting method was used to analyze and evaluate the risk factors for gestational diabetes and to determine a group of important factors. Lastly, a new integrated light gradient-boosting machine-extreme gradient boosting-gradient boosting tree (LightGBM-Xgboost-GB) learning method is proposed to determine whether pregnant women have gestational diabetes mellitus. We used the gray correlation degree to calculate the weight and used a genetic algorithm for optimization. In terms of prediction accuracy and comprehensive effects, the final model is better than the commonly used machine learning model. The ensemble learning model is comprehensive and flexible and can be used to determine whether pregnant women suffer from GDM. In addition to disease prediction, the model can also be extended for use to many other areas of research.},
  archive      = {J_IJCIS},
  author       = {Wang, Xiaojia and Wang, Yurong and Zhang, Shanshan and Yao, Lushi and Xu, Sheng},
  doi          = {10.1007/s44196-022-00110-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Analysis and prediction of gestational diabetes mellitus by the ensemble learning method},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Negative learning ant colony optimization for MaxSAT.
<em>IJCIS</em>, <em>15</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s44196-022-00120-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a new negative learning variant of ant colony optimization (ACO) has been used to successfully tackle a range of combinatorial optimization problems. For providing stronger evidence of the general applicability of negative learning ACO, we investigate how it can be adapted to solve the Maximum Satisfiability problem (MaxSAT). The structure of MaxSAT is different from the problems considered to date and there exists only a few ACO approaches for MaxSAT. In this paper, we describe three negative learning ACO variants. They differ in the way in which sub-instances are solved at each algorithm iteration to provide negative feedback to the main ACO algorithm. In addition to using IBM ILOG CPLEX, two of these variants use existing MaxSAT solvers for this purpose. The experimental results show that the proposed negative learning ACO variants significantly outperform the baseline ACO as well as IBM ILOG CPLEX and the two MaxSAT solvers. This result is of special interest because it shows that negative learning ACO can be used to improve over the results of existing solvers by internally using them to solve smaller sub-instances.},
  archive      = {J_IJCIS},
  author       = {Nurcahyadi, Teddy and Blum, Christian and Manyà, Felip},
  doi          = {10.1007/s44196-022-00120-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Negative learning ant colony optimization for MaxSAT},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Characterizing the temperature of SAT formulas.
<em>IJCIS</em>, <em>15</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s44196-022-00122-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable advances in SAT solving achieved in the last years have allowed to use this technology to solve many real-world applications, such as planning, formal verification and cryptography, among others. Interestingly, these industrial SAT problems are commonly believed to be easier than classical random SAT formulas, but estimating their actual hardness is still a very challenging question, which in some cases even requires to solve them. In this context, realistic pseudo-industrial random SAT generators have emerged with the aim of reproducing the main features of these application problems to better understand the success of those SAT solving techniques on them. In this work, we present a model to estimate the temperature of real-world SAT instances. This temperature represents the degree of distortion into the expected structure of the formula, from highly structured benchmarks (more similar to real-world SAT instances) to the complete absence of structure (observed in the classical random SAT model). Our solution is based on the popularity–similarity random model for SAT, which has been recently presented to reproduce two crucial features of application SAT benchmarks: scale-free and community structures. This model is able to control the hardness of the generated formula by introducing some randomizations in the expected structure. Using our regression model, we observe that the estimated temperature of the applications benchmarks used in the last SAT Competitions correlates to their hardness in most of the cases.},
  archive      = {J_IJCIS},
  author       = {Almagro-Blanco, Pedro and Giráldez-Cru, Jesús},
  doi          = {10.1007/s44196-022-00122-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Characterizing the temperature of SAT formulas},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Construction of fuzzy linguistic approximate concept lattice
in an incomplete fuzzy linguistic formal context. <em>IJCIS</em>,
<em>15</em>(1), 1–9. (<a
href="https://doi.org/10.1007/s44196-022-00125-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty research is one of the critical problems in artificial intelligence. In an uncertain environment, a large quantity of information is expressed in linguistic values. Aiming at the missing linguistic-valued information, we first propose incomplete fuzzy linguistic formal context and then discuss the fuzzy linguistic approximate concept. Our proposal can describe the attributes of objects from two aspects simultaneously. One is an object&#39;s essential attributes, and another includes the essential and possible attributes. As a result, more object-related information can be obtained to reduce information loss effectively. We design a similarity metric for correcting the errors caused by the initial complement operation. We then construct a corresponding fuzzy linguistic approximate concept lattice for the task of approximate information retrieval. Finally, we illustrate the applicability and feasibility of the proposed approach with concrete examples, which clearly show that our approach can better deal with the linguistic-valued information in an uncertain environment.},
  archive      = {J_IJCIS},
  author       = {Yang, Dongqiang and Yang, Xinran and Jia, Hui and Xu, Lixian and Guo, Jin},
  doi          = {10.1007/s44196-022-00125-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-9},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Construction of fuzzy linguistic approximate concept lattice in an incomplete fuzzy linguistic formal context},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The new versions of hermite–hadamard inequalities for
pre-invex fuzzy-interval-valued mappings via fuzzy riemann integrals.
<em>IJCIS</em>, <em>15</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s44196-022-00127-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we use the fuzzy order relation to show some novel variants of Hermite–Hadamard inequalities for pre-invex fuzzy-interval-valued mappings (F-I∙V-Ms), which we term fuzzy-interval Hermite–Hadamard inequalities and fuzzy-interval Hermite–Hadamard–Fejér inequalities. This fuzzy order relation is defined as the level of the fuzzy-interval space by the Kulisch–Miranker order relation. There are also some new exceptional instances mentioned. The theory proposed in this research is shown with practical examples that demonstrate its usefulness. This paper&#39;s approaches and methodologies might serve as a springboard for future study in this field.},
  archive      = {J_IJCIS},
  author       = {Khan, Muhammad Bilal and Noor, Muhammad Aslam and Zaini, Hatim Ghazi and Santos-García, Gustavo and Soliman, Mohamed S.},
  doi          = {10.1007/s44196-022-00127-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {The new versions of Hermite–Hadamard inequalities for pre-invex fuzzy-interval-valued mappings via fuzzy riemann integrals},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Short-term electrical load forecasting based on time
augmented transformer. <em>IJCIS</em>, <em>15</em>(1), 1–11. (<a
href="https://doi.org/10.1007/s44196-022-00128-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrical load forecasting is of vital importance in intelligent power management and has been a hot spot in industrial Internet application field. Due to the complex patterns and dynamics of the data, accurate short-term load forecasting is still a challenging task. Currently, many tasks use deep neural networks for power load forecasting, and most use recurrent neural network as the basic architecture, including Long Short-Term Memory (LSTM), Sequence to Sequence (Seq2Seq), etc. However, the performance of these models is not as good as expected due to the gradient vanishing problem in recurrent neural network. Transformer is a deep learning model initially designed for natural language processing, it calculates input–output representations and captures long dependencies entirely on attention mechanisms which has great performance for capturing the complex dynamic nonlinear sequence dependence on long sequence input. In this work, we proposed a model Time Augmented Transformer (TAT) for short-term electrical load forecasting. A temporal augmented module in TAT is designed to learn the temporal relationships representation between the input history series to adapt to the short-term power load forecasting task. We evaluate our approach on a real-word dataset for electrical load and extensively compared it to the performance of the existed electrical load forecasting model including statistical approach, traditional machine learning and deep learning methods, the experimental results show that the proposed TAT model results in higher precision and accuracy in short-term load forecasting.},
  archive      = {J_IJCIS},
  author       = {Zhang, Guangqi and Wei, Chuyuan and Jing, Changfeng and Wang, Yanxue},
  doi          = {10.1007/s44196-022-00128-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Short-term electrical load forecasting based on time augmented transformer},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient plant disease recognition system using hybrid
convolutional neural networks (CNNs) and conditional random fields
(CRFs) for smart IoT applications in agriculture. <em>IJCIS</em>,
<em>15</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s44196-022-00129-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, the Internet of Things (IoT) and Deep Learning Models (DLMs) can be utilized for developing smart agriculture to determine the exact location of the diseased part of the leaf on farmland in an efficient manner. There is no exception that convolutional neural networks (CNNs) have achieved the latest accomplishment in many aspects of human life and the farming sector. Semantic image segmentation is considered the main problem in computer vision. Despite tremendous progress in applications, approximately all semantic image segmentation algorithms fail to achieve sufficient hash results because of the absence of details sensitivity, problems in assessing the global similarity of image pixels, or both. Methods of post-processing improvement, as a wonderfully critical means of improving the underlying flaws mentioned above from algorithms, depend almost on Conditional Random Fields (CRFs). Therefore, plant disease prediction plays important role in the premature notification of the disease to alleviate its effects on disease forecast investigation purposes in the smart farming arena. Hence, this work proposes an efficient IoT-based plant disease recognition system using semantic segmentation methods such as FCN-8 s, CED-Net, SegNet, DeepLabv3, and U-Net with the CRF method to allocate disease parts in leaf crops. Evaluation of this network and comparison with other networks of the state art. The experimental results and their comparisons proclaim over F1-score, sensitivity, and intersection over union (IoU). The proposed system with SegNet and CRFs gives high results compared with other methods. The superiority and effectiveness of the mentioned improvement method, as well as its range of implementation, are confirmed through experiments.},
  archive      = {J_IJCIS},
  author       = {Rezk, Nermeen Gamal and Attia, Abdel-Fattah and El-Rashidy, Mohamed A. and El-Sayed, Ayman and Hemdan, Ezz El-Din},
  doi          = {10.1007/s44196-022-00129-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An efficient plant disease recognition system using hybrid convolutional neural networks (CNNs) and conditional random fields (CRFs) for smart IoT applications in agriculture},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A computational intelligence hybrid algorithm based on
population evolutionary and neural network learning for the crude oil
spot price prediction. <em>IJCIS</em>, <em>15</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-022-00130-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research attempts to reinforce the cultivating expression of radial basis function neural network (RBFnet) through computational intelligence (CI) and swarm intelligence (SI) learning methods. Consequently, the artificial immune system (AIS) and ant colony optimization (ACO) approaches are utilized to cultivate RBFnet for function approximation issue. The proposed hybridization of AIS and ACO approaches optimization (HIAO) algorithm combines the complementarity of exploitation and exploration to realize problem solving. It allows the solution domain having the advantages of intensification and diversification, which further avoids the situation of immature convergence. In addition, the empirical achievements have confirmed that the HIAO algorithm not only obtained the best accurate function approximation for theoretically standard nonlinear problems, it can be further applied on the instance solving for practical crude oil spot price prediction.},
  archive      = {J_IJCIS},
  author       = {Chen, Zhen-Yao},
  doi          = {10.1007/s44196-022-00130-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A computational intelligence hybrid algorithm based on population evolutionary and neural network learning for the crude oil spot price prediction},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monitoring using x-bar control chart using
neutrosophic-based generalized multiple dependent state sampling with
application. <em>IJCIS</em>, <em>15</em>(1), 1–10. (<a
href="https://doi.org/10.1007/s44196-022-00131-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an enhanced X-bar control chart using generalized multiple dependent state (GMDS) sampling under neutrosophic statistics is presented. The joint advantages of GMDS sampling and the neutrosophic statistics have been recycled for the efficient monitoring of the average quality characteristic of any production process. The efficiency of the proposed chart has been evaluated using the average run length values under different ranges of the parameters under study. The comparison of the proposed chart with the existing control chart has been discussed. The comparison shows that the proposed chart is better than the existing chart. Results reveal the superiority of the proposed neutrosophic-based GMDS sampling chart. In addition, an example has also been included for the practical implementation of the proposed methodology.},
  archive      = {J_IJCIS},
  author       = {Khan, Nasrullah and Ahmad, Liaquat and Aslam, Muhammad},
  doi          = {10.1007/s44196-022-00131-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-10},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Monitoring using X-bar control chart using neutrosophic-based generalized multiple dependent state sampling with application},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dual-space transfer learning based on an indirect mutual
promotion strategy. <em>IJCIS</em>, <em>15</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-022-00132-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning is designed to leverage knowledge in the source domain with labels to help build classification models in the target domain where labels are scarce or even unavailable. Previous studies have shown that high-level concepts extracted from original features are more suitable for cross-domain classification tasks, so many transfer learning methods transfer knowledge by modeling high-level concepts on the original feature space. However, there are two limitations to this method: First, learning high-level concepts directly on the original feature space will reduce the proportion of shared information contained in common features in the process of knowledge transfer bridge construction. Second, only learning multiple high-level concepts on the original feature space, the latent shared information contained in the domain-specific features cannot be targeted learned, so the latent shared information in the domain-specific features cannot be effectively used. To overcome these limitations, this paper proposes a novel method named Dual-Space Transfer Learning based on an Indirect Mutual Promotion Strategy (DSTL). The DSTL method is formalized as an optimization problem based on non-negative matrix tri-factorization. DSTL first extracts the common features between domains and constructs the common feature space. Then, the learning of the high-level concepts of the common feature space and the original feature space is integrated through an indirect promotion strategy, which can enhance the learning effect of common features and domain-specific features through the mutual help of the two feature spaces. The system test on benchmark data sets shows the superiority of the DSTL method.},
  archive      = {J_IJCIS},
  author       = {Cui, Teng and Pan, Jianhan and Du, Mingjing and Zhang, Qingyang},
  doi          = {10.1007/s44196-022-00132-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Dual-space transfer learning based on an indirect mutual promotion strategy},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrated neuro-evolution-based computing paradigm to study
the COVID-19 transposition and severity in romania and pakistan.
<em>IJCIS</em>, <em>15</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s44196-022-00133-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical treatment of the COVID-19 transposition and severity in Romania and Pakistan has been presented in this study, i.e., ANN-GA-SQP through artificial neural network genetic algorithms (ANN-GA) and sequential quadratic programming (SQP), a design of an integrated computational intelligent paradigm, COVID-19 is widely considered to be the greatest health threat humanity has ever faced. In terms of both health and economics, COVID-19 is a huge disaster. Many academics have looked at the COVID-19 model in their research papers, although they use different traditional techniques to represent it. The use of hybrid suggested solutions to solve this issue in the present article is significant, demonstrating the study&#39;s novelty. The SIR model of COVID-19 consists of a susceptible, infectious, and recovered class of population. The activation function for the construction of functions based on fitness in mean squared error sense is developed using nonlinear equations of the COVID-19 SIR model for the best performance of ANN-GA-SQP with the combined potential of GA and SQP of a network. While detailed refining is done with efficient local search with SQP, GAs operates as a global search. In addition, a neuron analysis will be presented to verify the effectiveness and complexity of the proposed method. Adam’s numerical methodology is applied to compare the sustainability and efficacy of the presented paradigm. Analytical evaluations of mean, median, and semi-interquartile range values, as well as Theil’s inequality coefficients, root mean squared error, and mean of absolute deviation) values have been observed. The convergence and correctness of the ANN-GA-SQP approach are further validated by statistical analyses.},
  archive      = {J_IJCIS},
  author       = {Shoaib, Muhammad and Abukhaled, Marwan and Kainat, Saba and Nisar, Kottakkaran Sooppy and Raja, Muhammad Asif Zahoor and Zubair, Ghania},
  doi          = {10.1007/s44196-022-00133-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Integrated neuro-evolution-based computing paradigm to study the COVID-19 transposition and severity in romania and pakistan},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Continuous dynamic update of fuzzy random forests.
<em>IJCIS</em>, <em>15</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-022-00134-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy random forests are well-known machine learning classification mechanisms based on a collection of fuzzy decision trees. An advantage of using fuzzy rules is the possibility to manage uncertainty and to work with linguistic scales. Fuzzy random forests achieve a good classification performance in many problems, but their quality decreases when they face a classification problem with imbalanced data between classes. In some applications, e.g., in medical diagnosis, the classifier is used continuously to classify new instances. In that case, it is possible to collect new examples during the use of the classifier, which can later be taken into account to improve the set of fuzzy rules. In this work, we propose a new iterative method to update the set of trees in the fuzzy random forest by considering trees generated from small sets of new examples. Experiments have been done with a dataset of diabetic patients to predict the risk of developing diabetic retinopathy, and with a dataset about occupancy of an office room. With the proposed method, it has been possible to improve the results obtained when using only standard fuzzy random forests.},
  archive      = {J_IJCIS},
  author       = {Pascual-Fontanilles, Jordi and Valls, Aida and Moreno, Antonio and Romero-Aroca, Pedro},
  doi          = {10.1007/s44196-022-00134-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Continuous dynamic update of fuzzy random forests},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A proposed biometric technique for improving iris
recognition. <em>IJCIS</em>, <em>15</em>(1), 1–11. (<a
href="https://doi.org/10.1007/s44196-022-00135-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the Iris Recognition system has been considered an effective biometric model for recognizing humans. This paper introduces an effective hybrid technique combining edge detection and segmentation, in addition to the convolutional neural network (CNN) and Hamming Distance (HD), for extracting features and classification. The proposed model is applied to different datasets, which are CASIA-Iris-Interval V4, IITD, and MMU. For validating the results of the proposed models, detailed modeling and simulation procedures took place using the mentioned three datasets. A comparison between the obtained results from the current work and published results from open literature was carried out as well. The Proposed Biometric Technique showed desirable recognition accuracies of 94.88% based on applying HD on CASIA, 96.56% based on applying CNN on IITD, and 98.01% based on applying CNN on MMU. The obtained accuracies illustrated the superiority of such a classifier compared to other classifiers used in the published literature.},
  archive      = {J_IJCIS},
  author       = {Farouk, Rahmatallah Hossam and Mohsen, Heba and El-Latif, Yasser M. Abd},
  doi          = {10.1007/s44196-022-00135-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A proposed biometric technique for improving iris recognition},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mining personalized individual semantics of self-confidence
participants in linguistic group decision-making. <em>IJCIS</em>,
<em>15</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s44196-022-00136-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Words representing individual preferences in group decision-making (GDM) are always associated with different meanings. Consequently, mining personalized semantics of decision-makers (DMs) hidden in preference expressions, and establishing a corresponding management mechanism, is an effective way to reach group consensus through computing with word methodology. However, the aforementioned consensus-reaching process may be hindered by self-confidence. To address this limitation, this study proposes a linguistic group decision model with self-confidence behavior. First, we identified the corresponding self-confidence levels for each DM. Next, we integrated different linguistic representation models into unified linguistic distribution-based models. We then obtained individual personalized semantics based on a consistency-driven optimization method, and designed a feedback-adjustment mechanism to improve the adjustment willingness of DMs and group consensus level. Finally, we conducted a quantitative experiment to demonstrate our model’s effectiveness and feasibility.},
  archive      = {J_IJCIS},
  author       = {Jing, Limei and Chao, Xiangrui},
  doi          = {10.1007/s44196-022-00136-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Mining personalized individual semantics of self-confidence participants in linguistic group decision-making},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New aggregation approaches with HSV to color edge detection.
<em>IJCIS</em>, <em>15</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s44196-022-00137-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of edge detection algorithms only deal with grayscale images, while their use with color images remains an open problem. This paper explores different approaches to aggregate color information of RGB and HSV images for edge extraction purposes through the usage of the Sobel operator and Canny algorithm. This paper makes use of Berkeley’s image data set, and to evaluate the performance of the different aggregations, the F-measure is computed. Higher potential of aggregations with HSV channels than with RGB channels is found. This article also shows that depending on the type of image used, RGB or HSV, some methods are more appropriate than others.},
  archive      = {J_IJCIS},
  author       = {Flores-Vidal, Pablo and Gómez, Daniel and Castro, Javier and Montero, Javier},
  doi          = {10.1007/s44196-022-00137-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {New aggregation approaches with HSV to color edge detection},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stable two-sided satisfied matching for hospitals and
patients based on the disappointment theory. <em>IJCIS</em>,
<em>15</em>(1), 1–11. (<a
href="https://doi.org/10.1007/s44196-022-00138-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the global spread of COVID-19 and the shortage of medical resources, the key to improve the quality of medical services is to solve the problem of hospital–patient matching. This paper constructs a two-sided matching (TSM) model based on the psychological perceptions of hospitals and patients to realize effective matching that maximizes the satisfaction of hospitals and patients. First, we determine the influencing factors of mutual choice between hospitals and patients through investigation and literature and establish a TSM evaluation system to obtain the preference order of hospitals and patients. Then, using disappointment theory, the preference order value is transformed into preference utility, and the preference utility of hospitals and patients is transformed into the perceived utility of hospital and patient satisfaction. Finally, under the constraint of stable matching, a multiobjective optimization model of TSM is established with the goal of maximizing the sum of the perceived utility of hospitals and patients. The optimal TSM results are obtained by solving the model, and an example is given to verify the practicability and effectiveness of the model. The results show that the stable bilateral satisfaction matching model considering the psychological factors of both sides can fully meet the expectations of hospitals and patients and has certain practical value.},
  archive      = {J_IJCIS},
  author       = {Wang, Xiaojia and Wang, Rong and Zhang, Shanshan and Liu, Junhang and Jiang, Li},
  doi          = {10.1007/s44196-022-00138-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Stable two-sided satisfied matching for hospitals and patients based on the disappointment theory},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting propositional satisfiability based on graph
attention networks. <em>IJCIS</em>, <em>15</em>(1), 1–10. (<a
href="https://doi.org/10.1007/s44196-022-00139-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boolean satisfiability problems (SAT) have very rich generic and domain-specific structures. How to capture these structural features in the embedding space and feed them to deep learning models is an important factor influencing the use of neural networks to solve SAT problems. Graph neural networks have achieved good results, especially for message-passing models. These capture the displacement-invariant architecture well, whether building end-to-end models or improving heuristic algorithms for traditional solvers. We present the first framework for predicting the satisfiability of domain-specific SAT problems using graph attention networks, GAT-SAT. Our model can learn satisfiability features in a weakly supervised setting, i.e., in the absence of problem-specific feature engineering. We test the model to predict the satisfiability of randomly generated SAT instances SR(N) and random 3-SAT problems. Experiments demonstrate that our model improves the prediction accuracy of random 3-SAT problems by 1–4% and significantly outperforms other graph neural network approaches on random SR(N). Compared to NeuroSAT, our model can almost always achieve the same or even higher accuracy with half the amount of iterations. At the end of the paper, we also try to explain the role played by the graph attention mechanism in the model.},
  archive      = {J_IJCIS},
  author       = {Chang, Wenjing and Zhang, Hengkai and Luo, Junwei},
  doi          = {10.1007/s44196-022-00139-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-10},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Predicting propositional satisfiability based on graph attention networks},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A stock price forecasting model integrating complementary
ensemble empirical mode decomposition and independent component
analysis. <em>IJCIS</em>, <em>15</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-022-00140-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, due to the non-stationary behavior of data samples, modeling and forecasting the stock price has been challenging for the business community and researchers. In order to address these mentioned issues, enhanced machine learning algorithms can be employed to establish stock forecasting algorithms. Accordingly, introducing the idea of “decomposition and ensemble” and the theory of “granular computing”, a hybrid model in this paper is established by incorporating the complementary ensemble empirical mode decomposition (CEEMD), sample entropy (SE), independent component analysis (ICA), particle swarm optimization (PSO), and long short-term memory (LSTM). First, aiming at reducing the complexity of the original data of stock price, the CEEMD approach decomposes the data into different intrinsic mode functions (IMFs). To alleviate the cumulative error of IMFs, SE is performed to restructure the IMFs. Second, the ICA technique separates IMFs, describing the internal foundation structure. Finally, the LSTM model is adopted for forecasting the stock price results, in which the LSTM hyperparameters are optimized by synchronously utilizing the PSO algorithm. The experimental results on four stock prices from China stock market reveal the accuracy and robustness of the established model from the aspect of statistical efficiency measures. In theory, a useful attempt is made by integrating the idea of “granular computing” with “decomposition and ensemble” to construct the forecasting model of non-stationary data. In practice, the research results will provide scientific reference for the business community and researchers.},
  archive      = {J_IJCIS},
  author       = {Chen, Youwei and Zhao, Pengwei and Zhang, Zhen and Bai, Juncheng and Guo, Yuqi},
  doi          = {10.1007/s44196-022-00140-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A stock price forecasting model integrating complementary ensemble empirical mode decomposition and independent component analysis},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sequence of u-shaped convolutional networks for assessment
of degree of delamination around scribe. <em>IJCIS</em>, <em>15</em>(1),
1–11. (<a href="https://doi.org/10.1007/s44196-022-00141-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of protective layers is the primary method of keeping metallic structures resistant to degradation. The measurement of the layer resistance to delamination is one of the important indicators of the protection quality. Therefore, ISO 4628 standard has been issued to handle and quantify the main coating defects. Here, an innovative assessment of degree of delamination around a scribe according to ISO 4628 standard has been practically realized. It utilizes an computer-driven deep learning-based method. The assessment method is composed of two shallow U-shaped convolutional networks in a row; the first for preliminary and the second for refined detection of delamination area around a scribe. The experiments performed on 586 samples showed that the proposed sequence of U-shaped convolutional networks meets the edge computing standards, provides good generalization capability, and provides precise delamination area detection for a large variability of surfaces.},
  archive      = {J_IJCIS},
  author       = {Rozsivalova, Veronika and Dolezel, Petr and Stursa, Dominik and Rozsival, Pavel},
  doi          = {10.1007/s44196-022-00141-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Sequence of U-shaped convolutional networks for assessment of degree of delamination around scribe},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Grid feature-based weighted simulation method for
multi-objective reliability-based design optimization. <em>IJCIS</em>,
<em>15</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s44196-022-00142-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliability analysis and reliability-based design have attracted huge attention since their origin, especially in the engineering design optimization field. Integrating a novel grid feature (GF) mechanism into the weighted simulation method (WSM), a grid feature-based weighted simulation method (GFWSM) is proposed in this paper. By sorting the samples in the random variable space, the GF mechanism serializes the failure probability calculation process, which can reduce the number of performance function evaluations required by the WSM. The proposed GFWSM is integrated into an efficient evolutionary multi-objective optimizer, disruption-based multi-objective equilibrium optimization algorithm (DMOEOA), for solving multi-objective reliability-based design optimization (MORBDO) problems. Different reliability analysis examples are employed to verify the advantages of the proposed GFWSM. Various constrained multi-objective reliability-based design optimization problems have been selected to test the effectiveness of the GFWSM-DMOEOA algorithm. The simulation results indicate that GFWSM and GFWSM-DMOEOA algorithm have achieved a good balance between accuracy and efficiency.},
  archive      = {J_IJCIS},
  author       = {Chen, Hao and Li, Weikun and Song, Wentao and Yang, Ping and Cui, Weicheng},
  doi          = {10.1007/s44196-022-00142-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Grid feature-based weighted simulation method for multi-objective reliability-based design optimization},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Clausal forms in MaxSAT and MinSAT. <em>IJCIS</em>,
<em>15</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s44196-022-00143-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We tackle the problem of reducing non-clausal MaxSAT and MinSAT to clausal MaxSAT and MinSAT. Our motivation is twofold: (i) the clausal form transformations used in SAT are unsound for MaxSAT and MinSAT, because they do not preserve the minimum or maximum number of unsatisfied clauses, and (ii) the state-of-the-art MaxSAT and MinSAT solvers require as input a multiset of clauses. The main contribution of this paper is the definition of three different cost-preserving transformations. Two transformations extend the usual equivalence preserving transformation used in SAT to MaxSAT and MinSAT. The third one extends the well-known Tseitin transformation. Furthermore, we report on an empirical comparison of the performance of the proposed transformations when solved with a state-of-the-art MaxSAT solver.},
  archive      = {J_IJCIS},
  author       = {Li, Chu Min and Manyà, Felip and Soler, Joan Ramon and Vidal, Amanda},
  doi          = {10.1007/s44196-022-00143-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Clausal forms in MaxSAT and MinSAT},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Concept-based label distribution learning for text
classification. <em>IJCIS</em>, <em>15</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s44196-022-00144-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification is a crucial task in data mining and artificial intelligence. In recent years, deep learning-based text classification methods have made great development. The deep learning methods supervise model training by representing a label as a one-hot vector. However, the one-hot label representation cannot adequately reflect the relation between an instance and the labels, as labels are often not completely independent, and the instance may be associated with multiple labels in practice. Simply representing the labels as one-hot vectors leads to overconfidence in the model, making it difficult to distinguish some label confusions. In this paper, we propose a simulated label distribution method based on concepts (SLDC) to tackle this problem. This method captures the overlap between the labels by computing the similarity between an instance and the labels and generates a new simulated label distribution for assisting model training. In particular, we incorporate conceptual information from the knowledge base into the representation of instances and labels to address the surface mismatching problem when instances and labels are compared for similarity. Moreover, to fully use the simulated label distribution and the original label vector, we set up a multi-loss function to supervise the training process. Expensive experiments demonstrate the effectiveness of SLDC on five complex text classification datasets. Further experiments also verify that SLDC is especially helpful for confused datasets.},
  archive      = {J_IJCIS},
  author       = {Li, Hui and Huang, Guimin and Li, Yiqun and Zhang, Xiaowei and Wang, Yabing},
  doi          = {10.1007/s44196-022-00144-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Concept-based label distribution learning for text classification},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalized cubic pythagorean fuzzy aggregation operators
and their application to multi-attribute decision-making problems.
<em>IJCIS</em>, <em>15</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s44196-022-00145-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cubic Pythagorean fuzzy (CPF) set (CPFS) is a hybrid set that can hold much more information and can be used to describe both an interval-valued Pythagorean fuzzy set (IVPFS) and Pythagorean fuzzy set (PFS) at the same time to handle data uncertainties. Based on it, the present study is classified into three phases. The first phase is to modify the existing operational laws and aggregation operators (AOs) in the article presented by Abbas et al. (Journal of Intelligent &amp; Fuzzy Systems, vol. 37, no. 1, pp. 1529–1544, (2019)). The main objective of improved operational laws is to eliminate the flows and ambiguities in existing AOs. Secondly, based on these laws, various AOs to aggregate the information are acquired along with their requisite properties and relations. Lastly, an approach for interpreting the multi-attribute decision-making (MCDM) problem based on the stated operators is given and illustrated with an example. Some of the existing models are used to perform a comprehensive comparative analysis to demonstrate their impacts.},
  archive      = {J_IJCIS},
  author       = {Amin, Fazli and Rahim, Muhammad and Ali, Asad and Ameer, Eskandar},
  doi          = {10.1007/s44196-022-00145-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Generalized cubic pythagorean fuzzy aggregation operators and their application to multi-attribute decision-making problems},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Measure identification for the choquet integral: A python
module. <em>IJCIS</em>, <em>15</em>(1), 1–10. (<a
href="https://doi.org/10.1007/s44196-022-00146-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy integrals are common concepts which are used to aggregate input values in practical applications. Aggregation of inputs using fuzzy integrals opens up numerous possibilities for modeling interaction, redundancy, and synergy of inputs. However, fuzzy integrals need a fuzzy measure to start this aggregation process. This situation pushes us into the fuzzy measure identification process. This process becomes difficult due to the monotony condition of the fuzzy measure and the exponential increase on the number of measure parameters. There are in the literature many ways to determine fuzzy measures. One of them is learning from data. In this paper, our aim is to introduce a new fuzzy measure identification tool to learn measures from empirical data. It is a Python module which finds the measure that minimizes the difference between the computed and expected outputs of the Choquet integral. In addition, we study some properties of the learning process. In particular, we consider k-additive fuzzy measures and belief functions as well as arbitrary fuzzy measures. Using these variety of measures we examine the effect of k and noisy data on the learning process.},
  archive      = {J_IJCIS},
  author       = {Türkarslan, Ezgi and Torra, Vicenç},
  doi          = {10.1007/s44196-022-00146-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-10},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Measure identification for the choquet integral: A python module},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Argumentation reasoning with graph isomorphism networks for
reddit conversation analysis. <em>IJCIS</em>, <em>15</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s44196-022-00147-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automated analysis of different trends in online debating forums is an interesting tool for sampling the agreement between citizens in different topics. In previous work, we have defined computational models to measure different values in these online debating forums. One component in these models has been the identification of the set of accepted posts by an argumentation problem that characterizes this accepted set through a particular argumentation acceptance semantics. A second component is the classification of posts into two groups: the ones that agree with the root post of the debate, and the ones that disagree with it. Once we compute the set of accepted posts, we compute the different measures we are interested to get from the debate, as functions defined over the bipartition of the posts and the set of accepted posts. In this work, we propose to explore the use of graph neural networks (GNNs), based on graph isomorphism networks, to solve the problem of computing these measures, using as input the debate tree, instead of using our previous argumentation reasoning system. We focus on the particular online debate forum Reddit, and on the computation of a measure of the polarization in the debate. We explore the use of two different approaches: one where a single GNN model computes directly the polarization of the debate, and another one where the polarization is computed using two different GNNs: the first one to compute the accepted posts of the debate, and the second one to compute the bipartition of the posts of the debate. Our results over a set of Reddit debates show that GNNs can be used to compute the polarization measure with an acceptable error, even if the number of layers of the network is bounded by a constant. We observed that the model based on a single GNN shows the lowest error, yet the one based on two GNNs has more flexibility to compute additional measures from the debates. We also compared the execution time of our GNN-based models with a previous approach based on a distributed algorithm for the computation of the accepted posts, and observed a better performance.},
  archive      = {J_IJCIS},
  author       = {Alsinet, Teresa and Argelich, Josep and Béjar, Ramón and Gibert, Daniel and Planes, Jordi},
  doi          = {10.1007/s44196-022-00147-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Argumentation reasoning with graph isomorphism networks for reddit conversation analysis},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Z-transform-based profile matching to develop a
learning-free keyword spotting method for handwritten document images.
<em>IJCIS</em>, <em>15</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s44196-022-00148-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For easy accessibility of the information from the digitized document images, optical character recognition (OCR)-based software can be used. But in the case of handwritten documents, the performance of the state-of-the-art OCR systems is not satisfactory owing to the complexity of the unconstrained handwriting. Hence, research affinity comes up with an alternative solution for this problem called keyword spotting (KWS) which is much more practical than an OCR-based solution. This work proposes a novel learning-free KWS method that can be applied to a heterogeneous collection of handwritten documents. In this work, we introduce a new way of profile matching to compare the query word profiles (i.e., both upper and lower) with the target words’ profiles. At first, both query and target words are binarized, and then two profiles from each such word are generated. Next, we formulate rules to filter out the irrelevant words concerning the query word and obtain the probable candidate query (i.e., target) words. Then we compare the profiles of the query and candidate query words in the Z-transform domain using the condition of resonance for the damped oscillator. However, before the match, we perform an affine transformation on the Bezier curve representation of the profiles of the candidate query words to reduce the effects like scaling, rotation, and shearing which might occur due to the variant writing styles of individuals. The proposed method achieves satisfactory performance compared to state-of-the-art learning-free methods when applied to four publicly available standard datasets namely ICFHR 2014 H-KWS competition Modern, IAM, ICFHR 2016 H-KWS competition Botany and ICFHR 2016 H-KWS competition Konzilsprotokolle datasets.},
  archive      = {J_IJCIS},
  author       = {Banerjee, Debanshu and Bhowal, Pratik and Malakar, Samir and Cuevas, Erik and Pérez‑Cisneros, Marco and Sarkar, Ram},
  doi          = {10.1007/s44196-022-00148-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Z-transform-based profile matching to develop a learning-free keyword spotting method for handwritten document images},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mining statistically significant patterns with high utility.
<em>IJCIS</em>, <em>15</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s44196-022-00149-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistically significant pattern mining (SSPM) is to mine patterns with significance based on hypothesis test. Under the constraint of statistical significance, our study aims to introduce a new preference relation into high utility patterns and to discover high utility and significant patterns (HUSPs) from transaction datasets, which has never been considered in existing SSPM problems. Our approach can be divided into two parts, HUSP-Mining and HUSP-Test. HUSP-Mining looks for HUSP candidates and HUSP-Test tests their significance. HUSP-Mining is not outputting all high utility itemsets (HUIs) as HUSP candidates; it is established based on candidate length and testable support requirements which can remove many insignificant HUIs early in the mining process; compared with the traditional HUIs mining algorithm, it can get candidates in a short time without losing the real HUSPs. HUSP-Test is to draw significant patterns from the results of HUSP-Mining based on Fisher’s test. We propose an iterative multiple testing procedure, which can alternately and efficiently reject a hypothesis and safely ignore the hypotheses that have less utility than the rejected hypothesis. HUSP-Test controls Family-wise Error Rate (FWER) under a user-defined threshold by correcting the test level which can find more HUSPs than standard Bonferroni’s control. Substantial experiments on real datasets show that our algorithm can draw HUSPs efficiently from transaction datasets with strong mathematical guarantee.},
  archive      = {J_IJCIS},
  author       = {Tang, Huijun and Qian, Jiangbo and Liu, Yangguang and Gao, Xiao-Zhi},
  doi          = {10.1007/s44196-022-00149-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Mining statistically significant patterns with high utility},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-supervised remote sensing image scene classification
based on generative adversarial networks. <em>IJCIS</em>,
<em>15</em>(1), 1–11. (<a
href="https://doi.org/10.1007/s44196-022-00150-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the availability of numerous high-resolution remote sensing images, remote sensing image scene classification has been widely used in various fields. Compared with the field of natural images, the insufficient number of labeled remote sensing images limits the performance of supervised scene classification, while unsupervised methods are difficult to meet the practical applications. Therefore, this paper proposes a semi-supervised remote sensing image scene classification method using generative adversarial networks. The proposed method introduces dense residual block, pre-trained Inception V3 networks, gating unit, pyramidal convolution, and spectral normalization into GANs to promote the semi-supervised classification performance. To be specific, the pre-trained Inception V3 network is introduced to extract semantic features to enhance the feature discriminant capability. The gating unit is utilized to capture the relationships among features. The pyramidal convolution is integrated into dense residual block to capture different levels of details to strengthen the feature representation capability. The spectral normalization is introduced to stabilize the GANs training to improve semi-supervised classification accuracy. Extensive experimental results on publicly available EuroSAT and UC Merced datasets show that the proposed method gains the highest overall accuracy, especially when only a few labeled samples are available.},
  archive      = {J_IJCIS},
  author       = {Guo, Dongen and Wu, Zechen and Zhang, Yuanzheng and Shen, Zhen},
  doi          = {10.1007/s44196-022-00150-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Semi-supervised remote sensing image scene classification based on generative adversarial networks},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New reasoning models: Improving optimisation and decision
support with the management of uncertainty and constraints.
<em>IJCIS</em>, <em>15</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s44196-022-00151-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Valls, Aida and Fernández, Cèsar and Villaret, Mateu},
  doi          = {10.1007/s44196-022-00151-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {New reasoning models: Improving optimisation and decision support with the management of uncertainty and constraints},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pythagorean fuzzy bonferroni mean with weighted interaction
operator and its application in fusion of online multidimensional
ratings. <em>IJCIS</em>, <em>15</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s44196-022-00152-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the aggregation problem of online multi-attribute interactive ratings, a decision-making method based on Pythagorean Fuzzy Bonferroni mean with weighted interaction (PFWIBM) operator is developed by mining the advantages of ratings driven decision-making and the quantitative advantages of Pythagorean fuzzy sets on linguistic ratings. First, the shortcomings of existing operators in criterion interactive representation are analyzed, and the improved Bonferroni mean with weighted interaction and its dual operator are defined, which are used to aggregate the membership information and non-membership information under the Pythagorean fuzzy environment, respectively, and then the PFWIBM operator is constructed. Second, a generation method of interaction coefficients embedded in the PFWIBM operator is designed by combining expert knowledge and user ratings to overcome the limitations of the method of relying on subjective setting parameter values. Third, based on the proposed operator and the transformation relationship between Pythagorean fuzzy sets and linguistic ratings, an online multi-dimensional rating aggregation decision-making approach for solving product raking problems is developed. Finally, the proposed method is applied to a passenger car ranking example to show the feasibility of the method, and through some comparative analysis, the advantages of the proposed operator are clarified, and the influence of operator parameters on the decision-making results is analyzed.},
  archive      = {J_IJCIS},
  author       = {Yang, Yi and Yang, Feifan and Chen, Jie and Zeng, Yangyan and Liu, Limei},
  doi          = {10.1007/s44196-022-00152-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Pythagorean fuzzy bonferroni mean with weighted interaction operator and its application in fusion of online multidimensional ratings},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A large group decision making method considering experts’
non-cooperative behavior for investment selection of renewable energy
projects. <em>IJCIS</em>, <em>15</em>(1), 1–27. (<a
href="https://doi.org/10.1007/s44196-022-00153-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of renewable energy has attracted the attention of investors, which makes the evaluation of renewable energy projects a momentous issue. As the investment selection of renewable energy projects requires the joint discussion of experts from different professional backgrounds (such as energy, transportation, construction, economy, environment, etc.), it belongs to the category of large group decision-making (LGDM). Therefore, this paper is devoted to propose a novel LGDM method considering experts’ non-cooperative behavior for investment selection of renewable energy projects. First, considering that the complexity of renewable energy projects makes it difficult for experts to express their views in a single linguistic word, the hesitant fuzzy linguistic term set is used as the tool for expert evaluation in this paper. Second, since the assessment information provided by experts from different fields are often heterogeneous, a consensus-reaching process with a feedback mechanism is introduced which comprehensively considers three reliable sources: the experts’ trust relationship in the social trust network, the consensus contribution in the subgroup and the opinions’ similarity among experts. Further, to improve the efficiency and rationality of decision-making, an experts’ historical adjustment data-based non-cooperative behavior management method is proposed. Finally, the effectiveness and innovation of the proposed method are verified by a case of renewable energy power generation project investment selection in Qingdao, China and a series of comparative analysis.},
  archive      = {J_IJCIS},
  author       = {Liu, Peide and Dong, Xin and Wang, Peng},
  doi          = {10.1007/s44196-022-00153-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A large group decision making method considering experts’ non-cooperative behavior for investment selection of renewable energy projects},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BKGNN-TI: A bilinear knowledge-aware graph neural network
fusing text information for recommendation. <em>IJCIS</em>,
<em>15</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s44196-022-00154-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph (KG)-based recommendation methods effectively alleviate the data sparsity and cold-start problems in collaborative filtering. Among these methods, neighborhood-based methods are the mainstream methods. However, these methods ignore some meta-information about the items, specifically, the diversity of item information (e.g., texts) and feature interaction between neighboring nodes. In this paper, we propose a Bilinear Knowledge-aware Graph Neural Network Fusing Text Information (BKGNN-TI), which can model both knowledge graph information and text information. In particular, the information in knowledge graph contains not only the existing high-order connectivity but also feature interactions between neighboring nodes at the same level in KG. First, we construct the information propagation layer using the bilinear collector and linear collector. Feature interactions between neighboring nodes and the high-order connectivity are collected in the information propagation layer to generate the item knowledge representations. The bilinear collector emphasizes the importance of second-order feature interaction between neighboring nodes in the KG. Then, texts are also introduced when computing the item representations, which can help further infer user interests. We choose objective program titles and introductions as text information to avoid the influence of subjective factors. BKGNN-TI designs an ALBERT-based sequence encoder to encode texts by the structure of ALBERT+Bi-LSTM+Attention, thus enriching the feature representations of the items. In the experiments, we utilize two language datasets, i.e., the English public dataset Movielens-20M and the Chinese dataset IPTV constructed by ourselves. The results demonstrate that our BKGNN-TI outperforms baselines, indicating that our BKGNN-TI is a generalization for both Chinese and English datasets.},
  archive      = {J_IJCIS},
  author       = {Zhang, Yang and Li, Chuanzhen and Cai, Juanjuan and Liu, Yuchen and Wang, Hui},
  doi          = {10.1007/s44196-022-00154-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {BKGNN-TI: A bilinear knowledge-aware graph neural network fusing text information for recommendation},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RecNet: A resource-constraint aware neural network for used
car recommendation. <em>IJCIS</em>, <em>15</em>(1), 1–10. (<a
href="https://doi.org/10.1007/s44196-022-00155-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource constraints, e.g., limited product inventory or financial strength, may affect consumers’ choices or preferences in some recommendation tasks but are usually ignored in previous recommendation methods. In this paper, we aim to mine the cue of user preferences or intention in the case of resource-constraint recommendation tasks. For this purpose, we specifically build a largely used car transaction dataset possessing resource-constraint characteristics. Accordingly, we propose a resource-constraint-aware network to predict the user’s future interaction based on dynamic connections between users and items. To describe the user-item connection dynamically, mutually recursive recurrent neural networks (MRRNNs) are introduced to capture long-term interactive dependencies, and effective representations of users and items are obtained. To further consider the resource constraint, a resource-constraint branch is built to explore resource variation’s influence on user preferences. Finally, mutual information is introduced to measure the similarity between the future user action and fused historical behavior features to predict future interaction. The fused features come from both MRRNNs and resource-constraint branches. We test the performance on the built used car transaction dataset and the Tmall dataset, and the experimental results verify the effectiveness of our framework.},
  archive      = {J_IJCIS},
  author       = {Shi, Haihua and Qian, Jianjun and Zhu, Nengjun and Zhang, Tong and Cui, Zhen and Wu, Qianliang and Feng, Shanshan},
  doi          = {10.1007/s44196-022-00155-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-10},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {RecNet: A resource-constraint aware neural network for used car recommendation},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved sea lion optimization for workload elasticity
prediction with neural networks. <em>IJCIS</em>, <em>15</em>(1), 1–26.
(<a href="https://doi.org/10.1007/s44196-022-00156-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The work in this paper presents a study into nature-inspired optimization applied to workload elasticity prediction using neural networks. Currently, the trend is for proactive decision support in increasing or decreasing the available resource in cloud computing. The aim is to avoid overprovision leading to resource waste and to avoid resource under-provisioning. The combination of optimization and neural networks has potential for the performance, accuracy, and stability of the prediction solution. In this context, we initially proposed an improved variant of sea lion optimization (ISLO) to boost the efficiency of the original in solving optimization problems. The designed optimization results are validated against eight well-known metaheuristic algorithms on 20 benchmark functions of CEC’2014 and CEC’2015. After that, improved sea lion optimization (ISLO) is used to train a hybrid neural network. Finally, the trained neural model is used for resource auto-scaling based on workload prediction with 4 real and public datasets. The experiments show that our neural network model provides improved results in comparison with other models, especially in comparison with neural networks trained using the original sea lion optimization. The proposed ISLO proved efficiency and improvement in solving problems ranging from global optimization with swarm intelligence to the prediction of workload elasticity.},
  archive      = {J_IJCIS},
  author       = {Nguyen, Binh Minh and Tran, Trung and Nguyen, Thieu and Nguyen, Giang},
  doi          = {10.1007/s44196-022-00156-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An improved sea lion optimization for workload elasticity prediction with neural networks},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DWDP-stream: A dynamic weight and density peaks clustering
algorithm for data stream. <em>IJCIS</em>, <em>15</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-022-00157-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying clusters of arbitrary shapes and constantly processing the newly arrived data points are two critical challenges in the study of clustering. This paper proposes a dynamic weight and density peaks clustering algorithm to simultaneously solve these two key issues. An online–offline framework is used, creating and maintaining micro-clusters in the online phase, and treating the micro-clusters as pseudo-points to form the final cluster in the offline phase. In the online phase, when a new data point is merged into the corresponding micro-cluster, a dynamic weight method is proposed to update the weight of the micro-cluster according to the distance between the point and the center of the micro-cluster, so as to more accurately describe the information of the micro-cluster. In the offline phase, the density peak clustering algorithm is improved, natural neighbors are introduced to adaptively obtain the local density of the data point, and the allocation process is improved to reduce the probability of allocation errors. The algorithm is evaluated on different synthetic and real-world datasets using different quality metrics. The experimental results show that the proposed algorithm improves the clustering quality in both static and streaming environments.},
  archive      = {J_IJCIS},
  author       = {Chen, Di and Du, Tao and Zhou, Jin and Wu, Yunzheng and Wang, Xingeng},
  doi          = {10.1007/s44196-022-00157-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {DWDP-stream: A dynamic weight and density peaks clustering algorithm for data stream},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A systematic research on system recovery based on improved
genetic algorithm and quotient resilience model under attack and damage.
<em>IJCIS</em>, <em>15</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s44196-022-00158-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vulnerability of the current network has become an urgent problem to be solved. The focus of network protection should be shifted from traditional network protection to the direction of effective recovery even after being attacked and damaged, and then, the concept of resilience came into being. This paper selects physical explosion attacks to establish damaged network. An improved system resilience recovery strategy is established which considers task importance and time efficiency. Aiming at the initial population is too random, easy to mature and with poor solution, this paper improves genetic algorithm by new greedy model in population initialization and head-to-head mutation operator. Simulation shows that the improved genetic algorithm is better and more stable, the improved quotient model is more effective in system resilience recovery measured by index-E proposed in this paper.},
  archive      = {J_IJCIS},
  author       = {Zhen, Li and Lu, Tian and Xu, Sun Chen and Mei, Wu Yu and Sheng, Wang Dong and Hong, Miao},
  doi          = {10.1007/s44196-022-00158-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A systematic research on system recovery based on improved genetic algorithm and quotient resilience model under attack and damage},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel social network group decision-making method in a
quantum framework. <em>IJCIS</em>, <em>15</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s44196-022-00159-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks (SNs) have become popular as a medium for disseminating information and connecting like-minded people. They play a central role in decision-making by correlating the behaviors and preferences of connected agents. However, it is difficult to identify social influence effects in decision-making. In this article, we propose a framework of how to describe the uncertain nature of the social network group decision-making (SN-GDM) process. Social networks analysis (SNA) and quantum probability theory (QPT) are combined to construct a decision framework considering superposition and interference effects in SN-GDM scenarios. For the first time, we divide interference effects into symmetry and asymmetry. We construct an influence diagram, which is a quantum-like Bayesian network (QLBN), to model group decisions with interactions. We identify symmetry interference terms from Shapley value and asymmetry interference terms from trust value, respectively. The probability of an alternative is calculated through quantum probability theory in our influence diagram. The combination of QLBN model and social network could gain an understanding of how the group preferences evolve within SN-GDM scenarios, and provide new insights into SNA. Finally, an overall comparative analysis is performed with traditional SNA and other quantum decision models.},
  archive      = {J_IJCIS},
  author       = {Cai, Mei and Jian, Xinglian and Hong, YuanYuan and Xiao, Jingmei and Gao, Yu and Hu, Suqiong},
  doi          = {10.1007/s44196-022-00159-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel social network group decision-making method in a quantum framework},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced salp search algorithm for optimization extreme
learning machine and application to dew point temperature prediction.
<em>IJCIS</em>, <em>15</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s44196-022-00160-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme learning machine (ELM) is popular as a method of training single hidden layer feedforward neural networks. However, the ELMs optimized by the traditional gradient descent algorithms cannot fundamentally solve the influence of the random selection of the input weights and biases. Therefore, this paper proposes a method of extreme learning machine optimized by an enhanced salp search algorithm (NSSA-ELM). Salp search algorithm (SSA) is a metaheuristic algorithm, to improve the performance of SSA exploration and avoid getting stuck in local optima, the neighborhood centroid opposite‑based learning is used to optimize SSA. This method maintains the diversity of the population, which is conducive to avoid local optimization and accelerate convergence. This paper performs classification tests on NSSA and other metaheuristic-optimized ELMs on ten datasets, and regression tests on 5 datasets. Finally, the prediction ability of dew point temperature is evaluated. The meteorological data of five climatically representative cities in China from 2016 to 2022 were collected to predict the dew point temperature. The experimental results show that the NSSA-ELM is the best model, and its generalization performance and accuracy are better than other models.},
  archive      = {J_IJCIS},
  author       = {Zhang, Xiangmin and Zhou, Yongquan and Huang, Huajuan and Luo, Qifang},
  doi          = {10.1007/s44196-022-00160-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhanced salp search algorithm for optimization extreme learning machine and application to dew point temperature prediction},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting sales profiles of products in an exceptional
context: COVID-19 pandemic. <em>IJCIS</em>, <em>15</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s44196-022-00161-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate demand forecasting has always been essential for retailers in order to be able to survive in the highly competitive, volatile modern market. However, anticipating product demand is an extremely difficult task in the context of short product life cycles in which consumer demand is influenced by many heterogeneous variables. During the COVID-19 pandemic in particular, with all its related new constraints, the fashion industry has seen a huge decline in sales, which makes it difficult for existing sales forecasting methods to accurately predict new product sales. This paper proposes an original sales forecasting framework capable of considering the effect of the COVID-19 related crisis on sales. The proposed framework combines clustering, classification, and regression. The main goals of this framework are (1) to predict a sales pattern for each item based on its attributes and (2) to correct it by modelling the impact of the crisis on sales. We evaluate our proposed framework using a real-world dataset of a French fashion retailer with Omnichannel sales. Despite the fact that during the lockdown period online sales were still possible, consumer purchases were significantly impacted by this crisis. Experimental analysis show that our methodology learns the impact of the crisis on consumer behavior from online sales, and then, adapts the sales forecasts already obtained.},
  archive      = {J_IJCIS},
  author       = {Sleiman, Rita and Mazyad, Ahmad and Hamad, Moez and Tran, Kim-Phuc and Thomassey, Sébastien},
  doi          = {10.1007/s44196-022-00161-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Forecasting sales profiles of products in an exceptional context: COVID-19 pandemic},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analytical structure and performance of interval type-2
fuzzy two-term controllers with varying footprint of uncertainty.
<em>IJCIS</em>, <em>15</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s44196-022-00162-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While type-2 fuzzy control has gained a lot of attention in the recent years, several challenges still remain with respect to controller design. The footprint of uncertainty (FoU) plays a very important role in designing type-2 fuzzy controllers, since the performance of type-2 fuzzy controllers largely depends on the choice of FoU. In this paper, we propose a simplified model of interval type-2 (IT2) fuzzy two-term controllers of Takagi–Sugeno (TS) type with only two rules in the rule base. The controller model is derived with varying FoUs based on only two type-2 input fuzzy sets (the simplest case). An extension to multiple input fuzzy sets is also presented. We investigate the variation in control surface and computational aspects of the IT2 fuzzy two-term controller as the FoU is varied. The performance of the proposed IT2 fuzzy controller with respect to varying FoUs is evaluated in the simulation study.},
  archive      = {J_IJCIS},
  author       = {Raj, Ritu and Yang, Jung-Min},
  doi          = {10.1007/s44196-022-00162-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Analytical structure and performance of interval type-2 fuzzy two-term controllers with varying footprint of uncertainty},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Markdown optimization with generalized weighted least
squares estimation. <em>IJCIS</em>, <em>15</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s44196-022-00163-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retailers increasingly apply price markdowns for their seasonal products. Efficiency of these markdown applications is driven by the accuracy of empirical models, especially toward the end of a selling season. In the literature, recent sales are recognized to be more important than older sales data for estimating the current period’s demand for a given markdown level. The importance difference between the weeks of a selling season is addressed by weighted least squares (WLS) method with continuous weight functions of time. This study suggests a generalization of the weight functions and a method for optimizing their shape and discretization parameters to stimulate the predictive accuracy of models. We find that addressing the importance difference of recent sales observations using our generalized weight functions improves the forecast accuracy by up to 20%, and most of the improvement stems from our weight discretization method.},
  archive      = {J_IJCIS},
  author       = {Hekimoğlu, Mustafa},
  doi          = {10.1007/s44196-022-00163-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Markdown optimization with generalized weighted least squares estimation},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid picture fuzzy similarity measure and improved VIKOR
method. <em>IJCIS</em>, <em>15</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s44196-022-00165-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picture fuzzy set (PFS) can intuitively express the answers of “yes”, “neutral”, “no” and “reject”, which have strong advantages in solving uncertain information. The similarity measure is an effective tool to determine the relationship between two picture fuzzy sets (PFSs). In this paper, we propose a hybrid picture fuzzy (PF) similarity measure which combines the Hamming distance and the transformed tetrahedral centroid distance and verifies that it satisfies the four properties of the similarity measure. The proposed and existing picture fuzzy similarity measures are compared and investigated through numerical examples and some applications of pattern recognition. The results show that the proposed similarity measure not only produces no unreasonable results, but also overcomes the shortcomings of the existing similarity measures. Furthermore, we investigate an improved VIKOR method based on the proposed similarity measure of PFS. Finally, through an example, several multi-attribute decision-making (MADM) methods are compared and analyzed to illustrate the effectiveness and practicability of the improved VIKOR method.},
  archive      = {J_IJCIS},
  author       = {Li, Linyu and Chen, Zichun and Jiang, Xiaowei},
  doi          = {10.1007/s44196-022-00165-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A hybrid picture fuzzy similarity measure and improved VIKOR method},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization model of raw material selection process for
complex industry based on improved sequential quadratic programming
algorithm. <em>IJCIS</em>, <em>15</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s44196-022-00166-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Raw materials for industrial production mainly come from nature with wide sources and uneven quality, while production requires strictly with the materials’ quality and their quality indicators are very mutual coupling. In actual production, unreasonable combination and formula often exist in the process of raw material selection, impeding the improvement of production efficiency, quality, energy-saving, and emission reduction. Unfortunately, research on this actual issue is currently vacant, so the main object of this paper is to address the selection of raw materials and formulations in actual production. Based on the designed logical combination algorithm and improved SQP algorithm, this study established the batch combination model and formula calculation model from the perspective of optimal combination and formula. Finally, a practical example of actual production is given to demonstrate the utility and application of this research.},
  archive      = {J_IJCIS},
  author       = {He, Xiuli and Zhang, Yang and Hong, Mengna and Li, Jigeng},
  doi          = {10.1007/s44196-022-00166-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimization model of raw material selection process for complex industry based on improved sequential quadratic programming algorithm},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Auto-generated relative importance for multi-agent inducing
variable in uncertain and preference involved evaluation.
<em>IJCIS</em>, <em>15</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s44196-022-00167-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inducing information and bi-polar preference-based weights allocation and relevant decision-making are one important branch of Yager’s decision theory. In the context of basic uncertain information environment, there exist more than one inducing factor and the relative importance between them should be determined. Some subjective methods require decision makers to indicate the bi-polar preference extents for each inducing factor as well as the relative importance between all the involved inducing factors. However, although the bi-polar preference extents for inducing factors can often be elicited, sometimes decision makers cannot provide the required relative importance. This work presents some approaches to address such problem in basic uncertain information environment. From the mere bi-polar preference extents offered by decision makers, we propose three methods, statistic method, distance method and linguistic variable method, to derive relative importance between different inducing factors, respectively. Each of them has advantages and disadvantages, and the third method serves as a trade-off between the first two methods. The rationale of preference and uncertainty involved evaluation is analyzed, detailed evaluation procedure is presented, and numerical example is given to illustrate the proposals.},
  archive      = {J_IJCIS},
  author       = {Zhou, Meng-Die and Chen, Zhen-Song and Jiang, Jiani and Qian, Gang and García-Zamora, Diego and Dutta, Bapi and Zhan, Qiuyan and Jin, LeSheng},
  doi          = {10.1007/s44196-022-00167-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Auto-generated relative importance for multi-agent inducing variable in uncertain and preference involved evaluation},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Healthy food recommendation using a time-aware community
detection approach and reliability measurement. <em>IJCIS</em>,
<em>15</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s44196-022-00168-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food recommendation systems have been increasingly developed in online food services to make recommendations to users according to their previous diets. Although unhealthy diets may cause challenging diseases such as diabetes, cancer, and premature heart diseases, most of the developed food recommendation systems neglect considering health factors in their recommendation process. This emphasizes the importance of the reliability of the recommendation from the health content perspective. This paper proposes a new food recommendation system based on health-aware reliability measurement. In particular, we develop a time-aware community detection approach that groups users into disjoint sets and utilizes the identified communities as the nearest neighbors set in rating prediction. Then, a novel reliability measurement is introduced by considering both the health and accuracy criteria of predictions to evaluate the reliability of predicted ratings. Also, the unreliable predictions are recalculated by removing ineffective users from the nearest neighbors set. Finally, the recalculated predictions are utilized to generate a list of foods as recommendations. Different experiments on a crawled dataset demonstrate that the proposed method enhances the performance around 7.63%, 6.97%, 7.37%, 15.09%, and 16.17% based on precision, recall, F1, normalized discounted cumulative gain (NDCG), and health metrics, respectively, compared to the second-best model.},
  archive      = {J_IJCIS},
  author       = {Ahmadian, Sajad and Rostami, Mehrdad and Jalali, Seyed Mohammad Jafar and Oussalah, Mourad and Farrahi, Vahid},
  doi          = {10.1007/s44196-022-00168-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Healthy food recommendation using a time-aware community detection approach and reliability measurement},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Correction: Z-transform-based profile matching to develop a
learning-free keyword spotting method for handwritten document images.
<em>IJCIS</em>, <em>15</em>(1), 1. (<a
href="https://doi.org/10.1007/s44196-022-00169-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Banerjee, Debanshu and Bhowal, Pratik and Malakar, Samir and Cuevas, Erik and Pérez‑Cisneros, Marco and Sarkar, Ram},
  doi          = {10.1007/s44196-022-00169-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Correction: Z-transform-based profile matching to develop a learning-free keyword spotting method for handwritten document images},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Some results for intuitionistic fuzzy inequality.
<em>IJCIS</em>, <em>15</em>(1), 1–28. (<a
href="https://doi.org/10.1007/s44196-022-00170-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy sets, characterized by membership degree $$\mu $$ , non-membership degree $$\upsilon $$ and hesitation degree $$\pi $$ , are a meaningful extension of fuzzy set. Inequalities on intuitionistic fuzzy sets/values are very important in solving real problems. In this paper, some inequalities on intuitionistic fuzzy sets are derived from operations. Moreover, three unweighted intuitionistic fuzzy aggregation operators, including unweighted intuitionistic fuzzy Square, unweighted intuitionistic fuzzy Arithmetic and unweighted intuitionistic fuzzy Geometric, are developed. Later, some corresponding inequality relations on them are deeply explored. Finally, some inequalities on intuitionistic fuzzy value are constructed by equality $$\mu +\upsilon +\pi =1$$ in critical definition and proved by some existing famous inequalities, which provide a novel basis for the intuitionistic fuzzy inequalities in operations and aggregation operators.},
  archive      = {J_IJCIS},
  author       = {Peng, Xindong and Garg, Harish and Luo, Zhigang},
  doi          = {10.1007/s44196-022-00170-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Some results for intuitionistic fuzzy inequality},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data augmentation for small sample iris image based on a
modified sparrow search algorithm. <em>IJCIS</em>, <em>15</em>(1), 1–11.
(<a href="https://doi.org/10.1007/s44196-022-00173-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training convolutional neural networks (CNN) often require a large amount of data. However, for some biometric data, such as fingerprints and iris, it is often difficult to obtain a large amount of data due to privacy issues. Therefore, training the CNN model often suffers from specific problems, such as overfitting, low accuracy, poor generalization ability, etc. To solve them, we propose a novel image augmentation algorithm for small sample iris image in this article. It is based on a modified sparrow search algorithm (SSA) called chaotic Pareto sparrow search algorithm (CPSSA), combined with contrast limited adaptive histogram equalization (CLAHE). The CPSSA is used to search for a group of clipping limit values. Then a set of iris images that satisfies the constraint condition is produced by CLAHE. In the fitness function, cosine similarity is used to ensure that the generated images are in the same class as the original one. We select 200 categories of iris images from the CASIA-Iris-Thousand dataset and test the proposed augmentation method on four CNN models. The experimental results show that, compared with the some standard image augmentation methods such as flipping, mirroring and clipping, the accuracy and Equal Error Rate (EER)of the proposed method have been significantly improved. The accuracy and EER of the CNN models with the best recognition performance can reach 95.5 and 0.6809 respectively. This fully shows that the data augmentation method proposed in this paper is effective and quite simple to implement.},
  archive      = {J_IJCIS},
  author       = {Xiong, Qi and Zhang, Xinman and He, Shaobo and Shen, Jun},
  doi          = {10.1007/s44196-022-00173-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Data augmentation for small sample iris image based on a modified sparrow search algorithm},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning style integrated deep reinforcement learning
framework for programming problem recommendation in online judge system.
<em>IJCIS</em>, <em>15</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s44196-022-00176-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exercise recommendation is an integral part of enabling personalized learning. Giving appropriate exercises can facilitate learning for learners. The programming problem recommendation is a specific application of the exercise recommendation. Therefore, an innovative recommendation framework for programming problems that integrate learners’ learning styles is proposed. In addition, there are some difficulties to be solved in this framework, such as quantifying learning behavior, representing programming problems, and quantifying learning strategies. For the difficulties in quantifying learning behavior and quantifying learning strategies, a programming problem recommendation algorithm based on deep reinforcement learning (DRLP) is proposed. DRLP includes the specific design of action space, action-value Q-network, and reward function. Learning style is embedded into DRLP through action space to make recommendations more personalized. To represent the programming problem in DRLP, a multi-dimensional integrated programming problem representation model is proposed to quantify the difficulty feature, knowledge point feature, text description, input description, and output description of programming problems. In particular, Bi-GRU is introduced to learn texts’ contextual semantic association information from both positive and negative directions. Finally, a simulation experiment is carried out with the actual learning behavior data of 47,147 learners in the LUOGU Online Judge system. Compared with the optimal baseline model, the recommendation effect of DRLP has improved (HR, MRR, and Novelty have increased by 4.35%, 1.15%, and 1.1%), which proves the rationality of the programming problem representation model and action-value Q-network.},
  archive      = {J_IJCIS},
  author       = {Xu, Yuhui and Ni, Qin and Liu, Shuang and Mi, Yifei and Yu, Yangze and Hao, Yujia},
  doi          = {10.1007/s44196-022-00176-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Learning style integrated deep reinforcement learning framework for programming problem recommendation in online judge system},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on the recognition method of the axle end mark of a
train wheelset based on machine vision. <em>IJCIS</em>, <em>15</em>(1),
1–19. (<a href="https://doi.org/10.1007/s44196-022-00178-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whether the wheelset of a high-speed train has defects such as cracks is very important to the safety of high-speed trains. Hence, the wheelset must be regularly inspected for flaws. For flaw detection of a wheelset, it is necessary to record the axle end information of the wheelset to correlate with the flaw detection results. To quickly and accurately identify the axle end mark of the wheelset, an automatic identification method based on machine vision is proposed. Our method identifies seven types of marks on the axle end, including the smelting number, steel grade number, unit number, sequence number, year and month, axle type mark, and the azimuth mark. Using the established automatic identification method of axle end marks, based on Retinex theory, an improved dual-core Laplacian combined with Gaussian filtering operation is proposed to solve the problem of the low contrast of the wheelset axle end image. An improved image tilt correction algorithm based on the combination of Hough circle detection and bilinear interpolation is proposed, which solves the angle tilt problem of the target character area of the axis end image. To handle the various types of axis end markers and the small amount of data, a retraining method to improve recognition accuracy is proposed. This method first uses Chi_Sim as the basic font for training and then retrains based on the trained font. Finally, Tesseract-OCR is used to improve the accuracy of the recognition results. Experiments are carried out by developing an automatic recognition program for axle end marks. The results show that the proposed method can effectively identify and classify seven-character types, and the recognition accuracy reaches 96.88% while the recognition time of each image is 5.88 s.},
  archive      = {J_IJCIS},
  author       = {He, Yuchun and Liu, Dezhi and Zeng, Yong and Lu, Qian and Yao, Suheng and Yuan, Yuxin},
  doi          = {10.1007/s44196-022-00178-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Research on the recognition method of the axle end mark of a train wheelset based on machine vision},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
