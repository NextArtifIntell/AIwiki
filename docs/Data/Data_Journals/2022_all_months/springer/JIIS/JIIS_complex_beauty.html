<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JIIS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jiis---61">JIIS - 61</h2>
<ul>
<li><details>
<summary>
(2022). An improved recommendation based on graph convolutional
network. <em>JIIS</em>, <em>59</em>(3), 801–823. (<a
href="https://doi.org/10.1007/s10844-022-00727-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional network is a recently developed artificial neural network method commonly used in recommendation system research. This paper points out three shortcomings of existing recommendation systems based on the graph convolutional network. 1. Existing models that take the one-hot encoding based on node ordinal numbers in the graph or encoding based on original entity attributes as input may not fully utilize the information carried by the attribute interactions. 2. Previous models update the node embeddings only by the first-order neighbors in the graph convolution layer, which is easily affected by noise. 3. Existing models do not take into account differences in user opinions. We propose an improved graph convolutional network-based collaborative filtering model to address these drawbacks. We identify inner and cross interaction between user attributes and item attributes, and then we take the vector representations of aggregated attributes graph as input. In the convolutional layer, we aggregate the second-order collaborative signals and incorporate the different user opinions. The experiments on three public datasets show that our model outperforms state-of-the-art models.},
  archive      = {J_JIIS},
  author       = {He, Yichen and Mao, Yijun and Xie, Xianfen and Gu, Wanrong},
  doi          = {10.1007/s10844-022-00727-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {3},
  pages        = {801-823},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {An improved recommendation based on graph convolutional network},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FPGA supported rough set reduct calculation for big
datasets. <em>JIIS</em>, <em>59</em>(3), 779–799. (<a
href="https://doi.org/10.1007/s10844-022-00725-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rough sets theory developed by Prof. Z. Pawlak is one of the tools used in intelligent systems for data analysis and processing. In modern systems, the amount of the collected data is increasing quickly, so the computation speed becomes the critical factor. One of the solutions to this problem is data reduction. Removing the redundancy in the rough sets can be achieved with the reduct. Most of the algorithms for reduct generation are only software implementations, resulting in many limitations coming from using the fixed word length, as well as consuming the time for fetching and processing of the instructions and data. These limitations make the software-based implementations relatively slow. Unlike software-based systems, hardware systems can process data much faster. This paper presents FPGA and softcore CPU based device for large datasets reduct calculation using rough set methods. Presented architecture has been tested on two real datasets by downloading and running presented solutions inside FPGA. Tested datasets had 1 000 to 1 000 000 objects. For the research purpose, the algorithm was also implemented in C language and ran on a PC. The time of a reduct calculation in hardware and software was considered. The obtained results show an increase in the speed of data processing.},
  archive      = {J_JIIS},
  author       = {Kopczynski, Maciej and Grzes, Tomasz},
  doi          = {10.1007/s10844-022-00725-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {3},
  pages        = {779-799},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {FPGA supported rough set reduct calculation for big datasets},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Entity-aware answer sentence selection for question
answering with transformer-based language models. <em>JIIS</em>,
<em>59</em>(3), 755–777. (<a
href="https://doi.org/10.1007/s10844-022-00724-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Answer Sentence Selection (AS2) task is defined as the task of ranking the candidate answers for each question based on a matching score. The matching score is the probability of being a correct answer for a given question. Detecting the question class and matching it with the named entities of the answer sentence to narrow down the search space was used in primary question answering systems. We used this idea in the state-of-the-art text matching models namely, Transformer-based language models. In this paper, we proposed two different architectures: Ent-match and Ent-add, while using two different question classifiers: Convolutional Neural Network-based (CNN-based) and rule-based. The proposed models outperform the state-of-the-art AS2 model, namely TANDA and RoBERTa-base on both TREC-QA and Wiki-QA datasets. Using Wiki-QA, the Ent-add (CNN-based) model outperforms the TANDA model by 2.1% and 1.9% improvement over Mean Average Precision (MAP) and Mean Reciprocal Rank (MRR) metrics, respectively. Over the TREC-QA dataset the Ent-match (CNN-based) model outperformed the TANDA model with 1.5% and 1.4% improvement over MAP and MRR, respectively.},
  archive      = {J_JIIS},
  author       = {Abbasiantaeb, Zahra and Momtazi, Saeedeh},
  doi          = {10.1007/s10844-022-00724-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {3},
  pages        = {755-777},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Entity-aware answer sentence selection for question answering with transformer-based language models},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GIAD-ST: Detecting anomalies in human monitoring based on
generative inpainting via self-supervised multi-task learning.
<em>JIIS</em>, <em>59</em>(3), 733–754. (<a
href="https://doi.org/10.1007/s10844-022-00722-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a generative inpainting-based method to detect anomalous images in human monitoring via self-supervised multi-task learning. Our previous methods, where a deep captioning model is employed to find salient regions in an image and exploit caption information for each of them, detect anomalies in human monitoring at region level by considering the relations of overlapping regions. Here, we focus on image-level detection, which is preferable when humans prefer an immediate alert and handle them by themselves. However, in such a setting, the methods could show their deficiencies due to their reliance on the salient regions and their neglect of non-overlapping regions. Moreover, they take all regions equally important, which causes the performance to be easily influenced by unimportant regions. To alleviate these problems in image-level detection, we first employ inpainting techniques with a designed local and global loss to better capture the relation between a region and its surrounding area in an image. Then, we propose an attention-based Gaussian weighting anomaly score to combine all the regions by considering their importance for mitigating the influences of unimportant regions. The attention mechanism exploits multi-task learning for higher accuracy. Extensive experiments on two real-world datasets demonstrate the superiority of our method in terms of AUROC, precision, and recall over the baselines. The AUROC has improved from 0.933 to 0.989 and from 0.911 to 0.953 compared with the best baseline on the two datasets.},
  archive      = {J_JIIS},
  author       = {Dong, Ning and Suzuki, Einoshin},
  doi          = {10.1007/s10844-022-00722-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {3},
  pages        = {733-754},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {GIAD-ST: Detecting anomalies in human monitoring based on generative inpainting via self-supervised multi-task learning},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A contextual-bandit approach for multifaceted reciprocal
recommendations in online dating. <em>JIIS</em>, <em>59</em>(3),
705–731. (<a href="https://doi.org/10.1007/s10844-022-00708-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender Systems (RS) provide an effective way to deal with the problem of information overload by suggesting relevant items to users that the users may prefer. However, many online social platforms such as online dating and online recruitment recommend users to each other where both the users have preferences that should be considered for generating successful recommendations. Reciprocal Recommender Systems (RRS) are user-to-user Recommender Systems that recommend a list of users to a user by considering the preferences of both the parties involved. Generating successful recommendations inherently face the exploitation-exploration dilemma which requires predicting the best recommendation from the current information or gathering more information about the environment. To address this, we formulate reciprocal recommendation generation task as a contextual bandit problem which is a principled approach where the agent chooses an action from a set of actions based on contextual information and receives a reward for the chosen action. We propose SiameseNN-UCB algorithm: a deep neural network-based strategy that follows Siamese architecture to transform raw features and learn reward for the chosen action. Upper confidence bound type exploration is used to solve exploitation-exploration trade-off. In this algorithm, we attempt to generate reciprocal recommendations by utilizing multiple aspects such as multi-criteria ratings of a user, popularity-awareness, demographic information, and availability of users. Experimental studies conducted with speed dating data set demonstrate the effectiveness of the proposed approach.},
  archive      = {J_JIIS},
  author       = {Kumari, Tulika and Sharma, Ravish and Bedi, Punam},
  doi          = {10.1007/s10844-022-00708-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {3},
  pages        = {705-731},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A contextual-bandit approach for multifaceted reciprocal recommendations in online dating},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A data-driven situation-aware framework for predictive
analysis in smart environments. <em>JIIS</em>, <em>59</em>(3), 679–704.
(<a href="https://doi.org/10.1007/s10844-022-00721-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of Internet of Things (IoT), it is vital for smart environments to be able to efficiently provide effective predictions of user’s situations and take actions in a proactive manner to achieve the highest performance. However, there are two main challenges. First, the sensor environment is equipped with a heterogeneous set of data sources including hardware and software sensors, and oftentimes humans as complex sensors, too. These sensors generate a huge amount of raw data. In order to extract knowledge and do predictive analysis, it is necessary that the raw sensor data be cleaned, understood, analyzed, and interpreted. Second challenge refers to predictive modeling. Traditional predictive models predict situations that are likely to happen in the near future by keeping and analyzing the history of past user’s situations. Traditional predictive analysis approaches have become less effective because of the massive amount of data continuously streamed in that both affects data processing efficiency and complicates the data semantics. To address the above challenges, we propose a data-driven, situation-aware framework for predictive analysis in smart environments. First, to effectively analyze the sensor data, we employ the Situ-Morphism method to transfer sensor-enabled situation information to vector information. Then we introduce new similarity metrics and implement similarity prediction based on Locality Sensitive Hashing to improve data processing efficiency and effectively handle the data semantics. Experiment results show that the predictive analysis method proposed in this paper can be effective.},
  archive      = {J_JIIS},
  author       = {Gholami, Hoda and Chang, Carl K. and Aduri, Pavan and Ma, Anxiang and Rekabdar, Banafsheh},
  doi          = {10.1007/s10844-022-00721-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {3},
  pages        = {679-704},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A data-driven situation-aware framework for predictive analysis in smart environments},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-stage sequential recommendation for side information
fusion and long-term and short-term preferences modeling. <em>JIIS</em>,
<em>59</em>(3), 657–677. (<a
href="https://doi.org/10.1007/s10844-022-00723-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommender systems aim to model users’ changing interests based on their historical behavior and predict what they will be interested in at the next moment. In recent years, approaches to modeling users’ long-term/short-term preferences have achieved promising results. Previous works typically model historical interactions through an end-to-end neural network incorporating rich side information, which relies on a final loss function to optimize all parameters. However, they tend to concatenate side information and item ID into a vector representation, leading to irreversible fusion. We propose a two-stage sequence recommendation framework to address this problem. The first stage aims to enhance the representation ability of sequence through a non-invasive bidirectional self-attentive item embedding. In the second stage, we use a time-interval aware Gated Recurrent Units with attention to capture the user’s latest intents, while predicting long-term preferences based on the first stage. To integrate the long-term/short-term preferences, we generate the final preference representation using an attention-based adaptive fusion module. We conduct extensive experiments on four benchmark datasets and the results demonstrate the effectiveness of our proposed model.},
  archive      = {J_JIIS},
  author       = {Lei, Jingsheng and Li, Yuexin and Yang, Shengying and Shi, Wenbin and Wu, Yi},
  doi          = {10.1007/s10844-022-00723-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {3},
  pages        = {657-677},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Two-stage sequential recommendation for side information fusion and long-term and short-term preferences modeling},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-stage music separation network with dual-branch
attention and hybrid convolution. <em>JIIS</em>, <em>59</em>(3),
635–656. (<a href="https://doi.org/10.1007/s10844-022-00711-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a lightweight multi-stage network for monaural vocal and accompaniment separation. We design a dual-branch attention (DBA) module to obtain the correlation of each position pair and that among the channels of feature maps, respectively. The square CNN (i.e. the size of the filter is k× k) shares the weights of each of the square areas in feature maps that which makes its ability of feature extraction limited. In order to address it, we propose a hybrid convolution (HC) block based on hybrid convolutional mechanism instead of square CNN to capture the dependencies along with the time dimension and the frequency dimension respectively. The ablation experiments demonstrate that the DBA module and HC block can assist in improving the separation performance. Experimental results show that our proposed network achieves outstanding performance on the MIR-1K dataset only with fewer parameters, and competitive performance compared with state-of-the-arts on DSD100 and MUSDB18 datasets.},
  archive      = {J_JIIS},
  author       = {Chen, Yadong and Hu, Ying and He, Liang and Huang, Hao},
  doi          = {10.1007/s10844-022-00711-x},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {3},
  pages        = {635-656},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Multi-stage music separation network with dual-branch attention and hybrid convolution},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Aspect extraction and classification for sentiment analysis
in drug reviews. <em>JIIS</em>, <em>59</em>(3), 613–633. (<a
href="https://doi.org/10.1007/s10844-022-00712-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) of patients’ opinions expressed in drug reviews can extract valuable information about specific aspects of a particular drug such as effectiveness, side effects and patient conditions. One of the most important and challenging tasks of ABSA is to extract the implicit and explicit aspects from a text, and to classify the extracted aspects into predetermined classes. Supervised learning algorithms possess high accuracy in extracting and classifying aspects; however, they require annotated datasets whose manual construction is time-consuming and costly. In this paper, first a new method was introduced for identifying expressions that indicate an aspect in user reviews about drugs in English. Then, distant supervision was adopted to automate the construction of a training set using sentences and phrases that are annotated as aspect classes in the drug domain. The results of the experiments showed that the proposed method is able to identify various aspects of the test set with 74.4% F-measure, and outperforms the existing aspect extraction methods. Also, training the random forest classifier on the dataset that was constructed via distant supervision obtained the F-measure of 73.96%, and employing this dataset to fine-tune BERT for aspect classification yielded better F-measure (78.05%) in comparison to an existing method in which the random forest classifier trained on an accurate manually constructed dataset.},
  archive      = {J_JIIS},
  author       = {Imani, Mostafa and Noferesti, Samira},
  doi          = {10.1007/s10844-022-00712-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {3},
  pages        = {613-633},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Aspect extraction and classification for sentiment analysis in drug reviews},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving knowledge-based dialogue generation through
two-stage knowledge selection and knowledge selection-guided pointer
network. <em>JIIS</em>, <em>59</em>(3), 591–611. (<a
href="https://doi.org/10.1007/s10844-022-00709-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing End-to-End neural models for dialogue generation tend to generate generic and uninformative responses. Recently, knowledge-based dialogue models have been developed to generate more informative responses by leveraging external knowledge. However, it is still challenging for the models to select appropriate knowledge from an external knowledge base and generate responses coherent with the context and knowledge. In this paper, we propose a new method that uses two-stage knowledge selection to get proper knowledge for response generation without the guidance of ground-truth knowledge. Specifically, in the first stage the model selects knowledge according to the relevance between the context and candidate knowledge from a global perspective. During response generation, dynamic knowledge attention is performed to capture the knowledge relevant to the current decoding state, which is the second stage. Furthermore, we incorporate a knowledge selection-guided pointer network into the decoder to copy words from the captured knowledge. Experimental results on DuConv and Wizard-of-Wikipedia datasets demonstrate that our model can generate more coherent and informative responses than baselines do.},
  archive      = {J_JIIS},
  author       = {Liu, Mengjuan and Zhao, Pei and Liu, Jiang and Zhuang, Yulin and Yang, Yunfan},
  doi          = {10.1007/s10844-022-00709-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {3},
  pages        = {591-611},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Improving knowledge-based dialogue generation through two-stage knowledge selection and knowledge selection-guided pointer network},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new knowledge discovery approach for mining business trade
barriers. <em>JIIS</em>, <em>59</em>(3), 567–590. (<a
href="https://doi.org/10.1007/s10844-022-00701-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-border trade barriers introduced by national authorities to protect local business and labor force cause substantial damage to international economical actors. Therefore, identifying such barriers beyond regulator’s audit reporting is of paramount importance. This paper contributes towards this goal by proposing a novel approach that uses natural language processing and deep learning method for uncovering Finnish-Russian trade barriers in the fish industry from selected business discussion forums. Especially, the approach makes use i) a three-leg ontology for data collection, ii) a BERT architecture for mapping Onkivisit-Shaw-Kananen trade barrier ontology to negative polarity posts and, iii) a new reverse-engineering clustering approach to identify the causes of individual trade-barrier types. A comparison with official statistical reports has been carried out to identify the salient aspects of trade-barriers that hold regardless of the time difference. The findings reveal the dominance of the Time-length barrier type in the Finnish discussion forum dataset and import vs export tariff discrepancy and product requirement barrier types in the Russian forum dataset. The developed framework can serve as a tool to assist companies or regulators in providing business-related recommendations to overcome the detected trade barriers.},
  archive      = {J_JIIS},
  author       = {Bounab, Yazid and Oussalah, Mourad},
  doi          = {10.1007/s10844-022-00701-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {3},
  pages        = {567-590},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A new knowledge discovery approach for mining business trade barriers},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A distantly supervised approach for recognizing product
mentions in user-generated content. <em>JIIS</em>, <em>59</em>(3),
543–566. (<a href="https://doi.org/10.1007/s10844-022-00718-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As online purchasing becomes more popular, users trust more information published on social media than on advertisement content. Opinion mining is often applied to social media, and opinion target extraction is one of its main sub-tasks. In this paper, we focus on recognizing target entities related to electronic products. We propose a method called ProdSpot, for training a named entity extractor to identify product mentions in user text based on the distant supervision paradigm. ProdSpot relies only on an unlabeled set of product offer titles and a list of product brand names. Initially, surface forms are identified from product titles. Given a collection of user posts, our method selects sentences that contain at least one surface form to be automatically labeled. A cluster-based filtering strategy is applied to detect and filter out possible mislabelled sentences. Finally, data augmentation is used to produce more general and diverse training. The set of augmented sentences constitutes the training set to train a recognition model. Experiments demonstrate that the training data automatically generated yields results similar to those achieved by a supervised model. Our best result for precision is only 9% lower than a supervised model, while our recall level is higher by approximately 7% in two distinct product categories. Compared to a state-of-the-art supervised method specifically designed to recognize mobile phone names, our method achieved competitive results with F1 values only 4% lower while not requiring user supervision. Our filtering and data augmentation steps directly influence these results.},
  archive      = {J_JIIS},
  author       = {Vieira, Henry S. and Silva, Altigran S. da and Calado, Pável and de Moura, Edleno S.},
  doi          = {10.1007/s10844-022-00718-4},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {3},
  pages        = {543-566},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A distantly supervised approach for recognizing product mentions in user-generated content},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing aspect and opinion terms semantic relation for
aspect sentiment triplet extraction. <em>JIIS</em>, <em>59</em>(2),
523–542. (<a href="https://doi.org/10.1007/s10844-022-00710-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect sentiment triplet extraction is the most recent subtask of aspect-based sentiment analysis, which aims to extract triplets information from a review sentence, including an aspect term, corresponding sentiment polarity, and associated opinion expression. Although existing researchers adopt an end-to-end method to avoid the error propagation caused by the pipeline manner, they cannot effectively establish the semantic association between aspects and opinions when extracting triples. Furthermore, utilizing sequence tagging methods in extraction and classification tasks will lead to problems, such as increased model search space and sentiment inconsistency of multi-word entities. To tackle the above issues, we propose an enhancing aspect and opinion terms semantic relation framework to make extract triplets more exact by fully capturing interactive information. Specifically, dual convolutional neural networks are used to construct aspect-oriented and opinion-oriented features respectively, the semantic relation is considered through the attention mechanism, and then feedback to each extraction task. We also employ a span-based tagging scheme to extract multiple entities directly under the supervision of span boundary detection accurately predict sentiment polarity based on span distance. We conduct extensive experiments on four benchmark datasets, and the experimental results demonstrate that our model significantly outperforms all baseline methods.},
  archive      = {J_JIIS},
  author       = {Zhang, Yongsheng and Ding, Qi and Zhu, Zhenfang and Liu, Peiyu and Xie, Fu},
  doi          = {10.1007/s10844-022-00710-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {2},
  pages        = {523-542},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Enhancing aspect and opinion terms semantic relation for aspect sentiment triplet extraction},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SentiCode: A new paradigm for one-time training and global
prediction in multilingual sentiment analysis. <em>JIIS</em>,
<em>59</em>(2), 501–522. (<a
href="https://doi.org/10.1007/s10844-022-00714-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main objective of multilingual sentiment analysis is to analyze reviews regardless of the original language in which they are written. Switching from one language to another is very common on social media platforms. Analyzing these multilingual reviews is a challenge since each language is different in terms of syntax, grammar, etc. This paper presents a new language-independent representation approach for sentiment analysis, SentiCode. Unlike previous work in multilingual sentiment analysis, the proposed approach does not rely on machine translation to bridge the gap between different languages. Instead, it exploits common features of languages, such as part-of-speech tags used in Universal Dependencies. Equally important, SentiCode enables sentiment analysis in multi-language and multi-domain environments simultaneously. Several experiments were conducted using machine/deep learning techniques to evaluate the performance of SentiCode in multilingual (English, French, German, Arabic, and Russian) and multi-domain environments. In addition, the vocabulary proposed by SentiCode and the effect of each token were evaluated by the ablation method. The results highlight the 70% accuracy of SentiCode, with the best trade-off between efficiency and computing time (training and testing) in a total of about 0.67 seconds, which is very convenient for real-time applications.},
  archive      = {J_JIIS},
  author       = {Kanfoud, Mohamed Raouf and Bouramoul, Abdelkrim},
  doi          = {10.1007/s10844-022-00714-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {2},
  pages        = {501-522},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {SentiCode: A new paradigm for one-time training and global prediction in multilingual sentiment analysis},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting and explaining emergency department visits in a
public hospital. <em>JIIS</em>, <em>59</em>(2), 479–500. (<a
href="https://doi.org/10.1007/s10844-022-00716-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency Departments (EDs) are the most overcrowded places in public hospitals. Machine learning can support decisions on effective ED resource management by accurately forecasting the number of ED visits. In addition, Explainable Artificial Intelligence (XAI) techniques can help explain decisions from forecasting models and address challenges like lack of trust in machine learning results. The objective of this paper is to use machine learning and XAI to forecast and explain the ED visits on the next on duty day. Towards this end, a case study is presented that uses the XGBoost algorithm to create a model that forecasts the number of patient visits to the ED of the University Hospital of Ioannina in Greece, based on historical data from patient visits, time-based data, dates of holidays and special events, and weather data. The SHapley Additive exPlanations (SHAP) framework is used to explain the model. The evaluation of the forecasting model resulted in an MAE value of 18.37, revealing a more accurate model than the baseline, with an MAE of 29.38. The number of patient visits is mostly affected by the day of the week of the on duty day, the mean number of visits in the previous four on duty days, and the maximum daily temperature. The results of this work can help policy makers in healthcare make more accurate and transparent decisions that increase the trust of people affected by them (e.g., medical staff).},
  archive      = {J_JIIS},
  author       = {Petsis, Spyridon and Karamanou, Areti and Kalampokis, Evangelos and Tarabanis, Konstantinos},
  doi          = {10.1007/s10844-022-00716-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {2},
  pages        = {479-500},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Forecasting and explaining emergency department visits in a public hospital},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Obtaining synthetic indications and sorting relevant
structures from complex hierarchical clusters of multivariate data.
<em>JIIS</em>, <em>59</em>(2), 455–477. (<a
href="https://doi.org/10.1007/s10844-022-00703-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical clustering of multivariate data usually provide useful information on the similarity among elements. Unfortunately, the clustering does not immediately suggest the data-governing structure. Moreover, the number of information retrieved by the data clustering can be sometimes so large to make the results little interpretable. This work presents two tools to derive relevant information from a large number of quantitative multivariate data, simply by post-processing the dendrograms resulting from hierarchical clustering. The first tool helps gaining a good insight in the physical relevance of the obtained clusters, i.e. whether the detected families of elements result from true or spurious similarities due to, e.g., experimental uncertainty. The second tool provides a deeper knowledge of the factors governing the distribution of the elements in the multivariate space, that is the determination of the most relevant parameters which affect the similarities among the configurations. These tools are, in particular, suitable to process experimental results to cope with related uncertainties, or to analyse multivariate data resulting from the study of complex or chaotic systems.},
  archive      = {J_JIIS},
  author       = {Fustioni, Damiano and Vignati, Federica and Niro, Alfonso},
  doi          = {10.1007/s10844-022-00703-x},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {2},
  pages        = {455-477},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Obtaining synthetic indications and sorting relevant structures from complex hierarchical clusters of multivariate data},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A distantly supervised approach for enriching product graphs
with user opinions. <em>JIIS</em>, <em>59</em>(2), 435–454. (<a
href="https://doi.org/10.1007/s10844-022-00717-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Product Graphs (PGs) are knowledge graphs that structure the relationship of products and their characteristics. They have become very popular lately due to their potential to enable AI-related tasks in e-commerce. With the rise of social media, many dynamic and subjective information on products and their characteristics became widely available, creating an opportunity to aggregate such information to PGs. In this paper, we propose a method called PGOpi (Product Graph enriched with Opinions), whose goal is to enrich existing PGs with subjective information extracted from reviews written by customers. PGOpi uses a deep learning model to map opinions extracted from user reviews to nodes in the PG corresponding to targets of these opinions. To alleviate manual labor dependency for training the model, we devise a distant supervision strategy based on word embeddings. We have performed an extensive experimental evaluation on five product categories of two representative real-world datasets. The proposed unsupervised approach achieves superior micro F1 score over more complex unsupervised models. It also presents comparable results to a fully-supervised model.},
  archive      = {J_JIIS},
  author       = {Moreira, Johny and de Melo, Tiago and Barbosa, Luciano and Silva, Altigran da},
  doi          = {10.1007/s10844-022-00717-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {2},
  pages        = {435-454},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A distantly supervised approach for enriching product graphs with user opinions},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A case study comparing machine learning with statistical
methods for time series forecasting: Size matters. <em>JIIS</em>,
<em>59</em>(2), 415–433. (<a
href="https://doi.org/10.1007/s10844-022-00713-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is one of the most active research topics. Machine learning methods have been increasingly adopted to solve these predictive tasks. However, in a recent work, evidence was shown that these approaches systematically present a lower predictive performance relative to simple statistical methods. In this work, we counter these results. We show that these are only valid under an extremely low sample size. Using a learning curve method, our results suggest that machine learning methods improve their relative predictive performance as the sample size grows. The R code to reproduce all of our experiments is available at https://github.com/vcerqueira/MLforForecasting .},
  archive      = {J_JIIS},
  author       = {Cerqueira, Vitor and Torgo, Luis and Soares, Carlos},
  doi          = {10.1007/s10844-022-00713-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {2},
  pages        = {415-433},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A case study comparing machine learning with statistical methods for time series forecasting: Size matters},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Expanding normalized systems from textual domain
descriptions using TEMOS. <em>JIIS</em>, <em>59</em>(2), 391–414. (<a
href="https://doi.org/10.1007/s10844-022-00706-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional requirements on a software system are traditionally captured as text that describes the expected functionality in the domain of a real-world system. Natural language processing methods allow us to extract the knowledge from such requirements and transform it, e.g., into a model. Moreover, these methods can improve the quality of the requirements, which usually suffer from ambiguity, incompleteness, and inconsistency. This paper presents a novel approach to using natural language processing. We use the method of grammatical inspection to find specific patterns in the description of functional requirement specifications (written in English). Then, we transform the requirements into a model of Normalized Systems elements. This may realize a possible component of the eagerly awaited text-to-software pipeline. The input of this method is represented by textual requirements. Its output is a running prototype of an information system created using Normalized Systems (NS) techniques. Therefore, the system is ready to accept further enhancements, e.g., custom code fragments, in an evolvable manner ensured by compliance with the NS principles. A demonstration of pipeline implementation is also included in this paper. The text processing part of our pipeline extends the existing pipeline implemented in our system TEMOS, where we propose and implement methods of checking the quality of textual requirements concerning ambiguity, incompleteness, and inconsistency.},
  archive      = {J_JIIS},
  author       = {Šenkýř, David and Suchánek, Marek and Kroha, Petr and Mannaert, Herwig and Pergl, Robert},
  doi          = {10.1007/s10844-022-00706-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {2},
  pages        = {391-414},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Expanding normalized systems from textual domain descriptions using TEMOS},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attention-based hybrid CNN-LSTM and spectral data
augmentation for COVID-19 diagnosis from cough sound. <em>JIIS</em>,
<em>59</em>(2), 367–389. (<a
href="https://doi.org/10.1007/s10844-022-00707-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 pandemic has fueled the interest in artificial intelligence tools for quick diagnosis to limit virus spreading. Over 60% of people who are infected complain of a dry cough. Cough and other respiratory sounds were used to build diagnosis models in much recent research. We propose in this work, an augmentation pipeline which is applied on the pre-filtered data and uses i) pitch-shifting technique to augment the raw signal and, ii) spectral data augmentation technique SpecAugment to augment the computed mel-spectrograms. A deep learning based architecture that hybridizes convolution neural networks and long-short term memory with an attention mechanism is proposed for building the classification model. The feasibility of the proposed is demonstrated through a set of testing scenarios using the large-scale COUGHVID cough dataset and through a comparison with three baselines models. We have shown that our classification model achieved 91.13% of testing accuracy, 90.93% of sensitivity and an area under the curve of receiver operating characteristic of 91.13%.},
  archive      = {J_JIIS},
  author       = {Hamdi, Skander and Oussalah, Mourad and Moussaoui, Abdelouahab and Saidi, Mohamed},
  doi          = {10.1007/s10844-022-00707-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {2},
  pages        = {367-389},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Attention-based hybrid CNN-LSTM and spectral data augmentation for COVID-19 diagnosis from cough sound},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approaches and algorithms to mitigate cold start problems in
recommender systems: A systematic literature review. <em>JIIS</em>,
<em>59</em>(2), 341–366. (<a
href="https://doi.org/10.1007/s10844-022-00698-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cold Start problems in recommender systems pose various challenges in the adoption and use of recommender systems, especially for new item uptake and new user engagement. This restricts organizations to realize the business value of recommender systems as they have to incur marketing and operations costs to engage new users and promote new items. Owing to this, several studies have been done by recommender systems researchers to address the cold start problems. However, there has been very limited recent research done on collating these approaches and algorithms. To address this gap, the paper conducts a systematic literature review of various strategies and approaches proposed by researchers in the last decade, from January 2010 to December 2021, and synthesizes the same into two categories: data-driven strategies and approach-driven strategies. Furthermore, the approach-driven strategies are categorized into five main clusters based on deep learning, matrix factorization, hybrid approaches, or other novel approaches in collaborative filtering and content-based algorithms. The scope of this study is limited to a systematic literature review and it does not include an experimental study to benchmark and recommend the best approaches and their context of use in cold start scenarios.},
  archive      = {J_JIIS},
  author       = {Panda, Deepak Kumar and Ray, Sanjog},
  doi          = {10.1007/s10844-022-00698-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {2},
  pages        = {341-366},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Approaches and algorithms to mitigate cold start problems in recommender systems: A systematic literature review},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodal time-aware attention networks for depression
detection. <em>JIIS</em>, <em>59</em>(2), 319–339. (<a
href="https://doi.org/10.1007/s10844-022-00704-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression is a common mental disorder, which may lead to suicide when the condition is severe. With the advancement of technology, there are billions of people who share their thoughts and feelings on social media at any time and from any location. Social media data has therefore become a valuable resource to study and detect the depression of the user. In our work, we use Instagram as the platform to study depression detection. We use hashtags to find users and label them as depressive or non-depressive according to their self-statement. Text, image, and posting time are used jointly to detect depression. Furthermore, the time interval between posts is important information when studying medical-related data. In this paper, we use time-aware LSTM to handle the irregularity of time intervals in social media data and use an attention mechanism to pay more attention to the posts that are important for detecting depression. Experiment results show that our model outperforms previous work with an F1-score of 95.6%. In addition to the good performance on Instagram, our model also outperforms state-of-the-art methods in detecting depression on Twitter with an F1-score of 90.8%. This indicates the potential of our model to be a reference for psychiatrists to assess the patient; or for users to know more about their mental health condition.},
  archive      = {J_JIIS},
  author       = {Cheng, Ju Chun and Chen, Arbee L. P.},
  doi          = {10.1007/s10844-022-00704-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {2},
  pages        = {319-339},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Multimodal time-aware attention networks for depression detection},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Handling inconsistencies in tables with nulls and functional
dependencies. <em>JIIS</em>, <em>59</em>(2), 285–317. (<a
href="https://doi.org/10.1007/s10844-022-00700-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we address the problem of handling inconsistencies in tables with missing values (also called nulls) and functional dependencies. Although the traditional view is that table instances must respect all functional dependencies imposed on them, it is nevertheless relevant to develop theories about how to handle instances that violate some dependencies. Regarding missing values, we make no assumptions on their existence: a missing value exists only if it is inferred from the functional dependencies of the table. We propose a formal framework in which each tuple of a table is associated with a truth value among the following: true, false, inconsistent or unknown; and we show that our framework can be used to study important problems such as consistent query answering or data quality measures - to mention just two. In this paper, however, we focus mainly on consistent query answering, a problem that has received considerable attention during the last decades. The main contributions of the paper are the following: (a) we introduce a new approach to handle inconsistencies in a table with nulls and functional dependencies, (b) we give algorithms for computing all true, inconsistent and false tuples, and (c) we give a novel solution to the consistent query answering problem and compare our solution to that of table repairs.},
  archive      = {J_JIIS},
  author       = {Laurent, Dominique and Spyratos, Nicolas},
  doi          = {10.1007/s10844-022-00700-0},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {2},
  pages        = {285-317},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Handling inconsistencies in tables with nulls and functional dependencies},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced density peak-based community detection algorithm.
<em>JIIS</em>, <em>59</em>(2), 263–284. (<a
href="https://doi.org/10.1007/s10844-022-00702-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peak algorithm is a widely accepted density-based clustering algorithm, which shows excellent performance for the discrete data with any shape, any distribution and any density. However, the traditional density peak model is suitable for the complex network. To solve this problem, an enhanced density peak-based community detection algorithm is proposed in this paper, simply called DPCD. Firstly, a novel local density suitable for complex networks is defined to jointly consider the node distribution and network structure. Secondly, based on the node density and network structure, a density connected tree is constructed to measure a density following distance of each node. Finally, an improved density peak model is constructed to quickly and accurately cluster complex networks. Experiments on multiple synthetic networks and real networks show that our DPCD algorithm offers better community detection results.},
  archive      = {J_JIIS},
  author       = {Chen, Lei and Zheng, Heding and Li, Yuan and Liu, Zhaohua and Zhao, Lv and Tang, Hongzhong},
  doi          = {10.1007/s10844-022-00702-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {2},
  pages        = {263-284},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Enhanced density peak-based community detection algorithm},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive benchmark for fake news detection.
<em>JIIS</em>, <em>59</em>(1), 237–261. (<a
href="https://doi.org/10.1007/s10844-021-00646-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, really huge volumes of fake news are continuously posted by malicious users with fraudulent goals thus leading to very negative social effects on individuals and society and causing continuous threats to democracy, justice, and public trust. This is particularly relevant in social media platforms (e.g., Facebook, Twitter, Snapchat), due to their intrinsic uncontrolled publishing mechanisms. This problem has significantly driven the effort of both academia and industries for developing more accurate fake news detection strategies: early detection of fake news is crucial. Unfortunately, the availability of information about news propagation is limited. In this paper, we provided a benchmark framework in order to analyze and discuss the most widely used and promising machine/deep learning techniques for fake news detection, also exploiting different features combinations w.r.t. the ones proposed in the literature. Experiments conducted on well-known and widely used real-world datasets show advantages and drawbacks in terms of accuracy and efficiency for the considered approaches, even in the case of limited content information.},
  archive      = {J_JIIS},
  author       = {Galli, Antonio and Masciari, Elio and Moscato, Vincenzo and Sperlí, Giancarlo},
  doi          = {10.1007/s10844-021-00646-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {1},
  pages        = {237-261},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A comprehensive benchmark for fake news detection},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MAA-PTG: Multimodal aspect-aware product title generation.
<em>JIIS</em>, <em>59</em>(1), 213–235. (<a
href="https://doi.org/10.1007/s10844-022-00695-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For e-commerce platforms, high-quality product titles are a vital element in facilitating transactions. A concise, accurate, and informative product title can not only stimulate consumers’ desire to buy the products, but also provide them with precise shopping guides. However, previous work is mainly based on manual rules and templates, which not only limits the generalization ability of the model, but also lacks dominant product aspects in the generated titles. In this paper, we propose a Transformer-based Multimodal Aspect-Aware Product Title Generation model, denoted as MAA-PTG, which can effectively integrate the visual and textual information of the product to generate a valuable title. Specifically, on the decoder side, we construct an image cross-attention layer to incorporate the local image feature. And then, we explore various strategies to fuse product aspects and global image features. During training, we also adopt an aspect-based reward augmented maximum likelihood (RAML) training strategy to promote our model to generate a product title covering the key product aspects. We elaborately construct an e-commerce product dataset consisting of the product-title pairs. The experimental results on this dataset demonstrate that compared with competitive methods, our MAA-PTG model has significant advantages in ROUGE score and human evaluation.},
  archive      = {J_JIIS},
  author       = {Zhang, Mengli and Gang, Zhou and Yu, Wanting and Huang, Ningbo and Liu, Wenfen},
  doi          = {10.1007/s10844-022-00695-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {1},
  pages        = {213-235},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {MAA-PTG: Multimodal aspect-aware product title generation},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Summarizing consumer reviews. <em>JIIS</em>, <em>59</em>(1),
193–212. (<a href="https://doi.org/10.1007/s10844-022-00694-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce giants like Amazon rely on consumer reviews to allow buyers to inform other potential buyers about a product’s pros and cons. While these reviews can be useful, they are less so when the number of reviews is large; no consumer can be expected to read hundreds or thousands of reviews in order to gain better understanding about a product. In an effort to provide an aggregate representation of reviews, Amazon offers an average user rating represented by a 1- to 5-star score. This score only represents how reviewers feel about a product without providing insight into why they feel that way. In this work, we propose an AI technique that generates an easy-to-read, concise summary of a product based on its reviews. It provides an overview of the different aspects reviewers emphasize in their reviews and, crucially, how they feel about those aspects. Our methodology generates a list of the topics most-mentioned by reviewers, conveys reviewer sentiment for each topic and calculates an overall summary score that reflects reviewers’ overall sentiment about the product. These sentiment scores adapt the same 1- to 5-star scoring scale in order to remain familiar to Amazon users.},
  archive      = {J_JIIS},
  author       = {Peal, Michael and Hossain, Md Shafaeat and Chen, Jundong},
  doi          = {10.1007/s10844-022-00694-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {1},
  pages        = {193-212},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Summarizing consumer reviews},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fake news detection based on statement conflict.
<em>JIIS</em>, <em>59</em>(1), 173–192. (<a
href="https://doi.org/10.1007/s10844-021-00678-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of fake news has become essential in recent years. This paper presents a new technique that is highly effective in identifying fake news articles. We assume a scenario where the relationship between a news article and a statement has already been classified as either agreeing or disagreeing with the statement, being uncertain about it, or being unrelated to it. Using this information, we focus on selecting the news articles that are most likely to be fake. We propose two models: the first one uses only the agree and disagree classifications; the second uses a subjective opinions based model that can also handle the uncertain cases. Our experiments on a real-world dataset (the Fake News Challenge 1 dataset) and a simulated dataset validate that both proposed models achieve state-of-the-art performance. Furthermore, we show which model to use in different scenarios to get the best performance.},
  archive      = {J_JIIS},
  author       = {Zhang, Danchen and Xu, Jiawei and Zadorozhny, Vladimir and Grant, John},
  doi          = {10.1007/s10844-021-00678-1},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {1},
  pages        = {173-192},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Fake news detection based on statement conflict},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incremental and accurate computation of machine learning
models with smart data summarization. <em>JIIS</em>, <em>59</em>(1),
149–172. (<a href="https://doi.org/10.1007/s10844-021-00690-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, data scientists prefer “easy” high-level languages like R and Python, which accomplish complex mathematical tasks with a few lines of code, but they present memory and speed limitations. Data summarization has been a fundamental technique in data mining that has promise with more demanding data science applications. Unfortunately, most summarization approaches require reading the entire data set before computing any machine learning (ML) model, the old-fashioned way. Also, it is hard to learn models if there is an addition or removal of data samples. Keeping these motivations in mind, we present incremental algorithms to smartly compute summarization matrix, previously used in parallel DBMSs, to compute ML models incrementally in data science languages. Compared to the previous approaches, our new smart algorithms interleave model computation periodically, as the data set is being summarized. A salient feature is scalability to large data sets, provided the summarization matrix fits in RAM, a reasonable assumption in most cases. We show our incremental approach is intelligent and works for a wide spectrum of ML models. Our experimental evaluation shows models get increasingly accurate, reaching total accuracy when the data set is fully scanned. On the other hand, we show our incremental algorithms are as fast as Python ML library, and much faster than R built-in routines.},
  archive      = {J_JIIS},
  author       = {Al-Amin, Sikder Tahsin and Ordonez, Carlos},
  doi          = {10.1007/s10844-021-00690-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {1},
  pages        = {149-172},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Incremental and accurate computation of machine learning models with smart data summarization},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A relational tsetlin machine with applications to natural
language understanding. <em>JIIS</em>, <em>59</em>(1), 121–148. (<a
href="https://doi.org/10.1007/s10844-021-00682-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tsetlin machines (TMs) are a pattern recognition approach that uses finite state machines for learning and propositional logic to represent patterns. In addition to being natively interpretable, they have provided competitive accuracy for various tasks. In this paper, we increase the computing power of TMs by proposing a first-order logic-based framework with Herbrand semantics. The resulting TM is relational and can take advantage of logical structures appearing in natural language, to learn rules that represent how actions and consequences are related in the real world. The outcome is a logic program of Horn clauses, bringing in a structured view of unstructured data. In closed-domain question-answering, the first-order representation produces 10 × more compact KBs, along with an increase in answering accuracy from 94.83% to 99.48%. The approach is further robust towards erroneous, missing, and superfluous information, distilling the aspects of a text that are important for real-world understanding},
  archive      = {J_JIIS},
  author       = {Saha, Rupsa and Granmo, Ole-Christoffer and Zadorozhny, Vladimir I. and Goodwin, Morten},
  doi          = {10.1007/s10844-021-00682-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {1},
  pages        = {121-148},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A relational tsetlin machine with applications to natural language understanding},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rating behavior evaluation and abnormality forensics
analysis for injection attack detection. <em>JIIS</em>, <em>59</em>(1),
93–119. (<a href="https://doi.org/10.1007/s10844-021-00689-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative recommender systems (CRSs) have become an essential component in a wide range of e-commerce systems. However, CRSs are also easy to suffer from malicious attacks due to the fundamental vulnerability of recommender systems. Facing with the limited representative of rating behavior and the unbalanced distribution of rating profiles, how to further improve detection performance and deal with unlabeled real-world data is a long-standing but unresolved issue. This paper develops a new detection approach to defend anomalous threats for recommender systems. First, eliminating the influence of disturbed rating profiles on abnormality detection is analyzed in order to reduce the unbalanced distribution as far as possible. Based on the remaining rating profiles, secondly, rating behaviors which belong to the same dense region using standard distance measures are further partitioned by exploiting a probability mass-based dissimilarity mechanism. To reduce the scope of determining suspicious items while keeping the advantage of target item analysis (TIA), thirdly, suspected items captured by TIA are empirically converted into an associated item-item graph according to frequent patterns of rating distributions. Finally, concerned attackers can be detected based on the determined suspicious items. Extensive experiments on synthetic data demonstrate the effectiveness of the proposed detection approach compared with benchmarks. In addition, discovering interesting findings such as suspected items or ratings on four different real-world datasets is also analyzed and discussed.},
  archive      = {J_JIIS},
  author       = {Yang, Zhihai and Sun, Qindong and Liu, Zhaoli and Yan, Jinpei and Zhang, Yaling},
  doi          = {10.1007/s10844-021-00689-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {1},
  pages        = {93-119},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Rating behavior evaluation and abnormality forensics analysis for injection attack detection},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LOD search engine: A semantic search over linked data.
<em>JIIS</em>, <em>59</em>(1), 71–91. (<a
href="https://doi.org/10.1007/s10844-021-00687-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few years, there has been a significant growth in the amount of data published in RDF and adoption of Linked Data principles. Every day, a large number of people and communities contribute to the publication of datasets as Linked Data on Linked Open Data (LOD) cloud. Due to a large size of LOD cloud on the Web and the RDF representation of linked dataset, searching and retrieving relevant data on the Web is a major challenge. Because the data is published in RDF triple format, i.e. an interlinked structure, traditional search engines are unable to perform searches on Linked Data. This article introduces LOD search engine, a novel semantic search engine that searches on Semantic Web documents (such as Linked Data or triples) to retrieve a set of relevant information based on user queries. For searching over triples, we proposed two semantic search methods: Forward Search and Backward Search. To improve search results, two new ranking methods have also been introduced: Domain Ranking and Triple Ranking. The proposed LOD search engine produced remarkable results and outperformed other semantic search engines. In the best-case scenario, the proposed LOD search engine outperforms the swoogle and falcons by 22.35%, 43.38% and 33.18% in terms of precision, recall, and F-Measure respectively.},
  archive      = {J_JIIS},
  author       = {Azad, Hiteshwar kumar and Deepak, Akshay and Azad, Amisha},
  doi          = {10.1007/s10844-021-00687-0},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {1},
  pages        = {71-91},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {LOD search engine: A semantic search over linked data},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local feature selection for multiple instance learning.
<em>JIIS</em>, <em>59</em>(1), 45–69. (<a
href="https://doi.org/10.1007/s10844-021-00680-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a local feature selection method for the Multiple Instance Learning (MIL) framework. Unlike conventional feature selection algorithms that assign a global set of features to the whole data set, our algorithm, called Multiple Instance Local Salient Feature Selection (MI-LSFS), searches the feature space to find the relevant features within each bag. We also propose a new multiple instance classification algorithm, called Multiple Instance Learning via Embedded Structures with Local Feature Selection (MILES-LFS), by integrating the information learned by MI-LSFS during the feature selection process. In MILES-LFS, we use information learned by MI-LSFS to identify a reduced subset of representative bags. For each representative bag, we identify its most representative instances. Using the instance prototypes of all representative bags and their relevant features, we project and map the MIL data to a standard feature vector data. Finally, we train a 1-Norm support vector machine (1-Norm SVM) to learn the classifier. We investigate the performance of MI-LSFS in selecting the local relevant features using synthetic and benchmark data sets. The results confirm that MI-LSFS can identify the relevant features for each bag. We also investigate the performance of the proposed MILES-LFS algorithm on several synthetic and real benchmark data sets. The results confirm that MILES-LFS has a robust classification performance comparable to the well-known MILES algorithm. More importantly, our results confirm that using the reduced set of prototypes to project the MIL data reduces the computational time significantly without affecting the classification accuracy.},
  archive      = {J_JIIS},
  author       = {Shahrjooihaghighi, Aliasghar and Frigui, Hichem},
  doi          = {10.1007/s10844-021-00680-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {1},
  pages        = {45-69},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Local feature selection for multiple instance learning},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LexTex: A framework to generate lexicons using WordNet word
senses in domain specific categories. <em>JIIS</em>, <em>59</em>(1),
21–44. (<a href="https://doi.org/10.1007/s10844-021-00679-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lexicons have risen as alternative resources to common supervised methods for classification or regression in different domains (e.g., Sentiment Analysis). These resources (especially lexical) lack of important domain context and it is not possible to tune/edit/improve them depending on new domains and data. With the exponential production of data and annotations witnessed today in several domains, leveraging lexical resources to improve existing lexicons becomes a must. In this work, a novel framework to build lexicons independently from the target domain and from input categories where each text needs to be classified is provided. It employs state-of-the-art Natural Language Processing, Word Sense Disambiguation tools, and techniques to make the method as general as possible. The framework takes as input a heterogeneous collection of annotated text towards a fixed number of categories. Its output is a list of WordNet word senses with weights for each category. We prove the effectiveness of the framework taking as case study the Emotion Detection task by employing the generated lexicons within such a domain. The results prove the effectiveness of proposed framework. Additionally, the paper shows an use case on the human-robot interaction within the Emotion Detection task. Furthermore we applied our methodology in several other domains and compared our approach against common supervised methods (regressors) showing the effectiveness of the generated lexicons. By freely providing the framework we aim at encouraging and disseminating the production of context-aware and domain-specific lexicons in other domains as well.},
  archive      = {J_JIIS},
  author       = {Dessì, Danilo and Diego, Reforgiato Recupero},
  doi          = {10.1007/s10844-021-00679-0},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {1},
  pages        = {21-44},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {LexTex: A framework to generate lexicons using WordNet word senses in domain specific categories},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting temporary deal success with social media timing
signals. <em>JIIS</em>, <em>59</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s10844-021-00681-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporary deals such as flash sales nowadays are popular strategies in retail business for cleaning out excessive inventories. It is known that the success of a temporary deal is related to product quality, promotion, and discount rates. In this paper, we look at another more obscure factor, that is the timing in the market, and we argue that such timing can be learned from social media. For example, the trending of words “summer” and “ice cream” in social media may indicate successful sales of air conditioners. We propose an approach to detect emerging words in social media as timing signals, and associate them with successful temporary deals. More specifically, the words that tend to emerge just before successful deals are considered as effective timing signals. We obtain a real-world temporary deal dataset from an industry partner and collect a social media datasets from Twitter for experiments. With experimental evaluation, we show and discuss the discovered timing signals. Furthermore, we propose a prediction framework and show that using social media timing signals can achieve better accuracy for predicting temporary deal success, comparing to internal deal information.},
  archive      = {J_JIIS},
  author       = {Zhang, Yihong and Shirakawa, Masumi and Hara, Takahiro},
  doi          = {10.1007/s10844-021-00681-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {1},
  pages        = {1-19},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Predicting temporary deal success with social media timing signals},
  volume       = {59},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchy-based semantic embeddings for single-valued &amp;
multi-valued categorical variables. <em>JIIS</em>, <em>58</em>(3),
613–640. (<a href="https://doi.org/10.1007/s10844-021-00693-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In low-resource domains, it is challenging to achieve good performance using existing machine learning methods due to a lack of training data and mixed data types (numeric and categorical). In particular, categorical variables with high cardinality pose a challenge to machine learning tasks such as classification and regression because training requires sufficiently many data points for the possible values of each variable. Since interpolation is not possible, nothing can be learned for values not seen in the training set. This paper presents a method that uses prior knowledge of the application domain to support machine learning in cases with insufficient data. We propose to address this challenge by using embeddings for categorical variables that are based on an explicit representation of domain knowledge (KR), namely a hierarchy of concepts. Our approach is to 1. define a semantic similarity measure between categories, based on the hierarchy—we propose a purely hierarchy-based measure, but other similarity measures from the literature can be used—and 2. use that similarity measure to define a modified one-hot encoding. We propose two embedding schemes for single-valued and multi-valued categorical data. We perform experiments on three different use cases. We first compare existing similarity approaches with our approach on a word pair similarity use case. This is followed by creating word embeddings using different similarity approaches. A comparison with existing methods such as Google, Word2Vec and GloVe embeddings on several benchmarks shows better performance on concept categorisation tasks when using knowledge-based embeddings. The third use case uses a medical dataset to compare the performance of semantic-based embeddings and standard binary encodings. Significant improvement in performance of the downstream classification tasks is achieved by using semantic information.},
  archive      = {J_JIIS},
  author       = {Mumtaz, Summaya and Giese, Martin},
  doi          = {10.1007/s10844-021-00693-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {613-640},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Hierarchy-based semantic embeddings for single-valued &amp; multi-valued categorical variables},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An overview of actionable knowledge discovery techniques.
<em>JIIS</em>, <em>58</em>(3), 591–611. (<a
href="https://doi.org/10.1007/s10844-021-00667-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The amazing progresses achieved in both data collecting and transferring have confronted us with a vast volume of stored and transient data. Analyzing such data can result in valuable knowledge providing a competitive advantage in support of decision-making. However, the high volume of the data makes it impossible to analyze such data manually. Data mining methods have been developed to automate this process. These methods extract useful knowledge from a massive amount of data. The vast majority of available methods focus on finding different types of patterns from various kinds of data whereas a few of them pay enough attention to the usability of mined patterns. Subsequently, there is a noticeable gap between delivered patterns and business expectations. Actionable Knowledge Discovery (AKD) is motivated to narrow this gap. Up to now, many AKD methods have been proposed. However, there is no comprehensive survey summarizing different aspects of such methods. Moreover, the lack of clear definitions and boundaries in this area makes it challenging to detect comparable methods. This paper aims at clarifying definitions and boundaries of AKD area. In this regard, some viewpoints are defined, and AKD methods are categorized by use of them. In addition, AKD methods are reviewed, and finally, a characterization table is presented that concludes the survey and can be used for studying different methods in AKD area.},
  archive      = {J_JIIS},
  author       = {Kalanat, Nasrin},
  doi          = {10.1007/s10844-021-00667-4},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {591-611},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {An overview of actionable knowledge discovery techniques},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The role of transitive closure in evaluating blocking
methods for dirty entity resolution. <em>JIIS</em>, <em>58</em>(3),
561–590. (<a href="https://doi.org/10.1007/s10844-021-00676-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity resolution (ER) is a process that identifies duplicate records referring to a real-world entity and links them together in one or more datasets. As a first step toward reducing the number of required record comparisons, blocking methods attempt to group records that are likely to match. A proper evaluation of blocking methods for selecting the best one has a direct effect on the ultimate ER performance. Currently, the available metrics for evaluating blocking techniques exclusively assess their actual potential. However, it is possible to deduce new pairs from the identified ones in dirty datasets due to transitive closure between matching record pairs. In the present study, a modification of current metrics is proposed to obtain a more accurate evaluation of blocking methods taking into account transitive closure and the potential of blocking methods. Comparing the existing and proposed metrics for ten available blocking algorithms on two dirty datasets demonstrates that the proposed metrics correlate significantly with ER final performance.},
  archive      = {J_JIIS},
  author       = {Niknam, Mahdi and Minaei-Bidgoli, Behrouz and Dianat, Rouhollah},
  doi          = {10.1007/s10844-021-00676-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {561-590},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {The role of transitive closure in evaluating blocking methods for dirty entity resolution},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A spiral-like method to place in the space (and interact
with) too many values. <em>JIIS</em>, <em>58</em>(3), 535–559. (<a
href="https://doi.org/10.1007/s10844-021-00677-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern information systems have to support the user in managing, understanding and interacting with, more and more data. Visualization could help users comprehend information more easily and reach conclusions in relative shorter time. However, the bigger the data is, the harder the problem of visualizing it becomes. In this paper we focus on the problem of placing a set of values in the 2D (or 3D) space. We present a novel family of algorithms that produces spiral-like layouts where the biggest values are placed in the centre of the spiral and the smaller ones in the peripheral area, while respecting the relative sizes. The derived layout is suitable not only for the visualization of medium-sized collections of values, but also for collections of values whose sizes follow power-law distribution because it makes evident the bigger values (and their relative size) and it does not leave empty spaces in the peripheral area which is occupied by the majority of the values which are small. Therefore, the produced drawings are both informative and compact. The algorithm has linear time complexity (assuming the values are sorted), very limited main memory requirements, and produces drawings of bounded space, making it appropriate for interactive visualizations, and visual interfaces in general. We showcase the application of the algorithms in various domains and interactive interfaces.},
  archive      = {J_JIIS},
  author       = {Tzitzikas, Yannis and Papadaki, Maria-Evangelia and Chatzakis, Manos},
  doi          = {10.1007/s10844-021-00677-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {535-559},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A spiral-like method to place in the space (and interact with) too many values},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Path-based reasoning with k-nearest neighbor and position
embedding for knowledge graph completion. <em>JIIS</em>, <em>58</em>(3),
513–533. (<a href="https://doi.org/10.1007/s10844-021-00671-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph completion aims to perform link prediction between entities. Reasoning over paths in incomplete knowledge graphs has become a hot research topic. However, most of the existing path reasoning methods ignore both the overlapping phenomenon of paths between similar relations and the order information of relations in paths, and they only consider the obvious paths between entities. To address the problems of knowledge graph reasoning, a new path-based reasoning method with K-Nearest Neighbor and position embedding is proposed in this paper. The method first projects entities and relations to continuous vector space, and then utilizes the idea of the K-Nearest Neighbor algorithm to find the K nearest neighbors of each relation. After that, the paths of similar relations are merged. Then, paths are modeled through the combination operations on relations. The position information of the relations is considered during the combination, that is, the position embedding is added to the relation vector in the path. A series of experiments are conducted on real datasets to prove the effectiveness of the proposed method. The experimental results show that the proposed method significantly outperforms all baselines on entity prediction and relation prediction tasks.},
  archive      = {J_JIIS},
  author       = {Peng, Zhihan and Yu, Hong and Jia, Xiuyi},
  doi          = {10.1007/s10844-021-00671-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {513-533},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Path-based reasoning with K-nearest neighbor and position embedding for knowledge graph completion},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Impact of techniques to reduce error in high error
rule-based expert system gradient descent networks. <em>JIIS</em>,
<em>58</em>(3), 481–512. (<a
href="https://doi.org/10.1007/s10844-021-00672-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning systems offer the key capability to learn about their operating environment from the data that they are supplied. They can learn via supervised and unsupervised training, from system results during operations, or both. However, while machine learning systems can identify solutions to problems and questions, in many cases they cannot explain how they arrived at them. Moreover, they cannot guarantee that they have not relied upon confounding variables and other non-causal relationships. In some circumstances, learned behaviors may violate legal or ethical principles such as rules regarding non-discrimination. In these and other cases, learned associations that are true in many – but not all – cases may result in critical system failures when processing exceptions to the learned behaviors. A machine learning system, which applies gradient descent to expert system networks, has been proposed as a solution to this. The expert system foundation means that the system can only learn across valid pathways, while the machine learning capabilities facilitate optimization via training and operational learning. While the initial results of this approach are promising, cases where networks were optimized into high error states (and for which continued optimization continued to increase the error level) were noted. This paper proposes and evaluates multiple techniques to handle these high error networks and improve system performance, in these cases.},
  archive      = {J_JIIS},
  author       = {Straub, Jeremy},
  doi          = {10.1007/s10844-021-00672-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {481-512},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Impact of techniques to reduce error in high error rule-based expert system gradient descent networks},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A systematic review of question answering systems for
non-factoid questions. <em>JIIS</em>, <em>58</em>(3), 453–480. (<a
href="https://doi.org/10.1007/s10844-021-00655-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question Answering (QA) is a field of study addressed to develop automatic methods for answering questions expressed in natural language. Recently, the emergence of the new generation of intelligent assistants, such as Siri, Alexa, and Google Assistant, has intensified the importance of an effective and efficient QA system able to handle questions with different complexities. Regarding the type of question to be answered, QA systems have been divided into two sub-areas: (i) factoid questions that require a single fact – e.g., a name of a person or a date, and (ii) non-factoid questions that need a more complex answer – e.g., descriptions, opinions, or explanations. While factoid QA systems have overcome human performance on some benchmarks, automatic systems for answering non-factoid questions remain a challenge and an open research problem. This work provides an overview of recent research addressing non-factoid questions. It focuses on which methods have been applied in each task, the data sets available, challenges and limitations, and possible research directions. From a total of 455 recent studies, we selected 75 papers based on our quality control system and exclusion criteria for an in-depth analysis. This systematic review helped to answer what are the tasks and methods involved in non-factoid, what are the data sets available, what the limitations are, and what is the recommendations for future research.},
  archive      = {J_JIIS},
  author       = {Cortes, Eduardo Gabriel and Woloszyn, Vinicius and Barone, Dante and Möller, Sebastian and Vieira, Renata},
  doi          = {10.1007/s10844-021-00655-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {453-480},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A systematic review of question answering systems for non-factoid questions},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leveraging autoencoders in change vector analysis of optical
satellite images. <em>JIIS</em>, <em>58</em>(3), 433–452. (<a
href="https://doi.org/10.1007/s10844-021-00670-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various applications in remote sensing demand automatic detection of changes in optical satellite images of the same scene acquired over time. This paper investigates how to leverage autoencoders in change vector analysis, in order to better delineate possible changes in a couple of co-registered, optical satellite images. Let us consider both a primary image and a secondary image acquired over time in the same scene. First an autoencoder artificial neural network is trained on the primary image. Then the reconstruction of both images is restored via the trained autoencoder so that the spectral angle distance can be computed pixelwise on the reconstructed data vectors. Finally, a threshold algorithm is used to automatically separate the foreground changed pixels from the unchanged background. The assessment of the proposed method is performed in three couples of benchmark hyperspectral images using different criteria, such as overall accuracy, missed alarms and false alarms. In addition, the method supplies promising results in the analysis of a couple of multispectral images of the burned area in the Majella National Park (Italy).},
  archive      = {J_JIIS},
  author       = {Andresini, Giuseppina and Appice, Annalisa and Iaia, Daniele and Malerba, Donato and Taggio, Nicolò and Aiello, Antonello},
  doi          = {10.1007/s10844-021-00670-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {433-452},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Leveraging autoencoders in change vector analysis of optical satellite images},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An ontology driven model for detection and classification of
cardiac arrhythmias using ECG data. <em>JIIS</em>, <em>58</em>(2),
405–431. (<a href="https://doi.org/10.1007/s10844-021-00685-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiac arrhythmias are not life-threatening straight away but can cause serious heart-related complications if not medically handled appropriately. An electrocardiogram (ECG) captures the heart’s electric activity and has widespread usage due to its easy deployment and non-invasive aspect. Arrhythmia classification through manual analysis of electrocardiogram (ECG) is troublesome, tedious, and prone to human errors that can lead to serious repercussions. Hence, it’s a more effective alternative to deploy computational techniques to automatically perform the classification. Traditional techniques are data-driven and require an immense amount of data to train and then perform identification. This paper presents an ontology-driven knowledge model to automatically diagnose arrhythmias based on the patient’s sensor-based ECG data. The proposed approach models the arrhythmia domain knowledge and the conceptual relationships relevant to classification of heartbeat into corresponding cardiac arrhythmias and to facilitate decision making with respect to the patients. The newly developed arrhythmia ontology consists of three different modules, each semantically annotating a different aspect of the arrhythmia detection process. A SWRL (Semantic Web Rule Language) based ontology classifier performs classification of patient’s ECG data into corresponding cardiac arrhythmia types. The constructed knowledge base is ontologically aligned with some benchmarked top-level ontologies that promotes the semantic interoperability across multiple domains. The resultant ontological model is validated with a real-world ECG dataset and compared with the existing approaches showing higher precision rate and comparable performance. The developed model establishes a standardized ontology, that promotes the exchange and shareability of consensual domain knowledge about arrhythmic conditions, supports information retrieval and knowledge discovery.},
  archive      = {J_JIIS},
  author       = {Hooda, Diksha and Rani, Rinkle},
  doi          = {10.1007/s10844-021-00685-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {405-431},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {An ontology driven model for detection and classification of cardiac arrhythmias using ECG data},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RecogNet-LSTM+CNN: A hybrid network with attention mechanism
for aspect categorization and sentiment classification. <em>JIIS</em>,
<em>58</em>(2), 379–404. (<a
href="https://doi.org/10.1007/s10844-021-00692-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis for user reviews has received substantial heed in recent years. There are many deep learning models for natural language processing (NLP) applications. Long-short term memory (LSTM) and Convolutional neural network (CNN) based models efficiently enhance sentiment accuracy. Aspect-level sentiment analysis involves aspect extraction, aspect categorization, and polarity classification. The aspect sentiments in the dataset are classified as positive, negative, and neutral, depending on the polarity score associated with the aspect emotions. Existing neural architectures combining LSTM and CNN employ only the implicit information from the dataset for sentiment classification. Alternatively, this paper highlights the integration of explicit knowledge from the external database (RecogNet) with the implicit information of the LSTM model to improvise the sentiment accuracy. Incorporating sentic and semantic clues from the RecogNet knowledge base to the LSTM increases aspect extraction and categorization efficiency. Furthermore, we implemented CNN with target and position attention mechanisms over the RecogNet-LSTM layer to further enhance the classification accuracy. Finally, the model evaluations are performed using five online datasets related to the restaurants, laptops, and locations. Among LSTM based hybrid models, our RecogNet-LSTM+CNN model with attention mechanism showed superior performance in aspect categorization and opinion classification.},
  archive      = {J_JIIS},
  author       = {Ramaswamy, Srividhya Lakshmi and Chinnappan, Jayakumar},
  doi          = {10.1007/s10844-021-00692-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {379-404},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {RecogNet-LSTM+CNN: A hybrid network with attention mechanism for aspect categorization and sentiment classification},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interest-aware influence diffusion model for social
recommendation. <em>JIIS</em>, <em>58</em>(2), 363–377. (<a
href="https://doi.org/10.1007/s10844-021-00684-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of social networks, the application of social relationships in recommendation systems has attracted more and more attention. The social recommendation system alleviates the problem of data sparsity by utilizing the preferences of users’ friends, so as to better model the user embedding. The traditional social recommendation model optimizes the user embedding through the first-order neighbors’ preference information, but it failed to model the social influence diffusion process from the global social network. Although the recently proposed DiffNet solves this problem to some extent, it ignores the fact that high-order adjacent users who have no common interests in the social network can also participate in graph convolution, which will make user embedding affected by negative information in social influence diffusion, thus affecting the performance of the recommendation system. Therefore, we propose a model named IDiffNet based on DiffNet. In IDiffNet, a self-supervised subgraph generation module is designed to identify users with similar interests according to user features. Thereby, the user social graph is decomposed into several user social subgraphs, and then user embedding is optimized through interest propagation on the subgraphs. Consequently, the IDiffNet can avoid the interaction of users with different interests in the user social network. Finally, we conducted a number of comparative experiments on two public datasets, and the results show that IDiffNet has better performance than current mainstream social recommendation models.},
  archive      = {J_JIIS},
  author       = {Li, Yuqiang and Zhan, Zhilong and Li, Huan and Liu, Chun},
  doi          = {10.1007/s10844-021-00684-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {363-377},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Interest-aware influence diffusion model for social recommendation},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An empirical evaluation of active learning strategies for
profile elicitation in a conversational recommender system.
<em>JIIS</em>, <em>58</em>(2), 337–362. (<a
href="https://doi.org/10.1007/s10844-021-00683-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational Recommender Systems have received widespread attention in both research and practice. They assist people in finding relevant and interesting items through a multi-turn conversation. The use of natural language interaction also allows users to express their preferences with more flexibility. However, these systems often have to work in a cold-start situation, and most of the conversation is dedicated to the profile elicitation step. In order to ensure good recommendations, this profile should be as rich as possible, which requires great user effort. In this paper, we investigate the application of Active Learning techniques for improving the profile elicitation step in a Conversational Recommender System. We compared five different state-of-the-art techniques, and carried out a user study with 219 users in order to assess their effectiveness both in terms of recommendation accuracy and user effort. Results show that assisting users by providing personalized suggestions during the profile elicitation step improves the quality of the recommendations in terms of Hit Rate and nDCG, compared to a strategy that requires users to come up with preferences on their own.},
  archive      = {J_JIIS},
  author       = {Iovine, Andrea and Lops, Pasquale and Narducci, Fedelucio and de Gemmis, Marco and Semeraro, Giovanni},
  doi          = {10.1007/s10844-021-00683-4},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {337-362},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {An empirical evaluation of active learning strategies for profile elicitation in a conversational recommender system},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A sampling approach to debiasing the offline evaluation of
recommender systems. <em>JIIS</em>, <em>58</em>(2), 311–336. (<a
href="https://doi.org/10.1007/s10844-021-00651-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline evaluation of recommender systems (RSs) mostly relies on historical data, which is often biased. The bias is a result of many confounders that affect the data collection process. In such biased data, user-item interactions are Missing Not At Random (MNAR). Measures of recommender system performance on MNAR test data are unlikely to be reliable indicators of real-world performance unless something is done to mitigate the bias. One widespread way that researchers try to obtain less biased offline evaluation is by designing new, supposedly unbiased performance metrics for use on MNAR test data. We investigate an alternative solution, a sampling approach. The general idea is to use a sampling strategy on MNAR data to generate an intervened test set with less bias — one in which interactions are Missing At Random (MAR) or, at least, one that is more MAR-like. An existing example of this approach is SKEW, a sampling strategy that aims to adjust for the confounding effect that an item’s popularity has on its likelihood of being observed. In this paper, after extensively surveying the literature on the bias problem in the offline evaluation of RSs, we propose and formulate a novel sampling approach, which we call WTD; we also propose a more practical variant, which we call WTD_H. We compare our methods to SKEW and to two baselines which perform a random intervention on MNAR data. We empirically validate for the first time the effectiveness of SKEW and we show our approach to be a better estimator of the performance that one would obtain on (unbiased) MAR test data. Our strategy benefits from high generality (e.g. it can also be employed for training a recommender) and low overheads (e.g. it does not require any learning).},
  archive      = {J_JIIS},
  author       = {Carraro, Diego and Bridge, Derek},
  doi          = {10.1007/s10844-021-00651-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {311-336},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A sampling approach to debiasing the offline evaluation of recommender systems},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). User-controlled federated matrix factorization for
recommender systems. <em>JIIS</em>, <em>58</em>(2), 287–309. (<a
href="https://doi.org/10.1007/s10844-021-00688-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation services have been extensively adopted in various user-centered applications to help users navigate a vast space of possible choices. In such scenarios, data ownership is a crucial concern since users may not be willing to share their sensitive preferences (e.g., visited locations, read books, bought items) with a central server. Unfortunately, data collection is at the basis of modern approaches to the recommendation problem. Decreased users’ willingness to share personal information and data protection policies can result in the “data scarcity” dilemma affecting applications such as recommender systems. In the work at hand, we thoroughly study and extend FPL (Federated Pair-wise Learning), a recommendation approach that follows the Federated Learning principles. In FPL, users collaborate in training a pair-wise learning to rank factorization model while controlling the amount of sensitive data that leaves their devices. An extensive experimental evaluation reveals the effectiveness of the proposed architecture concerning the accuracy and beyond-accuracy objectives and the impact of disclosed users’ information on the quality of the final model. The paper also analyzes the impact of communication costs with the central server on the system’s performance by varying local computation and training parallelism. Furthermore, the study investigates the injection of additional biases in the final recommendation that could affect the fairness of the system. The public implementation is available at https://split.to/sisinflab-fpl .},
  archive      = {J_JIIS},
  author       = {Anelli, Vito Walter and Deldjoo, Yashar and Di Noia, Tommaso and Ferrara, Antonio and Narducci, Fedelucio},
  doi          = {10.1007/s10844-021-00688-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {287-309},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {User-controlled federated matrix factorization for recommender systems},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analyzing and improving stability of matrix factorization
for recommender systems. <em>JIIS</em>, <em>58</em>(2), 255–285. (<a
href="https://doi.org/10.1007/s10844-021-00686-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to their flexibility and scalability, collaborative embedding-based models are widely employed for the top-N recommendation task. Their goal is to jointly represent users and items in a common low-dimensional embedding space where users are represented close to items for which they expressed a positive preference. The training procedure of these techniques is influenced by several sources of randomness, that can have a strong impact on the embeddings learned by the models. In this paper we analyze this impact on Matrix Factorization (MF). In particular, we focus on the effects of training the same model on the same data, but with different initial values for the latent representations of users and items. We perform several experiments employing three well known MF implementations over five datasets. We show that different random initializations lead the same MF technique to generate very different latent representations and recommendation lists. We refer to these inconsistencies as instability of representations and instability of recommendations, respectively. We report that stability of item representations is positively correlated to the accuracy of the model. We show that the stability issues affect also the items for which the recommender correctly predicts positive preferences. Moreover, we highlight that the effect is stronger for less popular items. To overcome these drawbacks, we present a generalization of MF called Nearest Neighbors Matrix Factorization (NNMF). The new framework learns the embedding of each user and item as a weighted linear combination of the representations of the respective nearest neighbors. This strategy has the effect to propagate the information about items and users also to their neighbors and allows the embeddings of users and items with few interactions to be supported by a higher amount of information. To empirically demonstrate the advantages of the new framework, we provide a detailed description of the NNMF variants of three common MF techniques. We show that NNMF models, compared to their MF counterparts, largely improve the stability of both representations and recommendations, obtain a higher and more stable accuracy performance, especially on long-tail items, and reach convergence in a fraction of epochs.},
  archive      = {J_JIIS},
  author       = {D’Amico, Edoardo and Gabbolini, Giovanni and Bernardis, Cesare and Cremonesi, Paolo},
  doi          = {10.1007/s10844-021-00686-1},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {255-285},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Analyzing and improving stability of matrix factorization for recommender systems},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sequential group recommendations based on satisfaction and
disagreement scores. <em>JIIS</em>, <em>58</em>(2), 227–254. (<a
href="https://doi.org/10.1007/s10844-021-00652-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, group recommendations have gained much attention. Nevertheless, most approaches consider only one round of recommendations. However, in a real-life scenario, it is expected that the history of previous recommendations is exploited to tailor the recommendations towards meeting the needs of the group members. Such history should include not only which items the system suggested, but also the reaction of the members to these items. This work introduces the problem of sequential group recommendations, by exploiting the concept of satisfaction and disagreement. Satisfaction describes how well the group received the suggested items. Disagreement describes the satisfaction bias among the group members. We utilize these concepts in three new aggregation methods, SDAA, SIAA and Average+, designed to address the specific challenges introduced by sequential group recommendations. We experimentally show the effectiveness of our methods using big real datasets for both stable and ephemeral groups.},
  archive      = {J_JIIS},
  author       = {Stratigi, Maria and Pitoura, Evaggelia and Nummenmaa, Jyrki and Stefanidis, Kostas},
  doi          = {10.1007/s10844-021-00652-x},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {227-254},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Sequential group recommendations based on satisfaction and disagreement scores},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). JIIS preface for the special issue on advances in
recommender systems. <em>JIIS</em>, <em>58</em>(2), 223–225. (<a
href="https://doi.org/10.1007/s10844-022-00697-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have been successfully applied to alleviate overloaded information and assist decision making in various domains and applications. Recently, several new research directions emerged and novel techniques were proposed to advance the development of recommender systems. In this special issue, we invited authors to submit the revised and extended version of their accepted papers in the track on recommender systems associated with ACM Symposium on Applied Computing in 2020 and 2021. Each submission was reviewed by at least two experts and revised according to the reviewers’ comments to ensure the quality of the paper. We hope this special issue can motivate researchers in the area of recommender systems to take the next step beyond traditional algorithm development and seek more opportunities in their research work.},
  archive      = {J_JIIS},
  author       = {Zheng, Yong and Chen, Li and Zanker, Markus and Symeonidis, Panagiotis},
  doi          = {10.1007/s10844-022-00697-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {223-225},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {JIIS preface for the special issue on advances in recommender systems},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Upper bounds for can-tree and FP-tree. <em>JIIS</em>,
<em>58</em>(1), 197–222. (<a
href="https://doi.org/10.1007/s10844-021-00673-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two efficient tree structures known as Can-tree (Leung et al., Knowledge and Information Systems, 11(3), 287–311, 2007) and FP-tree (Han et al., 2000) are used to store a database in memory for mining frequent patterns. However, there has been no discussion on tight upper bound for the number of nodes in these trees. Instead, a very loose upper bound of 2n (where n is the number of distinct items in the database) is used. In this paper, we provide a tighter upper bound for the number of nodes in Can-tree and FP-tree. The upper bound on the number of nodes is provided through a greedy algorithm for the Can-tree and a closed form solution is derived for the FP-tree. These results are illustrated by examples both in graphical and mathematical form.},
  archive      = {J_JIIS},
  author       = {Shahbazi, Nima and Gryz, Jarek},
  doi          = {10.1007/s10844-021-00673-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {197-222},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Upper bounds for can-tree and FP-tree},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IbLT: An effective granular computing framework for
hierarchical community detection. <em>JIIS</em>, <em>58</em>(1),
175–196. (<a href="https://doi.org/10.1007/s10844-021-00668-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mapping the vertices of network onto a tree helps to reveal the hierarchical community structures. The leading tree is a granular computing (GrC) model for efficient hierarchical clustering and it requires two elements: the distance between granules, and the density calculated in Euclidean space. For the non-Euclidean network data, the vertices need to be embedded in the Euclidean space before density calculation. This results in the marginalization of community centers. This paper proposes a new hierarchical community detection framework, called Importance-based Leading Tree (IbLT). Different from the density-based leading tree, IbLT calculates the structural similarity between vertices and the importance of the vertices respectively. It generates leading trees that match the structural features of the vertices, and thus, IbLT obtains more accurate results for the detection of hierarchical community structures. Experiments are conducted to evaluate the performance of the proposed novel IbLT-based method. On social network community detection task, the quantitative results show that this method achieves competitive accuracy.},
  archive      = {J_JIIS},
  author       = {Fu, Shun and Wang, Guoyin and Xu, Ji and Xia, Shuyin},
  doi          = {10.1007/s10844-021-00668-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {175-196},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {IbLT: An effective granular computing framework for hierarchical community detection},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-lingual transfer of abstractive summarizer to
less-resource language. <em>JIIS</em>, <em>58</em>(1), 153–173. (<a
href="https://doi.org/10.1007/s10844-021-00663-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic text summarization extracts important information from texts and presents the information in the form of a summary. Abstractive summarization approaches progressed significantly by switching to deep neural networks, but results are not yet satisfactory, especially for languages where large training sets do not exist. In several natural language processing tasks, a cross-lingual model transfer is successfully applied in less-resource languages. For summarization, the cross-lingual model transfer was not attempted due to a non-reusable decoder side of neural models that cannot correct target language generation. In our work, we use a pre-trained English summarization model based on deep neural networks and sequence-to-sequence architecture to summarize Slovene news articles. We address the problem of inadequate decoder by using an additional language model for the evaluation of the generated text in target language. We test several cross-lingual summarization models with different amounts of target data for fine-tuning. We assess the models with automatic evaluation measures and conduct a small-scale human evaluation. Automatic evaluation shows that the summaries of our best cross-lingual model are useful and of quality similar to the model trained only in the target language. Human evaluation shows that our best model generates summaries with high accuracy and acceptable readability. However, similar to other abstractive models, our models are not perfect and may occasionally produce misleading or absurd content.},
  archive      = {J_JIIS},
  author       = {Žagar, Aleš and Robnik-Šikonja, Marko},
  doi          = {10.1007/s10844-021-00663-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {153-173},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Cross-lingual transfer of abstractive summarizer to less-resource language},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis of information cascading and propagation barriers
across distinctive news events. <em>JIIS</em>, <em>58</em>(1), 119–152.
(<a href="https://doi.org/10.1007/s10844-021-00654-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {News reporting, on events that occur in our society, can have different styles and structures, as well as different dynamics of news spreading over time. News publishers have the potential to spread their news and reach out to a large number of readers worldwide. In this paper we would like to understand how well they are doing it and which kind of obstacles the news may encounter when spreading. The news to be spread wider cross multiple barriers such as linguistic (the most evident one, as they get published in other natural languages), economic, geographical, political, time zone, and cultural barriers. Observing potential differences between spreading of news on different events published by multiple publishers can bring insights into what may influence the differences in the spreading patterns. There are multiple reasons, possibly many hidden, influencing the speed and geographical spread of news. This paper studies information cascading and propagation barriers, applying the proposed methodology on three distinctive kinds of events: Global Warming, earthquakes, and FIFA World Cup. Our findings suggest that 1) the scope of a specific event significantly effects the news spreading across languages, 2) geographical size of a news publisher’s country is directly proportional to the number of publishers and articles reporting on the same information, 3) countries with shorter time-zone differences and similar cultures tend to propagate news between each other, 4) news related to Global Warming comes across economic barriers more smoothly than news related to FIFA World Cup and earthquakes and 5) events which may in some way involve political benefits are mostly published by those publishers which are not politically neutral.},
  archive      = {J_JIIS},
  author       = {Sittar, Abdul and Mladenić, Dunja and Grobelnik, Marko},
  doi          = {10.1007/s10844-021-00654-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {119-152},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Analysis of information cascading and propagation barriers across distinctive news events},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An overview of machine learning techniques in constraint
solving. <em>JIIS</em>, <em>58</em>(1), 91–118. (<a
href="https://doi.org/10.1007/s10844-021-00666-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constraint solving is applied in different application contexts. Examples thereof are the configuration of complex products and services, the determination of production schedules, and the determination of recommendations in online sales scenarios. Constraint solvers apply, for example, search heuristics to assure adequate runtime performance and prediction quality. Several approaches have already been developed showing that machine learning (ML) can be used to optimize search processes in constraint solving. In this article, we provide an overview of the state of the art in applying ML approaches to constraint solving problems including constraint satisfaction, SAT solving, answer set programming (ASP) and applications thereof such as configuration, constraint-based recommendation, and model-based diagnosis. We compare and discuss the advantages and disadvantages of these approaches and point out relevant directions for future work.},
  archive      = {J_JIIS},
  author       = {Popescu, Andrei and Polat-Erdeniz, Seda and Felfernig, Alexander and Uta, Mathias and Atas, Müslüm and Le, Viet-Man and Pilsl, Klaus and Enzelsberger, Martin and Tran, Thi Ngoc Trang},
  doi          = {10.1007/s10844-021-00666-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {91-118},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {An overview of machine learning techniques in constraint solving},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). User profiling and satisfaction inference in public
information access services. <em>JIIS</em>, <em>58</em>(1), 67–89. (<a
href="https://doi.org/10.1007/s10844-021-00661-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public information access services are provided by dozens of countries around the world as a means to promote transparency and democracy, and present a number of research opportunities for the development of computational models that help understand both users and their needs. Based on these observations, the present work discusses how the use of Natural Language Processing (NLP) methods may harvest valuable knowledge about citizen-government communication in user profiling and satisfaction inference tasks. More specifically, from a large text dataset of this kind, we build a number of models using a range of supervised machine learning methods - including bidirectional long short-term memory networks (LSTMs), pre-trained context-sensitive embeddings (BERT) and others - and show that these outperform textual and non-textual baseline alternatives alike. This outcome makes a case in favour of NLP methods for these tasks, and paves the way for further applications in the public information access domain.},
  archive      = {J_JIIS},
  author       = {Flores, Arthur Marçal and Pavan, Matheus Camasmie and Paraboni, Ivandré},
  doi          = {10.1007/s10844-021-00661-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {67-89},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {User profiling and satisfaction inference in public information access services},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge graph summarization impacts on movie
recommendations. <em>JIIS</em>, <em>58</em>(1), 43–66. (<a
href="https://doi.org/10.1007/s10844-021-00650-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A classical problem that frequently compromises Recommender System (RS) accuracy is the sparsity of the data about the interactions of the users with the items to be recommended. The use of side information (e.g. movie domain information) from a Knowledge Graph (KG) has proven effective to circumvent this problem. However, KG growth in terms of size and complexity gives rise to many challenges, including the demand for high-cost algorithms to handle large amounts of partially irrelevant and noisy data. Meanwhile, though Graph Summarization (GS) has become popular to support tasks such as KG visualization and search, it is still relatively unexplored in the KG-based RS domain. In this work, we investigate the potential of GS as a preprocessing step to condense side information in a KG and consequently reduce computational costs of using this information. We propose a GS method that combines embedding based on latent semantics (ComplEx) with nodes clustering (K-Means) in single-view and multi-view approaches for KG summarization, i.e. which act on the whole KG at once or on a separated KG view at a time, respectively. Then, we evaluate the impacts of these alternative GS approaches on several state-of-the-art KG-based RSs, in experiments using the MovieLens 1M dataset and side information gathered from IMDb and DBpedia. Our experimental results show that KG summarization can speed up the recommendation process without significant changes in movie recommendation quality, which vary in accordance with the GS approach, the summarization ratio, and the recommendation method.},
  archive      = {J_JIIS},
  author       = {Sacenti, Juarez A. P. and Fileto, Renato and Willrich, Roberto},
  doi          = {10.1007/s10844-021-00650-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {43-66},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Knowledge graph summarization impacts on movie recommendations},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Coarse-grained decomposition and fine-grained interaction
for multi-hop question answering. <em>JIIS</em>, <em>58</em>(1), 21–41.
(<a href="https://doi.org/10.1007/s10844-021-00645-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, question answering (QA) and reading comprehension (RC) has attracted much attention, and most research on QA has focused on multi-hop QA task which requires connecting multiple pieces of evidence scattered in a long context to answer the question. The key to the multi-hop QA task is semantic feature interaction between documents and questions, which is widely processed by Bi-directional Attention Flow (Bi-DAF), but Bi-DAF generally captures only the surface semantics of words in complex questions, and fails to capture implied semantic feature of intermediate answers, as well as ignoring parts of contexts related to the question and failing to extract the most important parts of multiple documents. In this paper, we propose a new model architecture for multi-hop question answering by applying two completion strategies:(1) Coarse-Grained complex question Decomposition (CGDe) strategy is introduced to decompose complex questions into simple ones without any additional annotations; (2) Fine-Grained Interaction (FGIn) strategy is introduced to explicitly represent each word in documents and extract more comprehensive and accurate sentences related to the inference path. The above two strategies are combined and tested on the SQuAD and HotpotQA datasets, and the experimental results show that our method outperforms state-of-the-art baselines.},
  archive      = {J_JIIS},
  author       = {Cao, Xing and Liu, Yun},
  doi          = {10.1007/s10844-021-00645-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {21-41},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Coarse-grained decomposition and fine-grained interaction for multi-hop question answering},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploiting stance hierarchies for cost-sensitive stance
detection of web documents. <em>JIIS</em>, <em>58</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s10844-021-00642-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fact checking is an essential challenge when combating fake news. Identifying documents that agree or disagree with a particular statement (claim) is a core task in this process. In this context, stance detection aims at identifying the position (stance) of a document towards a claim. Most approaches address this task through classification models that do not consider the highly imbalanced class distribution. Therefore, they are particularly ineffective in detecting the minority classes (for instance, ‘disagree’), even though such instances are crucial for tasks such as fact-checking by providing evidence for detecting false claims. In this paper, we exploit the hierarchical nature of stance classes which allows us to propose a modular pipeline of cascading binary classifiers, enabling performance tuning on a per step and class basis. We implement our approach through a combination of neural and traditional classification models that highlight the misclassification costs of minority classes. Evaluation results demonstrate state-of-the-art performance of our approach and its ability to significantly improve the classification performance of the important ‘disagree’ class.},
  archive      = {J_JIIS},
  author       = {Roy, Arjun and Fafalios, Pavlos and Ekbal, Asif and Zhu, Xiaofei and Dietze, Stefan},
  doi          = {10.1007/s10844-021-00642-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {1-19},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Exploiting stance hierarchies for cost-sensitive stance detection of web documents},
  volume       = {58},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
