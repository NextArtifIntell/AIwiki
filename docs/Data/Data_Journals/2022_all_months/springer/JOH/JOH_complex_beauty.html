<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JOH_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="joh---23">JOH - 23</h2>
<ul>
<li><details>
<summary>
(2022). Combining hybrid genetic search with ruin-and-recreate for
solving the capacitated vehicle routing problem. <em>JOH</em>,
<em>28</em>(5), 653–697. (<a
href="https://doi.org/10.1007/s10732-022-09500-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Capacitated Vehicle Routing Problem (CVRP) has been subject to intense research efforts for more than sixty years. Yet, significant algorithmic improvements are still being made. The most competitive heuristic solution algorithms of today utilize, and often combine, strategies and elements from evolutionary algorithms, local search, and ruin-and-recreate based large neighborhood search. In this paper we propose a new hybrid metaheuristic for the CVRP, where the education phase of the hybrid genetic search (HGS) algorithm proposed by (Vidal Hybrid Genetic Search for the CVRP: Open-Source Implementation and SWAP* Neighborhood 2020) is extended by applying large neighborhood search (LNS). By performing a series of computational experiments, we attempt to answer the following research questions: 1) Is it possible to gain performance by adding LNS as a component in the education phase of HGS? 2) How does the addition of LNS change the relative importance of the local search neighborhoods of HGS? 3) What is the effect of devoting computational efforts to the creation of an elite solution in the initial population of HGS? Through a set of computational experiments we answer these research questions, while at the same time obtaining a good configuration of global parameter settings for the proposed heuristic. Testing the heuristic on benchmark instances from the literature with limited computing time, it outperforms existing algorithms, both in terms of the final gap and the primal integral.},
  archive      = {J_JOH},
  author       = {Simensen, Martin and Hasle, Geir and Stålhane, Magnus},
  doi          = {10.1007/s10732-022-09500-9},
  journal      = {Journal of Heuristics},
  month        = {12},
  number       = {5},
  pages        = {653-697},
  shortjournal = {J. Heuristics},
  title        = {Combining hybrid genetic search with ruin-and-recreate for solving the capacitated vehicle routing problem},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling and evolutionary algorithm for solving a
multi-depot mixed vehicle routing problem with uncertain travel times.
<em>JOH</em>, <em>28</em>(5), 619–651. (<a
href="https://doi.org/10.1007/s10732-022-09503-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with a multi-depot mixed vehicle routing problem under uncertain travel times (MDMVRP-UT), where there are several different depots and a number of identical vehicles. A vehicle can come back to any of the depots after its service is completed. A light-robust-optimization model is set up to control the total travel time within a preset value and to minimize the total travel time as much as possible. Then an effective evolutionary algorithm (EA) is proposed to solve the light-robust-optimization model. In the proposed EA, two constructive heuristics, namely a random customer sequence-based heuristic and a minimum spanning tree-based heuristic, are presented according to the problem-specific knowledge to generate a high-quality initial population with a certain level of diversity. A destruction and construction-based reproduction operator is provided to give birth to high-quality feasible offspring. A pairwise interchange based local search method is proposed to enhance the local exploitation capability. A hybrid selection operator and a population updating method are employed to remain the diversity of the population. The effectiveness of the proposed EA is verified by comprehensive experiments based on the well-known benchmark instances in the literature.},
  archive      = {J_JOH},
  author       = {Sun, Liang},
  doi          = {10.1007/s10732-022-09503-6},
  journal      = {Journal of Heuristics},
  month        = {12},
  number       = {5},
  pages        = {619-651},
  shortjournal = {J. Heuristics},
  title        = {Modeling and evolutionary algorithm for solving a multi-depot mixed vehicle routing problem with uncertain travel times},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Breakout local search for the cyclic cutwidth minimization
problem. <em>JOH</em>, <em>28</em>(5), 583–618. (<a
href="https://doi.org/10.1007/s10732-022-09504-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cyclic cutwidth minimization problem (CCMP) is a graph layout problem that involves embedding a graph onto a circle to minimize the maximum cutwidth of the graph. In this paper, we present breakout local search (BLS) for solving CCMP, which combines a dedicated local search procedure to discover high-quality local optimal solutions and an adaptive diversification strategy to escape from local optima. Extensive computational results on a wide set of 179 publicly available benchmark instances show that the proposed BLS algorithm has excellent performance with respect to the best-performing state-of-the-art approaches in terms of solution quality and computational time. In particular, it reports improved best-known solutions for 31 instances, while finding matching best-known results on 139 instances.},
  archive      = {J_JOH},
  author       = {He, Mu and Wu, Qinghua and Lu, Yongliang},
  doi          = {10.1007/s10732-022-09504-5},
  journal      = {Journal of Heuristics},
  month        = {12},
  number       = {5},
  pages        = {583-618},
  shortjournal = {J. Heuristics},
  title        = {Breakout local search for the cyclic cutwidth minimization problem},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heuristics for optimizing 3D mapping missions over
swarm-powered ad-hoc clouds. <em>JOH</em>, <em>28</em>(4), 539–582. (<a
href="https://doi.org/10.1007/s10732-022-09502-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drones have been getting more and more popular in many economy sectors. Both scientific and industrial communities aim at making the impact of drones even more disruptive by empowering collaborative autonomous behaviors—also known as swarming behaviors—within fleets of multiple drones. In swarming-powered 3D mapping missions, unmanned aerial vehicles typically collect the aerial pictures of the target area whereas the 3D reconstruction process is performed in a centralized manner. However, such approaches do not leverage computational and storage resources from the swarm members. We address the optimization of a swarm-powered distributed 3D mapping mission for a real-life humanitarian emergency response application through the exploitation of a swarm-powered ad hoc cloud. Producing the relevant 3D maps in a timely manner, even when the cloud connectivity is not available, is crucial to increase the chances of success of the operation. In this work, we present a mathematical programming heuristic based on decomposition and a variable neighborhood search heuristic to minimize the completion time of the 3D reconstruction process necessary in such missions. Our computational results reveal that the proposed heuristics either quickly reach optimality or improve the best known solutions for almost all tested realistic instances comprising up to 1000 images and fifteen drones.},
  archive      = {J_JOH},
  author       = {Costa, Leandro R. and Aloise, Daniel and Gianoli, Luca G. and Lodi, Andrea},
  doi          = {10.1007/s10732-022-09502-7},
  journal      = {Journal of Heuristics},
  month        = {8},
  number       = {4},
  pages        = {539-582},
  shortjournal = {J. Heuristics},
  title        = {Heuristics for optimizing 3D mapping missions over swarm-powered ad-hoc clouds},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A systematic approach to parameter optimization and its
application to flight schedule simulation software. <em>JOH</em>,
<em>28</em>(4), 509–538. (<a
href="https://doi.org/10.1007/s10732-022-09501-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial software often has many parameters that critically impact performance. Frequently, these are left in a sub-optimal configuration for a given application because searching over possible configurations is costly and, except for developer instinct, the relationships between parameters and performance are often unclear and complex. While there have been significant advances in automated parameter tuning approaches recently, they are typically black-box. The high-quality solutions produced are returned to the user without explanation. The nature of optimisation means that, often, these solutions are far outside the well-established settings for the software, making it difficult to accept and use them. To address the above issue, a systematic approach to software parameter optimization is presented. Several well-established techniques are followed in sequence, each underpinning the next, with rigorous analysis of the search space. This allows the results to be explainable to both end users and developers, improving confidence in the optimal solutions, particularly where they are counter-intuitive. The process comprises statistical analysis of the parameters; single-objective optimization for each target objective; functional ANOVA to explain trends and inter-parameter interactions; and a multi-objective optimization seeded with the results from the single-objective stage. A case study demonstrates application to business-critical software developed by the international airline Air France-KLM for measuring flight schedule robustness. A configuration is found with a run-time of 80% that of the tried-and-tested configuration, with no loss in predictive accuracy. The configuration is supplemented with detailed analysis explaining the importance of each parameter, how they interact with each other, how they influence run-time and accuracy, and how the final configuration was reached. In particular, this explains why the configuration included some parameter settings that were outwith the usually recommended range, greatly increasing developer confidence and encouraging adoption of the new configuration.},
  archive      = {J_JOH},
  author       = {Brownlee, Alexander E. I. and Epitropakis, Michael G. and Mulder, Jeroen and Paelinck, Marc and Burke, Edmund K.},
  doi          = {10.1007/s10732-022-09501-8},
  journal      = {Journal of Heuristics},
  month        = {8},
  number       = {4},
  pages        = {509-538},
  shortjournal = {J. Heuristics},
  title        = {A systematic approach to parameter optimization and its application to flight schedule simulation software},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fixed set search applied to the multi-objective minimum
weighted vertex cover problem. <em>JOH</em>, <em>28</em>(4), 481–508.
(<a href="https://doi.org/10.1007/s10732-022-09499-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Fixed Set Search (FSS) is a novel metaheuristic that adds a learning mechanism to the Greedy Randomized Adaptive Search Procedure (GRASP). In recent publications, its efficiency has been shown on different types of combinatorial optimization problems like routing, machine scheduling and covering. In this paper the FSS is adapted to multi-objective problems for finding Pareto Front approximations. This adaptation is illustrated for the bi-objective Minimum Weighted Vertex Cover Problem (MWVCP). In this work, a simple and effective bi-objective GRASP algorithm for the MWVCP is developed in the first stage. One important characteristic of the proposed GRASP is that it avoids the use of weighted sums of objective functions in the local search and the greedy algorithm. In the second stage, the bi-objective GRASP is extended to the FSS by adding a learning mechanism adapted to multi-objective problems. The conducted computational experiments show that the proposed FSS and GRASP algorithm significantly outperforms existing methods for the bi-objective MWVCP. To fully evaluate the learning mechanism of the FSS, it is compared to the underlying GRASP algorithm on a wide range of performance indicators related to convergence, distribution, spread and cardinality.},
  archive      = {J_JOH},
  author       = {Jovanovic, Raka and Sanfilippo, Antonio P. and Voß, Stefan},
  doi          = {10.1007/s10732-022-09499-z},
  journal      = {Journal of Heuristics},
  month        = {8},
  number       = {4},
  pages        = {481-508},
  shortjournal = {J. Heuristics},
  title        = {Fixed set search applied to the multi-objective minimum weighted vertex cover problem},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data structures for speeding up tabu search when solving
sparse quadratic unconstrained binary optimization problems.
<em>JOH</em>, <em>28</em>(4), 433–479. (<a
href="https://doi.org/10.1007/s10732-022-09498-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quadratic unconstrained binary optimization (QUBO) problem belongs to the NP-hard complexity class of problems and has been the subject of intense research since the 1960s. Many problems in various areas of research can be reformulated as QUBO problems, and several reformulated instances have sparse matrices. Thus, speeding up implementations of methods for solving the QUBO problem can benefit all of those problems. Among such methods, Tabu Search (TS) has been particularly successful. In this work, we propose data structures to speed up TS implementations when the instance matrix is sparse. Our main result consists in employing a compressed sparse row representation of the instance matrix, and priority queues for conducting the search over the solution space. While our literature review indicates that current TS procedures for QUBO take linear time on the number of variables to execute one iteration, our proposed structures may allow better time complexities than that, depending on the sparsity of the instance matrix. We show, by means of extensive computational experiments, that our techniques can significantly decrease the processing time of TS implementations, when solving QUBO problem instances with matrices of relatively high sparsity. To assess the quality of our results regarding more intricate procedures, we also experimented with a Path Relinking metaheuristic implemented with the TS using our techniques. This experiment showed that our techniques can allow such metaheuristics to become more competitive.},
  archive      = {J_JOH},
  author       = {Liang, Ricardo N. and Anacleto, Eduardo A. J. and Meneses, Cláudio N.},
  doi          = {10.1007/s10732-022-09498-0},
  journal      = {Journal of Heuristics},
  month        = {8},
  number       = {4},
  pages        = {433-479},
  shortjournal = {J. Heuristics},
  title        = {Data structures for speeding up tabu search when solving sparse quadratic unconstrained binary optimization problems},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incomplete MaxSAT approaches for combinatorial testing.
<em>JOH</em>, <em>28</em>(4), 377–431. (<a
href="https://doi.org/10.1007/s10732-022-09495-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a Satisfiability (SAT)-based approach for building Mixed Covering Arrays with Constraints of minimum length, referred to as the Covering Array Number problem. This problem is central in Combinatorial Testing for the detection of system failures. In particular, we show how to apply Maximum Satisfiability (MaxSAT) technology by describing efficient encodings for different classes of complete and incomplete MaxSAT solvers to compute optimal and suboptimal solutions, respectively. Similarly, we show how to solve through MaxSAT technology a closely related problem, the Tuple Number problem, which we extend to incorporate constraints. For this problem, we additionally provide a new MaxSAT-based incomplete algorithm. The extensive experimental evaluation we carry out on the available Mixed Covering Arrays with Constraints benchmarks and the comparison with state-of-the-art tools confirm the good performance of our approaches.},
  archive      = {J_JOH},
  author       = {Ansótegui, Carlos and Manyà, Felip and Ojeda, Jesus and Salvia, Josep M. and Torres, Eduard},
  doi          = {10.1007/s10732-022-09495-3},
  journal      = {Journal of Heuristics},
  month        = {8},
  number       = {4},
  pages        = {377-431},
  shortjournal = {J. Heuristics},
  title        = {Incomplete MaxSAT approaches for combinatorial testing},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A memetic algorithm for the inventory routing problem.
<em>JOH</em>, <em>28</em>(3), 351–375. (<a
href="https://doi.org/10.1007/s10732-022-09497-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study an Inventory Routing Problem with deterministic customer demand in a two-tier supply chain. The supply chain network consists of a supplier using a single vehicle with a given capacity to deliver a single product type to multiple customers. We are interested in population-based algorithms to solve our problem. A Memetic Algorithm (MA) is developed based on the Genetic Algorithm (GA) and Variable Neighborhood Search methods. The proposed meta-heuristics are tested on small and large reference benchmarks. The results of the MA are compared to those of the classical GA and to the optimal solutions in the literature. The comparison shows the efficiency of using MA and its ability to generate high quality solutions in a reasonable computation time.},
  archive      = {J_JOH},
  author       = {Sakhri, Mohamed Salim Amri and Tlili, Mounira and Korbaa, Ouajdi},
  doi          = {10.1007/s10732-022-09497-1},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {3},
  pages        = {351-375},
  shortjournal = {J. Heuristics},
  title        = {A memetic algorithm for the inventory routing problem},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weighted iterated local branching for mathematical
programming problems with binary variables. <em>JOH</em>,
<em>28</em>(3), 329–350. (<a
href="https://doi.org/10.1007/s10732-022-09496-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local search algorithms are frequently used to handle complex optimization problems involving binary decision variables. One way of implementing a local search procedure is by using a mixed-integer programming solver to explore a neighborhood defined through a constraint that limits the number of binary variables whose values are allowed to change in a given iteration. Recognizing that not all variables are equally promising to change when searching for better neighboring solutions, we propose a weighted iterated local branching heuristic. This new procedure differs from similar existing methods since it considers groups of binary variables and associates with each group a limit on the number of variables that can change. The groups of variables are defined using weights that indicate the expected contribution of flipping the variables when trying to identify improving solutions in the current neighborhood. When the mixed-integer programming solver fails to identify an improving solution in a given iteration, the proposed heuristic may force the search into new regions of the search space by utilizing the group of variables that are least promising to flip. The weighted iterated local branching heuristic is tested on benchmark instances of the optimum satisfiability problem, and computational results show that the weighted method is superior to an alternative method without weights.},
  archive      = {J_JOH},
  author       = {Rodrigues, Filipe and Agra, Agostinho and Hvattum, Lars Magnus and Requejo, Cristina},
  doi          = {10.1007/s10732-022-09496-2},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {3},
  pages        = {329-350},
  shortjournal = {J. Heuristics},
  title        = {Weighted iterated local branching for mathematical programming problems with binary variables},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A heuristic search based on diversity for solving
combinatorial problems. <em>JOH</em>, <em>28</em>(3), 287–328. (<a
href="https://doi.org/10.1007/s10732-022-09494-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a novel heuristic search for solving combinatorial optimization problems which we call Diverse Search (DS). Like beam search, this constructive approach expands only a selected subset of the solutions in each level of the search tree. However, instead of selecting the solutions with the best values, we use an efficient method to select a diverse subset, after filtering out uninteresting solutions. DS also distinguishes solutions that do not produce better offspring, and applies a local search process to them. The intuition is that the combination of these strategies allows to reach more—and more diverse—local optima, increasing the chances of finding the global optima. We test DS on several instances of the Köerkel–Ghosh (KG) and K-median benchmarks for the Simple Plant Location Problem. We compare it with a state-of-the-art heuristic for the KG benchmark and the relatively old POPSTAR solver, which also relies on the idea of maintaining a diverse set of solutions and, surprisingly, reached a comparable performance. With the use of a Path Relinking post-optimization step, DS can achieve results of the same quality that the state-of-the-art in similar CPU times. Furthermore, DS proved to be slightly better on average for large scale problems with small solution sizes, proving to be an efficient algorithm that delivers a set of good and diverse solutions.},
  archive      = {J_JOH},
  author       = {Casas, Francisco and Torres, Claudio E. and Araya, Ignacio},
  doi          = {10.1007/s10732-022-09494-4},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {3},
  pages        = {287-328},
  shortjournal = {J. Heuristics},
  title        = {A heuristic search based on diversity for solving combinatorial problems},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finding fixed-length circuits and cycles in undirected
edge-weighted graphs: An application with street networks. <em>JOH</em>,
<em>28</em>(3), 259–285. (<a
href="https://doi.org/10.1007/s10732-022-09493-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes two heuristic algorithms for finding fixed-length circuits and cycles in undirected edge-weighted graphs. It focusses particularly on a largely unresearched practical application where we are seeking attractive round trips for pedestrians and joggers in urban street networks. Our first method is based on identifying suitable pairs of paths that are combined to form a solution; our second is based on local search techniques. Both algorithms display high levels of accuracy, producing solutions within just a few meters of the target. Run times for the local search algorithm are also short, with solutions in large cities often being found in less than one second.},
  archive      = {J_JOH},
  author       = {Lewis, R. and Corcoran, P.},
  doi          = {10.1007/s10732-022-09493-5},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {3},
  pages        = {259-285},
  shortjournal = {J. Heuristics},
  title        = {Finding fixed-length circuits and cycles in undirected edge-weighted graphs: An application with street networks},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ride matching and vehicle routing for on-demand mobility
services. <em>JOH</em>, <em>28</em>(3), 235–258. (<a
href="https://doi.org/10.1007/s10732-022-09491-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On-Demand Mobility Services (ODMS) have gained considerable popularity over the past few years. Travelers use mobile phone applications to easily request a ride, update trip itinerary and pay the ride fare. This paper describes a novel methodology for integrated ride matching and vehicle routing for ODMS with ridesharing and transfer options. The methodology adopts a hybrid heuristic approach, which enables solving medium to large problem instances in near real-time. The solution of this problem will be a set of routes for vehicles and a ride match for each passenger. The heuristic (1) promptly responds to individual ride requests, and (2) periodically re-evaluates the generated solutions and recommend modifications to enhance the overall solution quality by increasing the number of served passengers and total profit of the system. The results of a set of experiments considering hypothetical and real-world networks show that the methodology can provide efficient solutions while satisfying the real-time execution requirements. In addition, the results show that the Transportation Network Company (TNC) could serve more passengers and achieve higher profitability if more passengers are willing to rideshare or transfer. Also, activating a rollback procedure increases the number of served passengers and associated profits.},
  archive      = {J_JOH},
  author       = {Lotfi, Sepide and Abdelghany, Khaled},
  doi          = {10.1007/s10732-022-09491-7},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {3},
  pages        = {235-258},
  shortjournal = {J. Heuristics},
  title        = {Ride matching and vehicle routing for on-demand mobility services},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Document representation and classification with
twitter-based document embedding, adversarial domain-adaptation, and
query expansion. <em>JOH</em>, <em>28</em>(2), 211–233. (<a
href="https://doi.org/10.1007/s10732-019-09417-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document vectorization with an appropriate encoding scheme is an essential component in various document processing tasks, including text document classification, retrieval, or generation. Training a dedicated document in a specific domain may require large enough data and sufficient resource. This motivates us to propose a novel document representation scheme with two main components. First, we train TD2V, a generic pre-trained document embedding for English documents from more than one million tweets in Twitter. Second, we propose a domain adaptation process with adversarial training to adapt TD2V to different domains. To classify a document, we use the rank list of its similar documents using query expansion techniques, either Average Query Expansion or Discriminative Query Expansion. Experiments on datasets from different online sources show that by using TD2V only, our method can classify documents with better accuracy than existing methods. By applying adversarial adaptation process, we can further boost and achieve the accuracy on BBC, BBCSport, Amazon4, 20NewsGroup datasets. We also evaluate our method on a specific domain of sensitivity classification and achieve the accuracy of higher than $$95\%$$ even with a short text fragment having 1024 characters on 5 datasets: Snowden, Mormon, Dyncorp, TM, and Enron.},
  archive      = {J_JOH},
  author       = {Tran, Minh-Triet and Trieu, Lap Q. and Tran, Huy Q.},
  doi          = {10.1007/s10732-019-09417-w},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {2},
  pages        = {211-233},
  shortjournal = {J. Heuristics},
  title        = {Document representation and classification with twitter-based document embedding, adversarial domain-adaptation, and query expansion},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). English–vietnamese cross-language paraphrase identification
using hybrid feature classes. <em>JOH</em>, <em>28</em>(2), 193–209. (<a
href="https://doi.org/10.1007/s10732-019-09411-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paraphrase identification plays an important role with various applications in natural language processing tasks such as machine translation, bilingual information retrieval, plagiarism detection, etc. With the development of information technology and the Internet, the requirement of textual comparing is not only in the same language but also in many different language pairs. Especially in Vietnamese, detecting paraphrase in the English–Vietnamese pair of sentences is a high demand because English is one of the most popular foreign languages in Vietnam. However, the in-depth studies on cross- language paraphrase identification tasks between English and Vietnamese are still limited. Therefore, in this paper, we propose a method to identify the English–Vietnamese cross-language paraphrase cases, using hybrid feature classes. These classes are calculated by using the fuzzy-based method as well as the siamese recurrent model, and then combined to get the final result with a mathematical formula. The experimental results show that our model achieves 87.4% F-measure accuracy.},
  archive      = {J_JOH},
  author       = {Dinh, Dien and Le Thanh, Nguyen},
  doi          = {10.1007/s10732-019-09411-2},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {2},
  pages        = {193-209},
  shortjournal = {J. Heuristics},
  title        = {English–Vietnamese cross-language paraphrase identification using hybrid feature classes},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identifying intentions in forum posts with cross-domain
data. <em>JOH</em>, <em>28</em>(2), 171–192. (<a
href="https://doi.org/10.1007/s10732-019-09410-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a method to identify forum posts expressing user intentions in online discussion forums. The results of this task, for example buying intentions, can be exploited for targeted advertising or other marketing tasks. Our method utilizes labeled data from other domains to help the learning task in the target domain by using a Naive Bayes (NB) framework to combine the data statistics . Because the distributions of data vary from domain to domain, it is important to adjust the contributions of different data sources when constructing the learning model, to achieve accurate results. Here, we propose to adjust the parameters of the NB classifier by optimizing an objective, which is equivalent to maximizing the between-class separation, using stochastic gradient descent. Experimental results show that our method outperforms several competitive baselines on a benchmark dataset consisting of forum posts from four domains: Cellphone, Electronics, Camera, and TV. In addition, we explore the possibility of combining NB posteriors computed during the optimization process with another classifier, namely Support Vector Machines. Experimental results show the usefulness of optimized NB class posteriors when using as features for SVMs in the cross-domain settings.},
  archive      = {J_JOH},
  author       = {Phuong, Tu Minh and Linh, Le Cong and Bach, Ngo Xuan},
  doi          = {10.1007/s10732-019-09410-3},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {2},
  pages        = {171-192},
  shortjournal = {J. Heuristics},
  title        = {Identifying intentions in forum posts with cross-domain data},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimating searching cost of regular path queries on large
graphs by exploiting unit-subqueries. <em>JOH</em>, <em>28</em>(2),
149–169. (<a href="https://doi.org/10.1007/s10732-018-9402-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular path queries (RPQs) are widely used on a graph whose answer is a set of tuples of nodes connected by paths corresponding to a given regular expression. Traditional automata-based approach for evaluating RPQs is restricted in the explosion of graph size, which makes graph searching take high cost (i.e. memory space and response time). Recently, a cost-based optimization technique using rare labels has been proved to be effective when it is applied to large graph. However, there is still a room for improvement, because the rare labels in the graph and/or the query are coarse information which could not guarantee the minimum searching cost all the time. This is our motivation to find a new approach using fine-grained information to estimate correctly the searching cost, which helps improving the performance of RPQs evaluation. For example, by using estimated searching cost, we can decompose an RPQ into small subqueries or separate multiple RPQs into small batch of queries in an efficient way for parallelism evaluation. In this paper, we present a novel approach for estimating the searching cost of RPQs on large graphs with cost functions based on the combinations of the searching cost of unit-subqueries (i.e. every smallest possible query). We extensively evaluated our method on real-world datasets including Alibaba, Yago, Freebase as well as synthetic datasets. Experimental results show that our estimation method obtains high accuracy which is approximately 87% on average. Moreover, two comparisons with automata-based and rare label based approaches demonstrate that our approach outperforms traditional ones.},
  archive      = {J_JOH},
  author       = {Nguyen, Van-Quyet and Huynh, Quyet-Thang and Kim, Kyungbaek},
  doi          = {10.1007/s10732-018-9402-0},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {2},
  pages        = {149-169},
  shortjournal = {J. Heuristics},
  title        = {Estimating searching cost of regular path queries on large graphs by exploiting unit-subqueries},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on “the eighth international symposium on
information and communication technology—SoICT 2017.” <em>JOH</em>,
<em>28</em>(2), 147–148. (<a
href="https://doi.org/10.1007/s10732-022-09492-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOH},
  author       = {Ide, Ichiro and Binh, Huynh Thi Thanh},
  doi          = {10.1007/s10732-022-09492-6},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {2},
  pages        = {147-148},
  shortjournal = {J. Heuristics},
  title        = {Special issue on “The eighth international symposium on information and communication Technology—SoICT 2017”},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A GRASP algorithm with tabu search improvement for solving
the maximum intersection of k-subsets problem. <em>JOH</em>,
<em>28</em>(1), 121–146. (<a
href="https://doi.org/10.1007/s10732-022-09490-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The selection of individuals with similar characteristics from a given population have always been a matter of interest in several scientific areas: data privacy, genetics, art, among others. This work is focused on the maximum intersection of k-subsets problem (kMIS). This problem tries to find a subset of k individuals with the maximum number of features in common from a given population and a set of relevant features. The research presents a Greedy Randomized Adaptive Search Procedure (GRASP) where the local improvement is replaced by a complete Tabu Search metaheuristic with the aim of further improving the quality of the obtained solutions. Additionally, a novel representation of the solution is considered to reduce the computational effort. The experimental comparison carefully analyzes the contribution of each part of the algorithm to the final results as well as performs a thorough comparison with the state-of-the-art method. Results, supported by non-parametric statistical tests, confirms the superiority of the proposal.},
  archive      = {J_JOH},
  author       = {Casado, Alejandra and Pérez-Peló, Sergio and Sánchez-Oro, Jesús and Duarte, Abraham},
  doi          = {10.1007/s10732-022-09490-8},
  journal      = {Journal of Heuristics},
  month        = {2},
  number       = {1},
  pages        = {121-146},
  shortjournal = {J. Heuristics},
  title        = {A GRASP algorithm with tabu search improvement for solving the maximum intersection of k-subsets problem},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lower and upper bounds for scheduling energy-consuming tasks
with storage resources and piecewise linear costs. <em>JOH</em>,
<em>28</em>(1), 93–120. (<a
href="https://doi.org/10.1007/s10732-021-09486-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the problem of scheduling a set of time- and energy-constrained preemptive tasks on a discrete time horizon. At each time period, the total energy required by the tasks that are in process can be provided by two energy sources: a reversible one and a non-reversible one. The non-reversible energy source can provide an unlimited amount of energy for a given period but at the expense of a time-dependent piecewise linear cost. The reversible energy source is a storage resource. The goal is to schedule each task preemptively inside its time window and to dispatch the required energy to the sources at each time period, while satisfying the reversible source capacity constraints and minimizing the total cost. We propose a mixed integer linear program of pseudo-polynomial size to solve this NP-hard problem. Acknowledging the limits of this model for problem instances of modest size, we propose an iterative decomposition matheuristic to compute an upper bound. The method relies on an efficient branch-and-price method or on a local search procedure to solve the scheduling problem without storage. The energy source allocation problem for a fixed schedule can in turn be solved efficiently by dynamic programming as a particular lot-sizing problem. We also propose a lower bound obtained by solving the linear programming relaxation of a new extended formulation by column generation. Experimental results show the quality of the bounds compared to the ones obtained using mixed integer linear program.},
  archive      = {J_JOH},
  author       = {Ngueveu, Sandra Ulrich and Artigues, Christian and Absi, Nabil and Kedad-Sidhoum, Safia},
  doi          = {10.1007/s10732-021-09486-w},
  journal      = {Journal of Heuristics},
  month        = {2},
  number       = {1},
  pages        = {93-120},
  shortjournal = {J. Heuristics},
  title        = {Lower and upper bounds for scheduling energy-consuming tasks with storage resources and piecewise linear costs},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new heuristic for finding verifiable k-vertex-critical
subgraphs. <em>JOH</em>, <em>28</em>(1), 61–91. (<a
href="https://doi.org/10.1007/s10732-021-09487-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given graph G, a k-vertex-critical subgraph (k-VCS) $$H \subseteq G$$ is a subgraph with chromatic number $$\chi (H)=k$$ , for which no vertex can be removed without decreasing its chromatic number. The main motivation for finding a k-VCS is to prove k is a lower bound on $$\chi (G)$$ . A graph may have several k-VCSs, and the k-Vertex-Critical Subgraph Problem asks for one with the least possible vertices. We propose a new heuristic for this problem. Differently from typical approaches that modify candidate subgraphs on a vertex-by-vertex basis, it generates new subgraphs by a heuristic that optimizes for maximum edges. We show this strategy has several advantages, as it allows a greater focus on smaller subgraphs for which computing $$\chi $$ is less of a bottleneck. Experimentally the proposed method matches or improves previous results in nearly all cases, and more often finds solutions that are provenly k-VCSs. We find new best k-VCSs for several DIMACS instances, and further improve known lower bounds for the chromatic number in two open instances, also fixing their chromatic numbers by matching existing upper bounds.},
  archive      = {J_JOH},
  author       = {Gliesch, Alex and Ritt, Marcus},
  doi          = {10.1007/s10732-021-09487-9},
  journal      = {Journal of Heuristics},
  month        = {2},
  number       = {1},
  pages        = {61-91},
  shortjournal = {J. Heuristics},
  title        = {A new heuristic for finding verifiable k-vertex-critical subgraphs},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using state-space shortest-path heuristics to solve the
long-haul point-to-point vehicle routing and driver scheduling problem
subject to hours-of-service regulatory constraints. <em>JOH</em>,
<em>28</em>(1), 23–59. (<a
href="https://doi.org/10.1007/s10732-021-09489-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the vehicle routing and driver scheduling problem of finding a low cost route and stoppage schedule for long-haul point-to-point full-load trips with intermediate stops due to refueling needs and driver hours-of-service regulatory restrictions. This is an important problem for long-haul truck drivers because in practice regulatory driving limits often do not coincide with availability of stoppage alternatives for quick rest, for meal, for overnight, or for weekly downtime required stops. The paper presents a methodology and algorithm to pick routes that optimize stoppages within the HOS constraints, an important factor of both highway safety and driver productivity. A solution for this variant of the vehicle routing and truck driver scheduling problem (VRTDS-HOS) that is fast enough to potentially be used in real time is proposed by modeling possible stoppage configurations as nodes in an iteratively built multi-dimensional state-space graph and by using heuristics to decrease processing time when searching for the lowest-cost path in that graph. Individual nodes in the graph are characterized by spatial, temporal, and stoppage attributes, and are expanded sequentially to search for low-cost paths between the origin and the destination. Within this multi-dimensional state-space graph, the paper proposes two heuristics applied to a shortest-path algorithmic solution based on the $$A^*$$ algorithm to increase processing speed enough to potentially permit real-time usage. An illustrative application to Brazilian regulations is provided. Results were successful and are reported together with sensitivity analyses comparing alternative routes and different heuristics processing speeds.},
  archive      = {J_JOH},
  author       = {De Genaro Chiroli, Daiane Maria and Mayerle, Sérgio Fernando and de Figueiredo, João Neiva},
  doi          = {10.1007/s10732-021-09489-7},
  journal      = {Journal of Heuristics},
  month        = {2},
  number       = {1},
  pages        = {23-59},
  shortjournal = {J. Heuristics},
  title        = {Using state-space shortest-path heuristics to solve the long-haul point-to-point vehicle routing and driver scheduling problem subject to hours-of-service regulatory constraints},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intersections management for autonomous vehicles: A
heuristic approach. <em>JOH</em>, <em>28</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s10732-021-09488-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Roads intersections are one of the main causes of traffic jams since vehicles need to stop and wait for their time to go. Scenarios that only consider autonomous vehicles can minimize this problem using intelligent systems that manage the time when each vehicle will pass across the intersection. This paper proposes a mathematical model and a heuristic that optimize this management. The efficiency of this approach is demonstrated using traffic simulations, with scenarios of different complexities, and metrics representing the arrival time, $$\hbox {CO}_{{2}}$$ emission and fuel consumption. The results show that the present approach is scalable, maintaining its performance even in complex real scenarios. Moreover, its execution time is maintained in milliseconds, what suggests this approach as a candidate for dealing with real-time and dynamic scenarios.},
  archive      = {J_JOH},
  author       = {Silva, Victor and Siebra, Clauirton and Subramanian, Anand},
  doi          = {10.1007/s10732-021-09488-8},
  journal      = {Journal of Heuristics},
  month        = {2},
  number       = {1},
  pages        = {1-21},
  shortjournal = {J. Heuristics},
  title        = {Intersections management for autonomous vehicles: A heuristic approach},
  volume       = {28},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
