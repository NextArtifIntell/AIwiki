<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NCA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="nca---1200">NCA - 1200</h2>
<ul>
<li><details>
<summary>
(2022). Multi-domain fusion deep graph convolution neural network
for EEG emotion recognition. <em>NCA</em>, <em>34</em>(24), 22241–22255.
(<a href="https://doi.org/10.1007/s00521-022-07643-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG)-based emotion recognition has become a hot research field, with the most attention given to decoding three basic types of emotional states (i.e., positive, negative, and neutral) by EEG. Traditional EEG emotion recognition is a single feature input mode that cannot cover multiple feature information. For brain function networks, the feature extraction process is very cumbersome. There will also be individual differences in the characteristics of different subjects. Therefore, the theory of graph convolution and brain function connection is introduced into this research, and the multi-domain fusion features input deep graph convolution neural network (MdGCNN) is proposed in this paper. Pearson correlation is used to determine the adjacency matrix. The Sortpooling layer is employed as a bridge between the graph convolution neural layer and the normal neural network layer and sorts the node features in a consistent order. Based on analyzing the characteristics of a single electrode, the brain topology structure features are automatically extracted. Taking MdGCNN as the basic model and considering the method of minimizing the feature distance between the source and the target domain, we propose a transfer learning (TL) emotion recognition model for cross-subject called MdGCNN-TL. Meanwhile, MdGCNN-TL is extended to traverse the target domain of a single subject in a two-to-one domain form. According to the idea of principal component analysis, the transfer model with a high recognition effect is determined with the degree of subject correlation (SC), and MdGCNN-TL is upgraded to MdGCNN-TL-SC. Experimental analysis on the SEED dataset is performed to evaluate the proposed models. Further validation of the model is implemented on the DEAP dataset. The results show that the proposed model has achieved better performance in EEG emotion recognition.},
  archive      = {J_NCA},
  author       = {Bi, Jinying and Wang, Fei and Yan, Xin and Ping, Jingyu and Wen, Yongzhao},
  doi          = {10.1007/s00521-022-07643-1},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {22241-22255},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-domain fusion deep graph convolution neural network for EEG emotion recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). SiamOA: Siamese offset-aware object tracking. <em>NCA</em>,
<em>34</em>(24), 22223–22239. (<a
href="https://doi.org/10.1007/s00521-022-07684-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object tracking task can be divided into two subtasks: classification and regression. Some state-of-the-art methods utilize classification score and quality estimation score to select proposal box. However, their classification branches and quality estimation branches are inconsistent in the training stage and the inference stage. Besides, the existing anchor-based regression relies on a lot of prior knowledge, which aggravates the burden of trackers. To alleviate these problems, we propose a simple and effective Siamese offset-aware object tracking (SiamOA) method. More specifically, we firstly propose a IoU-guided classification branch which unifies original classification branch and regression quality estimation branch and use intersection over union (IoU) to guide three classification branches to eliminate the inconsistency between training and inference. We secondly propose a more accurate offset-aware regression branch, by coarsely estimating the interval into which the bounding box edge offsets fall, and accurately predicting the displacements of the offsets within this interval. To optimize the classification and regression branches in an end-to-end manner, we thirdly propose a joint classification and regression alternative refining strategy to introduce the information exchange between them. We conduct extensive experiments on some challenging benchmarks like VOT2016, VOT2018, OTB100, UAV123, GOT-10 k, and results show the excellent performance of our SiamOA.},
  archive      = {J_NCA},
  author       = {Zhang, Jianming and Xie, Xianding and Zheng, Zhuofan and Kuang, Li-Dan and Zhang, Yudong},
  doi          = {10.1007/s00521-022-07684-6},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {22223-22239},
  shortjournal = {Neural Comput. Appl.},
  title        = {SiamOA: Siamese offset-aware object tracking},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). OGT: Optimize graph then training GNNs for node
classification. <em>NCA</em>, <em>34</em>(24), 22209–22222. (<a
href="https://doi.org/10.1007/s00521-022-07677-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have shown excellent performance in graph-related tasks and have arisen widespread attention. However, most existing works on GNNs mainly focus on proposing a novel GNN model or modifying the models to improve performance in various graph-related tasks and seldom consider possible problems in the graph data as model input data. This paper studies that low-degree nodes, accounting for most of the real-world graphs, naturally have message passing insufficiency problem due to too little information from other nodes when generating node embedding, which will affect the performance of the GNNs. To solve this problem, we propose a simple but practical method-Optimize Graph Then Training (OGT), which adds edges between low-degree nodes and some nodes with the same predicted label based on the GNNs prediction results and the inherent information in the graph. The OGT aims to improve the performance of GNNs in semi-supervised node classification tasks by augmenting the input data. More importantly, the OGT is regarded as a data preprocessing technique and can be used naturally with baseline GNN models (e.g., GCN, GAT, GraphSAGE, and SGC) to improve the performance of these models without making other modifications. Extensive experiments on three benchmark citation datasets with five typical GNN models verify that OGT consistently improves the performance of various GNNs to a great extent, where 1.9\% (Cora), 1.0\% (Citeseer), and 1.3\% (Pubmed) average accuracy improvement on the node classification task.},
  archive      = {J_NCA},
  author       = {Wei, Quanmin and Wang, Jinyan and Hu, Jun and Li, Xianxian and Yi, Tong},
  doi          = {10.1007/s00521-022-07677-5},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {22209-22222},
  shortjournal = {Neural Comput. Appl.},
  title        = {OGT: Optimize graph then training GNNs for node classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Individual tree crown delineation in high-resolution remote
sensing images based on u-net. <em>NCA</em>, <em>34</em>(24),
22197–22207. (<a
href="https://doi.org/10.1007/s00521-022-07640-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a deep learning-based framework for individual tree crown delineation in aerial and satellite images. This is an important task, e.g., for forest yield or carbon stock estimation. In contrast to earlier work, the presented method creates irregular polygons instead of bounding boxes and also provides a tree cover mask for areas that are not separable. Furthermore, it is trainable with low amounts of training data and does not need 3D height information from, e.g., laser sensors. We tested the approach in two scenarios: (1) with 30 cm WorldView-3 satellite imagery from an urban region in Bengaluru, India, and (2) with 5 cm aerial imagery of a densely forested area near Gartow, Germany. The intersection over union between the reference and predicted tree cover mask is 71.2\% for the satellite imagery and 81.9\% for the aerial images. On the polygon level, the method reaches an accuracy of 46.3\% and a recall of 63.7\% in the satellite images and an accuracy of 52\% and recall of 66.2\% in the aerial images, which is comparable to previous works that only predicted bounding boxes. Depending on the image resolution, limitations to separate individual tree crowns occur in situations where trees are hardly separable even for human image interpreters (e.g., homogeneous canopies, very small trees). The results indicate that the presented approach can efficiently delineate individual tree crowns in high-resolution optical images. Given the high availability of such imagery, the framework provides a powerful tool for tree monitoring. The source code and pretrained weights are publicly available at https://github.com/AWF-GAUG/TreeCrownDelineation .},
  archive      = {J_NCA},
  author       = {Freudenberg, Maximilian and Magdon, Paul and Nölke, Nils},
  doi          = {10.1007/s00521-022-07640-4},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {22197-22207},
  shortjournal = {Neural Comput. Appl.},
  title        = {Individual tree crown delineation in high-resolution remote sensing images based on U-net},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transfer precipitation learning via patterns of dependency
matrix-based machine learning approaches. <em>NCA</em>, <em>34</em>(24),
22177–22196. (<a
href="https://doi.org/10.1007/s00521-022-07674-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate precipitation prediction is very significant for urban, environmental, and water resources management as well as mitigating the negative effects of drought and flood. However, precipitation prediction is a complex and challenging task which involves meteorological parameters that contain uncertainty. This study attempts to ease the complexity of the problem via proposing a correlation matrix approach. Covariance and correlation matrices are analytical tools that are widely used to identify the interrelationships and possible dependencies throughout the data. Correlation matrices have some advantages over covariance matrices. The main drawback of covariance matrices is their sensitivity to the measurement units of variables. The variables with relatively large variances will dominate the results of multivariate analysis when the covariance matrix is used. Accordingly, the covariance matrix fails to provide useful information when there exist large differences between variances of variables. On the other hand, besides their easy interpretable features, the results of different analyses obtained from correlation matrices can effectively be compared. Therefore, in this study, in order to improve the performances of the predictive models, interrelationships and possible dependencies among data obtained from eighteen precipitation observation stations located in the Upper Euphrates Basin of Turkey (1980–2010) is investigated using correlation matrix approach. Relatedly, dependencies between the stations are resolved by means of examining the correlation matrix and optimal model inputs (data of particular stations) are selected for each prediction scenario. The transfer precipitation learning was performed throughout the period from 1980 to 2010 for eighteen precipitation observation stations located in the Upper Euphrates. Three different data-driven models Fuzzy, K-nearest neighbors (KNN), and multilinear regression (MR) are developed based on the patterns of correlation matrix. Predictive powers of the models are compared by means of performance evaluation criteria, i.e., Nash–Sutcliffe efficiency, mean square error, mean absolute error, and coefficient of determination (R2). Results of this study show that all developed correlation matrix patterns-based Fuzzy, KNN, and MR models have high precipitation prediction performance. However, even though all model results are close to each other, Fuzzy model provided more accurate results with requiring data from a relatively low number of stations. Therefore, patterns of correlation matrix-based Fuzzy model is the most efficient and well-suited approach for precipitation prediction among all the developed models.},
  archive      = {J_NCA},
  author       = {Altunkaynak, Abdüsselam and Küllahcı, Kübra},
  doi          = {10.1007/s00521-022-07674-8},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {22177-22196},
  shortjournal = {Neural Comput. Appl.},
  title        = {Transfer precipitation learning via patterns of dependency matrix-based machine learning approaches},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel multi-objective optimization model for sustainable
supply chain network design problem in closed-loop supply chains.
<em>NCA</em>, <em>34</em>(24), 22157–22175. (<a
href="https://doi.org/10.1007/s00521-022-07668-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing and modeling a supply chain network are the important steps in determining the costs and time associated with bringing goods to market by evaluating alternate scenarios in light of available resources and locations in the chain. In closed-loop supply chains, the network is extended to include backward chain members and thereby sustainable supply chains are achieved. A network that is optimized can reduce carbon footprint, assist with meeting sustainability goals, improve delivery quality, and ultimately result in an improved customer experience, added value, and differentiation. In this study, a closed-loop supply chain network model is considered to simultaneously optimize the three dimensions of sustainability: economical, environmental, and social. The proposed model is developed using a goal programming technique in supply chain processes with the aim of minimizing costs and environmental damage and maximizing the social benefit. The developed model is integrated with the decision variables regarding the number of workers so as to increase employment, especially regarding the social effects of sustainability. A new model is obtained by weighting the three main dimensions of sustainability with the fuzzy analytic hierarchy process technique. A scenario analysis is conducted to show the impact of the parameters such as capacity, demand, costs, and carbon emissions. According to the scenario analysis results, the parameter having the greatest impact on the decision variables is demand; moreover, where there is an increase of 30\% in demand, it has been determined that there is an increase of more than 100\% in the number of workers and purchasing costs compared to the base case scenario. In addition, the increase in demand naturally increases transportation costs more than 50\% as well.},
  archive      = {J_NCA},
  author       = {Salçuk, Kafiye and Şahin, Cenk},
  doi          = {10.1007/s00521-022-07668-6},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {22157-22175},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel multi-objective optimization model for sustainable supply chain network design problem in closed-loop supply chains},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CTSC-net: An effectual CT slice classification network to
categorize organ and non-organ slices from a 3-d CT image. <em>NCA</em>,
<em>34</em>(24), 22141–22156. (<a
href="https://doi.org/10.1007/s00521-022-07701-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computed tomography (CT) is a non-invasive diagnostic imaging modality that reveals more insight into human organs than conventional X-rays. In general, the CT output is a 3-D image that is formed by combining multiple 2D images or slices together. It is essential to keep in mind that not all of the slices provide significant information to detect tumours. Usually, a 3-D CT image obtained from the CT scanners has a significant number of unwanted non-organ slices in it. Radiologists typically devote a significant amount of time to select the slices with organ from a 3-D CT image. The presence of a tumour is only evident in the organ slice; hence, radiologists must be cautious not to skip any organ slices. This work is evaluated on the LITS, 3DIRCADb and COVID-19 CT datasets. The three datasets collectively contain 22,435 organ slices and 53,661 non-organ slices, and there is a huge gap between the number of organ and non-organ slices. There is a need for the automatic elimination of non-organ slices in 3-D CT volumes to assist the physicians, and hence, this work focuses on the automatic recognition of organ slices from 3-D CT volumes. In this paper, a new deep model called the computed tomography slice classification network (CTSC-Net) is proposed for CT slice classification between organ and non-organ slices. The model is trained on 77,980 CT slices, validated on 9748 slices and tested on 12,571 slices. Nine CNN architectures with different layer settings are trained and tested to arrive at the final optimal model. The performance measures are computed in terms of true positive rate, true negative rate, sensitivity, specificity and accuracy. The 20-layer CTSC-Net achieves a validation accuracy of 95.04\% and an overall testing accuracy of 99.96\%. The proposed model is compared to eight different pre-trained CNN models, and the results of the proposed CTSC-Net surpassed all the comparable models. The activation feature maps of different layers of the CTSC-Net are visualized to verify the discriminative features learned by the network. Hence, the proposed CTSC-Net can be employed as a computer-aided diagnosis tool to help physicians discard unnecessary non-organ slices from the 3-D CT volume and to speed up the CT diagnosis process.},
  archive      = {J_NCA},
  author       = {Nithiyaraj, Emerson and Selvaraj, Arivazhagan},
  doi          = {10.1007/s00521-022-07701-8},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {22141-22156},
  shortjournal = {Neural Comput. Appl.},
  title        = {CTSC-net: An effectual CT slice classification network to categorize organ and non-organ slices from a 3-D CT image},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On multi-objective covering salesman problem. <em>NCA</em>,
<em>34</em>(24), 22127–22140. (<a
href="https://doi.org/10.1007/s00521-022-07683-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the Covering Salesman Problems (CSPs) addressed in the literature are considered full coverage. However, in real-life emergency situations like earthquake, flood, endemic and rural health care supply chain, full coverage of the cities may not always be possible due to various reasons like insufficient supply, limited time frame, insufficient manpower and damage of routes. In this study, we formulate a multi-objective CSP (MOCSP) restricting the number of nodes visited in a tour within a given range, so that a given percentage of nodes is at least covered. The objectives are maximization of coverage and minimization of tour length. Due to conflicting nature of the objectives, the problem is posed as a multi-objective optimization problem (MOOP). To solve the problem, the metaheuristic Non-dominated Sorting Genetic Algorithm-II (NSGA-II) is used with some modifications. The chromosome is designed to represent a tour with number of visited nodes within a given range. For the purpose of implementation, a one-dimensional array of variable length is used. New crossover and mutation operators are designed which are suitable for the problem and the corresponding chromosome representation. For simulation purpose, 19 benchmark test problems of Traveling Salesman Problem (TSP) from TSPLIB (Reinelt in ORSA J Comp 3:376–384) are used, where the number of nodes (i.e., cities) varies between 52 and 818. For each test problem, 12 instances are generated taking different values of problem parameters. Then, the set of optimal solutions are obtained for each instance, and the results are analyzed. A comparison of results for six test problems shows that our algorithm produces the best-known solutions for small and medium sized problems. However, for large sized problems, our algorithm produces better quality solutions in some cases only.},
  archive      = {J_NCA},
  author       = {Biswas, Amiya and Tripathy, Siba Prasada and Pal, Tandra},
  doi          = {10.1007/s00521-022-07683-7},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {22127-22140},
  shortjournal = {Neural Comput. Appl.},
  title        = {On multi-objective covering salesman problem},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting the performance of constant volume depletion
tests for gas condensate reservoirs using artificial intelligence
techniques. <em>NCA</em>, <em>34</em>(24), 22115–22125. (<a
href="https://doi.org/10.1007/s00521-022-07682-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of gas condensate reservoirs relies strongly on the accuracy of pressure–volume–temperature (PVT) data. The produced volumes of gases and liquids can be predicted, under different conditions, using PVT relationships. Also, the design of surface facilities such as storage tanks and fluids separators requires detailed information about the PVT behaviors. However, measuring the PVT properties is costly and time-consuming. Therefore, this work presents a quick and reliable approach to evaluating the PVT properties for gas condensate reservoirs using artificial intelligence techniques. Constant volume depletion (CVD) data were collected from different wells. More than 1000 data sets were collected from 68 wells that cover wide ranges of fluid compositions and reservoir conditions. The collected data contain mole fractions of gas condensate components, pressure relative volume, and reservoir temperature. First, data cleaning was performed to remove the outliers utilizing the standard deviations technique. Thereafter, artificial neural network (ANN), adaptive neuro-fuzzy inference system (ANFIS), and support vector machines (SVM) were used to develop new models to predict the performance of CVD tests. Different evaluation indexes were used to assess the reliability of the developed models; root–mean–square error and correlation coefficient (R2) were used. The obtained results showed that ANN model outperforms ANFIS and SVM techniques in predicting the PVT behavior. The values of coefficient of determinations are 0.995, 0.959, and 0.948 for the testing data using ANN, ANFIS, and SVM models, respectively. The root-mean-square error was reduced from around 1.20 to less than 0.5 using the ANN model, for the testing data set. Additionally, a new correlation was developed using the ANN technique to predict the CVD performance. The new correlation showed a very acceptable accuracy and less estimation errors compared to the available models. Ultimately, this work introduces a new approach to saving time and effort in determining the PVT behavior. A new correlation is presented to provide a direct and simple approach for estimating CVD performance.},
  archive      = {J_NCA},
  author       = {Ahmed, M. Elmuzafar and Sultan, Abdullah S. and Hassan, Amjed and Abdulraheem, Abdulazeez and Mahmoud, Mohamed},
  doi          = {10.1007/s00521-022-07682-8},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {22115-22125},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting the performance of constant volume depletion tests for gas condensate reservoirs using artificial intelligence techniques},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning framework for detecting and localizing
abnormal pedestrian behaviors at grade crossings. <em>NCA</em>,
<em>34</em>(24), 22099–22113. (<a
href="https://doi.org/10.1007/s00521-022-07660-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a deep learning-based framework to detect and localize the pedestrians’ anomaly behaviors in videos captured at the grade crossing. A skeleton detection and tracking algorithm are employed to capture the key point trajectories of body movements of the pedestrians. A deep recurrent neural network is applied to learn the normal patterns of pedestrians’ movements using dynamics skeleton trajectories features. An anomaly behaviors detection and localization algorithm are developed by analyzing each pedestrian’s reconstructed trajectories. In the experiments, a video dataset involving normal pedestrian behaviors is established by collecting data at multiple grade crossing spots with different camera angles. Then the proposed framework is trained on the dataset to learn the regularity patterns of normal pedestrians and localize the anomaly behaviors during the testing phase. To the best of our knowledge, it is the first attempt to analyze pedestrians’ behavior at a grade crossing. The experimental results show that the proposed framework can detect and localize the anomaly behaviors, such as squatting down, lingering, and other behaviors that may cause safety issues at the grade crossing. Our study also points out the direction for further improvement of the present development to meet the need for real-world applications.},
  archive      = {J_NCA},
  author       = {Jiang, Zhuocheng and Song, Ge and Qian, Yu and Wang, Yi},
  doi          = {10.1007/s00521-022-07660-0},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {22099-22113},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning framework for detecting and localizing abnormal pedestrian behaviors at grade crossings},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assessing the correlation between the sustainable energy for
all with doing a business by artificial neural network. <em>NCA</em>,
<em>34</em>(24), 22087–22097. (<a
href="https://doi.org/10.1007/s00521-022-07638-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial intelligence-based solutions have become widespread in various fields and have been observed to produce important solutions to critical problems. In this context, it is aimed to assess and establish a direct correlation between energy production/consumption and establishing sustainable business models by using artificial intelligence models. Thus, artificial intelligence-based models have been developed by using parameters related to global energy consumption, doing business, and critical concepts of the relevant topics. The results show that the proposed artificial intelligent-based models reveal a significant correlation between doing business and energy. The outcome of the study could be used in the determination of country strategies in critical areas such as transportation, infrastructure, and education in the near and far future.},
  archive      = {J_NCA},
  author       = {Demir, İdris},
  doi          = {10.1007/s00521-022-07638-y},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {22087-22097},
  shortjournal = {Neural Comput. Appl.},
  title        = {Assessing the correlation between the sustainable energy for all with doing a business by artificial neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CNN-LSTM and clustering-based spatial–temporal demand
forecasting for on-demand ride services. <em>NCA</em>, <em>34</em>(24),
22071–22086. (<a
href="https://doi.org/10.1007/s00521-022-07681-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Passenger demand forecasting is of great importance to the on-demand ride systems. With the accurate forecasting of demand, it can be determined from which regions and when the passengers demand a vehicle. In this way, passenger and vehicle waiting times, fuel costs of vehicles can be reduced. In the literature, various models such as time series, long short-term memory (LSTM), convolutional neural network (CNN), and hybrid of CNN-LSTM are used for demand forecasting in on-demand ride service systems. These models forecast demands by considering temporal and spatial data separately or together. In models that use spatial and spatial–temporal data, generally, the city is divided into zones in the form of a grid. This partitioning method has some disadvantages, such as misleading the forecasting accuracy by considering regions without demand and ignoring the geographical conditions. In this study, two new models, ConvLSTM2D-clustering and CNN-LSTM-clustering are proposed to overcome these disadvantages and make more accurate and robust forecasts. The proposed models use clustering instead of grid partitioning in dividing the city into zones and take time-of-day, time-of-week variables into account in forecasting as well as passenger demand. The presented models have been used in the passenger demand forecasting of Turkcell Technology Company, which provides on-demand ride services for its employees in Istanbul, Turkey. Experimental results, validated on real-world data provided by Turkcell, show that the proposed models partition the city more effectively and achieve 14–55\% better short- and long-term forecasting performances than the compared models in terms of mean squared error.},
  archive      = {J_NCA},
  author       = {Ay, Merhad and Kulluk, Sinem and Özbakır, Lale and Gülmez, Burak and Öztürk, Güney and Özer, Sertay},
  doi          = {10.1007/s00521-022-07681-9},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {22071-22086},
  shortjournal = {Neural Comput. Appl.},
  title        = {CNN-LSTM and clustering-based spatial–temporal demand forecasting for on-demand ride services},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Industrial data classification using stochastic
configuration networks with self-attention learning features.
<em>NCA</em>, <em>34</em>(24), 22047–22069. (<a
href="https://doi.org/10.1007/s00521-022-07657-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial data contain a lot of noisy information, which cannot be well suppressed in deep learning models. The current industrial data classification models are problematic in terms of feature incompleteness and inadequate self-adaptability, insufficient capacity for approximation of classifier and weak robustness. To this end, this paper proposes an intelligent classification method based on self-attention learning features and stochastic configuration networks (SCNs). This method imitates human cognitive mode to regulate feedback so as to achieve ensemble learning. In particular, firstly, at the feature extraction stage, a fused deep neural network model based on self-attention is constructed. It adopts a self-attention long short-term memory (LSTM) network and self-attention residual network with adaptive hierarchies and extracts the fault global temporal features and local spatial features of the industrial time-series dataset after noise suppression, respectively. Secondly, at the classifier design stage, the fused complete feature vectors are sent to SCNs with universal approximation capability to establish general classification criteria. Then, based on generalized error and entropy theory, the performance indexes for real-time evaluation of credibility of uncertainty classified results are established, and the adaptive adjustment mechanism of self-attention fusion networks for the network hierarchy is built to realize the self-optimization of multi-hierarchy complete features and their classification criteria. Finally, fuzzy integral is used to integrate the classified results of self-attention fusion network models with different hierarchies to improve the robustness of the classification model. Compared with other classification models, the proposed model performs better using rolling bearing fault dataset.},
  archive      = {J_NCA},
  author       = {Li, Weitao and Deng, Yali and Ding, Meishuang and Wang, Dianhui and Sun, Wei and Li, Qiyue},
  doi          = {10.1007/s00521-022-07657-9},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {22047-22069},
  shortjournal = {Neural Comput. Appl.},
  title        = {Industrial data classification using stochastic configuration networks with self-attention learning features},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CADNet157 model: Fine-tuned ResNet152 model for breast
cancer diagnosis from mammography images. <em>NCA</em>, <em>34</em>(24),
22023–22046. (<a
href="https://doi.org/10.1007/s00521-022-07648-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The risk of death incurred by breast cancer is rising exponentially, especially among women. This made the early breast cancer detection a crucial problem. In this paper, we propose a computer-aided diagnosis (CAD) system, called CADNet157, for mammography breast cancer based on transfer learning and fine-tuning of well-known deep learning models. Firstly, we applied hand-crafted features-based learning model using four extractors (local binary pattern, gray-level co-occurrence matrix, and Gabor) with four selected machine learning classifiers (K-nearest neighbors, support vector machine, random forests, and artificial neural networks). Then, we performed some modifications on the Basic CNN model and fine-tuned three pre-trained deep learning models: VGGNet16, InceptionResNetV2, and ResNet152. Finally, we conducted a set of experiments using two benchmark datasets: Digital Database for Screening Mammography (DDSM) and INbreast. The results of the conducted experiments showed that for the hand-crafted features based CAD system, we achieved an area under the ROC curve (AUC) of 95.28\% for DDSM using random forest and 98.10\% for INbreast using support vector machine with the histogram of oriented gradients extractor. On the other hand, CADNet157 model (i.e., fine-tuned ResNet152) was the best performing deep model with an AUC of 98.90\% (sensitivity: 97.72\%, specificity: 100\%), and 98.10\% (sensitivity: 100\%, specificity: 96.15\%) for, respectively, DDSM and INbreast. The CADNet157 model overcomes the limitations of traditional CAD systems by providing an early detection of breast cancer and reducing the risk of false diagnosis.},
  archive      = {J_NCA},
  author       = {Mokni, Raouia and Haoues, Mariem},
  doi          = {10.1007/s00521-022-07648-w},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {22023-22046},
  shortjournal = {Neural Comput. Appl.},
  title        = {CADNet157 model: Fine-tuned ResNet152 model for breast cancer diagnosis from mammography images},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assessing vascular complexity of PAOD patients by deep
learning-based segmentation and fractal dimension. <em>NCA</em>,
<em>34</em>(24), 22015–22022. (<a
href="https://doi.org/10.1007/s00521-022-07642-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assessment of vascular complexity in the lower limbs provides relevant information about peripheral artery occlusive diseases (PAOD), thus fostering improvements both in therapeutic decisions and prognostic estimation. The current clinical practice consists of visually inspecting and evaluating cine-angiograms of the interested region, which is largely operator-dependent. We present here an automatic method for segmenting the vessel tree and compute a quantitative measure, in terms of fractal dimension (FD), of the vascular complexity. The proposed workflow consists of three main steps: (i) conversion of the cine-angiographies to single static images with a broader field of view, (ii) automatic segmentation of the vascular trees, and (iii) calculation and assessment of FD as complexity index. In particular, this work defines (1) a method to reduce the inter-observer variability in judging vascular complexity in cine-angiography images from patients affected by peripheral artery occlusive disease (PAOD), and (2) the use of Fractal Dimension as a metric of shape complexity of vascular tree. The inter-class correlation coefficient (ICC) is computed as inter-observer agreement metric and to account for possible systematic error, that depends on the experience of the raters. The automatic segmentation of vascular tree achieved an Area Under the Curve mean value of $$0.77~\pm ~0.07$$ , with a min-max range of $$0.57-0.87$$ . Absolute operator agreement was higher over the segmented image ( $$ICC=0.96$$ ) compared to the video ( $$ICC=0.76$$ ) and the a broader field of view image ( $$ICC=0.92$$ ). Fractal Dimension computed on both manual segmented images (ground truths) and automatically showed a good correlation with the clinical score (0.85 and 0.75, respectively). Experimental analyses suggest that extracting the vascular tree from cine-angiography can substantially improve the reliability of visual assessment of vascular complexity in PAOD. Results also reveal the effectiveness of FD in evaluating complex vascular tree structures.},
  archive      = {J_NCA},
  author       = {Bruno, Pierangela and Spadea, Maria Francesca and Scaramuzzino, Salvatore and De Rosa, Salvatore and Indolfi, Ciro and Gargiulo, Giuseppe and Giugliano, Giuseppe and Esposito, Giovanni and Calimeri, Francesco and Zaffino, Paolo},
  doi          = {10.1007/s00521-022-07642-2},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {22015-22022},
  shortjournal = {Neural Comput. Appl.},
  title        = {Assessing vascular complexity of PAOD patients by deep learning-based segmentation and fractal dimension},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CSA-CDGAN: Channel self-attention-based generative
adversarial network for change detection of remote sensing images.
<em>NCA</em>, <em>34</em>(24), 21999–22013. (<a
href="https://doi.org/10.1007/s00521-022-07637-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing images change detection (RSICD) is a task to identify desired significant differences between multi-temporal images acquired at different times. From the existing methods, most of them solved this issue with a Siamese network, focusing on how to utilize the comparison between two image features to generate an initial difference map. However, Siamese network-based methods have three drawbacks: (1) complex architecture; (2) rough change map; (3) cumbersome detecting procedure: including feature extraction and feature comparison. To overcome the above drawbacks, we devoted our work to design a general framework which has a simple architecture, integrated detecting procedure, and good capacity of detecting subtle changes. In this paper, we proposed a channel self-attention network based on the generative adversarial network for change detection of remote sensing images. The network used an encoder–decoder network to directly produce a change map from two input images. It was better to detect small punctate and slim linear changes than Siamese-based networks. By regarding RSICD as an image translation problem, we used a Generative Adversarial Network to detect changes. In addition, a channel self-attention module was proposed to further improve the performance of this network. Experimental results on three public remote sensing RGB-image datasets, including change detection dataset, Wuhan University building change detection dataset and LEVIR building Change Detection dataset demonstrated that our method outperformed other state-of-the-art methods. In terms of the F1 score, the proposed method achieved maximum improvements of 5.1\%, 3.1\%, and 1.7\% on the above datasets, respectively. Models and codes will be available at https://github.com/wangle53/CSA-CDGAN .},
  archive      = {J_NCA},
  author       = {Wang, Zhixue and Zhang, Yu and Luo, Lin and Wang, Nan},
  doi          = {10.1007/s00521-022-07637-z},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21999-22013},
  shortjournal = {Neural Comput. Appl.},
  title        = {CSA-CDGAN: Channel self-attention-based generative adversarial network for change detection of remote sensing images},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection and tracking of chickens in low-light images using
YOLO network and kalman filter. <em>NCA</em>, <em>34</em>(24),
21987–21997. (<a
href="https://doi.org/10.1007/s00521-022-07664-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous monitoring of chickens’ movement on-farm is a challenge. The present study aimed to associate the modified YOLO v4 model with a bird tracking algorithm based on a Kalman filter to identify a chicken’s movement using low-resolution video. The videos were captured in grayscale using a top-view camera with a low resolution of 702 × 480 pixels, preventing the application of usual image processing techniques. We used YOLO to extract the characteristics of the image and classification automatically. A dataset with images of tagged chickens was used to detect chickens, being 1000 frames tagged in different videos. The generated model was applied in a video that returned the bounding box of the location of the chicken in the frame. With the limits of the box, the centroid was calculated and exported in a CSV file for tracking processing. The Kalman filter was implemented to track chickens in low light intensity. Results indicated that YOLO presented a 99.9\% accuracy in detecting chickens in low-quality videos. Using the Kalman filter, the algorithm tracks the chickens and gives them a particular identification number until they leave the compartment. Furthermore, each moving chicken is located in different colors along with the maps below the image, making chicken detection more convenient. The tracking results of chickens show that the proposed method can correctly handle the new entry and exit moving targets in crowded conditions.},
  archive      = {J_NCA},
  author       = {Siriani, Allan Lincoln Rodrigues and Kodaira, Vanessa and Mehdizadeh, Saman Abdanan and de Alencar Nääs, Irenilza and de Moura, Daniella Jorge and Pereira, Danilo Florentino},
  doi          = {10.1007/s00521-022-07664-w},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21987-21997},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection and tracking of chickens in low-light images using YOLO network and kalman filter},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Context-awareness trust management model for trustworthy
communications in the social internet of things. <em>NCA</em>,
<em>34</em>(24), 21961–21986. (<a
href="https://doi.org/10.1007/s00521-022-07656-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The social Internet of Things (SIoT) is the next generation of the Internet of Things network. It entails the evolution of intelligent devices into social ones, aiming at building interactions with people in order to link groups and develop their own social context. Because a high volume of data is shared throughout the network’s diverse nodes, security measures are essential to ensure that users may interact safely. Trust management (TM) models have been presented in the literature to avoid detrimental interactions and preserve a system’s optimal functioning. In reality, given the SIoT context of nodes varies over time, a TM mechanism must contain methods for evaluating the level of trustworthiness. Existing methods, on the other hand, continue to lack effective solutions for addressing contextual SIoT attributes that define the network node while assessing trust. The utmost objective of this paper is to perform an in-depth analysis of contextual trust-awareness based on the defined TM model “CTM-SIoT” in order to more precisely detect malicious SIoT nodes to maintain safe network connections. As part of our trust evaluation process, machine learning techniques are employed to study the behavior of nodes. Our objective is to limit contacts with aggressive and unskilled service providers. Experimentation was carried out using the Cooja simulator on a simulated SIoT dataset based on real social data. With an F-measure value of up to 1, we validated the Artificial Neural Network’s suitability as a classifier for our issue statement. When compared to other conventional trust classification methods, the findings demonstrated that handling contextual SIoT characteristics inside our TM model enhanced the performance of a TM mechanism with a 0.037\% rise in F-measure and a 0.13\% drop in FPR, in identifying malicious nodes even for a system with 50\% of malicious transactions.},
  archive      = {J_NCA},
  author       = {Magdich, Rim and Jemal, Hanen and Ben Ayed, Mounir},
  doi          = {10.1007/s00521-022-07656-w},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21961-21986},
  shortjournal = {Neural Comput. Appl.},
  title        = {Context-awareness trust management model for trustworthy communications in the social internet of things},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Kernel-based similarity sorting and allocation for few-shot
semantic segmentation. <em>NCA</em>, <em>34</em>(24), 21939–21960. (<a
href="https://doi.org/10.1007/s00521-022-07654-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot semantic segmentation tackles the problem of recognizing novel class objects from images with only a few annotated exemplars. The key problem in few-shot semantic segmentation is how to effectively model the correspondences between support and query features. Previous works propose to tackle the problem by prototype matching or distance based metric learning. In this work, we introduce a kernel-based similarity matching model, enforcing robust guidance from both foreground and background semantics. In addition, guidance sorting and allocation modules are presented to better explore the guidance from support set. Specifically, guidance sorting module calibrates the most similar semantic patterns on query maps for each support pixel and produces the index vectors. While the allocation module is able to select the most representative correspondences on similarity maps based on index vectors. To integrate the insights of kernel-based similarity features we define a pyramidal paradigm, which progressively integrates guidance signal, query features and mask priors. In this way, the relationships between support and query features are dynamically explored in both foreground and background semantics. Extensive qualitative and quantitative evaluations on PASCAL-5i, COCO-20i and FSS-1000 are conducted to prove the efficiency and advantage of our proposed method. Experimental results demonstrate that our method performs favorably against state-of-the-art methods with reasonable computational cost.},
  archive      = {J_NCA},
  author       = {Liu, Ze-yu and Liu, Jian-wei},
  doi          = {10.1007/s00521-022-07654-y},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21939-21960},
  shortjournal = {Neural Comput. Appl.},
  title        = {Kernel-based similarity sorting and allocation for few-shot semantic segmentation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic segmentation of COVID-19 from computed tomography
images using modified u-net model-based majority voting approach.
<em>NCA</em>, <em>34</em>(24), 21927–21938. (<a
href="https://doi.org/10.1007/s00521-022-07653-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coronavirus disease (COVID-19) is an important public health problem that has spread rapidly around the world and has caused the death of millions of people. Therefore, studies to determine the factors affecting the disease, to perform preventive actions and to find an effective treatment are at the forefront. In this study, a deep learning and segmentation-based approach is proposed for the detection of COVID-19 disease from computed tomography images. The proposed model was created by modifying the encoder part of the U-Net segmentation model. In the encoder part, VGG16, ResNet101, DenseNet121, InceptionV3 and EfficientNetB5 deep learning models were used, respectively. Then, the results obtained with each modified U-Net model were combined with the majority vote principle and a final result was reached. As a result of the experimental tests, the proposed model obtained 85.03\% Dice score, 89.13\% sensitivity and 99.38\% specificity on the COVID-19 segmentation test dataset. The results obtained in the study show that the proposed model will especially benefit clinicians in terms of time and cost.},
  archive      = {J_NCA},
  author       = {Uçar, Murat},
  doi          = {10.1007/s00521-022-07653-z},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21927-21938},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic segmentation of COVID-19 from computed tomography images using modified U-net model-based majority voting approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the forecasting of multivariate financial time series
using hybridization of DCC-GARCH model and multivariate ANNs.
<em>NCA</em>, <em>34</em>(24), 21911–21925. (<a
href="https://doi.org/10.1007/s00521-022-07631-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Volatility plays a crucial role in financial markets and accurate prediction of the stock price indices is of high interest. In multivariate time series, Dynamic Conditional Correlation (DCC)-Generalized Autoregressive Conditional Heteroscedastic (GARCH) is used to model and forecast the volatility (risk) and co-movement between stock prices data. We propose multivariate artificial neural networks (MANNs) hybridized with the DCC-GARCH model to forecast the volatility of stock prices and to examine the time-varying correlation. The daily share price data of five stock markets: S&amp;P 500 (USA), FTSE-100 (UK), KSE-100 (Pakistan), Malaysia (KLSE) and BSESN (India) covering the period from 1st, January 2013 to 17th, March 2020 are considered for empirical analysis. Moreover, the hybrid models of MANNs and DCC-GARCH are developed in two ways: (i) MANNs is provided as an input to DCC-GARCH (1,1) producing a hybrid model of DCC-GARCH(1,1)-MANNs and (ii) DCC-GARCH(1,1) model is set as an input to MANNs resulting hybrid model of MANNs-DCC-GARCH(1,1). Furthermore, the performances of the proposed models are compared with single models via the root mean square (RMSE), mean absolute error (MAE) and relative mean absolute error (RMAE). The empirical results show that DCC-GARCH (1,1)-MANNs, a parametric model, outperforms both in-sample and out-sample forecasts and helps to examine the time-varying correlation and also provides volatility forecast as well, whereas the hybrid model MANNs-DCC-GARCH (1,1) provides forecast only. Therefore, the hybrid model of DCC-GARCH (1,1)-MANNs is found suitable as compared to MANNs-DCC-GARCH(1,1) to model and forecast the stock price indices under consideration.},
  archive      = {J_NCA},
  author       = {Fatima, Samreen and Uddin, Mudassir},
  doi          = {10.1007/s00521-022-07631-5},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21911-21925},
  shortjournal = {Neural Comput. Appl.},
  title        = {On the forecasting of multivariate financial time series using hybridization of DCC-GARCH model and multivariate ANNs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial neural networks integrated mixed integer
mathematical model for multi-fleet heterogeneous time-dependent cash in
transit problem with time windows. <em>NCA</em>, <em>34</em>(24),
21891–21909. (<a
href="https://doi.org/10.1007/s00521-022-07659-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cash in transit (CIT) problem is a version of the vehicle routing problem (VRP), which deals with the planning of money distribution from the depot(s) to the automated teller machines (ATMs) safely and quickly. This study investigates a novel CIT problem, which is a variant of time-dependent VRP with time windows. To establish a more realistic approach to the time-dependent CIT problem, vehicle speed varying according to traffic density is considered. The problem is formulated as a mixed-integer mathematical model. Artificial neural networks (ANNs) are used to forecast the money demand for each ATM. For this purpose, key factors are defined, and a formulation is proposed to determine the money deposited to and withdrawn into ATMs. The mathematical model is run for different scenarios, and optimum routes are obtained.},
  archive      = {J_NCA},
  author       = {Ayyıldız, Ertuğrul and Taşkın, Alev and Yıldız, Aslıhan and Özkan, Coşkun},
  doi          = {10.1007/s00521-022-07659-7},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21891-21909},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial neural networks integrated mixed integer mathematical model for multi-fleet heterogeneous time-dependent cash in transit problem with time windows},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature space partition: A local–global approach for
classification. <em>NCA</em>, <em>34</em>(24), 21877–21890. (<a
href="https://doi.org/10.1007/s00521-022-07647-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a local–global classification scheme in which the feature space is, in a first phase, segmented by an unsupervised algorithm allowing, in a second phase, the application of distinct classification methods in each of the generated sub-regions. The proposed segmentation process intentionally produces difficult-to-classify and easy-to-classify sub-regions. Consequently, it is possible to outcome, besides of the classification labels, a measure of confidence for these labels. In almost homogeneous regions, one may be well-nigh sure of the classification result. The algorithm has a built-in stopping criterion to avoid over dividing the space, what would lead to overfitting. The Cauchy–Schwarz divergence is used as a measure of homogeneity in each partition. The proposed algorithm has shown very nice results when compared with 52 prototype selection algorithms. It also brings in the advantage of priory unveiling areas of the feature space where one should expect more (or less) difficult in classifying.},
  archive      = {J_NCA},
  author       = {Marcelino, C. G. and Pedreira, C. E.},
  doi          = {10.1007/s00521-022-07647-x},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21877-21890},
  shortjournal = {Neural Comput. Appl.},
  title        = {Feature space partition: A local–global approach for classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sliding space-disparity transformer for stereo matching.
<em>NCA</em>, <em>34</em>(24), 21863–21876. (<a
href="https://doi.org/10.1007/s00521-022-07621-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformers have achieved impressive performance in natural language processing and computer vision, including text translation, semantic segmentation, etc. However, due to excessive self-attention computation and memory occupation, the stereo matching task does not share its success. To promote this technology in stereo matching, especially with limited hardware resources, we propose a sliding space-disparity transformer named SSD-former. According to matching modeling, we simplify transformer for achieving faster speed, memory-friendly, and competitive performance. First, we employ the sliding window scheme to limit the self-attention operations in the cost volume for adapting to different resolutions, bringing efficiency and flexibility. Second, our space-disparity transformer remarkably reduces memory occupation and computation, only computing the current patch’s self-attention with two parts: (1) all patches of current disparity level at the whole spatial location and (2) the patches of different disparity levels at the exact spatial location. The experiments demonstrate that: (1) different from the standard transformer, SSD-former is faster and memory-friendly; (2) compared with 3D convolution methods, SSD-former has a larger receptive field and provides an impressive speed, showing great potential in stereo matching; and (3) our model obtains state-of-the-art performance and a faster speed on the multiple popular datasets, achieving the best speed–accuracy trade-off.},
  archive      = {J_NCA},
  author       = {Rao, Zhibo and He, Mingyi and Dai, Yuchao and Shen, Zhelun},
  doi          = {10.1007/s00521-022-07621-7},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21863-21876},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sliding space-disparity transformer for stereo matching},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SHAPE: A dataset for hand gesture recognition. <em>NCA</em>,
<em>34</em>(24), 21849–21862. (<a
href="https://doi.org/10.1007/s00521-022-07651-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand gestures are becoming an important part of the communication method between humans and machines in the era of fast-paced urbanization. This paper introduces a new standard dataset for hand gesture recognition, Static HAnd PosturE (SHAPE), with adequate side, variation, and practicality. Compared with the previous datasets, our dataset has more classes, subjects, or scenes than other datasets. In addition, the SHAPE dataset is also one of the first datasets to focus on Asian subjects with Asian hand gestures. The SHAPE dataset contains more than 34,000 images collected from 20 distinct subjects with different clothes and backgrounds. A recognition architecture is also presented to investigate the proposed dataset. The architecture consists of two phases that are the hand detection phase for preprocessing and the classification phase by customized state-of-the-art deep neural network models. This paper investigates not only the high accuracy, but also the lightweight hand gesture recognition models that are suitable for resource-constrained devices such as portable edge devices. The promising application of this study is to create a human–machine interface that solves the problem of insufficient space for a keyboard or a mouse in small devices. Our experiments showed that the proposed architecture could obtain high accuracy with the self-built dataset. Details of our dataset can be seen online at https://users.soict.hust.edu.vn/linhdt/dataset/},
  archive      = {J_NCA},
  author       = {Dang, Tuan Linh and Nguyen, Huu Thang and Dao, Duc Manh and Nguyen, Hoang Vu and Luong, Duc Long and Nguyen, Ba Tuan and Kim, Suntae and Monet, Nicolas},
  doi          = {10.1007/s00521-022-07651-1},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21849-21862},
  shortjournal = {Neural Comput. Appl.},
  title        = {SHAPE: A dataset for hand gesture recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive faster fixed-time trajectory tracking control for
manipulator. <em>NCA</em>, <em>34</em>(24), 21835–21847. (<a
href="https://doi.org/10.1007/s00521-022-07618-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes an adaptive nonsingular fixed-time controller to boost trajectory tracking precision and velocity for the manipulator system with lumped disturbance. First, while the system state is in the sliding phase, a fixed-time sliding mode (SM) surface is designed to improve tracking speed and accuracy. Secondly, an enhanced reaching law is designed by combining inverse trigonometric functions, which can reduce chattering while increasing the convergence velocity of the SM variables. Then, the adaptive law is developed to handle the upper bound of the unknown disturbance to overcome the difficulty of establishing the upper bound of the uncertain disturbance. It is demonstrated by the Lyapunov function theorem that the SM variables and tracking errors can reach a region near the zero point at a fixed time. As a result, by comparing the fixed-time controller presented in this work to other controllers, it is clear that the proposed fixed-time controller is better than other controllers.},
  archive      = {J_NCA},
  author       = {Zhang, Xin and Shi, Ran},
  doi          = {10.1007/s00521-022-07618-2},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21835-21847},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive faster fixed-time trajectory tracking control for manipulator},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep belief network for solving the image quality assessment
in full reference and no reference model. <em>NCA</em>, <em>34</em>(24),
21809–21833. (<a
href="https://doi.org/10.1007/s00521-022-07649-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image Quality Assessment (IQA) is one of the essential problems in image processing. The growth of natural image quality assessment methods has collected a large range of research achievements that are separated into three categories, such as Full Reference Image Quality Assessment (FR-IQA), and Reduced Reference Image Quality Assessment (RR-IQA), and No Reference Image Quality Assessment (NR-IQA). With the rapid growth of digital vision technology, the image quality estimation process quantifies the quality of an image that is used to transmit and acquire images. In this paper, we present a novel Lee Sigma Filterized Mathieu Feature Transformation-based Radial Kernel Deep Belief Network (LSFMFT-RKDBN) model that has been developed for estimating the image quality with and without a reference image. First, the proposed technique performs the quality estimation with full reference called LSFMFT-RKDBN-FR model work that is based on the layer-by-layer method. The visible layer of the Deep Belief Network (DBN) receives the test and reference images. Next, the input test and reference images are de-noised by applying the weighted Lee sigma filter. The de-noised images are partitioned into several patches for accurate feature extraction. Then, the Mathieu transformation is applied to obtain the test feature vector and reference feature vector. At the output layer, the radial basis kernel activation function is applied to analyze the feature vectors and display the estimated results. On the other hand, the proposed model is applied with no reference (LSFMFT-RKDBN-NR) to estimate the test image quality. The LSFMFT-RKDBN-NR model with image de-noising, patch extraction, and feature extraction is carried out to create a test feature vector. Finally, the estimated results are obtained at the output layer. We evaluate the proposed LSFMFT-RKDBN model on the CSIQ Image Quality dataset with qualitative and quantitative results analysis. The proposed LSFMFT-RKDBN model is used to estimate the image quality with higher accuracy and less time and memory consumption when compared to other related methods. The observed result shows the superior performance of the proposed LSFMFT-RKDBN model compared with the two state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Muthusamy, Dharmalingam and Sathyamoorthy, S.},
  doi          = {10.1007/s00521-022-07649-9},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21809-21833},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep belief network for solving the image quality assessment in full reference and no reference model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel rough set-based approach for minimum vertex cover of
hypergraphs. <em>NCA</em>, <em>34</em>(24), 21793–21808. (<a
href="https://doi.org/10.1007/s00521-022-07620-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimum vertex covering has been widely used and studied as a general optimization problem. We focus on one of its variation: minimum vertex cover of hypergraphs. Most existed algorithms are designed for general graphs, where each edge contains at most two vertices. Moreover, among these algorithms, rough set-based algorithms have been proposed recently and attract many researchers sight. However, they are not efficient enough when the number of nodes and hyperedges scale largely. To address these limitations, we propose a novel rough set-based approach by combining rough set theory with the stochastic local search algorithm. In this approach, three improvements have been introduced, i.e., (1) fast relative reduct construction method, which can quickly achieve a relative reduct, and it is based on low-complexity heuristics; (2) (p, q)-reverse incremental verification mechanism, which uses incremental positive region update technology to quickly verify whether a required attribute pair can be found; (3) adjusting iterative process rules, the main purposes of these rules are avoiding repeated computation and jumping out of local optimum. Finally, by comparing groups of benchmark graphs and hypergraphs with the existing algorithms based on rough sets, experimental results presents the advantages and limitations of our proposed approach.},
  archive      = {J_NCA},
  author       = {Zhou, Qian and Xie, Xiaojun and Dai, Hua and Meng, Weizhi},
  doi          = {10.1007/s00521-022-07620-8},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21793-21808},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel rough set-based approach for minimum vertex cover of hypergraphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An integrated spatiotemporal-based methodology for deepfake
detection. <em>NCA</em>, <em>34</em>(24), 21777–21791. (<a
href="https://doi.org/10.1007/s00521-022-07633-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid advances in deep learning models have made it easier for public and crackers to generate hyper-realistic deepfake videos in which faces are swapped. Such deepfake videos may constitute a significant threat to the world if they are misused to blackmail public figures and to deceive systems of face recognition. As a result, distinguishing these fake videos from real ones has become fundamental. This paper introduces a new deepfake video detection method. You Only Look Once (YOLO) face detector is used to detect faces from video frames. A proposed hybrid method based on proposing two different feature extraction methods is applied to these faces. The first feature extraction method, a proposed Convolution Neural Network (CNN), is based on the Histogram of Oriented Gradient (HOG) method. The second one is an ameliorated XceptionNet CNN. The two extracted sets of features are merged together and fed as input to a sequence of Gated Recurrent Units (GRUs) to extract the spatial and temporal features and then individuate the authenticity of videos. The proposed method is trained on the CelebDF-FaceForencics++ (c23) dataset and evaluated on the CelebDF test set. The experimental results and analysis confirm the superiority of the suggested method over the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Ismail, Aya and Elpeltagy, Marwa and Zaki, Mervat S. and Eldahshan, Kamal},
  doi          = {10.1007/s00521-022-07633-3},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21777-21791},
  shortjournal = {Neural Comput. Appl.},
  title        = {An integrated spatiotemporal-based methodology for deepfake detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Wi-fi signal-based human action acknowledgement using
channel state information with CNN-LSTM: A device less approach.
<em>NCA</em>, <em>34</em>(24), 21763–21775. (<a
href="https://doi.org/10.1007/s00521-022-07630-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action acknowledgment is an abundant and significant area for machine learning-based researchers due to the level of accuracy in identifying human actions. Due to the rapid growth of technologies in the machine and deep learning techniques, wireless sensors, handy Internet of Things (IoT) devices, and Wireless Fidelity (Wi-Fi), the activity recognition process is made effective with higher accuracy. By using those booming technologies and preserving the privacy of the test person we propose a novel human action recognition model that uses the channel state information (CSI) from Wi-Fi and the most prominent machine learning model, CNN with LSTM. Initially, CSI is introduced, the changes in CSI signals are assessed, and the obtained data samples are made as input to the CNN-LSTM model. To make the recognition more accurate, we also incorporated Kalman filters for noise removal and smoothed the data sample. Furthermore, we have used an image segmentation procedure to identify the initial and end times of all the activities considered and to fragment the image obtained, which is further fed as input to the CNN-LSTM model. Getting a dataset for the experiment is a herculean task. Hence a self-collected dataset is used to assess, or model proposed. Finally, the results obtained are verified and validated for their correctness with appropriate machine learning metrics and parameters like accuracy, F1 score, etc. Our proposed model affords the accuracy of 98.96\% for all the considered activities. The model can adapt itself even for a minimum sampling rate and subcarriers found in the test bed.},
  archive      = {J_NCA},
  author       = {Kumar, V. Dhilip and Rajesh, P and Polat, Kemal and Alenezi, Fayadh and Althubiti, Sara A and Alhudhaif, Adi},
  doi          = {10.1007/s00521-022-07630-6},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21763-21775},
  shortjournal = {Neural Comput. Appl.},
  title        = {Wi-fi signal-based human action acknowledgement using channel state information with CNN-LSTM: A device less approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Multi-modal medical image fusion based on densely-connected
high-resolution CNN and hybrid transformer. <em>NCA</em>,
<em>34</em>(24), 21741–21761. (<a
href="https://doi.org/10.1007/s00521-022-07635-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal medical image fusion (MMIF) has found wide application in the field of disease diagnosis and surgical guidance. Despite the popularity of deep learning (DL)-based fusion methods, these DL algorithms cannot provide satisfactory fusion performance due to the difficulty in capturing the local information and the long-range dependencies effectively. To address these issues, this paper has presented an unsupervised MMIF method by combining a densely-connected high-resolution network (DHRNet) with a hybrid transformer. In this method, the local features are firstly extracted from the source image using the DHRNet. Then these features are input into the fine-grained attention module in the hybrid transformer to produce the global features by exploring their long-range dependencies. The local and global features are fused by the projection attention module in the hybrid transformer. Finally, based on the fused features, the fused result is reconstructed by the decoder network. The presented network is trained using an unsupervised loss function including edge preservation value, structural similarity, sum of the correlations of differences and structural tensor. Experiments on various multi-modal medical images show that, compared with several traditional and DL-based fusion methods, the presented method can generate visually better fused results and provide better quantitative metrics values.},
  archive      = {J_NCA},
  author       = {Zhou, Quan and Ye, Shaozhuang and Wen, Mingwei and Huang, Zhiwen and Ding, Mingyue and Zhang, Xuming},
  doi          = {10.1007/s00521-022-07635-1},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21741-21761},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-modal medical image fusion based on densely-connected high-resolution CNN and hybrid transformer},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). P + FELU: Flexible and trainable fast exponential linear
unit for deep learning architectures. <em>NCA</em>, <em>34</em>(24),
21729–21740. (<a
href="https://doi.org/10.1007/s00521-022-07625-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Activation functions have an important role in obtaining the most appropriate output by processing the information coming into the network in deep learning architectures. Deep learning architectures are widely used in areas such as image processing applications, time series, and disease classification, generally in line with the analysis of large and complex data. Choosing the appropriate architecture and activation function is an important factor in achieving successful learning and classification performance. There are many studies to improve the performance of deep learning architectures and to overcome the disappearing gradient and negative region problems in activation functions. A flexible and trainable fast exponential linear unit (P + FELU) activation function is proposed to overcome existing problems. With the proposed P + FELU activation function, a higher success rate and faster calculation time can be achieved by incorporating the advantages of fast exponentially linear unit (FELU), exponential linear unit (ELU), and rectified linear unit (RELU) activation functions. Performance evaluations of the proposed P + FELU activation function were made on MNIST, CIFAR-10, and CIFAR-100 benchmark datasets. Experimental evaluations have shown that the proposed activation function outperforms the ReLU, ELU, SELU, MPELU, TReLU, and FELU activation functions and effectively improves the noise robustness of the network. Experimental results show that this activation function with “flexible and trainable” properties can effectively prevent vanishing gradient and make multilayer perceptron neural networks deeper.},
  archive      = {J_NCA},
  author       = {Adem, Kemal},
  doi          = {10.1007/s00521-022-07625-3},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21729-21740},
  shortjournal = {Neural Comput. Appl.},
  title        = {P + FELU: Flexible and trainable fast exponential linear unit for deep learning architectures},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AUBRec: Adaptive augmented self-attention via user behaviors
for sequential recommendation. <em>NCA</em>, <em>34</em>(24),
21715–21728. (<a
href="https://doi.org/10.1007/s00521-022-07623-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, self-attention models, and especially BERT4Rec (Sun, in: Proceedings of the 28th ACM international conference on information and knowledge management, 2019), have demonstrated themselves to be power tools for sequential recommendation. At their core, these models take a sequence of historical user behaviors as a sequential input, and then learn user behavior embeddings through an attention network to make their next recommendation. Yet, although a traditional self-attention model can effectively mine the potential relationship between user behaviors, the deep inherent characteristics of a user behavior sequence are still ignored. This mainly includes: the short-term and long-term information of a user behavior sequence; its continuous and non-continuous information; its forward and reverse asymmetric information; and its non-strong order dependency information. To address these issues, we propose a sequential recommendation model called AUBRec that uses controlled bidirectional self-attention to model user behavior sequences in an augmented manner. Specifically, we construct item interaction patterns based on the above-mentioned user behavior characteristics and then use these interaction patterns to locally augment attention. The item interaction patterns are created from a set of trainable parameter pairs, so it is learnable and lightweight. To further improve the accuracy and robustness of the model, we propose a dual-channel and confrontational self-attention model based on AUBRec, called AUBRec+. Extensive experiments on four publicly available datasets show that our method outperforms the current states-of-the-art in sequential recommendation.},
  archive      = {J_NCA},
  author       = {Fan, Jin and Yu, Xiaofeng and Wang, Zehao and Wang, Weijie and Sun, Danfeng and Wu, Huifeng},
  doi          = {10.1007/s00521-022-07623-5},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21715-21728},
  shortjournal = {Neural Comput. Appl.},
  title        = {AUBRec: Adaptive augmented self-attention via user behaviors for sequential recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic reconstruction of irregular shape defects in
pulsed thermography using deep learning neural network. <em>NCA</em>,
<em>34</em>(24), 21701–21714. (<a
href="https://doi.org/10.1007/s00521-022-07622-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative defect and damage reconstruction play a critical role in industrial quality management. Accurate defect characterisation in Infrared Thermography (IRT), as one of the widely used Non-Destructive Testing (NDT) techniques, always demands adequate pre-knowledge which poses a challenge to automatic decision-making in maintenance. This paper presents an automatic and accurate defect profile reconstruction method, taking advantage of deep learning Neural Networks (NN). Initially, a fast Finite Element Modelling (FEM) simulation of IRT is introduced for defective specimen simulation. Mask Region-based Convolution NN (Mask-RCNN) is proposed to detect and segment the defect using a single thermal frame. A dataset with a single-type-shape defect is tested to validate the feasibility. Then, a dataset with three mixed shapes of defect is inspected to evaluate the method’s capability on the defect profile reconstruction, where an accuracy over 90\% on Intersection over Union (IoU) is achieved. The results are compared with several state-of-the-art of post-processing methods in IRT to demonstrate the superiority at detailed defect corners and edges. This research lays solid evidence that AI deep learning algorithms can be utilised to provide accurate defect profile reconstruction in thermography NDT, which will contribute to the research community in material degradation analysis and structural health monitoring.},
  archive      = {J_NCA},
  author       = {Liu, Haochen and Li, Wenhan and Yang, Lichao and Deng, Kailun and Zhao, Yifan},
  doi          = {10.1007/s00521-022-07622-6},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21701-21714},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic reconstruction of irregular shape defects in pulsed thermography using deep learning neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning-based CFD simulations: A review, models,
open threats, and future tactics. <em>NCA</em>, <em>34</em>(24),
21677–21700. (<a
href="https://doi.org/10.1007/s00521-022-07838-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review targets various scenarios where CFD could be used and the logical parts needed for exemplary computations. The machine learning aspect with algorithms that have been implemented suggests design parameters to an algorithm that can be used for bodies in flights and different research-based algorithms that have been used and outlines the advantages, disadvantages, and tools used for computing the algorithm. Since fluid behavior is quite erratic, a single algorithm may not be versatile in every case. In some cases, multiple algorithms are combined for successful simulations. The uniqueness of the review lies in the combination of algorithms for every different case with theoretical analysis and disadvantages, which could be avoided by clubbing another algorithm that overcomes the problem. Since ML is not fully mature yet to provide high accuracy without bit preprocessing in the form of the numerical method, this is one of the heavy limitations that are briefly discussed.},
  archive      = {J_NCA},
  author       = {Panchigar, Dhruvil and Kar, Kunal and Shukla, Shashank and Mathew, Rhea Mary and Chadha, Utkarsh and Selvaraj, Senthil Kumaran},
  doi          = {10.1007/s00521-022-07838-6},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21677-21700},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning-based CFD simulations: A review, models, open threats, and future tactics},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive review on landmine detection using deep
learning techniques in 5G environment: Open issues and challenges.
<em>NCA</em>, <em>34</em>(24), 21657–21676. (<a
href="https://doi.org/10.1007/s00521-022-07819-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of Landmines, especially anti-tank mines, bombs, and unexploded substances, is one of the major challenges facing humanity. The devastation and human tragedy associated with undetected explosives are self-evident in war-torn communities. To deal with this problem, we are only left with proactive measures that such substances must be detected and dealt with before the fallout. Most available solutions have major shortcomings, such as cost, efficiency, and accuracy, where the trade-offs among them are inversely related. On the other hand, advances in deep learning, unmanned aerial vehicle, and sensing are making their way as potential technologies to revolutionize the detection and removal of landmines. In this paper, we go through the literature reviewing the most recent work featuring computerized technologies to detect landmines. To our knowledge, no such study has taken place in this respect. Our aim is to find out how deep learning can be integrated with landmine detection. We identify open challenges toward viable automated solutions that enable deep learning to optimize performance effectively.},
  archive      = {J_NCA},
  author       = {Barnawi, Ahmed and Budhiraja, Ishan and Kumar, Krishan and Kumar, Neeraj and Alzahrani, Bander and Almansour, Amal and Noor, Adeeb},
  doi          = {10.1007/s00521-022-07819-9},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21657-21676},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comprehensive review on landmine detection using deep learning techniques in 5G environment: Open issues and challenges},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review on crowd analysis of evacuation and abnormality
detection based on machine learning systems. <em>NCA</em>,
<em>34</em>(24), 21641–21655. (<a
href="https://doi.org/10.1007/s00521-022-07758-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human crowds have become hotspot research, particularly in crowd analysis to ensure human safety. Adaptations of machine learning (ML) approaches, especially deep learning, play a vital role in the applications of evacuation, detection, and prediction pertaining to crowd analysis. Further development in the analysis of crowd is needed to understand human behaviors due to the fast growth of crowd in urban megacities. This article presents a comprehensive review of crowd analysis ML-based systems, where it is categorized with respect to its purposes, viz. crowd evacuation that provides efficient evacuation routes, abnormality detection that could detect the occurrence of any irregular movement or behavior, and crowd prediction that could foresee the occurrence of any possible disasters or predict pedestrian trajectory. Moreover, this article reviews the applied techniques of machine learning with a brief discussion on the used software and simulation platforms. This work also classifies crowd evacuation into data-driven methods and goal-driven learning methods that have attracted significant attention due to their potential to adopt virtual agents with learning capabilities. This review finds that convolutional neural networks and recurrent neural networks have shown superiority in abnormality detection and prediction, whereas deep reinforcement learning has shown potential performance in the development of human level capacities of reasoning. These three methods contribute to the modeling and understanding of pedestrian behavior and will enhance further development in crowd analysis to ensure human safety.},
  archive      = {J_NCA},
  author       = {Bahamid, Alala and Mohd Ibrahim, Azhar},
  doi          = {10.1007/s00521-022-07758-5},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21641-21655},
  shortjournal = {Neural Comput. Appl.},
  title        = {A review on crowd analysis of evacuation and abnormality detection based on machine learning systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Global-local attention for emotion recognition.
<em>NCA</em>, <em>34</em>(24), 21625–21639. (<a
href="https://doi.org/10.1007/s00521-021-06778-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human emotion recognition is an active research area in artificial intelligence and has made substantial progress over the past few years. Many recent works mainly focus on facial regions to infer human affection, while the surrounding context information is not effectively utilized. In this paper, we proposed a new deep network to effectively recognize human emotions using a novel global-local attention mechanism. Our network is designed to extract features from both facial and context regions independently, then learn them together using the attention module. In this way, both the facial and contextual information is used to infer human emotions, therefore enhancing the discrimination of the classifier. The intensive experiments show that our method surpasses the current state-of-the-art methods on recent emotion datasets by a fair margin. Qualitatively, our global-local attention module can extract more meaningful attention maps than previous methods. The source code and trained model of our network are available at https://github.com/minhnhatvt/glamor-net .},
  archive      = {J_NCA},
  author       = {Le, Nhat and Nguyen, Khanh and Nguyen, Anh and Le, Bac},
  doi          = {10.1007/s00521-021-06778-x},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21625-21639},
  shortjournal = {Neural Comput. Appl.},
  title        = {Global-local attention for emotion recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep multi-task learning for image/video distortions
identification. <em>NCA</em>, <em>34</em>(24), 21607–21623. (<a
href="https://doi.org/10.1007/s00521-021-06576-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying distortions in images and videos is important and useful in various visual applications, such as image quality enhancement and assessment techniques. Instead of applying them blindly, these techniques can be applied or adjusted depending on the type of distortion identified. In this paper, we propose a deep multi-task learning (MTL) model for identifying the types of distortion in both images and videos, considering both single and multiple distortions. The proposed MTL model is composed of one convolutional neural network (CNN) shared between all tasks and N parallel classifiers, where each classifier is dedicated to identify a type of distortion. The proposed architecture also allows to adjust the number of tasks according to the number of distortion types considered, making the solution scalable. The proposed method has been evaluated on natural scene images and laparoscopic videos databases, each presenting a rich set of distortions. The experimental results demonstrate that our model achieves the best performance among the state-of-the-art methods for both single and multiple distortions (Code is available at: https://github.com/zoubidaameur/Deep-Multi-Task-Learning-for-Image-Video-Distortions-Identification ).},
  archive      = {J_NCA},
  author       = {Ameur, Zoubida and Fezza, Sid Ahmed and Hamidouche, Wassim},
  doi          = {10.1007/s00521-021-06576-5},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21607-21623},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep multi-task learning for image/video distortions identification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Texture images classification using improved local quinary
pattern and mixture of ELM-based experts. <em>NCA</em>, <em>34</em>(24),
21583–21606. (<a
href="https://doi.org/10.1007/s00521-021-06454-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Texture images classification plays an important role in machine vision that can be used to distinguish the surface and objects of an image from each other. Texture classification is a two-phases process consisting of feature extraction and classification. Feature extraction is a very important step in texture classification. Thus, we use improved local quinary pattern (ILQP) as descriptor to detect texture information of the images in feature extraction phase. Besides, in the classification phase, an innovative ensemble learning-based method is proposed which is named mixture of extreme learning machine-based experts with trainable gating network (MEETG). This method takes the advantages of extreme learning machine (ELM) for designing the structure of mixture of experts (ME) to overcome on some drawbacks of ME such as computation complexity and time-consuming learning process. The performance of texture features and MEETG is evaluated by applying five datasets: Brodatz album, ULUC dataset, KTH-TIPS dataset, Outex TC000012 dataset and ALOT dataset. Experimental results indicate that MEETG outperforms the other ensemble learning methods such as Bagging, Boosting and ME and also outperforms single classifiers such as nearest neighbor, decision tree, multi-layer perceptron and ELM on classification accuracy.},
  archive      = {J_NCA},
  author       = {Armi, Laleh and Abbasi, Elham and Zarepour-Ahmadabadi, Jamal},
  doi          = {10.1007/s00521-021-06454-0},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21583-21606},
  shortjournal = {Neural Comput. Appl.},
  title        = {Texture images classification using improved local quinary pattern and mixture of ELM-based experts},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detect and defense against adversarial examples in deep
learning using natural scene statistics and adaptive denoising.
<em>NCA</em>, <em>34</em>(24), 21567–21582. (<a
href="https://doi.org/10.1007/s00521-021-06330-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the enormous performance of deep neural networks (DNNs), recent studies have shown their vulnerability to adversarial examples (AEs), i.e., carefully perturbed inputs designed to fool the targeted DNN. Currently, the literature is rich with many effective attacks to craft such AEs. Meanwhile, many defense strategies have been developed to mitigate this vulnerability. However, these latter showed their effectiveness against specific attacks and does not generalize well to different attacks. In this paper, we propose a framework for defending DNN classifier against adversarial samples. The proposed method is based on a two-stage framework involving a separate detector and a denoising block. The detector aims to detect AEs by characterizing them through the use of natural scene statistic (NSS), where we demonstrate that these statistical features are altered by the presence of adversarial perturbations. The denoiser is based on block matching 3D (BM3D) filter fed by an optimum threshold value estimated by a convolutional neural network (CNN) to project back the samples detected as AEs into their data manifold. We conducted a complete evaluation on three standard datasets, namely MNIST, CIFAR-10 and Tiny-ImageNet. The experimental results show that the proposed defense method outperforms the state-of-the-art defense techniques by improving the robustness against a set of attacks under black-box, gray-box and white-box settings. The source code is available at: https://github.com/kherchouche-anouar/2DAE .},
  archive      = {J_NCA},
  author       = {Kherchouche, Anouar and Fezza, Sid Ahmed and Hamidouche, Wassim},
  doi          = {10.1007/s00521-021-06330-x},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21567-21582},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detect and defense against adversarial examples in deep learning using natural scene statistics and adaptive denoising},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards end-to-end car license plate location and
recognition in unconstrained scenarios. <em>NCA</em>, <em>34</em>(24),
21551–21566. (<a
href="https://doi.org/10.1007/s00521-021-06147-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from the rapid development of convolutional neural networks, the performance of car license plate detection and recognition has been largely improved. Nonetheless, most existing methods solve detection and recognition problems separately, and focus on specific scenarios, which hinders the deployment for real-world applications. To overcome these challenges, we present an efficient and accurate framework to solve the license plate detection and recognition tasks simultaneously. It is a lightweight and unified deep neural network, that can be optimized end-to-end and work in real-time. Specifically, for unconstrained scenarios, an anchor-free method is adopted to efficiently detect the bounding box and four corners of a license plate, which are used to extract and rectify the target region features. Then, a novel convolutional neural network branch is designed to further extract features of characters without segmentation. Finally, the recognition task is treated as sequence labeling problems, which are solved by Connectionist Temporal Classification (CTC) directly. Several public datasets including images collected from different scenarios under various conditions are chosen for evaluation. Experimental results indicate that the proposed method significantly outperforms the previous state-of-the-art methods in both speed and precision.},
  archive      = {J_NCA},
  author       = {Qin, Shuxin and Liu, Sijiang},
  doi          = {10.1007/s00521-021-06147-8},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21551-21566},
  shortjournal = {Neural Comput. Appl.},
  title        = {Towards end-to-end car license plate location and recognition in unconstrained scenarios},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced classification of remotely sensed hyperspectral
images through efficient band selection using autoencoders and genetic
algorithm. <em>NCA</em>, <em>34</em>(24), 21539–21550. (<a
href="https://doi.org/10.1007/s00521-021-06121-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral images (HSIs) contain significant number of contiguous dense spectral bands which often have large redundancy and high correlation that subsequently results into “curse of dimensionality” in HSI analysis. Therefore, efficient band selection techniques are crucial for dimensionality reduction of HSIs without any significant loss of spectral information contained in it. In this paper, deep learning autoencoders and genetic algorithm (GA) are used for efficient selection of the most revealing bands from a remotely sensed HSI. The proposed method formulates the HSI band selection process as a GA-based evolutionary optimization that minimizes the reconstruction error of an autoencoder which uses a few informative bands for HSI reconstruction. The proposed approach starts with spectral segmentation of the bands in an HSI into a number of spectral regions, and then, different autoencoders are trained on each segment with the original input band vectors contained in the segmented region. Finally, GA-based search heuristics is applied on each region in order to find out sparse sub-combination of spectral bands in such a way that the trained autoencoders would reconstruct the original segmented spectral vectors from the resulting band sub-combinations with least reconstruction errors. The final band selection is carried out by aggregating all the band sub-combinations returned from the segmented regions. Finally, the effectiveness of the proposed method is verified through selected bands validation by a support vector machine classifier. Experimental results on three publicly available HSI datasets depict the consistently superior effectiveness of the proposed band selection method over other state-of-the-art methods in land cover classification of remotely sensed HSIs.},
  archive      = {J_NCA},
  author       = {Singh, Pangambam Sendash and Karthikeyan, Subbiah},
  doi          = {10.1007/s00521-021-06121-4},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21539-21550},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced classification of remotely sensed hyperspectral images through efficient band selection using autoencoders and genetic algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leveraging semantic segmentation for hybrid image retrieval
methods. <em>NCA</em>, <em>34</em>(24), 21519–21537. (<a
href="https://doi.org/10.1007/s00521-021-06087-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content-based image retrieval (CBIR) is the task of finding images in a database that are the most similar to the input query based on its visual characteristics. Several methods from the state of the art based on visual methods (bag of visual words, VLAD, etc.) or recent deep leaning methods try to solve the CBIR problem. In particular, deep learning is a new field and used for several vision applications including CBIR. But, even with the increase in the performance of deep learning algorithms, this problem is still a challenge in computer vision. In this work, we propose three different methodologies combining deep learning-based semantic segmentation and visual features. We show experimentally that by exploiting semantic information in the CBIR context leads to an increase in the retrieval accuracy. We study the performance of the proposed approach on eight different datasets (Wang, Corel-10k, Corel-5k, GHIM-10K, MSRC V1, MSRC V2, Linnaeus and NUS-WIDE)},
  archive      = {J_NCA},
  author       = {Ouni, Achref and Royer, Eric and Chevaldonné, Marc and Dhome, Michel},
  doi          = {10.1007/s00521-021-06087-3},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21519-21537},
  shortjournal = {Neural Comput. Appl.},
  title        = {Leveraging semantic segmentation for hybrid image retrieval methods},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting image credibility in fake news over social media
using multi-modal approach. <em>NCA</em>, <em>34</em>(24), 21503–21517.
(<a href="https://doi.org/10.1007/s00521-021-06086-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media are the main contributors to spreading fake images. Fake images are manipulated images altered through software or by other means to change the information they convey. Fake images propagated over microblogging platforms generate misrepresentation and stimulate polarization in the people. Detection of fake images shared over social platforms is extremely critical to mitigating its spread. Fake images are often associated with textual data. Hence, a multi-modal framework is employed utilizing visual and textual feature learning. However, few multi-modal frameworks are already proposed; they are further dependent on additional tasks to learn the correlation between modalities. In this paper, an efficient multi-modal approach is proposed, which detects fake images of microblogging platforms. No further additional subcomponents are required. The proposed framework utilizes explicit convolution neural network model EfficientNetB0 for images and sentence transformer for text analysis. The feature embedding from visual and text is passed through dense layers and later fused to predict fake images. To validate the effectiveness, the proposed model is tested upon a publicly available microblogging dataset, MediaEval (Twitter) and Weibo, where the accuracy prediction of 85.3\% and 81.2\% is observed, respectively. The model is also verified against the newly created latest Twitter dataset containing images based on India&#39;s significant events in 2020. The experimental results illustrate that the proposed model performs better than other state-of-art multi-modal frameworks.},
  archive      = {J_NCA},
  author       = {Singh, Bhuvanesh and Sharma, Dilip Kumar},
  doi          = {10.1007/s00521-021-06086-4},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21503-21517},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting image credibility in fake news over social media using multi-modal approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Understanding cartoon emotion using integrated deep neural
network on large dataset. <em>NCA</em>, <em>34</em>(24), 21481–21501.
(<a href="https://doi.org/10.1007/s00521-021-06003-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion is an instinctive or intuitive feeling as distinguished from reasoning or knowledge. It varies over time, since it is a natural instinctive state of mind deriving from one’s circumstances, mood, or relationships with others. Since emotions vary over time, it is important to understand and analyze them appropriately. Existing works have mostly focused well on recognizing basic emotions from human faces. However, the emotion recognition from cartoon images has not been extensively covered. Therefore, in this paper, we present an integrated Deep Neural Network (DNN) approach that deals with recognizing emotions from cartoon images. Since state-of-works do not have large amount of data, we collected a dataset of size 8 K from two cartoon characters: ‘Tom’ &amp; ‘Jerry’ with four different emotions, namely happy, sad, angry, and surprise. The proposed integrated DNN approach, trained on a large dataset consisting of animations for both the characters (Tom and Jerry), correctly identifies the character, segments their face masks, and recognizes the consequent emotions with an accuracy score of 0.96. The approach utilizes Mask R-CNN for character detection and state-of-the-art deep learning models, namely ResNet-50, MobileNetV2, InceptionV3, and VGG 16 for emotion classification. In our study, to classify emotions, VGG 16 outperforms others with an accuracy of 96\% and F1 score of 0.85. The proposed integrated DNN outperforms the state-of-the-art approaches.},
  archive      = {J_NCA},
  author       = {Jain, Nikita and Gupta, Vedika and Shubham, Shubham and Madan, Agam and Chaudhary, Ankit and Santosh, K. C.},
  doi          = {10.1007/s00521-021-06003-9},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21481-21501},
  shortjournal = {Neural Comput. Appl.},
  title        = {Understanding cartoon emotion using integrated deep neural network on large dataset},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Synthetic data generation using DCGAN for improved traffic
sign recognition. <em>NCA</em>, <em>34</em>(24), 21465–21480. (<a
href="https://doi.org/10.1007/s00521-021-05982-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic sign detection and recognition perform a vital function in real-world driver guidance applications, including driver assistance systems. Research into vision-based traffic sign detection (TSD) and traffic sign recognition (TSR) has gained considerable attention in the scientific community, led mainly by three variables: identification, monitoring, and classification. In addition, TSR provides valuable details and alerts for smart cars including advanced driving assistance (ADAS) and cooperative intelligent transport systems (CITS). Our work will generate high-quality synthetic prohibitory sign images using deep convolutional generative adversarial networks (DCGAN). This paper analyzes and discusses CNN models incorporating different backbone architectures and feature extractors, focusing on Resnet 50 and Densenet for object detection. Assessment of the models provides important information, including mean average accuracy (mAP), workspace capacity, detection period, and the amount of billion floating-point operations (BFLOPS). The maximum average accuracy is 92\% (Densenet DCGAN), led by 91\% (Resnet 50 DCGAN), 88\% (Densenet), and 63\% (Resnet 50). We find when using the original image and a synthetic image, accuracy increases, while detection time falls. Our findings show that combining original images and synthetic images in the dataset for training can improve intersection over union (IoU) and traffic sign recognition performance.},
  archive      = {J_NCA},
  author       = {Dewi, Christine and Chen, Rung-Ching and Liu, Yan-Ting and Tai, Shao-Kuo},
  doi          = {10.1007/s00521-021-05982-z},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21465-21480},
  shortjournal = {Neural Comput. Appl.},
  title        = {Synthetic data generation using DCGAN for improved traffic sign recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effective training of convolutional neural networks for age
estimation based on knowledge distillation. <em>NCA</em>,
<em>34</em>(24), 21449–21464. (<a
href="https://doi.org/10.1007/s00521-021-05981-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Age estimation from face images can be profitably employed in several applications, ranging from digital signage to social robotics, from business intelligence to access control. Only in recent years, the advent of deep learning allowed for the design of extremely accurate methods based on convolutional neural networks (CNNs) that achieve a remarkable performance in various face analysis tasks. However, these networks are not always applicable in real scenarios, due to both time and resource constraints that the most accurate approaches often do not meet. Moreover, in case of age estimation, there is the lack of a large and reliably annotated dataset for training deep neural networks. Within this context, we propose in this paper an effective training procedure of CNNs for age estimation based on knowledge distillation, able to allow smaller and simpler “student” models to be trained to match the predictions of a larger “teacher” model. We experimentally show that such student models are able to almost reach the performance of the teacher, obtaining high accuracy over the LFW+, LAP 2016 and Adience datasets, but being up to 15 times faster. Furthermore, we evaluate the performance of the student models in the presence of image corruptions, and we demonstrate that some of them are even more resilient to these corruptions than the teacher model.},
  archive      = {J_NCA},
  author       = {Greco, Antonio and Saggese, Alessia and Vento, Mario and Vigilante, Vincenzo},
  doi          = {10.1007/s00521-021-05981-0},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21449-21464},
  shortjournal = {Neural Comput. Appl.},
  title        = {Effective training of convolutional neural networks for age estimation based on knowledge distillation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EMOCGAN: A novel evolutionary multiobjective cyclic
generative adversarial network and its application to unpaired image
translation. <em>NCA</em>, <em>34</em>(24), 21433–21447. (<a
href="https://doi.org/10.1007/s00521-021-05975-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) have been accepted as powerful models in the field of computer vision, speech and language processing, etc. However, a major concern regarding GANs is the requirement of paired images for image-to-image translation, which is not always possible in the case of real-world applications. Moreover, they also suffer from training instability as well as mode collapse problem. These concerns remain open challenging issues for GANs and become more complex in the case of cyclic GAN. Motivated by evolutionary GAN, we hereby propose a novel evolutionary multiobjective cyclic GAN (EMOCGAN) to address the above stated challenges related to cyclic GAN training for the image-to-image translation. In this work, we have also introduced a new approach for model training by integrating the concept of evolutionary computation, multiobjective optimization, cyclic GAN along with different selection mechanisms. To overcome local optima stagnation, metropolis acceptance criteria and Pareto-based selection on two scores (objective functions) are utilized. Evolutionary concepts in training helped to address the instability and mode collapse problems. Extensive experiments on real-world image datasets show that the EMOCGAN outperforms state-of-the-art method in terms of visually realistic appearance and retaining background information as well as salient objects. Quantitative comparisons of our EMOCGAN with the cyclic GAN also show significantly better scores obtained by our model, as indicated by structural similarity index (SSIM) and universal quality index (UQI). The model demonstrated best efficacy in terms of SSIM on Apple $$\leftrightarrow$$ Orange, while it shows higher UQI values for Monet $$\leftrightarrow$$ Picture and Summer $$\leftrightarrow$$ Winter datasets.},
  archive      = {J_NCA},
  author       = {Bharti, Vandana and Biswas, Bhaskar and Shukla, Kaushal Kumar},
  doi          = {10.1007/s00521-021-05975-y},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21433-21447},
  shortjournal = {Neural Comput. Appl.},
  title        = {EMOCGAN: A novel evolutionary multiobjective cyclic generative adversarial network and its application to unpaired image translation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fully neural object detection solutions for robot soccer.
<em>NCA</em>, <em>34</em>(24), 21419–21432. (<a
href="https://doi.org/10.1007/s00521-021-05972-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RoboCup is one of the major global AI events, gathering hundreds of teams from the world’s best universities to compete in various tasks ranging from soccer to home assistance and rescue. The commonality of these three seemingly dissimilar tasks is that in order to perform well, the robot needs to excel at the all major AI tasks: perception, control, navigation, strategy and planning. In this work, we focus on the first of these by presenting what is—to our knowledge—the first fully neural vision system for the Nao robot soccer. This is a challenging task, mainly due to the limited computational capabilities of the Nao robot. In this paper, we propose two novel neural network architectures for semantic segmentation and object detection that ensure low-cost inference, while improving accuracy by exploiting the properties of the environment. These models use synthetic transfer learning to be able to learn from a low number of hand-labeled images. The experiments show that our models outperform state-of-the-art methods such as Tiny YOLO at a fraction of the cost.},
  archive      = {J_NCA},
  author       = {Szemenyei, Márton and Estivill-Castro, Vladimir},
  doi          = {10.1007/s00521-021-05972-1},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {21419-21432},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fully neural object detection solutions for robot soccer},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GA-SRN: Graph attention based text-image semantic reasoning
network for fine-grained image classification and retrieval.
<em>NCA</em>, <em>34</em>(23), 21387–21401. (<a
href="https://doi.org/10.1007/s00521-022-07617-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new fine-grained image classification (FGIC) network with feature relationship enhancement of multiple stages is established. After the engaging of scene text in FGIC and retrieval, basic architecture of local, global, text feature encoders and classifier have been approved. This method retains these portions and expands them into a five-module architecture. In specific, positional encoding is incorporated to both local and textual feature encoders such that complementary information carried could engage in feature representation. In local and textual feature encoders, intra-modal semantic relation reasoning is introduced for FGIC by a proposed General Feature Relation Enhancement (GFRE) module. GFRE is a feature reasoning module applicable to any two inputs of same modality or distinct modalities. GFRE adopts Graph Attention which represents and infers relationships among graph data. Moreover, latest multi-modal reasoning module is improved by a proposed Multi-Head Multi-Modal Joint Semantic Reasoning module consisted of cross-modal GFREs by multi-head fusion. Experimental results on multiple datasets verify the effectiveness of the proposed algorithm.},
  archive      = {J_NCA},
  author       = {Li, Wenhao and Zhu, Hongqing and Yang, Suyi and Wang, Pengyu and Zhang, Han},
  doi          = {10.1007/s00521-022-07617-3},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21387-21401},
  shortjournal = {Neural Comput. Appl.},
  title        = {GA-SRN: Graph attention based text-image semantic reasoning network for fine-grained image classification and retrieval},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid learning model for spatio-temporal forecasting of PM
<span class="math display"><sub>2.5</sub></span> using aerosol optical
depth. <em>NCA</em>, <em>34</em>(23), 21367–21386. (<a
href="https://doi.org/10.1007/s00521-022-07616-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existence of several challenges and high cost in the development of monitoring infrastructure have become major reasons for data sparsity by statutory government agencies tasked to study pollution exposure in urban areas. As an effort to mitigate this problem, the recent usage of satellite aerosol optical depth data along with the usage of learning algorithms have become popular in recent times. This paper presents a novel four-staged approach using different machine learning, deep learning and statistical methods to develop a spatio-temporal hybrid model for temporal forecasting using data from existing stations along with satellite aerosol optical depth data for spatial interpolation. Experiments conducted on real-world data belonging to the cities of Kolkata, Bengaluru and Mumbai show that a consistent pattern is not followed in all the cities in all stages except in spatial interpolation where Random Forest Regression is found to surpass all other models used. While a long short-term memory network (LSTM Auto-Encoder) when employed in temporal forecasting inside the hybrid method outperforms others in Mumbai, a random forest regression-based method and a multi-layer perceptron-based method outperform others similarly in Kolkata and Bengaluru, respectively.},
  archive      = {J_NCA},
  author       = {Nath, Pritthijit and Roy, Biparnak and Saha, Pratik and Middya, Asif Iqbal and Roy, Sarbani},
  doi          = {10.1007/s00521-022-07616-4},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21367-21386},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid learning model for spatio-temporal forecasting of PM $$_{2.5}$$ using aerosol optical depth},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning-based integrative model for survival time
prediction of head and neck squamous cell carcinoma patients.
<em>NCA</em>, <em>34</em>(23), 21353–21365. (<a
href="https://doi.org/10.1007/s00521-022-07615-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oral Cancer is one of the prevailing diseases worldwide. Taking previous studies into account, observations have shown that oral cancer has a poor prognosis due to the delay in the detection of the disease. The outcomes of cancer detection and prevention are ineffective unless the mutation of genetic factors is thoroughly understood. Nevertheless, understanding and identifying genetic mutation is a challenging issue for researchers. Determining the survival time is one of the essential outcomes in cancer detection. The existing survival time-based studies introduced models that use one type of genomic data or on clinical data, which do not consider the structural and biological relationships of genomic data in cancer. However, the current work is being carried out by integrating different types of genomic and clinical data to get a better understanding of cancer characterization. The key component to understand the complex molecular mechanisms of cancer is data integration. However, the integration of multi-genomic data poses significant challenges due to the existence of high dimensions and diverse approaches in it. The focus of this study is to create an integrative model for improved prediction accuracy of clinical outcomes in the survivability of oral cancer. The proposed model initially uses dimensionality reduction and feature selection techniques for the identification and elimination of features with insignificant and meaningless values from the Head and Neck Squamous Cell Carcinoma (HNSC) dataset taken from The Cancer Genome Atlas (TCGA). The integrative model&#39;s predictive performance is then compared to the performance of the model based on clinical features only. The proposed model performed well on the training and testing sets, achieving a c-index of 0.9439 and 0.916, respectively. It can be concluded from the results that the integrative model can effectively differentiate the interaction of genomic data types and it can be beneficial for the patients having oral cancer in terms of significant diagnostics and treatment plans.},
  archive      = {J_NCA},
  author       = {Sharma, Diksha and Deepali and Garg, Vivek Kumar and Kashyap, Dharambir and Goel, Neelam},
  doi          = {10.1007/s00521-022-07615-5},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21353-21365},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning-based integrative model for survival time prediction of head and neck squamous cell carcinoma patients},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid optimization enabled deep learning model for colour
image segmentation and classification. <em>NCA</em>, <em>34</em>(23),
21335–21352. (<a
href="https://doi.org/10.1007/s00521-022-07614-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation is one of the most significant tasks in image analysis, and it plays an imperative job in image processing to analyse and attain meaningful information. Moreover, image segmentation is a major process of object recognition and categorization in computer vision domain. Image segmentation utilizes the image features for separating images into definite areas along with exclusive properties. Meanwhile, various colour image segmentation techniques are introduced in computer vision research area. However, these techniques are more time consuming and failed to afford anticipated segmentation outcome, because of poor segmentation results and high computational difficulty. To overcome these challenges, an effectual hybrid optimization-based Deep Learning (DL) technique is devised for colour image segmentation and classification in this research study. The median filter is applied for input image to eliminate the noises, which assists for better image segmentation and classification process. Moreover, Improved Invasive Weed Flower Pollination Optimization (IIWFPO) approach is introduced for image segmentation process in this work. In addition, Deep Residual Network (DRN) classifier is employed for image classification, and the classifier is trained by developed Fr-IIWFPO algorithm. The developed colour image segmentation and classification approach obtained better performance than traditional techniques with accuracy of 0.9187, sensitivity of 0.9334, and specificity of 0.8902.},
  archive      = {J_NCA},
  author       = {Rasi, D. and Deepa, S. N.},
  doi          = {10.1007/s00521-022-07614-6},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21335-21352},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid optimization enabled deep learning model for colour image segmentation and classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of novel automated language classification model
using pyramid pattern technique with speech signals. <em>NCA</em>,
<em>34</em>(23), 21319–21333. (<a
href="https://doi.org/10.1007/s00521-022-07613-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language classification using speeches is a complex issue in machine learning and pattern recognition. Various text and image-based language classification methods have been presented. But there are limited speech-based language classification methods in the literature. Also, the previously presented models classified limited numbers of languages, and few are accents. This work presents an automated handcrafted language classification model. The novel pyramid pattern is presented to extract the features extraction. Also, statistical features and maximum pooling are used to generate the features. We have developed our speech-language classification model using two datasets: (i) created a new big speech dataset containing 14,500 speeches in 29 languages, and (ii) used the VoxForge dataset. The neighborhood component analysis method is used to select the most informative 1000 features from the generated features, and these features are classified using a quadratic support vector machine classifier (QSVM). Our developed method yielded 98.87 ± 0.30\% and 97.12 ± 1.27\% accuracies for our and VoxForge datasets, respectively. Also, geometric mean, average precision, and F1-score evaluation parameters are calculated, and they are presented in the results section. This paper presents an accurate language classification model developed using two big speech-language datasets. Our results indicate the success of the proposed pyramid pattern-based language classification method in classifying various speech languages accurately.},
  archive      = {J_NCA},
  author       = {Akbal, Erhan and Barua, Prabal Datta and Tuncer, Turker and Dogan, Sengul and Acharya, U. Rajendra},
  doi          = {10.1007/s00521-022-07613-7},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21319-21333},
  shortjournal = {Neural Comput. Appl.},
  title        = {Development of novel automated language classification model using pyramid pattern technique with speech signals},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-scale error feedback network for low-light image
enhancement. <em>NCA</em>, <em>34</em>(23), 21301–21317. (<a
href="https://doi.org/10.1007/s00521-022-07612-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light image enhancement is a challenging task because brightness, contrast, noise and other factors must be considered simultaneously. However, most of the existing studies focus on improving illumination, and it is difficult to obtain natural images when the images of complex scenes are enhanced. To address this issue, we propose a neural network—a multi-scale error feedback network (MSEFN)—to enhance low-light images. The proposed network consists of an error feedback encoder module (EFEM), an error feedback decoder module (EFDM) and a feature integration module (FIM). As the main component of EFEM and EFDM, the error feedback feature extraction module can effectively retain spatial information by using the shuffle attention fusion block (SAFB) to fuse the acquired multi-scale features and nonadjacent features. FIM has the ability to capture contextual information that can compensate for the lack of global features in the network. Furthermore, the local uneven illumination (LUI) dataset and polynomial loss function constructed in this paper make our network more stable. Extensive experiments demonstrate that the proposed network outperforms state-of-the-art methods both qualitatively and quantitatively. The LUI dataset is publicly available at: https://github.com/Qyizos/LUI-dataset .},
  archive      = {J_NCA},
  author       = {Qian, Yi and Jiang, Zetao and He, Yuting and Zhang, Shaoqin and Jiang, Shenming},
  doi          = {10.1007/s00521-022-07612-8},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21301-21317},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-scale error feedback network for low-light image enhancement},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A knowledge guided bacterial foraging optimization algorithm
for many-objective optimization problems. <em>NCA</em>, <em>34</em>(23),
21275–21299. (<a
href="https://doi.org/10.1007/s00521-022-07611-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite that evolutionary and swarm intelligence algorithms have achieved considerable success on multi-objective optimization problems, they face huge challenges when dealing with many-objective optimization problems (MaOPs). There is an urgent call for effective evolutionary and swarm intelligence algorithms for MaOPs. Inspired by the satisfactory performance of bacterial foraging optimization (BFO) on the single-objective optimization problems, this paper extends BFO to deal with MaOPs and proposes a knowledge guided BFO for MaOPs (called as KLBFO). Firstly, KLBFO learns promising direction knowledge based on group decision making idea to guide the population to converge toward proper directions. Secondly, KLBFO learns elite knowledge by a new biological mechanism to accelerate the population to converge. Thirdly, KLBFO learns density knowledge by a new diversity management strategy based on orthogonal grid to produce well-distributed solutions. The performance of KLBFO is comprehensively evaluated by comparing it with eight state-of-the-art algorithms on two suites of test problems and one real-world problem. The empirical results have validated the superior performance of KLBFO for MaOPs.},
  archive      = {J_NCA},
  author       = {Yang, Cuicui and Weng, Yannan and Ji, Junzhong and Wu, Tongxuan},
  doi          = {10.1007/s00521-022-07611-9},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21275-21299},
  shortjournal = {Neural Comput. Appl.},
  title        = {A knowledge guided bacterial foraging optimization algorithm for many-objective optimization problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature extraction and neural network-based fatigue damage
detection and classification. <em>NCA</em>, <em>34</em>(23),
21253–21273. (<a
href="https://doi.org/10.1007/s00521-022-07609-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a methodology for detection and classification of fatigue damage in mechanical structures in the framework of neural networks (NN). The proposed methodology has been tested and validated with polycrystalline-alloy (AL7075-T6) specimens on a laboratory-scale experimental apparatus. Signal processing tools (e.g., discrete wavelet transform and Hilbert transform) have been applied on time series of ultrasonic test signals to extract features that are derived from: (i) Signal envelope, (ii) Low-frequency and high-frequency signal spectra, and (iii) Signal energy. The performance of the neural network, combined with each one of these features, is compared with the ground truth, generated from the original ultrasonic test signals and microscope images. The results show that the NN model, combined with the signal-energy feature, yields the best performance and that it is capable of detecting and classifying the fatigue damage with (up to) 98.5\% accuracy.},
  archive      = {J_NCA},
  author       = {Alqahtani, Hassan and Ray, Asok},
  doi          = {10.1007/s00521-022-07609-3},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21253-21273},
  shortjournal = {Neural Comput. Appl.},
  title        = {Feature extraction and neural network-based fatigue damage detection and classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A walk in the black-box: 3D visualization of large neural
networks in virtual reality. <em>NCA</em>, <em>34</em>(23), 21237–21252.
(<a href="https://doi.org/10.1007/s00521-022-07608-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the last decade Deep Learning has become a tool for solving challenging problems like image recognition. Still, Convolutional Neural Networks (CNNs) are considered black-boxes, which are difficult to understand by humans. Hence, there is an urge to visualize CNN architectures, their internal processes and what they actually learn. Previously, virtual realityhas been successfully applied to display small CNNs in immersive 3D environments. In this work, we address the problem how to feasibly render large-scale CNNs, thereby enabling the visualization of popular architectures with ten thousands of feature maps and branches in the computational graph in 3D. Our software ”DeepVisionVR” enables the user to freely walk through the layered network, pick up and place images, move/scale layers for better readability, perform feature visualization and export the results. We also provide a novel Pytorch module to dynamically link PyTorch with Unity, which gives developers and researchers a convenient interface to visualize their own architectures. The visualization is directly created from the PyTorch class that defines the Pytorch model used for training and testing. This approach allows full access to the network’s internals and direct control over what exactly is visualized. In a use-case study, we apply the module to analyze models with different generalization abilities in order to understand how networks memorize images. We train two recent architectures, CovidResNet and CovidDenseNet on the Caltech101 and the SARS-CoV-2 datasets and find that bad generalization is driven by high-frequency features and the susceptibility to specific pixel arrangements, leading to implications for the practical application of CNNs. The code is available on Github https://github.com/Criscraft/DeepVisionVR .},
  archive      = {J_NCA},
  author       = {Linse, Christoph and Alshazly, Hammam and Martinetz, Thomas},
  doi          = {10.1007/s00521-022-07608-4},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21237-21252},
  shortjournal = {Neural Comput. Appl.},
  title        = {A walk in the black-box: 3D visualization of large neural networks in virtual reality},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new cloud autonomous system as a service for multi-mobile
robots. <em>NCA</em>, <em>34</em>(23), 21223–21235. (<a
href="https://doi.org/10.1007/s00521-022-07605-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, mobile robot is used in most industrial and commercial fields. It can improve and carry out work complex tasks quickly and efficiently. However, using swarm robots to execute some tasks requires a complex system for assigning robots to these tasks. The main issue in the robot control systems is the limited facilities of robot embedded system components. Although, some researchers used cloud computing to develop robot services. They didn’t use the cloud for solving robot control issues. In this paper, we have used cloud computing for controlling robots to solve the problem of limited robot processing components. The main advantage of using cloud computing is its intensive computing power. This advantage motivates us to propose a new autonomous system for multi-mobile robots as a services-based cloud computing. The proposed system consists of three phases: clustering phase, allocation phase, and path planning phase. It groups all tasks/duties into clusters using the k-means algorithm. After that, it finds the optimal path for each robot to execute its duties in the cluster based on the Nearest neighbor and Harris Hawks Optimizer (HHO). The proposed system is compared with systems that use a genetic algorithm, simulated annealing algorithm, and HHO algorithm. From the finding, we find that the proposed system is more efficient than the other systems in terms of decision time, throughput, and the total distance of each robot.},
  archive      = {J_NCA},
  author       = {Nasr, Aida A.},
  doi          = {10.1007/s00521-022-07605-7},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21223-21235},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new cloud autonomous system as a service for multi-mobile robots},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Daytime sea fog monitoring using multimodal self-supervised
learning with band attention mechanism. <em>NCA</em>, <em>34</em>(23),
21205–21222. (<a
href="https://doi.org/10.1007/s00521-022-07602-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sea fog is a dangerous weather phenomenon that seriously affects maritime traffic and other operations at sea. The conventional sea fog detection methods are not only difficult to make full advantage of the multispectral information of cloud images, but also deficient in the exploration of deep-level semantic information, leading to poor detection results. In this paper, we proposed a multimodal self-supervised convolutional neural network incorporating intra-modal band attention mechanism (MSCNN-IBAM) based on multispectral images of Himawari-8. MSCNN-IBAM uses independent branches to extract features from different modality cloud images and characterize the importance of each band through attention mechanisms. Simultaneously, multimodal self-supervised learning and supervised learning are effectively combined to optimize the model by constructing a two-tuple trainset. Experimental results show the accuracy, precision, recall, and F1 score of the proposed method as 97.72\%, 95.84\%, 96.54\%, and 96.08\%, respectively, which have the competitive performance and acceptable computational efficiency. And the additional analysis of sea fog cases shows that the proposed method is not only effective in identifying sea fog, but also has the ability to locate sea fog regions.},
  archive      = {J_NCA},
  author       = {Li, Tao and Jin, Wei and Fu, Randi and He, Caifen},
  doi          = {10.1007/s00521-022-07602-w},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21205-21222},
  shortjournal = {Neural Comput. Appl.},
  title        = {Daytime sea fog monitoring using multimodal self-supervised learning with band attention mechanism},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Domain adaptation based on source category prototypes.
<em>NCA</em>, <em>34</em>(23), 21191–21203. (<a
href="https://doi.org/10.1007/s00521-022-07601-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA), which can transfer knowledge from labeled source domain to unlabeled target domain, needs to access a large number of labeled source data in the process of generalization. However, the data of two domains may not be accessed at the same time due to data privacy protection. To solve this problem, source-data free domain adaptation (SFDA) began to receive attention. However, too little source information will lead to some performance gaps. To balance the issues between UDA and SFDA, a new setting called Prototype-based domain adaptation (Prototype-DA) is proposed, which further improves the practicability of UDA by using source category prototype instead of source data. At the same time, it can also ensure the privacy of source data like SFDA. Specifically, our training process can be divided into two steps. First, the source data is used to pre-train a source model, and the source category prototypes are obtained after the training of source model. Then, to generalize the source model to the target domain, category maximum mean discrepancy (Category-MMD) is defined so that the target data can be aligned with the source category prototypes. In this way, source category prototypes will transfer knowledge to the target domain together with the source model. Through source category prototypes, Prototype-DA can not only achieve the comparable results than the method using source data, but also protect the privacy of source data to some extent. Furthermore, the target category prototypes are constructed and the consistency between the labels of target category prototypes and the classification results is required. This prototype-label consistency regularization, proposed by us for the first time, helps to extract discriminative features in the target domain. Compared with the previous UDA methods and SFDA methods, extensive experiments on multiple public domain adaptation datasets show that Prototype-DA achieves the state-of-the-art results. At the same time, the traditional UDA theory is expanded to our method setting and makes a theoretical analysis to ensure the effectiveness of our method.},
  archive      = {J_NCA},
  author       = {Zhou, Lihua and Ye, Mao and Xiao, Siying},
  doi          = {10.1007/s00521-022-07601-x},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21191-21203},
  shortjournal = {Neural Comput. Appl.},
  title        = {Domain adaptation based on source category prototypes},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analyzing modeled configuration using finite element
analysis for performance prediction of LSRM. <em>NCA</em>,
<em>34</em>(23), 21175–21189. (<a
href="https://doi.org/10.1007/s00521-022-07598-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to high precision, high speed, and high fault tolerance capability, the linear switched reluctance motor (LSRM) is applied in digital control technologies as well as electronic switching devices. The LSRM is considered as a good substitute for conventional linear drive systems for long-way transportation. In this paper, a single-stator and double-stator longitudinal flux-type LSRM for high-speed transit system is proposed. Since the flux in the longitudinal arrangement is in the same alignment as the motion of the translator, the proposed system is easier to construct, mechanically stable with minimum eddy current loss. It also produces the magnetic flux along the direction of motion, which makes it highly suitable for high-speed linear transit application. The proposed conceptual LSRM differs from the conventional LSRM, in such a way that the active stator holds the excitation windings, while at the same time it acts as a translational body that moves over the stationary translator bed. The motor characterization is performed in ANSYS electromagnetic simulation tool, to determine the applied forces, coupling inductance, and strength of the magnetic field of the proposed LSRM for the traction propulsion system. The finite element analysis (FEA) is utilized here to analyze the modeled configuration, for verification of the design and performance prediction of the proposed LSRM.},
  archive      = {J_NCA},
  author       = {Murty, V. Shirish and Jain, Shailendra and Ojha, Amit},
  doi          = {10.1007/s00521-022-07598-3},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21175-21189},
  shortjournal = {Neural Comput. Appl.},
  title        = {Analyzing modeled configuration using finite element analysis for performance prediction of LSRM},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimizing deadline violation time and energy consumption of
IoT jobs in fog–cloud computing. <em>NCA</em>, <em>34</em>(23),
21157–21173. (<a
href="https://doi.org/10.1007/s00521-022-07596-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, Internet of Things (IoT) devices are ubiquitous and their number is growing rapidly. These devices produce massive amount of data which need to be efficiently processed. Since most of the IoT devices are resource constrained in terms of computational capability and power resources, they have to offload their computation jobs to more powerful computing devices. Fog–cloud computing is a promising platform for processing IoT jobs. However, due to the heterogeneity of the computing devices, how to schedule IoT jobs in this environment is a challenging issue. To tackle this issue, in this paper, we first present a system model for the job scheduling problem in fog–cloud computing with the aim of optimizing the total deadline violation time of jobs and the energy consumption of the system. Then, we propose two nature-inspired optimization techniques, grey wolf optimization and grasshopper optimization algorithm to efficiently solve the job scheduling problem in the fog–cloud environment. The performance of the proposed algorithms is evaluated against the state-of-the-art algorithms using various simulation experiments. The results demonstrate that the proposed schedulers are capable of reducing the total deadline violation time about 68\% and energy consumption about 22\% compared to the second-best results.},
  archive      = {J_NCA},
  author       = {Dabiri, Samaneh and Azizi, Sadoon and Abdollahpouri, Alireza},
  doi          = {10.1007/s00521-022-07596-5},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21157-21173},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimizing deadline violation time and energy consumption of IoT jobs in fog–cloud computing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generating balanced and strong clusters based on
balance-constrained clustering approach (strong balance-constrained
clustering) for improving ensemble classifier performance. <em>NCA</em>,
<em>34</em>(23), 21139–21155. (<a
href="https://doi.org/10.1007/s00521-022-07595-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of clustering in generating random subspace has improved the accuracy and diversity of ensemble classification methods. If clusters are not balanced (unequal size of clusters) and not strong (unequal number of data from each class in each cluster), the results will deviate from classes with more samples in each cluster and thereby will be biased. The current paper presents a novel strong balance-constrained clustering or hard-strong clustering. This method creates diverse strong balanced data clusters to train different base classifiers and an artificial neural network with more than one hidden layer, in which the final decision is made for the data class through majority voting. By implementing the proposed method on 16 datasets, two objectives are followed: enhancing the performance of ensemble classifier and deep learning-based method (data mining objective), and adopting appropriate policies for budget, time, and energy assignment to various business domains by decision-makers (business objective). Based on the evaluation and comparison of the results, the proposed method is faster than other balancing methods. Furthermore, the accuracy of the proposed ensemble method has proved acceptable improvement than other ensemble classification methods.},
  archive      = {J_NCA},
  author       = {Mousavian Anaraki, Seyed Alireza and Haeri, Abdorrahman and Moslehi, Fateme},
  doi          = {10.1007/s00521-022-07595-6},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21139-21155},
  shortjournal = {Neural Comput. Appl.},
  title        = {Generating balanced and strong clusters based on balance-constrained clustering approach (strong balance-constrained clustering) for improving ensemble classifier performance},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Global balanced iterative pruning for efficient
convolutional neural networks. <em>NCA</em>, <em>34</em>(23),
21119–21138. (<a
href="https://doi.org/10.1007/s00521-022-07594-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase of structure complexity, convolutional neural networks (CNNs) take a fair amount of computation cost. Meanwhile, existing research reveals the salient parameter redundancy in CNNs. The current pruning methods can compress CNNs with little performance drop, but when the pruning ratio increases, the accuracy loss is more serious and the compressing rates of parameters and floating-point operations (FLOPs) are unbalanced. Moreover, the existing iterative pruning methods are difficult to accurately identify and delete unimportant parameters due to the accuracy drop during pruning. We propose a novel global balanced iterative pruning method (GBIP) for CNNs. Firstly, a global equilibrium pruning strategy based on feature distribution is proposed. Then the intermediate and output features of original network are applied to guide the fine-tuning of pruned network. Moreover, we design a shallow fully-connected network to allow the output of two networks to play an adversarial game, thereby it can quickly recover the pruned accuracy among iterative pruning intervals. We conduct extensive experiments on the image classification tasks CIFAR-10, CIFAR-100, and ILSVRC-2012 to verify our pruning method can achieve efficient compression for CNNs even without accuracy loss. On the ILSVRC-2012, when removing 36.78\% parameters and 45.55\% FLOPs of ResNet-18, the Top-1 accuracy drop are only 0.66\%. Our method is superior to some state-of-the-art pruning schemes in terms of compressing rate and accuracy. Moreover, we further demonstrate that GBIP has good generalization on the object detection task PASCAL VOC.},
  archive      = {J_NCA},
  author       = {Chang, Jingfei and Lu, Yang and Xue, Ping and Xu, Yiqun and Wei, Zhen},
  doi          = {10.1007/s00521-022-07594-7},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21119-21138},
  shortjournal = {Neural Comput. Appl.},
  title        = {Global balanced iterative pruning for efficient convolutional neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of hydraulic blockage at culverts from a single
image using deep learning. <em>NCA</em>, <em>34</em>(23), 21101–21117.
(<a href="https://doi.org/10.1007/s00521-022-07593-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-drainage hydraulic structures such as culverts and bridges in urban landscapes are prone to get blocked by the transported debris (e.g., urban, vegetated), which often reduces their hydraulic capacity and triggers flash floods. Unavailability of relevant data from blockage-originated flooding events and complex nature of debris accumulation are highlighted factors hindering the research within the blockage management domain. Wollongong City Council (WCC) blockage conduit policy is the leading formal guidelines to incorporate blockage into design guidelines; however, are criticized by the hydraulic engineers for its dependence on the post-flood visual inspections (i.e., visual blockage) instead of peak floods hydraulic investigations (i.e., hydraulic blockage). Apparently, no quantifiable relationship is reported between the visual blockage and hydraulic blockage; therefore, many consider WCC blockage guidelines invalid. This paper exploits the power of Artificial Intelligence (AI), motivated by its recent success, and attempts to relate visual blockage with hydraulic blockage by proposing a deep learning pipeline to predict hydraulic blockage from an image of the culvert. Two experiments are performed where the conventional pipeline and end-to-end learning approaches are implemented and compared in the context of predicting hydraulic blockage from a single image. In experiment one, the conventional deep learning pipeline approach (i.e., feature extraction using CNN and regression using ANN) is adopted. In contrast, in experiment two, end-to-end deep learning models (i.e., E2E_ MobileNet, E2E_ BlockageNet) are trained and compared with the conventional pipeline approach. Dataset (i.e., Hydraulics-Lab Blockage Dataset (HBD), Visual Hydraulics-Lab Dataset (VHD)) used in this research were collected from laboratory experiments performed using scaled physical models of culverts. E2E_ BlockageNet model was reported best in predicting hydraulic blockage with $$R^2$$ score of 0.91 and indicated that hydraulic blockage could be interrelated with the visual features at the culvert.},
  archive      = {J_NCA},
  author       = {Iqbal, Umair and Barthelemy, Johan and Perez, Pascal},
  doi          = {10.1007/s00521-022-07593-8},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21101-21117},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of hydraulic blockage at culverts from a single image using deep learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multistability analysis of switched fractional-order
recurrent neural networks with time-varying delay. <em>NCA</em>,
<em>34</em>(23), 21089–21100. (<a
href="https://doi.org/10.1007/s00521-022-07592-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the existence and dynamic behaviors of multiple equilibria of switched fractional-order recurrent neural networks (SFRNNs) with time-varying delay. By applying the characteristics of Caputo fractional calculus and an effective state space partition method, sufficient criteria are derived to ascertain that the n-neuron SFRNN has $$5^n$$ equilibria, among which $$3^n$$ ones are locally asymptotically stable and the rest are unstable. Moreover, the multistability of integer-order neural networks as a special case is also taken into consideration in this paper. Two illustrative examples are provided to substantiate the theoretical results.},
  archive      = {J_NCA},
  author       = {Liu, Peng and Xu, Minglin and Li, Yunliu and Yu, Peizhao and Li, Sanyi},
  doi          = {10.1007/s00521-022-07592-9},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21089-21100},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multistability analysis of switched fractional-order recurrent neural networks with time-varying delay},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recognition algorithm for deep convective clouds based on
FY4A. <em>NCA</em>, <em>34</em>(23), 21067–21088. (<a
href="https://doi.org/10.1007/s00521-022-07590-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The short-term heavy rainfalls, thunderstorm gales, hail, squall lines, tornadoes, thunderstorms and other disastrous weather caused by deep convective clouds greatly threaten social and economic activities and the safety of people’s lives and property. Therefore, it is of great value to study the recognition methods of deep convective clouds in the field of the weather forecast. Since deep convective clouds are characterized by a short life cycle, small spatial scale and complex structure, it is difficult to accurately monitor and identify deep convective clouds by traditional ground monitoring methods. In this paper, the semantic segmentation network SCNET based on attention mechanism was proposed and a deep learning network for the recognition of deep convective clouds was established with infrared and brightness temperature channels of FY4A stationary meteorological satellites as input features. The results showed that SCNET has a better recognition effect than meteorological and machine learning methods, such as single-band threshold method, SVM, NN, UNET and RESNET, and can effectively improve the recognition accuracy of deep convective clouds},
  archive      = {J_NCA},
  author       = {Li, Tao and Wu, Di and Wang, Lina and Yu, Xiaofeng},
  doi          = {10.1007/s00521-022-07590-x},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21067-21088},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recognition algorithm for deep convective clouds based on FY4A},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Plant leaf disease classification using deep attention
residual network optimized by opposition-based symbiotic organisms
search algorithm. <em>NCA</em>, <em>34</em>(23), 21049–21066. (<a
href="https://doi.org/10.1007/s00521-022-07587-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main obstacle in front of the sustainable development of the agricultural sector is the considerable amount of economic loss due to reduced food production because of plant diseases. Computer-aided diagnosis of plant health conditions has paved its way in recent times by employing deep learning techniques especially convolutional neural networks (CNNs). The existing techniques mainly attained high classification accuracy if the images are captured in laboratory environments. Application on real world in-field images reduces their accuracy level significantly. To overcome the above shortcoming, this article merged the attention learning mechanism with the residual learning blocks and used the attention residual learning (ARL) mechanism for discriminative feature extraction from the RGB images of plant leaves. By employing the ARL strategy in the standard ResNet-50 CNN model, a new CNN module named AResNet-50 is designed for successful leaf disease recognition. Further, to reduce the chance of accuracy decrement due to erroneous choice of the training hyperparameters, Opposition-based Symbiotic Organisms Search (OSOS) algorithm is implemented for optimizing the values of learning rate and momentum during the training process. The efficacy of the proposed optimally tuned attention residual learning network, OSOS-AResNet-50, is checked on a leaf database created by the authors. Fifteen health conditions of citrus, guava, mango, and eggplant leaves are identified from their RGB images captured in real world or practical environment. The obtained classification accuracy is 98.20\%. The experimental outcome reveals the superiority of OSOS-AResNet-50 over existing standard and largely used CNN models like AlexNet, VGG-16, VGG-19 and ResNet-50. Further, investigations disclose the importance of optimal training hyperparameter tuning and shows that approximately 2\% more accuracy can be obtained by finding optimal values of learning rate and momentum with the help of OSOS.},
  archive      = {J_NCA},
  author       = {Pandey, Akshay and Jain, Kamal},
  doi          = {10.1007/s00521-022-07587-6},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21049-21066},
  shortjournal = {Neural Comput. Appl.},
  title        = {Plant leaf disease classification using deep attention residual network optimized by opposition-based symbiotic organisms search algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved ZND model for solving dynamic linear complex matrix
equation and its application. <em>NCA</em>, <em>34</em>(23),
21035–21048. (<a
href="https://doi.org/10.1007/s00521-022-07581-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The online solving of a dynamic linear complex matrix equation (DLCME) is commonly encountered in many fields, and it exists for lots of engineering applications. For solving the DLCME, the gradient neural dynamics (GND) and the zeroing neural dynamics (ZND) are usually designed based on a predefined error function in scalar or matrix form to monitor the residual error convergence, respectively. In this paper, in order to improve the adaptability as the residual error decreasing with time and to release the limitation of convex activation function, an improved zeroing neural dynamics (IZND) model is proposed with a residual-based adaptive coefficient and a non-convex activation function. By using the Lyapunov stability theory, the global convergence and noise suppression of the proposed IZND model are theoretically discussed under the noise-free and noise-perturbed circumstances. Then, simulative verifications and a dynamic acoustic source localization application illustrate the efficacy and superiority of the proposed model for solving the DLCME. Comparing with some existing GND and ZND models, the proposed IZND model shows advanced performance in solution accuracy, noise suppression and convergence rate.},
  archive      = {J_NCA},
  author       = {Song, Zhiyuan and Lu, Zhenyao and Wu, Jiahao and Xiao, Xiuchun and Wang, Guancheng},
  doi          = {10.1007/s00521-022-07581-y},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21035-21048},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved ZND model for solving dynamic linear complex matrix equation and its application},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transfer learning through perturbation-based in-domain
spectrogram augmentation for adult speech recognition. <em>NCA</em>,
<em>34</em>(23), 21015–21033. (<a
href="https://doi.org/10.1007/s00521-022-07579-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of numerous frameworks and pedagogical practices has significantly improved the performance of deep learning-based speech recognition systems in recent years. The task of developing automatic speech recognition (ASR) in indigenous languages becomes enormously complex due to the wide range of auditory and linguistic components due to a lack of speech and text data, which has a significant impact on the ASR system&#39;s performance. The main purpose of the research is to effectively use in-domain data augmentation methods and techniques to resolve the challenges of data scarcity, resulting in an increased neural network consistency. This research further goes into more detail about how to create synthetic datasets via pooled augmentation methodologies in conjunction with transfer learning techniques, primarily spectrogram augmentation. Initially, the richness of the signal has been improved through the process of deformation of the time and/or the frequency axis. The time-warping aims to deform the signal&#39;s envelope, whereas frequency-warping alters spectral content. Second, the raw signal is examined using audio-level speech perturbation methods such as speed and vocal tract length perturbation. These methods are shown to be effective in addressing the issue of data scarcity while having a low implementation cost, making them simple to implement. Nevertheless, these methods have the effect of effectively increasing the dataset size because multiple versions of a single input are fed into the network during training, likely to result in overfitting. Consequently, an effort has been made to solve the problem of data overfitting by integrating two-level augmentation procedures via pooling of prosody/spectrogram modified and original speech signals using transfer learning techniques. Finally, the adult ASR system was experimented on using deep neural network (DNN) with concatenated feature analysis employing Mel-frequency cepstral coefficients (MFCC), pitch features, and the normalization technique of Vocal Tract Length Normalization (VTLN) on pooled Punjabi datasets, yielding a relative improvement of 41.16 percent in comparison with the baseline system.},
  archive      = {J_NCA},
  author       = {Kadyan, Virender and Bawa, Puneet},
  doi          = {10.1007/s00521-022-07579-6},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {21015-21033},
  shortjournal = {Neural Comput. Appl.},
  title        = {Transfer learning through perturbation-based in-domain spectrogram augmentation for adult speech recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient two-stage water cycle algorithm for complex
reliability-based design optimization problems. <em>NCA</em>,
<em>34</em>(23), 20993–21013. (<a
href="https://doi.org/10.1007/s00521-022-07574-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reliability-based design optimization (RBDO) problem considers the necessary uncertainty of measurements within the scope of planning to minimize the design objective while satisfying probabilistic constraints. Metaheuristic algorithms offer effective tools to address challenges that scientists and practitioners face in RBDO problems, including the use of multimodal objective functions, mixed design variables, and nondifference mathematical models. However, metaheuristic reliability-based design optimization (MRBDO) algorithms require reliability analysis to obtain accurate solutions, which leads to different convergence behaviors than those observed for gradient RBDO algorithms. One of the main drawbacks of such schemes is the high computational cost. In this work, we derive an error propagation rule from the inner reliability analysis to the outer optimization. Then, based on a two-stage water cycle algorithm (TSWCA), an improved MRBDO algorithm called TSWCA-MRBDO is developed to ensure universality and performance. In the proposed algorithm, the water cycle algorithm, with a global capacity, is used to find the best solution. A single-loop strategy is first adopted, in which the MRBDO problem is converted into the deterministic optimization problem to remarkably reduce the computational time of global search. Then, a two-stage algorithm is utilized to perform the local search. Numerical examples demonstrate that the proposed two-stage MRBDO algorithm can converge more quickly and efficiently in the global and local domains than other MRBDO algorithms.},
  archive      = {J_NCA},
  author       = {Meng, Zeng and Li, Hao and Zeng, Runqian and Mirjalili, Seyedali and Yıldız, Ali Rıza},
  doi          = {10.1007/s00521-022-07574-x},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20993-21013},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient two-stage water cycle algorithm for complex reliability-based design optimization problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid algorithm based on tabu search and generalized
network algorithm for designing multi-objective supply chain networks.
<em>NCA</em>, <em>34</em>(23), 20973–20992. (<a
href="https://doi.org/10.1007/s00521-022-07573-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, substantial progress has been made in developing efficient algorithms for solving combinatorial optimization problems. In this paper, following this direction, the problem of designing supply chains which is an important combinatorial optimization problem is considered. The structural properties of supply chain models are investigated to transform such models into a generalized network optimization model. The transformation to a generalized network optimization model reduces the algorithms&#39; solution time. Moreover, this paper proposes a new efficient hybrid algorithm based on tabu search and generalized network simplex algorithm (GN-TSA) for designing multi-objectives supply chain models. The developed algorithm&#39;s parameters are tuned properly, validated, and evaluated. The algorithm&#39;s performance is then compared to an exact algorithm embedded in the General Algebraic Modeling System (GAMS) and two metaheuristic algorithms, namely a linear programming simplex algorithm integrated with the tabu search approach (LP-TSA) and simulated annealing. The findings indicated that the GN-TSA obtains solutions very close to the exact algorithm with less computation time. In addition, the proposed algorithm outperforms the LP-TSA and simulated annealing in terms of computation time, while the quality of the solutions is the same as solutions obtained by LP-TSA and better than simulated annealing. On average, the results revealed that the reduction in computational time is more than 26.30\% using GN-TSA compared to LP-TSA and simulated annealing.},
  archive      = {J_NCA},
  author       = {Mohammed, Awsan and Duffuaa, Salih O.},
  doi          = {10.1007/s00521-022-07573-y},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20973-20992},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid algorithm based on tabu search and generalized network algorithm for designing multi-objective supply chain networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic evolutionary data and text document clustering
approach using improved aquila optimizer based arithmetic optimization
algorithm and differential evolution. <em>NCA</em>, <em>34</em>(23),
20939–20971. (<a
href="https://doi.org/10.1007/s00521-022-07571-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data and text clustering are popular and frequently used in the data mining domain, mainly to deal with big data analytics. The main problem in these techniques is finding the most coherent clusters allocating similar-related objects into one group. In this paper, an improved clustering analysis approach is proposed using an advanced optimization method called AOAOA. The proposed AOAOA method improved the Aquila optimizer (AO) search performance by the operators of the arithmetic optimization algorithms (AOA) and differential evolution (DE) and using a novel transition mechanism. The primary motivation for this modification is that the original optimizer suffers from local optima stagnation and lacks search balance. Thus, the proposed AOAOA overcame these shortcomings by integrating various powerful search strategies and a new update strategy. Experiments are conducted on two parts; eight standard data clustering datasets and ten text documents benchmark datasets to evaluate the performance of the proposed AOAOA method. The proposed method is compared against several well-known optimization algorithms and advanced state-of-the-art methods published in the literature. The data clustering results also showed promising performance for the proposed AOAOA compared to other comparative data clustering methods. Moreover, the results illustrated that the proposed AOAOA can find new best solutions for several different complicated cases as the text document clustering results. The proposed AOAOA got accurate and robust results compared to several state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Abualigah, Laith and Almotairi, Khaled H},
  doi          = {10.1007/s00521-022-07571-0},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20939-20971},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic evolutionary data and text document clustering approach using improved aquila optimizer based arithmetic optimization algorithm and differential evolution},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel genetic algorithm-based approach for compression and
acceleration of deep learning convolution neural network: An application
in computer tomography lung cancer data. <em>NCA</em>, <em>34</em>(23),
20915–20937. (<a
href="https://doi.org/10.1007/s00521-022-07567-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) models are computationally expensive in space and time, which makes it difficult to deploy DL models in edge computing devices, such as Raspberry-Pi or Jetson Nano. The current strategy uses genetic algorithm (GA), which compresses the deep convolution neural network models without compromising performance. GA was applied by converting the CNN layers into binary vectors. Further, the fitness function in GA was computed based on (i) the minimization of hidden units and (ii) test accuracy. The GA-based strategy was applied on different pre-trained architectures, namely AlexNet, VGG16, SqueezeNet, and ResNet50, respectively, by using three kinds of datasets, namely MNIST, CIFAR-10, and CIFAR-100. The proposed approach demonstrated the reduction in the storage space of AlexNet by 87.62\%, 80.97\%, and 86.20\% corresponding to the datasets MNIST, CIFAR-10, and CIFAR-100, respectively. Further, for the same three datasets, namely VGG16, ResNet50, and SqueezeNet, the system average compression was 91.15\%, 78.42\%, and 38.40\%, respectively. In addition to that, the inference time of the models using proposed strategy was significantly improved with an average of the four datasets of ~ 35.61\%, 9.23\%, 73.76\%, and 79.93\% corresponding to AlexNet, SqueezeNet, ResNet50, and VGG16 models. Further, our method when applied to the proposed CNN using the LIDC-IDRI dataset showed a 90.3\% reduction in the storage space and inference time. DL system when optimized using GA shows improved performance in both storage and execution time.},
  archive      = {J_NCA},
  author       = {Skandha, Sanagala S. and Agarwal, Mohit and Utkarsh, Kumar and Gupta, Suneet K. and Koppula, Vijaya K. and Suri, Jasjit S.},
  doi          = {10.1007/s00521-022-07567-w},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20915-20937},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel genetic algorithm-based approach for compression and acceleration of deep learning convolution neural network: An application in computer tomography lung cancer data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated classification of emphysema using data
augmentation and effective pixel location estimation with multi-scale
residual network. <em>NCA</em>, <em>34</em>(23), 20899–20914. (<a
href="https://doi.org/10.1007/s00521-022-07566-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern medical diagnosis also, the emphysema is still recognized by the computed tomography (CT) scans with a set of defined patterns as a classification problem in computer vision. There were as many algorithms developed in the past that attempt to classify the underlying patterns and their relevant associated clusters by modeling an automated system. And this classification modeling approach is responsible for the benchmarking classification and quantification of various emphysematous tissues from lung CT images on different scales in the literature. Hence, with the same motivation and intents, this article put forth a multiscale residual network with data augmentation model (MS-ResNet-DA). First, a generative adversarial network (GAN) is employed to augment the training samples and avoid the overfitting problem. These images are again augmented based on different image processing methods. Then, the obtained images are learned by MS-ResNet to categorize the emphysema. Still, the accuracies of categorizing the centrilobular emphysema (CLE) and panlobular emphysema (PLE) are not satisfactory because they do not have spatial dependence. So, an enhanced MS-ResNet-DA (EMS-ResNet-DA) model is proposed, which applies an effective position estimation algorithm to measure relative and absolute location data of emphysema pixels in the images. The relative location data give the current location of the emphysema pixel by extracting the relative dislocation measures from CT images. Also, the absolute location estimation model is based on the position encoding network to match the diseased image with the reference emphysema images and validate whether location data are implicitly learned when trained on categorical labels. Moreover, these location data of all pixels in the images are learned by the MS-ResNet for emphysema classification. Finally, the experimental results demonstrated that the EMS-ResNet-DA achieves an overall classification accuracy of 94.6\% that outclasses the conventional models.},
  archive      = {J_NCA},
  author       = {Manikandan, T. and Maheswari, S.},
  doi          = {10.1007/s00521-022-07566-x},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20899-20914},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated classification of emphysema using data augmentation and effective pixel location estimation with multi-scale residual network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). INNA: An improved neural network algorithm for solving
reliability optimization problems. <em>NCA</em>, <em>34</em>(23),
20865–20898. (<a
href="https://doi.org/10.1007/s00521-022-07565-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main objective of this paper is to present an improved neural network algorithm (INNA) for solving the reliability-redundancy allocation problem (RRAP) with nonlinear resource constraints. In this RRAP, both the component reliability and the redundancy allocation are to be considered simultaneously. Neural network algorithm (NNA) is one of the newest and efficient swarm optimization algorithms having a strong global search ability that is very adequate in solving different kinds of complex optimization problems. Despite its efficiency, NNA experiences poor exploitation, which causes slow convergence and also restricts its practical application of solving optimization problems. Considering this deficiency and to obtain a better balance between exploration and exploitation, searching procedure for NNA is reconstructed by implementing a new logarithmic spiral search operator and the searching strategy of the learner phase of teaching–learning-based optimization (TLBO) and an improved NNA has been developed in this paper. To demonstrate the performance of INNA, it is evaluated against seven well-known reliability optimization problems and finally compared with other existing meta-heuristics algorithms. Additionally, the INNA results are statistically investigated with the Wilcoxon sign-rank test and Multiple comparison test to show the significance of the results. Experimental results reveal that the proposed algorithm is highly competitive and performs better than previously developed algorithms in the literature.},
  archive      = {J_NCA},
  author       = {Kundu, Tanmay and Garg, Harish},
  doi          = {10.1007/s00521-022-07565-y},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20865-20898},
  shortjournal = {Neural Comput. Appl.},
  title        = {INNA: An improved neural network algorithm for solving reliability optimization problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leveraging greater relations for improving multi-choice
reading comprehension. <em>NCA</em>, <em>34</em>(23), 20851–20864. (<a
href="https://doi.org/10.1007/s00521-022-07561-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remarkable success has been achieved in the last few years on machine reading comprehension tasks. In previous works, long-range dependencies were captured by explicitly attending to all the tokens and modeling the relations between the question and each sentence. However, a great deal of important information regarding token-level and sentence-level relations in the passage, which are useful to infer the answer, were ignored in these works. We observed that the contextual information between the token-level and sentence-level in the same passage plays a vital role in reading comprehension tasks. To address this problem, we proposed a multi-stage maximization attention (MMA) network, which is used to capture the important relations in the passage from different levels of granularity at its hierarchical nature. By utilizing MMA as a module, we integrated two sentence-level question-aware matching mechanisms to infer the answer: (1) Co-matching is used to match the passage with the question and the candidate answer. (2) Sentence-level hierarchical attention is used to identify the importance of sentences conditioned on the question and the option. In addition, inspired by how humans solve multi-choice reading comprehension questions, the passage sentence selection strategy is fused into our model to select the most salient sentences to guide the model to infer the answer. The proposed model is evaluated on three multi-choice reading comprehension datasets RACE, Dream and MultiRC. Significance tests demonstrated the improvement of existing MRC models. A series of analyses were also conducted to interpret the effectiveness of the proposed model.},
  archive      = {J_NCA},
  author       = {Yan, Hong and Liu, Lijun and Feng, Xupeng and Huang, Qingsong},
  doi          = {10.1007/s00521-022-07561-2},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20851-20864},
  shortjournal = {Neural Comput. Appl.},
  title        = {Leveraging greater relations for improving multi-choice reading comprehension},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive enhanced infrared and visible image fusion using
hybrid decomposition and coupled dictionary. <em>NCA</em>,
<em>34</em>(23), 20831–20849. (<a
href="https://doi.org/10.1007/s00521-022-07559-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion aims to highlight the prominent infrared target while containing the valuable texture details as much as possible. However, visible images are susceptible to the environment, especially the low-illumination environment, which will seriously affect the quality of the fused image. To solve this problem, an adaptive enhanced infrared and visible image fusion algorithm based on hybrid $$\ell_{1} { - }\ell_{{0}}$$ layer decomposition model and coupled dictionary is proposed (we termed the proposed method as AEFusion). First, the visible image is adaptively enhanced according to the actual situation. Then a novel fusion scheme based on coupled dictionary and $$\ell_{{1}} { - }\ell_{{0}}$$ pyramid is proposed to obtain the pre-fusion image, to further highlight the significant information, we set the pre-fusion image as the benchmark to obtain the weight map which is used to fuse the final fused detail layer. Qualitative and quantitative experimental results demonstrate that the proposed method is superior to 11 state-of-the-art image fusion methods as more valuable texture information and prominent infrared targets are preserved by the AEFusion, which is beneficial to target detection and tracking tasks. Our code is publicly available at: https://github.com/VCMHE/IRfusion .},
  archive      = {J_NCA},
  author       = {Yin, Wenxia and He, Kangjian and Xu, Dan and Luo, Yueying and Gong, Jian},
  doi          = {10.1007/s00521-022-07559-w},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20831-20849},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive enhanced infrared and visible image fusion using hybrid decomposition and coupled dictionary},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MOAVOA: A new multi-objective artificial vultures
optimization algorithm. <em>NCA</em>, <em>34</em>(23), 20791–20829. (<a
href="https://doi.org/10.1007/s00521-022-07557-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a multi-objective version of the artificial vultures optimization algorithm (AVOA) for a multi-objective optimization problem called a multi-objective AVOA (MOAVOA). The inspirational concept of the AVOA is based on African vultures&#39; lifestyles. Archive, grid, and leader selection mechanisms are used for developing the MOAVOA. The proposed MOAVOA algorithm is tested oneight real-world engineering design problems and seventeen unconstrained and constrained mathematical optimization problems to investigates its appropriateness in estimating Pareto optimal solutions. Multi-objective particle swarm optimization, multi-objective ant lion optimization, multi-objective multi-verse optimization, multi-objective genetic algorithms, multi-objective salp swarm algorithm, and multi-objective grey wolf optimizer are compared with MOAVOA using generational distance, inverted generational distance, maximum spread, and spacing performance indicators. This paper demonstrates that MOAVOA is capable of outranking the other approaches. It is concluded that the proposed MOAVOA has merits in solving challenging multi-objective problems.},
  archive      = {J_NCA},
  author       = {Khodadadi, Nima and Soleimanian Gharehchopogh, Farhad and Mirjalili, Seyedali},
  doi          = {10.1007/s00521-022-07557-y},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20791-20829},
  shortjournal = {Neural Comput. Appl.},
  title        = {MOAVOA: A new multi-objective artificial vultures optimization algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A vision-based inventory method for stacked goods in
stereoscopic warehouse. <em>NCA</em>, <em>34</em>(23), 20773–20790. (<a
href="https://doi.org/10.1007/s00521-022-07551-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inventory of stacked goods in the stereoscopic warehouse is important for modern logistics. Currently, this inventory task is completed by counting manually. With the advance of industry 4.0 and deep learning technology, automatic inventory based on machine vision comes true, greatly saving labor and material costs. In this work, we firstly collected WSGID, an image dataset about wine boxes stacked in a stereoscopic winey warehouse. Moreover, we presented an automatic inventory method based on machine vision, consisting of a stacked goods surface detecting model and a prior-based quantity calculating algorithm. To get a better detecting performance, we introduced STCNet, an improved detection network based on Swin Transformer. The final results of 86.7 mAP, 82.8 mAP, and 85.9 mAP on three sub-datasets are achieved and are higher than the baselines. To count the quantity of goods after detection, we proposed an adaptive and robust calculating algorithm. Our method got an accuracy of 85.71 on the largest sub-dataset. Extensive experiments on the WSGID and COCO benchmark demonstrate the effectiveness of our approach. Our work indicates that the machine vision method successfully facilitates inventory for stacked goods in the stereoscopic warehouse.},
  archive      = {J_NCA},
  author       = {Yin, Haonan and Chen, Chuanjun and Hao, Chaofan and Huang, Biqing},
  doi          = {10.1007/s00521-022-07551-4},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20773-20790},
  shortjournal = {Neural Comput. Appl.},
  title        = {A vision-based inventory method for stacked goods in stereoscopic warehouse},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantic segmentation of chemical plumes from airborne
multispectral infrared images using u-net. <em>NCA</em>,
<em>34</em>(23), 20757–20771. (<a
href="https://doi.org/10.1007/s00521-022-07550-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The United States Environmental Protection Agency Airborne Spectral Photometric Environmental Collection Technology program provides infrared (IR) remote sensing capabilities from an aircraft platform to assist first responders in managing chemical releases into the atmosphere. One of the instruments used is a downward-looking eight-band multispectral imaging system that receives the upwelling IR radiance from the ground and atmosphere below the aircraft. Volatile organic compounds absorb and emit IR radiation at characteristic wavelengths and produce unique signatures in the imaging data. To automate the detection of chemical plumes, this research applied a deep learning-based semantic segmentation model on multispectral images collected during controlled releases of methanol. A U-Net model was developed for this application, and multiple experiments were conducted to optimize the model. Issues studied included the use of a temperature and emissivity separation algorithm to suppress temperature effects, a custom normalization method to reduce scene composition variance, experiments to shrink the network architecture, and evaluation of the utility of data augmentation. The optimized U-Net model was able to detect the plume area in images collected across different temperatures and locations while achieving false detection rates &lt; 0.02\%. The U-Net model exhibited an improved ability to discriminate methanol plumes from other scene elements such as buildings and roads when compared to the performance of shallow neural networks studied in previous work.},
  archive      = {J_NCA},
  author       = {Chen, Zizi and Small, Gary W.},
  doi          = {10.1007/s00521-022-07550-5},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20757-20771},
  shortjournal = {Neural Comput. Appl.},
  title        = {Semantic segmentation of chemical plumes from airborne multispectral infrared images using U-net},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). To learn or not to learn? Evaluating autonomous, adaptive,
automated traders in cryptocurrencies financial bubbles. <em>NCA</em>,
<em>34</em>(23), 20715–20756. (<a
href="https://doi.org/10.1007/s00521-022-07543-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial bubbles represent a severe problem for investors. In particular, the cryptocurrency market has witnessed the bursting of different bubbles in the last decade, which in turn have had spillovers on all the markets and real economies of countries. These kinds of markets and their unique characteristics are of great interest to researchers. Generally, investors and financial operators study market trends to understand when bubbles might occur using technical analysis tools. Such tools, which have been historically used, resulted in being precious allies at the basis of more advanced systems. In this regard, different autonomous, adaptive and automated trading agents have been introduced in the literature to study several kinds of markets. Among these, we can distinguish between agents with Zero/Minimal Intelligence (ZI/MI) and Computational Intelligence (CI)-based agents. The first ones typically trade on the market without resorting to complex learning strategies; the second ones usually use (deep) reinforcement learning mechanisms. However, these trading agents have never been tested on the cryptocurrencies market and related financial bubbles, which are still mostly overlooked in the literature. It is unclear how these agents can make profits/losses before, during, and after a bubble to adjust their strategy and avoid critical situations. This paper compares a broad set of trading agents (between ZI/MI and CI ones) and evaluates them with well-known financial indicators (e.g., volatility, returns Sharpe ratio, drawdown, Sortino and Omega ratio). Among the experiment’s outcomes, ZI/MI agents were more explainable than CI ones. Based on the results obtained above, we introduce GGSMZ, a trading agent relying on a neuro-fuzzy mechanism. The neuro-fuzzy system is able to learn from the trades performed by the agents adopted in the previous stage. GGSMZ’s performances overcome those of other tested agents. We argue that GGSMZ could be used by investors as a decision support tool.},
  archive      = {J_NCA},
  author       = {Guarino, Alfonso and Grilli, Luca and Santoro, Domenico and Messina, Francesco and Zaccagnino, Rocco},
  doi          = {10.1007/s00521-022-07543-4},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20715-20756},
  shortjournal = {Neural Comput. Appl.},
  title        = {To learn or not to learn? evaluating autonomous, adaptive, automated traders in cryptocurrencies financial bubbles},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Calliar: An online handwritten dataset for arabic
calligraphy. <em>NCA</em>, <em>34</em>(23), 20701–20713. (<a
href="https://doi.org/10.1007/s00521-022-07537-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Calligraphy is an essential part of the Arabic heritage and culture. It has been used in the past for the decoration of houses and mosques. Usually, such calligraphy is designed manually by experts with aesthetic insights. In the past few years, there has been a considerable effort to digitize such type of art by either taking a photograph of decorated buildings or drawing them using digital devices. The latter is considered an online form where the drawing is tracked by recording the apparatus movement, an electronic pen, for instance, on a screen. In the literature, there are many offline datasets with diverse Arabic styles for calligraphy. However, there is no available online dataset for Arabic calligraphy. In this paper, we illustrate our approach for collecting and annotating an online dataset for Arabic calligraphy called Calliar, which consists of 2,500 sentences. Calliar is annotated for stroke, character, word, and sentence-level prediction. We also propose various baseline models for the character classification task. The results we achieved highlight that it is still an open problem.},
  archive      = {J_NCA},
  author       = {Alyafeai, Zaid and Al-shaibani, Maged S. and Ghaleb, Mustafa and Al-Wajih, Yousif Ahmed},
  doi          = {10.1007/s00521-022-07537-2},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20701-20713},
  shortjournal = {Neural Comput. Appl.},
  title        = {Calliar: An online handwritten dataset for arabic calligraphy},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fine-tuning with local learning rules helps to compress and
accelerate spiking neural networks without accuracy loss. <em>NCA</em>,
<em>34</em>(23), 20687–20700. (<a
href="https://doi.org/10.1007/s00521-022-07513-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) are believed to be highly energy- and computationally efficient machine learning algorithms, especially when implemented on neuromorphic hardware. Some recent studies have revealed that lateral (intralayer) inhibitory connectivity is necessary for effective and stable learning of SNNs. However, for large-scale SNNs, lateral inhibitory connections require an additional large amount of calculations. This negatively affects both the SNN inference time and the size of required computing resources. In this study, we propose a fine-tuning procedure using original local learning rules, called FEELING, to be applied to the weights of interneuron sublayer, which is introduced for organizing more efficient competition between excitatory neurons. At the same time, the initialization of interneuron weight values is implemented by singular value decomposition of intralayer inhibitory weight matrix characterizing the original SNN architecture before optimization. The proposed procedure allows to compress and accelerate large-scale SNNs with lateral inhibition in the layers, alongside with maintenance of their recognition accuracy, as it is shown on MNIST dataset. We demonstrate that this new optimization technique is superior to simple pruning of inhibitory connections, even also followed by fine-tuning. Moreover, this method of fine-tuned decomposition suggests the association of excitatory and inhibitory functions to two different sublayers of neurons, as it is naturally observed in a biological neural system. We hope that findings of this study not only reveal some new aspects of the effective computation and bio-plausible architecture for SNNs but also assume a hypothetic reason for the evolutionary preference of inhibitory neurons over inhibitory connections.},
  archive      = {J_NCA},
  author       = {Nekhaev, D. V. and Demin, V. A.},
  doi          = {10.1007/s00521-022-07513-w},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20687-20700},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fine-tuning with local learning rules helps to compress and accelerate spiking neural networks without accuracy loss},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Frequency control of hybrid microgrid comprising solid oxide
fuel cell using hunger games search. <em>NCA</em>, <em>34</em>(23),
20671–20686. (<a
href="https://doi.org/10.1007/s00521-022-07512-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a novel hunger games search (HGS) based on specular reflection-based learning (SRL) and dynamic quasi-opposition-based learning (DQOL), named HGS_RQ, for improving the optimization performance of the classical HGS while dealing with load frequency control task. By these learnings, a fitter solution can be generated whether by SRL or DQOL and therefore, the quality of the best solution can be refined. The effectiveness of the proposed HGS_RQ is demonstrated and validated on two-area interconnected power system with considering nonlinearity effect of governor dead band. Additional supplementary controller is proposed to reinforce frequency regulation through solid oxide fuel cell. The objective function is adapted to minimize the integral time absolute error in frequency deviations and tie line power. The efficacy and superiority are affirmed by the comparisons with some of prominent recent methods. It can be noted that the adequate response is proved, since the maximum frequency deviation is 0.088 Hz, the settling time is about 2 s, and the steady-state frequency change is zero in the two areas. On the other hand, there is a significant reduction in tie line power transient response with maximum deviation of 1.318\% for the studied cases. Furthermore, the statistical measures and analysis of variance test are analyzed to exhibit the superior performance of the HGS_RQ in terms of accuracy and reliability.},
  archive      = {J_NCA},
  author       = {El-Hameed, Mohamed A. and Rizk-Allah, Rizk M. and El-Fergany, Attia A.},
  doi          = {10.1007/s00521-022-07512-x},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20671-20686},
  shortjournal = {Neural Comput. Appl.},
  title        = {Frequency control of hybrid microgrid comprising solid oxide fuel cell using hunger games search},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatiotemporal grid-based crash prediction—application of a
transparent deep hybrid modeling framework. <em>NCA</em>,
<em>34</em>(23), 20655–20669. (<a
href="https://doi.org/10.1007/s00521-022-07511-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic crashes are one of the significant causes of death worldwide, and the prediction of this event is complicated due to many contributing factors. This study used spatial, temporal, and spatiotemporal information to predict crashes in Chicago at 1 km grid levels. A Deep Hybrid Network (DHN) was developed by exploiting inherent unique characteristics of Convolution Neural Network (CNN), Long Short-term Memory (LSTM), and Deep Neural Network (DNN). The hyperparameters of the models were obtained through the Bayesian optimization algorithm. The proposed modeling framework investigated the feature importance, the spatial heterogeneity of predictions, the worst-performing spatial grids, and the spatial distribution of features pertinent to model performance. These analyses transform the proposed DHN into an interpretable and transparent model. The DHN model was compared with Logistic Regression (LR), DNN, CNN, LSTM, and bidirectional LSTM, and it outperformed the baseline models with an accuracy of 0.72, recall of 0.70, false alarm rate of 0.28, and AUC of 0.79. The top three essential features were time, weather, and taxi trips, consecutively. The grid-level distribution of prediction performance investigations revealed a consistent performance of all deep learning models in terms of failed grids (i.e., AUC is 0.5 or less). It was revealed that DHN has the fewest failed grids (i.e., 18 failed from 710 grids) among the experimented models. According to the district level analysis, the O’hare airport area and the central district had the fewest number of failed grids for all methods, while the far south district had the highest number of failed grids. In addition, it was observed that the passed grid had a higher average feature density than the failed grid.},
  archive      = {J_NCA},
  author       = {Kashifi, Mohammad Tamim and Al-Sghan, Ibrahim Yousif and Rahman, Syed Masiur and Al-Ahmadi, Hassan Musaed},
  doi          = {10.1007/s00521-022-07511-y},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20655-20669},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatiotemporal grid-based crash prediction—application of a transparent deep hybrid modeling framework},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gaussian-based probability fusion for person
re-identification with taylor angular margin loss. <em>NCA</em>,
<em>34</em>(23), 20639–20653. (<a
href="https://doi.org/10.1007/s00521-022-07496-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (ReID) aims to match the specific pedestrians in the public environment with cross-domain cameras. Posture change, occlusion, and viewpoint change complicate ReID. Representation learning and metric learning have been focused on in previous researches as a key to solving the problem of ReID task by adaptive learning emphasized character feature representation. This paper proposed a Gaussian-based probability fusion mechanism and an improved Taylor Angular Margin softmax loss function, that the methods can be joined to learn more discriminative features and then better embedding space with categories weights. Different from the existing network attention intervention methods that by guided measurement quality fuse with prediction, the probability fusion structure can generate fine-grained recognition features via attention learning, and then send these features into the proposed Taylor angular margin loss. This proposed loss can push the inter-class margin and mining the intra-class variance for more effective performance. Massive experiments on Market-1501, DukeMTMC-reID, and MSMT17 show predominant performance promotion. It achieves 90.5\% mAP and 96.4\% Rank-1 on Market-1501, 80.5\% mAP and 89.8\% Rank-1 on DukeMTMC-reID 59.7\% mAP and 82.5\% Rank-1 on MSMT17. Moreover, excellent improvements are shown on occlusion datasets, 55.6\% mAP and 65.1\% Rank-1 on Occluded-DukeMTMC, 74.8\% mAP and 80.5\% Rank-1 on Occluded-ReID.},
  archive      = {J_NCA},
  author       = {Huang, Zhiyong and Guan, Tianhui and Qin, Wencheng and Yu, Zhi and Tahsin, Lamia and Sun, Daming},
  doi          = {10.1007/s00521-022-07496-8},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20639-20653},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gaussian-based probability fusion for person re-identification with taylor angular margin loss},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural network-based error handler in natural language
processing. <em>NCA</em>, <em>34</em>(23), 20629–20638. (<a
href="https://doi.org/10.1007/s00521-022-07489-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grammar checking is one of the important applications of Natural Language Processing. Though the work in this area has been started decades before, the requirement of full-fledged grammar checking is still a demanding task. The recent revolution of Internet requires the computers not only deal with English Language but also in regional languages. People, who do not know English, tend to interact with computers through their regional language. Tamil is one such regional language which is recognized as classical (Semmozhi) language. Grammar checker application has been implemented for languages like English, Urdu, Punjabi, etc. But as far as Tamil is concerned, grammar checker is very scarce. There are many approaches to develop a grammar checker application. It can be statistical based, rule based or deep learning based. The proposed method involves hybrid approach to develop a Tamil grammar checker as Tamil has lot of grammatical features. In the proposed work, we concentrated on spell checking, consonant (Punarchi) error handling, long component letter error and subject–verb agreement errors. To tackle all these errors, combination of neural network approach as well as rule-based approach is proposed in this paper.},
  archive      = {J_NCA},
  author       = {Anbukkarasi, S. and Varadhaganapathy, S.},
  doi          = {10.1007/s00521-022-07489-7},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20629-20638},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural network-based error handler in natural language processing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rubber tapping line detection in near-range images via
customized YOLO and u-net branches with parallel aggregation heads
convolutional neural network. <em>NCA</em>, <em>34</em>(23),
20611–20627. (<a
href="https://doi.org/10.1007/s00521-022-07475-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current convolutional neural network structures for image-related tasks lean toward directed acyclic graphs with multiple output nodes. This enables a solution for the rubber tapping line detection that desires various output types, such as bounding boxes, points in pixels, or edges. This paper demonstrates multibranch deep convolutional networks whose outputs are bounding boxes and pixel segmentation masks by adopting YOLOv3 and U-Net structures. This paper proposes the functions of column-wise argmax and column-wise Softmax with redundant mask outputs intended to enhance pixel classification accuracy. Experiments with the networks discovered some novel segmentation loss functions, such as Dice’s coefficient, Focal, and Tversky’s index, having different characters for the tapping line prediction, which were observed by Hausdorff distance and F1-score. The network with multiple mask predictions can omit their weaknesses and yield higher tapping line detection accuracy compared to every single one. In the context of image processing, the column-wise Softmax and argmax algorithms were superior to the edge-thinning algorithm for detecting line vertices.},
  archive      = {J_NCA},
  author       = {Wongtanawijit, Rattachai and Khaorapapong, Thanate},
  doi          = {10.1007/s00521-022-07475-z},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20611-20627},
  shortjournal = {Neural Comput. Appl.},
  title        = {Rubber tapping line detection in near-range images via customized YOLO and U-net branches with parallel aggregation heads convolutional neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scenario-based optimization robust model project portfolio
selection under risk considerations. <em>NCA</em>, <em>34</em>(23),
20589–20609. (<a
href="https://doi.org/10.1007/s00521-022-07434-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In project portfolio selection (PPS) management, one of the main goals is the optimal management of projects with the least risk and the highest commercial value under risk considerations. Hence, this study considers the weight of each decision criterion, their impacts, and also the uncertainty in decision making. By taking into account all those assumptions, this paper seeks to conduct a PPS with aiming of maximizing the average value as the performance of each project, the rate of development of each project and minimizing the risk of interruption in the implementation of selected projects. The strategic goal of this study is to select robust project portfolios in the long run for less replacement. Accordingly, for attaining all goals, a combined method developed in three stages of PPS; first the weight of criteria from the F-AHP method is determined, next the F-TOPSIS method is used to calculate the relative scores for the projects, and finally a scenario-based robust multi-objective mathematical programming model is considered. This paper has been encountered with two challenges and complexity which is solved by the hybrid method based on the Multi-Choice Goal Programming with Utility Function (MCGP-UF) and the particle swarm optimization (PSO) algorithm (hybrid PSO-MCGP-UF). The results show an improvement in the solution time and the quality of the responses of the proposed method, which helps decision-makers at all stages of the PPS to achieve robustness portfolios in less time.},
  archive      = {J_NCA},
  author       = {Ramedani, Amir Ali and Didehkhani, Hosein and Mehrabian, Ahmad},
  doi          = {10.1007/s00521-022-07434-8},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20589-20609},
  shortjournal = {Neural Comput. Appl.},
  title        = {Scenario-based optimization robust model project portfolio selection under risk considerations},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep q network assisted method for underwater gliders
standoff tracking to the static target. <em>NCA</em>, <em>34</em>(23),
20575–20587. (<a
href="https://doi.org/10.1007/s00521-022-07408-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater gliders lack the necessary navigation equipment and have low control performance, which deteriorate the autonomy and efficiency of the sampling. The underwater gliders standoff tracking based on the Lyapunov guidance vector fields is introduced in this work to enhance the autonomy of gliders in observing the potential static targets. To avoid designing complex control processes, we convert the standoff tracking into a Markovian decision process and introduce reinforcement learning methods to solve the task. Also, to trade-off the fast training and achieving acceptable results, we design a control framework that integrates classical controller and reinforcement learning. The simulations show that the proposed framework outperform than the comparison method. This work can provide a new pattern for the sampling control of gliders. The proposed method combining reinforcement learning with classical controller can provide a reference for other applications of reinforcement learning.},
  archive      = {J_NCA},
  author       = {Zang, Wenchuan and Yao, Peng and Lv, Kunling and Song, Dalei},
  doi          = {10.1007/s00521-022-07408-w},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20575-20587},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep q network assisted method for underwater gliders standoff tracking to the static target},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning approaches and interventions for futuristic
engineering in agriculture. <em>NCA</em>, <em>34</em>(23), 20539–20573.
(<a href="https://doi.org/10.1007/s00521-022-07744-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With shrinking natural resources and the climate challenges, it is foreseen that there will be an imminent stress in agricultural outputs. Deep learning provides immense possibilities in allowing computational models to learn representation of data generated for precise application of agricultural inputs and the smart management of outputs. This will go a long way in addressing the global food security concerns. Present study demonstrates the discriminative and predictive power of state-of-the-art deep learning approaches that have been successfully applied to the various facets of engineering in agriculture; ranging from estimation of soil moisture, water stress determination, disease detection, weed identification, agro-produce quality evaluation and more. Realization of these approaches will preclude human judgment by the underlying iterations of deep learning framework resulting in an increased precision and universality. Broader acceptance and applicability of deep learning would require inclusion of ground-truth datasets and should feature integration of mechanisms for fusion of data from multiple provenances; thus making the models robust and field worthy.},
  archive      = {J_NCA},
  author       = {Chakraborty, Subir Kumar and Chandel, Narendra Singh and Jat, Dilip and Tiwari, Mukesh Kumar and Rajwade, Yogesh A. and Subeesh, A.},
  doi          = {10.1007/s00521-022-07744-x},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20539-20573},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning approaches and interventions for futuristic engineering in agriculture},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Definition, approaches, and analysis of code duplication
detection (2006–2020): A critical review. <em>NCA</em>, <em>34</em>(23),
20507–20537. (<a
href="https://doi.org/10.1007/s00521-022-07707-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code duplication detection is the act of finding similar code in software development. It is important for software engineer to address the issues of code duplication detection. In this paper, a critical review of previous works on code duplication for code clone and plagiarism detection is performed. The review involves five main parts. Firstly, a systematic literature review is conducted to confirm the selected articles. Secondly, a critical review of different code duplication approaches is conducted based on three phases; processing, detection, and decision. Thirdly, statistical analysis of the number of review articles is performed to show the trends and hots of code duplication research. Moreover, quantitative analysis of different code duplication approaches is presented to show the effectiveness of different approaches. Fourthly, the advantages and disadvantages of different approaches and techniques are summarized and discussed. Finally, the conclusion of the review is summarized and future research direction of code duplication is described.},
  archive      = {J_NCA},
  author       = {Chen, Chang-Feng and Zain, Azlan Mohd and Zhou, Kai-Qing},
  doi          = {10.1007/s00521-022-07707-2},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20507-20537},
  shortjournal = {Neural Comput. Appl.},
  title        = {Definition, approaches, and analysis of code duplication detection (2006–2020): A critical review},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient anomaly detection through surrogate neural
networks. <em>NCA</em>, <em>34</em>(23), 20491–20505. (<a
href="https://doi.org/10.1007/s00521-022-07506-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly Detection can be viewed as an open problem despite the growing plethora of known anomaly detection techniques. The applicability of various anomaly detectors can vary depending on the application area and problem settings. Especially in the Big Data industrial setting, an important problem is inference speed, which may render even a highly accurate anomaly detector useless. In this paper, we propose to address this problem by training a surrogate neural network based on an auxiliary training set approximating the source anomaly detector output. We show that existing anomaly detectors can be approximated with high accuracy and with application-enabling inference speed. We compare our approach to a number of state-of-the-art algorithms: one class k-nearest-neighbors (kNN), local outlier factor, isolation forest, auto-encoder and two types of generative adversarial networks. We perform this comparison in the context of an important problem in cyber-security—the discovery of outlying (and thus suspicious) events in large-scale computer network traffic. Our results show that the proposed approach can successfully replace the most accurate but prohibitively slow kNN. Moreover, we observe that the surrogate neural network may even improve the kNN accuracy. Finally, we discuss various implications that the proposed approach can have while reducing the complexity of applied anomaly detection systems.},
  archive      = {J_NCA},
  author       = {Flusser, Martin and Somol, Petr},
  doi          = {10.1007/s00521-022-07506-9},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20491-20505},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient anomaly detection through surrogate neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Understanding deep learning defenses against adversarial
examples through visualizations for dynamic risk assessment.
<em>NCA</em>, <em>34</em>(23), 20477–20490. (<a
href="https://doi.org/10.1007/s00521-021-06812-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep neural network models have been developed in different fields, where they have brought many advances. However, they have also started to be used in tasks where risk is critical. Misdiagnosis of these models can lead to serious accidents or even death. This concern has led to an interest among researchers to study possible attacks on these models, discovering a long list of vulnerabilities, from which every model should be defended. The adversarial example attack is a widely known attack among researchers, who have developed several defenses to avoid such a threat. However, these defenses are as opaque as a deep neural network model, how they work is still unknown. This is why visualizing how they change the behavior of the target model is interesting in order to understand more precisely how the performance of the defended model is being modified. For this work, three defense strategies, against adversarial example attacks, have been selected in order to visualize the behavior modification of each of them in the defended model. Adversarial training, dimensionality reduction, and prediction similarity were the selected defenses, which have been developed using a model composed of convolution neural network layers and dense neural network layers. In each defense, the behavior of the original model has been compared with the behavior of the defended model, representing the target model by a graph in a visualization. This visualization allows identifying the vulnerabilities of the model and shows how the defenses try to avoid them.},
  archive      = {J_NCA},
  author       = {Echeberria-Barrio, Xabier and Gil-Lerchundi, Amaia and Egana-Zubia, Jon and Orduna-Urrutia, Raul},
  doi          = {10.1007/s00521-021-06812-y},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20477-20490},
  shortjournal = {Neural Comput. Appl.},
  title        = {Understanding deep learning defenses against adversarial examples through visualizations for dynamic risk assessment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A distributed topology for identifying anomalies in an
industrial environment. <em>NCA</em>, <em>34</em>(23), 20463–20476. (<a
href="https://doi.org/10.1007/s00521-022-07106-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The devastating consequences of climate change have resulted in the promotion of clean energies, being the wind energy the one with greater potential. This technology has been developed in recent years following different strategic plans, playing special attention to wind generation. In this sense, the use of bicomponent materials in wind generator blades and housings is a widely spread procedure. However, the great complexity of the process followed to obtain this kind of materials hinders the problem of detecting anomalous situations in the plant, due to sensors or actuators malfunctions. This has a direct impact on the features of the final product, with the corresponding influence in the durability and wind generator performance. In this context, the present work proposes the use of a distributed anomaly detection system to identify the source of the wrong operation. With this aim, five different one-class techniques are considered to detect deviations in three plant components located in a bicomponent mixing machine installation: the flow meter, the pressure sensor and the pump speed.},
  archive      = {J_NCA},
  author       = {Zayas-Gato, Francisco and Michelena, Álvaro and Jove, Esteban and Casteleiro-Roca, José-Luis and Quintián, Héctor and Novais, Paulo and Méndez-Pérez, Juan Albino and Calvo-Rolle, José Luis},
  doi          = {10.1007/s00521-022-07106-7},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20463-20476},
  shortjournal = {Neural Comput. Appl.},
  title        = {A distributed topology for identifying anomalies in an industrial environment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Implementation of the BERT-derived architectures to tackle
disinformation challenges. <em>NCA</em>, <em>34</em>(23), 20449–20461.
(<a href="https://doi.org/10.1007/s00521-021-06276-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in the area of modern technologies confirms that information is not only a commodity but can also become a tool for competition and rivalry among governments and corporations, or can be applied by ill-willed people to use it in their hate speech practices. The impact of information is overpowering and can lead to many socially undesirable phenomena, such as panic or political instability. To eliminate the threats of fake news publishing, modern computer security systems need flexible and intelligent tools. The design of models meeting the above-mentioned criteria is enabled by artificial intelligence and, above all, by the state-of-the-art neural network architectures, applied in NLP tasks. The BERT neural network belongs to this type of architectures. This paper presents Transformer-based hybrid architectures applied to create models for detecting fake news.},
  archive      = {J_NCA},
  author       = {Kula, Sebastian and Kozik, Rafał and Choraś, Michał},
  doi          = {10.1007/s00521-021-06276-0},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20449-20461},
  shortjournal = {Neural Comput. Appl.},
  title        = {Implementation of the BERT-derived architectures to tackle disinformation challenges},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cybersecurity applications of computational intelligence.
<em>NCA</em>, <em>34</em>(23), 20447–20448. (<a
href="https://doi.org/10.1007/s00521-022-07908-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Herrero, Álvaro and Corchado, Emilio and Wozniak, Michal and Bae-Cho, Sung and Petrović, Slobodan},
  doi          = {10.1007/s00521-022-07908-9},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {20447-20448},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cybersecurity applications of computational intelligence},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantic drift prediction for class incremental deep metric
learning. <em>NCA</em>, <em>34</em>(22), 20299–20312. (<a
href="https://doi.org/10.1007/s00521-022-07600-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training a deep neural network in consecutive tasks remains a challenge due to catastrophic forgetting. Although class incremental learning (CIL) has been an active research area, CIL in deep metric learning has scarcely been discussed. One of the causes of catastrophic forgetting in class incremental deep metric learning is prototype drift. We propose a prototype drift estimation method, named semantic drift prediction to address the problem. Our drift estimation method utilizes residual ridge regression to learn the mapping of feature distributions from the old to the new model. We evaluate our method on Cifar-100, Tiny-Imagenet, and CUB-200 datasets using Triplet, infoNCE, ArcFace, and Circle loss. By automatically learning prototype drift in CIL, our method approximates the new prototype location more accurately and retains model performance better than semantic drift compensation given sufficient training data. As a result, our method only causes 18.8\%, 12.3\%, and 15.8\% of average forgetting on the three datasets, respectively. In addition, we also show that although inter-class distance and intra-class variation correlate with catastrophic forgetting, the most promising solution for the problem is by designing a better prototype drift prediction method.},
  archive      = {J_NCA},
  author       = {Nugroho, Kuntoro Adi and Ruan, Shanq-Jang},
  doi          = {10.1007/s00521-022-07600-y},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20299-20312},
  shortjournal = {Neural Comput. Appl.},
  title        = {Semantic drift prediction for class incremental deep metric learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Handling occlusion in prohibited item detection from x-ray
images. <em>NCA</em>, <em>34</em>(22), 20285–20298. (<a
href="https://doi.org/10.1007/s00521-022-07578-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prohibited item detection from X-ray images determines whether any prohibited items are present in baggage, and great progress has recently been made in this field with the development of deep learning. Nevertheless, the appearance of an occluded item interacts with the cover, which is different from occlusions encountered in conventional object detection. We design three mechanisms to handle this challenge on the assumption that the occluded part is still partially observed. First, we propose a scale interaction module in which the features in neighboring scales interact one or more times to enhance the model’s perception ability. Then, we design a cross-image weakly supervised semantic analysis model utilizing the coattention mechanism to perceive similar and different targets, breaking through the information bottleneck of the isolated detection of a single image. Finally, we introduce a multitask learning module to simultaneously optimize the model at the global level and pixel level. We evaluate our approach on the publicly available security inspection X-ray (SIXray) dataset, the occluded prohibited items X-ray (OPIXray) dataset, and the HIXray dataset, and the results show that our approach is competitive with other X-ray baggage inspection approaches.},
  archive      = {J_NCA},
  author       = {Liu, Dongsheng and Tian, Yan and Xu, Zhaocheng and Jian, Guotang},
  doi          = {10.1007/s00521-022-07578-7},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20285-20298},
  shortjournal = {Neural Comput. Appl.},
  title        = {Handling occlusion in prohibited item detection from X-ray images},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of lévy flight-based reptile search algorithm
with local search ability for power systems engineering design problems.
<em>NCA</em>, <em>34</em>(22), 20263–20283. (<a
href="https://doi.org/10.1007/s00521-022-07575-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for better-performing algorithms to solve real-world power systems engineering problems has always been a challenging topic. Due to their stochastic nature, metaheuristic algorithms can provide better results. Thus, they have a rising trend in terms of investigation. This paper is a further attempt to offer a better optimizing structure, therefore, aims to provide a better-performing algorithm both for designing an appropriate proportional–integral–derivative (PID) controller to effectively operate an automatic voltage regulator (AVR) system and extracting the optimum parameters of a power system stabilizer (PSS) employed in a single-machine infinite-bus (SMIB) power system. Therefore, the paper discusses the development of the Lévy flight-based reptile search algorithm with local search capability and evaluates its potential against challenging power systems engineering optimization problems. The Lévy flight concept is used for better exploration capability in the proposed algorithm, whereas the Nelder–Mead simplex search algorithm is integrated for further exploitation. The latter case is confirmed through 23 benchmark functions with different features using statistical and nonparametric tests. The superiority of the proposed Lévy flight-based reptile search and Nelder–Mead (L-RSANM) algorithm-based PID controller for the AVR system is demonstrated comparatively using convergence, statistical and nonparametric tests along with transient and frequency responses. Besides, it is also assessed against previously reported and different methods, showing further superiority for AVR system control. Furthermore, the extraordinary ability of the L-RSANM algorithm to design an efficient PSS employed in the SMIB power system is demonstrated, as well. In conclusion, the proposed L-RSANM algorithm is shown to be more capable to solve the challenging power systems engineering design problems.},
  archive      = {J_NCA},
  author       = {Ekinci, Serdar and Izci, Davut and Abu Zitar, Raed and Alsoud, Anas Ratib and Abualigah, Laith},
  doi          = {10.1007/s00521-022-07575-w},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20263-20283},
  shortjournal = {Neural Comput. Appl.},
  title        = {Development of lévy flight-based reptile search algorithm with local search ability for power systems engineering design problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing adversarial transferability with partial blocks on
vision transformer. <em>NCA</em>, <em>34</em>(22), 20249–20262. (<a
href="https://doi.org/10.1007/s00521-022-07568-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial examples can attack multiple unknown convolutional neural networks (CNNs) due to adversarial transferability, which reveals the vulnerability of CNNs and facilitates the development of adversarial attacks. However, most of the existing adversarial attack methods possess a limited transferability on vision transformers (ViTs). In this paper, we propose a partial blocks search attack (PBSA) method to generate adversarial examples on ViTs, which significantly enhance transferability. Instead of directly employing the same strategy for all encoder blocks on ViTs, we divide encoder blocks into two categories by introducing the block weight score and exploit distinct strategies to process them. In addition, we optimize the generation of perturbations by regularizing the self-attention feature maps and creating an ensemble of partial blocks. Finally, perturbations are adjusted by an adaptive weight to disturb the most effective pixels of original images. Extensive experiments on the ImageNet dataset are conducted to demonstrate the validity and effectiveness of the proposed PBSA. The experimental results reveal the superiority of the proposed PBSA to state-of-the-art attack methods on both ViTs and CNNs. Furthermore, PBSA can be flexibly combined with existing methods, which significantly enhances the transferability of adversarial examples.},
  archive      = {J_NCA},
  author       = {Han, Yanyang and Liu, Ju and Liu, Xiaoxi and Jiang, Xiao and Gu, Lingchen and Gao, Xuesong and Chen, Weiqiang},
  doi          = {10.1007/s00521-022-07568-9},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20249-20262},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing adversarial transferability with partial blocks on vision transformer},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A gene expression programming-based method for real-time
wear estimation of disc cutter on TBM cutterhead. <em>NCA</em>,
<em>34</em>(22), 20231–20247. (<a
href="https://doi.org/10.1007/s00521-022-07597-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent entry in the tunnel boring machine cutterhead for disc cutter wear inspection is a risky, time-consuming, and labor-intensive activity. Existing disc cutter wear prediction models mainly focus on cutter consumption before construction, and it is impossible to estimate the wear of a single cutter when they are applied to on-site construction. To solve this problem, this research presents a method for estimating the wear of each disc cutter on the cutterhead in real time by only using several monitored machine parameters. Firstly, a novel health index that can characterize the wear of each disc cutter is constructed, and the field parameters that have greater impact on the health index are selected. Then, the explicit mathematical expression between the selected parameters and the health index is established based on genetic expression programming. Finally, the on-site data collected from an Indian subway tunnel were used to validate the effectiveness and superiority of the proposed method. The results show that the proposed method can estimate the wear of each disc cutter in real time only by monitoring the rotational speed of cutterhead and tunneling speed. Its average accuracies on the validation set and test set are 90.6\% and 85.9\%, respectively. Compared with the ridge regression, decision tree, support vector regression and k-nearest neighbors, its accuracy on the test set is 13.0\%, 12.7\%, 11.2\%, and 15.4\% higher, respectively. Therefore, the proposed method can greatly reduce the cost for cutter inspection, and the explicit model can be easily deployed to the construction site.},
  archive      = {J_NCA},
  author       = {Tao, Jianfeng and Yu, Honggan and Qin, Chengjin and Sun, Hao and Liu, Chengliang},
  doi          = {10.1007/s00521-022-07597-4},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20231-20247},
  shortjournal = {Neural Comput. Appl.},
  title        = {A gene expression programming-based method for real-time wear estimation of disc cutter on TBM cutterhead},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent fake reviews detection based on aspect
extraction and analysis using deep learning. <em>NCA</em>,
<em>34</em>(22), 20213–20229. (<a
href="https://doi.org/10.1007/s00521-022-07531-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of social networking and e-commerce sites, users provide their feedback and comments in the form of reviews for any product, topic, or organization. Due to high influence of reviews on users, spammers use fake reviews to promote their product/organization and to demote the competitors. It is estimated that approximately 14\% of reviews on any platform are fake reviews. Several researchers have proposed various approaches to detect fake reviews. The limitation of existing approaches is that complete review text is analysed which increases computation time and degrades accuracy. In our proposed approach, aspects are extracted from reviews and only these aspects and respective sentiments are employed for fake reviews detection. Extracted aspects are fed into CNN for aspect replication learning. The replicated aspects are fed into LSTM for fake reviews detection. As per our knowledge, aspects extraction and replication are not applied for fake reviews detection which is our significant contribution due to optimization it offers. Ott and Yelp Filter datasets are used to compare performance with recent approaches. Experiment analysis proves that our proposed approach outperforms recent approaches. Our approach is also compared with traditional machine learning techniques to prove that deep neural networks perform complex computation better than traditional techniques.},
  archive      = {J_NCA},
  author       = {Bathla, Gourav and Singh, Pardeep and Singh, Rahul Kumar and Cambria, Erik and Tiwari, Rajeev},
  doi          = {10.1007/s00521-022-07531-8},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20213-20229},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intelligent fake reviews detection based on aspect extraction and analysis using deep learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SBOX-CGA: Substitution box generator based on chaos and
genetic algorithm. <em>NCA</em>, <em>34</em>(22), 20203–20211. (<a
href="https://doi.org/10.1007/s00521-022-07589-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {What makes artificial intelligence techniques so remarkable in the field of computer science is undoubtedly their success in producing effective solutions to difficult computational problems. In particular, metaheuristic optimization algorithms are a unique example of using artificial intelligence techniques to generate approximate solutions to problems that cannot be solved in polynomial time, called NP. Obtaining a substitution box (s-box) structure that will satisfy the desired requirements in cryptography is an example of these NP problems. In the literature, it is a hot topic to optimize the s-box structures obtained from chaotic entropy sources with heuristic algorithms to improve their cryptographic properties. The study with the highest nonlinearity value (110.25) based on optimization algorithms to date has been published in 2020. In this study, a method with a higher nonlinearity value than the algorithms previously proposed in the literature is developed. It has been shown that the nonlinearity value can be increased to 111.75. These results will be a basis for new research on the chaos-based s-box literature and will motivate new studies to develop alternative optimization algorithms in the future to obtain s-box structures based on the random selection equivalent to the AES s-box.},
  archive      = {J_NCA},
  author       = {Artuğer, Fırat and Özkaynak, Fatih},
  doi          = {10.1007/s00521-022-07589-4},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20203-20211},
  shortjournal = {Neural Comput. Appl.},
  title        = {SBOX-CGA: Substitution box generator based on chaos and genetic algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel automatic approach for glioma segmentation.
<em>NCA</em>, <em>34</em>(22), 20191–20201. (<a
href="https://doi.org/10.1007/s00521-022-07583-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quantitative analysis of brain magnetic resonance imaging (MRI) represents a tiring routine and enormously on accurate segmentation of some brain regions. Gliomas represent the most common and aggressive brain tumors. In their highest grade, it can lead to a very short life. The treatment planning is decided after the analysis of MRI data to assess tumors. This treatment is manually performed which needs time and represents a tedious task. Automatic and accurate segmentation technique becomes a challenging problem since these tumors can take a variety of sizes, contrast, and shape. For these reasons, we are motivated to suggest a new segmentation approach using deep learning. A new segmentation scheme is suggested using Convolutional Neural Networks (CNN). The presented scheme is tested using recent datasets (BraTS 2017, 2018, and 2020). It achieves good performances compared to new methods, with Dice scores of 0.86 for the Whole Tumor, 0.82 for Tumor Core, and 0.6 for Enhancing Tumor based on the first dataset. According to the second dataset, the three regions had an average of 0.88, 0.77, and 0.65, respectively. The new dataset provides 0.87, 0.91, and 0.79 for the three regions, respectively.},
  archive      = {J_NCA},
  author       = {Elhamzi, Wajdi and Ayadi, Wadhah and Atri, Mohamed},
  doi          = {10.1007/s00521-022-07583-w},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20191-20201},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel automatic approach for glioma segmentation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transfer learning-based EEG analysis of visual attention and
working memory on motor cortex for BCI. <em>NCA</em>, <em>34</em>(22),
20179–20190. (<a
href="https://doi.org/10.1007/s00521-022-07580-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain–Computer Interface (BCI) technology has been tested as a method to restore or improve brain function. It attempts to improve human cognitive functions by using BCI&#39;s ability to predict cognitive situations (e.g., attention and memory retention) in real time and use it to run psychosocial training programs. This research work aims to determine the impact of various cognitive activities (such as rest, visual attention, and short-term working memory) on the brain waves originating in the motor cortex region of the human brain. To analyze cognitive activities in the electroencephalogram signal, the study uses CNN-based transfer learning to better detect the cognitive activities. CNN-based deep learning has superior feature detection and classification capabilities than conventional machine learning algorithms. The study also investigates the variable epoch durations for better learning and has proven to provide better feature localization within the epoch. The deep learning algorithm-based classification demonstrated the difference between rest and active cognitive activities. Also, the distinction in the level of presence for these activities is different for various frequency bands.As a result, maximum accuracy of 89.74 and 91.02\% was observed in the beta band in the case of rest versus attention and working memory, respectively. On the other hand, for the same activities, alpha band accuracies were significantly lower, suggesting that the activities such as visual attention and working memory are present more in the beta and theta bands in comparison to the alpha band. However, when attention and working memory signals were compared with each other, the beta band gave 74.35\% accuracy, and with all three classes, it produced 76.06\%, which suggests that both the activities are present prominently in both frequency bands. The results have shown that the cognitive activities in the motor cortex are most prominent in the beta band, while the theta band also carries cognitive attributes. For BCI-based rehabilitation, the cognitive neurofeedback can be improved with the knowledge of the areas to focus on, which were established in the study.},
  archive      = {J_NCA},
  author       = {Kant, Piyush and Laskar, Shahedul Haque and Hazarika, Jupitara},
  doi          = {10.1007/s00521-022-07580-z},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20179-20190},
  shortjournal = {Neural Comput. Appl.},
  title        = {Transfer learning-based EEG analysis of visual attention and working memory on motor cortex for BCI},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IRF-LSTM: Enhanced regularization function in LSTM to
predict the rainfall. <em>NCA</em>, <em>34</em>(22), 20165–20177. (<a
href="https://doi.org/10.1007/s00521-022-07577-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sea surface temperature modifies the air in the earth’s atmosphere. $${\text{EINi}}\tilde{\eta }{\text{o}}$$ signs in the sea surface temperature spread the warm water in the ocean and take the rain. Several existing models forecast rainfall using statistical analysis, machine learning, and deep learning. Neural Networks are powerful models that are extensively used for solving problems in many areas but still suffer from significant weaknesses. The presence of nonlinear hidden layers makes the deep networks prone to severe overfitting. This research used a rainfall dataset and reduced the issue of overfitting by using the improved regularized function. The main contribution of this research is proposing the enhanced regularized function to predict rainfall to reduce the bias. To evaluate the performance of the proposed Improved Regularization Function Long Short-Term Memory (IRF-LSTM) to forecast rainfall are RMSE, MAE, NSE, r. The output performance of the proposed IRF-LSTM is surpassed other state-of-the-art methods and is verified as by far the best implementation.},
  archive      = {J_NCA},
  author       = {Bhimavarapu, Usharani},
  doi          = {10.1007/s00521-022-07577-8},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20165-20177},
  shortjournal = {Neural Comput. Appl.},
  title        = {IRF-LSTM: Enhanced regularization function in LSTM to predict the rainfall},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approaching what and how people with mental disorders
communicate in social media–introducing a multi-channel representation.
<em>NCA</em>, <em>34</em>(22), 20149–20164. (<a
href="https://doi.org/10.1007/s00521-022-07569-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last few years, studies related to the detection of mental disorders in social media have been increasing. The latter because the awareness created by health campaigns that emphasizes the commonness of these disorders among all of us has motivated the creation of new datasets, many of them extracted from social media platforms. In this study, we aim to contribute to the analysis of three major mental disorders that are hitting the world: Anorexia, Depression and Self-harm. To this end, we propose a novel model that, first, extracts three different views, or information channels, from the posts shared by users: thematic interests, writing style, and emotions. Then, it optimally fusions the information from each channel by using a gated multimodal unit. We evaluate the feasibility of our approach in the aforementioned tasks, first by comparing its output against traditional and modern strategies, and later against the best contestants in the eRisk evaluation forum. In both evaluations, our approach clearly outperforms all of its competitors. Through an exhaustive analysis section, we provide evidence of what is being captured by each information channel, then highlighting the importance and robustness of a more holistic view in critical classification tasks.},
  archive      = {J_NCA},
  author       = {Aragón, Mario Ezra and López-Monroy, A. Pastor and González, Luis C. and Montes-y-Gómez, Manuel},
  doi          = {10.1007/s00521-022-07569-8},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20149-20164},
  shortjournal = {Neural Comput. Appl.},
  title        = {Approaching what and how people with mental disorders communicate in social media–Introducing a multi-channel representation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel invasive plant detection approach using time series
images from unmanned aerial systems based on convolutional and recurrent
neural networks. <em>NCA</em>, <em>34</em>(22), 20135–20147. (<a
href="https://doi.org/10.1007/s00521-022-07560-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of invasive plants (IPs) is critical for the preservation of natural ecosystems. Unmanned Aerial Systems (UAS) offer an efficient method of monitoring IPs in conservation areas. However, the process of finding IPs in UAS is labor-intensive and error-prone. Deep learning techniques have the potential for object detection and increase the efficiency and accuracy of IP identification. This study develops a novel deep learning model using a UAS and associated geographic information system (GIS) to detect and identify invasive Phragmites australis (PA) in its early growth stage. This novel network, integrating a convolutional neural network (CNN) and a recurrent neural network (RNN), proves to be an efficient and accurate method to detect PA in time series UAS images. CNN is good at extracting spatial features on images, and RNN excels in processing temporal features. Temporal features of the time series UAS images are extracted and employed with spatial features for the classification by an RNN model. Experiments are conducted in Nature Conservancy’s Emiquon Preserve. The proposed network achieves the highest performance compared with other IP detection models. With its high generalization ability, the proposed model might find more applications in precision agriculture and land conservation areas.},
  archive      = {J_NCA},
  author       = {Guo, Yanhui and Zhao, Yun and Rothfus, Thomas A. and Avalos, Adam S.},
  doi          = {10.1007/s00521-022-07560-3},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20135-20147},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel invasive plant detection approach using time series images from unmanned aerial systems based on convolutional and recurrent neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A robust optimal mean cosine angle 2DPCA for image feature
extraction. <em>NCA</em>, <em>34</em>(22), 20117–20134. (<a
href="https://doi.org/10.1007/s00521-022-07572-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, angle two-dimensional principal component analysis (Angle 2DPCA) effectively enhances the robustness of traditional 2DPCA by using a measurement model based on F-norm in the relationship between reconstruction error and variance, and successfully applied in image feature extraction. However, the vital disadvantages of Angle 2DPCA are low computational efficiency, imperfect robustness and poor interpretability. To overcome these problems, we propose robust optimal mean cosine angle 2DPCA (ROMCA-2DPCA), a novel formulation of Angle 2DPCA. ROMCA-2DPCA employs R1-norm to maximize the ratio between the variance and input data and considers the optimal mean to complete data centralization, thereby not only reasonably reducing the computational complexity of the model but also effectively improving its robustness. Moreover, ROMCA-2DPCA strictly proves its convergence in theory, thereby greatly enhancing the interpretability of the model. Accordingly, we have developed a fast nongreedy iterative algorithm for solving the corresponding criterion function. Finally, the experimental results on some image databases show that our model is superior.},
  archive      = {J_NCA},
  author       = {Bi, Pengfei and Deng, Yiyan and Du, Xue},
  doi          = {10.1007/s00521-022-07572-z},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20117-20134},
  shortjournal = {Neural Comput. Appl.},
  title        = {A robust optimal mean cosine angle 2DPCA for image feature extraction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-level context-driven interaction modeling for human
future trajectory prediction. <em>NCA</em>, <em>34</em>(22),
20101–20115. (<a
href="https://doi.org/10.1007/s00521-022-07562-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human trajectory prediction is a challenging task with important applications such as intelligent surveillance and autonomous driving. We recognize that pedestrians in close and distant neighborhoods have different impacts on the person’s decision of future movements. Local scene context and global scene layout also affect the movement decision differently. Existing methods have not adequately addressed these interactions between humans and the multi-level contexts occurring at different spatial and temporal scales. To this end, we propose a multi-level context-driven interaction modeling (MCDIM) method for human future trajectory learning and prediction. Specifically, we construct a multilayer graph attention network (GAT) to model the hierarchical human–human interactions. An extra set of long short-term memory networks is designed to capture the correlations of these human–human interactions at different temporal scales. To model the human–scene interactions, we explicitly extract and encode the global scene layout features and local context features in the neighborhood of the person at each time step and capture the spatial–temporal information of the interactions between human and the local scene contexts. The human–human and human–scene interactions are incorporated into the multi-level GAT-based network for accurate prediction of future trajectories. We have evaluated the method on benchmark datasets: the walking pedestrians dataset provided by ETH Zurich (ETH) and the crowd data provided by the University of Cyprus. The results demonstrate that our MCDIM method outperforms existing methods, being able to generate more accurate and plausible trajectories for pedestrians. The average performance gain is 2 and 3 percentage points in terms of the average displacement error and final displacement error, respectively.},
  archive      = {J_NCA},
  author       = {He, Zhiquan and Sun, Hao and Cao, Wenming and He, Henry Z.},
  doi          = {10.1007/s00521-022-07562-1},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20101-20115},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-level context-driven interaction modeling for human future trajectory prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Influence of energy storage device on load frequency control
of an interconnected dual-area thermal and solar photovoltaic power
system. <em>NCA</em>, <em>34</em>(22), 20083–20099. (<a
href="https://doi.org/10.1007/s00521-022-07558-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mismatch between power generation and load demand causes unwanted fluctuations in frequency and tie-line power, and load frequency control (LFC) is an inevitable mechanism to compensate the mismatch. For this issue, this paper explores the influence of energy storage device (ESD) on ameliorating the LFC performance for an interconnected dual-area thermal and solar photovoltaic (PV) power system. Initially, to alleviate the frequency and tie-line power deviations, a proportional-integral (PI) controller is chosen and utilized in the system due to its effectiveness and simplicity in practice. For achieving the highest performance from this controller, salp swarm algorithm (SSA) is employed to search for optimal controller parameters by using integral of time-multiplied absolute error (ITAE) criterion. To affirm the contribution of SSA optimized PI controller, it is contrasted with a recent approach utilizing PI controller optimized by genetic algorithm (GA) and firefly algorithm (FA). It is observed that the results acquired for SSA are better than for GA and FA. To improve the system performance further, ESD such as redox flow battery (RFB) famous for its excellent disturbance rejection capability is integrated with the thermal power unit for the first time in the literature. It is divulged from the results that the system performance with RFB has boosted considerably with regard to shorter settling time, less undershoot/overshoot and smaller ITAE value of the frequency and tie-line power fluctuations. According to the sensitivity analysis, our proposal is found robust against system parameters variations and different loading conditions.},
  archive      = {J_NCA},
  author       = {Çelik, Emre and Öztürk, Nihat and Houssein, Essam H.},
  doi          = {10.1007/s00521-022-07558-x},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20083-20099},
  shortjournal = {Neural Comput. Appl.},
  title        = {Influence of energy storage device on load frequency control of an interconnected dual-area thermal and solar photovoltaic power system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved multipath residual CNN-based classification
approach for periapical disease prediction and diagnosis in dental
radiography. <em>NCA</em>, <em>34</em>(22), 20067–20082. (<a
href="https://doi.org/10.1007/s00521-022-07556-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dental radiography offers significant indication for medical/clinical diagnosis, quality assessment and treatment. Huge efforts have been taken while developing the digital dental X-ray image analysis system for the enhancement of clinical quality. In this manuscript, the datasets, methodology and analysis of performance are carried out for the evaluation of qualities regarding the dental treatment with the utilization of periapical images of dental X-ray that is taken before and after the operations. With the purpose of supporting dentists to make some clinical decisions, a tool pipeline for automated clinical quality evaluation is being proposed. In this approach, a disease diagnosis from the dental image analysis is made by means of deep learning techniques. Initially, the dental input dataset is preprocessed using bias-corrected filter technique. For segmentation process, semantic contextual network segmentation (SCNS) is employed. The features were extracted using multi-scale local ternary pattern (MS-LTP). Statistical linear discriminant analysis (SLDA) approach is employed for the selection of features. At last, the extracted and selected features outcome is post-processed to improve the rate of classifier performance. The classification process is carried out by means of improved multipath residual CNN (IMRCNN) classifier. Thus, the proposed technique provides better accuracy than others in the diagnosis of dental disease to predict Periapical Disease Detection in Dental Radiographs image. Thus, the disease is predicted so as to diagnose the severity earlier and helpful for dentist in making decisions on treatment process. Thus, finally the performance estimation has been made and the results were compared with existing techniques to prove the effectiveness of proposed strategy.},
  archive      = {J_NCA},
  author       = {Sankaran, K. Sakthidasan},
  doi          = {10.1007/s00521-022-07556-z},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20067-20082},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved multipath residual CNN-based classification approach for periapical disease prediction and diagnosis in dental radiography},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prairie dog optimization algorithm. <em>NCA</em>,
<em>34</em>(22), 20017–20065. (<a
href="https://doi.org/10.1007/s00521-022-07530-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a new nature-inspired metaheuristic that mimics the behaviour of the prairie dogs in their natural habitat called the prairie dog optimization (PDO). The proposed algorithm uses four prairie dog activities to achieve the two common optimization phases, exploration and exploitation. The prairie dogs&#39; foraging and burrow build activities are used to provide exploratory behaviour for PDO. The prairie dogs build their burrows around an abundant food source. As the food source gets depleted, they search for a new food source and build new burrows around it, exploring the whole colony or problem space to discover new food sources or solutions. The specific response of the prairie dogs to two unique communication or alert sound is used to accomplish exploitation. The prairie dogs have signals or sounds for different scenarios ranging from predator threats to food availability. Their communication skills play a significant role in satisfying the prairie dogs&#39; nutritional needs and anti-predation abilities. These two specific behaviours result in the prairie dogs converging to a specific location or a promising location in the case of PDO implementation, where further search (exploitation) is carried out to find better or near-optimal solutions. The performance of PDO in carrying out optimization is tested on a set of twenty-two classical benchmark functions and ten CEC 2020 test functions. The experimental results demonstrate that PDO benefits from a good balance of exploration and exploitation. Compared with the results of other well-known population-based metaheuristic algorithms available in the literature, the PDO shows stronger performance and higher capabilities than the other algorithms. Furthermore, twelve benchmark engineering design problems are used to test the performance of PDO, and the results indicate that the proposed PDO is effective in estimating optimal solutions for real-world optimization problems with unknown global optima. The PDO algorithm source codes is publicly available at https://www.mathworks.com/matlabcentral/fileexchange/110980-prairie-dog-optimization-algorithm .},
  archive      = {J_NCA},
  author       = {Ezugwu, Absalom E. and Agushaka, Jeffrey O. and Abualigah, Laith and Mirjalili, Seyedali and Gandomi, Amir H.},
  doi          = {10.1007/s00521-022-07530-9},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {20017-20065},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prairie dog optimization algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Streamflow modelling and forecasting for canadian watersheds
using LSTM networks with attention mechanism. <em>NCA</em>,
<em>34</em>(22), 19995–20015. (<a
href="https://doi.org/10.1007/s00521-022-07523-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the capability of sequence-to-sequence machine learning (ML) architectures in an effort to develop streamflow forecasting tools for Canadian watersheds. Such tools are useful to inform local and region-specific water management and flood forecasting related activities. Two powerful deep-learning variants of the Recurrent Neural Network were investigated, namely the standard and attention-based encoder-decoder long short-term memory (LSTM) models. Both models were forced with past hydro-meteorological states and daily meteorological data with a look-back time window of several days. These models were tested for 10 different watersheds from the Ottawa River watershed, located within the Great Lakes Saint-Lawrence region of Canada, an economic powerhouse of the country. The results of training and testing phases suggest that both models are able to simulate overall hydrograph patterns well when compared to observational records. Between the two models, the attention model significantly outperforms the standard model in all watersheds, suggesting the importance and usefulness of the attention mechanism in ML architectures, not well explored for hydrological applications. The mean performance accuracy of the attention model on unseen data, when assessed in terms of mean Nash–Sutcliffe Efficiency and Kling-Gupta Efficiency is, respectively, found to be 0.985 and 0.954 for these watersheds. Streamflow forecasts with lead times of up to 5 days with the attention model demonstrate overall skillful performance with well above the benchmark accuracy of 70\%. The results of the study suggest that the encoder–decoder LSTM, with attention mechanism, is a powerful modelling choice for developing streamflow forecasting systems for Canadian watersheds.},
  archive      = {J_NCA},
  author       = {Girihagama, Lakshika and Naveed Khaliq, Muhammad and Lamontagne, Philippe and Perdikaris, John and Roy, René and Sushama, Laxmi and Elshorbagy, Amin},
  doi          = {10.1007/s00521-022-07523-8},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19995-20015},
  shortjournal = {Neural Comput. Appl.},
  title        = {Streamflow modelling and forecasting for canadian watersheds using LSTM networks with attention mechanism},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A functional enhancement on scarred fingerprint using
sigmoid filtering. <em>NCA</em>, <em>34</em>(22), 19973–19994. (<a
href="https://doi.org/10.1007/s00521-022-07520-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fingerprint has been widely used in biometric applications. Numerous established researches on image enhancement techniques have been done to improve the quality of fingerprint images. However, the production of low-quality images due to the presence of scars remains a challenge in biometrics. The scars damage the fingerprint minutiae information due to broken ridges and they reduce the accuracy of identification. This research developed an image enhancement approach to improve the quality of scarred fingerprint images to generate accurate minutiae extraction. To achieve the aim, the scarred image was improved by removing noise using a new filter, Median Sigmoid (MS), and the corrected ridges were reconstructed using ridges structure enhancement algorithm. This was done to enhance the broken ridges structure. MS filter is a combination of median filter and modified sigmoid function that improves the image contrast and simultaneously removes noise in the fingerprint image. Following that, the filtered image was used in the ridges structure enhancement process. To identify true minutiae, the broken ridges structure in the filtered image needed to be accurately verified. In the ridges structure reconstruction process, an algorithm was enhanced to identify the best value of Sigma parameter (σ) used in the Gaussian Low-pass filter to generate a better orientation image. The image is important to reconstruct the corrupted fingerprint ridges structure. The evaluation for the proposed approach used the National Institute of Standards and Technology Special Database 14, and the results showed a 37\% improvement of the quality index in comparison to approaches found in related research. The findings of the evaluation showed that the proposed enhancement approach produced a better minutiae extraction result and this is very significant in the field of fingerprint image enhancement.},
  archive      = {J_NCA},
  author       = {Kolivand, Hoshang and Hamid, Ainul Azura Binti Abdul and Asadianfam, Shiva and Rahim, Mohd Shafry Mohd},
  doi          = {10.1007/s00521-022-07520-x},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19973-19994},
  shortjournal = {Neural Comput. Appl.},
  title        = {A functional enhancement on scarred fingerprint using sigmoid filtering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Instant-hybrid neural-cryptography (IHNC) based on fast
machine learning. <em>NCA</em>, <em>34</em>(22), 19953–19972. (<a
href="https://doi.org/10.1007/s00521-022-07539-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, cryptographic systems’ designers are facing significant challenges in their designs. They have to constantly search for new ideas of fast unbreakable algorithms with a very powerful key generator. In this paper, we propose a novel hybrid neural-cryptography methodology. It depends on new rule of very fast Backpropagation (BP) instant machine learning (ML). This proposed Hybrid Cryptography system is constructed from Encryptor and Decryptor based on the asymmetric Autoencoder type. The Encryptor encrypts and compresses a set of data to be instant code (i-code) using public key. While the Decryptor recovers this i-code (ciphered-data) based on two keys together. The first is the private key and the other is called instant-key (i-key). This i-key is generated from 3 factors as well (the original data itself, the generated i-code and the private key). The i-key is changing periodically with every transformation of plain data set, so it is powerful unpredictable key against the brute force.},
  archive      = {J_NCA},
  author       = {Badr, Assem},
  doi          = {10.1007/s00521-022-07539-0},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19953-19972},
  shortjournal = {Neural Comput. Appl.},
  title        = {Instant-hybrid neural-cryptography (IHNC) based on fast machine learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient hardware implementation of CNN-based object
trackers for real-time applications. <em>NCA</em>, <em>34</em>(22),
19937–19952. (<a
href="https://doi.org/10.1007/s00521-022-07538-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The object tracking field continues to evolve as an important application of computer vision. Real-time performance is typically required in most applications of object tracking. The recent introduction of Convolutional Neural network (CNN) techniques to the object tracking field enabled the attainment of significant performance gains. However, the heavy computational load required for CNNs conflicts with the real-time requirements required for object tracking. In this paper, we address these computational limitations on the algorithm-side and the circuit-side. On the algorithm side, we adopt interpolation schemes which can significantly reduce the processing time and the memory storage requirements. We also evaluate the approximation of the hardware-expensive computations to attain an efficient hardware design. Moreover, we modify the online-training scheme in order to achieve a constant processing time across all video frames. On the circuit side, we developed a hardware accelerator of the online training stage. We avoid transposed reading from the external memory to speed-up the data movement with no performance degradation. Our proposed hardware accelerator achieves 44 frames-per-second in training the fully connected layers.},
  archive      = {J_NCA},
  author       = {El-Shafie, Al-Hussein A. and Zaki, Mohamed and Habib, S. E. D.},
  doi          = {10.1007/s00521-022-07538-1},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19937-19952},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient hardware implementation of CNN-based object trackers for real-time applications},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Double-kernelized weighted broad learning system for
imbalanced data. <em>NCA</em>, <em>34</em>(22), 19923–19936. (<a
href="https://doi.org/10.1007/s00521-022-07534-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad learning system (BLS) is an emerging neural network with fast learning capability, which has achieved good performance in various applications. Conventional BLS does not effectively consider the problems of class imbalance. Moreover, parameter tuning in BLS requires much effort. To address the challenges mentioned above, we propose a double-kernelized weighted broad learning system (DKWBLS) to cope with imbalanced data classification. The double-kernel mapping strategy is designed to replace the random mapping mechanism in BLS, resulting in more robust features while avoiding the step of adjusting the number of nodes. Furthermore, DKWBLS considers the imbalance problem and achieves more explicit decision boundaries. Numerous experimental results show the superiority of DKWBLS in tackling imbalance problems over other imbalance learning approaches.},
  archive      = {J_NCA},
  author       = {Chen, Wuxing and Yang, Kaixiang and Zhang, Weiwen and Shi, Yifan and Yu, Zhiwen},
  doi          = {10.1007/s00521-022-07534-5},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19923-19936},
  shortjournal = {Neural Comput. Appl.},
  title        = {Double-kernelized weighted broad learning system for imbalanced data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structural-optimized sequential deep learning methods for
surface soil moisture forecasting, case study quebec, canada.
<em>NCA</em>, <em>34</em>(22), 19895–19921. (<a
href="https://doi.org/10.1007/s00521-022-07529-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface soil moisture (MSS) is a key factor governing environmental interactions in any catchment. Energy flux between soil and atmosphere, soil temperature, and heat diffusion in soil are examples of impressible interactions. Consequently, the agriculture sector and its many dependent industries are influenced by this element. Hence, investigating new optimized preprocessing and input selection methods for processing, interpretation, modeling, and prediction of MSS is necessary to ensure sustainable agriculture. To this end, satellite products were studied for the province of Quebec, Canada. Two overall deep learning (DL) approaches are proposed in this study. The first and most efficient one is extracting meaningful modeling parameters by the time-series structural-analysis-based method, and the second one is using the combination of optimization algorithms and the DL method. The structure of the extracted time series from satellite data was assessed by several tests and an intense periodic pattern was detected. Therefore, additive Holt–Winter’s (SHW), seasonal standardization (Sstd), and spectral analysis (SA) were chosen as preprocessing methods for the structural analysis preprocessing. The long short-term memory (LSTM) model was utilized for short-term forecasting of un-preprocessed and preprocessed MSS datasets. Along with structural-analysis-based methodology, genetic and teacher–learner-based algorithms (GA and TLA) were coupled with LSTM to assess the coupled models’ performance for MSS forecasting for the first time. Based on the structural analysis of data, limited hidden states (ht) were selected for modeling {1, 2, 7, 9, 52}: network training and forecasts were undertaken according to these hidden states. Since the long-term characteristics of the time series like trend and level are not significant in short-term modeling, the LSTM (Sstd, 9), correlation coefficient (R) = 0.970, root-mean-square error (RMSE) = 1.339 outperformed other models, followed closely by LSTM (SHW, 1), R = 0.922, RMSE = 1.958. Conversely, for long-term forecast, as these attributes impact the structure, LSTM (SHW, 2), R = 0.922, RMSE = 0.1961 was more successful in the prediction of patterns and fluctuations, followed by LSTM (Sstd, 52), R = 0.920, RMSE = 2.064, which was more complicated than the model developed for short-term modeling. GA-LSTM (ht = 32, R = 0.930, RMSE = 1.852) and TLA-LSTM (ht = 37, R = 0.934, RMSE = 1.781) also enhanced the long-term forecasting results. Integration of these two optimization methods had two benefits. First, due to the stochastic nature of optimization algorithms and DL methods, the search space for the optimized parameter (ht) was greatly increased and many possibilities were investigated. Second, the LSTM could perform a long-term forecast of the MSS without preprocessing, which was not possible by structural analysis. On the other hand, these methods were much computationally expensive and the combination of their controlling parameters with other controlling parameters of LSTM created numerous possibilities. However, as TLA is parameter free and much less sophisticated than GA, it is a more computational-effective method, and subsequently a better option than GA.},
  archive      = {J_NCA},
  author       = {Zeynoddin, Mohammad and Bonakdari, Hossein},
  doi          = {10.1007/s00521-022-07529-2},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19895-19921},
  shortjournal = {Neural Comput. Appl.},
  title        = {Structural-optimized sequential deep learning methods for surface soil moisture forecasting, case study quebec, canada},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An intelligent disease prediction and monitoring system
using feature selection, multi-neural network and fuzzy rules.
<em>NCA</em>, <em>34</em>(22), 19877–19893. (<a
href="https://doi.org/10.1007/s00521-022-07527-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a new intelligent disease prediction system for predicting the disease and also knowing the current status of the dead diseases such as diabetic, heart and cancer diseases. More number of people are affecting and losing their life early due to these diseases so that these are also called as dead diseases. The proposed disease prediction and monitoring system consists of two phases such as feature selection and classification phases. In the feature selection phase, a newly proposed feature selection algorithm called conditional random field and mutual information-based feature selection algorithm is used for identifying the most contributed features that are used to enhance the prediction accuracy. In the classification phase, a newly proposed fuzzy-aware multilayer backpropagation neural network is applied for predicting and monitoring the diabetic disease and heart disease effectively. Here, newly generated fuzzy rules are also incorporated for making effective decision on patient records. The proposed prediction and monitoring system is used to predict and monitor the heart, diabetic and cancer diseases. The experiments have been conducted for evaluating the performance of the proposed disease prediction and monitoring system by using UCI Machine Learning Repository datasets and also proved that as better than the existing disease prediction systems in terms of precision, recall, F-measure and prediction accuracy.},
  archive      = {J_NCA},
  author       = {Elizabeth Jesi, V. and Aslam, Shabnam Mohamed},
  doi          = {10.1007/s00521-022-07527-4},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19877-19893},
  shortjournal = {Neural Comput. Appl.},
  title        = {An intelligent disease prediction and monitoring system using feature selection, multi-neural network and fuzzy rules},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design of a robust hybrid fuzzy super-twisting speed
controller for induction motor vector control systems. <em>NCA</em>,
<em>34</em>(22), 19863–19876. (<a
href="https://doi.org/10.1007/s00521-022-07519-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with a new design of a hybrid fuzzy super-twisting sliding mode controller (HFSTSMC) for a three-phase induction motor (IM) controlled by the rotor flux orientation technique. Super-twisting sliding mode control is employed as a potential solution to limit the inherent chattering effect in the conventional sliding mode control without affecting the tracking accuracy and robustness. The super-twisting sliding mode control (STSMC) scheme is a modified second-order sliding mode control (SOSMC) scheme that does not need the information of any derivative of the sliding surface, but the experimental control coefficients found in the control law have an obvious effect on limiting chattering and the system response speed. Therefore, a robust hybrid controller was proposed based on the fuzzy logic control (FLC) approach to optimally tuning these coefficients. Whereas, the fuzzy logic controller is used as a supervisory controller to adjust the value of the gains according to the state of the system. Thus, providing high dynamic performance and achieving the highest rates of robustness in transient and uncertain conditions. On the other hand, increasing tracking accuracy and chattering phenomena reduction in steady states. The validation of the suggested scheme is verified by experimental approximating of simulations using MATLAB/SIMULINK and also compared with conventional and advanced controllers. The obtained results confirm the reduction of the chattering phenomenon and thus reduction of the total harmonic distortion (THD) in the motor current, and the effectiveness of the proposed scheme in various operating conditions.},
  archive      = {J_NCA},
  author       = {Nurettin, Abdülhamit and İnanç, Nihat},
  doi          = {10.1007/s00521-022-07519-4},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19863-19876},
  shortjournal = {Neural Comput. Appl.},
  title        = {Design of a robust hybrid fuzzy super-twisting speed controller for induction motor vector control systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Class binarization to neuroevolution for multiclass
classification. <em>NCA</em>, <em>34</em>(22), 19845–19862. (<a
href="https://doi.org/10.1007/s00521-022-07525-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiclass classification is a fundamental and challenging task in machine learning. The existing techniques of multiclass classification can be categorized as (1) decomposition into binary (2) extension from binary and (3) hierarchical classification. Decomposing multiclass classification into a set of binary classifications that can be efficiently solved by using binary classifiers, called class binarization, which is a popular technique for multiclass classification. Neuroevolution, a general and powerful technique for evolving the structure and weights of neural networks, has been successfully applied to binary classification. In this paper, we apply class binarization techniques to a neuroevolution algorithm, NeuroEvolution of Augmenting Topologies (NEAT), that are used to generate neural networks for multiclass classification. We propose a new method that applies Error-Correcting Output Codes (ECOC) to design the class binarization strategies on the neuroevolution for multiclass classification. The ECOC strategies are compared with the class binarization strategies of One-vs-One and One-vs-All on three well-known datasets of Digit, Satellite, and Ecoli. We analyse their performance from four aspects of multiclass classification degradation, accuracy, evolutionary efficiency, and robustness. The results show that the NEAT with ECOC performs high accuracy with low variance. Specifically, it shows significant benefits in a flexible number of binary classifiers and strong robustness.},
  archive      = {J_NCA},
  author       = {Lan, Gongjin and Gao, Zhenyu and Tong, Lingyao and Liu, Ting},
  doi          = {10.1007/s00521-022-07525-6},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19845-19862},
  shortjournal = {Neural Comput. Appl.},
  title        = {Class binarization to neuroevolution for multiclass classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to transfer attention in multi-level features for
rotated ship detection. <em>NCA</em>, <em>34</em>(22), 19831–19844. (<a
href="https://doi.org/10.1007/s00521-022-07491-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-scale object detection is one of the focuses of object detection, which is particularly vital for ship detection. In order to achieve the desired effects, most advanced Convolutional Neural Network-based detectors enumerate and make inferences over multi-resolution feature maps. However, the existing methods bring two critical problems: (1) Over-fitted anchor settings and supervisions for object scales will restrict the generalized performance of the algorithm. (2) Similar multi-resolution prediction branches insulate the feature space and prevent learning from branches at different levels. Drawing on the human cognitive process, this paper proposes a novel structure for multi-scale rotated ship detection called the Feature Attention Transfer module, which generates and transfers attention in multi-level feature maps to instruct each prediction branch to focus on the features that are not well extracted in other branches. Accordingly, a customized supervision method called “Inclusion–Exclusion Learning” is proposed for associative learning based on the prediction results on multi-scale branches. We employ an anchor-free rotated ship detection framework to verify the proposed module. Extensive experiments are conducted to demonstrate the effectiveness of the proposed algorithm, called SKFat, on three optical remote sensing image datasets. Experimental results show that the proposed modules improve the multi-resolution detection framework while introducing negligible inference overhead. The best result of the proposed algorithm achieves the state-of-the-art average precision while reaching a high inference speed.},
  archive      = {J_NCA},
  author       = {Cui, Zhenyu and Liu, Ying and Zhao, Wei and Wang, Cheng},
  doi          = {10.1007/s00521-022-07491-z},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19831-19844},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning to transfer attention in multi-level features for rotated ship detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel technique for stress detection from EEG signal using
hybrid deep learning model. <em>NCA</em>, <em>34</em>(22), 19819–19830.
(<a href="https://doi.org/10.1007/s00521-022-07540-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stress is burgeoning in today’s fast-paced lifestyle, and its detection is imperative. An electroencephalography (EEG) technique is used to identify the brain’s activities from the brain’s electrical bio-signals. However, only a highly trained physician can elucidate EEG signals due to their complexity. This study proposes a DWT-based hybrid deep learning model based on Convolution Neural Network and Bidirectional Long Short-Term Memory (CNN–BLSTM), which detects stress levels in humans. Further supports neurologists, mental health counselors, and physicians in making decisions on stress levels. The Physionet EEG dataset is used to detect the stress level for mental arithmetic tasks. Noise from multi-channel (19 channels) EEG signals has been removed and decomposed into four levels using Discrete Wavelet Transform (DWT). After decomposition, an automatic feature selection method, namely Convolution Neural Network (CNN), is used on the decomposed signals. Finally, BLSTM is used to classify stress levels. The accuracy of the proposed model is compared with CNN-based Long Short-Term Memory (LSTM) and previous work. The results show that the proposed hybrid model achieved higher classification accuracy (99.20\%) compared to others. Further, the stratified tenfold cross-validation technique is applied to validate the proposed model with a classification accuracy of 98.10\%.},
  archive      = {J_NCA},
  author       = {Malviya, Lokesh and Mal, Sandip},
  doi          = {10.1007/s00521-022-07540-7},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19819-19830},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel technique for stress detection from EEG signal using hybrid deep learning model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Regularized semi-supervised KLFDA algorithm based on density
peak clustering. <em>NCA</em>, <em>34</em>(22), 19791–19817. (<a
href="https://doi.org/10.1007/s00521-022-07495-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the problem that the existing semi-supervised FISHER discriminant analysis algorithm (FDA) cannot effectively use both labeled and unlabeled data for learning, we propose a semi-supervised Kernel local FDA Algorithm based on density peak clustering pseudo-labels (SDPCKLFDA). First, the proposed algorithm adopts the density peak clustering algorithm to generate the pseudo cluster labels for labeled and unlabeled data, and then the generated pseudo-labels are explored to construct two regularization strategies. The two regularization strategies are used to regularize the corresponding within-class scatter matrix and between-class scatter matrix of the local Fisher discriminant analysis, and finally the optimal projection vector is obtained by solving the objective function of the local Fisher discriminant analysis. The two constructed regularization strategies can not only effectively enhance the discriminant performance of the extracted feature but also make the proposed algorithm suitable for multimodal and noisy data. In addition, to accommodate nonlinear and non-Gaussian datasets, we also develop a kernel version of the proposed algorithm with the help of kernel trick. In the experiment, the proposed algorithm is compared with the FDA and its improved algorithms on some benchmark artificial datasets and UCI datasets. The experimental results show that the discriminant performance of the proposed algorithm has been significantly improved compared with the other algorithms.},
  archive      = {J_NCA},
  author       = {Tao, Xinmin and Bao, Yixuan and Zhang, Xiaohan and Liang, Tian and Qi, Lin and Fan, Zhiting and Huang, Shan},
  doi          = {10.1007/s00521-022-07495-9},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19791-19817},
  shortjournal = {Neural Comput. Appl.},
  title        = {Regularized semi-supervised KLFDA algorithm based on density peak clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiclass feature selection with metaheuristic optimization
algorithms: A review. <em>NCA</em>, <em>34</em>(22), 19751–19790. (<a
href="https://doi.org/10.1007/s00521-022-07705-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting relevant feature subsets is vital in machine learning, and multiclass feature selection is harder to perform since most classifications are binary. The feature selection problem aims at reducing the feature set dimension while maintaining the performance model accuracy. Datasets can be classified using various methods. Nevertheless, metaheuristic algorithms attract substantial attention to solving different problems in optimization. For this reason, this paper presents a systematic survey of literature for solving multiclass feature selection problems utilizing metaheuristic algorithms that can assist classifiers selects optima or near optima features faster and more accurately. Metaheuristic algorithms have also been presented in four primary behavior-based categories, i.e., evolutionary-based, swarm-intelligence-based, physics-based, and human-based, even though some literature works presented more categorization. Further, lists of metaheuristic algorithms were introduced in the categories mentioned. In finding the solution to issues related to multiclass feature selection, only articles on metaheuristic algorithms used for multiclass feature selection problems from the year 2000 to 2022 were reviewed about their different categories and detailed descriptions. We considered some application areas for some of the metaheuristic algorithms applied for multiclass feature selection with their variations. Popular multiclass classifiers for feature selection were also examined. Moreover, we also presented the challenges of metaheuristic algorithms for feature selection, and we identified gaps for further research studies.},
  archive      = {J_NCA},
  author       = {Akinola, Olatunji O. and Ezugwu, Absalom E. and Agushaka, Jeffrey O. and Zitar, Raed Abu and Abualigah, Laith},
  doi          = {10.1007/s00521-022-07705-4},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19751-19790},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multiclass feature selection with metaheuristic optimization algorithms: A review},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent advances in multi-objective grey wolf optimizer, its
versions and applications. <em>NCA</em>, <em>34</em>(22), 19723–19749.
(<a href="https://doi.org/10.1007/s00521-022-07704-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a comprehensive review of the multi-objective grey wolf optimizer (MOGWO) is provided. In multi-objective optimization (MO), more than one objective function must be considered at the same time. To deal with such problems, a priori or a posteriori MOGWO variants have been proposed in the literature. In the a priori model, the multi-objective functions are aggregated into a single objective function by a number of weights. In the posterior model, the multi-objective formulation is maintained and MOGWO is employed to estimate the Pareto optimal solutions representing the best trade-offs between the objectives. Due to the successful performance of MOGWO, it has been widely utilized for MO. This review covers the research growth of MOGWO in terms of a number of researches, topics, top researchers, etc. Furthermore, several versions of MOGWO have been introduced and reviewed with applications in diverse fields. This work also provides a critical analysis to show the shortcomings and limitations of using the basic version of MOGWO followed by several future directions. This review paper will be a base paper for any researcher interested to implement MOGWO in its work.},
  archive      = {J_NCA},
  author       = {Makhadmeh, Sharif Naser and Alomari, Osama Ahmad and Mirjalili, Seyedali and Al-Betar, Mohammed Azmi and Elnagar, Ashraf},
  doi          = {10.1007/s00521-022-07704-5},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19723-19749},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recent advances in multi-objective grey wolf optimizer, its versions and applications},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). An improved estimation of distribution algorithm for
multi-objective optimization problems with mixed-variable. <em>NCA</em>,
<em>34</em>(22), 19703–19721. (<a
href="https://doi.org/10.1007/s00521-022-07695-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective evolutionary algorithms face many challenges in optimizing mixed-variable multi-objective problems, such as quantization error, low search efficiency of discontinuous discrete variables, and difficulty in coding non-integer discrete variables. To overcome these challenges, this paper proposes a mixed-variable multi-objective evolutionary algorithm based on estimation of distribution algorithm (MVMO-EDA). Compared with traditional multi-objective evolutionary algorithms, MVMO-EDA has the following improvements: (1) instead of crossover and mutation, statistics and sampling are used to generate offspring, which can avoid the quantization error caused by crossover and mutation operations; (2) using index coding for discrete variables to improve the search efficiency; and (3) a scalable histogram probability distribution model and two crowding distance-based diversity maintenance strategies are used to improve the global optimization ability. The performance of the proposed MVMO-EDA is evaluated on the modified ZDT and DTLZ benchmark sets with mixed-variable, and the results show that MVMO-EDA has a competitive performance both in convergence and diversity.},
  archive      = {J_NCA},
  author       = {Wang, Wenxiang and Li, Kangshun and Jalil, Hassan and Wang, Hui},
  doi          = {10.1007/s00521-022-07695-3},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19703-19721},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved estimation of distribution algorithm for multi-objective optimization problems with mixed-variable},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature selection methods in microarray gene expression
data: A systematic mapping study. <em>NCA</em>, <em>34</em>(22),
19675–19702. (<a
href="https://doi.org/10.1007/s00521-022-07661-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is an important area of research in medicine and genetics. Cancer classification based on the microarray gene expression data is a challenge in this area due to its high-dimensional features and small sample size. This can negatively impact the performance of data mining and machine learning algorithms. FS is a key issue in reducing the size of the microarray, which is done to obtain useful information and eliminate redundant features. With the absence of a thorough investigation of the field, it is almost impossible for researchers to get an idea of how their work relates to existing studies and how it contributes to the research community. This paper provides a systematic mapping study to analyze and synthesize the studies conducted on the FS techniques in microarrays. To this end, 108 related articles published between 2000 and February 2022 were selected and reviewed based on five criteria: year and region, FS method adopted, dataset type, source of release, and type of evaluation software. Our main goal is to provide a fair idea to future researchers about the current situation of the field and future directions. The results of the study showed that classification is the most important task in FS. In a history-based evaluation, evolutionary methods were found to have the widest application to FS.},
  archive      = {J_NCA},
  author       = {Vahmiyan, Mahnaz and Kheirabadi, Mohammadtaghi and Akbari, Ebrahim},
  doi          = {10.1007/s00521-022-07661-z},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19675-19702},
  shortjournal = {Neural Comput. Appl.},
  title        = {Feature selection methods in microarray gene expression data: A systematic mapping study},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Known and unknown event detection in OTDR traces by deep
learning networks. <em>NCA</em>, <em>34</em>(22), 19655–19673. (<a
href="https://doi.org/10.1007/s00521-022-07634-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical fiber links are customarily monitored by Optical Time Domain Reflectometer (OTDR), an optoelectronic instrument that measures the scattered or reflected light along the fiber and returns a signal, namely the OTDR trace. OTDR traces are typically analyzed by experts in laboratories or by hand-crafted algorithms running in embedded systems to localize critical events occurring along the fiber. In this work, we address the problem of automatically detecting optical events in OTDR traces through a deep learning model that can be deployed in embedded systems. In particular, we take inspiration from Faster R-CNN and present the first 1D object-detection neural network for OTDR traces. Thanks to an ad-hoc preprocessing pipeline for OTDR traces, we can also identify unknown events, namely events that are not represented in training data but that might indicate rare and unforeseen situations that need to be reported. The resulting network brings several advantages with respect to existing solutions, as these typically classify fixed-size windows of OTDR traces, thus are less accurate in the localization. Moreover, existing solutions do not report events that cannot be safely associated to any label in the training set. Our experiments, performed on real OTDR traces, show very promising performance, and can be directly executed on embedded OTDR devices.},
  archive      = {J_NCA},
  author       = {Rizzo, Antonino Maria and Magri, Luca and Rutigliano, Davide and Invernizzi, Pietro and Sozio, Enrico and Alippi, Cesare and Binetti, Stefano and Boracchi, Giacomo},
  doi          = {10.1007/s00521-022-07634-2},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19655-19673},
  shortjournal = {Neural Comput. Appl.},
  title        = {Known and unknown event detection in OTDR traces by deep learning networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Amateur football analytics using computer vision.
<em>NCA</em>, <em>34</em>(22), 19639–19654. (<a
href="https://doi.org/10.1007/s00521-022-07692-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been an interest in visual sports analytics, and especially in player and ball detection, action recognition, and camera pose estimation in various sports. The greatest interest is associated with football or soccer. The purpose of this work is the design and implementation of a low-cost methodology that extracts football analytics from simple TV broadcasts, using solely computer vision techniques. In the paper, we discuss the state of the art in this field and propose an integrated pipeline that solves the problem of player localization in the court and extracts useful insights. Technical details concerning the proposed methods that enhance track player–ball movement and camera pose, along with post-analytic results, are presented. The paper concludes with some future expansions of the proposed pipeline.},
  archive      = {J_NCA},
  author       = {Mavrogiannis, Panagiotis and Maglogiannis, Ilias},
  doi          = {10.1007/s00521-022-07692-6},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19639-19654},
  shortjournal = {Neural Comput. Appl.},
  title        = {Amateur football analytics using computer vision},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated distinction of neoplastic from healthy liver
parenchyma based on machine learning. <em>NCA</em>, <em>34</em>(22),
19629–19638. (<a
href="https://doi.org/10.1007/s00521-022-07599-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver segmentation is a basic and important procedure in liver transplantation surgery as well as in liver volumetric assessment. What is commonly done in clinical practice and research is the time-consuming manual delineation of liver regions. Machine learning techniques offer a technological evolution in the field of medical imaging segmentation. By scanning and using computed tomography (CT) slices of liver cancer of different patients as input datasets for our experiments, we here aim to provide an automatic way to recognize liver tissue among other organs, to assess its volume, and importantly detect and measure the volume of hepatocellular carcinoma (HCC). The proposed tool for an automatic analysis of liver volumetry could be applied in several clinical cases, especially as a fast accurate indicator of healthy liver parenchyma before a major hepatectomy is performed so that the remaining healthy tissue and thus disease prognosis after tumor resection can be predicted. Similarly, volumetry prediction may facilitate liver transplantation by allowing an accurate morphometric matching of liver transplant with the host. Thus, such an approach may define the therapeutic strategy of choice in a personalized manner. Firstly, the performance of the proposed architecture model En-ResUNet is estimated for various samples using a variety of metrics, secondly a scheme is presented to automatically analyze the state of liver, diseased or not.},
  archive      = {J_NCA},
  author       = {Giannou, Olympia and Giannou, Anastasios D. and Zazara, Dimitra E. and Pavlidis, Georgios},
  doi          = {10.1007/s00521-022-07599-2},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19629-19638},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated distinction of neoplastic from healthy liver parenchyma based on machine learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiclass sentiment analysis on COVID-19-related tweets
using deep learning models. <em>NCA</em>, <em>34</em>(22), 19615–19627.
(<a href="https://doi.org/10.1007/s00521-022-07650-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 is an infectious disease with its first recorded cases identified in late 2019, while in March of 2020 it was declared as a pandemic. The outbreak of the disease has led to a sharp increase in posts and comments from social media users, with a plethora of sentiments being found therein. This paper addresses the subject of sentiment analysis, focusing on the classification of users’ sentiment from posts related to COVID-19 that originate from Twitter. The period examined is from March until mid-April of 2020, when the pandemic had thus far affected the whole world. The data is processed and linguistically analyzed with the use of several natural language processing techniques. Sentiment analysis is implemented by utilizing seven different deep learning models based on LSTM neural networks, and a comparison with traditional machine learning classifiers is made. The models are trained in order to distinguish the tweets between three classes, namely negative, neutral and positive.},
  archive      = {J_NCA},
  author       = {Vernikou, Sotiria and Lyras, Athanasios and Kanavos, Andreas},
  doi          = {10.1007/s00521-022-07650-2},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19615-19627},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multiclass sentiment analysis on COVID-19-related tweets using deep learning models},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Consolidating incentivization in distributed neural network
training via decentralized autonomous organization. <em>NCA</em>,
<em>34</em>(22), 19599–19613. (<a
href="https://doi.org/10.1007/s00521-022-07374-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data has reignited research interest in machine learning. Massive quantities of data are being generated regularly as a consequence of the development in the Internet, social networks, and online sensors. Particularly deep neural networks benefited greatly from this unprecedented data availability. Large models with millions of parameters are becoming common, and big data has been proved to be essential for their effective training. The scientific community has come up with a number of methods to create more accurate models, but most of these methods require high-performance infrastructure. There is also the issue of privacy, since anyone using leased processing power from a remote data center is putting their data in the hands of a third party. Studies on decentralized and non-binding methods among individuals with commodity hardware are scarce, though. Our work on LEARNAE seeks to respond to this challenge by creating a totally distributed and fault-tolerant framework of artificial neural network training. In our recent work, we demonstrated a method for incentivizing peers to participate to collaborative process, even if they are not interested in the neural network produced. For this, LEARNAE included a subsystem that rewards participants proportionately to their contribution using digital assets. In this article we add another important piece to the puzzle: A decentralized mechanism to mitigate the effect of bad actors, such as nodes that attempt to exploit LEARNAE’s network power without following the established rewarding rules. This is achieved by a novel reward mechanism, which takes into account the overall contribution of each node to the entire swarm. The network collaboratively builds a contribution profile for every participant, and the final rewards are dictated by these profiles. Taking for granted that the majority of the peers are benevolent, the whole process is tamper-proof, since it is implemented on blockchain and thus is protected by distributed consensus. All codebase is structured as a decentralized autonomous organization, which allows LEARNAE to embed new features like digital asset locking, proposal submitting, and voting.},
  archive      = {J_NCA},
  author       = {Nikolaidis, Spyridon and Refanidis, Ioannis},
  doi          = {10.1007/s00521-022-07374-3},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19599-19613},
  shortjournal = {Neural Comput. Appl.},
  title        = {Consolidating incentivization in distributed neural network training via decentralized autonomous organization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning and multimodal feature fusion for the aided
diagnosis of alzheimer’s disease. <em>NCA</em>, <em>34</em>(22),
19585–19598. (<a
href="https://doi.org/10.1007/s00521-022-07501-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate diagnosis of Alzheimer’s disease (AD) in the early stages, such as significant memory concern (SMC) and mild cognitive impairment (MCI), is essential in order to slow its progression through timely treatment. Recent achievements have shown that fusing multimodal neuroimaging data effectively facilitates AD diagnosis. However, most proposed fusion methods simply add or concatenate multimodal features and do not make full use of nonlinear features and texture features across the range of modalities. This paper proposes a diagnostic model that effectively diagnoses AD in different stages by fusing functional magnetic resonance imaging (fMRI) and structural MRI (sMRI) information. First, fMRI and sMRI scans are preprocessed, and mean regional homogeneity (mReHo) transformation is performed for the preprocessed fMRI scans. Then, 3DMR-PCANet extracts features of mReHo images. The basic ResNet module is stacked to build a 3DResNet-10 model for feature extraction of sMRI scans. Next, two image features are fused by kernel canonical correlation analysis. Finally, a support vector machine (SVM) is utilized for the classification of fused features. Experimental results on the Alzheimer&#39;s Disease Neuroimaging dataset demonstrate the effectiveness of the proposed method. Specifically, this method improves on the accuracy, specificity, sensitivity, F1 value and area under the curve (AUC) of existing methods in comparisons of the normal control (NC) versus SMC, NC versus MCI, NC versus AD, SMC versus MCI, SMC versus AD, and MCI versus AD groups, which confirms that the proposed method can mine information on the correlation between fMRI and sMRI data of the same subject and can effectively classify AD patients in different stages.},
  archive      = {J_NCA},
  author       = {Jia, Hongfei and Lao, Huan},
  doi          = {10.1007/s00521-022-07501-0},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19585-19598},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning and multimodal feature fusion for the aided diagnosis of alzheimer&#39;s disease},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). COREM2 project: A beginning to end approach for cyber
intrusion detection. <em>NCA</em>, <em>34</em>(22), 19565–19584. (<a
href="https://doi.org/10.1007/s00521-022-07084-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing need to use online services has made it necessary to ensure protection against all kinds of cyber-threats. This research effort aims to tackle network security problems as follows: It introduces the hybrid intrusion detection system COREM2 that successfully detects nine cyber-attacks. Its architecture comprises of a two-dimensional convolutional neural network (2-D CNN), a recurrent neural network with long short-term memory layers and a multilayer perceptron. The COREM2 was successfully tested against the timely Kitsune Network Attack Dataset, achieving an overall accuracy of 98.64\% and 98.92\% in the training and testing phases, respectively. Since this is a multiclass classification effort, the “one-versus-all strategy” was employed to validate the introduced model, which has proved its ability to generalize. COREM2 outperforms other state-of-the-art approaches achieving overall accuracy above 98\%, rare for field cyber-security intrusion. We strongly suggest that it can be safely used as a prototype for further research on network security enhancement. Furthermore, this research introduces a holistic approach for cyber intrusion detection, using the COREM2 in order to classify network traffic as benign or malicious. It captures network flow packets in the form of PCAP files (packet capture), and it stores them in.csv files and it evaluates them in order to perform classification in ten classes as provided by the Kitsune Dataset. If the malicious traffic exceeds a certain limit, the model notifies the user to take all necessary actions. The proposed method has an average processing power of 10,000 packets per 8 s. It potentially can be used in any device that has Internet access.},
  archive      = {J_NCA},
  author       = {Psathas, Anastasios Panagiotis and Iliadis, Lazaros and Papaleonidas, Antonios and Bountas, Dimitris},
  doi          = {10.1007/s00521-022-07084-w},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19565-19584},
  shortjournal = {Neural Comput. Appl.},
  title        = {COREM2 project: A beginning to end approach for cyber intrusion detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self organizing maps for cultural content delivery.
<em>NCA</em>, <em>34</em>(22), 19547–19564. (<a
href="https://doi.org/10.1007/s00521-022-07376-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tailored analytics play a key role in the successful delivery of cultural content to huge and diverse groups. Primarily the latter depends on a number of information retrieval factors determining user experience quality, most prominently precision, recall, and timing. These imply that cultural analytics should be designed with strong predictive power. In turn, the latter relies heavily on the clustering of the system user base. A self organizing map is a neural network architecture trained in an unsupervised way through a modified Hebbian rule to couple distances between two distinct spaces such that a manifold in the high dimensional space is projected smoothly to the lower dimensional one. The twofold focus of this work is the development of a tensor user distance metric for SOMs as well as the inclusion of behavioral attributes therein, both aiming at additional descriptive power and clustering flexibility. As a concrete example, the proposed SOMs are applied to data taken from a cultural content delivery system. The proposed methodology is evaluated based on a scoring method assessing both complexity and clustering quality criteria, including the number of epochs, the average cluster distance, and the topological error, with encouraging results.},
  archive      = {J_NCA},
  author       = {Drakopoulos, Georgios and Giannoukou, Ioanna and Mylonas, Phivos and Sioutas, Spyros},
  doi          = {10.1007/s00521-022-07376-1},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19547-19564},
  shortjournal = {Neural Comput. Appl.},
  title        = {Self organizing maps for cultural content delivery},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning for groundwater pollution source
identification and monitoring network optimization. <em>NCA</em>,
<em>34</em>(22), 19515–19545. (<a
href="https://doi.org/10.1007/s00521-022-07507-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of the source in groundwater pollution is the only way to drastically deal with resulting environmental problems. This can only be achieved by an appropriate monitoring network, the optimization of which is prerequisite for the solution of the inverse modeling problem, i.e., identifying the source of the pollutant on the basis of measurements taken within the pollution field. For this reason, a theoretical confined aquifer with two pumping wells and six suspected sources is studied. Simulations of combinations of possible source locations, and hydraulic parameters, produce sets of measurement features for a 29 × 29 grid representing potential monitoring wells. Three sets of simulations are conducted to produce synthetic datasets, representing different groundwater pollution modeling methods. Features (input-X variables) coupled with respective sources (output-Y variables) are formulated in two different dataset formats (Types A, B) in order to train classification (random forests, multilayer perceptron) and computer vision (convolutional neural networks) algorithms, respectively, to solve the inverse modeling problem. In addition, appropriate feature selection and trial-and-error tests are employed for supporting the optimization of monitoring wells’ number, locations and sampling frequency. The methodology can successfully produce various sub-optimal monitoring strategies for various budgets.},
  archive      = {J_NCA},
  author       = {Kontos, Yiannis N. and Kassandros, Theodosios and Perifanos, Konstantinos and Karampasis, Marios and Katsifarakis, Konstantinos L. and Karatzas, Kostas},
  doi          = {10.1007/s00521-022-07507-8},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19515-19545},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning for groundwater pollution source identification and monitoring network optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Applying machine learning techniques to predict and explain
subscriber churn of an online drug information platform. <em>NCA</em>,
<em>34</em>(22), 19501–19514. (<a
href="https://doi.org/10.1007/s00521-022-07603-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presently, most markets are extremely saturated and, as a result, businesses are highly competitive. Hence, avoiding the loss of preexisting customers is pivotal, deeming the prediction of customer loss crucial to efficiently target potential churners and attempt to retain them. This study provides an in-depth comparison of various machine learning techniques and advanced preprocessing methods as well as an overall guide for handling churn prediction problems. Churn prediction is fundamentally a binary classification problem. To handle said problem, within this paper, numerous methods that belong to different machine learning categories (linear, nonlinear, ensemble, neural networks) are constructed, optimized and trained on the subscription data of a new real-world dataset originating from a popular online drug information platform that provides information on drugs and drug substances as well as professional tools for pharmacotherapy decision making. In contrast with previous works that address traditional customer churn in relation to telecom, banking or insurance industries, the current study addresses online subscriber churn where users might churn at any given moment. This study also focuses on the proper preprocessing of the given data via advanced machine learning methods, as well as evaluating the models under different conditions to measure their robustness. The results are presented, compared, analyzed and explained. Extensive feature importance analysis is performed to explain not only the models themselves but to also indicate the main factors that contribute toward churning. The findings co-align with the notion that, under the important condition that the dataset is preprocessed using not only statistical methods but machine learning techniques as well, all methods perform adequately and are generally viable options, but ensemble methods, namely Random Forests, are more flexible and resistant toward outliers. Feature importance analysis indicates that usage, not demographic data, is the prime indicator of churn.},
  archive      = {J_NCA},
  author       = {Theodoridis, Georgios and Tsadiras, Athanasios},
  doi          = {10.1007/s00521-022-07603-9},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19501-19514},
  shortjournal = {Neural Comput. Appl.},
  title        = {Applying machine learning techniques to predict and explain subscriber churn of an online drug information platform},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep autoencoders for acoustic anomaly detection:
Experiments with working machine and in-vehicle audio. <em>NCA</em>,
<em>34</em>(22), 19485–19499. (<a
href="https://doi.org/10.1007/s00521-022-07375-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing usage of digital microphones has generated an increased interest in the topic of Acoustic Anomaly Detection (AAD). Indeed, there are several real-world AAD application domains, including working machines and in-vehicle intelligence (the main target of this research project). This paper introduces three deep AutoEncoders (AE) for unsupervised AAD tasks, namely a Dense AE, a Convolutional Neural Network (CNN) AE and Long Short-Term Memory Autoencoder (LSTM) AE. To tune the deep learning architectures, development data were adopted from public domain audio datasets related with working machines. A large set of computational experiments was held, showing that the three proposed deep autoencoders, when combined with a melspectrogram sound preprocessing, are quite competitive and outperform a recently proposed AE baseline. Next, on a second experimental stage, aiming to address the final in-vehicle passenger safety goal, the three AEs were adapted to learn from in-vehicle normal audio, assuming three realistic scenarios that were generated by a synthetic audio mixture tool. In general, a high quality AAD discrimination was obtained: working machine data – 72\% to 91\%; and in-vehicle audio – 78\% to 81\%. In conjunction with an automotive company, an in-vehicle AAD intelligent system prototype was further developed, aiming to test a selected model (LSTM AE) during a pilot demonstration event that targeted the cough anomaly. Interesting results were obtained, with the AAD system presenting a high cough classification accuracy (e.g., 100\% for front seat locations).},
  archive      = {J_NCA},
  author       = {Coelho, Gabriel and Matos, Luís Miguel and Pereira, Pedro José and Ferreira, André and Pilastri, André and Cortez, Paulo},
  doi          = {10.1007/s00521-022-07375-2},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19485-19499},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep autoencoders for acoustic anomaly detection: Experiments with working machine and in-vehicle audio},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantic segmentation supervised deep-learning algorithm for
welding-defect detection of new energy batteries. <em>NCA</em>,
<em>34</em>(22), 19471–19484. (<a
href="https://doi.org/10.1007/s00521-022-07474-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the main component of the new energy battery, the safety vent usually is welded on the battery plate, which can prevent unpredictable explosion accidents caused by the increasing internal pressure of the battery. The welding quality of safety vent directly affects the safety and stability of the battery; so, the welding-defect detection is of great significance. In this paper, we researched the welding-defect detection method based on semantic segmentation algorithm. The automatic detection method should recognize, locate, and count the area of defects. However, small differences between inter-classes, strong variations in defect size, and uncertain annotation create challenges for defect semantic segmentation. To address these challenges, a customized deep learning model based on two-branch architecture is proposed to segment welding-defect at the pixel level. This architecture involves three modules as follows, (i) The Spatial Branch is elaborately designed to capture spatial details and generate high-resolution feature representation; (ii) The Context Branch is responsible for obtaining semantic context; (iii) The Feature Fusion Block is proposed to merge the two types of feature representation and enhance mutual connections. Furthermore, a welding image dataset was built to validate our method, and the network’s performance of defect segmentation and classification were evaluated by the defects images and the normal images, respectively. Data augmentation strategies are performed to overcome the problem of imbalanced distribution and inaccurate labels of the dataset, which is caused by the ambiguity of defect edges and the subjectivity of manual annotation. The experiment results indicate that our method achieves 86.704 $$\%$$ of mIoU (mean intersection of union), which supports the effectiveness of the deep learning model in segmenting defects. Besides, 98.896 $$\%$$ of AP (average precision) and 0 $$\%$$ of MDR (miss detection rate) further suggests the applicability of the proposed framework in industrial applications.},
  archive      = {J_NCA},
  author       = {Yang, Yatao and He, Yuqing and Guo, Haolin and Chen, Ziliang and Zhang, Li},
  doi          = {10.1007/s00521-022-07474-0},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19471-19484},
  shortjournal = {Neural Comput. Appl.},
  title        = {Semantic segmentation supervised deep-learning algorithm for welding-defect detection of new energy batteries},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel multi-step forecasting strategy for enhancing deep
learning models’ performance. <em>NCA</em>, <em>34</em>(22),
19453–19470. (<a
href="https://doi.org/10.1007/s00521-022-07158-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-step forecasting is considered as an open challenge in time-series analysis. Although several approaches were proposed to address this complex prediction problem, none of them could secure the development of an efficient as well as a reliable multi-step forecasting model. In this research, we present a novel strategy for the development of accurate, robust and reliable multi-step deep learning models. The proposed strategy is based on a sophisticated algorithmic framework, which is able to process, transform and deliver “high-quality” and “suitable” time-series training data. The suitability of the transformed data is secured by taking into consideration and exploiting the dynamics and the sampling of the time-series in conjunction with the forecasting horizon as well as the imposition of the stationarity property. The conducted numerical experiments performed on challenging real-world time-series datasets from the application domains: finance, commodity, climate and air quality, which demonstrate the efficacy, robustness and reliability of the proposed multi-step strategy.},
  archive      = {J_NCA},
  author       = {Livieris, Ioannis E. and Pintelas, Panagiotis},
  doi          = {10.1007/s00521-022-07158-9},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19453-19470},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel multi-step forecasting strategy for enhancing deep learning models’ performance},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multisource financial sentiment analysis for detecting
bitcoin price change indications using deep learning. <em>NCA</em>,
<em>34</em>(22), 19441–19452. (<a
href="https://doi.org/10.1007/s00521-022-07509-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of deep learning (DL) in various areas, such as computer vision, fueled the interest in several novel DL-enabled applications, such as financial trading, which could potentially surpass the previously used approaches. Indeed, there has been a plethora of DL-based trading methods proposed in recent years. Despite the success of these methods, they typically rely on a very restricted set of information, usually employing only price-related information. As a result, they ignore sentiment-related information, which can have a profound impact and be a strong predictor of various assets, such as cryptocurencies. The contribution of this paper is multifold. First, we examine whether the use of sentiment information, as extracted by various online sources, including news articles, is beneficial when training DL agents for trading. Then, given the difficulty of training reliable sentiment extractors for financial applications, we evaluate the impact of using different DL models as sentiment extractors, as well as employ an unsupervised training pipeline for further improving their performance. Finally, we propose an effective multisource sentiment fusion approach that can improve the performance over the rest of the evaluated approaches. The conducted experiments have been performed using several different configurations and models, ranging from multilayer perceptrons (MLPs) to convolutional neural networks (CNNs) and recurrent neural networks (RNNs), to provide a reliable evaluation of sentiment-aware DL-based trading strategies providing evidence that sentiment information might be a stronger predictor compared to the information provided by the actual price time series for Bitcoin.},
  archive      = {J_NCA},
  author       = {Passalis, Nikolaos and Avramelou, Loukia and Seficha, Solon and Tsantekidis, Avraam and Doropoulos, Stavros and Makris, Giorgos and Tefas, Anastasios},
  doi          = {10.1007/s00521-022-07509-6},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19441-19452},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multisource financial sentiment analysis for detecting bitcoin price change indications using deep learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural intuitionistic fuzzy system with justified
granularity. <em>NCA</em>, <em>34</em>(22), 19423–19439. (<a
href="https://doi.org/10.1007/s00521-022-07504-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy systems are intensively investigated and extended to construct forecasting models. In particular, intuitionistic fuzzy sets are used to capture higher levels of uncertainty occurring in the modeled data. Neural networks are also used to reflect nonlinearity relationships frequently observed in time series. This paper proposes a new hybrid system merging fuzzy system with neural networks and an advanced optimization technique, the principle of justified granularity. Using this technique, we construct an innovative time-series forecasting model. In the experimental part of the paper, we demonstrate the advantages arising from applying the proposed approach to metal price forecasting. Finally, we provide evidence that the proposed model is competitive with the current state-of-the-art models for the forecasting horizons of one and five days.},
  archive      = {J_NCA},
  author       = {Hajek, Petr and Froelich, Wojciech and Olej, Vladimir and Novotny, Josef},
  doi          = {10.1007/s00521-022-07504-x},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19423-19439},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural intuitionistic fuzzy system with justified granularity},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent fault diagnosis of rolling bearings based on
LSTM with large margin nearest neighbor algorithm. <em>NCA</em>,
<em>34</em>(22), 19401–19421. (<a
href="https://doi.org/10.1007/s00521-022-07353-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial machinery, rolling bearings are often rated as the most likely to fail in mechanical systems due to excessive working stress. Therefore, effective methods to diagnose the faults in rolling bearings are becoming necessary and required to ensure economic efficiency and manufacturing reliability. Recently, several studies tried to develop deep learning models for intelligent fault diagnosis based on traditional methods. However, creating an effective method for fault recognition is still a major obstacle due to varying operating conditions, large amount of collected data and redundant noise in measured vibration signals. Advanced signal processing techniques and traditional strategies often consist of shallow constructs that suffer from learning a huge amount of data, losing valuable fault information, yielding in low accuracy and labor time losses. In this paper, a combination method of long short-term memory with large margin nearest neighbor (LSTM-LMNN) is designed to address the above issues and effectively recognize multi-faults in mechanical rotating machines. Different from traditional LSTMs, the proposed LSTM-LMNN utilizes a powerful orthogonal weight initialization technique to memorize the critical information of faults during parameters updating and strongly organizing the samples of each condition in pattern classification process. Two experimental studies of bearing fault diagnosis demonstrate that the proposed LSTM-LMNN model outperformed other existing methods in terms of diagnostic efficiency, stability, and reliability.},
  archive      = {J_NCA},
  author       = {Aljemely, Anas H. and Xuan, Jianping and Al-Azzawi, Osama and Jawad, Farqad K. J.},
  doi          = {10.1007/s00521-022-07353-8},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19401-19421},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intelligent fault diagnosis of rolling bearings based on LSTM with large margin nearest neighbor algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on deep learning modeling in real life:
Anomaly detection, biomedical, concept analysis, finance, image
analysis, recommendation. <em>NCA</em>, <em>34</em>(22), 19397–19400.
(<a href="https://doi.org/10.1007/s00521-022-07832-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Iliadis, Lazaros and Magri, Luca},
  doi          = {10.1007/s00521-022-07832-y},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {19397-19400},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on deep learning modeling in real life: Anomaly detection, biomedical, concept analysis, finance, image analysis, recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-scale channel-wise convolution-based multi-level
heat stress assessment. <em>NCA</em>, <em>34</em>(21), 19181–19191. (<a
href="https://doi.org/10.1007/s00521-022-07518-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the previous works on heat stress detection, various state-of-the-art machine learning techniques had been used to detect stress patterns from electroencephalographic (EEG) signals. Since the handcrafted feature engineering-based approaches pose certain limitations and are sensitive to transform the nonlinearities of EEG, deep learning techniques have drawn attention in the domain of EEG-based applications. Moreover, existing approaches for stress detection consider the whole frequency band (delta to gamma) which conceals the redundant and lossy information that increased the false detection rate. Also, these approaches were implemented only to identify the stress in binary classes and confined their application to identifying the level of stress. Therefore, a multi-scale channel-wise convolution-based multi-level heat stress assessment has been proposed in this paper. The novel contributions of this work are (1) designing a multi-scale convolutional neural network (MS-CNN) for extracting precise information from individual frequency bands of EEG, (2) use of sparse connectivity to reduce the redundant information and increase the performance with less trainable parameters, and (3) multi-level heat stress assessment for precise identification of the severity of stress. The proposed approaches were evaluated on pre-recorded data of 10 rats in a simulated laboratory environment. The high accuracy of approximately 96–97\% and 90–92\% has been achieved for binary and multi-level stress detection. There is approximately a 6 to 50\% reduction in the trainable parameters with a 2\% improvement of accuracy achieved on adopting channel-wise convolution over MS-CNN and deep convolutional neural network (DCNN). This demonstrates the effectiveness of the adopted multiscale feature extraction and sparse connectivity to improve the performance with a less complex model.},
  archive      = {J_NCA},
  author       = {Nagpal, Chetna and Upadhyay, Prabhat Kumar},
  doi          = {10.1007/s00521-022-07518-5},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {19181-19191},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-scale channel-wise convolution-based multi-level heat stress assessment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Preassigned/fixed-time stochastic synchronization of complex
networks via simpler nonchattering quantified adaptive control
strategies. <em>NCA</em>, <em>34</em>(21), 19161–19179. (<a
href="https://doi.org/10.1007/s00521-022-07503-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the preassigned-time (PAT) and fixed-time (FXT) synchronization of complex networks with stochastic disturbances, in which simpler nonchattering quantified adaptive controllers are designed. First, more relaxed conditions are proposed, and the settling time is calculated more precisely compared with existing results by utilizing some constructing comparison systems. Furthermore, different from existing results, the novel quantified adaptive controllers without sign function and linear feedback term not only are simpler but also can avoid chattering phenomenon. In addition, communication constraints and limited bandwidths are fully taken into account. Therefore, each parameter that needs to be transmitted will be quantified. Moreover, based on more relaxed conditions, several novel PAT control schemes are considered, in which the settling time can be preassigned based on actual demand. Finally, numerical simulation illustrates the effectiveness of the theories about the PAT and FXT synchronization.},
  archive      = {J_NCA},
  author       = {Hou, Meng and He, Qiushi and Ma, Yuechao},
  doi          = {10.1007/s00521-022-07503-y},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {19161-19179},
  shortjournal = {Neural Comput. Appl.},
  title        = {Preassigned/fixed-time stochastic synchronization of complex networks via simpler nonchattering quantified adaptive control strategies},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-intrusive load monitoring based on semi-supervised
smooth teacher graph learning with voltage–current trajectory.
<em>NCA</em>, <em>34</em>(21), 19147–19160. (<a
href="https://doi.org/10.1007/s00521-022-07508-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-intrusive load monitoring (NILM) is a novel and cost-effective technology for monitoring load electricity energy consumption detail. It can support the construction of “energy internet” and electricity consumption big data in smart cities, promote the construction of internet ecology, and support the dual carbon goal achieved. Recently, most current researchers have employed machine learning methods to make those inferences. As the most challenging problem in this specific field, the machine learning algorithms usually require a large pool of labeled observations and are poor in multi-state load identification. In this paper, we first design a semi-supervised learning backbone that leverages external and internal structural information to reduce the required labeling effort. Then, a smooth teacher graph based on semi-supervised learning model is proposed for multi-state load, the teacher graph helps the fusing of cluster become tighter and more effective for multi-state load signatures. Specifically, we use the color V–I trajectory to enhance the load signature’s uniqueness. Experiments in public datasets PLAID and WHITED show the performance of the proposed method. We find that our algorithm could outperform state-of-the-art results on these datasets.},
  archive      = {J_NCA},
  author       = {Han, Yinghua and Li, Keke and Feng, Hantong and Zhao, Qiang},
  doi          = {10.1007/s00521-022-07508-7},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {19147-19160},
  shortjournal = {Neural Comput. Appl.},
  title        = {Non-intrusive load monitoring based on semi-supervised smooth teacher graph learning with voltage–current trajectory},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LZW-CIE: A high-capacity linguistic steganography based on
LZW char index encoding. <em>NCA</em>, <em>34</em>(21), 19117–19145. (<a
href="https://doi.org/10.1007/s00521-022-07499-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the effect of digitalization, the transfer of all text documents over the Internet rather than human transmission has increased, and this situation has revealed the idea that text documents can be used as a carrier that can safely store information. Realizing that methods such as word-line shifting, usage of spaces, replacement of the word with its synonym are fragile against steganalysis, led to new searches and it was determined that deep learning models were more resistant to detecting the presence of hidden words. In this study, the text generation based on the information that is wanted to be hidden without a carrier text, both at word and character level, was performed. Arithmetic coding, perfect tree and Huffman coding methods were used as secret information embedding methods in text generation based on word level. In this part of the study, bidirectional LSTM architecture with attention mechanism was created as language model. In text generation based on character level, a new secret information embedding algorithm is created by combining the LZW compression algorithm with the Char Index (LZW-Char Index Encoding) method. The character-level model is created as a result of using the encoder–decoder architecture together with bidirectional LSTM and Bahdanau attention. The proposed method was evaluated from the perspectives of information embedding efficiency, information imperceptibility and hidden information capacity. As a result of the experiments, it was determined that the method exceeded the state-of-the-art performance and was more resistant to steganalysis.},
  archive      = {J_NCA},
  author       = {Varol Arısoy, Merve},
  doi          = {10.1007/s00521-022-07499-5},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {19117-19145},
  shortjournal = {Neural Comput. Appl.},
  title        = {LZW-CIE: A high-capacity linguistic steganography based on LZW char index encoding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A trust-based large-scale group decision making consensus
reaching framework for intercity railway public–private partnership
model selection. <em>NCA</em>, <em>34</em>(21), 19091–19115. (<a
href="https://doi.org/10.1007/s00521-022-07462-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public–private partnership is a form of contract that the government regards private sectors as long-term partners in infrastructures and public services. With increasing intercity travel passengers, the intercity railway PPP projects have attracted more and more attention. The PPP model selection is a complex decision problem for PPP project construction. It usually requires many experts from different fields to be involved in project process, which belongs to a large-scale group decision making (LSGDM) problem. Therefore, a trust-based LSGDM consensus reaching framework is proposed for intercity railway PPP model selection. Firstly, this paper develops a new clustering algorithm by considering the direct trust relationship and the opinion deviation. Based on the trust value between experts within subgroups, a trust consensus model to obtain stable trust relationships is built. Then, the weights associated with experts and subgroups are calculated. Furthermore, minimum adjustment models for different opinion consensus levels are built to improve the opinion consensus of subgroups. Finally, Hangzhou-Shaoxing-Taizhou intercity railway PPP model selection problem is offered to show the effectiveness of the new approach, and comparative analysis is conducted.},
  archive      = {J_NCA},
  author       = {Meng, Fanyong and Chen, Bicong and Wang, Zongrun},
  doi          = {10.1007/s00521-022-07462-4},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {19091-19115},
  shortjournal = {Neural Comput. Appl.},
  title        = {A trust-based large-scale group decision making consensus reaching framework for intercity railway public–private partnership model selection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Augmenting the global semantic information between words to
heterogeneous graph for deception detection. <em>NCA</em>,
<em>34</em>(21), 19079–19090. (<a
href="https://doi.org/10.1007/s00521-022-07492-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting deceptive reviews can assist customers in grasping the real evaluation of products and services to make better purchase decisions and help companies satisfy timely to their customers’ expectations. Methods based on neural networks for deceptive review detection have made significant progress in recent years. Models using attention mechanisms such as BERT have demonstrated the ability to capture contextual information in review texts. However, their ability to capture global information about the word level is limited. This latter is the strength of Graph Convolutional Networks (GCNs). In this study, we propose a detection model (SGCN-BERT) based on the combination of Semantic Graph Convolutional Network (SGCN) and pre-trained model BERT. During the construction of the heterogeneous review graph, we consider both the co-occurrence relationship and semantic relationship between words to enrich the graph information. The graph embedding of the reviews are obtained through SGCN and input to BERT together with word embeddings. Global and local information containing lexical-semantic interact through different layers of BERT, allowing them to influence and build the final classification representation jointly mutually. Comprehensive tests on four public datasets show that our method outperforms previous methods and has good generalization capability.},
  archive      = {J_NCA},
  author       = {Li, Shi and Cheng, Wenfeng},
  doi          = {10.1007/s00521-022-07492-y},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {19079-19090},
  shortjournal = {Neural Comput. Appl.},
  title        = {Augmenting the global semantic information between words to heterogeneous graph for deception detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning-based localization and segmentation of wrist
fractures on x-ray radiographs. <em>NCA</em>, <em>34</em>(21),
19061–19077. (<a
href="https://doi.org/10.1007/s00521-022-07510-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X-rays are the primary tools in examining the suspected fractures in humans in this era. Manual examination of X rays is a time-consuming process, which requires expert radiologists or trained orthopaedic surgeons. The demanding workloads, unavailability of radiologists in small setups and at primary/community health centres results in the inability to diagnose and delay in the treatment due to unnecessary referrals by the primary care clinicians. Moreover, the shortage of expert radiologists and orthopaedic surgeons in medically under-resourced areas such as rural areas in India have motivated us to develop an automated fracture detection model. We have developed a deep neural network to detect, localize and divide the wrist region into segments to identify fractures around wrist joint in radiographs. The orthopaedic surgeon has manually annotated the fractures by drawing a bounding box and segmented mask. We have utilized two different domains of datasets for the better convergence of the model. There is a similarity in the crack patterns of the surface crack image dataset and the wrist fracture dataset, which consists of 3000 and 315 images. A part of the dataset is made publicly available for research purposes to overcome data collection and labelling barriers for identifying wrist fractures. The crack patterns in the wrist bone samples are learned by effectively transferring the knowledge or weights obtained from surface crack datasets. The proposed architecture utilizes Feature Pyramid Network as the backbone architecture where the last-level max pool layer of the architecture is replaced with the concatenation of AdaptiveConcatPool, AdaptiveAvgPool, AdaptiveMaxPool layers. Additionally, the concept of freezing and unfreezing the network during two phases of transfer learning is utilized for better model convergence. Every radiograph is assigned a ground truth label for evaluating the accuracy of the model. The performance measure for fracture detection and localization is evaluated using the Average precision value using the concept of Intersection over Union. The result of the proposed model is compared against the ground truth label annotated by the radiologists and related studies. The average precision of 92.278 on 50° and 79.003 on a strict scale of 75° was reported for fracture detection. Similarly, the average precision of 77.445 on 50° and 52.156 on a strict scale of 75° was reported for fracture segmentation.},
  archive      = {J_NCA},
  author       = {Joshi, Deepa and Singh, Thipendra P. and Joshi, Anil Kumar},
  doi          = {10.1007/s00521-022-07510-z},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {19061-19077},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-based localization and segmentation of wrist fractures on X-ray radiographs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An attention-based hybrid deep neural networks for accurate
identification of transcription factor binding sites. <em>NCA</em>,
<em>34</em>(21), 19051–19060. (<a
href="https://doi.org/10.1007/s00521-022-07502-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transcription factors (TF) control gene expression by binding to specific regions of DNA sequence. TF play an important role in various disease processes, and their identification helps in understanding underlying gene regulation leading to disease risk. Currently, the most powerful models used for the predicting binding sites between TF and DNA sequence from ChIP-Seq dataset are lagging in terms of good feature extraction capabilities. We propose two models named PCLAtt and TranAtt for the prediction of 690 TF-cell line pairs from DNA sequence data. PCLAtt consists of two sets of convolutional neural networks—bidirectional long short-term memory (CNN-BiLSTM) layers in parallel followed by a multi-head attention layer and weight-shared dense layer which all contribute towards extracting efficient features from DNA sequence. TranAtt consists of convolution layers of a pre-trained model along with a BiLSTM layer and attention layer. The convolutional layers of the model act as a motif scanner and the BiLSTM layer learns the regulatory grammar of the motifs. Further, the attention mechanism is applied to give more importance to those sequence regions of DNA that consist of transcription factor binding motifs thus resulting in better performance of the proposed models. PCLAtt outperformed other state-of-the-art methods like DeepSEA, DanQ, TBiNet and DeepATT in prediction of binding sites between TF and the DNA sequence.},
  archive      = {J_NCA},
  author       = {Bhukya, Raju and Kumari, Archana and Dasari, Chandra Mohan and Amilpur, Santhosh},
  doi          = {10.1007/s00521-022-07502-z},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {19051-19060},
  shortjournal = {Neural Comput. Appl.},
  title        = {An attention-based hybrid deep neural networks for accurate identification of transcription factor binding sites},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A distributed EMDN-GRU model on spark for passenger waiting
time forecasting. <em>NCA</em>, <em>34</em>(21), 19035–19050. (<a
href="https://doi.org/10.1007/s00521-022-07482-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is hard to forecast waiting time from mobile trajectory big data on the traditional centralized mining platform, and especially the taxi driving direction cannot be clearly distinguished by the GPS trajectories of taxicabs in intelligent transportation systems. To this end, we propose a direction identification method (named CA-D) combined with Coordinate Axis and GPS Direction to distinguish taxi driving direction and then establish a distributed model (named EMDN-GRU) on Spark to forecast passenger waiting time based on an Empirical Mode Decomposition (EMD) algorithm with Normalization and a Gated Recurrent Unit (GRU) model. Specifically, in the process of waiting time forecasting, the CA-D method is used to differentiate directions to reduce the data interference caused by different taxi driving directions. Furthermore, the EMD algorithm with normalization is utilized to process large-scale GPS trajectory data. Finally, the GRU model with adjusted parameters is employed to forecast the time-series data obtained in the previous step, and the forecasting results are denormalized and superimposed to produce waiting time for passengers. Compared with LSTM, GRU, EMD-LSTM, EMD-GRU, CNN, and BP, the experimental results from a case study indicate that EMDN-GRU is significantly superior to others. In particular, from three data sets of weekday, weekend, and one week, the MAPE values of EMDN-GRU are reduced by 92.48\%, 95.01\%, and 90.47\% at most.},
  archive      = {J_NCA},
  author       = {Xia, Dawen and Bai, Yu and Geng, Jian and Zhang, Wenyong and Hu, Yang and Li, Yantao and Li, Huaqing},
  doi          = {10.1007/s00521-022-07482-0},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {19035-19050},
  shortjournal = {Neural Comput. Appl.},
  title        = {A distributed EMDN-GRU model on spark for passenger waiting time forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Road anomaly detection using a dynamic sliding window
technique. <em>NCA</em>, <em>34</em>(21), 19015–19033. (<a
href="https://doi.org/10.1007/s00521-022-07436-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need to use roads is vital. In reality, smooth asphalt roads help people in their daily lives by saving time, avoiding traffic, and preserving the means of transportation. Recently, road anomaly detection using smartphone sensors such as accelerometers, gyroscopes, and GPS has become an important topic in the field of Intelligent Transportation Systems (ITS). In this context, many solutions have been proposed using Static Sliding Window (SSW), which is based on fixed window length. However, in the real world, the window length of the anomaly changes according to the speed value and the anomaly width, which is considered as a major drawback of SSW. In this paper, we propose a new technique called Dynamic Sliding Window (DSW), which aims to improve the quality of road anomaly detection by preprocessing the accelerometer signal. The proposed technique is applied to the same dataset and under the same conditions as the SSW. To cover all scenarios, thirty different virtual roads and several types of anomalies (speed bumps, metal bumps, and potholes) were used as training and test data. The resulting outputs of the DSW and SSW have been used by seven heuristic algorithms proposed by previous researchers and seven classifiers based on twelve feature detectors. The obtained results using the proposed DSW have been compared to those obtained using the SSW to demonstrate the efficiency of the former. Indeed, based on the comparison, the proposed DSW has proven its potential to outperform all previous road anomaly detection methods.},
  archive      = {J_NCA},
  author       = {Chibani, Noureddine and Sebbak, Faouzi and Cherifi, Walid and Belmessous, Khadidja},
  doi          = {10.1007/s00521-022-07436-6},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {19015-19033},
  shortjournal = {Neural Comput. Appl.},
  title        = {Road anomaly detection using a dynamic sliding window technique},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Soft computing techniques for modelling and multi-objective
optimization of magnetic field assisted powder mixed EDM process.
<em>NCA</em>, <em>34</em>(21), 18993–19014. (<a
href="https://doi.org/10.1007/s00521-022-07498-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work emphasizes on artificial neural network (ANN) and genetic algorithm (GA) for modelling and optimization of Magnetic Field Assisted powder mixed EDM (PMEDM) process. Fabricated Magnetic Field Assisted PMEDM setup was utilized for experimentation to machine Aluminium 6061 alloy by aluminium powder agglomerated in EDM oil. Peak current (IP), spark on duration (SON), spark off duration (SOFF), magnetic field (MF) and powder concentration (PC) are considered as machining parameters, and material removal rate (MRR), tool wear rate (TWR), surface roughness (SR), recast layer thickness (RLT) and overcut (OC) as machining performances. Mathematical models for predicting the responses namely MRR, TWR, SR, RLT and OC have been developed using feed-forward backpropagation ANN. The influence of machining parameters on MRR, TWR, SR, RLT and OC has been studied on developed ANN model. Further ANN models are interfaced with GA for multi-objective optimization to find out the optimum machining parameters for maximizing MRR, and minimizing TWR, SR, RLT and OC. ANN model developed provides better prediction on the responses for 2 hidden layers with 6 and 4 neurons in each hidden layer. The absolute error between the predicted and experimental results at optimized level observed is less than 5\%. Machined surface at optimum machining parameters revealed the presence of smaller craters, voids, micro-cracks and molten particles.},
  archive      = {J_NCA},
  author       = {Rouniyar, Arun Kumar and Shandilya, Pragya},
  doi          = {10.1007/s00521-022-07498-6},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18993-19014},
  shortjournal = {Neural Comput. Appl.},
  title        = {Soft computing techniques for modelling and multi-objective optimization of magnetic field assisted powder mixed EDM process},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-AUV cooperative navigation method based on the
augmented adaptive embedded cubature kalman filter algorithm.
<em>NCA</em>, <em>34</em>(21), 18975–18992. (<a
href="https://doi.org/10.1007/s00521-022-07450-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative navigation is part of the essential method for multiple autonomous underwater vehicles (AUVs) to gain an accurate position when performing tasks underwater. However, the positioning accuracy and stability of the traditional algorithms are affected by the dimension of state-space and the unknown time-varying noise in the ocean, which cannot meet the demand of the increasing positioning performance. For this problem, we propose a cooperative navigation method based on the augmented adaptive embedded cubature Kalman filter (A-AECKF) algorithm. Due to the non-additivity of the system noise in the realistic model of multi-AUV cooperative navigation, we augment the dimension of the state variables firstly, which combines with the system model to estimate the noise. Then we adopt embedded cubature criterion reselecting cubature points and their weights to minimize the positioning error caused by state augmentation. Finally, a nonlinear noise statistical estimator is used to estimate the time-varying ranging noise in real time, which effectively suppresses the positioning error caused by the non-Gaussian white noise. We evaluate the performance of the proposed A-AECKF cooperated navigation method comprehensively under the circumstance with high-dimensional state-space and the unknown time-varying measurement noise. Compared with other related algorithms, the experimental results indicate that the presented method possesses higher positioning accuracy and stability.},
  archive      = {J_NCA},
  author       = {Luo, Qinghua and Shao, Yang and Li, Jianfeng and Yan, Xiaozhen and Liu, Chao},
  doi          = {10.1007/s00521-022-07450-8},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18975-18992},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-AUV cooperative navigation method based on the augmented adaptive embedded cubature kalman filter algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Beyond the colors: Enhanced deep learning on invasive ductal
carcinoma. <em>NCA</em>, <em>34</em>(21), 18953–18973. (<a
href="https://doi.org/10.1007/s00521-022-07478-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the most common cancer-related causes of morbidity and mortality in women around the world, and its early detection is essential for successful treatment. Invasive ductal carcinoma (IDC) is the most prevalent phenotypic subtype of all breast cancers, accounting for 80\% of all cases. Deep learning (DL) has been used to diagnose breast cancer in a variety of situations. Our aims with this study were to contribute early detection of IDC as well as other cancer types and to help physicians while inspecting whole slide images belonging to possible cases. This study will also explore ways of improving the performance of deep learning models. While evaluating the models, the Matthew correlation coefficient (MCC) score was preferred instead of the F1 score, which did not take into account the real negatives. Pretrained networks (Xception, InceptionResNetV2, NASNetLarge) and two custom models, feature extraction technique, various color spaces (RGB, Gray, CMYK, HSV, HED, YIQ, YUV, YCrCb, LAB, LUV, XYZ), color changes (square, polynomial, multiplicative inverse) and ensemble modeling were tested. Our findings show that color data in image patches are crucial. The performance improvement of the convolutional neural network (CNN)-based model is achieved by generating various color spaces and their changes from the input channels in the preprocessing stage. It also showed that, despite the computation time advantage, feature extraction reduced the MCC score. Our novel ensemble methods based on precision and convex hull density were tested. We made an ensemble model with better MCC (0.6931) and F1 (0.7958) scores on test data, while the first study on this dataset has an F1 score of 0.7180.},
  archive      = {J_NCA},
  author       = {Ozturk, Mustafa and Baran, Munevver and Latifoğlu, Fatma},
  doi          = {10.1007/s00521-022-07478-w},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18953-18973},
  shortjournal = {Neural Comput. Appl.},
  title        = {Beyond the colors: Enhanced deep learning on invasive ductal carcinoma},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An abstract parabolic system-based physics-informed long
short-term memory network for estimating breath alcohol concentration
from transdermal alcohol biosensor data. <em>NCA</em>, <em>34</em>(21),
18933–18951. (<a
href="https://doi.org/10.1007/s00521-022-07505-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of estimating breath alcohol concentration based on transdermal alcohol biosensor data is considered. Transdermal alcohol concentration provides a promising alternative to classical methods such as breathalyzers or drinking diaries. A physics-informed long short-term memory (LSTM) network with covariates for the solution of the estimation problem is developed. The data-driven nature of an LSTM is augmented with a first-principles physics-based population model for the diffusion of ethanol through the epidermal layer of the skin. The population model in an abstract parabolic framework appears as part of a regularization term in the loss function of the LSTM. While learning, the model is encouraged to both fit the data and to produce physically meaningful outputs. To deal with the high variation observed in the data, a mechanism for the uncertainty quantification of the estimates based on a recently discovered relation between Monte-Carlo dropout and Bayesian learning is used. The physics-based population model and the LSTM are trained and tested using controlled laboratory collected breath and transdermal alcohol data collected in four sessions from 40 orally dosed participants (50\% female, ages 21–33 years, 35\% BMI above 25.0) resulting in 256 usable drinking episodes partitioned into training and testing sets. Body measurement (e.g., BMI, hip to waist ratio, etc.), personal (e.g., sex, age, race, etc.), drinking behavior (e.g., frequent, rarely, etc.), and environmental (e.g., temperature, humidity, etc.) covariates were also collected from participants. The importance of various covariates in the estimation is investigated using Shapley values. It is shown that the physics-informed LSTM network can be successfully applied to drinking episodes from both the training and test sets and that the physics-based information leads to better generalization ability on new drinking episodes with the uncertainty quantification yielding credible bands that effectively capture the true signal. Compared to two machine learning models from previous studies, the proposed model reduces relative $$L_2$$ error in estimated breath alcohol concentration by 58 and 72\% and relative peak error by 33 and 76\%.},
  archive      = {J_NCA},
  author       = {Oszkinat, Clemens and Luczak, Susan E. and Rosen, I. Gary},
  doi          = {10.1007/s00521-022-07505-w},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18933-18951},
  shortjournal = {Neural Comput. Appl.},
  title        = {An abstract parabolic system-based physics-informed long short-term memory network for estimating breath alcohol concentration from transdermal alcohol biosensor data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the use of machine learning to account for reservoir
management rules and predict streamflow. <em>NCA</em>, <em>34</em>(21),
18917–18931. (<a
href="https://doi.org/10.1007/s00521-022-07500-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to develop a Machine Learning (ML)-based technique to infer reservoir management rules and predict downstream discharge values. The case study is the Hackensack River Watershed in New Jersey, USA. A Long Short-Term Memory (LSTM) model was used to predict streamflow values at the USGS station at New Milford, right downstream of Oradell reservoir. A good agreement between observed and simulated streamflow values was obtained during the 2020–2021 testing period. An NSE value of 0.93 was determined with the 48-h precipitation lead time, suggesting that the 48-h precipitation forecast mostly drives releases Oradell reservoir. The developed model was tested during Hurricane Ida. The analysis revealed that a similar NSE of 0.95 was obtained with a 48-h precipitation lead time followed by the 12-h lead time model, which was based on the watershed response time. In addition, the conducted feature analysis revealed that only four out of the seven upstream USGS stations in the watershed have a significant impact on the model’s performance. This work implies that ML can capture reservoir management rules and predict reservoir releases using precipitation and upstream flow data as input variables. This study lays the groundwork for a generalization of the method over the CONUS to infer reservoirs’ operation rules for streamflow simulation.},
  archive      = {J_NCA},
  author       = {Tounsi, Achraf and Temimi, Marouane and Gourley, Jonathan J.},
  doi          = {10.1007/s00521-022-07500-1},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18917-18931},
  shortjournal = {Neural Comput. Appl.},
  title        = {On the use of machine learning to account for reservoir management rules and predict streamflow},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Multi-scale attentional similarity guidance network for
few-shot semantic segmentation. <em>NCA</em>, <em>34</em>(21),
18895–18915. (<a
href="https://doi.org/10.1007/s00521-022-07494-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot semantic segmentation tackles the problem of recognizing novel class objects from images with only a few annotated exemplars. In this work, a multi-scale attentional similarity guidance neural network is proposed to tackle the challenging few-shot semantic segmentation task. This work attempts to build a pyramidal paradigm, which analyzes multi-scale correspondence from diverse levels of semantic features. To achieve this goal, the attentional guided network is introduced to exploit similarity maps, attention vectors as well as query features to segment unseen class objects using only a few image samples. Specifically, the proposed network aims to extract the similarity maps with both foreground and background semantics, which enable more stable correspondences between query and support features. Meanwhile, the object-aware correlation module is introduced to construct attention vector, which is able to guide the network focusing on interested objects and suppress irrelevant background regions. The final segmentation mask is obtained by cross-scale guidance module reinforced by attention mechanism, which takes advantage of both similarity maps and attention vectors. In this way, the proposed network is capable of handling the diversity of object instances, which leads to robust segmentation results. Extensive qualitative and quantitative evaluations on PASCAL-5i, COCO-20i and FSS-1000 verify the effectiveness of the proposed method. The proposed method achieves favorable performance with much less trainable parameters (i.e., 4.2 M parameters with ResNet-50 backbone).},
  archive      = {J_NCA},
  author       = {Liu, Ze-yu and Liu, Jian-wei},
  doi          = {10.1007/s00521-022-07494-w},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18895-18915},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-scale attentional similarity guidance network for few-shot semantic segmentation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A layer-level multi-scale architecture for lung cancer
classification with fluorescence lifetime imaging endomicroscopy.
<em>NCA</em>, <em>34</em>(21), 18881–18894. (<a
href="https://doi.org/10.1007/s00521-022-07481-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce our unique dataset of fluorescence lifetime imaging endo/microscopy (FLIM), containing over 100,000 different FLIM images collected from 18 pairs of cancer/non-cancer human lung tissues of 18 patients by our custom fibre-based FLIM system. The aim of providing this dataset is that more researchers from relevant fields can push forward this particular area of research. Afterwards, we describe the best practice of image post-processing suitable per the dataset. In addition, we propose a novel hierarchically aggregated multi-scale architecture to improve the binary classification performance of classic CNNs. The proposed model integrates the advantages of multi-scale feature extraction at different levels, where layer-wise global information is aggregated with branch-wise local information. We integrate the proposal, namely ResNetZ, into ResNet, and appraise it on the FLIM dataset. Since ResNetZ can be configured with a shortcut connection and the aggregations by Addition or Concatenation, we first evaluate the impact of different configurations on the performance. We thoroughly examine various ResNetZ variants to demonstrate the superiority. We also compare our model with a feature-level multi-scale model to illustrate the advantages and disadvantages of multi-scale architectures at different levels.},
  archive      = {J_NCA},
  author       = {Wang, Qiang and Hopgood, James R. and Fernandes, Susan and Finlayson, Neil and Williams, Gareth O. S. and Akram, Ahsan R. and Dhaliwal, Kevin and Vallejo, Marta},
  doi          = {10.1007/s00521-022-07481-1},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18881-18894},
  shortjournal = {Neural Comput. Appl.},
  title        = {A layer-level multi-scale architecture for lung cancer classification with fluorescence lifetime imaging endomicroscopy},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal design of fuzzy-PID controller for automatic
generation control of multi-source interconnected power system.
<em>NCA</em>, <em>34</em>(21), 18859–18880. (<a
href="https://doi.org/10.1007/s00521-022-07470-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper suggests a fuzzy logic controller (FLC) structure from seven membership functions (MFs) and its input–output relationship rules to design a secondary controller to reduce load frequency control (LFC) issues. The FLC is coupled to a proportional–integral–derivative (PID) controller as the proposed FPID controller, which is tuned by an optimized water cycle algorithm (WCA). The proposed WCA: FPID scheme was implemented with two models from the literature under the integral time absolute error cost function. Initially, a two-area non-reheat unit was implemented, and the gains of PID and FPID controllers were adjusted to verify the suitability of WCA in solving LFC issues. Then, in order to identify the robustness of the closed-loop system, sensitivity analysis is carried out. Additionally, a two-area non-reheat unit was tested under the governor dead band nonlinearity. To guarantee the suitability of the proposed FPID controller, a model with a mixture of power plants, such as reheat, hydro, and gas unit in each area was carried out with and without the HVDC link, which can increase practical issues with LFC. The proposed controller&#39;s robustness was studied for all models under numerous scenarios, step load perturbations (SLP), and different objective functions. Simulation results proved that the proposed FPID controller provided superior performance compared to recently reported techniques in terms of peaks and settling time.},
  archive      = {J_NCA},
  author       = {Barakat, Mohamed},
  doi          = {10.1007/s00521-022-07470-4},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18859-18880},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimal design of fuzzy-PID controller for automatic generation control of multi-source interconnected power system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reliable plagiarism detection system based on deep learning
approaches. <em>NCA</em>, <em>34</em>(21), 18837–18858. (<a
href="https://doi.org/10.1007/s00521-022-07486-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The phenomenon of scientific burglary has seen a significant increase recently due to the technological development in software. Therefore, many types of research have been developed to address this phenomenon. However, detecting lexical, syntactic, and semantic text plagiarism remains to be a challenge. Thus, in this study, we have computed and recorded all the features that reflect different types of text similarities in a new database. The created database is proposed for intelligent learning to solve text plagiarism detection problems. Using the created database, a reliable plagiarism detection system is also proposed, which depends on intelligent deep learning. Different approaches to deep learning, such as convolution and recurrent neural network architectures, were considered during the construction of this system. A comparative study was implemented to evaluate the proposed intelligent system on the two benchmark datasets: PAN 2013 and PAN 2014 of the PAN Workshop series. The experimental results showed that the proposed system based on long short-term memory (LSTM) achieved the first rank compared to up-to-date ranking systems.},
  archive      = {J_NCA},
  author       = {El-Rashidy, Mohamed A. and Mohamed, Ramy G. and El-Fishawy, Nawal A. and Shouman, Marwa A.},
  doi          = {10.1007/s00521-022-07486-w},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18837-18858},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reliable plagiarism detection system based on deep learning approaches},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lightweight spatial attentive network for vehicular visual
odometry estimation in urban environments. <em>NCA</em>,
<em>34</em>(21), 18823–18836. (<a
href="https://doi.org/10.1007/s00521-022-07484-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual odometry is the process of estimating the motion between two consecutive images. Traditional visual odometry algorithms require the careful fabrication of state-of-the-art building blocks based on geometry. These algorithms are highly sensitive to noise, and performance degradation of a single subprocess compromises the performance of the entire system. On the other hand, learning-based methods automatically learn the features required through motion mapping. However, current learning-based methods are computationally expensive and require a significant amount of time to estimate the pose from a video sequence. This method proposes a lightweight deep neural networks architecture to estimate the odometry by exploiting the refined features through spatial attention. Three different training and test splits of the KITTI benchmark are used to effectively evaluate the proposed approach. The execution time of the proposed approach is $$\sim$$ 1 ms, speeded up by 47 times over [1]. Performed experiments demonstrate the promising performance of the proposed method to the methods used in the comparison.},
  archive      = {J_NCA},
  author       = {Gadipudi, Nivesh and Elamvazuthi, Irraivan and Lu, Cheng-Kai and Paramasivam, Sivajothi and Su, Steven},
  doi          = {10.1007/s00521-022-07484-y},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18823-18836},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lightweight spatial attentive network for vehicular visual odometry estimation in urban environments},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modified multiverse optimizer technique-based two degree of
freedom fuzzy PID controller for frequency control of microgrid systems
with hydrogen aqua electrolyzer fuel cell unit. <em>NCA</em>,
<em>34</em>(21), 18805–18821. (<a
href="https://doi.org/10.1007/s00521-022-07453-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research work proposes a modified multiverse optimizer (MMVO) technique to optimize the parameters of a 2 degree of freedom fuzzy PID (2DOF-FPID) controller for frequency control of microgrid systems. In this study, the model design consists of renewable energy sources like wind power and solar power as well as storage elements like battery energy storage systems and flywheel energy storage system with Hydrogen aqua electrolyzer integrated fuel cell unit. Initially, the performances of the MMVO technique is established over the multiverse optimizer algorithm as well as other techniques like grew wolf optimizer, gravitational search algorithm, genetic algorithm and particle swarm optimization algorithms in benchmark test functions. In the next stage, a 2 degree of freedom fuzzy PID controller (2DOF-FPID) is proposed with MMVO is applied to optimize the controller parameters. For this study, two test models are considered for minimizing the frequency fluctuations occurring due to the presence of wind and PV sources and 2DOF-FPID controllers are designed by the MMVO technique. To justify the efficacy of the planned controller, the execution of the 2DOF-FPID controller is associated with PI, PID and 2DOF-PID. A sensitivity analysis is performed by changing the system parameters to justify the robustness of the proposed controller.},
  archive      = {J_NCA},
  author       = {Mishra, Sonalika and Nayak, Pratap Chandra and Prusty, Ramesh Chandra and Panda, Sidhartha},
  doi          = {10.1007/s00521-022-07453-5},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18805-18821},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modified multiverse optimizer technique-based two degree of freedom fuzzy PID controller for frequency control of microgrid systems with hydrogen aqua electrolyzer fuel cell unit},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MultiBSP: Multi-branch and multi-scale perception object
tracking framework based on siamese CNN. <em>NCA</em>, <em>34</em>(21),
18787–18803. (<a
href="https://doi.org/10.1007/s00521-022-07420-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object tracking has achieved impressive performance in computer vision. However, there are many challenges due to complex scenarios in reality. The mainstream trackers mostly locate the object in form of two branches, which limits the ability of trackers to fully mine similarity between template and search region. In this paper, we propose a multi-branch and multi-scale perception object tracking framework based on Siamese Convolutional Neural Networks (MultiBSP), in which the multi-branch tracking framework is established based on the idea of relation mining, and a tower-structured relation network is designed for each branch to learn the non-linear relation function between template and search region. By branch combination, multiple branches can verify their predictions with each other, which is beneficial to robust tracking. Besides, in order to sense the scale and aspect ratio of object in advance, a multi-scale perception module is designed by utilizing the dilated convolutions in five scales, which contributes to the ability of tracker to deal with scale variation. In addition, we propose an information enhancement module that focuses on important features and suppresses unnecessary ones along spatial and channel dimensions. Extensive experiments on six visual tracking benchmarks including OTB100, VOT2018, VOT2019, UAV123, GOT-10k, and LaSOT demonstrate that our MultiBSP can achieve robust tracking and have state-of-the-art performance. Finally, ablation experiments verify the effectiveness of each module and the tracking stability is proved by qualitative and quantitative analyses.},
  archive      = {J_NCA},
  author       = {Jiang, Jin and Yang, Xiaoyuan and Li, Zhengze and Shen, Kangqing and Jiang, Fazhen and Ren, Huwei and Li, Yixiao},
  doi          = {10.1007/s00521-022-07420-0},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18787-18803},
  shortjournal = {Neural Comput. Appl.},
  title        = {MultiBSP: Multi-branch and multi-scale perception object tracking framework based on siamese CNN},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attention mechanism-based deep learning method for hairline
fracture detection in hand x-rays. <em>NCA</em>, <em>34</em>(21),
18773–18785. (<a
href="https://doi.org/10.1007/s00521-022-07412-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wrist and finger fractures detection is always the weak point of associate study, because there are small targets in X-rays, such as hairline fractures. In this paper, a dataset, consisting of 4346 anteroposterior, lateral and oblique hand X-rays, is built from many orthopedic cases. Specifically, it contains a lot of hairline fractures. An automatic preprocessing based on generative adversative network (GAN) and a detection network, called WrisNet, are designed to improve the detection performance of wrist and finger fractures. In the preprocessing, an attention mechanism-based GAN is proposed for obtaining the approximation of manual windowing enhancement. A multiscale attention-module-based generator of the GAN is proposed to increase continuity between pixels. The discriminator and the generator can achieve 93\% structural similarity (SSIM) as manual windowing enhancement without manual parameter adjustment. The designed WrisNet is composed of two components: a feature extraction module and a detection module. A group convolution and a lightweight but efficient triplet attention mechanism are elaborately embedded into the feature extraction module, resulting in richer representations of hairline fractures. To obtain more accurate locating information in this condition, the soft non-maximum suppression algorithm is employed as the post-processing method of the detection module. As shown in experimental results, the designed method can have obvious average precision (AP) improvement up to 7\% or more than other mainstream frameworks. The automatic preprocessing and the detection net can greatly reduce the degree of artificial intervention, so it is easy to be implemented in real clinical environment.},
  archive      = {J_NCA},
  author       = {Wang, Wenkong and Huang, Weijie and Lu, Quanli and Chen, Jiyang and Zhang, Menghua and Qiao, Jia and Zhang, Yong},
  doi          = {10.1007/s00521-022-07412-0},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18773-18785},
  shortjournal = {Neural Comput. Appl.},
  title        = {Attention mechanism-based deep learning method for hairline fracture detection in hand X-rays},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An earthquake damage identification approach from VHR image
using mathematical morphology and machine learning. <em>NCA</em>,
<em>34</em>(21), 18757–18771. (<a
href="https://doi.org/10.1007/s00521-022-07452-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An accurate earthquake-induced damage assessment from very high resolution satellite images requires a joint use of spectral and spatial information. The spatial relations between pixels in damaged areas should properly be included in the classification model in order to exploit the spatial information. Morphological Profiles (MPs) and Attribute Profiles (APs) are the state-of-the-art image processing methods that produce a set of filtered images, which are able to highlight specific patterns representing a specific land cover class. In this study, the MPs and the APs are used to create additional spatial features for two different very high resolution post-event satellite images, acquired from the City of Bam in Iran and the City of Port-au-Prince in Haiti. These contextual features are then analyzed by means of a feature selection algorithm, called Minimum Redundancy Maximum Relevance, to find the most relevant features contributing the damage class the most. A final feature subset of selected features is analyzed using two different classifiers, which are k-nearest neighbors and support-vector machines. The results show that the use of a proper configuration of those profiles can significantly improve the classification accuracy and the quality of the thematic map, but generalization of the classification model is limited especially for the larger areas.},
  archive      = {J_NCA},
  author       = {Alataş, Enes Oğuzhan and Taşkın, Gülşen},
  doi          = {10.1007/s00521-022-07452-6},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18757-18771},
  shortjournal = {Neural Comput. Appl.},
  title        = {An earthquake damage identification approach from VHR image using mathematical morphology and machine learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature-enhanced embedding learning for heterogeneous
collaborative filtering. <em>NCA</em>, <em>34</em>(21), 18741–18756. (<a
href="https://doi.org/10.1007/s00521-022-07490-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous information network (HIN) has recently been receiving increasing attention in recommender systems due to its practicability in depicting data heterogeneity. The rich structural and semantic information embodied in the HIN can help mining latent features of users and items for recommendations. However, almost all existing HIN-based recommendation methods focus on the design of complicated learning architecture while using simply initialized features. In this paper, we propose a novel feature-enhanced embedding learning model which combines informative feature initialization strategy with simple learning architecture for heterogeneous collaborative filtering. We first build multiple homogeneous sub-networks by extracting different relations guided by meta-paths from the HIN. We then design a comprehensive feature initialization strategy that contains semantic and spatial encoding module to characterize the node feature. After that, a simple learning architecture based on multi-layer perceptron is applied to learn the latent representation of users and items. Next, a novel convolutional neural network-based fusion mechanism is used to determine the attention weight of semantic relations and compress multiple embedding vectors into a compact representation to apply for final recommendation. Finally, we conduct extensive experiments on two classic datasets to demonstrate the effectiveness and feasibility of the proposed FHetCF method in solving HIN-based recommendation tasks. Results show that the proposed method soundly outperforms the competitive baselines by 1.71 to 10.46\% on hit ratio and 3.17 to 13.75\% on normalized discounted cumulative gain, respectively. The proposed method opens up a new avenue to effectively utilize heterogeneous information to improve recommendation performance.},
  archive      = {J_NCA},
  author       = {Yang, Wenchuan and Li, Jichao and Tan, Suoyi and Tan, Yuejin and Lu, Xin},
  doi          = {10.1007/s00521-022-07490-0},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18741-18756},
  shortjournal = {Neural Comput. Appl.},
  title        = {Feature-enhanced embedding learning for heterogeneous collaborative filtering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Event-triggered trajectory-tracking guidance for reusable
launch vehicle based on neural adaptive dynamic programming.
<em>NCA</em>, <em>34</em>(21), 18725–18740. (<a
href="https://doi.org/10.1007/s00521-022-07468-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the trajectory-tracking guidance performance for reusable launch vehicle under various uncertainties and distortions, an event-triggered (ET) guidance method based on neural adaptive dynamic programming (ADP) is proposed. Firstly, the reference trajectory and corresponding steady-state control are generated optimally offline based on Gauss pseudo-spectral method. Secondly, the approximate optimal feedback controller based on single-critic ADP is designed. The great adaptation capacity inheriting from reinforcement learning technique ensures the tracking errors to converge to zero, and yet no offline dataset or pre-training is required. Event-triggered mechanism is introduced to reduce online training computation and save data transmission resource. Event-triggered condition is designed and the asymptotic stability of the event-triggered guidance system is proved. Comprehensive simulations are conducted and results validate the effectiveness of the feedback controller based on ADP and the significantly improved efficiency of ET mechanism. Besides, the improved performance of the proposed guidance method over traditional method of linear quadratic regulator has also been verified through simulations.},
  archive      = {J_NCA},
  author       = {Wang, Xueyun and Quan, Zhiyuan and Li, Yifan and Liu, Yunpeng},
  doi          = {10.1007/s00521-022-07468-y},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18725-18740},
  shortjournal = {Neural Comput. Appl.},
  title        = {Event-triggered trajectory-tracking guidance for reusable launch vehicle based on neural adaptive dynamic programming},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design of induction motor speed observer based on long
short-term memory. <em>NCA</em>, <em>34</em>(21), 18703–18723. (<a
href="https://doi.org/10.1007/s00521-022-07458-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a machine learning regression algorithm based on speed estimation for sensorless control of an induction motor. Long short-term memory (LSTM) based on deep learning method is used to design the induction motor speed observer. The proposed LSTM observer utilizes only the measured stator currents and voltages. It estimates the motor speed in the presence of inherent dynamics and sensor noises. Although LSTM is one of the common deep learning methods, its implementation on speed estimation for induction motor has not been tackled in the literature. The estimation performance of proposed LSTM observer (LSTMO) is investigated using four common metrics: root relative squared error, mean absolute error, mean squared error and root mean squared error. Performance of the proposed method is well guaranteed for different operating speeds. The designed observer is compared with the traditional sliding mode observer in order to prove the validity. It can be deduced from experimental results that the proposed method estimates the actual speed value successfully. LSTMO tracks the speed accurately regardless of any changes in reference speed. It is shown that there is no chattering effect on the estimated speed as compared with SMO.},
  archive      = {J_NCA},
  author       = {Ilten, Erdem and Calgan, Haris and Demirtas, Metin},
  doi          = {10.1007/s00521-022-07458-0},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18703-18723},
  shortjournal = {Neural Comput. Appl.},
  title        = {Design of induction motor speed observer based on long short-term memory},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ENCVIDC: An innovative approach for encoded video content
classification. <em>NCA</em>, <em>34</em>(21), 18685–18702. (<a
href="https://doi.org/10.1007/s00521-022-07480-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase in the sum of online video viewers on the internet every day, the video service providers are getting interested to know about the nature of the content being viewed through the supplied network in order to accomplish their business associated objectives that may include the user’s internet behavior profile, etc. Due to the widespread use of encoded video streaming techniques, the network video traffic classification has turned out to be a challenging task. As devoid of the authentic decryption key, it is impossible to comprehend the actual content viewed by the user. However, the current advances in machine learning have demonstrated the fact that encryption can also lead to certain information leak which yields promising results in determining the actual transmitted content between the two communicating parties. This research proposes a classifier for determining the encrypted video content over different streaming sites such as YouTube, Netflix and Dailymotion. We demonstrated that an eavesdropper can determine the stream video content even if the traffic is encrypted by identifiable patterns extracted from the captured traffic. We used different machine algorithms for the task and conducted a series of tests, demonstrating that our classification based on Random Forest showed accuracy greater than 98\% and has the ability to execute all the network-related business objectives of any enterprise network.},
  archive      = {J_NCA},
  author       = {Amjad, Faiqa and Khan, Fawad and Tahir, Shahzaib and Yaqoob, Tahreem and Abbas, Haider},
  doi          = {10.1007/s00521-022-07480-2},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18685-18702},
  shortjournal = {Neural Comput. Appl.},
  title        = {ENCVIDC: An innovative approach for encoded video content classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning enabled optimized feature selection and
classification for grading diabetic retinopathy severity in the fundus
image. <em>NCA</em>, <em>34</em>(21), 18663–18683. (<a
href="https://doi.org/10.1007/s00521-022-07471-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic Retinopathy (DR), one of the most progressive sight-threatening diseases caused by the long-term diabetic condition, can lead to vision impairment and blindness later. Early diagnosis and timely treatment help control and avert DR from its progression. However, manual grading is exceptionally challenging and arduous due to the complex anatomical features in the retina. Therefore, developing an automated diagnostic method for screening DR is obligatory. This paper proposes a deep learning-enabled optimized feature selection approach to classify the stage of DR severity in the fundus image. At first, a pre-processing phase eradicates the noise and improves the contrast in the retinal fundus image. Then, blood vessel segmentation is performed using the Coherence Enhancing Energy Based Regularized Level Set Evolution method in the green channel fundus image. Subsequently, the optic disk is segmented with Canny Anisotropic Diffusion filter and morphological transformations. Next, the candidate lesion region is detected using an Attention-based Fusion Network (AFU-Net). Then, shape and texture features are extracted, and then, the optimal subset of features is selected using the Improved Harris Hawk Optimization algorithm. Finally, a deep Convolutional Neural Network classifies the DR stages, and the model weight is updated using the same algorithm. The proposed method achieved superior performance in two benchmark public datasets compared with the existing state-of-the-art methods using F1-score, accuracy, sensitivity, and specificity measures.},
  archive      = {J_NCA},
  author       = {Dayana, A. Mary and Emmanuel, W. R. Sam},
  doi          = {10.1007/s00521-022-07471-3},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18663-18683},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning enabled optimized feature selection and classification for grading diabetic retinopathy severity in the fundus image},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Support matrix machine with pinball loss for classification.
<em>NCA</em>, <em>34</em>(21), 18643–18661. (<a
href="https://doi.org/10.1007/s00521-022-07460-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machine (SVM) is one of the highly efficient classification algorithms. Unfortunately, it is designed only for input samples expressed as vectors. In real life, most input samples are naturally in matrix form and include structural information, such as electroencephalogram (EEG) signals and gray images. Support matrix machine (SMM), which can capture the latent structure within input matrices by regularizing the regression matrix to be low rank, is more suitable for matrix-form data than the SVM. However, the SMM adopts hinge loss, which is easily sensitive to noise and unstable to re-sampling. In this paper, to tackle this issue, we propose a new SMM with pinball loss (Pin−SMM), which can simultaneously consider the intrinsic structural information of input matrices and noise insensitivity. Our Pin−SMM is defined as a spectral elastic net with pinball loss, penalizing the rightly classified points. The optimization problem of Pin−SMM is also convex, which motivates us to construct the fast alternating direction method of multipliers (Fast ADMM) to solve it. Comprehensive experiments on two popular image datasets and an EEG dataset with different noises are conducted, and the experimental results confirm the effectiveness of our presented algorithm.},
  archive      = {J_NCA},
  author       = {Feng, Renxiu and Xu, Yitian},
  doi          = {10.1007/s00521-022-07460-6},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18643-18661},
  shortjournal = {Neural Comput. Appl.},
  title        = {Support matrix machine with pinball loss for classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vision-based size classification of iron ore pellets using
ensembled convolutional neural network. <em>NCA</em>, <em>34</em>(21),
18629–18641. (<a
href="https://doi.org/10.1007/s00521-022-07473-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an iron ore pelletization plant, pellets are produced inside a rotating disc pelletizer. Online pellet size distribution is an important performance indicator of the pelletization process. Image processing-based system is an effective solution for online size analysis of iron ore pellets. This paper proposes a machine learning algorithm for estimating the size class of the pellets during their production by imaging from an area inside the disc pelletizer. Instead of computing the size of each individual pellets in the acquired image, this method proposes a qualitative approach to get the overall size estimate of the pellets in production. The key idea of this paper is to find out whether the disc is producing VERY SMALL, SMALL, MEDIUM, or BIG-sized pellets. A weighted average ensemble of different convolutional neural networks such as VGG16, Mobilenet, and Resnet50 is used to achieve this objective. Furthermore, batch normalization is applied to improve the estimation performance of the proposed model. A novel data augmentation method is applied to the in situ captured images to create the data set used to train and evaluate the proposed ensemble of CNN models. Results of experiments indicate that it is possible to detect the operating state of the pelletization disc by acquiring images from the inside area of the disc with sufficient accuracy.},
  archive      = {J_NCA},
  author       = {Deo, Arya Jyoti and Sahoo, Animesh and Behera, Santosh Kumar and Das, Debi Prasad},
  doi          = {10.1007/s00521-022-07473-1},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18629-18641},
  shortjournal = {Neural Comput. Appl.},
  title        = {Vision-based size classification of iron ore pellets using ensembled convolutional neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Selection of object detections using overlap map
predictions. <em>NCA</em>, <em>34</em>(21), 18611–18627. (<a
href="https://doi.org/10.1007/s00521-022-07469-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in deep neural networks have led to significant improvement of object detection accuracy. However, object detection in crowded scenarios is a challenging task for neural networks since extremely overlapped objects provide fewer visible cues for a model to learn from. Further complicating the detection of overlapping objects is the fact that most object detectors produce multiple redundant detections for single objects, which are indistinguishable from detections of separate overlapped objects. Most existing works use some variant of non-maximum suppression to prune duplicate candidate bounding boxes based on their confidence scores and the amount of overlap between predicted bounding boxes. These methods are unaware of how much overlap there actually is between the objects in the image, and are therefore inclined to merge detections for highly overlapped objects. In this paper, we propose an overlap aware box selection solution that uses a predicted overlap map to help it decide which highly overlapping bounding boxes are associated with actual overlapping objects and should not be pruned. We show our solution outperforms the state-of-the-art set-NMS bounding box selection algorithm for both the crowdHuman dataset and a sports dataset.},
  archive      = {J_NCA},
  author       = {Rana, Md Sohel and Nibali, Aiden and He, Zhen},
  doi          = {10.1007/s00521-022-07469-x},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18611-18627},
  shortjournal = {Neural Comput. Appl.},
  title        = {Selection of object detections using overlap map predictions},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective evolutionary algorithm on reliability
redundancy allocation with interval alternatives for system parameters.
<em>NCA</em>, <em>34</em>(21), 18595–18609. (<a
href="https://doi.org/10.1007/s00521-022-07459-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a multi-objective reliability redundancy allocation model with constraints representing the system complexity. A reliability model to enhance the system reliability and to diminish the system cost through a feasible redundancy in its stages is proposed. We develop an evolutionary algorithm using precedence and dominance property to obtain Pareto-optimal solutions guided by a Euclidean norm. An illustration of the model is presented for a series-parallel configuration of an oil transportation subsystem. The results are analyzed for various interval alternatives with randomization in the interval parameter.},
  archive      = {J_NCA},
  author       = {Maneckshaw, B. and Mahapatra, G. S.},
  doi          = {10.1007/s00521-022-07459-z},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18595-18609},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective evolutionary algorithm on reliability redundancy allocation with interval alternatives for system parameters},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cost-aware real-time job scheduling for hybrid cloud using
deep reinforcement learning. <em>NCA</em>, <em>34</em>(21), 18579–18593.
(<a href="https://doi.org/10.1007/s00521-022-07477-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid cloud computing enables enterprises to get the best of both private and public cloud models. One of its primary benefits is to reduce operational costs, and the prerequisite is that jobs should be executed in an effective way in the hybrid environment. Although many job scheduling methods have been proposed for cloud in the past decade, most of them focus on handling batch jobs rather than real-time ones. Moreover, few of them have ever considered real-time jobs in hybrid cloud. Inspired by the recent success of using deep reinforcement learning (DRL) for solving complex optimization problems, in this paper, we propose a DRL-based approach for scheduling real-time jobs in hybrid cloud, with a focus on optimizing monetary cost for job executions while ensuring that high quality of service and low responsible time can be also achieved. Specifically, our method can learn to make appropriate decisions in selecting suitable virtual machines for incoming jobs in real-time over hybrid cloud, with the scheduling agent getting trained through rewards in its learning experiences. We give the detailed design of our approach, and our experimental results demonstrate that our method is more cost-efficient, compared to the current approaches.},
  archive      = {J_NCA},
  author       = {Cheng, Long and Kalapgar, Archana and Jain, Amogh and Wang, Yue and Qin, Yongtai and Li, Yuancheng and Liu, Cong},
  doi          = {10.1007/s00521-022-07477-x},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18579-18593},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cost-aware real-time job scheduling for hybrid cloud using deep reinforcement learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Boundary intermittent stabilization for delay
reaction–diffusion cellular neural networks. <em>NCA</em>,
<em>34</em>(21), 18561–18577. (<a
href="https://doi.org/10.1007/s00521-022-07457-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exponential stability is considered for delay reaction–diffusion cellular neural networks (DRDCNNs) under two cases where the state information is fully available and not fully available. When the state information of controlled system is fully available, an aperiodically intermittent boundary controller is designed to stabilize the controlled system. When the state information is not fully available, we propose an observer based on the boundary output to estimate the system state, and an observer-based aperiodically intermittent boundary controller is designed. Employing the Lyapunov functional method and Poincaré’s inequality, we obtain a criterion to ensure DRDCNNs achieve the exponential stabilization. Based on our obtained results, the influence of diffusion coefficient matrix, control gains, time-delays and control proportion on the stability are studied. To illustrate the effectiveness of our theoretical results, at last, numerical examples are given.},
  archive      = {J_NCA},
  author       = {Li, Xing-Yu and Fan, Qing-Ling and Liu, Xiao-Zhen and Wu, Kai-Ning},
  doi          = {10.1007/s00521-022-07457-1},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18561-18577},
  shortjournal = {Neural Comput. Appl.},
  title        = {Boundary intermittent stabilization for delay reaction–diffusion cellular neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis of moving cluster with scene constraints for group
behavior pattern mining. <em>NCA</em>, <em>34</em>(21), 18545–18560. (<a
href="https://doi.org/10.1007/s00521-022-07433-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group behavior pattern mining in traffic scenarios is a challenging problem due to group variability and behavioral regionality. Most methods are either based on trajectory data stored in static databases regardless of the variability of group members or do not consider the influence of scene structures on behaviors. However, in traffic scenarios, information about group members may change over time, and objects&#39; motions show regional characteristics owing to scene structures. To address these issues, we present a general framework of a moving cluster with scene constraints (MCSC) discovery consisting of semantic region segmentation, mapping, and an MCSC decision. In the first phase, a hidden Markov chain is adopted to model the evolution of behaviors along a video clip sequence, and a Markov topic model is proposed for semantic region analysis. During the mapping procedure, to generate snapshot clusters, moving objects are mapped into the corresponding sets of moving objects according to the semantic regions where they are located at each timestamp. In the MCSC decision phase, a candidate MCSC recognition algorithm and screening algorithm are designed to incrementally identify and output MCSCs. The effectiveness of the proposed approach is verified by experiments carried out using public road traffic data.},
  archive      = {J_NCA},
  author       = {Yang, Yuanfeng and Li, Lin and Zhang, Liang and Liu, Gang and Liu, Zhaobin},
  doi          = {10.1007/s00521-022-07433-9},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18545-18560},
  shortjournal = {Neural Comput. Appl.},
  title        = {Analysis of moving cluster with scene constraints for group behavior pattern mining},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Correction to: Predicting customer churn for platform
businesses: Using latent variables of variational autoencoder as
consumers’ purchasing behavior. <em>NCA</em>, <em>34</em>(21),
18543–18544. (<a
href="https://doi.org/10.1007/s00521-022-07610-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Hasumoto, Kyosuke and Goto, Masayuki},
  doi          = {10.1007/s00521-022-07610-w},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18543-18544},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: predicting customer churn for platform businesses: using latent variables of variational autoencoder as consumers’ purchasing behavior},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Predicting customer churn for platform businesses: Using
latent variables of variational autoencoder as consumers’ purchasing
behavior. <em>NCA</em>, <em>34</em>(21), 18525–18541. (<a
href="https://doi.org/10.1007/s00521-022-07418-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customer churn is considered a critical issue for all businesses, as customer loss leads to a decrease in future profits. Although acquiring new customers can address such losses, this process tends to cost more than retaining existing customers. Therefore, identifying potential churners and then retaining them is important. While churn prediction has been studied widely, current research must analyze more complex business models in response to their increase, such as platform businesses. However, modeling churn prediction for these businesses is challenging because consumer behavior over platforms is more complicated. Past approaches to churn prediction can be improved upon using recent advancements in deep learning that capture the nonlinear relationships behind the data in a data-driven manner, especially for complex business models. This study proposes a method of extracting latent features from purchase histories as explanatory variables for churn prediction using a variational autoencoder with the actual customer distribution as a prior. The proposed method is validated using real purchase data from a platform business and shows a 1.5\% improvement in F-measure against the baseline, and a 20\% improvement for customers with recent transactions. Subsequently, the variables are examined using several methods for data analysis to interpret the meanings of the extracted features and underlying customers’ purchasing behavior in the group of potential churners. With these analyses, the model provides practical implications for understanding what kind of purchasing behavior may lead to churn and planning effective retention strategies.},
  archive      = {J_NCA},
  author       = {Hasumoto, Kyosuke and Goto, Masayuki},
  doi          = {10.1007/s00521-022-07418-8},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18525-18541},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting customer churn for platform businesses: Using latent variables of variational autoencoder as consumers’ purchasing behavior},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LS-net: A convolutional neural network for leaf segmentation
of rosette plants. <em>NCA</em>, <em>34</em>(21), 18511–18524. (<a
href="https://doi.org/10.1007/s00521-022-07479-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leaf segmentation from plant images is a challenging task, especially when multiple leaves are overlapping in images with a complex background. Recently, deep learning-based methods have demonstrated their effectiveness in the realm of image segmentation. In this study, a novel convolutional neural network called LS-Net has been proposed for the leaf segmentation of rosette plants. The experiment is performed over 2010 images from the plant phenotyping (CVPPP) and KOMATSUNA datasets. The segmentation ability of the LS-Net has been investigated by comparing it with four recently applied existing CNN-based segmentation models, namely DeepLab V3 + , Seg Net, Fast-FCN with Pyramid Pooling Module, and U-Net. The analysis of the experimental results clearly demonstrates the superiority of the proposed LS-Net to other tested CNN models.},
  archive      = {J_NCA},
  author       = {Deb, Mainak and Garai, Arpan and Das, Arunita and Dhal, Krishna Gopal},
  doi          = {10.1007/s00521-022-07479-9},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18511-18524},
  shortjournal = {Neural Comput. Appl.},
  title        = {LS-net: A convolutional neural network for leaf segmentation of rosette plants},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient and portable solar cell defect detection
system. <em>NCA</em>, <em>34</em>(21), 18497–18509. (<a
href="https://doi.org/10.1007/s00521-022-07464-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The photovoltaic (PV) system industry is continuously developing around the world due to the high energy demand, even though the primary current energy source is fossil fuels, which are a limited source and other sources are very expensive. Solar cell defects are a major reason for PV system efficiency degradation, which causes disturbance or interruption of the generated electric current. In this study, a novel system for discovering solar cell defects is proposed, which is compatible with portable and low computational power devices. It is based on K-means, MobileNetV2 and linear discriminant algorithms to cluster solar cell images and develop a detection model for each constructed cluster. It can extract the distinct features between defective and nondefective solar cell clusters and overcome the confusion between different cell shapes. The proposed system was assessed using a benchmark dataset of electroluminescence images. The results demonstrate that it achieved the highest accuracy at a substantial rate compared to recent studies.},
  archive      = {J_NCA},
  author       = {El-Rashidy, Mohamed A.},
  doi          = {10.1007/s00521-022-07464-2},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18497-18509},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient and portable solar cell defect detection system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adam or eve? Automatic users’ gender classification via
gestures analysis on touch devices. <em>NCA</em>, <em>34</em>(21),
18473–18495. (<a
href="https://doi.org/10.1007/s00521-022-07454-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gender classification of mobile devices’ users has drawn a great deal of attention for its applications in healthcare, smart spaces, biometric-based access control systems and customization of user interface (UI). Previous works have shown that authentication systems can be more effective when considering soft biometric traits such as the gender, while others highlighted the significance of this trait for enhancing UIs. This paper presents a novel machine learning-based approach to gender classification leveraging the only touch gestures information derived from smartphones’ APIs. To identify the most useful gesture and combination thereof for gender classification, we have considered two strategies: single-view learning, analyzing, one at a time, datasets relating to a single type of gesture, and multi-view learning, analyzing together datasets describing different types of gestures. This is one of the first works to apply such a strategy for gender recognition via gestures analysis on mobile devices. The methods have been evaluated on a large dataset of gestures collected through a mobile application, which includes not only scrolls, swipes, and taps but also pinch-to-zooms and drag-and-drops which are mostly overlooked in the literature. Conversely to the previous literature, we have also provided experiments of the solution in different scenarios, thus proposing a more comprehensive evaluation. The experimental results show that scroll down is the most useful gesture and random forest is the most convenient classifier for gender classification. Based on the (combination of) gestures taken into account, we have obtained F1-score up to 0.89 in validation and 0.85 in testing phase. Furthermore, the multi-view approach is recommended when dealing with unknown devices and combinations of gestures can be effectively adopted, building on the requirements of the system our solution is built-into. Solutions proposed turn out to be both an opportunity for gender-aware technologies and a potential risk deriving from unwanted gender classification.},
  archive      = {J_NCA},
  author       = {Guarino, Alfonso and Lettieri, Nicola and Malandrino, Delfina and Zaccagnino, Rocco and Capo, Carmine},
  doi          = {10.1007/s00521-022-07454-4},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18473-18495},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adam or eve? automatic users’ gender classification via gestures analysis on touch devices},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A decomposition-ensemble broad learning system for AQI
forecasting. <em>NCA</em>, <em>34</em>(21), 18461–18472. (<a
href="https://doi.org/10.1007/s00521-022-07448-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The combination of decomposition algorithms and prediction models is a common structure for air quality time series forecasting. In this study, we develop a dynamic decomposition framework by adding the time window based on empirical mode decomposition, ensemble empirical mode decomposition and complementary ensemble empirical mode decomposition with adaptive noise. Moreover, we proposed a decomposition-ensemble broad learning system for air quality index forecasting based on broad learning system (BLS) which is a simple and efficient neural network. In this model, we combine the developed decomposition algorithms with BLS to bring out their merits. The air pollution datasets from Huainan city and Fuyang city are utilized to establish the empirical experiment. The experimental results reveal that our proposed ensemble model outperforms other baselines, including prediction models and models with decomposition algorithms.},
  archive      = {J_NCA},
  author       = {Zhan, Choujun and Jiang, Wei and Lin, Fabing and Zhang, Shuntao and Li, Bing},
  doi          = {10.1007/s00521-022-07448-2},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18461-18472},
  shortjournal = {Neural Comput. Appl.},
  title        = {A decomposition-ensemble broad learning system for AQI forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SWTNet: Hyperspectral image classification using two-stage
combined shallow and deep feature extraction. <em>NCA</em>,
<em>34</em>(21), 18439–18459. (<a
href="https://doi.org/10.1007/s00521-022-07440-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of remote sensing Hyperspectral Image (HSI) using spectral-spatial feature extraction methods has attracted researchers worldwide, giving prodigious achievement. We propose a PSL framework where P, S, and L denote Principal Component Analysis (PCA), SWTNet, and Linear Support Vector Classification (SVC), respectively. SWTNet model includes a 2D Stationary Wavelet Transform (SWT) for extracting shallow spectral-spatial texture features followed by multiple input multiscale 3D Convolutional Neural Networks (CNNs) model for deep feature extraction. The SWTNet is a two-stage combined shallow and deep feature extraction model that extracts spectral-spatial discriminative features with a strong correlation. The multiple-input of the CNN model helps to perform cross-correlation with the input data. The multiscale property eases the problem of loss of details during the convolution process. We classify the extracted features using the Linear SVC classifier. Our experimental results showcase the potential of our proposed PSL framework, which outmatch accuracy results compared to the other state-of-the-art models when examined using limited training samples.},
  archive      = {J_NCA},
  author       = {Ladi, Pradeep Kumar and Kakita, Murali Gopal and Dash, Ratnakar and Ladi, Sandeep Kumar},
  doi          = {10.1007/s00521-022-07440-w},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18439-18459},
  shortjournal = {Neural Comput. Appl.},
  title        = {SWTNet: Hyperspectral image classification using two-stage combined shallow and deep feature extraction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Three stage fusion for effective time series forecasting
using bi-LSTM-ARIMA and improved DE-ABC algorithm. <em>NCA</em>,
<em>34</em>(21), 18421–18437. (<a
href="https://doi.org/10.1007/s00521-022-07431-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fusion is a state-of-the-art technique to observe the behavioral pattern from time series data. Fusion models efficiently and effectively interpret both linear and nonlinear patterns that are the constraints of an individual model due to feature limitations. In this paper, a three-stage fusion model is proposed to handle time series data and improve stock market forecasting accuracy. In the first phase of fusion, stock market inputs that are constituted with historical data and market sentiments of the targeted stock are pooled along with established technical indicators of the stock market. Market sentiments are examined through sentiment polarity index using big data platform Hadoop. In the second phase, Auto Regressive Integrated Moving Average (ARIMA) and Long Short-Term Memory (LSTM) are combined to observe linear and nonlinear features of the final stock dataset. In the third phase, an improved Artificial Bee Colony (ABC) algorithm using differential evolution (DE) is examined for the hyperparameter selection of the proposed DE-ABC-Bi-LSTM-ARIMA model for the stock market prediction. In this paper, experiments are performed on established and diversified reported historical datasets Dow Jones Industrial Average index, Nikkei 225 (N225) index, S&amp;P 500 index and NASDAQ GS index. The proposed fusion model DE-ABC-Bi-LSTM-ARIMA outperformed the benchmark models used in this paper.},
  archive      = {J_NCA},
  author       = {Kumar, Raghavendra and Kumar, Pardeep and Kumar, Yugal},
  doi          = {10.1007/s00521-022-07431-x},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18421-18437},
  shortjournal = {Neural Comput. Appl.},
  title        = {Three stage fusion for effective time series forecasting using bi-LSTM-ARIMA and improved DE-ABC algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Subspace embedding for classification. <em>NCA</em>,
<em>34</em>(21), 18407–18420. (<a
href="https://doi.org/10.1007/s00521-022-07409-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace embedding is a popular technique to discover a mapping space in which the samples are expected to be represented appropriately. In recent years, graph has received increasing attention in subspace embedding and most of these related graph-based algorithms directly construct the connecting graph in original space. But some redundant information probably exists in the data with high dimension, and thus, it is hard to ensure the quality of graph. In this paper, we propose a novel discriminative subspace embedding (DSE) algorithm for classification. DSE is a supervised subspace learning method. In DSE, an intra-class graph and an inter-class graph are used to characterize the relationship among samples from the same class and different classes, respectively. DSE assumes that the embeddings of samples from the same class should be similar while different embeddings should be learned for the samples belonging to different classes. Based on this assumption, the above two graphs are constructed in mapping space. In order to enhance the quality of projections, the reconstruction of original data is also taken into consideration in DSE. Finally, some datasets are adopted to test the performance of DSE. Experimental results illustrate that effective representations can be learned by DSE and it has a more competitive learning ability, in comparison with related algorithms.},
  archive      = {J_NCA},
  author       = {Liu, Zheng and Jin, Wei and Mu, Ying},
  doi          = {10.1007/s00521-022-07409-9},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18407-18420},
  shortjournal = {Neural Comput. Appl.},
  title        = {Subspace embedding for classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A soft voting ensemble learning-based approach for
multimodal sentiment analysis. <em>NCA</em>, <em>34</em>(21),
18391–18406. (<a
href="https://doi.org/10.1007/s00521-022-07451-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is possible to determine people&#39;s feelings and opinions about a subject or product from social media posts via sentiment analysis. With the pervasive usage of the Internet and smart devices, the data produced daily by users can be in different modalities such as text, image, audio, and video. Multimodal sentiment analysis is to reveal the feeling of the user&#39;s posts by analyzing the data in different modalities as a whole. One of the major challenges of multimodal sentiment is how the sentiment obtained on different modalities is combined to ensure sentiment and meaning integrity of the post. Also, many studies use the same classifying methods to analyze different modalities. In fact, each classifier can be effective in different feature sets. In this study, a soft voting-based ensemble model is proposed that takes advantage of the effective performance of different classifiers on different modalities. In the proposed model, deep feature extraction was made with deep learning methods (BiLSTM, CNN) from the multimodal datasets. After the feature selection was conducted on the features which are a fusion of text and image features, the final feature sets were classified with the soft voting-based ensemble learning model. The performance of the proposed model has been tested on two different benchmark datasets consisting of text–image pairs. As a result of the experimental studies, it was revealed that the proposed model outperformed multiple adversary models on the same datasets.},
  archive      = {J_NCA},
  author       = {Salur, Mehmet Umut and Aydın, İlhan},
  doi          = {10.1007/s00521-022-07451-7},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18391-18406},
  shortjournal = {Neural Comput. Appl.},
  title        = {A soft voting ensemble learning-based approach for multimodal sentiment analysis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic personality prediction: An enhanced method using
ensemble modeling. <em>NCA</em>, <em>34</em>(21), 18369–18389. (<a
href="https://doi.org/10.1007/s00521-022-07444-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human personality is significantly represented by those words which he/she uses in his/her speech or writing. As a consequence of spreading the information infrastructures (specifically the Internet and social media), human communications have reformed notably from face to face communication. Generally, Automatic Personality Prediction (or Perception) (APP) is the automated forecasting of the personality on different types of human generated/exchanged contents (like text, speech, image, video, etc.). The major objective of this study is to enhance the accuracy of APP from the text. To this end, we suggest five new APP methods including term frequency vector-based, ontology-based, enriched ontology-based, latent semantic analysis (LSA)-based, and deep learning-based (BiLSTM) methods. These methods as the base ones, contribute to each other to enhance the APP accuracy through ensemble modeling (stacking) based on a hierarchical attention network (HAN) as the meta-model. The results show that ensemble modeling enhances the accuracy of APP.},
  archive      = {J_NCA},
  author       = {Ramezani, Majid and Feizi-Derakhshi, Mohammad-Reza and Balafar, Mohammad-Ali and Asgari-Chenaghlu, Meysam and Feizi-Derakhshi, Ali-Reza and Nikzad-Khasmakhi, Narjes and Ranjbar-Khadivi, Mehrdad and Jahanbakhsh-Nagadeh, Zoleikha and Zafarani-Moattar, Elnaz and Akan, Taymaz},
  doi          = {10.1007/s00521-022-07444-6},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18369-18389},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic personality prediction: An enhanced method using ensemble modeling},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An island parallel harris hawks optimization algorithm.
<em>NCA</em>, <em>34</em>(21), 18341–18368. (<a
href="https://doi.org/10.1007/s00521-022-07367-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Harris hawk optimization (HHO) is an impressive optimization algorithm that makes use of unique mathematical approaches. This study proposes an island parallel HHO (IP-HHO) version of the algorithm for optimizing continuous multi-dimensional problems for the first time in the literature. To evaluate the performance of the IP-HHO, thirteen unimodal and multimodal benchmark problems with different dimensions (30, 100, 500, and 1000) are evaluated. The implementation of this novel algorithm took into account the investigation, exploitation, and avoidance of local optima issues effectively. Parallel computation provides a multi-swarm environment for thousands of hawks simultaneously. On all issue cases, we were able to enhance the performance of the sequential version of the HHO algorithm. As the number of processors increases, the suggested IP-HHO method enhances its performance while retaining scalability and improving its computation speed. The IP-HHO method outperforms the other state-of-the-art metaheuristic algorithms on average as the size of the dimensions grows.},
  archive      = {J_NCA},
  author       = {Dokeroglu, Tansel and Sevinc, Ender},
  doi          = {10.1007/s00521-022-07367-2},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18341-18368},
  shortjournal = {Neural Comput. Appl.},
  title        = {An island parallel harris hawks optimization algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of the current publication trends on missing data
imputation over three decades: Direction and future research.
<em>NCA</em>, <em>34</em>(21), 18325–18340. (<a
href="https://doi.org/10.1007/s00521-022-07702-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies on missing data have increased in the past few decades. It is an uncontrollable phenomenon and could occur during the data collection in practically any research field. Numerous missing data imputation techniques are well documented in the literature. However, very few studies have systematically examined the evolutionary nuances of a specific area while offering insight into the emerging imputation methods in that field. The primary objective of this paper is to provide a comprehensive review of studies concerning missing data imputation methods in classification problems from several viewpoints: (a) publication trends (by year, subject area, country, document language, and author), (b) keyword analysis, (c) the most cited documents and (d) the most influenced authors. Bibliometric analysis has been conducted using VOSviewer and Harzing Publish or Perish software, covering 430 journal articles published in Scopus from 1991 to June 2021. One of the findings reveals an emerging trend in missing data imputation methods using random forest and nearest neighbor. Above all, this research is a valuable resource for gaining insights into the available imputation techniques at a glance.},
  archive      = {J_NCA},
  author       = {Adnan, Farah Adibah and Jamaludin, Khairur Rijal and Wan Muhamad, Wan Zuki Azman and Miskon, Suraya},
  doi          = {10.1007/s00521-022-07702-7},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18325-18340},
  shortjournal = {Neural Comput. Appl.},
  title        = {A review of the current publication trends on missing data imputation over three decades: Direction and future research},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of machine learning-based human activity
recognition for diverse applications. <em>NCA</em>, <em>34</em>(21),
18289–18324. (<a
href="https://doi.org/10.1007/s00521-022-07665-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) is a very active yet challenging and demanding area of computer science. Due to the articulated nature of human motion, it is not trivial to detect human activity with high accuracy for all applications. Generally, activities are recognized from a series of actions performed by the human through vision-based sensors or non-vision-based sensors. HAR’s application areas span from health, sports, smart home-based, and other diverse areas. Moreover, detecting human activity is also needed to automate systems to monitor ambient and detect suspicious activity while performing surveillance. Besides, providing appropriate information about individuals is a necessary task in pervasive computing. However, identifying human activities and actions is challenging due to the complexity of activities, speed of action, dynamic recording, and diverse application areas. Besides that, all the actions and activities are performed in distinct situations and backgrounds. There is a lot of work done in HAR; finding a suitable algorithm and sensors for a certain application area is still challenging. While some surveys are already conducted in HAR, the comprehensive survey to investigate algorithms and sensors concerning diverse applications is not done yet. This survey investigates the best and optimal machine learning algorithms and techniques to recognize human activities in the field of HAR. It provides an in-depth analysis of which algorithms might be suitable for a certain application area. It also investigates which vision-based or non-vision-based acquisition devices are mostly employed in the literature and are suitable for a specific HAR application.},
  archive      = {J_NCA},
  author       = {Kulsoom, Farzana and Narejo, Sanam and Mehmood, Zahid and Chaudhry, Hassan Nazeer and Butt, Ayesha and Bashir, Ali Kashif},
  doi          = {10.1007/s00521-022-07665-9},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {18289-18324},
  shortjournal = {Neural Comput. Appl.},
  title        = {A review of machine learning-based human activity recognition for diverse applications},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Mitigating sensitive data exposure with adversarial
learning for fairness recommendation systems. <em>NCA</em>,
<em>34</em>(20), 18097–18111. (<a
href="https://doi.org/10.1007/s00521-022-07373-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fairness is an important research problem for recommendation systems, and unfair recommendation methods can lead to discrimination against users. Gender is a kind of sensitive feature, exposure sensitive feature can lead to unfair treatment of males and females. However, gender discrimination is still a significant challenge that cannot be addressed well with current recommender methods. To alleviate this problem, we present a novel Unbias Gender Recommendation (UGRec) to balance performance between females and males. We propose a multihop graph aggregation mechanism to improve the representation of users and items, and we design a gender debias component with adversarial learning to eliminate gender bias by filtering out users’ representations. With this design, UGRec can effectively filter out gender bias information and balance fairness between females and males. The experimental results based on three datasets demonstrate the effectiveness and advancement of our proposed UGRec model on fair recommendation.},
  archive      = {J_NCA},
  author       = {Liu, Haifeng and Wang, Yukai and Lin, Hongfei and Xu, Bo and Zhao, Nan},
  doi          = {10.1007/s00521-022-07373-4},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {18097-18111},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mitigating sensitive data exposure with adversarial learning for fairness recommendation systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contour-enhanced CycleGAN framework for style transfer from
scenery photos to chinese landscape paintings. <em>NCA</em>,
<em>34</em>(20), 18075–18096. (<a
href="https://doi.org/10.1007/s00521-022-07432-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image style transfer based on the generative adversarial network model has become an important research field. Among these generative adversarial network models, a distinct advantage of CycleGAN is that it can transfer between multiple domains when the data is not paired. To approximate the effects of the texturing method with the characteristics of traditional Chinese painting—&quot;Cun method&quot;, this paper proposes an image style transfer framework to realize the transfer from scenery photos to Chinese landscape paintings. We design a contour-enhancing translation branch, which effectively guides the transfer from photos to paintings with edge detection operators computing the gradient maps. Simulation results show that this method can convert real scenery photos to Chinese landscape paintings. The Inception Score shows that contour enhancement can make the generated set performs better on sensitivity to image edges. The Kernel Inception distance and Inception-based Structural Similarity between the generated image and the &quot;Cun method&quot; data set shows that contour enhancement can make the generated image closer to the &quot;Cun method&quot; effect. Compared with Kernel Inception distance and Frechet-Inception Distance, the Inception-based Structural Similarity proposed in this paper directly focuses on similarity, the similarities between the mean features of images generated by our model, and the &quot;Cun method&quot; set is 97.89\%, and the composite similarity metric being 0.92. The method also performs better than the MUNIT, NiceGAN, CycleGAN, and U-GAT-IT reference models under the Neural Image Assessment metric. This indicates that the introduction of the edge operator makes the generated landscape paintings more aesthetic, especially in situations where scenery photos are rich in edge information.},
  archive      = {J_NCA},
  author       = {Peng, Xianlin and Peng, Shenglin and Hu, Qiyao and Peng, Jinye and Wang, Jiaxin and Liu, Xinyu and Fan, Jianping},
  doi          = {10.1007/s00521-022-07432-w},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {18075-18096},
  shortjournal = {Neural Comput. Appl.},
  title        = {Contour-enhanced CycleGAN framework for style transfer from scenery photos to chinese landscape paintings},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local search genetic algorithm-based possibilistic weighted
fuzzy c-means for clustering mixed numerical and categorical data.
<em>NCA</em>, <em>34</em>(20), 18059–18074. (<a
href="https://doi.org/10.1007/s00521-022-07411-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering for mixed numerical and categorical attributes has attracted many researchers due to its necessity in many real-world applications. One crucial issue concerned in clustering mixed data is to select an appropriate distance metric for each attribute type. Besides, some current clustering methods are sensitive to the initial solutions and easily trap into a locally optimal solution. Thus, this study proposes a local search genetic algorithm-based possibilistic weighted fuzzy c-means (LSGA-PWFCM) for clustering mixed numerical and categorical data. The possibilistic weighted fuzzy c-means (PWFCM) is firstly proposed in which the object-cluster similarity measure is employed to calculate the distance between two mixed-attribute objects. Besides, each attribute is placed a different important role by calculating its corresponding weight in the PWFCM procedure. Thereafter, GA is used to find a set of optimal parameters and the initial clustering centroids for the PFCM algorithm. To avoid local optimal solution, local search-based variable neighborhoods are embedded in the GA procedure. The proposed LSGA-PWFCM algorithm is compared with other benchmark algorithms based on some public datasets in UCI machine learning repository to evaluate its performance. Two clustering validation indices are used, i.e., clustering accuracy and Rand index. The experimental results show that the proposed LSGA-PWFCM outperforms other algorithms on most of the tested datasets.},
  archive      = {J_NCA},
  author       = {Nguyen, Thi Phuong Quyen and Kuo, R. J. and Le, Minh Duc and Nguyen, Thi Cuc and Le, Thi Huynh Anh},
  doi          = {10.1007/s00521-022-07411-1},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {18059-18074},
  shortjournal = {Neural Comput. Appl.},
  title        = {Local search genetic algorithm-based possibilistic weighted fuzzy c-means for clustering mixed numerical and categorical data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective stochastic paint optimizer (MOSPO).
<em>NCA</em>, <em>34</em>(20), 18035–18058. (<a
href="https://doi.org/10.1007/s00521-022-07405-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single-objective version of stochastic paint optimizer (SPO) is appropriately changed to solve multi-objective optimization problems described as MOSPO. Color theory, the color wheel, and color combination methods are the main concepts of SPO. The SPO will be able to do excellent exploration and exploitation thanks to four simple color combination rules that do not have any internal parameters. Principles like using of fixed-sized external archive make the recommended technique various from the initial single-objective SPO. In addition, to perform multi-objective optimization, the leader selection feature has been added to SPO. The efficiency of recommended multi-objective stochastic paint optimizer (MOSPO) is tested on ten mathematical (CEC-09) and eight multi-objective engineering design problems concerning remarkable precision and uniformity compared to multi-objective particle swarm optimization (MOPSO), multi-objective slap swarm algorithm (MSSA), and multi-objective ant lion optimizer. According to the results of different performance metrics, such as generational distance (GD), inverted generational distance (IGD), maximum spread, and spacing, the proposed algorithm can provide quality Pareto fronts with very competitive results with high convergence.},
  archive      = {J_NCA},
  author       = {Khodadadi, Nima and Abualigah, Laith and Mirjalili, Seyedali},
  doi          = {10.1007/s00521-022-07405-z},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {18035-18058},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective stochastic paint optimizer (MOSPO)},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An optimized deep learning architecture for breast cancer
diagnosis based on improved marine predators algorithm. <em>NCA</em>,
<em>34</em>(20), 18015–18033. (<a
href="https://doi.org/10.1007/s00521-022-07445-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is the second leading cause of death in women; therefore, effective early detection of this cancer can reduce its mortality rate. Breast cancer detection and classification in the early phases of development may allow for optimal therapy. Convolutional neural networks (CNNs) have enhanced tumor detection and classification efficiency in medical imaging compared to traditional approaches. This paper proposes a novel classification model for breast cancer diagnosis based on a hybridized CNN and an improved optimization algorithm, along with transfer learning, to help radiologists detect abnormalities efficiently. The marine predators algorithm (MPA) is the optimization algorithm we used, and we improve it using the opposition-based learning strategy to cope with the implied weaknesses of the original MPA. The improved marine predators algorithm (IMPA) is used to find the best values for the hyperparameters of the CNN architecture. The proposed method uses a pretrained CNN model called ResNet50 (residual network). This model is hybridized with the IMPA algorithm, resulting in an architecture called IMPA-ResNet50. Our evaluation is performed on two mammographic datasets, the mammographic image analysis society (MIAS) and curated breast imaging subset of DDSM (CBIS-DDSM) datasets. The proposed model was compared with other state-of-the-art approaches. The obtained results showed that the proposed model outperforms the compared state-of-the-art approaches, which are beneficial to classification performance, achieving 98.32\% accuracy, 98.56\% sensitivity, and 98.68\% specificity on the CBIS-DDSM dataset and 98.88\% accuracy, 97.61\% sensitivity, and 98.40\% specificity on the MIAS dataset. To evaluate the performance of IMPA in finding the optimal values for the hyperparameters of ResNet50 architecture, it compared to four other optimization algorithms including gravitational search algorithm (GSA), Harris hawks optimization (HHO), whale optimization algorithm (WOA), and the original MPA algorithm. The counterparts algorithms are also hybrid with the ResNet50 architecture produce models named GSA-ResNet50, HHO-ResNet50, WOA-ResNet50, and MPA-ResNet50, respectively. The results indicated that the proposed IMPA-ResNet50 is achieved a better performance than other counterparts.},
  archive      = {J_NCA},
  author       = {Houssein, Essam H. and Emam, Marwa M. and Ali, Abdelmgeid A.},
  doi          = {10.1007/s00521-022-07445-5},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {18015-18033},
  shortjournal = {Neural Comput. Appl.},
  title        = {An optimized deep learning architecture for breast cancer diagnosis based on improved marine predators algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using BERT and knowledge graph for detecting triples in
vietnamese text. <em>NCA</em>, <em>34</em>(20), 17999–18013. (<a
href="https://doi.org/10.1007/s00521-022-07439-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the challenges in constructing Knowledge Graphs from text is verifying the correctness of the produced results. Each language has its unique characteristics, so a Knowledge Graphs construction system may perform better on certain languages and worse on others. In order to detect the most suitable Knowledge Graph construction systems for Vietnamese, in this paper, we propose a method to classify triples extracted from such systems into two categories: Existent and Non-existent. Vietnamese is a low-resource language with limited natural language processing tools and datasets. By combining BERT with a self-constructed Vietnamese Knowledge Graph, we build a classification model to verify the existence of triples in paragraphs. Our results suggest that BERT can learn contextual relations between words from a large amount of text, even for a low-resource language like Vietnamese. BERT’s adaptive capability to detect meaningful triples is also shown and discussed. The outcome of this paper could potentially be used to build more sophisticated systems to solve Knowledge Graph construction and Triple Classification tasks in low resource languages.},
  archive      = {J_NCA},
  author       = {Do, Phuc and Le, Hung and Pham, An B. and Nguyen, Cuong H.},
  doi          = {10.1007/s00521-022-07439-3},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17999-18013},
  shortjournal = {Neural Comput. Appl.},
  title        = {Using BERT and knowledge graph for detecting triples in vietnamese text},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning modeling for the prediction of materials
energy. <em>NCA</em>, <em>34</em>(20), 17981–17998. (<a
href="https://doi.org/10.1007/s00521-022-07416-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) is a fast-evolving field of artificial intelligence that has been applied in many domains due to the increasing availability of computerized databases, including materials science; for instance, validating crystal descriptors for energy prediction poses difficult problems. This work investigates machine learning models to substitute the laboratory crystal energy prediction using two- and three-body distribution functions as structural and atomic descriptors. To achieve this, ML algorithms were used notably ElasticNet, Bayesian Ridge, Random Forest, Support Vector Machine, and Deep Neural Networks to model structural descriptors. Moreover, a non-conventional Deep Neural Networks topology was developed and implemented to model atomic descriptors. Five-fold cross-validation procedure was performed on each model; quality assessment metrics were else used for testing and evaluation in order to identify the most robust descriptors. Finally, the best result of energy prediction was achieved by combining both two- and three-body atomic distribution functions.},
  archive      = {J_NCA},
  author       = {Mouzai, Meriem and Oukid, Saliha and Mustapha, Aouache},
  doi          = {10.1007/s00521-022-07416-w},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17981-17998},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning modeling for the prediction of materials energy},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Object affordance detection with boundary-preserving network
for robotic manipulation tasks. <em>NCA</em>, <em>34</em>(20),
17963–17980. (<a
href="https://doi.org/10.1007/s00521-022-07446-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object affordance detection aims to identify, locate and segment the functional regions of objects, so that robots can understand and manipulate objects like humans. The affordance detection task has two main challenges: (1) Due to the need to provide accurate positioning information for the robot to manipulate objects, the affordance segmentation results are required to have high boundary quality. (2) Different kinds of objects have significant differences in appearances, but may have the same affordance. Correspondingly, parts with the same appearance may have different affordances. The existing methods regard affordance detection as an image segmentation problem, without focusing on the boundary quality of detection results. In addition, most of the existing methods do not consider the potential relationship between object categories and object affordances. Aiming at the above problems, we propose a boundary-preserving network (BPN) to provide affordance masks with better boundary quality for robots to manipulate objects. Our framework contains three new components: the IoU (Intersection-over-Union) branch, the affordance boundary branch and the relationship attention module. The IoU branch is used to predict the IoU score of each object bounding box. The affordance boundary branch is used to guide the network to learn the boundary features of objects. The relationship attention module is used to enhance the feature representation capability of the network by exploring the potential relationship between object categories and object affordances. Experiments show that our method is helpful to improve the boundary quality of the predicted affordance masks. On the IIT-AFF dataset, the performance of the proposed BPN is 2.32\% (F-score) and 2.89\% (F-score) higher than that of the strong baseline in terms of affordance masks and the boundaries of affordance masks, respectively. Furthermore, the real-world robot manipulation experiments show that the proposed BPN can provide accurate affordance information for robots to manipulate objects.},
  archive      = {J_NCA},
  author       = {Yin, Congcong and Zhang, Qiuju},
  doi          = {10.1007/s00521-022-07446-4},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17963-17980},
  shortjournal = {Neural Comput. Appl.},
  title        = {Object affordance detection with boundary-preserving network for robotic manipulation tasks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A light defect detection algorithm of power insulators from
aerial images for power inspection. <em>NCA</em>, <em>34</em>(20),
17951–17961. (<a
href="https://doi.org/10.1007/s00521-022-07437-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of high-voltage transmission lines, the number of power transmission line equipments is correspondingly increasing. Power insulator is the basic component which plays the key role in the stable operation of power system. As a common defect of power insulators, missing-cap issue will affect the structural strength and durability of different power insulators. Therefore, the condition monitoring of power insulators is a daily but priority power line inspection task. Faced with the weak image features of small insulator defects in the aerial images, the conventional handcrafted features could not extract effectively powerful image features. Meanwhile, the small-scale insulator defects will bring a certain effect to the model training of deep learning. Therefore, the high-efficiency and accurate defect inspection still present a challenging task against complex backgrounds. To address the above issues, aimed at the missing-cap defects of power insulators, a novel defect identification algorithm from aerial images is proposed by taking advantage of state-of-the-art deep learning and transfer learning models. Fused with Spatial Pyramid Pooling (SPP) and MobileNet networks, a light deep convolutional neural network (DCNN) model based on You Only Look Once (YOLO) V3 network is proposed for fast and accurate insulator location to remove complex background interference. On the basis, combined with Dempster–Shafer (DS) evidence theory, the improved transfer learning model based on feature fusion is proposed for high-precision defect identification of power insulators. Experiments show that the proposed method could acquire a better identification performance against complex power inspection environment compared with other related detection models.},
  archive      = {J_NCA},
  author       = {Yang, Lei and Fan, Junfeng and Song, Shouan and Liu, Yanhong},
  doi          = {10.1007/s00521-022-07437-5},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17951-17961},
  shortjournal = {Neural Comput. Appl.},
  title        = {A light defect detection algorithm of power insulators from aerial images for power inspection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ANGraph: Attribute-interactive neighborhood-aggregative
graph representation learning. <em>NCA</em>, <em>34</em>(20),
17937–17949. (<a
href="https://doi.org/10.1007/s00521-022-07426-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the graph representation learning problem that has emerged with the advent of numerous graph analysis tasks in the recent past. The task of representation learning from graphs of heterogeneous object attributes and complex topological structures is important yet challenging in practice. We propose an Attribute-interactive Neighborhood-aggregative Graph learning scheme (ANGraph), which better preserves structure proximity and attribute affinity by leveraging attribute interaction and smoothness measures to incorporate vertices similar/close to each other in the original space. In addition, the proposed neighborhood aggregation mechanism aims to improve the performance of GNNs in various types of graphs. Evaluations carried out on five node classification datasets with different information densities verify the benefits of discriminative utilization of vertex information and show that ANGraph significantly outperforms the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Shen, Ying and Li, Huizhi and Li, Dagang and Zheng, Jingwei and Wang, Wenmin},
  doi          = {10.1007/s00521-022-07426-8},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17937-17949},
  shortjournal = {Neural Comput. Appl.},
  title        = {ANGraph: Attribute-interactive neighborhood-aggregative graph representation learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An approach based on 1D fully convolutional network for
continuous sign language recognition and labeling. <em>NCA</em>,
<em>34</em>(20), 17921–17935. (<a
href="https://doi.org/10.1007/s00521-022-07415-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign language is the most important communication method for people with speech impairments, and automatic sign language recognition helps them communicate with normal people without barriers. For portability considerations, the device that integrates surface electromyography (sEMG) sensors and inertial measurement units (IMU) is used to collect and obtain 1D 14-channel sign language data. However, 1D data are not readable by humans. In order to accurately obtain effective sign language to better complete word-level and continuous sign language recognition, synchronized video and a lot of labor costs are needed. In this paper, we propose an approach based on 1D fully convolutional network (FCN) called as SignD-Net, which can be used for labeling and recognition of 1D time series sign language data. SignD-Net compares sign language labeling with object detection and uses YOLO as the basis to assign a bounding box to each predicted object. Using the optimal 1D-CNN model selected by the experiments, continuous sign language labeling and recognition can be realized. With limited data, the model is pre-trained with word-level sign language data and simulated sentence-level data, and at the end of the training, real collected and manually labeled sign language data are used. Through experiments on sign language test data, SignD-Net has been proven to have excellent capabilities, achieving a mean average precision (mAP) of 99.18\% on the labeling task, and achieving a sentence-level accuracy of up to 98.74\% on the recognition task.},
  archive      = {J_NCA},
  author       = {Wang, Fei and Li, Chen and Liu, Chuan-wen and Zeng, Zhen and Xu, Ke and Wu, Jin-xiu},
  doi          = {10.1007/s00521-022-07415-x},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17921-17935},
  shortjournal = {Neural Comput. Appl.},
  title        = {An approach based on 1D fully convolutional network for continuous sign language recognition and labeling},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stability and synchronization of fractional-order
generalized reaction–diffusion neural networks with multiple time delays
and parameter mismatch. <em>NCA</em>, <em>34</em>(20), 17905–17920. (<a
href="https://doi.org/10.1007/s00521-022-07414-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, stability and synchronization of fractional-order generalized reaction–diffusion neural networks with multiple time delays and parameter mismatch are investigated. The global uniform stability conditions of fractional-order generalized reaction–diffusion neural networks are derived. Furthermore, considering parameter mismatch, the global synchronization conditions of fractional-order generalized reaction–diffusion neural networks with multiple time delays are given via the Lyapunov direct method. Finally, two numerical examples are presented to show the effectiveness of our theoretical results.},
  archive      = {J_NCA},
  author       = {Gu, Yajuan and Wang, Hu and Yu, Yongguang},
  doi          = {10.1007/s00521-022-07414-y},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17905-17920},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stability and synchronization of fractional-order generalized reaction–diffusion neural networks with multiple time delays and parameter mismatch},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization of supervised learning models for modeling of
mean monthly flows. <em>NCA</em>, <em>34</em>(20), 17877–17904. (<a
href="https://doi.org/10.1007/s00521-022-07406-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling of mean monthly flow is of particular importance for long-term planning of processes relying on water abstraction, such as reservoir operations. Advantage of data-driven models for these applications is the ability to predict monthly streamflow based on the combined hydrological and climatological input data. Methodology and recommendations for implementation of supervised learning (SL), from choice of input variables and optimization of model parameters in dependence of dataset size to final model evaluation, remains generally undefined. The main objective of this paper is to model mean monthly flow by SL models, while optimization algorithms (genetic algorithm-GA and simulated annealing-SA) are used to optimize and automate the choice of parameters and the reliable set of input variables. Detailed analysis of accuracy and amount of time needed to build three supervised learning models (ANN, SVM and NNM) for modeling of mean monthly flow is given in the paper. The 40-years input dataset has been shown as long enough for building models of satisfying quality, and was used in the further analysis where GA and SA were used first for optimization of model parameters, and later, for simultaneous optimization of both model parameters and input variables for SL models. In the analysis, time series was always split in building, calibration and verification part, while optimization was done on the building and calibration part. Data outside the particular time series was used for additional verification. Optimization of the model parameters by the exhaustive search indicated that the most accurate models were ANN and SVM, overperforming NNM across all data subsets, revealing that models need to be built with external variables. Optimization using GA and SA with SVM produced obvious movement toward optimal values, especially when the choice of parameters and input variables was optimized with GA-SVM.},
  archive      = {J_NCA},
  author       = {Berbić, Jadran and Ocvirk, Eva and Gilja, Gordon},
  doi          = {10.1007/s00521-022-07406-y},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17877-17904},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimization of supervised learning models for modeling of mean monthly flows},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multivariable models including artificial neural network and
M5P-tree to forecast the stress at the failure of alkali-activated
concrete at ambient curing condition and various mixture proportions.
<em>NCA</em>, <em>34</em>(20), 17853–17876. (<a
href="https://doi.org/10.1007/s00521-022-07427-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alkali-activated concrete (AAC) has emerged as a sustainable construction material due to the environmental issues associated with cement production. This type of concrete is cementless concrete that employs industrial or agro by-product ashes like fly ash (FA) and ground granulated blast furnace slag (GGBFS) in their mixture proportions as the primary binders instead of conventional Portland cement. All concrete composites, including AAC, rely on compressive strength. However, the 28-day compressive strength of concrete is critical in structural design. Therefore, developing an authoritative model for estimating AAC compressive strength saves time, energy, and money while guiding the construction and formwork removal. This study used artificial neural network (ANN), M5P-tree, linear regression, non-linear regression, and multi-logistic regression models to predict blended GGBFS/FA-based AAC’s compressive strength at different mixture proportions curing ages. A comprehensive dataset consists of 469 samples collected in several academic research studies and analyzed to develop the models. In the modeling process, for the first time, twelve effective variable parameters on the compressive strength of the AAC, including the alkaline solution-to-binder ratio, FA content, SiO2/Al2O3 of FA, GGBFS content, SiO2/CaO of GGBFS, fine and coarse aggregate content, NaOH and Na2SiO3 content, Na2SiO3/NaOH ratio, molarity and age of concrete specimens were considered as the modeling input parameters. Various statistical assessment tools such as RMSE, MAE, SI, OBJ value, and R2 were used to evaluate the efficiency of the developed models. The results indicated that the ANN model better predicted GGBFS/FA-based AAC mixtures’ compressive strength than the other models. Moreover, the sensitivity analysis demonstrated that the alkaline liquid-to-binder ratio, NaOH content, and age of concrete specimens were those parameters that significantly influenced the compressive strength of the AAC.},
  archive      = {J_NCA},
  author       = {Ahmed, Hemn Unis and Mohammed, Ahmed S. and Mohammed, Azad A.},
  doi          = {10.1007/s00521-022-07427-7},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17853-17876},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multivariable models including artificial neural network and M5P-tree to forecast the stress at the failure of alkali-activated concrete at ambient curing condition and various mixture proportions},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MITNET: A novel dataset and a two-stage deep learning
approach for mitosis recognition in whole slide images of breast cancer
tissue. <em>NCA</em>, <em>34</em>(20), 17837–17851. (<a
href="https://doi.org/10.1007/s00521-022-07441-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mitosis assessment of breast cancer has a strong prognostic importance and is visually evaluated by pathologists. The inter, and intra-observer variability of this assessment is high. In this paper, a two-stage deep learning approach, named MITNET, has been applied to automatically detect nucleus and classify mitoses in whole slide images (WSI) of breast cancer. Moreover, this paper introduces two new datasets. The first dataset is used to detect the nucleus in the WSIs, which contains 139,124 annotated nuclei in 1749 patches extracted from 115 WSIs of breast cancer tissue, and the second dataset consists of 4908 mitotic cells and 4908 non-mitotic cells image samples extracted from 214 WSIs which is used for mitosis classification. The created datasets are used to train the MITNET network, which consists of two deep learning architectures, called MITNET-det and MITNET-rec, respectively, to isolate nuclei cells and identify the mitoses in WSIs. In MITNET-det architecture, to extract features from nucleus images and fuse them, CSPDarknet and Path Aggregation Network (PANet) are used, respectively, and then, a detection strategy using You Look Only Once (scaled-YOLOv4) is employed to detect nucleus at three different scales. In the classification part, the detected isolated nucleus images are passed through proposed MITNET-rec deep learning architecture, to identify the mitosis in the WSIs. Various deep learning classifiers and the proposed classifier are trained with a publicly available mitosis datasets (MIDOG and ATYPIA) and then, validated over our created dataset. The results verify that deep learning-based classifiers trained on MIDOG and ATYPIA have difficulties to recognize mitosis on our dataset which shows that the created mitosis dataset has unique features and characteristics. Besides this, the proposed classifier outperforms the state-of-the-art classifiers significantly and achieves a $$68.7\%$$ F1-score and $$49.0\%$$ F1-score on the MIDOG and the created mitosis datasets, respectively. Moreover, the experimental results reveal that the overall proposed MITNET framework detects the nucleus in WSIs with high detection rates and recognizes the mitotic cells in WSI with high F1-score which leads to the improvement of the accuracy of pathologists’ decision.},
  archive      = {J_NCA},
  author       = {Çayır, Sercan and Solmaz, Gizem and Kusetogullari, Huseyin and Tokat, Fatma and Bozaba, Engin and Karakaya, Sencer and Iheme, Leonardo Obinna and Tekin, Eren and Yazıcı, Çisem and Özsoy, Gülşah and Ayaltı, Samet and Kayhan, Cavit Kerem and İnce, Ümit and Uzel, Burak and Kılıç, Onur},
  doi          = {10.1007/s00521-022-07441-9},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17837-17851},
  shortjournal = {Neural Comput. Appl.},
  title        = {MITNET: A novel dataset and a two-stage deep learning approach for mitosis recognition in whole slide images of breast cancer tissue},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting stress–strain behavior of carbon nanotubes using
neural networks. <em>NCA</em>, <em>34</em>(20), 17821–17836. (<a
href="https://doi.org/10.1007/s00521-022-07430-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks are employed to predict stress–strain curves for all single-walled carbon nanotube configurations with diameters up to 4 nm. Three model architectures are investigated for the molecular dynamics-derived dataset: a multilayer perceptron, a one-dimensional convolutional neural network, and a residual neural network. The performance of the three models is compared, and they are found to closely match an atomistic-physics-based paradigm while being orders of magnitude faster. The effect of the dataset size on the prediction quality is analyzed. It is shown that 30\% of the entire carbon nanotube configuration dataset is representative of the problem. Remarkably, all models demonstrate high accuracy, capturing even the smallest variations due to thermal fluctuations, and can provide averaged stress–strain curves without thermal fluctuations. Additionally, a sensitivity analysis was performed to investigate how the various input feature combinations affect the quality of elimination or prediction of thermal fluctuations. The results are determined by different combinations of input features, with current diameter in combination with temperature identified as the most important parameters affecting the inclusion or exclusion of thermal fluctuations.},
  archive      = {J_NCA},
  author       = {Košmerl, Valentina and Štajduhar, Ivan and Čanađija, Marko},
  doi          = {10.1007/s00521-022-07430-y},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17821-17836},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting stress–strain behavior of carbon nanotubes using neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence approach for modeling petroleum
refinery catalytic desulfurization process. <em>NCA</em>,
<em>34</em>(20), 17809–17820. (<a
href="https://doi.org/10.1007/s00521-022-07423-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequently, petroleum refineries create a variety of fuels as well as a vast range of chemicals for diverse applications. One of the most frequent procedures for purifying petroleum products from unwanted sulfur species and reducing SO2 emissions is the hydrodesulfurization (HDS) process. However, HDS is still challenging since a variety of factors influence sulfur removal rates, including operating circumstances, feed compositions, catalyst activity, and so on. In actuality, reducing sulfur compounds comes at a high price, both environmentally and economically. In practice, it is necessary to forecast process yields and their implications for productivity, profitability, and environmental considerations. The study of such outcomes could serve as guidance for scholars and practitioners alike. Machine Learning (ML) algorithms have proven to be effective in solving various real-world problems in engineering and industrial fields, including the petroleum industry. This study presents a four-input support vector regression (SVR) model hybridized with a Bayesian optimization to predict three yields of the HDS process including outlet sulfur concentration, percentage of SO2 emission, and percentage of biphenyl. The proposed models are used to identify the best laboratory configuration for better optimization of the HDS process. The obtained modeling results reveal that the proposed models are competent with a high degree of accuracy. The correlation coefficients during the testing of the three models were 99.1, 99.2, and 98.8\% while the average experimental errors RMSE and MRAE were 0.022 and 0.097, respectively.},
  archive      = {J_NCA},
  author       = {Al-Jamimi, Hamdi A. and BinMakhashen, Galal M. and Saleh, Tawfik A.},
  doi          = {10.1007/s00521-022-07423-x},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17809-17820},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial intelligence approach for modeling petroleum refinery catalytic desulfurization process},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalized zero-shot domain adaptation with target unseen
class prototype learning. <em>NCA</em>, <em>34</em>(20), 17793–17807.
(<a href="https://doi.org/10.1007/s00521-022-07413-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized zero-shot domain adaptation (GZSDA) aims to classify samples from seen and unseen classes in a target domain by utilizing labeled data for all classes from a source domain and labeled data from seen classes in the target domain. GZSDA is more challenging than zero-shot learning or domain adaptation problems. We aim to learn prototypes for unseen classes in the target domain. The test samples can be classified into one of the seen and unseen classes based on the distance with the prototypes for seen and unseen classes in the target domain. Therefore, we propose a generalized zero-shot domain adaptation with a target unseen class prototype learning method (TUPL). We project the source samples and the target samples into a common subspace by making the samples of the same class near to cope with the domain difference. To strengthen the intra-class compactness of the samples, we pull samples closer to their class prototypes while maintaining data variance, learning discriminative representations in the subspace. Then, we learn the target unseen class prototypes by the relationships of the source and target domains and the relationships of the seen and unseen classes to get more accurate ones. The evaluations on the GZSDA datasets show that TUPL outperforms existing methods.},
  archive      = {J_NCA},
  author       = {Li, Xiao and Fang, Min and Chen, Bo},
  doi          = {10.1007/s00521-022-07413-z},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17793-17807},
  shortjournal = {Neural Comput. Appl.},
  title        = {Generalized zero-shot domain adaptation with target unseen class prototype learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High embedding capacity in 3D model using intelligent fuzzy
based clustering. <em>NCA</em>, <em>34</em>(20), 17783–17792. (<a
href="https://doi.org/10.1007/s00521-022-07404-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High embedding capacity plays a vital role in the watermarking schemes to secure the ownership, authenticity, and copyright-related issues of 3D models. This study describes the watermark embedding using the High Embedding Capacity in 3D Models based on Intelligent Fuzzy Clustering scheme that includes standard Fuzzy C-means (HE-FCM) and Intelligent Fuzzy C-Means (HE-IFCM). Efficiency of optimized cluster segmentation is evaluated and compared with other optimization algorithms. Bit embedding intervals are identified in the resultant clusters to embed the watermark data resulting high embedding capacity. The embedded watermark can be extracted by performing the reverse operation. The embedding capacity, distortion rate and robustness are analyzed using Peak Signal to Noise Ratio (PSNR), Root Means Square Error, correlation coefficient and Hausdorff distance. This scheme is capable of embedding 3 KB to 15 KB for small models and 164KB to 820 KB for larger models achieving around 68 dB of PSNR with less distortion. HE-IFCM is successful in embedding large capacity of watermark data resulting in minimal distortion.},
  archive      = {J_NCA},
  author       = {Narendra, Modigari and Valarmathi, M. L. and Anbarasi, L. Jani and Sarobin, M. Vergin Raja and Al-Turjman, Fadi},
  doi          = {10.1007/s00521-022-07404-0},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17783-17792},
  shortjournal = {Neural Comput. Appl.},
  title        = {High embedding capacity in 3D model using intelligent fuzzy based clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neurodynamic algorithms for constrained distributed convex
optimization over fixed or switching topology with time-varying
communication delay. <em>NCA</em>, <em>34</em>(20), 17761–17781. (<a
href="https://doi.org/10.1007/s00521-022-07399-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the distributed optimization operation mechanism of multi-agent systems, this paper considers how to solve the distributed convex optimization problem with linear inequality constraints when agents in the system have time-varying delays in information interaction. Neurodynamic algorithms which can counteract the negative effect of communication delay on the system are proposed and analyzed, respectively, over fixed or switched topology. In addition, sufficient conditions of linear matrix inequality form are given by the Lyapunov theory. Finally, the convergences and effectiveness of the proposed neurodynamic algorithms over fixed topology and switched topology are verified by numerical examples and a practical application.},
  archive      = {J_NCA},
  author       = {Luan, Linhua and Qin, Sitian},
  doi          = {10.1007/s00521-022-07399-8},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17761-17781},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neurodynamic algorithms for constrained distributed convex optimization over fixed or switching topology with time-varying communication delay},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CAM-k: A novel framework for automated estimating pixel area
using k-means algorithm integrated with deep learning based-CAM
visualization techniques. <em>NCA</em>, <em>34</em>(20), 17741–17759.
(<a href="https://doi.org/10.1007/s00521-022-07428-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposed and implemented a novel framework that can automatically generate accurate area estimation of the identified brick-labeled pixels with the pixel-based intersection of union (IoU) technique. This novel framework employs a combination of fully convolutional neural network with class activation map and K-Means algorithm (CAM-K) to classify, visualize and calculate the pixel areas of brick-labeled images. The existing IoU method based on ground truth and estimated bounding boxes is not suitable for the calculation of localized pixel area. Experiment with our CAM-K framework revealed that it can reliably estimate the pixel areas of the detected object in classified images. Compared with the current state of IoU application, the proposed framework can realize specifically just those targeted pixels objects, and therefore, it can offer a far more realistic IoU metric.},
  archive      = {J_NCA},
  author       = {Hacıefendioğlu, Kemal and Mostofi, Fatemeh and Toğan, Vedat and Başağa, Hasan Basri},
  doi          = {10.1007/s00521-022-07428-6},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17741-17759},
  shortjournal = {Neural Comput. Appl.},
  title        = {CAM-K: A novel framework for automated estimating pixel area using K-means algorithm integrated with deep learning based-CAM visualization techniques},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). R2U++: A multiscale recurrent residual u-net with dense skip
connections for medical image segmentation. <em>NCA</em>,
<em>34</em>(20), 17723–17739. (<a
href="https://doi.org/10.1007/s00521-022-07419-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {U-Net is a widely adopted neural network in the domain of medical image segmentation. Despite its quick embracement by the medical imaging community, its performance suffers on complicated datasets. The problem can be ascribed to its simple feature extracting blocks: encoder/decoder, and the semantic gap between encoder and decoder. Variants of U-Net (such as R2U-Net) have been proposed to address the problem of simple feature extracting blocks by making the network deeper, but it does not deal with the semantic gap problem. On the other hand, another variant UNET++ deals with the semantic gap problem by introducing dense skip connections but has simple feature extraction blocks. To overcome these issues, we propose a new U-Net based medical image segmentation architecture R2U++. In the proposed architecture, the adapted changes from vanilla U-Net are: (1) the plain convolutional backbone is replaced by a deeper recurrent residual convolution block. The increased field of view with these blocks aids in extracting crucial features for segmentation which is proven by improvement in the overall performance of the network. (2) The semantic gap between encoder and decoder is reduced by dense skip pathways. These pathways accumulate features coming from multiple scales and apply concatenation accordingly. The modified architecture has embedded multi-depth models, and an ensemble of outputs taken from varying depths improves the performance on foreground objects appearing at various scales in the images. The performance of R2U++ is evaluated on four distinct medical imaging modalities: electron microscopy, X-rays, fundus, and computed tomography. The average gain achieved in IoU score is 1.5 ± 0.37\% and in dice score is 0.9 ± 0.33\% over UNET++, whereas, 4.21 ± 2.72 in IoU and 3.47 ± 1.89 in dice score over R2U-Net across different medical imaging segmentation datasets.},
  archive      = {J_NCA},
  author       = {Mubashar, Mehreen and Ali, Hazrat and Grönlund, Christer and Azmat, Shoaib},
  doi          = {10.1007/s00521-022-07419-7},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17723-17739},
  shortjournal = {Neural Comput. Appl.},
  title        = {R2U++: A multiscale recurrent residual U-net with dense skip connections for medical image segmentation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). An innovative quadratic interpolation salp swarm-based
local escape operator for large-scale global optimization problems and
feature selection. <em>NCA</em>, <em>34</em>(20), 17663–17721. (<a
href="https://doi.org/10.1007/s00521-022-07391-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salp swarm algorithm (SSA) is a unique swarm intelligent algorithm widely used for various practical applications due to its simple framework and good optimization performance. However, like other swarm-based algorithms, SSA yields local optimal solutions and has a slow convergence rate and low solution accuracy when dealing with high-dimensional global optimization problems. Based on quadratic interpolation and a local escape operator (LEO), a salp swarm optimization algorithm (QSSALEO) is proposed to address these issues. Quadratic interpolation around the best search agent aids QSSALEO&#39;s exploitation ability and solution accuracy, whereas the local escaping operator employs random operators to escape local optima. These tactics complement one another to help SSA promote convergence performance. Furthermore, the algorithm strives for a balance of exploitation and exploration. The proposed QSSALEO method was tested using the CEC 2017 benchmark with 50 and 100 decision variables, as well as seven CEC2008lsgo test functions with 200, 500, and 1000 decision variables, and its performance was compared to that of other metaheuristic algorithms and advanced algorithms, including seven salp swarm variants. The experimental results reveal that QSSALEO outperforms SSA and other population-based algorithms regarding convergence rate and solution correctness. The QSSALEO was then evaluated as a feature selection algorithm on 19 datasets (including three high-dimensional datasets). Friedman and Wilcoxon rank-sum statistical tests are also used to analyze the results. According to experimental data and statistical tests, the QSSALEO algorithm is very competitive and often superior to the algorithms employed in research. Therefore, the proposed method can also be considered a specialized large-scale global optimization optimizer whose performance surpasses state-of-the-art algorithms such as CMA-ES and SHADE. The algorithm source code is available at https://github.com/MohammedQaraad/An-Innovative-Quadratic-interpolation-Salp-Swarm .},
  archive      = {J_NCA},
  author       = {Qaraad, Mohammed and Amjad, Souad and Hussein, Nazar K. and Elhosseini, Mostafa A.},
  doi          = {10.1007/s00521-022-07391-2},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17663-17721},
  shortjournal = {Neural Comput. Appl.},
  title        = {An innovative quadratic interpolation salp swarm-based local escape operator for large-scale global optimization problems and feature selection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel method for intrusion detection in computer networks
by identifying multivariate outliers and ReliefF feature selection.
<em>NCA</em>, <em>34</em>(20), 17647–17662. (<a
href="https://doi.org/10.1007/s00521-022-07402-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of unusual data in computer networks is a critical task for intrusion detection systems. In this study, a novel approach has been proposed for improving intrusion detection system performance by finding multivariate outliers and optimal feature selection. The NSL-KDD dataset consisting of 41 features has been utilized to create and test the system. Firstly, the ReliefF Feature Selection approach has been employed to identify the best features that maintain the classification performance at a high level and 20 features have been determined. Then, to find outliers in the dataset, the Mahalanobis Distance and Chi-Square approaches have been applied. After that, various machine learning methods have been applied to the dataset, and the results have been compared. According to the results, higher classification success has been reached in nearly half the time as a consequence of 20 features obtained from the feature selection and outlier identification processes, compared to the classification done using 41 features. With 99.2187\% accuracy, the Random Forest Algorithm has achieved the best classification success. Finally, it has been observed that the suggested approach provides statistically significant results with a quick detection time and higher classification accuracy.},
  archive      = {J_NCA},
  author       = {Uzun, Birnur and Ballı, Serkan},
  doi          = {10.1007/s00521-022-07402-2},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17647-17662},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel method for intrusion detection in computer networks by identifying multivariate outliers and ReliefF feature selection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Short range correlation transformer for occluded person
re-identification. <em>NCA</em>, <em>34</em>(20), 17633–17645. (<a
href="https://doi.org/10.1007/s00521-022-07400-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occluded person re-identification is one of the challenging areas of computer vision, which faces problems such as inefficient feature representation and low recognition accuracy. Recently, vision transformer is introduced into the field of re-identification and achieved state-of-the-art results by constructing global feature relationships between patch sequences. However, vision transformer is not good at capturing short-range correlations of patch sequence and exploiting spatial correlation in patch sequence, which leads to a decrease in the accuracy and robustness of the network in the face of occluded person re-identification. Therefore, to address the above problems, we design a partial feature transformer-based occluded person re-identification framework named PFT. The proposed PFT utilizes three modules to enhance the efficiency of vision transformer. (1) Patch full dimension enhancement module. We design a learnable tensor with the same size as patch sequences, which is full-dimensional and deeply embedded in patch sequences to enrich the diversity of training samples. (2) Fusion and reconstruction module. We extract the less important part of obtained patch sequences, and fuse them with original patch sequence to reconstruct the original patch sequences. (3) Spatial Slicing Module. We slice and group patch sequences from spatial direction, which can effectively improve the short-range correlation of patch sequences. Experimental results over occluded and holistic re-identification datasets demonstrate that the proposed PFT network achieves superior performance consistently and outperforms the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Zhao, Yunbin and Zhu, Songhao and Wang, Dongsheng and Liang, Zhiwei},
  doi          = {10.1007/s00521-022-07400-4},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17633-17645},
  shortjournal = {Neural Comput. Appl.},
  title        = {Short range correlation transformer for occluded person re-identification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation of adversarial attacks sensitivity of classifiers
with occluded input data. <em>NCA</em>, <em>34</em>(20), 17615–17632.
(<a href="https://doi.org/10.1007/s00521-022-07387-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the noteworthy achievements of deep learning models, there are transformative applications that aim at cost reduction and the improvement in human quality of life. Nevertheless, recent work aimed at testing a classifier’s ability to withstand targeted and black-box adversarial attacks demonstrated that deep learning models, in particular, are brittle and lack certain robustness that makes them particularly weak, and ultimately leading to a lack of trust. For this specific area, a question arises concerning certain regions’ sensitivity in the input space against adversarial perturbations for a classification model. This paper aims to study such a problem by looking into a Sensitivity-inspired Constrained Evaluation Method (SICEM) to deterministically evaluate how much a region of the input space is vulnerable to adversarial perturbations compared to other regions and also the entire input space. Our experiments suggest that SICEM can accurately quantify region vulnerabilities on MNIST and CIFAR-10 datasets.},
  archive      = {J_NCA},
  author       = {Sooksatra, Korn and Rivas, Pablo},
  doi          = {10.1007/s00521-022-07387-y},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17615-17632},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluation of adversarial attacks sensitivity of classifiers with occluded input data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MHD stagnation-point flow of hybrid nanofluid with
convective heated shrinking disk, viscous dissipation and joule heating
effects. <em>NCA</em>, <em>34</em>(20), 17601–17613. (<a
href="https://doi.org/10.1007/s00521-022-07371-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes the MHD stagnation-point flow of Cu-Al2O3/H2O hybrid nanofluid toward a convectively heated shrinking disk with convective boundary condition, suction, Joule heating and viscous dissipation effects. Similarity transformation reduces the PDEs into a system of ODEs, which then numerically solved using the bvp4c solver. The comparison between present and previous results in certain cases shows an excellent agreement with approximately 0\% relative error. Two solutions exist in which the second solution appears near to the separation value of the velocity ratio parameter. The stability analysis shows that the first solution is physically stable (realizable in practice). An increase of suction and magnetic parameters extends the critical value and aids the performance of heat transfer operation. Further, the heat transfer rate boosts while the critical values unchanged with the rise of Eckert number (implies the operating Joule heating and viscous dissipation) and Biot number (implies the operating convective boundary condition). The temperature profile reduces with the increment of velocity ratio parameter, Eckert and Biot numbers while the velocity increases with the addition of velocity ratio and magnetic parameters. This study is important in the estimation of the flow and thermal behavior for Cu-Al2O3/H2O when the physical parameters are embedded.},
  archive      = {J_NCA},
  author       = {Khashi’ie, Najiyah Safwa and Wahid, Nur Syahirah and Md Arifin, Norihan and Pop, Ioan},
  doi          = {10.1007/s00521-022-07371-6},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17601-17613},
  shortjournal = {Neural Comput. Appl.},
  title        = {MHD stagnation-point flow of hybrid nanofluid with convective heated shrinking disk, viscous dissipation and joule heating effects},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bidirectional parallel echo state network for speech emotion
recognition. <em>NCA</em>, <em>34</em>(20), 17581–17599. (<a
href="https://doi.org/10.1007/s00521-022-07410-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech is an effective way for communicating and exchanging complex information between humans. Speech signal has involved a great attention in human-computer interaction. Therefore, emotion recognition from speech has become a hot research topic in the field of interacting machines with humans. In this paper, we proposed a novel speech emotion recognition system by adopting multivariate time series handcrafted feature representation from speech signals. Bidirectional echo state network with two parallel reservoir layers has been applied to capture additional independent information. The parallel reservoirs produce multiple representations for each direction from the bidirectional data with two stages of concatenation. The sparse random projection approach has been adopted to reduce the high-dimensional sparse output for each direction separately from both reservoirs. Random over-sampling and random under-sampling methods are used to overcome the imbalanced nature of the used speech emotion datasets. The performance of the proposed parallel ESN model is evaluated from the speaker-independent experiments on EMO-DB, SAVEE, RAVDESS, and FAU Aibo datasets. The results show that the proposed SER model is superior to the single reservoir and the state-of-the-art studies.},
  archive      = {J_NCA},
  author       = {Ibrahim, Hemin and Loo, Chu Kiong and Alnajjar, Fady},
  doi          = {10.1007/s00521-022-07410-2},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17581-17599},
  shortjournal = {Neural Comput. Appl.},
  title        = {Bidirectional parallel echo state network for speech emotion recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). COVID-19 forecasting and intervention planning using gated
recurrent unit and evolutionary algorithm. <em>NCA</em>,
<em>34</em>(20), 17561–17579. (<a
href="https://doi.org/10.1007/s00521-022-07394-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid spread of COVID-19, caused by the SARS-CoV-2 virus, has had and continues to pose a significant threat to global health. We propose a predictive model based on the gated recurrent unit (GRU) that investigates the influence of non-pharmaceutical interventions (NPIs) on the progression of COVID-19. The proposed model is validated by case studies for multiple states in the United States. It should be noted that the proposed model can be generalized to other regions of interest. The results show that the predictive model can achieve accurate forecasts across the US. The forecast is then utilized to identify the optimal mitigation policies. The goal is to identify the best stringency level for each policy that can minimize the total number of new COVID-19 cases while minimizing the mitigation costs. A meta-heuristics method, named multi-population evolutionary algorithm with differential evolution (MPEA-DE), has been developed to identify optimal mitigation strategies that minimize COVID-19 infection cases while reducing economic and other negative implications. We compared the optimal mitigation strategies identified by the MPEA-DE model with three baseline search strategies. The results show that MPEA-DE performs better than other baseline models based on prescription dominance.},
  archive      = {J_NCA},
  author       = {Bi, Luning and Fili, Mohammad and Hu, Guiping},
  doi          = {10.1007/s00521-022-07394-z},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17561-17579},
  shortjournal = {Neural Comput. Appl.},
  title        = {COVID-19 forecasting and intervention planning using gated recurrent unit and evolutionary algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Counting spikelets from infield wheat crop images using
fully convolutional networks. <em>NCA</em>, <em>34</em>(20),
17539–17560. (<a
href="https://doi.org/10.1007/s00521-022-07392-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wheat is one of the world’s three main crops, with global consumption projected to reach more than 850 million tons by 2050. Stabilising yield and quality of wheat cultivation is a major issue. With the use of remote sensing and non-invasive imaging technology, the Internet of things (IoT) has allowed us to constantly monitor crop development in agriculture. The output of such technologies may be analysed using machine-learning algorithms and image processing methods to extract useful information for crop management assistance. Counting wheat spikelets from infield images is considered one of the challenges related to estimating yield traits of wheat crops. For this challenging problem, we propose a density estimation approach related to crowd counting, SpikeCount. Our proposed counting methods are based on deep learning architectures as those have the advantage of being able to identify features automatically. Annotation of images with the ground truth is required for machine learning approaches, but those are expensive in terms of time and resources. We use transfer Learning in both tasks, segmentation and counting. Our results indicate the segmentation is beneficial as focusing only on the regions of interest improves counting accuracy in most scenarios. In particular, transfer learning from similar images produced excellent results for the counting task for most of the stages of wheat development.},
  archive      = {J_NCA},
  author       = {Alkhudaydi, Tahani and De La lglesia, Beatriz},
  doi          = {10.1007/s00521-022-07392-1},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17539-17560},
  shortjournal = {Neural Comput. Appl.},
  title        = {Counting spikelets from infield wheat crop images using fully convolutional networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-objective artificial bee colony algorithm for
cost-sensitive subset selection. <em>NCA</em>, <em>34</em>(20),
17523–17537. (<a
href="https://doi.org/10.1007/s00521-022-07407-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection typically aims to select a feature subset that maximally contributes to the performance of a further process (such as clustering, classification and regression). Most of the current feature selection methods handle all features in the dataset with the same importance while evaluating the possible feature subsets in a solution space. However, this case may not be appropriate since each feature in a dataset comes with its own impact and importance. In particular, each feature may provide a different cost to achieve some specific purposes. To address this issue, we introduce an improved multi-objective artificial bee colony-based cost-sensitive subset selection method which simultaneously tries to minimize two main conflicting objectives: the classification error rate and the feature cost. According to the results on well-known benchmarks, the proposed cost-sensitive subset selection approach outperforms the recently introduced multi-objective variants of the artificial bee colony, particle swarm optimization and genetic algorithms. To the best of our knowledge, this work is one of the earliest studies on multi-objective cost-sensitive subset selection in the literature.},
  archive      = {J_NCA},
  author       = {Hancer, Emrah},
  doi          = {10.1007/s00521-022-07407-x},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17523-17537},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-objective artificial bee colony algorithm for cost-sensitive subset selection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BERT’s sentiment score for portfolio optimization: A
fine-tuned view in black and litterman model. <em>NCA</em>,
<em>34</em>(20), 17507–17521. (<a
href="https://doi.org/10.1007/s00521-022-07403-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In financial markets, sentiment analysis on natural language sentences can improve forecasting. Many investors rely on information extracted from newspapers or their feelings. Therefore, this information is expressed in their language. Sentiment analysis models classify sentences (or entire texts) with their polarity (positive, negative, or neutral) and derive a sentiment score. In this paper, we use this sentiment (polarity) score to improve the forecasting of stocks and use it as a new “view” in the Black and Litterman model. This score is related to various events (both positive and negative) that have affected some stocks. The sentences used to determine the scores are taken from articles published in Financial Times (an international financial newspaper). To improve the forecast using this average sentiment score, we use a Monte Carlo method to generate a series of possible paths for several trading hours after the article was published to discretize (or approximate) the Wiener measure, which is applied to the paths and returning an exact price as results. Finally, we use the price determined in this way to calculate a yield to be used as views in a new type of “dynamic” portfolio optimization, based on hourly prices. We compare the results by applying the views obtained, disregarding the sentiment and leaving the initial portfolio unchanged.},
  archive      = {J_NCA},
  author       = {Colasanto, Francesco and Grilli, Luca and Santoro, Domenico and Villani, Giovanni},
  doi          = {10.1007/s00521-022-07403-1},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17507-17521},
  shortjournal = {Neural Comput. Appl.},
  title        = {BERT’s sentiment score for portfolio optimization: A fine-tuned view in black and litterman model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A real time prediction methodology for hurricane evolution
using LSTM recurrent neural networks. <em>NCA</em>, <em>34</em>(20),
17491–17505. (<a
href="https://doi.org/10.1007/s00521-022-07384-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast and accurate prediction of hurricane evolution from genesis onwards is needed to reduce loss of life and enhance community resilience. In this work, a novel model development methodology for predicting storm trajectory is proposed based on two classes of Recurrent Neural Networks (RNNs). The RNN models are trained on input features available in or derived from the HURDAT2 North Atlantic hurricane database maintained by the National Hurricane Center (NHC). The models use probabilities of storms passing through any location, computed from historical data. A detailed analysis of model forecasting error shows that Many-To-One prediction models are less accurate than Many-To-Many models owing to compounded error accumulation, with the exception of 6-hr predictions, for which the two types of model perform comparably. Application to 75 or more test storms in the North Atlantic basin showed that, for short-term forecasting up to 12 h, the Many-to-Many RNN storm trajectory prediction models presented herein are significantly faster than ensemble models used by the NHC, while leading to errors of comparable magnitude.},
  archive      = {J_NCA},
  author       = {Bose, Rikhi and Pintar, Adam and Simiu, Emil},
  doi          = {10.1007/s00521-022-07384-1},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17491-17505},
  shortjournal = {Neural Comput. Appl.},
  title        = {A real time prediction methodology for hurricane evolution using LSTM recurrent neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generative adversarial network to evaluate quantity of
information in financial markets. <em>NCA</em>, <em>34</em>(20),
17473–17490. (<a
href="https://doi.org/10.1007/s00521-022-07401-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the information obtainable from the markets are potentially limitless. Economic theory has always supported the possible advantage obtainable from having more information than competitors, however quantifying the advantage that these can give has always been a problem. In particular, in this paper we study the amount of information obtainable from the markets taking into account only the time series of the prices, through the use of a specific Generative Adversarial Network. We consider two types of financial instruments traded on the market, stocks and cryptocurrencies: the first are traded in a market subject to opening and closing hours, whereas cryptocurrencies are traded in a 24/7 market. Our goal is to use this GAN to be able to “convert” the amount of information that the different instruments can have in discriminative and predictive power, useful to improve forecast. Finally, we demonstrate that by using the initial dataset with the 5 most important feature useds by traders, the prices of cryptocurrencies present higher discriminatory and predictive power than stocks, while by adding a feature the situation can be completely reversed.},
  archive      = {J_NCA},
  author       = {Santoro, Domenico and Grilli, Luca},
  doi          = {10.1007/s00521-022-07401-3},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17473-17490},
  shortjournal = {Neural Comput. Appl.},
  title        = {Generative adversarial network to evaluate quantity of information in financial markets},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new modified artificial bee colony algorithm for energy
demand forecasting problem. <em>NCA</em>, <em>34</em>(20), 17455–17471.
(<a href="https://doi.org/10.1007/s00521-022-07675-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to accurately estimate energy consumption in the medium and long term based on actual indications is critical for countries to plan and prioritize their futures and take the appropriate actions. This paper proposes a new modified artificial bee colony (M-ABC) method that can adaptively select an optimal search equation to more accurately estimate Turkey’s energy consumption. In the study, linear (M-ABCL) and quadratic (M-ABCQ) mathematical models were developed, and gross domestic product (GDP), population, import, and export data were used as input parameters for energy demand estimation. The weight values in the regression models are calculated according to the objective function with the proposed M-ABC. In this way, the weight values that will produce estimations with the lowest error according to the selected years are found, and then the most appropriate energy demand estimations are made. We compared the performance of our proposed M-ABC algorithm with ant colony optimization (ACO), particle swarm optimization (PSO), and hybrid ACO and PSO (HAP) algorithms. In addition, various estimation suggestions are presented under four different scenarios using input parameters. According to the results, the models suggested with the M-ABC algorithm were more successful in estimating the energy demand. According to the results of the presented four scenarios, the energy demand in 2025 is 145.26, 139.85, 126.26, and 144.17 million tons of oil equivalent (Mtoe) for the M-ABCL model, and 185.62, 161.94, 118.96, and 159.71 Mtoe for the M-ABCQ model, respectively. Thus, it is predicted that average consumption will increase by 51.65\% in the linear model and 70.94\% in the quadratic model.},
  archive      = {J_NCA},
  author       = {Özdemir, Durmuş and Dörterler, Safa and Aydın, Doğan},
  doi          = {10.1007/s00521-022-07675-7},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17455-17471},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new modified artificial bee colony algorithm for energy demand forecasting problem},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning with deep gaussian processes and homothety in
weather simulation. <em>NCA</em>, <em>34</em>(20), 17441–17453. (<a
href="https://doi.org/10.1007/s00521-022-07386-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Observations and numerical prediction models are the main methods for measuring and estimating the earth&#39;s energy balance parameters. However, the margin of error is very high when simulating meteorological parameters (e.g., latent heat and sensible heat) due to natural disturbances such as the coverage of sensors by clouds. To reduce the margin of error, a machine learning method representing model uncertainty can be useful to minimize fluctuations on measured parameters. In this paper, a learning method with Deep Gaussian Processes offering a probabilistic deep learning is proposed to analyze the numerical prediction model. Then, an optimizer based on a geometric transformation with homothety has been defined to perform the transport of the simulated data to the measured data. The proposed method is tested on the measurements of the global radiation parameter. A satisfactory result is obtained with a reduction of the error margin of about 98\%. This means that the approach is applicable to other parameters to make the numerical forecast model more reliable.},
  archive      = {J_NCA},
  author       = {Coulibaly, Lassana and Kounta, Cheick Abdoul Kadir A. and Kamsu-Foguem, Bernard and Tangara, Fana},
  doi          = {10.1007/s00521-022-07386-z},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17441-17453},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning with deep gaussian processes and homothety in weather simulation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization of FDM process parameters to minimize surface
roughness with integrated artificial neural network model and symbiotic
organism search. <em>NCA</em>, <em>34</em>(20), 17423–17439. (<a
href="https://doi.org/10.1007/s00521-022-07370-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fused deposition modeling (FDM) has shown to be a highly beneficial process for product development. However, one of the great challenges in using FDM is maintaining the surface quality of the produced part. Poor texture quality can be regarded as a defect. It is not part of the geometric prototype but results from the fabrication process. Poor input parameters typically cause these defects by the user. This paper presents the integration between an artificial neural network (ANN) and symbiotic organism search, known as ANN–SOS, to model and minimize the surface roughness (Ra) of the FDM process. The FDM input parameters considered were layer height, print speed, print temperature, and outer shell speed. The experimental data were collected using the central composite design response surface method. Then, the surface roughness model was established using an ANN. After validating the model&#39;s accuracy, it was combined with symbiotic organism search (SOS) to determine the optimal parameter settings for the minimum surface roughness value. The results illustrate that ANN–SOS with a 4-8-8-1 network structure would be the best model for surface roughness prediction. It was observed that decreasing the layer thickness, printing speed, print temperature, and outer shell speed of the FDM input parameters for ANN–SOS resulted in minimum surface roughness of approximately 2.011 µm, which was 12.36\% better than the RSM method.},
  archive      = {J_NCA},
  author       = {Saad, Mohd Sazli and Mohd Nor, Azuwir and Abd Rahim, Irfan and Syahruddin, Muhammad Ariffin and Mat Darus, Intan Zaurah},
  doi          = {10.1007/s00521-022-07370-7},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17423-17439},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimization of FDM process parameters to minimize surface roughness with integrated artificial neural network model and symbiotic organism search},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid IMM-JPDAF algorithm for tracking multiple sperm
targets and motility analysis. <em>NCA</em>, <em>34</em>(20),
17407–17421. (<a
href="https://doi.org/10.1007/s00521-022-07390-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semen analysis has received a lot of attention because of its important role in determining infertility in men. It involves several factors, the most important of which are sperm morphology, sperm concentration, and sperm motility. In addition, measurements of sperm cell mobility reflect important parameters in medical diagnosis. As computer-assisted semen analysis systems are very expensive and not prolific, especially in small medical laboratories, semen analysis is often done manually. This is a time-consuming and costly process. Therefore, we have developed an automated system that evaluates sperm motility parameters which can be of great help to clinicians in achieving more accurate results at a lower cost and time. The system tracks the movement of most spermatozoa cells in a semen sample taken from a microscope and then carefully measures all the parameters related to sperm movement to determine the fertility or infertility rate of the subject. Detecting large numbers of sperm cells is challenging because there are a large number of colliding targets that cause false alarms. In this work, the background subtraction method is used to determine the sperms within the video frames, and the joint probabilistic data association filter algorithm is used to estimate the sperm trajectory and to associate different tracks. Since the sperm represents maneuvering movements, the interacting multiple models technique was used along with the JPDAF algorithms to obtain more accurate results. Our evaluations on real and synthetic data reveal the superiority of our method over previous work in sperm cell tracking.},
  archive      = {J_NCA},
  author       = {Tumuklu Ozyer, Gulsah and Ozyer, Baris and Negin, Farhood and Alarabi, İnas and Agahian, Saeid},
  doi          = {10.1007/s00521-022-07390-3},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17407-17421},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid IMM-JPDAF algorithm for tracking multiple sperm targets and motility analysis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). User intent classification in noisy texts: An investigation
on neural language models. <em>NCA</em>, <em>34</em>(20), 17381–17406.
(<a href="https://doi.org/10.1007/s00521-022-07383-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User-generated content is a fundamental source of information to aid the decision-making in several tasks, such as online marketing and follow-up intent response. Nonetheless, they also present several challenges, as the utterance sentences are short, noisy, lack proper grammar, and relate to multiple classes. Classification from texts has been widely addressed in the last years by extracting features from pretrained language models. However, because of the noisy nature of utterance sentences, directly extracting embeddings from general corpora may not work well to train a user-intention classifier. This manuscript investigates if such a perception empirically proves true in three real-world datasets, one written in English and two in Portuguese. To that, we evaluate pretrained embeddings with several strategies, including different language-based models, general and specific pretrained embeddings, learning embeddings from scratch, and fine-tuning embeddings. We show that adjusting the language of the embeddings to the target dataset vocabulary with a step of the task adaptive pretraining strategy achieves the best overall results. However, directly employing bag-of-words could also work surprisingly well. We also analyze the results with an interpretability method to better understand the predictions and identify classes incorrectly labeled in a dataset.},
  archive      = {J_NCA},
  author       = {Blackman Sphaier, Patrick and Paes, Aline},
  doi          = {10.1007/s00521-022-07383-2},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17381-17406},
  shortjournal = {Neural Comput. Appl.},
  title        = {User intent classification in noisy texts: An investigation on neural language models},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneous data fusion and loss function design for tooth
point cloud segmentation. <em>NCA</em>, <em>34</em>(20), 17371–17380.
(<a href="https://doi.org/10.1007/s00521-022-07379-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tooth point cloud segmentation plays an important role in the digital dentistry, and has received much attention in the past decade. Recently, methods based on the graph neural network have made significant progress. However, the development has been hindered by two challenges: (1) the heterogeneous geometry data are analyzed separately or combined linearly which leads to a semantic gap in different streams; (2) there is mis-alignment between the loss function and evaluation metrics in the segmentation task. In this paper, a novel interacted graph network is presented that combines cues from heterogeneous geometry data by extending the graph attention architecture to propagate information among the different graphs. Moreover, in this paper, an approach is designed to search the segmentation loss function based on the computation graphs according to the evaluation metrics, and the evolution algorithm is revised to avoid potential loss and equivalent loss functions. Our method and other methods use the Shining3D Tooth Segmentation dataset, with experimental results compared in terms of accuracy.},
  archive      = {J_NCA},
  author       = {Liu, Dongsheng and Tian, Yan and Zhang, Yujie and Gelernter, Judith and Wang, Xun},
  doi          = {10.1007/s00521-022-07379-y},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17371-17380},
  shortjournal = {Neural Comput. Appl.},
  title        = {Heterogeneous data fusion and loss function design for tooth point cloud segmentation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic generalized normal distribution optimization for
feature selection. <em>NCA</em>, <em>34</em>(20), 17355–17370. (<a
href="https://doi.org/10.1007/s00521-022-07398-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High dimensionality of data represents a major problem that affects the accuracy of the classification. This problem related with classification is mainly resulted from the availability of irrelevant features. Feature selection represents a solution to a problem by selecting the most informative features and discard the irrelevant features. Generalized normal distribution optimization (GNDO) represents a newly developed optimization that confirmed its outperformance in comparison with well-known optimization algorithms on parameter extraction for photovoltaic models. As an optimization algorithm, however, GNDO suffers from degraded performance when dealing with a problem with a high dimensionality. The main problems of GNDO include exploitation problem by falling into local optima problem. Also, GNDO has solutions diversity problem when it deals with data with high dimensionality. To alleviate the drawbacks of this algorithm and solve feature selection problems, a local search algorithm (LSA) is used. The new algorithm is called dynamic generalized normal distribution optimization (DGNDO), which includes the following main improvements to GNDO: it can improve the best solution to solve the local optima problem, it can improve solution diversity by improving the randomly selected solution, and it can improve both exploration and exploitation combined. To confirm the outperformance and efficiency of the new DGNDO algorithm, DGNDO algorithm is applied on 20 benchmarked datasets from UCI repository of data. In addition, DGNDO algorithm results are compared with seven well-known optimization algorithms using number of evaluation metrics including classification, accuracy, fitness, the number of selected features, statistical results using Wilcoxon test and convergence curves. The obtained results reveal the superiority of DGNDO algorithm over all other competing algorithms.},
  archive      = {J_NCA},
  author       = {Tubishat, Mohammad and Rawshdeh, Zainab and Jarrah, Hazim and Elgamal, Zenab Mohamed and Elnagar, Ashraf and Alrashdan, Maen T.},
  doi          = {10.1007/s00521-022-07398-9},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17355-17370},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic generalized normal distribution optimization for feature selection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An empirical application of a hybrid ANFIS model to predict
household over-indebtedness. <em>NCA</em>, <em>34</em>(20), 17343–17353.
(<a href="https://doi.org/10.1007/s00521-022-07389-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increase in debt levels of families in different parts of the world has drawn the attention of organizations dedicated to the prevention of financial risk and has highlighted the need to develop early detection methods for over-indebtedness. In this paper, we propose a hybrid model of the adaptive neural fuzzy inference system (ANFIS) and Probit model for the prediction of household over-indebtedness. The proposed model is compared with Probit, artificial neural networks (ANN), classification and regression trees (CART), random forest (RF) and support vector machine (SVM) models. The most relevant parameters for the performance of each model are optimized, and we address data balance problems through the synthetic minority over-sampling technique (SMOTE). We use data obtained from the Financial Household Survey of the Central Bank of Chile. The results show that the proposed model performs significantly better than the reference models in terms of the correct classification of indebted individuals. Consequently, this model provides an innovative understanding of household over-indebtedness, which can be useful for different governmental entities focused on preventing excessive indebtedness and maintaining financial stability.},
  archive      = {J_NCA},
  author       = {Kristjanpoller, Werner and Astudillo, Nicole and Olson, Josephine E.},
  doi          = {10.1007/s00521-022-07389-w},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17343-17353},
  shortjournal = {Neural Comput. Appl.},
  title        = {An empirical application of a hybrid ANFIS model to predict household over-indebtedness},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of voting behavior in election using support
vector machine, extreme learning machine and deep learning.
<em>NCA</em>, <em>34</em>(20), 17329–17342. (<a
href="https://doi.org/10.1007/s00521-022-07395-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the extreme learning machine, support vector machine, and deep learning models were used to predict the effect on the voting behavior of election music’s used in the elections in Turkey. A questionnaire was conducted to measure the effect of election music on the voting behavior in Turkey. This questionnaire was applied face to face to 412 people. The twelve questions were used to determine the effect of the election music on the voters. The first eleven of these questions in the questionnaire was used as the input variables of the models. The last question was determined whether the election music affects the voting behavior or not. The last question was selected as the output variable of the models. The extreme learning machine, support vector machine, and deep learning models estimated the voting behavior with 98.32\%, 92.02\% and 99.08\% accuracy, respectively. Moreover, the sensitivity analysis and t-test were performed for the input variables in the models. These analyses obtained that 7th question was the most important question on the questionnaire. This study found that politicians can be used the deep learning algorithm to estimate the voting behavior in elections.},
  archive      = {J_NCA},
  author       = {Imik Tanyildizi, Nural and Tanyildizi, Harun},
  doi          = {10.1007/s00521-022-07395-y},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17329-17342},
  shortjournal = {Neural Comput. Appl.},
  title        = {Estimation of voting behavior in election using support vector machine, extreme learning machine and deep learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A secure two-qubit quantum model for segmentation and
classification of brain tumor using MRI images based on blockchain.
<em>NCA</em>, <em>34</em>(20), 17315–17328. (<a
href="https://doi.org/10.1007/s00521-022-07388-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The size of the medical imaging data is increasing day by day which requires improved tools/applications to perform accurate and efficient diagnoses. Another important concern is to secure the patient&#39;s personal information. Therefore, this research work focuses on a novel secure framework for brain tumor diagnosis. The proposed methodology comprises three main core steps. Initially, the patient&#39;s MRI data are encrypted and decrypted using the SHA-256 algorithm to secure the brain data. The decrypted images are supplied to the 2-qubit quantum model named Javeria (J). Quantum model for tumor classification, which comprises three layers as two dense layers and one Keras layer with a softmax activation unit. The classified tumor images are input to the semantic segmentation model named J. SegCNN for tumor segmentation. The proposed J. SegCNN model contains 11 layers that are trained on selected batch-size and Adam optimizer solver. The proposed model provides a 98\% dice similarity coefficient (DSC) which is far better as compared to the latest research works.},
  archive      = {J_NCA},
  author       = {Amin, Javaria and Anjum, Muhammad Almas and Gul, Nadia and Sharif, Muhammad},
  doi          = {10.1007/s00521-022-07388-x},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17315-17328},
  shortjournal = {Neural Comput. Appl.},
  title        = {A secure two-qubit quantum model for segmentation and classification of brain tumor using MRI images based on blockchain},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven estimation models of asphalt mixtures dynamic
modulus using ANN, GP and combinatorial GMDH approaches. <em>NCA</em>,
<em>34</em>(20), 17289–17314. (<a
href="https://doi.org/10.1007/s00521-022-07382-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of the present study is to develop and evaluate machine learning-based prediction models, employing the artificial neural networks (ANNs), Genetic Programming (GP), and the Combinatorial Group Method of Data Handling (GMDH-Combi), for dynamic modulus (E*) of hot mix asphalt estimation. To develop the models, an experimental database including 1320 data was employed in which dynamic shear modulus of binder, binder phase angle, cumulative percent retained on (3/8-in.) sieve, No. 4 sieve, percent passing No. 200 sieve by total aggregate weight, volumetric percent air voids in the mix, and volumetric effective binder content were considered as the effective contributing parameters on E*. Considered input parameters can be readily measured using simple laboratory tests. The proposed models’ performances were evaluated using common error criteria and compared with that of existing models for estimating E* such as the Witczak, modified Witczak, revised Bari–Witczak, Hirsch, Yu and Shen, Al-Khateeb (I) and (II), global and the simplified global models. The results indicated that the ANN model with correlation coefficients of 0.9821 and 0.9839, respectively, for training and testing, is more accurate than the GMDH (0.9500 and 0.9503) and GP (0.9493 and 0.9495)-based developed models. Additionally, the accuracies of the proposed models outperform entire existing models. Moreover, a wide range of input data was considered in the model development, and the proposed models’ generality and robustness were investigated through a parametric analysis over the covered ranges. The main benefit of using the GMDH and GP approaches was providing closed-form explicit mathematical expressions, which leads to simple and straightforward applications for general engineers and researchers in the field.},
  archive      = {J_NCA},
  author       = {Rezazadeh Eidgahee, Danial and Jahangir, Hashem and Solatifar, Nader and Fakharian, Pouyan and Rezaeemanesh, Mansoureh},
  doi          = {10.1007/s00521-022-07382-3},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17289-17314},
  shortjournal = {Neural Comput. Appl.},
  title        = {Data-driven estimation models of asphalt mixtures dynamic modulus using ANN, GP and combinatorial GMDH approaches},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Practical prescribed-time bipartite synchronization of
interacting neural networks via high-gain coupling. <em>NCA</em>,
<em>34</em>(20), 17279–17288. (<a
href="https://doi.org/10.1007/s00521-022-07381-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work examines the practical prescribed-time bipartite synchronization problem of some interacting neural networks under the leaderless and leader-follower framework, respectively, where the topological structure follows certain signed graph. By applying a feedback controller with well-designed high-gain function, the practical bipartite synchronization is proved to be achievable when time approaches certain prescribed-time. Our theorems provide simple criteria for designing the control parameters and reveal the impact of the underlying network. An interesting finding is that, under a leader-follower framework, bipartite synchronization is unachievable under the conventional pinning controller if the followers that can reach the leader belong to different sets of the signed graph. Furthermore, despite the use of increasing control gain, the control signals are shown to remain bounded. Finally, some numerical examples are presented to show the theoretical result’s validity.},
  archive      = {J_NCA},
  author       = {Ayepah, Kwaku and Sun, Mei and Lyu, Deguang and Jia, Qiang},
  doi          = {10.1007/s00521-022-07381-4},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17279-17288},
  shortjournal = {Neural Comput. Appl.},
  title        = {Practical prescribed-time bipartite synchronization of interacting neural networks via high-gain coupling},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved reptile search algorithm with novel mean transition
mechanism for constrained industrial engineering problems. <em>NCA</em>,
<em>34</em>(20), 17257–17277. (<a
href="https://doi.org/10.1007/s00521-022-07369-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Engineering designs are common industrial optimization problems that need an efficient method to determine the parameters of the problems. This paper proposes a novel engineering design parameters identification method based on an enhanced optimization method called IRSA. The conventional reptile search algorithm (RSA) is utilized in the proposed IRSA method with the mutation technique (MT). These two search methods are used to find the optimal parameters values for the given problems and are employed based on a novel mean transition mechanism . The proposed mean transition mechanism adjusts the searching process by changing between the search process (i.e., RSA or MT) to avoid the main weaknesses of the original RSA: the permutation convergence and unbalance between the search methods. Experiments are conducted on ten benchmark functions from CEC2019 and five industrial engineering design problems. The results are evaluated using worst, mean, and best fitness function values. The proposed method is compared with other well-established methods, and it got better and promising results. The proposed IRSA method’s performance proved its ability to address the mathematical benchmark functions and engineering design problems.},
  archive      = {J_NCA},
  author       = {Almotairi, Khaled H and Abualigah, Laith},
  doi          = {10.1007/s00521-022-07369-0},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17257-17277},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved reptile search algorithm with novel mean transition mechanism for constrained industrial engineering problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New hybrid GR6J-wavelet-based genetic algorithm-artificial
neural network (GR6J-WGANN) conceptual-data-driven model approaches for
daily rainfall–runoff modelling. <em>NCA</em>, <em>34</em>(20),
17231–17255. (<a
href="https://doi.org/10.1007/s00521-022-07372-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rainfall–runoff modeling is significant for efficient water resources management and planning. The hydrological conceptual models can have challenges, such as dealing with nonlinearity and needing more data, whereas data-driven models are generally lacking in reflecting the physical process in the basin. Accordingly, two-hybrid model structures, namely Génie Rural à 6 paramètres Journalier (GR6J)-wavelet-based-genetic algorithm-artificial neural network1 (GR6J-WGANN1) and GR6J-wavelet-based genetic algorithm-artificial neural network2 (GR6J-WGANN2) models, were proposed in this study to develop rainfall–runoff modeling performance. The novel GR6J-WGANN1 model used the routing store outflow (QR), exponential store outflow (QRexp), and direct flow (QD) obtained from the GR6J, and the GR6J-WGANN2 model used the soil moisture index (SMI) obtained from the GR6J as input data. The wavelet transformation and Boruta algorithm were implemented to decompose the input data into components and select important wavelet components, respectively. The performance of the GR6J, standalone WGANN models, and hybrid models were tested in three sub-basins of Konya Closed Basin, Turkey, which generally has arid and changing climate conditions. The hybrid models performed better than the conceptual and data-driven models, particularly regarding the extreme flow predictions. Using soil moisture index, routing store outflow, exponential store outflow, and direct flow as the output of the GR6J in GR6J-WGANN1 and GR6J-WGANN2 improved the rainfall–runoff modeling performance remarkably. The findings of this study indicated that hybrid models, which integrate strong sides of conceptual and data-driven models, can be more useful for producing more accurate forecasting results.},
  archive      = {J_NCA},
  author       = {Sezen, Cenk and Partal, Turgay},
  doi          = {10.1007/s00521-022-07372-5},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17231-17255},
  shortjournal = {Neural Comput. Appl.},
  title        = {New hybrid GR6J-wavelet-based genetic algorithm-artificial neural network (GR6J-WGANN) conceptual-data-driven model approaches for daily rainfall–runoff modelling},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computational AI models in VAT photopolymerization: A
review, current trends, open issues, and future opportunities.
<em>NCA</em>, <em>34</em>(20), 17207–17229. (<a
href="https://doi.org/10.1007/s00521-022-07694-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence has played a potential role in present technological advancements. In terms of additive manufacturing or 3D printing techniques, computational AI models and algorithms such as artificial neural network, genetic algorithms, evolutionary algorithms, conventional machine learning techniques like decision tree, Naïve Bayes, K nearest neighbours, support vector machine, and ensemble methods including random forest, etc., has shown incredible results in the past few years. The applications of artificial intelligence in manufacturing are rapidly influencing most of the factors such as process optimization, material property prediction, determining the probability of product failure, real-time monitoring of processes, secure remote customer interactions, feature automation, material tuning, design feature recommendation, precise analysis, quality control/enhancement, or dynamic system modelling. Recent research in the field of VAT photopolymerization indicates that the creation of complex, versatile material systems with adaptable mechanical, chemical, and optical properties via the high-resolution processes includes a variety of 3D printing technologies, like stereolithography, digital illumination processing, and continuous liquid interface production. It has a compelling future in the last industrial revolution, Industry 4.0. This review compiles the evolution, current trends, open issues, and future computational AI models in 3D-printing VAT photopolymerization. Possibilities, prospects, and projects are well discussed to understand the significance of this technology.},
  archive      = {J_NCA},
  author       = {Sachdeva, Isha and Ramesh, Sivasubramani and Chadha, Utkarsh and Punugoti, Hruditha and Selvaraj, Senthil Kumaran},
  doi          = {10.1007/s00521-022-07694-4},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17207-17229},
  shortjournal = {Neural Comput. Appl.},
  title        = {Computational AI models in VAT photopolymerization: A review, current trends, open issues, and future opportunities},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Event prediction within directional change framework using a
CNN-LSTM model. <em>NCA</em>, <em>34</em>(20), 17193–17205. (<a
href="https://doi.org/10.1007/s00521-022-07687-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial forecasting has always been an intriguing research area in the field of finance. The widely accepted approach to forecast financial data is to perform predictions using time series data. In time series analysis, sampling the financial data with a predefined frequency (e.g. hourly, daily) leads to an uneven and discontinued data flow. Directional Change is a newly proposed approach that replaces physical time within the financial data and establishes an event-driven framework. With the emergence of the machine and deep learning-based methods, researchers have utilised them in financial time series. These techniques have shown to outperform conventional approaches. This paper aims to employ the CNN-LSTM model to investigate its predictive competence within the Directional Change (DC) framework to predict DC event prices. To obtain this objective, we first create the tick bars/candles of the GBPUSD, EURUSD, USDCHF, and USDCAD tick prices from January to August 2019. Then, the DC-based summaries of the selected tick bar/candle for each currency pair will be generated and fed to the CNN-LSTM model. The CNN-LSTM network architecture incorporates the robustness of Convolutional Neural Network (CNN) in feature extraction and Long Short-Term Memory (LSTM) in predicting sequential data. The results suggest that the performance of the CNN-LSTM model improves significantly within the DC framework.},
  archive      = {J_NCA},
  author       = {Rostamian, Ahoora and O’Hara, John G.},
  doi          = {10.1007/s00521-022-07687-3},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {17193-17205},
  shortjournal = {Neural Comput. Appl.},
  title        = {Event prediction within directional change framework using a CNN-LSTM model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel epsilon-dominance harris hawks optimizer for
multi-objective optimization in engineering design problems.
<em>NCA</em>, <em>34</em>(19), 17007–17036. (<a
href="https://doi.org/10.1007/s00521-022-07352-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, A Multi-Leaders Guided Harris Hawks optimizer using Epsilon-Dominance relation is developed for solving multi-objective optimization problems. For this reason, the standard HHO algorithm is equipped with a fixed-size external archive to ensure the elitism concept. On the other hand, both crowding distance computation and epsilon dominance relation are adopted when updating the archive in the hope of improving the diversity of solutions. Moreover, an efficient leader selection procedure is proposed to guarantee convergence towards less-crowded Pareto regions. Our algorithm’s performance is validated on 18 test functions in all, 5 with two objectives and 13 with three objectives, and it is compared with four well-regarded algorithms, namely: Multi-objective Evolutionary Algorithm Based on Decomposition (MOEA/D), Multi-Objective Grey Wolf Optimizer (MOGWO), Multi-Objective Particle Swarm Optimization (MOPSO), and Multi-objective Salp Swarm Algorithm (MSSA). Also, it is applied to solve four engineering real-world problems, namely: Four bar truss, Speed reducer, Disk brake design, and Welded beam design problems. Inverted Generational Distance (IGD) metric and Hypervolume (HV) metric were used to quantify the behaviors of multi-objective algorithms. The obtained results show the performance of the proposed algorithm in terms of convergence and diversity for the benchmark functions and the engineering real-world problems.},
  archive      = {J_NCA},
  author       = {Allou, Lotfi and Zouache, Djaafar and Amroun, Kamal and Got, Adel},
  doi          = {10.1007/s00521-022-07352-9},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {17007-17036},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel epsilon-dominance harris hawks optimizer for multi-objective optimization in engineering design problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Resource-constrained FPGA implementation of YOLOv2.
<em>NCA</em>, <em>34</em>(19), 16989–17006. (<a
href="https://doi.org/10.1007/s00521-022-07351-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Progress is being made to deploy convolutional neural networks (CNNs) into the Internet of Things (IoT) edge devices for handling image analysis tasks locally. These tasks require low-latency and low-power computation on low-resource IoT edge devices. However, CNN-based algorithms, e.g. YOLOv2, typically contain millions of parameters. With the increase in the CNN’s depth, filters are increased by a power of two. A large number of filters and operations could lead to frequent off-chip memory access that affects the operation speed and power consumption of the device. Therefore, it is a challenge to map a deep CNN into a low-resource edge IoT platform. To address this challenge, we present a resource-constrained Field-Programmable Gate Array implementation of YOLOv2 with optimized data transfer and computing efficiency. Firstly, a scalable cross-layer dataflow strategy is proposed which allows on-chip data transfer between different types of layers, and offers flexible off-chip data transfer when the intermediate results are unaffordable on-chip. Next, a filter-level data-reuse dataflow strategy together with a filter-level parallel multiply-accumulate operation computing processing elements array is developed. Finally, multi-level sliding buffers are developed to optimize the convolutional computing loop and reuse the input feature maps and weights. Experiment results show that our implementation has achieved 4.8 W of low-power consumption for executing YOLOv2, an 8-bit deep CNN containing 50.6 MB weights, using low-resource of 8.3 Mbits on-chip memory. The throughput and power efficiency are 100.33 GOP/s and 20.90 GOP/s/W, respectively.},
  archive      = {J_NCA},
  author       = {Zhang, Zhichao and Mahmud, M. A. Parvez and Kouzani, Abbas Z.},
  doi          = {10.1007/s00521-022-07351-w},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16989-17006},
  shortjournal = {Neural Comput. Appl.},
  title        = {Resource-constrained FPGA implementation of YOLOv2},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of physiological disorders in apples fruit
using a hybrid model based on convolutional neural network and machine
learning methods. <em>NCA</em>, <em>34</em>(19), 16973–16988. (<a
href="https://doi.org/10.1007/s00521-022-07350-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physiological disorders in apples are due to post-harvest conditions. For this reason, automatic identification of physiological disorders is important in obtaining agricultural information. Image processing is one of the techniques that can help achieve the features of physiological disorders. Physiological disorders during image acquisition can be affected by the changes in brightness values created by different lighting conditions. This changes the results of the classification. In recent years, the convolutional neural network (CNN) has been a successful approach in automatically obtaining deep features from raw images in image classification problems. The study aims to classify physiological disorders using machine learning (ML) methods according to extracted deep features of the images under different lighting conditions. The data sets were created by acquired images (1080 images) and augmentation images (4320 images). Deep features were extracted using five popular pre-trained CNN models in these data sets, and these features were classified using five ML methods. The highest average accuracy was obtained with the VGG19(fc6) + SVM method in the data set-1 and data set-2 and were 96.11 and 96.09\%, respectively. With this study, physiological disorders can be determined early, and needed precautions can be taken before and after harvest, not too late.},
  archive      = {J_NCA},
  author       = {Buyukarikan, Birkan and Ulker, Erkan},
  doi          = {10.1007/s00521-022-07350-x},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16973-16988},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of physiological disorders in apples fruit using a hybrid model based on convolutional neural network and machine learning methods},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Long short-term cognitive networks. <em>NCA</em>,
<em>34</em>(19), 16959–16971. (<a
href="https://doi.org/10.1007/s00521-022-07348-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a recurrent neural system named long short-term cognitive networks (LSTCNs) as a generalization of the short-term cognitive network (STCN) model. Such a generalization is motivated by the difficulty of forecasting very long time series efficiently. The LSTCN model can be defined as a collection of STCN blocks, each processing a specific time patch of the (multivariate) time series being modeled. In this neural ensemble, each block passes information to the subsequent one in the form of weight matrices representing the prior knowledge. As a second contribution, we propose a deterministic learning algorithm to compute the learnable weights while preserving the prior knowledge resulting from previous learning processes. As a third contribution, we introduce a feature influence score as a proxy to explain the forecasting process in multivariate time series. The simulations using three case studies show that our neural system reports small forecasting errors while being significantly faster than state-of-the-art recurrent models.},
  archive      = {J_NCA},
  author       = {Nápoles, Gonzalo and Grau, Isel and Jastrzębska, Agnieszka and Salgueiro, Yamisleydi},
  doi          = {10.1007/s00521-022-07348-5},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16959-16971},
  shortjournal = {Neural Comput. Appl.},
  title        = {Long short-term cognitive networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic scene generation using sentiment analysis and
bidirectional recurrent neural network with multi-head attention.
<em>NCA</em>, <em>34</em>(19), 16945–16958. (<a
href="https://doi.org/10.1007/s00521-022-07346-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text generation is one of the complex tasks associated with natural language processing. For efficient text generation, syntax and semantics of the language have to be considered to assign context to key phrases. The main objective of the proposed work is to perform text generation specifically for movie scripts. The training data consist of a self-annotated corpus of movie scripts depicting scenes, specific to certain genre where the annotation mainly focuses on a specific director’s movie scripts. The scene generation is set forth by word embedding with sentiment classification where the emotionally analyzed words are vectorized using the EmoVec algorithm performing sentiment analysis. Based on the sentiment and location associated with each scene, context for the phrases is identified and proceeded to build a well-defined script. Bidirectional long short-term memory BLSTM with multi-head attention is used to capture the information processed in both forward and backward propagation in order to understand future context. The vocabulary is built using Stanford’s Internet Movie Database IMDB datasets to perform word-based encoding for which requirement of an extensive vocabulary is imminent.},
  archive      = {J_NCA},
  author       = {Dharaniya, R. and Indumathi, J. and Uma, G. V.},
  doi          = {10.1007/s00521-022-07346-7},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16945-16958},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic scene generation using sentiment analysis and bidirectional recurrent neural network with multi-head attention},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mutual purification for unsupervised domain adaptation in
person re-identification. <em>NCA</em>, <em>34</em>(19), 16929–16944.
(<a href="https://doi.org/10.1007/s00521-022-07340-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation person re-identification aims to adapt the model learned on a labeled source domain to an unlabeled target domain. It has attracted extensively attention in the computer vision community due to its important applications in security and surveillance. Existing approaches are primary to utilize pseudo labels assigned by clustering algorithm as supervision information on target domain. One of the most successful methods exploits neighbors of each unlabeled image to generate pseudo labels, in which contain noise and errors inevitably. In this paper, we propose a Mutual Purification Network (MP-Net) to alleviate errors of pseudo-labels and errors accumulation. MP-Net aims to utilize two independent pre-trained models to learn external auxiliary knowledge from each other, which consists of mutual purification neighbors-exploiting (MPNE) and mutual purification selection (MPS). MPNE focuses on using the common and unique knowledge of the two models to mine more robust neighbor relationships for alleviating the noise and errors from the normal neighbors exploiting. MPS aims to filter outliers and construct reliable triplets during training with triplet loss in unsupervised scenario. Each model selects more reliable and informative positives and negatives for peer models based on dynamic ranking and isolation computation. Extensive experiments on three large-scale public datasets, including Market-1501, DukeMTMC and MSMT17 illustrate that our MP-Net outperforms or shows comparable results to the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Zhang, Lei and Diao, Qishuai and Jiang, Na and Zhou, Zhong and Wu, Wei},
  doi          = {10.1007/s00521-022-07340-z},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16929-16944},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mutual purification for unsupervised domain adaptation in person re-identification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantic enhanced top-k similarity search on weighted HIN.
<em>NCA</em>, <em>34</em>(19), 16911–16927. (<a
href="https://doi.org/10.1007/s00521-022-07339-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similarity searches on heterogeneous information networks (HINs) have attracted wide attention from both industrial and academic areas in recent years; for example, they have been used for friend detection in social networks and collaborator recommendation in coauthor networks. The structural information on the HIN can be captured by multiple metapaths, and people usually utilize metapaths to design methods for similarity search. The rich semantics in HINs are not only structural information but also content stored in nodes. However, the content similarity of nodes was usually not valued in the existing methods. Although some researchers have recently considered both types of information in machine learning-based methods for similarity search, they have used structure and content information separately. To address this issue by balancing the influence of structure and content information flexibly in the process of searching, we propose a double channel convolutional neural network model for top-k similarity search, which uses path instances as model inputs and generates structure and content embeddings for nodes based on different metapaths. We design an attention mechanism to enhance the differences in metapaths for each node. Another attention mechanism is used to combine the content and structure information of nodes. Finally, an importance evaluation function is designed to improve the accuracy and make the model more explainable. The experimental results show that our search algorithm can effectively support top-k similarity search in HINs and achieve higher performance than existing approaches.},
  archive      = {J_NCA},
  author       = {Zhang, Yun and Yu, Minghe and Zhang, Tiancheng and Yu, Ge},
  doi          = {10.1007/s00521-022-07339-6},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16911-16927},
  shortjournal = {Neural Comput. Appl.},
  title        = {Semantic enhanced top-k similarity search on weighted HIN},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Breast cancer detection by using associative classifier with
rule refinement method based on relevance feedback. <em>NCA</em>,
<em>34</em>(19), 16897–16910. (<a
href="https://doi.org/10.1007/s00521-022-07336-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-aided diagnosis system that uses classification process for an automated detection of breast cancer could provide a second opinion that improves diagnosis. Several researchers have proposed the use of associative classifier that generates strong associations between features and reveals hidden relationship that can be missed by other classification algorithms. However, the effectiveness of an associative classifier depends largely on the generalized rules based on training data. Often, the number of training data is limited, which may further produce the classification rules that are stagnant and cannot adapt to a changing distribution of test images, as such it may not produce complete and accurate rules for classification for future cases. This paper aims to address this issue by refining rules that are static using dynamic rule refinement technique. This technique helps to adapt to the changes in the new evidences that can be used for classification to further enhance the performance of the associative classifier. A method named the rule refinement based on incremental modification is proposed that dynamically refines the rules after the suggested term is validated by the experts. Once the initial classification is performed using the generalized rules for each test example, the results are validated using the experts feedback. Based on the validated classification result either correct or incorrect, the rules that are responsible for classification are refined in three phases. These refined rules are used for classification of future test examples that leads to improved prediction accuracy in comparison with the classifier that uses generalized static rules. The performance of the proposed method evaluated on the digital database for screening mammography dataset is promising and has achieved an overall classification accuracy of 96\% in the biased setting and an accuracy of 95.24\% in the unbiased setting as compared to the accuracy 90.48\% of baseline classifier with static rules.},
  archive      = {J_NCA},
  author       = {Abubacker, Nirase Fathima and Azman, Azreen and Doraisamy, Shyamala and Murad, Masrah Azrifah Azmi},
  doi          = {10.1007/s00521-022-07336-9},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16897-16910},
  shortjournal = {Neural Comput. Appl.},
  title        = {Breast cancer detection by using associative classifier with rule refinement method based on relevance feedback},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A supervised discriminant data representation: Application
to pattern classification. <em>NCA</em>, <em>34</em>(19), 16879–16895.
(<a href="https://doi.org/10.1007/s00521-022-07332-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of machine learning and pattern recognition algorithms generally depends on data representation. That is why, much of the current effort in performing machine learning algorithms goes into the design of preprocessing frameworks and data transformations able to support effective machine learning. The method proposed in this work consists of a hybrid linear feature extraction scheme to be used in supervised multi-class classification problems. Inspired by two recent linear discriminant methods: robust sparse linear discriminant analysis (RSLDA) and inter-class sparsity-based discriminative least square regression (ICS_DLSR), we propose a unifying criterion that is able to retain the advantages of these two powerful methods. The resulting transformation relies on sparsity-promoting techniques both to select the features that most accurately represent the data and to preserve the row-sparsity consistency property of samples from the same class. The linear transformation and the orthogonal matrix are estimated using an iterative alternating minimization scheme based on steepest descent gradient method and different initialization schemes. The proposed framework is generic in the sense that it allows the combination and tuning of other linear discriminant embedding methods. According to the experiments conducted on several datasets including faces, objects, and digits, the proposed method was able to outperform competing methods in most cases.},
  archive      = {J_NCA},
  author       = {Dornaika, F. and Khoder, A. and Moujahid, A. and Khoder, W.},
  doi          = {10.1007/s00521-022-07332-z},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16879-16895},
  shortjournal = {Neural Comput. Appl.},
  title        = {A supervised discriminant data representation: Application to pattern classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatiotemporal context-aware network for video salient
object detection. <em>NCA</em>, <em>34</em>(19), 16861–16877. (<a
href="https://doi.org/10.1007/s00521-022-07330-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been witnessed that there is an increasing interest in video salient object detection (VSOD) in computer vision field. Different from image salient object detection (ISOD), VSOD not only requires appearance information but also needs motion cues. Thus, it is essential to exploit spatiotemporal information to generate accurate saliency results. Existing VSOD models mainly combine an ISOD model with long short-term memory (LSTM) or flow-estimation modules to integrate saliency cues estimated from spatial and temporal domain. However, flow-estimation modules heavily rely on optical flow images; the generation process of which is rather time-consuming and severely limits its applications in practice. Besides, the LSTM can only exploit motion cues via a step-by-step propagation in the time domain and is hard to realize the multi-scale spatiotemporal interaction. In this paper, we propose the SCANet to solve the above problems. Specifically, we develop the pyramid dilated 3D convolutional (PD3C) module to generate rich temporal features by leveraging context information. Besides, a feature aggregation module is designed to effectively integrate spatial and temporal features. Equipped with these modules, the SCANet is capable of generating high-quality saliency maps at more than real-time inference speed (41 FPS on a single Titan Xp GPU). Extensive experimental results on six widely used benchmark datasets prove that SCANet outperforms state-of-the-art methods in terms of three standard evaluation metrics. Our code will be publicly available at https://github.com/clelouch/SCANet .},
  archive      = {J_NCA},
  author       = {Chen, Tianyou and Xiao, Jin and Hu, Xiaoguang and Zhang, Guofeng and Wang, Shaojie},
  doi          = {10.1007/s00521-022-07330-1},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16861-16877},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatiotemporal context-aware network for video salient object detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An UWB-based indoor coplanar localization and anchor
placement optimization method. <em>NCA</em>, <em>34</em>(19),
16845–16860. (<a
href="https://doi.org/10.1007/s00521-022-07329-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrawideband (UWB)-based localization systems are appropriated for human and vehicle tracking because the time-of-flight between UWB devices can be accurately estimated. A moving UWB embedded target can be located by the anchors whose positions are set in the initialization step. Considering that some areas are unreachable or dangerous for humankind or some urgent tasks make it impossible to set the position for anchors manually. Hence, we propose a coplanar localization method for one-side-open areas, which is easy for deploying. In this method, the coordinates of the inside node can be estimated by the coplanar outside anchors that are attached to an outside window and are easy for calibrating. However, optimizing anchor placement is still a critical challenge that affects localization performance and is essentially NP-complete. To improve the localization accuracy, we propose an anchor placement optimization method that is based on utilizing the genetic algorithm and minimizing the Cramer-Rao lower bound. Finally, field experiments are conducted, and a thorough comparison confirms the efficiency and effectiveness of the proposed method.},
  archive      = {J_NCA},
  author       = {Pan, Hao and Qi, Xiaogang and Liu, Meili and Liu, Lifang},
  doi          = {10.1007/s00521-022-07329-8},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16845-16860},
  shortjournal = {Neural Comput. Appl.},
  title        = {An UWB-based indoor coplanar localization and anchor placement optimization method},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel transfer learning-based short-term solar forecasting
approach for india. <em>NCA</em>, <em>34</em>(19), 16829–16843. (<a
href="https://doi.org/10.1007/s00521-022-07328-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models in recent times have shown promising results for solar energy forecasting. Solar energy depends heavily on local weather conditions, and as a result, typically hundreds of models are built, which need site and season-specific training. The model maintenance and management also become a tedious job with such a large number of models. Here, we are motivated to use transfer learning to accommodate local variations in the solar pattern over the available global pattern. It may also be noted that apparently transfer learning has been rarely/never used for solar forecasting. In this paper, we have proposed a bidirectional gated recurrent unit (BGRU) based model, which employs transfer learning for short-term solar energy forecasting. The said model yields better forecasting accuracy compared to site-specific models with a lower variance. It also takes 39.6\% less parameters and 76.1\% reduced time for training. The current literature suggests that selection of base scenario for transfer learning is an open problem and in this paper, we have also proposed an intuitive strategy for the same. The effectiveness of the same is established through empirical study.},
  archive      = {J_NCA},
  author       = {Goswami, Saptarsi and Malakar, Sourav and Ganguli, Bhaswati and Chakrabarti, Amlan},
  doi          = {10.1007/s00521-022-07328-9},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16829-16843},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel transfer learning-based short-term solar forecasting approach for india},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A noise-tolerant cryptosystem based on the decomposition of
bit-planes and the analysis of chaotic gauss iterated map. <em>NCA</em>,
<em>34</em>(19), 16805–16828. (<a
href="https://doi.org/10.1007/s00521-022-07327-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secure communication has become a challenging task for researchers. In these circumstances, several encryption techniques for digital images have been proposed. In this paper, a new cryptosystem for color images is proposed based on the bit-plane decomposition, chaos theory and discrete wavelet transform (DWT). Bit plane decomposition and DWT are incorporated in order to reduce the overall computational time of the proposed encryption algorithm. To achieve the desired purpose, only the low frequency band is considered for the encryption, because a major part of the plaintext image lies in the low-frequency components. Moreover, chaotic maps are deployed to generate the random sequences and the key-image, which are used to create the diffusion in the plaintext image. For creating the randomness in the plaintext image, the seed values are selected based on the analysis of Gauss Iterated Map (GIM). The cipher image generated using the proposed encryption algorithm can also tolerate channel noise. If the ciphered data are altered by an unauthorized person or by the noisy channel, the plaintext image can still be recovered with little loss of information. The proposed work’s noise tolerance is assessed using cropping and noise attack analysis. To figure out the strength of the proposed cryptosystem, security parameters such as unified average change intensity (UACI) and number of pixels change rate (NPCR), entropy, energy, contrast correlation, and entropy are under consideration. The entropy values, NPCR and UACI, are larger than 7.99, 33 and 99.4\%, respectively, which are remarkable.},
  archive      = {J_NCA},
  author       = {Shafique, Arslan},
  doi          = {10.1007/s00521-022-07327-w},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16805-16828},
  shortjournal = {Neural Comput. Appl.},
  title        = {A noise-tolerant cryptosystem based on the decomposition of bit-planes and the analysis of chaotic gauss iterated map},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SafeMove: Monitoring seniors with mild cognitive impairments
using deep learning and location prediction. <em>NCA</em>,
<em>34</em>(19), 16785–16803. (<a
href="https://doi.org/10.1007/s00521-022-07320-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to society aging, age-related issues such as mild cognitive impairments (MCI) and dementia are attracting the attention of health professionals, scientists and governments. Seniors suffering from such impairments notice a slight deterioration in their cognitive abilities, which may lead to memory loss and behavioural disorders. In consequence, such seniors refrain from doing their everyday outdoor activities. Technology, e.g. smartphones, wearables and artificial intelligence, can provide seniors and their relatives with a variety of monitoring tools. In a nutshell, locations are analysed and, under specific situations, alarms are raised so that caregivers urgently informed. In this context, the discovery and prediction of trajectories and behaviours play a key role in deploying effective monitoring solutions. In this paper, we present a real-time smartphone-based monitoring system, called SafeMove, to discover and predict elderly people behaviours by analyzing outdoor trajectories. This is achieved by firstly analysing the elder’s mobility data previously collected using the proposed model called SpaceTime-Convolutional Neural Network (ST-CNN) in order to predict the most popular locations he/she might visit in the next time. Based on the predicted locations, the elder can be monitored in bounded region. Time and space-related variables, such as the distance traversed, the direction of the movements and the time spent, are analyzed in our abnormal behaviour detection (ABD) model that takes advantage of recurrent neural networks (RNNs). The effectiveness and the efficiency of our system for predicting the next location and detection the abnormal behaviors are evaluated using different datasets comprising real-world GPS trajectories.},
  archive      = {J_NCA},
  author       = {Al-Molegi, Abdulrahman and Martínez-Ballesté, Antoni},
  doi          = {10.1007/s00521-022-07320-3},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16785-16803},
  shortjournal = {Neural Comput. Appl.},
  title        = {SafeMove: Monitoring seniors with mild cognitive impairments using deep learning and location prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DCNet: Dual-cascade network for single image dehazing.
<em>NCA</em>, <em>34</em>(19), 16771–16783. (<a
href="https://doi.org/10.1007/s00521-022-07319-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image dehazing is a challenging ill-posed problem in the field of computer vision. Existing learning-methods usually use a single convolutional neural network (CNN) model to solve it, which lacks details recovery mechanism and leads to poor performance. In this paper, we propose an end-to-end Dual-cascade Network for image dehazing, which obtains the haze-free image in a coarse-to-fine manner. Specifically, the overall model consists of two sub-networks: Net-U and Net-D. The Net-U employs an encoder–decoder architecture to restore a coarse dehazing result, which leverages residual channel attention block for distilling hierarchical features, and transmits the contextual information into next stage. To preserve the spatial details of latent image, our Net-D adopts a constant-size CNN structure, and captures the texture-rich features by utilizing residual multi-scale spatial block. Moreover, we apply an effective selective fusion module to integrate these derived features from Net-U and Net-D. Experimental comparisons show that our method obtains comparable or even better results than existing state-of-the-art methods in terms of quantitative evaluation and visual performance. The code will be made publicly available on GitHub.},
  archive      = {J_NCA},
  author       = {Yi, Weichao and Dong, Liquan and Liu, Ming and Zhao, Yuejin and Hui, Mei and Kong, Lingqin},
  doi          = {10.1007/s00521-022-07319-w},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16771-16783},
  shortjournal = {Neural Comput. Appl.},
  title        = {DCNet: Dual-cascade network for single image dehazing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uncertainty handling in convolutional neural networks.
<em>NCA</em>, <em>34</em>(19), 16753–16769. (<a
href="https://doi.org/10.1007/s00521-022-07313-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of convolutional neural networks is degraded by noisy data, especially in the test phase. To address this challenge, a new convolutional neural network structure with data indeterminacy handling in the neutrosophic (NS) domain, named as Neutrosophic Convolutional Neural Networks, is proposed for image classification. For this task, images are firstly mapped from the pixel domain to three sets true (T), indeterminacy (I) and false (F) in NS domain by the proposed method. Then, NCNN with two parallel paths, one with the input of T and another with I, is constructed followed by an appropriate combination of paths to generate the final output. Here, two paths are trained simultaneously, and neural network weights are updated using back propagation algorithm. The effectiveness of NCNN to handle noisy data is analyzed mathematically in terms of the weights update rule. Proposed two paths NS idea is applied to two basic models: CNN and VGG-Net to construct NCNN and NVGG-Net, respectively. The proposed method has been evaluated on MNIST, CIFAR-10 and CIFAR-100 datasets contaminated with 20 levels of Gaussian noise. Results show that two-path NCNN outperforms CNN by 5.11\% and 2.21\% in 5 pairs (training, test) with different levels of noise on MNIST and CIFAR-10 datasets, respectively. Finally, NVGG-Net increases the accuracy by 3.09\% and 2.57\% compared to VGG-Net on CIFAR-10 and CIFAR-100 datasets, respectively.},
  archive      = {J_NCA},
  author       = {Rashno, Elyas and Akbari, Ahmad and Nasersharif, Babak},
  doi          = {10.1007/s00521-022-07313-2},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16753-16769},
  shortjournal = {Neural Comput. Appl.},
  title        = {Uncertainty handling in convolutional neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Piecewise graph convolutional network with edge-level
attention for relation extraction. <em>NCA</em>, <em>34</em>(19),
16739–16751. (<a
href="https://doi.org/10.1007/s00521-022-07312-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Network (GCN) is a critical method to capture non-sequential information of sentences and recognize long-distance syntactic information. However, the adjacency matrix of GCN has two problems: redundant syntactic information and wrong dependency parsing results. Because the syntactic information is represented by unweighted adjacency matrices in most existing GCN methods. Toward this end, we propose a novel model, PGCN-EA, using Piecewise Graph Convolutional Network with Edge-level Attention to address these two problems. In specific, we first employ the piecewise adjacency matrix based on entity pair, which aims to dynamically reduce the sentence’s redundant features. Second, we propose Edge-level Attention to assign the different weights among nodes based on GCN’s input and create the weight adjacency matrix, emphasizing the importance of child words with the target word and alleviating the influence of wrong dependency parsing. Our model on a benchmark dataset has carried out extensive experiments and achieved the best PR curve as compared to seven baseline models, which are at least more than $$2.3\%$$ .},
  archive      = {J_NCA},
  author       = {Yuan, Changsen and Huang, Heyan and Feng, Chong and Cao, Qianwen},
  doi          = {10.1007/s00521-022-07312-3},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16739-16751},
  shortjournal = {Neural Comput. Appl.},
  title        = {Piecewise graph convolutional network with edge-level attention for relation extraction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neuro-semantic prediction of user decisions to contribute
content to online social networks. <em>NCA</em>, <em>34</em>(19),
16717–16738. (<a
href="https://doi.org/10.1007/s00521-022-07307-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding at microscopic level the generation of contents in an online social network (OSN) is highly desirable for an improved management of the OSN and the prevention of undesirable phenomena, such as online harassment. Content generation, i.e., the decision to post a contributed content in the OSN, can be modeled by neurophysiological approaches on the basis of unbiased semantic analysis of the contents already published in the OSN. This paper proposes a neuro-semantic model composed of (1) an extended leaky competing accumulator (ELCA) as the neural architecture implementing the user concurrent decision process to generate content in a conversation thread of a virtual community of practice, and (2) a semantic modeling based on the topic analysis carried out by a latent Dirichlet allocation (LDA) of both users and conversation threads. We use the similarity between the user and thread semantic representations to built up the model of the interest of the user in the thread contents as the stimulus to contribute content in the thread. The semantic interest of users in discussion threads are the external inputs for the ELCA, i.e., the external value assigned to each choice.. We demonstrate the approach on a dataset extracted from a real life web forum devoted to fans of tinkering with musical instruments and related devices. The neuro-semantic model achieves high performance predicting the content posting decisions (average F score 0.61) improving greatly over well known machine learning approaches, namely random forest and support vector machines (average F scores 0.19 and 0.21).},
  archive      = {J_NCA},
  author       = {Cleveland, Pablo and Rios, Sebastian A. and Aguilera, Felipe and Graña, Manuel},
  doi          = {10.1007/s00521-022-07307-0},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16717-16738},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neuro-semantic prediction of user decisions to contribute content to online social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MCFL: Multi-label contrastive focal loss for deep imbalanced
pedestrian attribute recognition. <em>NCA</em>, <em>34</em>(19),
16701–16715. (<a
href="https://doi.org/10.1007/s00521-022-07300-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian Attribute Recognition (PAR) can provide valuable clues for several innovative surveillance applications. It is also a difficult task because inference of the multiple attributes at a far distance is challenging in real complex scenarios. Most existing methods improve the PAR with visual attention mechanisms or body-part detection modules, which increase the complexity of networks and require manual annotations of the human body. Also, uneven data distribution, leading to a decline in recall values, is still underestimated. This paper presents a novel multi-label optimization algorithm to mitigate these issues, named Multi-label Contrastive Focal Loss (MCFL). Specifically, we first propose a multi-label focal loss to emphasize the error-prone and minority attributes with a separated re-weighting scheme. And then, we introduce a multi-label contrastive learning strategy based on the multi-label divergences to help the deep network to distinguish the hard fine-grained attributes. We conduct extensive experiments on seven PAR benchmarks, and results indicate that the proposed MCFL with the native ResNet-50 backbone surpasses the state-of-the-art comparison methods in mean accuracy and recall.},
  archive      = {J_NCA},
  author       = {Chen, Lin and Song, Jingkuan and Zhang, Xuerui and Shang, Mingsheng},
  doi          = {10.1007/s00521-022-07300-7},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16701-16715},
  shortjournal = {Neural Comput. Appl.},
  title        = {MCFL: Multi-label contrastive focal loss for deep imbalanced pedestrian attribute recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A promotive structural balance model based on reinforcement
learning for signed social networks. <em>NCA</em>, <em>34</em>(19),
16683–16700. (<a
href="https://doi.org/10.1007/s00521-022-07298-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the structural balance problem in signed social networks, a number of structural balance models have been developed. However, these models neglect the effect of the number of nodes are connected to the changed edges, which is not consistent with the practical requirement of social network systems. For this issue, we propose a novel structural balance model, which jointly takes the minimization of the number of changed edges and the number of nodes connected to the changed edges into account. Then, to optimize the proposed model, we design a novel algorithm based on reinforcement learning, which is a first attempt to use reinforcement learning for structural balance problem. Since nodes in a network don&#39;t need to be identified by specific states when solving structural balance problem, a stateless Q-learning is adopted. Furthermore, a policy improvement operator is incorporated into the stateless Q-learning to enhance its ability in exploring solutions in a complex search space. Experimental results on the six networks show that the proposed algorithm has dominance in terms of optimal solutions, stability, and convergence against the other comparison algorithms.},
  archive      = {J_NCA},
  author       = {Yang, Mingzhou and Wang, Xingwei and Ma, Lianbo and He, Qiang and Huang, Min},
  doi          = {10.1007/s00521-022-07298-y},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16683-16700},
  shortjournal = {Neural Comput. Appl.},
  title        = {A promotive structural balance model based on reinforcement learning for signed social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid classifier based on support vector machine and jaya
algorithm for breast cancer classification. <em>NCA</em>,
<em>34</em>(19), 16669–16681. (<a
href="https://doi.org/10.1007/s00521-022-07290-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The experts’ decisions and evaluating the patients’ data are the most significant parts affecting the breast cancer analysis. For early breast cancer detection, numerous techniques of machine learning not only can assist in examining and diagnosis the medical data quickly but also decrease the potential errors that could be occurred due to inexpert or unskilled decision-makers. Support vector machine is one of the famous classifiers that has already made an important contribution to the field of cancer classification. However, configurations of different kernel function and their parameters can significantly affect the performance of the SVM classifier. To further improve the classification accuracy of the SVM classifier for breast cancer diagnosis, an intelligent cancer classification method is proposed based on selecting a feature subset and optimizing the relevant parameters (i.e., penalty factor parameter ( $$c$$ ) and kernel parameter $$\gamma$$ ) of the SVM classifier concurrently through an intelligent algorithm using the Jaya algorithm. Then, this method (Jaya-SVM) was applied to precisely characterize the breast cancer dataset, including 699 samples, which are 458 and 241 for benign and malignant, respectively. Furthermore, to evaluate the effectiveness of the proposed Jaya-SVM classifier, it is compared in terms of the computational complexity and the classification accuracy with several combinatorial metaheuristic classifiers, namely the genetic algorithm (GA), differential evolution (DE), particle swarm optimization (PSO), and cuckoo search (CS) based-SVM. Apart from this, a Breast Cancer Coimbra Dataset taken from the UCI library is used to validate the effectiveness of the proposed method. The results are presented, explained, and conclusions are drawn.},
  archive      = {J_NCA},
  author       = {Alshutbi, Mohammed and Li, Zhiyong and Alrifaey, Moath and Ahmadipour, Masoud and Othman, Muhammad Murtadha},
  doi          = {10.1007/s00521-022-07290-6},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16669-16681},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid classifier based on support vector machine and jaya algorithm for breast cancer classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Spatial-temporal dynamic semantic graph neural network.
<em>NCA</em>, <em>34</em>(19), 16655–16668. (<a
href="https://doi.org/10.1007/s00521-022-07285-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing methods based on graph neural network for traffic flow forecasting cannot effectively exploit potential semantic features, multiple features are aggregated without refining the proportion of their respective weights, and the over-smoothing problem limits the stacked depth of the model. To solve these problems, spatial-temporal dynamic semantic graph neural network is proposed in this paper. Firstly, two different semantic features have been captured by dynamic time warping algorithm and Pearson correlation coefficient for constructing two semantic adjacency matrices. Secondly, a dynamic aggregation method is proposed that learns the weighting ratio corresponding to each feature through training. Thirdly, the injection-stacked structure is designed to solve the over-smoothing problem and allow the network to be stacked with more layer and improve the forecasting accuracy. Finally, the experiments on four PEMS datasets with various methods such as spatio-temporal graph convolutional networks, attention-based spatial-temporal graph convolutional networks, etc. verify that spatial-temporal dynamic semantic graph neural network obtains minimal forecasting errors by capturing the potential semantic features, dynamically aggregating multiple features, and deepening the network layers by injecting-stacked structure. It achieves that root mean square error is 25.59, mean absolute error is 16.12 and mean absolute percentage error is 16.15 on the PEMS03 dataset.},
  archive      = {J_NCA},
  author       = {Zhang, Rui and Xie, Fei and Sun, Rui and Huang, Lei and Liu, Xixiang and Shi, Jianjun},
  doi          = {10.1007/s00521-022-07285-3},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16655-16668},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatial-temporal dynamic semantic graph neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-scale interest dynamic hierarchical transformer for
sequential recommendation. <em>NCA</em>, <em>34</em>(19), 16643–16654.
(<a href="https://doi.org/10.1007/s00521-022-07281-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing sequential recommendation methods focus on modeling the temporal relationships of users’ historical behaviors and excel in exploiting users’ dynamic interests to improve recommendation performance. However, these methods rarely consider the existence of multi-scale user behavior sequences (e.g., temporal, location, and material scales), and sometimes user multi-scale interests play a decisive role in predicting final user preferences. To investigate the influence of multi-scale interests on user preferences, we study to develop a Multi-scale Interest Dynamic Hierarchical Transformer Model (MIDHT) to fine-grain modeling of users’ interests. Specifically, the proposal includes: First, the neighbor attention mechanism determines whether two neighboring items merge or not. Second, we generate the block mask matrix based on the above judgment results. Third, we compute the implicit representation of the current layer using the dynamic block mask matrix and the self-attention mechanism. Last, the dynamic block mask matrix of all layers to infer the corresponding hierarchical structure. Thorough experiments are implemented to show the features of MIDHT under different component settings. Furthermore, experimental results on three real-world datasets show that MIDHT significantly outperforms the state-of-the-art baselines on different evaluation metrics.},
  archive      = {J_NCA},
  author       = {Huang, Nana and Hu, Ruimin and Xiong, Mingfu and Peng, Xiaoran and Ding, Hongwei and Jia, Xiaodong and Zhang, Lingkun},
  doi          = {10.1007/s00521-022-07281-7},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16643-16654},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-scale interest dynamic hierarchical transformer for sequential recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid teaching–learning slime mould algorithm for global
optimization and reliability-based design optimization problems.
<em>NCA</em>, <em>34</em>(19), 16617–16642. (<a
href="https://doi.org/10.1007/s00521-022-07277-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slime mould algorithm (SMA) is a novel metaheuristic algorithm with good performance for optimization problems, but it may encounter premature or low accuracy in complex optimization problems. This paper presents a hybrid SMA using teaching–learning based optimization (TLBO), called TLSMA, for solving global optimization and reliability-based design optimization (RBDO) problems. The key point of TLSMA is to combine the capacities of exploration and exploitation from SMA and TLBO, which can enhance the convergence ability of SMA. Moreover, the TLSMA is extended for solving RBDO problems under probabilistic constraints, which are handled by the adaptive chaos control method. The proposed algorithm is tested by a series of experiments with two parts. First, TLSMA is verified by 24 well-known benchmark optimization problems with unimodal and multimodal functions, and is compared with several state-of-the-art metaheuristic algorithms. The results of benchmark optimization problems show that TLSMA outperforms PSO, BBO, GWO, WOA, SSA, TLBO and SMA. Then, TLSMA-RBDO is tested by five RBDO problems, including a numerical and four engineering problems. The results illustrate that the proposed algorithm has high performance in the RBDO problems, which is significantly superior to the compared algorithms.},
  archive      = {J_NCA},
  author       = {Zhong, Changting and Li, Gang and Meng, Zeng},
  doi          = {10.1007/s00521-022-07277-3},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16617-16642},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid teaching–learning slime mould algorithm for global optimization and reliability-based design optimization problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Elderly people activity monitoring with involved binary
sensors and deep convolution neural network. <em>NCA</em>,
<em>34</em>(19), 16605–16615. (<a
href="https://doi.org/10.1007/s00521-022-07268-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data reveal that by 2025, the number of elderly population will have surpassed 1.4 billion. The percent of the elderly desire a healthy and private environment. They might be homebound without even any external help or nursing due to the heavy pricing of elderly treatment centres. The activities of the elderly must be continuously monitored in order to detect indications and symptoms of any sickness. Despite the fact that some elderly people live in shelters, their behaviour is heavily controlled by handheld sensors and webcams. In addition, practically all surveillance activities intrude on the privacy of the elderly. As a result, a Deep Convolutional Neural Network (DCNN) model has been proposed as a means of ensuring perfect anonymity while also monitoring activities. This model was built using the Aruba data set. It was created by collecting inputs from numerous binary sensors throughout the test house and predicting the most likely sequence of activities that the monitored individual would carry out in the least period of time possible. The obtained image data are then processed into information and sent into the Deep Convolution Neural Network model that has been recommended as an input. Twelve basic everyday activities are taken into account when analysing the DCNN. Finally, with an F1 score of 0.82, the proposed Deep Convolution Neural Network model outperforms the present model in all twelve activities, as well as all other key assessment parameters.},
  archive      = {J_NCA},
  author       = {Rajesh, P. and Kavitha, R.},
  doi          = {10.1007/s00521-022-07268-4},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16605-16615},
  shortjournal = {Neural Comput. Appl.},
  title        = {Elderly people activity monitoring with involved binary sensors and deep convolution neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Surrogate modeling for spacecraft thermophysical models
using deep learning. <em>NCA</em>, <em>34</em>(19), 16577–16603. (<a
href="https://doi.org/10.1007/s00521-022-07257-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal modeling is a critical technology in spacecraft thermal control systems, where the complex spatially and temporally variable parameters used as inputs to the spacecraft usually result in long operation times, which hinders sensitivity analysis and control strategies. The uniqueness of both the space environment and the working conditions of each spacecraft, make thermal models differ in different space environments; thus, traditional thermal modeling methods that rely heavily on physical knowledge need to build more than one corresponding thermal model, and they also cannot generalize well. Therefore, an intelligent surrogate modeling strategy for spacecraft thermophysical models that uses deep learning, called SMS-DL, is proposed. An intelligent batch processing system for thermal analysis based on NX TMG Thermal Analysis was designed to automate the input of the thermal design parameters and the output of the thermal analysis results through macro-recording and playback using a state-of-the-art biconjugate gradient solver to provide superior speed, reliability, and accuracy, thus achieving a trade-off between high accuracy and low computational cost. One deep neural network based on Bayesian optimization was pre-trained using the thermal analysis data of the spacecraft in the source domain calculated using a batch processing system, which had a computational speed that was 1000+ times faster than that of the traditional thermophysical model and high computational accuracy of 99\%+. Then, it was applied to the target domain with a limited amount of thermal analysis data using model fine-tuning. The theoretical and experimental results from the thermal analysis modeling of the near-ultraviolet radiation detector on the China Space Station Telescope developed in China demonstrated that deep transfer learning effectively adapted the pre-trained model from one working condition to another, improved the prediction accuracy by at least 86.4\% over the direct prediction accuracy using the pre-trained model, and had better predictive performance than learning from scratch with only a limited amount of data.},
  archive      = {J_NCA},
  author       = {Xiong, Yan and Guo, Liang and Zhang, Yang and Xu, Mingxing and Tian, Defu and Li, Ming},
  doi          = {10.1007/s00521-022-07257-7},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16577-16603},
  shortjournal = {Neural Comput. Appl.},
  title        = {Surrogate modeling for spacecraft thermophysical models using deep learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). E-tanh: A novel activation function for image processing
neural network models. <em>NCA</em>, <em>34</em>(19), 16563–16575. (<a
href="https://doi.org/10.1007/s00521-022-07245-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural network (ANN) is one of the technologies used for emerging real-world problems. Activation functions (AF) are used in deep learning architectures to make decisions in the hidden and output layers. An AF influences the dynamics of training and performance of an ANN. This paper proposes a novel AF called E-Tanh by extending the Tanh AF for ANN models. When used in three shallow ANN models with 2, 4, and 6 hidden layers with the Modified National Institute of Standards and Technology database (MNIST), it gave a maximum accuracy of 99.5\% for handwritten digits classification than the results produced by the existing AFs. The proposed AF E-Tanh outperformed other existing and well-known AFs ReLU, Sigmoid, Tanh, Swish, and E-Swish. In deep ANNs with 5–50 hidden layers, the proposed AF’s prediction accuracy of up to 25 hidden layers was higher than the existing AFs on the MNIST database. When used in shallow CNN for the CIFAR10 database, it outperformed other AFs. When used in wide residual network, it performed poorly in classifying images in CIFAR10 and CIFAR100 database but performed competitively with all other AFs in CNN models on the MNIST dataset.},
  archive      = {J_NCA},
  author       = {Kalaiselvi, T. and Padmapriya, S. T. and Somasundaram, K. and Praveenkumar, S.},
  doi          = {10.1007/s00521-022-07245-x},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16563-16575},
  shortjournal = {Neural Comput. Appl.},
  title        = {E-tanh: A novel activation function for image processing neural network models},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A teacher-student framework for liver and tumor segmentation
under mixed supervision from abdominal CT scans. <em>NCA</em>,
<em>34</em>(19), 16547–16561. (<a
href="https://doi.org/10.1007/s00521-022-07240-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver and tumor segmentation from abdominal CT scans and an important step towards computer-assisted diagnosis or treatment planning for various hepatic diseases. Training convolutional neural networks for image segmentation demands a large number of pixel-wise labels which are inefficient to acquire. In order to leverage massive weak annotations, we developed a teacher-student framework using both pixel annotated dataset (strong dataset) and bounding box annotated dataset (weak dataset). A teacher annotator transfers the knowledge from the strong dataset to the weak one by refining its bounding box labels into pseudo pixel-wise labels. Motivated by the spatial layout of organ and tumor, we proposed a hierarchical organ-to-lesion (O2L) attention module to regularize the teacher annotator trained on the strong dataset. A student segmentor is trained with the mix of strong and refined weak datasets. A localization branch in the student network aggregates deep features to predict positions of organ and lesion, improving the segmentation of small objects. A comparative study with state-of-the-art methods demonstrates the proposed method strikes the balance between model performance and annotation efficiency. This model shows robustness to the quality of bounding box annotations. The model is also validated on kidney and tumor segmentation.},
  archive      = {J_NCA},
  author       = {Sun, Liyan and Wu, Jianxiong and Ding, Xinghao and Huang, Yue and Chen, Zhong and Wang, Guisheng and Yu, Yizhou},
  doi          = {10.1007/s00521-022-07240-2},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16547-16561},
  shortjournal = {Neural Comput. Appl.},
  title        = {A teacher-student framework for liver and tumor segmentation under mixed supervision from abdominal CT scans},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Segmentation and classification of breast cancer using novel
deep learning architecture. <em>NCA</em>, <em>34</em>(19), 16533–16545.
(<a href="https://doi.org/10.1007/s00521-022-07230-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the most frequent cancers in women, and it has a higher mortality rate than other cancers. As a result, early detection is critical. In computer-assisted disease diagnosis, accurate segmentation of the region of interest is a vital concept. The segmentation techniques have been widely used by doctors and physicians to locate the pathology, identify the abnormality, compute the tissue volume, analyze the anatomical structures, and provide treatment. Cancer diagnostic efficiency is based on two aspects: The precision value associated with the segmentation and calculation of the tumor area and the accuracy of the features extracted from the images to categorize the benign or malignant tumors. A novel deep-learning architecture for tumor segmentation is therefore proposed in this study, and machine learning algorithms are used to categorize benign or malignant tumors. The segmentation results improve the decision-making capability of the physicians to identify whether a tumor is malignant or not and normally, the machine learning techniques need expert annotation and pathology reports to identify this. This challenge is overcome in this work with the help of the GoogLeNet architecture used for segmentation. The segmentation results are then offered to the Support Vector Mchine, Decision Tree, Random Forest, and Naïve Bayes classifier to improve their efficiency. Our work has provided better results in terms of accuracy, Jaccard and dice coefficient, sensitivity, and specificity compared to conventional architectures. The proposed model offers an accuracy score of 99.12\% which is relatively higher than the other techniques. A 3.78\% accuracy improvement is noticed by the proposed model against the AlexNet classifier and the actual increase is 4.61\% on average when compared to the existing techniques.},
  archive      = {J_NCA},
  author       = {Ramesh, S. and Sasikala, S. and Gomathi, S. and Geetha, V. and Anbumani, V.},
  doi          = {10.1007/s00521-022-07230-4},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16533-16545},
  shortjournal = {Neural Comput. Appl.},
  title        = {Segmentation and classification of breast cancer using novel deep learning architecture},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). CS-RNN: Efficient training of recurrent neural networks
with continuous skips. <em>NCA</em>, <em>34</em>(19), 16515–16532. (<a
href="https://doi.org/10.1007/s00521-022-07227-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks (RNNs) provide powerful tools for sequence problems. However, simple RNN and its variants are prone to high computational cost, for which RNN variants like Skip RNN have been proposed. To further reduce the cost, we introduce a new recurrent network model, continuous skip RNN (CS-RNN), to overcome the limitation of Skip RNN. The model learns to omit relatively continuous elements in a sequence, which are less relevant to the task, allowing it to maintain its inference ability while reducing the training costs significantly. Two hyperparameters are introduced to control the number of skips to balance the efficiency and the accuracy. Six different experiments have been conducted to demonstrate the feasibility and efficiency of the proposed CS-RNN. The model is evaluated by the number of FLOPs, the accuracy, and a new metric proposed for the trade-off between efficiency and accuracy. The results have shown a significant improvement in efficiency by the proposed continuous skips while the performance of RNN has been retained, which is promising for efficient training of RNNs over long sequences.},
  archive      = {J_NCA},
  author       = {Chen, Tianyu and Li, Sheng and Yan, Jun},
  doi          = {10.1007/s00521-022-07227-z},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16515-16532},
  shortjournal = {Neural Comput. Appl.},
  title        = {CS-RNN: Efficient training of recurrent neural networks with continuous skips},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Compression of deep neural networks: Bridging the gap
between conventional-based pruning and evolutionary approach.
<em>NCA</em>, <em>34</em>(19), 16493–16514. (<a
href="https://doi.org/10.1007/s00521-022-07161-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many studies have been carried out on model compression to handle the high computational cost and high memory footprint brought by the implementation of deep neural networks. In this paper, model compression of convolutional neural networks is constructed as a multiobjective optimization problem with two conflicting objectives, reducing the model size and improving the performance. A novel structured pruning method called Conventional-based and Evolutionary Approaches Guided Multiobjective Pruning (CEA-MOP) is proposed to address this problem, where the power of conventional pruning methods is effectively exploited for the evolutionary process. A delicate balance in pruning rate and model accuracy has been automated achieved by a multiobjective optimization evolutionary model. First, an ensemble framework integrates pruning metrics to establish a codebook for further evolutionary operations. Then, an efficient coding method is developed to shorten the length of chromosome, thus ensuring its superior scalability. Finally, sensitivity analysis is automatically carried out to determine the upper bound of pruning rate for each layer. Notably, on CIFAR-10, CEA-MOP reduces more than 50\% FLOPs on ResNet-110 and improves the relative accuracy. Moreover, on ImageNet, CEA-MOP reduces more than 50\% FLOPs on ResNet-101 with negligible top-1 accuracy drop.},
  archive      = {J_NCA},
  author       = {Zhang, Yidan and Wang, Guangjin and Yang, Taibo and Pang, Tianfeng and He, Zhenan and Lv, Jiancheng},
  doi          = {10.1007/s00521-022-07161-0},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16493-16514},
  shortjournal = {Neural Comput. Appl.},
  title        = {Compression of deep neural networks: Bridging the gap between conventional-based pruning and evolutionary approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent fault diagnosis for distribution grid
considering renewable energy intermittency. <em>NCA</em>,
<em>34</em>(19), 16473–16492. (<a
href="https://doi.org/10.1007/s00521-022-07155-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a versatile intelligent fault diagnosis (IFD) scheme for a distribution grid integrated with intermittent renewable energy resources (RER). Renewable generation parameters (wind speed and solar irradiation) and load demand intermittency along with fault information (fault inception angle and resistance) uncertainty are modeled by employing different probability density functions. Then, advanced signal processing techniques are used to extract useful features from the recorded signals. The proposed approach sends the extracted features as inputs to feedforward neural networks (FF-NNs) to diagnose (detect, classify, and identify faulty sections) and locate the faults. The presented results confirm the efficacy of the developed IFD scheme and show that it is independent of renewable generation and load demand intermittency along with fault information uncertainty. Additionally, the proposed scheme is independent of the presence of measurement noises. Furthermore, this work investigates the effectiveness of the developed IFD scheme under various contingency cases (branch outages and RER generation outages). Finally, a laboratory prototype IFD scheme is built by integrating a physical phasor measurement unit (PMU) with a real-time digital simulator (RTDS) rack to diagnose faults in the distribution grid. The results confirm the effectiveness of the prototype IFD scheme, as they show good agreement with the simulation results.},
  archive      = {J_NCA},
  author       = {Shafiullah, Md and Abido, M. A. and Al-Mohammed, A. H.},
  doi          = {10.1007/s00521-022-07155-y},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16473-16492},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intelligent fault diagnosis for distribution grid considering renewable energy intermittency},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed algorithm for mixed equilibrium problems with
event-triggered strategy. <em>NCA</em>, <em>34</em>(19), 16463–16472.
(<a href="https://doi.org/10.1007/s00521-022-07115-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new iterative method based on the event-triggered strategy for finding a solution to a mixed equilibrium problem (MEP) is introduced in this paper. The target of the MEP is to find a point in a closed convex set, guaranteeing that the sum of bifunctions about this point is non-negative. To decrease the cost of communication, the MEP is investigated with an event-triggered protocol. Furthermore, it is the first attempt to combine the MEP with an event-triggered strategy. Although there exist difficulties caused by the asymmetry of the network structure associated with directed graphs, nonlinearity and strong coupling of the MEP, the novel algorithm for directed graphs, two event-triggered conditions and the range of the solution associated with the MEP are obtained to handle these challenges. Under the directed time-varying graph, the designed algorithm can converge to a solution to the MEP and reach average consensus. Finally, a numerical example is presented to illustrate the effectiveness of the above algorithm.},
  archive      = {J_NCA},
  author       = {Zhou, Hongtao and Xia, Liang and Su, Housheng},
  doi          = {10.1007/s00521-022-07115-6},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16463-16472},
  shortjournal = {Neural Comput. Appl.},
  title        = {Distributed algorithm for mixed equilibrium problems with event-triggered strategy},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on the human heat transfer model of chinese pilots
and experimental verification of model correctness. <em>NCA</em>,
<em>34</em>(19), 16441–16461. (<a
href="https://doi.org/10.1007/s00521-020-05293-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A three-dimensional human heat transfer model has been improved based on Chinese pilots’ anthropometric data. The temperature distribution of pilots can be simulated by this model. The improved model to simulate the variation of temperature distribution over time in pilots is adopted. To verify the model, an experimental study on temperature distribution of human body is carried out in this paper. The human heat transfer model built in the paper considering heat production from food and blood resistance can simulate the temperature distribution of Chinese pilots.},
  archive      = {J_NCA},
  author       = {Dang, Sina and Xue, Hongjun and Zhang, Xiaoyan and Zhong, Chengwen and Tao, Caiyong},
  doi          = {10.1007/s00521-020-05293-9},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16441-16461},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on the human heat transfer model of chinese pilots and experimental verification of model correctness},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monocular depth map estimation based on a multi-scale deep
architecture and curvilinear saliency feature boosting. <em>NCA</em>,
<em>34</em>(19), 16423–16440. (<a
href="https://doi.org/10.1007/s00521-022-07663-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating depth from a monocular camera is a must for many applications, including scene understanding and reconstruction, robot vision, and self-driving cars. However, generating depth maps from single RGB images is still a challenge as object shapes are to be inferred from intensity images strongly affected by viewpoint changes, texture content and light conditions. Therefore, most current solutions produce blurry approximations of low-resolution depth maps. We propose a novel depth map estimation technique based on an autoencoder network. This network is endowed with a multi-scale architecture and a multi-level depth estimator that preserve high-level information extracted from coarse feature maps as well as detailed local information present in fine feature maps. Curvilinear saliency, which is related to curvature estimation, is exploited as a loss function to boost the depth accuracy at object boundaries and raise the performance of the estimated high-resolution depth maps. We evaluate our model on the public NYU Depth v2 and Make3D datasets. The proposed model yields superior performance on both datasets compared to the state-of-the-art, achieving an accuracy of $$~86\%$$ and showing exceptional performance at the preservation of object boundaries and small 3D structures. The code of the proposed model is publicly available at https://github.com/SaddamAbdulrhman/MDACSFB .},
  archive      = {J_NCA},
  author       = {Abdulwahab, Saddam and Rashwan, Hatem A. and Garcia, Miguel Angel and Masoumian, Armin and Puig, Domenec},
  doi          = {10.1007/s00521-022-07663-x},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16423-16440},
  shortjournal = {Neural Comput. Appl.},
  title        = {Monocular depth map estimation based on a multi-scale deep architecture and curvilinear saliency feature boosting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent advances of bat-inspired algorithm, its versions and
applications. <em>NCA</em>, <em>34</em>(19), 16387–16422. (<a
href="https://doi.org/10.1007/s00521-022-07662-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bat-inspired algorithm (BA) is a robust swarm intelligence algorithm that finds success in many problem domains. The ecosystem of bat animals inspires the main idea of BA. This review paper scanned and analysed the state-of-the-art researches investigated using BA from 2017 to 2021. BA has very impressive characteristics such as its easy-to-use, simple in concepts, flexible and adaptable, consistent, and sound and complete. It has strong operators that incorporate the natural selection principle through survival-of-the-fittest rule within the intensification step attracted by local-best solution. Initially, the growth of the recent solid works published in Scopus indexed articles is summarized in terms of the number of BA-based Journal articles published per year, citations, top authors, work with BA, top institutions, and top countries. After that, the different versions of BA are highlighted to be in line with the complex nature of optimization problems such as binary, modified, hybridized, and multiobjective BA. The successful applications of BA are reviewed and summarized, such as electrical and power system, wireless and network system, environment and materials engineering, classification and clustering, structural and mechanical engineering, feature selection, image and signal processing, robotics, medical and healthcare, scheduling domain, and many others. The critical analysis of the limitations and shortcomings of BA is also mentioned. The open-source codes of BA code are given to build a wealthy BA review. Finally, the BA review is concluded, and the possible future directions for upcoming developments are suggested such as utilizing BA to serve in dynamic, robust, multiobjective, large-scaled optimization as well as improve BA performance by utilizing structure population, tuning parameters, memetic strategy, and selection mechanisms. The reader of this review will determine the best domains and applications used by BA and can justify their BA-related contributions.},
  archive      = {J_NCA},
  author       = {Alyasseri, Zaid Abdi Alkareem and Alomari, Osama Ahmad and Al-Betar, Mohammed Azmi and Makhadmeh, Sharif Naser and Doush, Iyad Abu and Awadallah, Mohammed A. and Abasi, Ammar Kamal and Elnagar, Ashraf},
  doi          = {10.1007/s00521-022-07662-y},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16387-16422},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recent advances of bat-inspired algorithm, its versions and applications},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward automatic support for leading court debates: A novel
task proposal &amp; effective approach of judicial question generation.
<em>NCA</em>, <em>34</em>(19), 16367–16385. (<a
href="https://doi.org/10.1007/s00521-022-07588-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Court debate, with multiple parties (e.g., judge, plaintiff, defendant), is an essential component in a civil trial where the judge leads the conversation and the litigants respond in turn following the judge’s question. Unlike other types of dialogues, the judge’s leading role can be critical with respect to the goal of case investigation, and it is non-trivial to examine the case logic considering also the need for specialized domain knowledge. Judge question generation in court debate is a novel but significant task to assist/train the junior judges to raise effective questions in a legal context as well as help the litigants prepare a court debate in advance. We propose an innovative end-to-end model called ’Judicial Questioning Aid’ which is capable of proactively leading the court debate by asking useful questions to a certain litigant given previous context. Unlike prior efforts in Natural Language Generation (NLG), the proposed model encodes the contextual utterance information with respect to global legal knowledge and local case judicial factors, as well as simulates the intention switch across different conversation turns. Extensive experiments based on a large civil trial dataset show that the proposed model can generate more accurate and readable questions against several alternatives in the multi-party court debate scene.},
  archive      = {J_NCA},
  author       = {Ji, Changzhen and Zhang, Yating and Liu, Xiaozhong and Jatowt, Adam and Bhowmick, Sourav S. and Sun, Changlong and Zhu, Conghui and Zhao, Tiejun},
  doi          = {10.1007/s00521-022-07588-5},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16367-16385},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward automatic support for leading court debates: A novel task proposal &amp; effective approach of judicial question generation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Model predictive control for trajectory-tracking and
formation of wheeled mobile robots. <em>NCA</em>, <em>34</em>(19),
16351–16365. (<a
href="https://doi.org/10.1007/s00521-022-07195-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model predictive control (MPC) naturally guarantees optimal transient process and constraints satisfaction. Most mature MPC theories concern with linear time-invariant systems, it is not trivial to develop MPC for time-varying or nonlinear systems. A linear time-varying model predictive control strategy is proposed in this paper for single-wheeled mobile robot trajectory tracking subject to the non-holonomic constraint and control constraints. The kinematic equation of the robot is converted into a linear time-varying form after linearizing and discretizing, the time-varying MPC is capable to be applied in consequence. The proposed trajectory tracking task is extended to the formation control among multiple robots solved by means of nonlinear model predictive control directly. The extended formation MPC is in the leader-following framework. Recursive feasibility and stability are proved for the closed-loop system.},
  archive      = {J_NCA},
  author       = {Wei, Juntao and Zhu, Bing},
  doi          = {10.1007/s00521-022-07195-4},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16351-16365},
  shortjournal = {Neural Comput. Appl.},
  title        = {Model predictive control for trajectory-tracking and formation of wheeled mobile robots},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Denoising of piecewise constant signal based on total
variation. <em>NCA</em>, <em>34</em>(19), 16341–16349. (<a
href="https://doi.org/10.1007/s00521-022-06937-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Total variation denoising (TVD) algorithm is suitable for the restoration of piecewise constant signals (PCS). The amplitude accuracy of discontinuities affects the overall denoising effect. Improving the amplitude accuracy of discontinuities is the difficulty of PCS denoising. Recent papers have presented TVD-based algorithms to improve the denoising precision. After applying the forward–backward splitting (FBS) method, the iteration of the denoising is comprised by the traditional TVD. This paper proposes a new upper bound function to enhance the accuracy of the traditional TVD method. Then, the enhanced TVD is used to update the TVD-based algorithm to improve the denoising efficiency. The experimental results demonstrate that the proposed method has superior performance compared to other methods in PCS denoising.},
  archive      = {J_NCA},
  author       = {Lv, Donghao and Cao, Weihua and Hu, Wenkai and Gan, Chao and Wu, Min},
  doi          = {10.1007/s00521-022-06937-8},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16341-16349},
  shortjournal = {Neural Comput. Appl.},
  title        = {Denoising of piecewise constant signal based on total variation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gene-CWGAN: A data enhancement method for gene expression
profile based on improved CWGAN-GP. <em>NCA</em>, <em>34</em>(19),
16325–16339. (<a
href="https://doi.org/10.1007/s00521-022-07417-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional machine learning methods are difficult to obtain good performance in the classification of gene expression data due to its characteristics of high dimension and small sample size. As a data enhancement technology, conditional Wasserstein generative adversarial network based on gradient punishment (CWGAN-GP) has strong universality and can generate high-quality samples of specified labels, which has been proved to improve the performance of classification models. However, the samples generated by CWGAN-GP have low sample diversity and distribution uncertainty on gene expression data, which may decrease the classification accuracy of classifiers. Therefore, a data enhancement method for gene expression data based on CWGAN-GP (Gene-CWGAN) is proposed in this study. First, to stabilize the distribution of generated samples, a dataset partition method based on sample dispersion is adopted in Gene-CWGAN to make the distribution of training samples as close as possible to the real sample distribution. Subsequently, the space of the generated samples is redefined and a constraint penalty term is adopted to eliminate the restriction of the originally generated space. Finally, in order to overcome the problem of network volatility on the quality of generated samples, a Gene-CWGAN based on a proxy model (Gene-CWGAN-PS) is proposed to ensure the sample quality. Experimental results on five public gene expression data verify that the Gene-CWGAN outperforms other involved methods in terms of diversity, distribution stability, and quality of generated samples.},
  archive      = {J_NCA},
  author       = {Han, Fei and Zhu, Shaojun and Ling, Qinghua and Han, Henry and Li, Hailong and Guo, Xinli and Cao, Jiechuan},
  doi          = {10.1007/s00521-022-07417-9},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16325-16339},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gene-CWGAN: A data enhancement method for gene expression profile based on improved CWGAN-GP},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast medical concept normalization for biomedical literature
based on stack and index optimized self-attention. <em>NCA</em>,
<em>34</em>(19), 16311–16324. (<a
href="https://doi.org/10.1007/s00521-022-07228-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical concept normalization aims to construct a semantic mapping between mentions and concepts and to uniformly represent mentions that belong to the same concept. In the large-scale biological literature database, a fast concept normalization method is essential to process a large number of requests and literature. To this end, we propose a hierarchical concept normalization method, named FastMCN, with much lower computational cost and a variant of transformer encoder, named stack and index optimized self-attention (SISA), to improve the efficiency and performance. In training, FastMCN uses SISA as a word encoder to encode word representations from character sequences and uses a mention encoder which summarizes the word representations to represent a mention. In inference, FastMCN indexes and summarizes word representations to represent a query mention and output the concept of the mention which with the maximum cosine similarity. To further improve the performance, SISA was pre-trained using the continuous bag-of-words architecture with 18.6 million PubMed abstracts. All experiments were evaluated on two publicly available datasets: NCBI disease and BC5CDR disease. The results showed that SISA was three times faster than the transform encoder for encoding word representations and had better performance. Benefiting from SISA, FastMCN was efficient in both training and inference, i.e. it achieved the peak performance of most of the baseline methods within 30 s and was 3000–5600 times faster than the state-of-the-art method in inference.},
  archive      = {J_NCA},
  author       = {Liang, Likeng and Hao, Tianyong and Zhan, Choujun and Qiu, Hong and Wang, Fu Lee and Yan, Jun and Weng, Heng and Qu, Yingying},
  doi          = {10.1007/s00521-022-07228-y},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16311-16324},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fast medical concept normalization for biomedical literature based on stack and index optimized self-attention},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fitting multiple temporal usage patterns in day-ahead hourly
building load forecasting under patch learning framework. <em>NCA</em>,
<em>34</em>(19), 16291–16309. (<a
href="https://doi.org/10.1007/s00521-022-07152-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel day-ahead hourly building load forecasting approach under the framework of patch learning, a recently proposed data-driven model that aggregates a global model and several patch models to further reduce forecasting errors. A patch learning model based on the long short-term memory network is hereby employed to address such a time-series-based forecasting problem, where the long short-term memory network is considered as the global model and the support vector regression is selected as the patch model. To obtain satisfying performance, the largest absolute error measurement is selected to evaluate load forecasting errors and identify patch locations. Furthermore, a genetic algorithm with an elitist preservation strategy and the grid search method are employed for hyperparameter tuning of the global model and patch models, respectively. The performance of the proposed model is tested and verified on two practical building load data sets and the Lorenz chaotic time-series data and compared with four advanced building load forecasting models on several common metrics.},
  archive      = {J_NCA},
  author       = {Dan, Zhaohui and Wang, Bo and Zhang, Qian and Wu, Zhou and Fan, Huijin and Liu, Lei and Sun, Muxia},
  doi          = {10.1007/s00521-022-07152-1},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16291-16309},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fitting multiple temporal usage patterns in day-ahead hourly building load forecasting under patch learning framework},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep reinforcement learning for urban multi-taxis cruising
strategy. <em>NCA</em>, <em>34</em>(19), 16275–16289. (<a
href="https://doi.org/10.1007/s00521-022-07255-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taxis play an important role in urban transportation system. Efficient taxi cruising strategies are helpful to alleviate urban traffic congestions, reduce pollution emission, attenuate greenhouse gas, and also provide a fast service for passengers. However, in real scenarios, taxis cruising strategies are mostly based on their own experiences. At unfamiliar urban areas or during off-peak hours, drivers usually have no good idea for an optimal cruising strategy, which causes a low efficiency for service and also increases taxi operation costs. Considering that it is difficult to construct an analytical model for the taxis scheduling and cruising, in this paper, we put forward a data-driven model for multi-taxis cruising based on reinforcement learning. Furthermore, an evolutionary reinforcement learning method is proposed, which aims at improving the exploration of reinforcement learning and enhancing reinforcement learning to maximize the global reward in multi-agent tasks. In the experimental part, two other kinds of deep Q-learning methods and a roaming strategy are employed in the comparisons. The results demonstrate the superiority of our proposed algorithm.},
  archive      = {J_NCA},
  author       = {Guo, Weian and Hua, Zhenyao and Kang, Zecheng and Li, Dongyang and Wang, Lei and Wu, Qidi and Lerch, Alexander},
  doi          = {10.1007/s00521-022-07255-9},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16275-16289},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep reinforcement learning for urban multi-taxis cruising strategy},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Empirical study on meta-feature characterization for
multi-objective optimization problems. <em>NCA</em>, <em>34</em>(19),
16255–16273. (<a
href="https://doi.org/10.1007/s00521-022-07302-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algorithm recommendation based on meta-learning was studied previously. The research on the meta-features extraction, which is a key for the success of recommendation, is lacking for multi-objective optimization problems (MOPs). This paper proposes four sets of meta-features to characterize MOPs. In addition, the algorithm recommendation model based on meta-learning is extended to the field of multi-objective optimization. To evaluate the efficiency and effectiveness of the extracted meta-features, 29 MOPs benchmark functions with different dimensions and two real-world MOPs are employed for comprehensive comparison. Experimental results show that the proposed meta-features in this paper can fully characterize MOPs and are empirically efficient for algorithm recommendation.},
  archive      = {J_NCA},
  author       = {Chu, Xianghua and Wang, Jiayun and Li, Shuxiang and Chai, Yujuan and Guo, Yuqiu},
  doi          = {10.1007/s00521-022-07302-5},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16255-16273},
  shortjournal = {Neural Comput. Appl.},
  title        = {Empirical study on meta-feature characterization for multi-objective optimization problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial bee colony algorithm with an adaptive search
manner and dimension perturbation. <em>NCA</em>, <em>34</em>(19),
16239–16253. (<a
href="https://doi.org/10.1007/s00521-022-06981-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial bee colony (ABC) can effectively solve some complex optimization problems. However, its convergence speed is slow and the exploitation capacity is insufficient at the last search stage. In order to tackle these issues, this paper proposes a modified ABC with an adaptive search manner and dimension perturbation (called ASDABC). There are two important search manners: exploration and exploitation. A suitable search manner is beneficial for the search. An explorative search strategy and another exploitative search strategy are selected to build a strategy pool. To adaptively choose an appropriate search manner, an evaluating indicator is designed to relate the current search status. According to the evaluating indicator, an adaptive method is used to determine which kind of search manner is suitable for the current search. Additionally, a dynamic dimension perturbation strategy is used to enhance the exploration and exploration ability. To verify the performance of ASDABC, 50 problems are tested including 22 classical functions and 28 complex functions. Experiment result shows that ASDABC achieves competitive performance when contrasted with seven different ABC variants.},
  archive      = {J_NCA},
  author       = {Ye, Tingyu and Wang, Hui and Wang, Wengjun and Zeng, Tao and Zhang, Luqi and Huang, Zhikai},
  doi          = {10.1007/s00521-022-06981-4},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16239-16253},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial bee colony algorithm with an adaptive search manner and dimension perturbation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Superpixels with contour adherence via label expansion for
image decomposition. <em>NCA</em>, <em>34</em>(19), 16223–16237. (<a
href="https://doi.org/10.1007/s00521-022-07315-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Superpixels could effectively decompose an image into perceptually meaningful partitions, thus facilitating various high-level computer vision tasks. As a pre-processing tool to speed up the subsequent steps, superpixel generation is expected to be outstanding in decomposition quality and computational efficiency. In this work, we introduce the contour prior into a non-iterative clustering framework and then put forward a package of optimizations. First, contour existence between two pixels on the image plane is utilized as a scaling factor to magnify their joint color and spatial similarity. Then the inter-pixel correlation and the boundaries between different objects can be precisely described. In addition, we conduct an early assignment strategy on the conventional non-iterative clustering structure based on the smooth assumption, leading to efficient label expansion during updating and assignment. Moreover, we adopt a contour-tuned redistribution strategy to generate content-aware superpixels with the exact amount to substitute the grid sampling. Finally, these optimizations could form a synergistic framework to generate higher-quality superpixels. Extensive experiments confirm that the proposed method outperforms the baselines and achieves comparable results with state-of-the-art superpixel algorithms for several quantitative metrics.},
  archive      = {J_NCA},
  author       = {Li, Cheng and He, Wangpeng and Liao, Nannan and Gong, Jianglei and Hou, Shuwei and Guo, Baolong},
  doi          = {10.1007/s00521-022-07315-0},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16223-16237},
  shortjournal = {Neural Comput. Appl.},
  title        = {Superpixels with contour adherence via label expansion for image decomposition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Scalable multi-view clustering with graph filtering.
<em>NCA</em>, <em>34</em>(19), 16213–16221. (<a
href="https://doi.org/10.1007/s00521-022-07326-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of multi-source data, multi-view clustering has attracted great attention in recent years. Most existing multi-view methods operate in raw feature space and heavily depend on the quality of original feature representation. Moreover, they are often designed for feature data and ignore the rich topology structure information. Accordingly, in this paper, we propose a generic framework to cluster both attribute and graph data with heterogeneous features. It is capable of exploring the interplay between feature and structure. Specifically, we first adopt graph filtering technique to eliminate high-frequency noise to achieve a clustering-friendly smooth representation. To handle the scalability challenge, we develop a novel sampling strategy to improve the quality of anchors. Extensive experiments on attribute and graph benchmarks demonstrate the superiority of our approach with respect to state-of-the-art approaches.},
  archive      = {J_NCA},
  author       = {Liu, Liang and Chen, Peng and Luo, Guangchun and Kang, Zhao and Luo, Yonggang and Han, Sanchu},
  doi          = {10.1007/s00521-022-07326-x},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16213-16221},
  shortjournal = {Neural Comput. Appl.},
  title        = {Scalable multi-view clustering with graph filtering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy rule-based models via space partition and information
granulation. <em>NCA</em>, <em>34</em>(19), 16199–16211. (<a
href="https://doi.org/10.1007/s00521-022-06974-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy rule-based model (FRBM) has attracted significant attention in various fields due to its accuracy and high level of interpretability. In this study, two granular Takagi–Sugeno (T–S) FRBMs are designed by employing fuzzy space partition and the principle of allocation of information granularity. The designed models considering different abstraction levels concentrate on the balance of interpretability and accuracy and reflect the rational granularity of rules’ output. According to the layered partition results, the granular T–S FRBMs are generated under two different granularity allocation strategies: uniformly and non-uniformly allocation of information granularity to the T–S FRBM’s parameters. Meanwhile, a unified index incorporating the principle of justifiable granularity is introduced for serving as examining the performance of the granular T–S FRBM and judging whether the obtained partitions need to be further divided in the next layer. The designed models with different types of allocating information granularity are compared with state-of-the-art granular rule modeling way on synthetic datasets and publicly available datasets to illustrate the study’s effectiveness. Under the same information granularity allocation strategy, the designed models in this study can achieve prediction intervals with sound robustness and granular performance. As an application example, a real-world dataset is analyzed to exhibit the potential practicality of the designed models.},
  archive      = {J_NCA},
  author       = {Pang, Yunhui and Wang, Lidong and Liu, Yifei and Guo, Jiayi},
  doi          = {10.1007/s00521-022-06974-3},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16199-16211},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fuzzy rule-based models via space partition and information granulation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sparse discriminant twin support vector machine for binary
classification. <em>NCA</em>, <em>34</em>(19), 16173–16198. (<a
href="https://doi.org/10.1007/s00521-022-07001-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a binary classification problem, twin support vector machine (TSVM) has a faster learning speed than support vector machine (SVM) by seeking a pair of nonparallel hyperplanes. However, TSVM has two deficiencies: poor discriminant ability and poor sparsity. To relieve them, we propose a novel sparse discriminant twin support vector machine (SD-TSVM). Inspired by the idea of the Fisher criterion, maximizing the between-class scatter and minimizing the within-class scatter, SD-TSVM introduces twin Fisher regularization terms, which may improve the discriminant ability of SD-TSVM. Moreover, SD-TSVM has a good sparsity by utilizing both the 1-norm of model coefficients and the hinge loss. Thus, SD-TSVM can efficiently perform data reduction. Classification results on nine real-world datasets show that SD-TSVM has a satisfactory performance compared with related methods.},
  archive      = {J_NCA},
  author       = {Zheng, Xiaohan and Zhang, Li and Yan, Leilei},
  doi          = {10.1007/s00521-022-07001-1},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16173-16198},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sparse discriminant twin support vector machine for binary classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on neural computing and applications 2021.
<em>NCA</em>, <em>34</em>(19), 16169–16171. (<a
href="https://doi.org/10.1007/s00521-022-07732-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Liu, Kai and Cao, Jingjing and Yang, Yimin and Yap, Wun-She and Tan, Rui and Wang, Zenghui},
  doi          = {10.1007/s00521-022-07732-1},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {16169-16171},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on neural computing and applications 2021},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A physics-informed dynamic deep autoencoder for accurate
state-of-health prediction of lithium-ion battery. <em>NCA</em>,
<em>34</em>(18), 15997–16017. (<a
href="https://doi.org/10.1007/s00521-022-07291-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lithium-ion batteries (LIBs) are currently the standard for energy storage in portable consumer electronic devices. They are also used in electric vehicles and in some large industrial settings and for grid power storage. The adverse consequences of a dramatic battery failure can be significant compared with the cost of timely replacement or maintenance. Consequently, accurate state-of-health (SOH) prediction is important to inform maintenance or replacement decisions. In this work, we address current challenges related to accuracy and interpretability in data-driven SOH prediction for LIBs by devising a novel physics-informed machine learning prognostic model, termed PIDDA. PIDDA includes three elements: an autoencoder, a physics-informed model training, and a physics-based prediction adjustment. We examine and benchmark our model against alternative data-driven SOH prediction models using the NASA battery prognostic dataset. The computational experiments demonstrate that PIDDA (1) provides significantly higher prediction accuracy; (2) requires less prior data for its predictions; (3) produces more informative and interpretable predictions than alternative models. We conclude with an ablation study of PIDDA to analyze the relative effectiveness of two of its elements, the physics equations in the model training and the physics-based prediction adjustment. The results show that the former (training) provides the heavy lifting in accuracy improvement, roughly two-thirds, and the latter (adjustment) the remaining incremental improvement.},
  archive      = {J_NCA},
  author       = {Xu, Zhaoyi and Guo, Yanjie and Saleh, Joseph Homer},
  doi          = {10.1007/s00521-022-07291-5},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15997-16017},
  shortjournal = {Neural Comput. Appl.},
  title        = {A physics-informed dynamic deep autoencoder for accurate state-of-health prediction of lithium-ion battery},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced decision making in multi-scenarios for autonomous
vehicles using alternative bidirectional q network. <em>NCA</em>,
<em>34</em>(18), 15981–15996. (<a
href="https://doi.org/10.1007/s00521-022-07278-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To further enhance decision making in autonomous vehicles field, grant more safety, comfort, reduce traffic, and accidents, learning approaches were adopted, mainly reinforcement learning. However, possibility in upgrading these algorithms is still available due to many limitations including : convergence rate, stability, handling multiple dynamic environments, raw performance, robustness, and complexity of algorithms. To tackle these problems, we propose a novel extension of the well-known deep Q network called “alternative bidirectional Q network” that aims mainly to enhance stability and performance with improving exploration and Q values update policies, to overcome the literature gap that generally focuses on only one policy to handle decision making in multiple scenarios (avoiding obstacles, goal-oriented environments, etc.). In “alternative bidirectional Q network,” data about previous, current, and upcoming states are used to update the Q values where the actions are selected according to the relation between these data to handle several scenarios: highways, merges, roundabouts, and parking. This concept provides reinforcement learning agents with more balance between exploration and exploitation and enhances stability during learning. A gym simulator was adopted for training and testing the proposed algorithm’s outcome, while various state-of-the-art algorithms were used as benchmark models. The performance of the proposed extension was evaluated using several metrics being: loss, accuracy, speed, and reward values, where the results of comparison showed the superiority of the novel extension in all scenarios for most of the exploited metrics. The experiment results were confirmed using the complexity and the robustness aspects.},
  archive      = {J_NCA},
  author       = {Rais, Mohamed Saber and Zouaidia, Khouloud and Boudour, Rachid},
  doi          = {10.1007/s00521-022-07278-2},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15981-15996},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced decision making in multi-scenarios for autonomous vehicles using alternative bidirectional q network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ordinal regression with representative feature strengthening
for face anti-spoofing. <em>NCA</em>, <em>34</em>(18), 15963–15979. (<a
href="https://doi.org/10.1007/s00521-022-07272-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face anti-spoofing is a crucial link to ensure the security of face recognition. This paper proposes a novel face anti-spoofing method, which performs ordinal regression with representative feature strengthening to learn generalized and discriminative representation for the live and spoof face classification. Specifically, we propose a semantic label schema, which encodes the inter-class ordinal relationships among live and various spoof faces into supervision information to supervise deep neural networks to perform ordinal regression. It enables the learned model to finely constrain the relative distances among features of different categories in the feature space according to the ordinal relationships. The representative feature strengthening network is designed to strengthen important features and meanwhile weaken redundant features for the classification decision. It leverages a dual-task architecture that takes the same single image as input and shares representations via feature fusing blocks. The network first fuses hierarchical paired convolutional features of two streams to learn the common concern of the two related tasks and then, aggregates the learned local convolutional features into a global representation by a learnable feature weighting block. The network is trained to minimize the Kullback–Leibler divergence loss in an end-to-end manner supervised by the semantic labels. Extensive intra-dataset and cross-dataset experiments demonstrate that the proposed method outperforms the state-of-the-art approaches on four widely used face anti-spoofing datasets.},
  archive      = {J_NCA},
  author       = {Jiang, Fangling and Liu, Pengcheng and Zhou, Xiang-Dong},
  doi          = {10.1007/s00521-022-07272-8},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15963-15979},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ordinal regression with representative feature strengthening for face anti-spoofing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneous graph convolutional network pre-training as
side information for improving recommendation. <em>NCA</em>,
<em>34</em>(18), 15945–15961. (<a
href="https://doi.org/10.1007/s00521-022-07251-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the recommendation domain, most of the existing integrated graph neural network (GNN)-based architectures have still much focused on encoding the associated extra side information in forms of heterogeneous information network (HIN). Then, it is simultaneously utilized in multiple fine-tuning processes to effectively learn preferences from user–item interaction data which might require tremendous computational efforts. In addition, these approaches have also failed to incorporate with previous learnt and transferable knowledge from pre-trained models to better fine-tune for recommendation task. To meet these challenges, in this paper we propose a novel heterogeneous graph neural architecture, named: PreHIN4Rec. The proposed PreHIN4Rec is considered as the graph pre-training approach for leveraging the performance of recommendation task in both accuracy and scalability aspects. In general, our proposed PreHIN4Rec is designed to efficiently preserve both heterogeneous schematic and local structural latent features of user–item interactions in forms of HINs. It can effectively support to better fine-tune for achieving remarkable improvements in recommendation tasks through integrating with existing recommendation frameworks. The extensive experiments in benchmark datasets demonstrate the effectiveness of our proposed PreHIN4Rec model in comparing with recent state-of-the-art GNN-based recommendation baselines.},
  archive      = {J_NCA},
  author       = {Do, Phuc and Pham, Phu},
  doi          = {10.1007/s00521-022-07251-z},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15945-15961},
  shortjournal = {Neural Comput. Appl.},
  title        = {Heterogeneous graph convolutional network pre-training as side information for improving recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-variate heart disease optimization and recognition
framework. <em>NCA</em>, <em>34</em>(18), 15907–15944. (<a
href="https://doi.org/10.1007/s00521-022-07241-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases (CVD) are the most widely spread diseases all over the world among the common chronic diseases. CVD represents one of the main causes of morbidity and mortality. Therefore, it is vital to accurately detect the existence of heart diseases to help to save the patient life and prescribe a suitable treatment. The current evolution in artificial intelligence plays an important role in helping physicians diagnose different diseases. In the present work, a hybrid framework for the detection of heart diseases using medical voice records is suggested. A framework that consists of four layers, namely “Segmentation” Layer, “Features Extraction” Layer, “Learning and Optimization” Layer, and “Export and Statistics” Layer is proposed. In the first layer, a novel segmentation technique based on the segmentation of variable durations and directions (i.e., forward and backward) is suggested. Using the proposed technique, 11 datasets with 14,416 numerical features are generated. The second layer is responsible for feature extraction. Numerical and graphical features are extracted from the resulting datasets. In the third layer, numerical features are passed to 5 different Machine Learning (ML) algorithms, while graphical features are passed to 8 different Convolutional Neural Networks (CNN) with transfer learning to select the most suitable configurations. Grid Search and Aquila Optimizer (AO) are used to optimize the hyperparameters of ML and CNN configurations, respectively. In the last layer, the output of the proposed hybrid framework is validated using different performance metrics. The best-reported metrics are (1) 100\% accuracy using ML algorithms including Extra Tree Classifier (ETC) and Random Forest Classifier (RFC) and (2) 99.17\% accuracy using CNN.},
  archive      = {J_NCA},
  author       = {Balaha, Hossam Magdy and Shaban, Ahmed Osama and El-Gendy, Eman M. and Saafan, Mahmoud M.},
  doi          = {10.1007/s00521-022-07241-1},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15907-15944},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-variate heart disease optimization and recognition framework},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New loss functions to improve deep learning estimation of
heat transfer. <em>NCA</em>, <em>34</em>(18), 15889–15906. (<a
href="https://doi.org/10.1007/s00521-022-07233-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are promising alternatives to simulate physical problems. These networks are capable of eliminating the requirement of numerical iterations. The DNNs could learn the governing physics of engineering problems through a learning process. The structure of deep networks and parameters of the training process are two basic factors that influence the simulation accuracy of DNNs. The loss function is the main part of the training process that determines the goal of training. During the training process, lost function regularly is used to adapt parameters of the deep network. The subject of using DNNs to learn the physical images is a novel topic and demands novel loss functions to capture the physical meanings. Thus, for the first time, the present study aims to develop new loss functions to enhance the training process of DNNs. Here, three novel loss functions were introduced and examined to estimate the temperature distributions in thermal conduction problems. The images of temperature distribution obtained in the present research were systematically compared with the literature data. The results showed that one of the introduced loss functions could significantly outperformance the literature loss functions available in the literature. Using a new loss function improved the mean error by 67.1\%. Moreover, using new loss functions eliminated the pixels predictions (with large errors) by 96\%.},
  archive      = {J_NCA},
  author       = {Edalatifar, Mohammad and Ghalambaz, Mohammad and Tavakoli, Mohammad Bagher and Setoudeh, Farbod},
  doi          = {10.1007/s00521-022-07233-1},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15889-15906},
  shortjournal = {Neural Comput. Appl.},
  title        = {New loss functions to improve deep learning estimation of heat transfer},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-layer perceptron neural network model for predicting
the hydrate equilibrium conditions in multi-component hydrocarbon
systems. <em>NCA</em>, <em>34</em>(18), 15863–15887. (<a
href="https://doi.org/10.1007/s00521-022-07284-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a model based on multilayer perceptron neural network (MLPNN) for the prediction of hydrate equilibrium conditions in hydrocarbon systems. The model heuristics are based on an extensive experimental dataset found in the open literature (consisting of 2883 data points for pure component, 993 data points binary component and 484 data points for multicomponent systems, for a wide range of temperature, compositions, and considering different equilibrium phases and presence of inhibitors). Absolute average relative deviation (AARD), mean squared error (MSE) and the regression coefficient (R2) are used as the evaluation criteria to test the efficacy and accuracy of the model’s performance. Results were validated with data points not used to develop the proposed model and found to be in close agreement. The model’s performance was also compared to well-known rigorous equilibrium models (Ng–Robinson and Colorado School of Mines models) and found superior in terms of accuracy with a AARD value as low as 0.60 MPa for the same experimental dataset. The results and comparison indicate that the proposed MLPNN model can be confidently used to predict hydrate equilibrium conditions for various hydrocarbon systems.},
  archive      = {J_NCA},
  author       = {Nasir, Qazi and Suleman, Humbul and Ud Din, Israf and Elfadol, Yasir Elsheikh},
  doi          = {10.1007/s00521-022-07284-4},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15863-15887},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-layer perceptron neural network model for predicting the hydrate equilibrium conditions in multi-component hydrocarbon systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Data-driven multi-objective affective product design
integrating three-dimensional form and color. <em>NCA</em>,
<em>34</em>(18), 15835–15861. (<a
href="https://doi.org/10.1007/s00521-022-07232-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) form and color are the main appearance elements that arouse product emotion. To use more complete data of appearance and emotion and their comprehensive coupling relationship to improve the emotional design quality, this paper proposes a novel method of data-driven multi-objective affective product design integrating 3D form and color. Based on neural network and machine learning algorithms, it constructs multiple models covering the entire process of affective product design. The models include a mathematical model for quantifying 3D form’s complete surface and color to obtain their complete mixed data, a recognition model for identifying more accurate and comprehensive emotions and obtaining complete emotional data by using the mixed data to participate in the recognition modeling, a prediction model for establishing a comprehensive coupling relationship between appearance and emotion and achieving more accurate emotion prediction, and an optimization model for better realizing optimal designs in response to multiple emotions by utilizing the comprehensive coupling relationship. To validate the effectiveness and practicability of the proposed method, its design application system and an experimental study on two design models (Model I and Model II) are constructed and applied in car design. Model I uses the more complete mixed data for design, while Model II does not. The results show that the emotional design quality and efficiency of Model I are better than those of Model II, which highlights the value of complete data and comprehensive coupling relationship for affective product design.},
  archive      = {J_NCA},
  author       = {Wang, Zeng and Liu, Weidong and Yang, Minglang},
  doi          = {10.1007/s00521-022-07232-2},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15835-15861},
  shortjournal = {Neural Comput. Appl.},
  title        = {Data-driven multi-objective affective product design integrating three-dimensional form and color},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Whole constraint and partial triplet-center loss for
infrared-visible re-identification. <em>NCA</em>, <em>34</em>(18),
15821–15834. (<a
href="https://doi.org/10.1007/s00521-022-07276-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a hybrid cross-dual-path feature learning network (HCDFL) to learn local discriminative characteristics and exploit a novel loss function called whole constraint loss and partial triplet-center loss (WCPTL) to narrow the discrepancy between cross-modality. HCDFL firstly extracts person features of two modalities, respectively, then horizontally slices the extracted features into p stripes and maps them into the shared space, finally utilizes modality-specific identity loss, cross-entropy and WCPTL proposed in this paper to improve the overall performance. Within WCPTL, whole constraint loss is utilized to narrow the discrepancy between two modalities, and partial triplet-center loss is utilized to ensure that samples from the same category can be close to the category center and away from other categories center. Experimental results demonstrate that the proposed method achieves better performance than other methods on two public datasets SYSU-MM01 and RegDB.},
  archive      = {J_NCA},
  author       = {Lv, Zhihan and Zhu, Songhao and Wang, Dongsheng and Liang, Zhiwei},
  doi          = {10.1007/s00521-022-07276-4},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15821-15834},
  shortjournal = {Neural Comput. Appl.},
  title        = {Whole constraint and partial triplet-center loss for infrared-visible re-identification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneous feature ensemble modeling with stochastic
configuration networks for predicting furnace temperature of a municipal
solid waste incineration process. <em>NCA</em>, <em>34</em>(18),
15807–15819. (<a
href="https://doi.org/10.1007/s00521-022-07271-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the accuracy, generalization ability, stability, and training efficiency of a furnace temperature model in the process of municipal solid waste incineration, a heterogeneous feature ensemble modeling method for furnace temperature is proposed in this paper. First, heterogeneous features are generated according to the operation mechanism of the waste incineration process, and the training subset of the furnace temperature- and grate temperature-based model is determined from the historical data of this process. Second, the base model pools of furnace temperature and grate temperature are constructed by a regularized stochastic configuration network, and a set of optimal base models are retained by selective base model technology. Then, a negative correlation learning strategy is employed to establish a simultaneous training ensemble model of furnace temperature, and a regularized stochastic configuration network is used to establish a secondary training ensemble model of furnace temperature. The final output of the furnace temperature is obtained by the average value of the output of the above two ensemble models. Finally, a comparative experiment is carried out using the historical data of a waste incineration plant. The results show that the furnace temperature model established in this paper has advantages in accuracy, generalization ability, stability, and training efficiency. It can be applied to the field of furnace temperature prediction and control in the waste incineration process.},
  archive      = {J_NCA},
  author       = {Yan, Aijun and Guo, Jingcheng and Wang, Dianhui},
  doi          = {10.1007/s00521-022-07271-9},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15807-15819},
  shortjournal = {Neural Comput. Appl.},
  title        = {Heterogeneous feature ensemble modeling with stochastic configuration networks for predicting furnace temperature of a municipal solid waste incineration process},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An application of machine learning regression to feature
selection: A study of logistics performance and economic attribute.
<em>NCA</em>, <em>34</em>(18), 15781–15805. (<a
href="https://doi.org/10.1007/s00521-022-07266-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study demonstrates how to profit from up-to-date dynamic economic big data, which contributes to selecting economic attributes that indicate logistics performance as reflected by the Logistics Performance Index (LPI). The analytical technique employs a high degree of productivity in machine learning (ML) for prediction or regression using adequate economic features. The goal of this research is to determine the ideal collection of economic attributes that best characterize a particular anticipated variable for predicting a country’s logistics performance. In addition, several potential ML regression algorithms may be used to optimize prediction accuracy. The feature selection of filter techniques of correlation and principal component analysis (PCA), as well as the embedded technique of LASSO and Elastic-net regression, is utilized. Then, based on the selected features, the ML regression approaches artificial neural network (ANN), multi-layer perceptron (MLP), support vector regression (SVR), random forest regression (RFR), and Ridge regression are used to train and validate the data set. The findings demonstrate that the PCA and Elastic-net feature sets give the closest to adequate performance based on the error measurement criteria. A feature union and intersection procedure of an acceptable feature set are used to make a more precise decision. Finally, the union of feature sets yields the best results. The findings suggest that ML algorithms are capable of assisting in the selection of a proper set of economic factors that indicate a country&#39;s logistics performance. Furthermore, the ANN was shown to be the best effective prediction model in this investigation.},
  archive      = {J_NCA},
  author       = {Jomthanachai, Suriyan and Wong, Wai Peng and Khaw, Khai Wah},
  doi          = {10.1007/s00521-022-07266-6},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15781-15805},
  shortjournal = {Neural Comput. Appl.},
  title        = {An application of machine learning regression to feature selection: A study of logistics performance and economic attribute},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel TS fuzzy-GMDH model optimized by PSO to determine
the deformation values of rock material. <em>NCA</em>, <em>34</em>(18),
15755–15779. (<a
href="https://doi.org/10.1007/s00521-022-07214-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since determining the rock deformation directly in the laboratory is costly and time consuming, it is important to reliably determine/estimate this parameter through the use of several simple rock index tests. This study develops a new hybrid intelligent technique according to Takagi–Sugeno Fuzzy Inference System-Group Method of Data Handling optimized by the particle swarm optimization, called TS Fuzzy-GMDH-PSO for prediction of the rock deformation. The PSO role in this advanced system is to optimize the membership functions of TS Fuzzy-GMDH model for enhancing the level of prediction capacity. In this research, four rock index tests including Schmidt hammer, p-wave velocity, porosity and point load were selected and conducted in laboratory in order to establish a suitable database for prediction purposes. To demonstrate the feasibility and applicability of the advanced hybrid model, two base models of TS Fuzzy and GMDH were also modeled to forecast rock deformation. After conducting several sensitivity analyses on the mentioned models to get the highest performance capacity, their prediction levels were evaluated using some statistical indices, such as root mean square error and correlation coefficient (R). The comparative results confirmed the superiority of the TS Fuzzy-GMDH-PSO over other two models, namely TS Fuzzy and GMDH in terms of both train and test phases. It can be concluded that the TS Fuzzy-GMDH-PSO can be recommended as a powerful, capable and new model to solve the problems related to rock strength and deformation.},
  archive      = {J_NCA},
  author       = {Harandizadeh, Hooman and Armaghani, Danial Jahed and Hasanipanah, Mahdi and Jahandari, Soheil},
  doi          = {10.1007/s00521-022-07214-4},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15755-15779},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel TS fuzzy-GMDH model optimized by PSO to determine the deformation values of rock material},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Correction to: An improved binary sparrow search algorithm
for feature selection in data classification. <em>NCA</em>,
<em>34</em>(18), 15753. (<a
href="https://doi.org/10.1007/s00521-022-07546-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Gad, Ahmed G. and Sallam, Karam M. and Chakrabortty, Ripon K. and Ryan, Michael J. and Abohany, Amr A.},
  doi          = {10.1007/s00521-022-07546-1},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15753},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: An improved binary sparrow search algorithm for feature selection in data classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). An improved binary sparrow search algorithm for feature
selection in data classification. <em>NCA</em>, <em>34</em>(18),
15705–15752. (<a
href="https://doi.org/10.1007/s00521-022-07203-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature Selection (FS) is an important preprocessing step that is involved in machine learning and data mining tasks for preparing data (especially high-dimensional data) by eliminating irrelevant and redundant features, thus reducing the potential curse of dimensionality of a given large dataset. Consequently, FS is arguably a combinatorial NP-hard problem in which the computational time increases exponentially with an increase in problem complexity. To tackle such a problem type, meta-heuristic techniques have been opted by an increasing number of scholars. Herein, a novel meta-heuristic algorithm, called Sparrow Search Algorithm (SSA), is presented. The SSA still performs poorly on exploratory behavior and exploration-exploitation trade-off because it does not duly stimulate the search within feasible regions, and the exploitation process suffers noticeable stagnation. Therefore, we improve SSA by adopting: i) a strategy for Random Re-positioning of Roaming Agents (3RA); and ii) a novel Local Search Algorithm (LSA), which are algorithmically incorporated into the original SSA structure. To the FS problem, SSA is improved and cloned as a binary variant, namely, the improved Binary SSA (iBSSA), which would strive to select the optimal or near-optimal features from a given dataset while keeping the classification accuracy maximized. For binary conversion, the iBSSA was primarily validated against nine common S-shaped and V-shaped Transfer Functions (TFs), thus producing nine iBSSA variants. To verify the robustness of these variants, three well-known classification techniques, including k-Nearest Neighbor (k-NN), Support Vector Machine (SVM), and Random Forest (RF) were adopted as fitness evaluators with the proposed iBSSA approach and many other competing algorithms, on 18 multifaceted, multi-scale benchmark datasets from the University of California Irvine (UCI) data repository. Then, the overall best-performing iBSSA variant for each of the three classifiers was compared with binary variants of 12 different well-known meta-heuristic algorithms, including the original SSA (BSSA), Artificial Bee Colony (BABC), Particle Swarm Optimization (BPSO), Bat Algorithm (BBA), Grey Wolf Optimization (BGWO), Whale Optimization Algorithm (BWOA), Grasshopper Optimization Algorithm (BGOA) SailFish Optimizer (BSFO), Harris Hawks Optimization (BHHO), Bird Swarm Algorithm (BBSA), Atom Search Optimization (BASO), and Henry Gas Solubility Optimization (BHGSO). Based on a Wilcoxon’s non-parametric statistical test ( $$\alpha =0.05$$ ), the superiority of iBSSA with the three classifiers was very evident against counterparts across the vast majority of the selected datasets, achieving a feature size reduction of up to 92\% along with up to 100\% classification accuracy on some of those datasets.},
  archive      = {J_NCA},
  author       = {Gad, Ahmed G. and Sallam, Karam M. and Chakrabortty, Ripon K. and Ryan, Michael J. and Abohany, Amr A.},
  doi          = {10.1007/s00521-022-07203-7},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15705-15752},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved binary sparrow search algorithm for feature selection in data classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Wavelet-based self-supervised learning for multi-scene image
fusion. <em>NCA</em>, <em>34</em>(18), 15689–15704. (<a
href="https://doi.org/10.1007/s00521-022-07242-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image fusion can provide more comprehensive information by integrating images from different sensors. So far, intensive research has been devoted to utilizing deep learning to fuse images from multiple sensors more effectively. However, most existing image fusion methods are single-scene-specific with substantial model complexity, and none of the current deep learning-based methods has the noise suppression capability. In this paper, we propose a simple and effective unified image fusion framework with noise suppression capability. The core of the proposed method is a novel self-supervised image reconstruction task. Specifically, we destroy several selected regions of an image in the frequency domain by utilizing discrete wavelet transform and reconstruct it by an encoder–decoder model. Then, in the fusion phase, the two images to be fused are first encoded by the encoder and the features are averaged and then decoded to obtain the final fused image. To keep the fusion network small, we construct the encoder–decoder model with three-layer convolutional neural network. In this way, the fusion phase is much faster than the latest works (only 0.0082s on average). We conducted experiments on four image fusion scenarios and synthesized a new experiment of fusing noisy images. Both subjective and objective evaluations demonstrate that the proposed method outperforms existing state-of-the-art approaches in these experiments. Codes are available at https://github.com/slliuEric/WaveSSL .},
  archive      = {J_NCA},
  author       = {Liu, Shaolei and Qu, Linhao and Qiao, Qin and Wang, Manning and Song, Zhijian},
  doi          = {10.1007/s00521-022-07242-0},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15689-15704},
  shortjournal = {Neural Comput. Appl.},
  title        = {Wavelet-based self-supervised learning for multi-scene image fusion},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An integrated interval-valued intuitionistic fuzzy
AHP-TOPSIS methodology to determine the safest route for cash in transit
operations: A real case in istanbul. <em>NCA</em>, <em>34</em>(18),
15673–15688. (<a
href="https://doi.org/10.1007/s00521-022-07236-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Cash in Transit (CIT) deals with the money distribution and picking up between depot(s), central bank, bank branches, Automated Teller Machines (ATMs), jewelry stores, and exchange offices, safely and quickly. It is critical for companies carrying out CIT activities to identify risks and their priorities. It is one of the problems to be resolved for CIT companies to determine the risks that may occur on the route for each vehicle that will carry money from a certain center to the demand points. It is important for decision makers how critical these routes are concerning risks. Within the scope of the study, determining the risks, the weights of these risks, and high-risk routes accordingly are discussed. The literature review related to the problem is first consulted. After the literature review, interviews are made with experts on their subject. The main criteria and sub-criteria to define the risks are determined. Then, these criteria are weighted by the Interval-Valued Intuitionistic Fuzzy Analytical Hierarchy Process (IVIF-AHP), and risk assessment is made to alternative routes based on these weighted risks. The routes are evaluated by Interval-Valued Intuitionistic Fuzzy Technique for Order Preference by Similarity to Ideal Solution (IVIF-TOPSIS) methodology, and thus, it is determined which route has the highest risk and which route has the lowest risk. In this way, it is stated on which route should be used for the vehicles to distribute money and which routes should be improved.},
  archive      = {J_NCA},
  author       = {Yildiz, Aslihan and Guneri, Ali Fuat and Ozkan, Coskun and Ayyildiz, Ertugrul and Taskin, Alev},
  doi          = {10.1007/s00521-022-07236-y},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15673-15688},
  shortjournal = {Neural Comput. Appl.},
  title        = {An integrated interval-valued intuitionistic fuzzy AHP-TOPSIS methodology to determine the safest route for cash in transit operations: A real case in istanbul},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LW-net: An interpretable network with smart lifting wavelet
kernel for mechanical feature extraction and fault diagnosis.
<em>NCA</em>, <em>34</em>(18), 15661–15672. (<a
href="https://doi.org/10.1007/s00521-022-07225-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been applied in mechanical fault diagnosis. Hereinto, the convolutional neural network (CNN) has the shallow convolution operation, supporting the function of feature learning. However, the interpretability of CNN has always been an urgent problem to be solved. Due to the advantages of lifting wavelets and their transforms for impact fault diagnosis, an interpretable network called LW-Net with smart lifting wavelet kernels is proposed for mechanical feature extraction and fault diagnosis. Different from the traditional CNN, the shallow layer of the net is designed to be the lifting layer, concluding split, prediction and update sublayers by the natural convolution operation of lifting wavelet transforms. The smart lifting wavelet kernels are constructed by the mathematic constraints of lifting wavelets, resulting in the nice properties of signal processing. Meanwhile, the kernels with only two parameters are learned from the input data and updated by the back-propagation process. The lifting layer is suitable to accurately extract the impact fault features, improving the effective fault diagnosis of LW-Net. Moreover, the interpretability of LW-Net to achieve shallow feature extraction is verified and discussed by the repeatable simulations. The underlying logic and physical meaning of the lifting layer is revealed to be the adaptive waveform matching and learning based on the inner product matching principle. LW-Net is applied to the engineering diagnostic cases of the Case Western Reserve University dataset and planetary gearbox dataset to verify the effectiveness. The results show the method outperforms the classical and popular methods on the converge speed, classification accuracy and feature extraction.},
  archive      = {J_NCA},
  author       = {Yuan, Jing and Cao, Shuwei and Ren, Gangxing and Su, Fengxian and Jiang, Huiming and Zhao, Qian},
  doi          = {10.1007/s00521-022-07225-1},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15661-15672},
  shortjournal = {Neural Comput. Appl.},
  title        = {LW-net: An interpretable network with smart lifting wavelet kernel for mechanical feature extraction and fault diagnosis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bio-plausible digital implementation of a reward modulated
STDP synapse. <em>NCA</em>, <em>34</em>(18), 15649–15660. (<a
href="https://doi.org/10.1007/s00521-022-07220-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reward-modulated Spike-Timing-Dependent Plasticity (R-STDP) is a learning method for Spiking Neural Network (SNN) that makes use of an external learning signal to modulate the synaptic plasticity produced by Spike-Timing-Dependent Plasticity (STDP). Combining the advantages of reinforcement learning and the biological plausibility of STDP, online learning on SNN in real-world scenarios can be applied. This paper presents a fully digital architecture, implemented on an Field-Programmable Gate Array (FPGA), including the R-STDP learning mechanism in a SNN. The hardware results obtained are comparable to the software simulations results using the Brian2 simulator. The maximum error is of 0.083 when a 14-bits fix-point precision is used in realtime. The presented architecture shows an accuracy of 95\% when tested in an obstacle avoidance problem on mobile robotics with a minimum use of resources.},
  archive      = {J_NCA},
  author       = {Quintana, Fernando M. and Perez-Peña, Fernando and Galindo, Pedro L.},
  doi          = {10.1007/s00521-022-07220-6},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15649-15660},
  shortjournal = {Neural Comput. Appl.},
  title        = {Bio-plausible digital implementation of a reward modulated STDP synapse},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Time-series prediction of hourly atmospheric pressure using
ANFIS and LSTM approaches. <em>NCA</em>, <em>34</em>(18), 15633–15648.
(<a href="https://doi.org/10.1007/s00521-022-07275-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Atmospheric pressure (AP), which is an indicator of weather events, plays an important role in climatology, agriculture, meteorology, atmospheric and environmental science, human and animal life, and Earth’s living ecosystem. In this regard, accurate AP forecasting plays a crucial role in today’s life as it provides critical information about future weather events. In this study, four different machine learning techniques such as long short-term memory (LSTM) neural network, adaptive neuro-fuzzy inference system (ANFIS) with fuzzy c-means, ANFIS with subtractive clustering, and ANFIS with grid partition (GP) were used for one-hour-ahead AP forecasting. To achieve this, the hourly AP data measured between 2012 and 2019 at the seven measurement stations (Adana, Ankara, Gumushane, Denizli, Kirklareli, Sanliurfa, and Van) in different climate regions of Turkey were obtained. The estimation accuracy was verified by four performance criteria: R, RMSE, MAPE, and MAE. As a result, the highest relative R-value of 0.9986 and the lowest error values of RMSE = 0.2905 hPa, MAPE = 0.0230\%, and MAE = 0.2040 hPa for one-hour-ahead AP forecasting were obtained from the ANFIS-GP model.},
  archive      = {J_NCA},
  author       = {Bilgili, Mehmet and Ilhan, Akın and Ünal, Şaban},
  doi          = {10.1007/s00521-022-07275-5},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15633-15648},
  shortjournal = {Neural Comput. Appl.},
  title        = {Time-series prediction of hourly atmospheric pressure using ANFIS and LSTM approaches},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient deep learning-based semantic mapping approach
using monocular vision for resource-limited mobile robots. <em>NCA</em>,
<em>34</em>(18), 15617–15631. (<a
href="https://doi.org/10.1007/s00521-022-07273-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic mapping is still challenging for household collaborative robots. Deep learning models have proved their capability to extract semantics from the scene and learn robot odometry. For interfacing semantic information with robot odometry, existing approaches extract both semantics and robot odometry separately and then integrate them using fusion techniques. Such approaches face many issues while integration, and the mapping procedure requires a lot of memory and resources to process the information. In an attempt to produce accurate semantic mapping with resource-limited devices, this paper proposes an efficient deep learning-based model to simultaneously estimate robot odometry by using monocular sequence frames and detecting objects in the frames. The proposed model includes two main components: using a YOLOv3 object detector as a backbone and a convolutional long short-term (Conv-LSTM) recurrent neural network to model the changes in camera pose. The unique advantage of the proposed model is that it boycotts the need for data association and the requirement of multi-sensor fusion. We conducted the experiments on a LoCoBot robot in a laboratory environment, attaining satisfactory results with such limited computational resources. Additionally, we tested the proposed method on the Kitti dataset, reaching an average test loss of 15.93 on various sequences. The experiments are documented in this video https://www.youtube.com/watch?v=hnmqwxpaTEw .},
  archive      = {J_NCA},
  author       = {Singh, Aditya and Narula, Raghav and Rashwan, Hatem A. and Abdel-Nasser, Mohamed and Puig, Domenec and Nandi, G. C.},
  doi          = {10.1007/s00521-022-07273-7},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15617-15631},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient deep learning-based semantic mapping approach using monocular vision for resource-limited mobile robots},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Audiovisual speech recognition for kannada language using
feed forward neural network. <em>NCA</em>, <em>34</em>(18), 15603–15615.
(<a href="https://doi.org/10.1007/s00521-022-07249-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audiovisual speech recognition is one of the promising technologies in a noisy environment. In this work, we develop the database for Kannada Language and develop an AVSR system for the same. The proposed work is categorized into three main components: a. Audio mechanism. b. Visual speech mechanism. c. Integration of audio and visual mechanisms. In the audio model, MFCC is used to extract the features and a one-dimensional convolutional neural network is used for classification. In the visual module, Dlib is used to extract the features and long short-term memory recurrent neural network is used for classification. Finally, integration of audio and visual module is done using feed forward neural network. Audio speech recognition of Kannada dataset training accuracy achieved is 93.86 and 91.07\% for testing data using seventy epochs. Visual speech recognition for Kannada dataset training accuracy is 77.57\%, and testing accuracy is 75\%. After integration, audiovisual speech recognition for Kannada dataset train accuracy is 93.33\% and for testing is 92.26\%.},
  archive      = {J_NCA},
  author       = {Shashidhar, R. and Patilkulkarni, S.},
  doi          = {10.1007/s00521-022-07249-7},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15603-15615},
  shortjournal = {Neural Comput. Appl.},
  title        = {Audiovisual speech recognition for kannada language using feed forward neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Photonic-aware neural networks. <em>NCA</em>,
<em>34</em>(18), 15589–15601. (<a
href="https://doi.org/10.1007/s00521-022-07243-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photonics-based neural networks promise to outperform electronic counterparts, accelerating neural network computations while reducing power consumption and footprint. However, these solutions suffer from physical layer constraints arising from the underlying analog photonic hardware, impacting the resolution of computations (in terms of effective number of bits), requiring the use of positive-valued inputs, and imposing limitations in the fan-in and in the size of convolutional kernels. To abstract these constraints, in this paper we introduce the concept of Photonic-Aware Neural Network (PANN) architectures, i.e., deep neural network models aware of the photonic hardware constraints. Then, we devise PANN training schemes resorting to quantization strategies aimed to obtain the required neural network parameters in the fixed-point domain, compliant with the limited resolution of the underlying hardware. We finally carry out extensive simulations exploiting PANNs in image classification tasks on well-known datasets (MNIST, Fashion-MNIST, and Cifar-10) with varying bitwidths (i.e., 2, 4, and 6 bits). We consider two kernel sizes and two pooling schemes for each PANN model, exploiting $$2\times 2$$ and $$3\times 3$$ convolutional kernels, and max and average pooling, the latter more amenable to an optical implementation. $$3\times 3$$ kernels perform better than $$2\times 2$$ counterparts, while max and average pooling provide comparable results, with the latter performing better on MNIST and Cifar-10. The accuracy degradation due to the photonic hardware constraints is quite limited, especially on MNIST and Fashion-MNIST, demonstrating the feasibility of PANN approaches on computer vision tasks.},
  archive      = {J_NCA},
  author       = {Paolini, Emilio and De Marinis, Lorenzo and Cococcioni, Marco and Valcarenghi, Luca and Maggiani, Luca and Andriolli, Nicola},
  doi          = {10.1007/s00521-022-07243-z},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15589-15601},
  shortjournal = {Neural Comput. Appl.},
  title        = {Photonic-aware neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A meta-heuristic-based energy efficient route modeling for
EV on non-identical road surfaces. <em>NCA</em>, <em>34</em>(18),
15575–15588. (<a
href="https://doi.org/10.1007/s00521-022-07205-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric vehicles (EVs) have emerged as a fast-growing industry not only in India but all over the world due to their environment friendly and economic properties. Moreover, it is being seen as a future replacement for fast depleting fossil fuels. But still, the international vehicle market cannot accept EVs as a ubiquitous vehicle manufacturing standard due to their short cruising range and underdeveloped charging infrastructure. Therefore, as an immediate and cost-effective solution to a problem subject to limited battery capacity, the EV route regularization, i.e., optimum energy usage route selection becomes utmost important. To accomplish this objective, this paper proposes a meta-heuristic routing model based on the principles of Artificial Bee Colony (ABC). The proposed model has been designed to consider prominent energy consumption influencing parameters like speed, battery health, road elevation, etc. Moreover, tractive effort modeling on different road surfaces like dry, wet, snow, and icy is also embedded in the design of EV route modeling. The simulation of the proposed model has been done to quantify its performance bys utilizing route maps as well as real-time information of vehicles’ location by the Warrigal project as input. The analysis of obtained results has revealed the traces of saving in EVs’ energy consumption of about 7.1\% in comparison with Google maps if the route suggested by the proposed model is followed.},
  archive      = {J_NCA},
  author       = {Kumar, Ashwani and Kumar, Ravinder and Aggarwal, Ashutosh},
  doi          = {10.1007/s00521-022-07205-5},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15575-15588},
  shortjournal = {Neural Comput. Appl.},
  title        = {A meta-heuristic-based energy efficient route modeling for EV on non-identical road surfaces},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast homomorphic SVM inference on encrypted data.
<em>NCA</em>, <em>34</em>(18), 15555–15573. (<a
href="https://doi.org/10.1007/s00521-022-07202-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel methods are popular machine learning methods that provide automated pattern analysis of raw datasets. Of particular interest is Support Vector Machines that are used to solve supervised machine learning problems in many areas such as business, finance and healthcare. Nowadays, complex computations and data analytic tasks can be outsourced to specialized third parties. However, data owners might be reluctant to share their data especially when it includes sensitive information. Therefore, a need for privacy-preserving machine learning applications cannot be overstated. We present FHSVM: a Fast Homomorphic evaluation of non-linear SVM prediction on encrypted data using Fully Homomorphic Encryption. We provide design, implementation and several algorithmic and architectural optimizations such as novel packing strategies and parallel implementation to achieve real-time private prediction. We employed the CKKS FHE scheme to implement FHSVM under 128-bit security level. We evaluated FHSVM on a contemporary real-world large dataset compiled for anti-money laundering tasks in Bitcoin transactions. Empirical analysis demonstrates that homomorphic SVM prediction can be performed in 1.25 s on multi-core CPU platforms. In addition, FHSVM shows zero accuracy loss when compared to the non-privacy-preserving implementation. This shows that FHSVM is both computationally secure and fully utilizes the data.},
  archive      = {J_NCA},
  author       = {Al Badawi, Ahmad and Chen, Ling and Vig, Saru},
  doi          = {10.1007/s00521-022-07202-8},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15555-15573},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fast homomorphic SVM inference on encrypted data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Image based rainfall amount estimation for auto-wiping of
vehicles. <em>NCA</em>, <em>34</em>(18), 15543–15554. (<a
href="https://doi.org/10.1007/s00521-022-07269-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With rapid development of deep learning, a lot of computer vision tasks, such as object detection and semantic segmentation, have been applied to various Advanced Driver Assistance Systems. However, few computer vision solutions to estimate rainfall amount have been developed so far. So, we propose a rainfall amount estimation method based on deep learning and computer vision. The proposed method mainly consists of two steps. The first step is raindrop segmentation, and the second step is rainfall amount estimation. The raindrop segmentation is specifically based on three techniques: A relational ASPP to explore the correlation between raindrop features, a height attention module to consider the features that vary depending on raindrop locations, and a masking loss to further improve the performance of raindrop segmentation. Second, using the segmented raindrops, we present a rainfall amount estimation algorithm for auto-wiping. We experimentally achieved acceptable raindrop segmentation performance, i.e., mean IoU (mIoU) score of 70.6\% that is much higher than other algorithms. This verifies that the proposed network is good at segmenting raindrops on a windshield. And, we demonstrate that the proposed rainfall amount estimation scheme provides sufficiently high accuracy of about 93\%. In addition, we have built a rainy driving dataset for computer vision-based auto-wiping purpose and published it publicly on https://github.com/jjh930910/raindrop-segmentation .},
  archive      = {J_NCA},
  author       = {Lee, Seung Hoon and Jeon, Jung Ho and Choi, Dong Yoon and Park, Jong Min and Song, Byung Cheol},
  doi          = {10.1007/s00521-022-07269-3},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15543-15554},
  shortjournal = {Neural Comput. Appl.},
  title        = {Image based rainfall amount estimation for auto-wiping of vehicles},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid algorithm based on modified chemical reaction
optimization and best-first search algorithm for solving minimum vertex
cover problem. <em>NCA</em>, <em>34</em>(18), 15513–15541. (<a
href="https://doi.org/10.1007/s00521-022-07262-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum vertex cover problem (MVCP) is one of the well-known NP-complete problems that can be used to formulate numerous real-life applications. The MVCP has been solved using different approaches, exact, heuristic, and metaheuristic. Chemical reaction optimization (CRO) is a population-based metaheuristic algorithm that simulates what happens in chemical reactions to solve many problems. In this paper, the MVCP is solved using hybridization of a modified version of the CRO algorithm and the best-first search (BFS) algorithm. This hybridization is symbolized by MCROA-BFS. The BFS algorithm is exploited to generate initial populations with high-quality initial solutions in comparison with the random bit-vector (RBV) approach as a traditional approach for generating initial populations for several population-based metaheuristic algorithms. At first, the MCROA is evaluated analytically in terms of run time complexity. Then the performance of the MCROA is evaluated experimentally to show the effectiveness of exploiting the BFS in terms of quality of gained solutions and run time. The most valuable player algorithm (MVPA), genetic algorithm (GA), and hybrid CRO algorithm (HCROA) are metaheuristic algorithms that used the RBV approach to generate the initial population. MCROA-BFS is compared, under the selected performance metrics, with these metaheuristic algorithms in addition to MCROA with the RBV approach (MCROA-RBV). The conducted experiments were carried out using 18 instances of DIMACS and BHOSLIB benchmarks. The experimental results revealed the superiority of MCROA-BFS over MVPA, GA, and MCROA-RBV in terms of both performance metrics. Although HCROA has the smallest run time, it failed to obtain high-quality solutions in comparison with MCROA.},
  archive      = {J_NCA},
  author       = {Khattab, Hebatullah and Mahafzah, Basel A. and Sharieh, Ahmad},
  doi          = {10.1007/s00521-022-07262-w},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15513-15541},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid algorithm based on modified chemical reaction optimization and best-first search algorithm for solving minimum vertex cover problem},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A low latency traffic sign detection model with an automatic
data labeling pipeline. <em>NCA</em>, <em>34</em>(18), 15499–15512. (<a
href="https://doi.org/10.1007/s00521-022-07253-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a crucial sub-task for autonomous driving and intelligent transportation, traffic sign detection attracts a lot of researchers’ attention. Although prior works have achieved promising results, it still suffers from two problems, the need of massive labeled data and the slow inference speed on high-resolution images, which are also the common problem of generic object detection. Motivated by these problems, we propose a lightweight traffic sign detection model and employ an automatic data labeling pipeline. The detection model utilizes a cascaded structure that consists of a localization module and a recognition module, achieving quite fast speed on GPU and edge devices. We discard all complex structures and operations to boost the speed of the model, making it easy for deployment. Then, we propose a two-stage automatic data labeling pipeline to reduce the cost of data labeling work. With only traffic sign template images, a synthetic dataset is constructed for generating initial pseudo labels in the first stage. In the second stage, we propose to use an image pretext model to refine the initial labels. The accuracy of the final pseudo labels is nearly 100\%. We test the proposed method on TT-100K, GTSDB, and GTSRB datasets, and the results show that the model trained with the pseudo labels only has a negligible accuracy loss compared with the model trained by real labels. The proposed model’s calculation latency is around 1 ms on GPU, and the accuracy is still on par with the state-of-the-art models.},
  archive      = {J_NCA},
  author       = {Luo, Jiapeng and Wang, Zhongfeng},
  doi          = {10.1007/s00521-022-07253-x},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15499-15512},
  shortjournal = {Neural Comput. Appl.},
  title        = {A low latency traffic sign detection model with an automatic data labeling pipeline},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Standalone and ensemble-based machine learning techniques
for particle froude number prediction in a sewer system. <em>NCA</em>,
<em>34</em>(18), 15481–15497. (<a
href="https://doi.org/10.1007/s00521-022-07237-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hydraulic capacity of a channel is impacted due to sediment deposition in urban drainage and sewer system. As a result, the self-cleansing mechanism is a widely used phenomena in urban drainage and sewer systems. In this context, the prediction of particle Froude number plays an important role in the design of the sewer system. This study investigates the performance of multiple standalone and ensemble machine learning techniques for the prediction of particle Froude number with reference to non-deposition with deposited bed. Five datasets available in the literature comprising of wide ranges of the volumetric sediment concentration ( $$C_v$$ ), dimensional grain size of particles ( $$D_{gr}$$ ), sediment median size (d), hydraulic radius (R), pipe friction factor ( $$\lambda $$ ) have been utilized in this study. For standalone techniques, we made use of a decision tree regressor (DecisionTreeRegressor), multilayer perceptron regressor (MLPRegressor), while for ensemble approach extreme gradient boosting regressor (XGBRegressor), extra trees regressor (ExtraTreesRegressor) have been utilized. To evaluate the proposed models, several performance metrics have been used such as correlation coefficient (CC), Nash–Sutcliffe efficiency (NSE), root mean square error (RMSE), and R $$^2$$ . Results indicate that ensemble techniques are more accurate as compared to the standalone methods and empirical equations. Among the proposed models, ExtraTreesRegressor provides the highest prediction (CC = 0.978, NSE = 0.957, RMSE = 0.208, and R $$^2$$ = 0.957) followed by XGBRegressor, MLPRegressor, and DecisionTreeRegressor for the prediction of particle Froude number.},
  archive      = {J_NCA},
  author       = {Shakya, Deepti and Deshpande, Vishal and Agarwal, Mayank and Kumar, Bimlesh},
  doi          = {10.1007/s00521-022-07237-x},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15481-15497},
  shortjournal = {Neural Comput. Appl.},
  title        = {Standalone and ensemble-based machine learning techniques for particle froude number prediction in a sewer system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting traffic flow with spatial–temporal convolutional
graph attention networks. <em>NCA</em>, <em>34</em>(18), 15457–15479.
(<a href="https://doi.org/10.1007/s00521-022-07235-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is crucial for intelligent transportation system, such as traffic management, congestion alleviation and public risk assessment. Recently, attention mechanism and deep neural networks are utilized to capture traffic dependencies. However, two challenges have yet to be well addressed: (i) previous works overlook the global dependencies across different regions; (ii) how to integrate spatial and temporal information aggregation with latent channel-aware semantics. To tackle these issues, we propose a deep spatial–temporal convolutional graph attention network for citywide traffic flow prediction. We first apply the multi-resolution transformer network to capture traffic dependencies among different regions with the encoding of multi-level periodicity. Spatial dependencies are captured by the attentive graph neural networks followed by convolutional networks from local view to global view. We further propose to inject spatial contextual signals into our framework with the designed channel-aware recalibration residual network, which effectively endows model with the capability of mapping spatial–temporal data patterns into different representation subspaces of latent semantics. The extensive experiments on four real-world datasets demonstrate at least 5\% performance gain of our framework by comparing with 19 state-of-the-art traffic prediction methods.},
  archive      = {J_NCA},
  author       = {Zhang, Xiyue and Xu, Yong and Shao, Yizhen},
  doi          = {10.1007/s00521-022-07235-z},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15457-15479},
  shortjournal = {Neural Comput. Appl.},
  title        = {Forecasting traffic flow with spatial–temporal convolutional graph attention networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel approach of data race detection based on CNN-BiLSTM
hybrid neural network. <em>NCA</em>, <em>34</em>(18), 15441–15455. (<a
href="https://doi.org/10.1007/s00521-022-07248-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing data race detection approaches based on deep learning are suffering from the problems of unique feature extraction and low accuracy. To this end, this paper proposes a novel approach called SmartRace based on a CNN-BiLSTM hybrid neural network to detect data race. To build the dataset, SmartRace selects 25 real-world applications from five benchmark suites and then extracts multi-level features by a static analysis tool Wala. A tool ConRacer is employed to help label the samples. SmartRace leverages the Kmeans-SMOTE algorithm to make the positive samples and negative counterparts well distributed. The samples are vectorized and fed into a deep learning model. Finally, a CNN-BiLSTM hybrid neural network is built and trained to detect data race. The experimental results show that the accuracy of SmartRace is up to 4.94\% higher than that of the existing detection approach. Furthermore, we compare SmartRace with the existing dynamic and static detection tools, demonstrating the effectiveness of SmartRace.},
  archive      = {J_NCA},
  author       = {Zhang, Yang and Yan, Jiali and Qiao, Liu and Gao, Hongbin},
  doi          = {10.1007/s00521-022-07248-8},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15441-15455},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel approach of data race detection based on CNN-BiLSTM hybrid neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced graph convolutional network based on node
importance for document-level relation extraction. <em>NCA</em>,
<em>34</em>(18), 15429–15439. (<a
href="https://doi.org/10.1007/s00521-022-07223-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction aims to reason complex semantic relations among entities expressed by multiple associated mentions in a document. Existing methods construct document-level graphs to model interactions between entities. However, these methods only pay attention to the connection relationship of nodes, yet ignore the importance of nodes decided by topological structure. In this paper, we propose a novel method, named Enhanced Graph Convolutional Network (EGCN), to extract document-level relations. Unlike previous methods that only model the connection relationship between two nodes, we further exploit the global topological structural information by measuring node importance. We merge these non-local relationship into a Graph Convolutional Network to aggregate relevant information. In addition, to model semantic and syntactic interactions in documents, we design a novel strategy to construct document-level heterogeneous graphs with different types of edges. Experimental results demonstrate that our EGCN outperforms the previous models by 5.54\%, 1.7\%, and 2.9\% $$F_1$$ on three public document-level relation extraction datasets.},
  archive      = {J_NCA},
  author       = {Sun, Qi and Zhang, Kun and Huang, Kun and Li, Xun and Zhang, Ting and Xu, Tiancheng},
  doi          = {10.1007/s00521-022-07223-3},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15429-15439},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced graph convolutional network based on node importance for document-level relation extraction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A genetic programming-based convolutional neural network for
image quality evaluations. <em>NCA</em>, <em>34</em>(18), 15409–15427.
(<a href="https://doi.org/10.1007/s00521-022-07218-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring the perceptual quality of digital images is fundamentally important since digital image transmissions through the Internet continue to increase exponentially. Many automatic image quality evaluation (IQE) metrics have been developed based on image features correlated to image distortions; however, those metrics are only effective on particular image distortion types. In recent years, convolutional neural network (CNNs) have been developed for IQEs. These CNNs first capture image features from distorted images; image qualities are predicted based on the captured image features. Since the CNN weights are randomly initialized and are updated with respect to a loss function, image features which are strongly correlated to image quality are not guaranteed to be captured. In this paper, a hybrid deep neural network (DNN) is proposed by integrating image quality metrics to capture image features which are correlated to image quality; the approach guarantees that significant image features are included to predict image quality. Also, a tree-based classifier namely geometric semantic genetic programming is proposed to perform the overall predictions by incorporating CNN predictions and image features; the approach is simpler than the fully connected network but is able to model the nonlinear image qualities. The performance of the proposed hybrid DNN is evaluated by an image quality database with 3000 distorted images. The mean correlation achieved by the proposed hybrid DNN is 0.57 which is higher than the other tested methods. Experimental results with the t- test, F-test and Tueky’s range tests show that the proposed hybrid DNN achieves more accurate image predictions with a 99.9\% confidence level, compared to the state-of-the-art IQE metics and the most recently developed CNN for IQEs.},
  archive      = {J_NCA},
  author       = {Chan, Kit Yan and Lam, Hak-Keung and Jiang, Huimin},
  doi          = {10.1007/s00521-022-07218-0},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15409-15427},
  shortjournal = {Neural Comput. Appl.},
  title        = {A genetic programming-based convolutional neural network for image quality evaluations},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Advances in computer–human interaction for detecting facial
expression using dual tree multi band wavelet transform and gaussian
mixture model. <em>NCA</em>, <em>34</em>(18), 15397–15408. (<a
href="https://doi.org/10.1007/s00521-020-05037-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In human communication, facial expressions play an important role, which carries enough information about human emotions. Last two decades, it becomes a very active research area in pattern recognition and computer vision. In this type of recognition, there is a drawback of how to extract the features because of its dynamic nature of facial structures, which are extracted from the facial images and to predict the level of difficulties in the extraction of the facial expressions. In this research, an efficient approach for emotion or facial expression analysis based on dual-tree M-band wavelet transform (DTMBWT) and Gaussian mixture model (GMM) is presented. Different facial expressions are represented by DTMBWT at various decomposition levels from one to six. From the representations, DTMBWT energy and entropy features are extracted as features for the corresponding facial expression. These features are analyzed for the recognition using GMM classifier by varying the number of Gaussians used. Japanese female facial expression database which contains seven facial expressions; happy, sad, angry, fear, neutral, surprise and disgust are employed for the evaluation. Results show that the framework provides 98.14\% accuracy using fourth-level decomposition, which is considerably high.},
  archive      = {J_NCA},
  author       = {Kommineni, Jenni and Mandala, Satria and Sunar, Mohd Shahrizal and Chakravarthy, Parvathaneni Midhu},
  doi          = {10.1007/s00521-020-05037-9},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15397-15408},
  shortjournal = {Neural Comput. Appl.},
  title        = {Advances in computer–human interaction for detecting facial expression using dual tree multi band wavelet transform and gaussian mixture model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A stacked ensemble learning model for intrusion detection in
wireless network. <em>NCA</em>, <em>34</em>(18), 15387–15395. (<a
href="https://doi.org/10.1007/s00521-020-04986-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection pretended to be a major technique for revealing the attacks and guarantee the security on the network. As the data increases tremendously every year on the Internet, a single algorithm is not sufficient for the network security. Because, deploying a single learning approach may suffer from statistical, computational and representational issues. To eliminate these issues, this paper combines multiple machine learning algorithms called stacked ensemble learning, to detect the attacks in a better manner than conventional learning, where a single algorithm is used to identify the attacks. The stacked ensemble system has been taken the benchmark data set, NSL-KDD, to compare its performance with other popular machine learning algorithms such as ANN, CART, random forest, SVM and other machine learning methods proposed by researchers. The experimental results show that stacked ensemble learning is a proper technique for classifying attacks than other existing methods. And also, the proposed system shows better accuracy compare to other intrusion detection models.},
  archive      = {J_NCA},
  author       = {Rajadurai, Hariharan and Gandhi, Usha Devi},
  doi          = {10.1007/s00521-020-04986-5},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15387-15395},
  shortjournal = {Neural Comput. Appl.},
  title        = {A stacked ensemble learning model for intrusion detection in wireless network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bike sharing usage prediction with deep learning: A survey.
<em>NCA</em>, <em>34</em>(18), 15369–15385. (<a
href="https://doi.org/10.1007/s00521-022-07380-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a representative of shared mobility, bike sharing has become a green and convenient way to travel in cities in recent years. Bike usage prediction becomes more important for supporting efficient operation and management in bike share systems as the basis of inventory management and bike rebalancing. The essential of usage prediction in bike sharing systems is to model the spatial interactions of nearby stations, the temporal dependence of demands, and the impacts of environmental and societal factors. Deep learning has shown a great advantage of making a precise prediction for bike sharing usage. Recurrent neural networks capture the temporal dependence with the memory cell and gate mechanisms. Convolutional neural networks and graph neural networks learn spatial interactions of nearby stations with local convolutional operations defined for the grid-format and graph-format inputs respectively. In this survey, the latest studies about bike sharing usage prediction with deep learning are reviewed, with a classification for the prediction problems and models. Different applications based on bike usage prediction are discussed, both within and beyond bike share systems. Some research directions are pointed out to encourage future research. To the best of our knowledge, this paper is the first comprehensive survey that focuses on bike sharing usage prediction with deep learning techniques.},
  archive      = {J_NCA},
  author       = {Jiang, Weiwei},
  doi          = {10.1007/s00521-022-07380-5},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15369-15385},
  shortjournal = {Neural Comput. Appl.},
  title        = {Bike sharing usage prediction with deep learning: A survey},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An automatic fire detection system based on deep
convolutional neural networks for low-power, resource-constrained
devices. <em>NCA</em>, <em>34</em>(18), 15349–15368. (<a
href="https://doi.org/10.1007/s00521-022-07467-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale fires have been increasingly reported in the news media. These events can cause a variety of irreversible damage, what encourages the search for effective solutions to prevent and fight fires. A promising solution is an automatic system based on computer vision capable of detecting fire in early stages, enabling rapid suppression to mitigate damage, minimizing combat and restoration costs. Currently, the most effective systems are typically based on convolutional neural networks (CNNs). However, these networks are computationally expensive and consume a large amount of memory, usually requiring graphics processing units to operate properly in emergency situations. Thus, we propose a CNN-based fire detector system suitable for low-power, resource-constrained devices. Our approach consists of training a deep detection network and then removing its less important convolutional filters in order to reduce its computational cost while trying to preserve its original performance. Through an investigation of different pruning techniques, our results show that we can reduce the computational cost by up to 83.60\% and the memory consumption by up to 83.86\% without degrading the system’s performance. A case study was performed on a Raspberry Pi 4 where the results demonstrate the viability of implementing our proposed system on a low-end device.},
  archive      = {J_NCA},
  author       = {de Venâncio, Pedro Vinícius A. B. and Lisboa, Adriano C. and Barbosa, Adriano V.},
  doi          = {10.1007/s00521-022-07467-z},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15349-15368},
  shortjournal = {Neural Comput. Appl.},
  title        = {An automatic fire detection system based on deep convolutional neural networks for low-power, resource-constrained devices},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning applications for COVID-19 outbreak
management. <em>NCA</em>, <em>34</em>(18), 15313–15348. (<a
href="https://doi.org/10.1007/s00521-022-07424-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the COVID-19 epidemic has resulted in millions of deaths and has impacted practically every area of human life. Several machine learning (ML) approaches are employed in the medical field in many applications, including detecting and monitoring patients, notably in COVID-19 management. Different medical imaging systems, such as computed tomography (CT) and X-ray, offer ML an excellent platform for combating the pandemic. Because of this need, a significant quantity of study has been carried out; thus, in this work, we employed a systematic literature review (SLR) to cover all aspects of outcomes from related papers. Imaging methods, survival analysis, forecasting, economic and geographical issues, monitoring methods, medication development, and hybrid apps are the seven key uses of applications employed in the COVID-19 pandemic. Conventional neural networks (CNNs), long short-term memory networks (LSTM), recurrent neural networks (RNNs), generative adversarial networks (GANs), autoencoders, random forest, and other ML techniques are frequently used in such scenarios. Next, cutting-edge applications related to ML techniques for pandemic medical issues are discussed. Various problems and challenges linked with ML applications for this pandemic were reviewed. It is expected that additional research will be conducted in the upcoming to limit the spread and catastrophe management. According to the data, most papers are evaluated mainly on characteristics such as flexibility and accuracy, while other factors such as safety are overlooked. Also, Keras was the most often used library in the research studied, accounting for 24.4 percent of the time. Furthermore, medical imaging systems are employed for diagnostic reasons in 20.4 percent of applications.},
  archive      = {J_NCA},
  author       = {Heidari, Arash and Jafari Navimipour, Nima and Unal, Mehmet and Toumaj, Shiva},
  doi          = {10.1007/s00521-022-07424-w},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15313-15348},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning applications for COVID-19 outbreak management},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Delve into balanced and accurate approaches for ship
detection in aerial images. <em>NCA</em>, <em>34</em>(18), 15293–15312.
(<a href="https://doi.org/10.1007/s00521-021-06275-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ship detection in aerial images is a challenging task compared with generic object detection, mainly due to the three reasons: expensive and lack of aerial datasets, imbalance problems caused by scale variation and small objects, scarce feature representation brought by particular perspectives in aerial images. In this paper, we propose four methods for mitigating the problems above. First, we use the virtual 3D engine to create scenes with ship objects and annotate the collected images with bounding boxes automatically to generate the synthetic ship detection dataset, called unreal-ship. Second, we adopt a more balanced feature fusion structure Balanced Feature Pyramids (BFP), integrating and strengthening the features from each pyramid to obtain high-level and low-level information to reduce the imbalance problems of feature levels. Then we design an efficient anchor generation structure Guided Anchor, utilizing the semantic information to guide and generate high-quality anchors. Last, we adopt the IoU-based sampling method to reduce the uneven distribution of examples’ IoUs caused by random sampling. Our experiments prove that our ship object detection tasks will profit from the synthetic dataset by adding the synthetic dataset as additional data. Without bells and whistles, the structures, including BFP, Guided Anchor, and IoU-based sampling, achieve 2.5 points, 1.8 points, and 1.3 points Average Precision (AP) higher than our baseline algorithm, respectively. All the three structures promote an average of over 4 points AP. Extensive experiments on different backbones show that our methods achieve state-of-the-art performance compared with the remarkable detection frameworks and perform well in our detection models with different backbone networks.},
  archive      = {J_NCA},
  author       = {He, Boyong and Huang, Bo and Shen, Yue and Wu, Liaoni},
  doi          = {10.1007/s00521-021-06275-1},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15293-15312},
  shortjournal = {Neural Comput. Appl.},
  title        = {Delve into balanced and accurate approaches for ship detection in aerial images},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-intrusive load monitoring algorithm based on household
electricity use habits. <em>NCA</em>, <em>34</em>(18), 15273–15291. (<a
href="https://doi.org/10.1007/s00521-021-06088-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction of smart grid is an important part of improving the utilization rate of electric energy. As an important way for the construction of smart grid, non-intrusive load decomposition methods have been extensively studied. In this type of method, limited by transmission cost and network bandwidth, low-frequency data has been widely used in practical applications. However, the accuracy of device identification in this case faces challenges. Due to the relatively single characteristics of low-frequency data, it is difficult to express the operating status of complex electrical appliances, resulting in low decomposition performance. In this paper, a non-intrusive load is proposed based on household electrical habits by studying the relationship between household electricity consumption habits and load status decomposition method. The Gaussian mixture model and time information are used to model the probability distribution of the electrical appliance state. This probability distribution is then used as the observation probability distribution of the factor hidden Markov model. In such a way, the BH-FHMM model is proposed. Finally, load decomposition is carried out through the load decomposition process of the FHMM model. In order to verify the performance of the proposed method, an experimental comparison is conducted based on the REDD data set. According to the results, a significant improvement in equipment recognition accuracy is obtained.},
  archive      = {J_NCA},
  author       = {Yin, Bo and Li, Zhenhuan and Xu, Jiali and Li, Lin and Yang, Xinghai and Du, Zehua},
  doi          = {10.1007/s00521-021-06088-2},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15273-15291},
  shortjournal = {Neural Comput. Appl.},
  title        = {Non-intrusive load monitoring algorithm based on household electricity use habits},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An integrated cyber security risk management framework and
risk predication for the critical infrastructure protection.
<em>NCA</em>, <em>34</em>(18), 15241–15271. (<a
href="https://doi.org/10.1007/s00521-022-06959-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber security risk management plays an important role for today’s businesses due to the rapidly changing threat landscape and the existence of evolving sophisticated cyber attacks. It is necessary for organisations, of any size, but in particular those that are associated with a critical infrastructure, to understand the risks, so that suitable controls can be taken for the overall business continuity and critical service delivery. There are a number of works that aim to develop systematic processes for risk assessment and management. However, the existing works have limited input from threat intelligence properties and evolving attack trends, resulting in limited contextual information related to cyber security risks. This creates a challenge, especially in the context of critical infrastructures, since attacks have evolved from technical to socio-technical and protecting against them requires such contextual information. This research proposes a novel integrated cyber security risk management (i-CSRM) framework that responds to that challenge by supporting systematic identification of critical assets through the use of a decision support mechanism built on fuzzy set theory, by predicting risk types through machine learning techniques, and by assessing the effectiveness of existing controls. The framework is composed of a language, a process, and it is supported by an automated tool. The paper also reports on the evaluation of our work to a real case study of a critical infrastructure. The results reveal that using the fuzzy set theory in assessing assets&#39; criticality, our work supports stakeholders towards an effective risk management by assessing each asset&#39;s criticality. Furthermore, the results have demonstrated the machine learning classifiers’ exemplary performance to predict different risk types including denial of service, cyber espionage and crimeware.},
  archive      = {J_NCA},
  author       = {Kure, Halima Ibrahim and Islam, Shareeful and Mouratidis, Haralambos},
  doi          = {10.1007/s00521-022-06959-2},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15241-15271},
  shortjournal = {Neural Comput. Appl.},
  title        = {An integrated cyber security risk management framework and risk predication for the critical infrastructure protection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pipeline risk big data intelligent decision-making system
based on machine learning and situation awareness. <em>NCA</em>,
<em>34</em>(18), 15221–15239. (<a
href="https://doi.org/10.1007/s00521-021-06738-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underground pipelines are an indispensable part of urban public facilities. However, the frequent occurrence of pipeline accidents in recent years has not only brought great inconvenience to people’s lives, but also affected people’s lives and property safety to a certain extent. Therefore, timely treatment and treatment are very important. Preventing sudden underground pipeline accidents plays an important role in improving urban livability. This article studies pipeline risk big data intelligent decision-making systems based on machine learning and situational awareness. In this paper, by analyzing the application scope of gas leakage and diffusion models under different modes, leakage, diffusion, fire and explosion models are determined, and a combined model framework of leakage accident consequence system analysis is formed. The system uses the pipeline failure probability model and the pipeline failure consequence analysis model to determine the pipeline failure probability, the probability and the consequences of each accident; it uses the spatial analysis ability of GIS technology to determine the accident impact area and displays the impact area in graphics form. Through the effect verification of the test set, the prediction result of the SVR model based on the grid search parameter, the relative percentage error of the predicted value of each sample and the true value fluctuate is in the range of 4\%-36\%, and the amplitude is not very large. Most of the error values are approximately 13.56\% of the MAPE value. The results show that the optimization method using grid search parameters can have better prediction performances.},
  archive      = {J_NCA},
  author       = {Zhong, Xiong and Zhang, Xinsheng and Zhang, Ping},
  doi          = {10.1007/s00521-021-06738-5},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15221-15239},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pipeline risk big data intelligent decision-making system based on machine learning and situation awareness},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variational restricted boltzmann machines to automated
anomaly detection. <em>NCA</em>, <em>34</em>(18), 15207–15220. (<a
href="https://doi.org/10.1007/s00521-022-07060-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven methods are implemented using particularly complex scenarios that reflect in-depth perennial knowledge and research. Hence, the available intelligent algorithms are completely dependent on the quality of the available data. This is not possible for real-time applications, due to the nature of the data and the computational cost that is required. This work introduces an Automatic Differentiation Variational Inference (ADVI) Restricted Boltzmann Machine (RBM) to perform real-time anomaly detection of industrial infrastructure. Using the ADVI methodology, local variables are automatically transformed into real coordinate space. This is an innovative algorithm that optimizes its parameters with mathematical methods by choosing an approach that is a function of the transformed variables. The ADVI RBM approach proposed herein identifies anomalies without the need for prior training and without the need to find a detailed solution, thus making the whole task computationally feasible.},
  archive      = {J_NCA},
  author       = {Demertzis, Konstantinos and Iliadis, Lazaros and Pimenidis, Elias and Kikiras, Panagiotis},
  doi          = {10.1007/s00521-022-07060-4},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15207-15220},
  shortjournal = {Neural Comput. Appl.},
  title        = {Variational restricted boltzmann machines to automated anomaly detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning from data streams for automation and orchestration
of 6G industrial IoT: Toward a semantic communication framework.
<em>NCA</em>, <em>34</em>(18), 15197–15206. (<a
href="https://doi.org/10.1007/s00521-022-07065-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Established methods of communication are based mainly on Shannon’s theory of information, which purposefully overlooks semantic elements of communication. The future wireless technology should promise to facilitate many services, based on content, needs, and semantics, precisely customized to network capabilities. This gave rise to significant concern for Semantic Communication (SC), a novel paradigm considering the message’s meaning during transmission. Federated learning (FL) and Asynchronous Advantage Actor Critic (A3C) are the two emerging distributed and artificially intelligent approaches that provide diverse and possibly massive network coverage for data-driven SC solutions of industry 4.0 automation. Although SC is still in an early development stage, FL-empowered architecture has been recognized as one of the most promising solutions to meet the ubiquitous intelligence in the anticipated sixth-generation (6G) networks. This paper identifies industry 4.0 automation needs that drive the convergence of artificial intelligence and 6G for learning from data streams. We develop a novel SC framework based on the FL and A3C networks and discuss its potential along with transfer learning to address most of the new difficulties anticipated in 6G for industrial communication networks. Our proposed framework has been evaluated with extensive simulation results.},
  archive      = {J_NCA},
  author       = {Pokhrel, Shiva Raj},
  doi          = {10.1007/s00521-022-07065-z},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15197-15206},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning from data streams for automation and orchestration of 6G industrial IoT: Toward a semantic communication framework},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DFE: Efficient IoT network intrusion detection using deep
feature extraction. <em>NCA</em>, <em>34</em>(18), 15175–15195. (<a
href="https://doi.org/10.1007/s00521-021-06826-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the Internet of Things (IoT) has received a lot of attention. It has been used in many applications such as the control industry, industrial plants, and medicine. In this regard, a fundamental necessity is to implement security in IoT. To this end, Network intrusion detection systems (NIDSs) have been recently in the detection of network attacks and threats. Currently, these systems use a variety of deep learning (DL) models such as the convolutional neural networks to improve the detection of attacks. However, almost all current DL-based NIDSs are made up of many layers, and therefore, they need a lot of processing resources because of their high number of parameters. On the other hand, due to the lack of processing resources, such inefficient DL models are unusable in IoT devices. This paper presents a very accurate NIDS that is named DFE, and it uses a very lightweight and efficient neural network based on the idea of deep feature extraction. In this model, the input vector of the network is permuted in a 3D space, and its individual values are brought close together. This allows the model to extract highly discriminative features using a small number of layers without the need to use large 2D or 3D convolution filters. As a result, the network can achieve an accurate classification using a significantly small number of required calculations. This makes the DFE ideal for real-time intrusion detection by IoT devices with limited processing capabilities. The efficacy of the DFE has been evaluated using three popular public datasets named UNSW-NB15, CICIDS2017, and KDDCup99, and the results show the superiority of the proposed model over the state-of-the-art algorithms},
  archive      = {J_NCA},
  author       = {Basati, Amir and Faghih, Mohammad Mehdi},
  doi          = {10.1007/s00521-021-06826-6},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15175-15195},
  shortjournal = {Neural Comput. Appl.},
  title        = {DFE: Efficient IoT network intrusion detection using deep feature extraction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HamDroid: Permission-based harmful android anti-malware
detection using neural networks. <em>NCA</em>, <em>34</em>(18),
15165–15174. (<a
href="https://doi.org/10.1007/s00521-021-06755-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Android platforms are a popular target for attackers, while many users around the world are victims of Android malwares threatening their private information. Numerous Android anti-malware applications are fake and do not work as advertised because they have been developed either by amateur programmers or by software companies that are not focused on the security aspects of the business. Such applications usually ask for and generally receive non-necessary permissions which at the end collect sensitive information. The rapidly developing fake anti-malware is a serious problem, and there is a need for detection of harmful Android anti-malware. This article delivers a dataset of Android anti-malware, including malicious or benign, and a customized multilayer perceptron neural network that is being used to detect anti-malware based on the permissions of the applications. The results show that the proposed method can detect with very high accuracy fake anti-malware, while it outperforms other standard classifiers in terms of accuracy, precision, and recall.},
  archive      = {J_NCA},
  author       = {Seraj, Saeed and Khodambashi, Siavash and Pavlidis, Michalis and Polatidis, Nikolaos},
  doi          = {10.1007/s00521-021-06755-4},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15165-15174},
  shortjournal = {Neural Comput. Appl.},
  title        = {HamDroid: Permission-based harmful android anti-malware detection using neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting and responding to hostile disinformation
activities on social media using machine learning and deep neural
networks. <em>NCA</em>, <em>34</em>(18), 15141–15163. (<a
href="https://doi.org/10.1007/s00521-022-07296-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disinformation attacks that make use of social media platforms, e.g., the attacks orchestrated by the Russian “Internet Research Agency” during the 2016 U.S. Presidential election campaign and the 2016 Brexit referendum in the UK, have led to increasing demands from governmental agencies for AI tools that are capable of identifying such attacks in their earliest stages, rather than responding to them in retrospect. This research undertaken on behalf of the Canadian Armed Forces and Department of National Defence. Our ultimate objective is the development of an integrated set of machine-learning algorithms which will mobilize artificial intelligence to identify hostile disinformation activities in “near-real-time.” Employing The Dark Crawler, the Posit Toolkit, TensorFlow (Deep Neural Networks), plus the Random Forest classifier and short-text classification programs known as LibShortText and LibLinear, we have analysed a wide sample of social media posts that exemplify the “fake news” that was disseminated by Russia’s Internet Research Agency, comparing them to “real news” posts in order to develop an automated means of classification.},
  archive      = {J_NCA},
  author       = {Cartwright, Barry and Frank, Richard and Weir, George and Padda, Karmvir},
  doi          = {10.1007/s00521-022-07296-0},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15141-15163},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detecting and responding to hostile disinformation activities on social media using machine learning and deep neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CanarDeep: A hybrid deep neural model with mixed fusion for
rumour detection in social data streams. <em>NCA</em>, <em>34</em>(18),
15129–15140. (<a
href="https://doi.org/10.1007/s00521-021-06743-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unrelenting trend of doctored narratives, content spamming, fake news and rumour dissemination on social media can lead to grave consequences that range from online intimidating and trolling to lynching and riots in real- life. It has therefore become vital to use computational techniques that can detect rumours, do fact-checking and inhibit its amplification. In this paper, we put forward a model for rumour detection in streaming data on social platforms. The proposed CanarDeep model is a hybrid deep neural model that combines the predictions of a hierarchical attention network (HAN) and a multi-layer perceptron (MLP) learned using context-based (text + meta-features) and user-based features, respectively. The concatenated context feature vector is generated using feature-level fusion strategy to train HAN. Eventually, a decision-level late fusion strategy using logical OR combines the individual classifier prediction and outputs the final label as rumour or non-rumour. The results demonstrate improved performance to the existing state-of-the-art approach on the benchmark PHEME dataset with a 4.45\% gain in F1-score. The model can facilitate well-time intervention and curtail the risk of widespread rumours in streaming social media by raising an alert to the moderators.},
  archive      = {J_NCA},
  author       = {Jain, Deepak Kumar and Kumar, Akshi and Shrivastava, Akshat},
  doi          = {10.1007/s00521-021-06743-8},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15129-15140},
  shortjournal = {Neural Comput. Appl.},
  title        = {CanarDeep: A hybrid deep neural model with mixed fusion for rumour detection in social data streams},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). C-ANN: A deep leaning model for detecting black-marketed
colluders in twitter social network. <em>NCA</em>, <em>34</em>(18),
15113–15127. (<a
href="https://doi.org/10.1007/s00521-021-06756-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twitter social media has been emerging as one of the most admired channels for sharing news and opinions. A tweet once posted becomes noteworthy after it gets a high number of positive responses from other people in the form of retweets sharing the same medium. The number of retweets a tweet gets is an alternative metric for positive affirmations received from the crowd-sourced medium. The rise in the number of retweets helps in not making a topic trending but also helps the tweet getting broadcasted. Similarly, a high number of followers gained by a user increases his social presence in the online ecosystem. Both these metrics influence the popularity of the user to a great extent. Users who are interested in bolstering their tweets contact merchants of black-marketing services and become part of this dark web community. They get engaged in these collusive activities to get a high number of followers or retweets instantly. These users are genuine, showing a blend of human and automated behavior. In our proposed collusion defection model, C-ANN, we have attempted to build a framework that can detect collusive users with a maximum accuracy of 94\% using multiple basic and derived attributes based on user profile and activity.},
  archive      = {J_NCA},
  author       = {Gera, Suruchi and Sinha, Adwitiya},
  doi          = {10.1007/s00521-021-06756-3},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15113-15127},
  shortjournal = {Neural Comput. Appl.},
  title        = {C-ANN: A deep leaning model for detecting black-marketed colluders in twitter social network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mitigation of black hole attacks using firefly and
artificial neural network. <em>NCA</em>, <em>34</em>(18), 15101–15111.
(<a href="https://doi.org/10.1007/s00521-022-06946-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Mobile Ad hoc Network (MANET), network topology changes as devices/users/nodes move and nodes can serve as a source, destination, or router for the information. One of the challenging tasks in MANET is secure routing because of the change of network topology, open nature of wireless communications and frequent breakage in communication links. Thus, it is critically important to develop a robust and secure routing protocol for sending data from the source to the destination in MANET. In this paper, we investigate black hole attacks where compromised nodes utilize routing protocols for self-exposing which has the shortest route for data forwarding to the destination node. Specifically, the proposed approach enhances the Ad hoc On-Demand Distance Vector routing protocol for combating black hole attacks by leveraging the Firefly Algorithm with Artificial Neural Network. Performance evaluation is carried out using numerical results obtained from several experiments and considering different metrics such as computation overhead, packet delivery rate, throughput and delay. Numerical results show that the proposed approach outperforms the traditional approaches.},
  archive      = {J_NCA},
  author       = {Rani, Pooja and Kavita and Verma, Sahil and Rawat, Danda B. and Dash, Sonali},
  doi          = {10.1007/s00521-022-06946-7},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15101-15111},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mitigation of black hole attacks using firefly and artificial neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on large-scale neural computing and
cybersecurity opportunities using artificial intelligence. <em>NCA</em>,
<em>34</em>(18), 15099–15100. (<a
href="https://doi.org/10.1007/s00521-022-07535-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Tyagi, Sumarga Kumar Sah and Pimenidis, Elias and Jain, Sanjeev and Serrano, Will},
  doi          = {10.1007/s00521-022-07535-4},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {15099-15100},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on large-scale neural computing and cybersecurity opportunities using artificial intelligence},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A cross-and-dot-product neural network based filtering for
maneuvering-target tracking. <em>NCA</em>, <em>34</em>(17), 14929–14944.
(<a href="https://doi.org/10.1007/s00521-022-07338-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maneuvering-target tracking is a critical topic for target tracking. However, suffering from unknown and changeable target movements, tracking performance of common algorithms still leaves large rooms for improvement. Recently, neural network-based algorithms are proposed to greatly improve the tracking performance, while their generalization ability remains a problem. That is, when the target states distribute beyond the range of training set, their tracking errors will dramatically increase. To conquer this problem, this paper proposes a Cross-and-Dot-Product neural network based filtering algorithm. Specifically, a network is designed to estimate transition matrices with turn rate information of moving targets by calculating the cross-product and dot-product data. Thereby, our network can correctly understand the maneuvering-target movements as real-time constant turn models, instead of a database-limited end-to-end mapping. Furthermore, an adaptive probability allocation method is designed to form a double-channel filtering algorithm. The proposed algorithm derives the final tracking results by fusing the states from two unscented Kalman filters together: one filter is based on the constant velocity model, and the other is based on the model with the transition matrices estimated by network. The simulation results verify that the proposed algorithm outperforms other state-of-the-art algorithms both in tracking performance and generalization ability.},
  archive      = {J_NCA},
  author       = {Liu, Jingxian and Yang, Shuhong and Yang, Fan},
  doi          = {10.1007/s00521-022-07338-7},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14929-14944},
  shortjournal = {Neural Comput. Appl.},
  title        = {A cross-and-dot-product neural network based filtering for maneuvering-target tracking},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of predictive models of asphalt pavement
distresses in idaho through gene expression programming. <em>NCA</em>,
<em>34</em>(17), 14913–14927. (<a
href="https://doi.org/10.1007/s00521-022-07305-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Good predictive models should feature the capability of obtaining accurate results through easy and accessible methods in a timely manner. Following a “golden triangle” connecting the accuracy, complexity and applicability of each model, this work employed gene expression programming (GEP) algorithm to develop models for four typical distresses of asphalt pavements in the state of Idaho, respectively. The models developed in this work retain and combine advantages of empirical models and machine learning models and thus serve as promising alternatives to mechanistic–empirical (ME) models. Models with explicit forms were selected and calibrated by GEP, in an intelligent and automatic way. This work also proposes a variable selection method featuring principal component analysis coupled with correlation analysis, and this method was utilized in data pre-processing for construction of simple models with precise model form. Furthermore, this work introduces a systematic and comprehensive approach to evaluation of model accuracy, robustness and sensitivity, based on various statistical methods. Compared with regression models and ME models, the models generated by GEP achieved higher and more stable accuracy. Finally, we present the trade-off between model accuracy and rationality and point out the importance and necessity of reaching a balance in the golden triangle.},
  archive      = {J_NCA},
  author       = {Deng, Yong and Shi, Xianming},
  doi          = {10.1007/s00521-022-07305-2},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14913-14927},
  shortjournal = {Neural Comput. Appl.},
  title        = {Development of predictive models of asphalt pavement distresses in idaho through gene expression programming},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assessing cloud QoS predictions using OWA in neural network
methods. <em>NCA</em>, <em>34</em>(17), 14895–14912. (<a
href="https://doi.org/10.1007/s00521-022-07297-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality of Service (QoS) is the key parameter to measure the overall performance of service-oriented applications. In a myriad of web services, the QoS data has multiple highly sparse and enormous dimensions. It is a great challenge to reduce computational complexity by reducing data dimensions without losing information to predict QoS for future intervals. This paper uses an Induced Ordered Weighted Average (IOWA) layer in the prediction layer to lessen the size of a dataset and analyse the prediction accuracy of cloud QoS data. The approach enables stakeholders to manage extensive QoS data better and handle complex nonlinear predictions. The paper evaluates the cloud QoS prediction using an IOWA operator with nine neural network methods—Cascade-forward backpropagation, Elman backpropagation, Feedforward backpropagation, Generalised regression, NARX, Layer recurrent, LSTM, GRU and LSTM-GRU. The paper compares results using RMSE, MAE, and MAPE to measure prediction accuracy as a benchmark. A total of 2016 QoS data are extracted from Amazon EC2 US-West instance to predict future 96 intervals. The analysis results show that the approach significantly decreases the data size by 66\%, from 2016 to 672 records with improved or equal accuracy. The case study demonstrates the approach&#39;s effectiveness while handling complexity, reducing data dimension with better prediction accuracy.},
  archive      = {J_NCA},
  author       = {Hussain, Walayat and Gao, Honghao and Raza, Muhammad Raheel and Rabhi, Fethi A. and Merigó, Jose M.},
  doi          = {10.1007/s00521-022-07297-z},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14895-14912},
  shortjournal = {Neural Comput. Appl.},
  title        = {Assessing cloud QoS predictions using OWA in neural network methods},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Refined marine object detector with attention-based spatial
pyramid pooling networks and bidirectional feature fusion strategy.
<em>NCA</em>, <em>34</em>(17), 14881–14894. (<a
href="https://doi.org/10.1007/s00521-022-07264-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marine object detection has become increasingly important in intelligent underwater robot. Because of color cast and blur in underwater images, features directly extracted from backbone networks usually lack interesting and discriminative characters, that affects performance on marine object detection. To this end, this paper proposes a novel refined marine object detector with attention-based spatial pyramid pooling networks and bidirectional feature fusion strategy to relieve the weakening of features and address marine object detection issues. Firstly, an attention-based spatial pyramid pooling network named as SA-SPPN is proposed to enrich interesting information and extend receptive field on original features extracted from backbone network. Based on enhanced multiple level features, the bidirectional feature fusion strategy is designed to fuse different level features and generate robust feature maps for detection. Specifically, the top-down connection could transfer semantic information from high-level features to enhance low-level features. The bottom-up pathway could extend resolution of high-level features. Furthermore, the cross-layer connections are integrated into both top-down passway and bottom-up passway to carry out multiple branch fusion. On bounding boxes regression phase, the distance-IoU loss is adopted to improve regression speed and accuracy. Finally, this paper conducts series experiments on underwater image datasets and URPC datasets to detect marine objects. The experimental results reveal that our approach could achieve impressive performance and reach 79.64\% mAP on underwater image datasets, 79.31\% mAP on URPC2019 datasets and 79.93\% mAP on URPC2020 datasets, respectively. For standard object detection, the proposed algorithm also could realize notable performance and get 81.9\% mAP on PASCAL VOC datasets.},
  archive      = {J_NCA},
  author       = {Xu, Fengqiang and Wang, Huibing and Sun, Xudong and Fu, Xianping},
  doi          = {10.1007/s00521-022-07264-8},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14881-14894},
  shortjournal = {Neural Comput. Appl.},
  title        = {Refined marine object detector with attention-based spatial pyramid pooling networks and bidirectional feature fusion strategy},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Who are the “silent spreaders”?: Contact tracing in
spatio-temporal memory models. <em>NCA</em>, <em>34</em>(17),
14859–14879. (<a
href="https://doi.org/10.1007/s00521-022-07210-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 epidemic has swept the world for over two years. However, a large number of infectious asymptomatic COVID-19 cases (ACCs) are still making the breaking up of the transmission chains very difficult. Efforts by epidemiological researchers in many countries have thrown light on the clinical features of ACCs, but there is still a lack of practical approaches to detect ACCs so as to help contain the pandemic. To address the issue of ACCs, this paper presents a neural network model called Spatio-Temporal Episodic Memory for COVID-19 (STEM-COVID) to identify ACCs from contact tracing data. Based on the fusion Adaptive Resonance Theory (ART), the model encodes a collective spatio-temporal episodic memory of individuals and incorporates an effective mechanism of parallel searches for ACCs. Specifically, the episodic traces of the identified positive cases are used to map out the episodic traces of suspected ACCs using a weighted evidence pooling method. To evaluate the efficacy of STEM-COVID, a realistic agent-based simulation model for COVID-19 spreading is implemented based on the recent epidemiological findings on ACCs. The experiments based on rigorous simulation scenarios, manifesting the current situation of COVID-19 spread, show that the STEM-COVID model with weighted evidence pooling has a higher level of accuracy and efficiency for identifying ACCs when compared with several baselines. Moreover, the model displays strong robustness against noisy data and different ACC proportions, which partially reflects the effect of breakthrough infections after vaccination on the virus transmission.},
  archive      = {J_NCA},
  author       = {Hu, Yue and Subagdja, Budhitama and Tan, Ah-Hwee and Quek, Chai and Yin, Quanjun},
  doi          = {10.1007/s00521-022-07210-8},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14859-14879},
  shortjournal = {Neural Comput. Appl.},
  title        = {Who are the ‘silent spreaders’?: Contact tracing in spatio-temporal memory models},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Perception-oriented single image super-resolution network
with receptive field block. <em>NCA</em>, <em>34</em>(17), 14845–14858.
(<a href="https://doi.org/10.1007/s00521-022-07341-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has been widely applied to single image super-resolution(SISR). However, the majority of deep learning methods employ the Mean Square Error(MSE) loss as the objective optimization function, and the generated results are frequently too smooth and lack of details. In addition, the high-frequency information of the reconstructed image is severely lost, resulting in a generated image with poor visual effects. In order to address the aforementioned issues, this paper proposes a super-resolution network (RRFDB-GAN) with a receptive field module with a generative adversarial network as the main framework. The network adopts the receptive field block (RFB), which enables it to extract the features in multiple scales and to improve the discriminability. In this paper, the Residual in Residual Dense Block (RRDB) and the Residual of Receptive Field Dense Block (RRFDB) are combined into a new module, called Basic block. This module enhances the capability of feature reconstruction for low-resolution images. During the upsampling stage, a combination of Nearest Neighborhood Interpolation and Sub-pixel convolution is used to reduce the computational complexity and provide additional contextual information for super-resolution reconstruction, while achieving satisfactory performance. Finally, the four Basic blocks are integrated with the upsampling module into a simple end-to-end framework. Extensive experimental results demonstrate that the proposed method in this paper shows more details on the five test sets and outperforms other methods in terms of quantitative metrics and perception assessment.},
  archive      = {J_NCA},
  author       = {Zhang, Wei and Hou, Yaqing and Fan, Wanshu and Yang, Xin and Zhou, Dongsheng and Zhang, Qiang and Wei, Xiaopeng},
  doi          = {10.1007/s00521-022-07341-y},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14845-14858},
  shortjournal = {Neural Comput. Appl.},
  title        = {Perception-oriented single image super-resolution network with receptive field block},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An empirical study of low-resource neural machine
translation of manipuri in multilingual settings. <em>NCA</em>,
<em>34</em>(17), 14823–14844. (<a
href="https://doi.org/10.1007/s00521-022-07337-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine translation requires a large amount of parallel data for a production level of translation quality. This is one of the significant factors behind the lack of machine translation systems for most spoken/written languages. Likewise, Manipuri is a low resource Indian language, and there is very little digital textual available data for the same. In this work, we attempt to address the low resource neural machine translation for Manipuri and English using other Indian languages in a multilingual setup. We train an LSTM based many-to-many multilingual neural machine translation system that is infused with cross-lingual features. Experimental results show that our method improves over the vanilla many-to-many multilingual and bilingual baselines for both Manipuri to/from English translation tasks. Furthermore, our method also improves over the vanilla many-to-many multilingual system for the translation task of all the other Indian languages to/from English. We also examine the generalizability of our multilingual model by evaluating the translation among the language pairs which do not have a direct link via the zero-shot translation and compare it against the pivot-based translation.},
  archive      = {J_NCA},
  author       = {Singh, Salam Michael and Singh, Thoudam Doren},
  doi          = {10.1007/s00521-022-07337-8},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14823-14844},
  shortjournal = {Neural Comput. Appl.},
  title        = {An empirical study of low-resource neural machine translation of manipuri in multilingual settings},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A scaling calculus for the design and initialization of ReLU
networks. <em>NCA</em>, <em>34</em>(17), 14807–14821. (<a
href="https://doi.org/10.1007/s00521-022-07308-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a system for calculating a “scaling constant” for layers and weights of neural networks. We relate this scaling constant to two important quantities that relate to the optimizability of neural networks, and argue that a network that is “preconditioned” via scaling, in the sense that all weights have the same scaling constant, will be easier to train. This scaling calculus results in a number of consequences, among them the fact that the geometric mean of the fan-in and fan-out, rather than the fan-in, fan-out, or arithmetic mean, should be used for the initialization of the variance of weights in a neural network. Our system allows for the off-line design &amp; engineering of ReLU (Rectified Linear Unit) neural networks, potentially replacing blind experimentation. We verify the effectiveness of our approach on a set of benchmark problems.},
  archive      = {J_NCA},
  author       = {Defazio, Aaron and Bottou, Léon},
  doi          = {10.1007/s00521-022-07308-z},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14807-14821},
  shortjournal = {Neural Comput. Appl.},
  title        = {A scaling calculus for the design and initialization of ReLU networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Determination of the number of components in the PARAFAC
model with a nonnegative tensor structure: A simulated EEG data study.
<em>NCA</em>, <em>34</em>(17), 14793–14805. (<a
href="https://doi.org/10.1007/s00521-022-07318-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parallel factor analysis (PARAFAC) is a powerful tool for detecting latent components in human electroencephalogram (EEG) in the time-space-frequency domain. As an essential parameter, the number of latent components should be set in advance. However, any component number selection method already proposed in the literature became a rule of thumb. Existing studies have demonstrated the methods’ performance on artificial data with a simplified structure, often not mimicking a real data character. On the other hand, the ground-truth latent structure is not always known for real-world data. With the objective to provide a comprehensive overview of component number selection methods and discuss their applicability to EEG, our study focuses on nontrivial and nonnegative simulated data structures resembling real EEG properties as closely as possible. This is achieved through an accurate head model and well-controlled cortical activation sources. By considering different noise levels and disruptions from the optimal structure, the performance of the twelve component number selection methods is closely inspected. Moreover, we validate a new approach for component number selection, which we recently proposed and applied to EEG tasks. We found that methods based on the eigenvalue analysis, variance explained, or presence of redundant components are inappropriate for component number selection in EEG tensor decomposition. On the other hand, three existing methods and the newly proposed approach produced promising results on nontrivial simulated EEG data. Nevertheless, component number selection for PARAFAC analysis of EEG is a complex yet unresolved problem, and new approaches are needed.},
  archive      = {J_NCA},
  author       = {Rošťáková, Zuzana and Rosipal, Roman},
  doi          = {10.1007/s00521-022-07318-x},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14793-14805},
  shortjournal = {Neural Comput. Appl.},
  title        = {Determination of the number of components in the PARAFAC model with a nonnegative tensor structure: A simulated EEG data study},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 4D-GWR: Geographically, altitudinal, and temporally weighted
regression. <em>NCA</em>, <em>34</em>(17), 14777–14791. (<a
href="https://doi.org/10.1007/s00521-022-07311-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geographically weighted regression (GWR) models varying relationships and is a local spatial regression approach. It has been used in several application domains, such as meteorology, environmental management, ecology, etc. The datasets collected in these applications include spatial (latitude, longitude), altitudinal, and temporal nonstationarities and so the values of parameters that are found in such datasets change over space and time. In the literature, several GWR models have been proposed to handle such datasets. However, these methods do not consider spatial, altitudinal, and temporal nonstationarity in the datasets simultaneously. This study deals with developing a GWR technique, 4D-GWR, to capture spatial, altitudinal, and temporal nonstationarities to improve the prediction accuracy. In addition, a new parameter estimation strategy, which utilizes n-dimension golden section search algorithm, is proposed to estimate parameters of 4D-GWR approach. Experimental evaluations were conducted to compare the proposed 4D-GWR approach with the classical approaches of GWR (2D-GWR), GAWR, GTWR, and GWANN using real-time and synthetic meteorological datasets. The results showed that 4D-GWR approach outperforms other approaches in terms of RMSE between the predicted and actual air temperatures, runtime, and dataset size. Experiments showed that GWANN could not handle more than 15,000 observation points, 2D-GWR, GAWR, and GTWR could not handle more than 40,000 observation points and, in contrast, the 4D-GWR could handle all dataset sizes, successfully. When the actual and predicted air temperature values are compared, the highest correlation of 0.95 was obtained by 4D-GWR and the lowest correlation of 0.77 was obtained by GWANN.},
  archive      = {J_NCA},
  author       = {Tasyurek, Murat and Celik, Mete},
  doi          = {10.1007/s00521-022-07311-4},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14777-14791},
  shortjournal = {Neural Comput. Appl.},
  title        = {4D-GWR: Geographically, altitudinal, and temporally weighted regression},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Residential housing price index forecasting via neural
networks. <em>NCA</em>, <em>34</em>(17), 14763–14776. (<a
href="https://doi.org/10.1007/s00521-022-07309-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the past decade, the housing market in China has witnessed rapid growth and the significance of forecasting related to housing prices has undoubtedly elevated, which has become an important issue to the people in investment and policymakers in regulations. In this study, we explore neural networks for residential housing price index forecasts from ten major Chinese cities for July 2005–April 2021. We aim at constructing simple and accurate neural networks as a contribution to pure technical forecasts of the Chinese residential housing market. To facilitate the analysis, we investigate different model settings across algorithms, delays, hidden neurons, and data spitting ratios, and arrive at a simple neural network with three delays and three hidden neurons, which produces stable performance of about 0.75\% average relative root mean square error across the ten cities for the training, validation, and testing phases. Our results can be used on a standalone basis or combined with fundamental forecasts to form perspectives of residential housing price trends and carry out policy analysis.},
  archive      = {J_NCA},
  author       = {Xu, Xiaojie and Zhang, Yun},
  doi          = {10.1007/s00521-022-07309-y},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14763-14776},
  shortjournal = {Neural Comput. Appl.},
  title        = {Residential housing price index forecasting via neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A memristor-based circuit design and implementation for
blocking on pavlov associative memory. <em>NCA</em>, <em>34</em>(17),
14745–14761. (<a
href="https://doi.org/10.1007/s00521-022-07162-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional Pavlov associative memory circuit includes reinforcement and extinction in the classical conditioned reflex. In fact, in addition to the reinforcement and extinction, classical conditioned reflex is accompanied by several higher-order effects. The blocking process is a very common phenomenon in organisms, and it is one of the higher-order effects. In this paper, a circuit based on memristor is designed to realize blocking based on Pavlov’s associative memory. First of all, the circuit constructs a complete neural network circuit. The input neuron circuit composed of CMOS and other devices replaces the DC signal source and can generate pulse signals, making the circuit more bionic. Secondly, advanced neural activities such as learning memory, associative memory, and forgetting are realized. At the same time, the blocking process was realized on the basis of classical conditioned reflex, and the circuit successfully simulated the appearance and disappearance of the blocking phenomenon. Finally, the circuit simulation was carried out through PSPICE, and the simulation results proved the correctness of the circuit design.},
  archive      = {J_NCA},
  author       = {Du, Sichun and Deng, Qing and Hong, Qinghui and Li, Jun and Liu, Haiyang and Wang, Chunhua},
  doi          = {10.1007/s00521-022-07162-z},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14745-14761},
  shortjournal = {Neural Comput. Appl.},
  title        = {A memristor-based circuit design and implementation for blocking on pavlov associative memory},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Statistical analysis of blood characteristics of COVID-19
patients and their survival or death prediction using machine learning
algorithms. <em>NCA</em>, <em>34</em>(17), 14729–14743. (<a
href="https://doi.org/10.1007/s00521-022-07325-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study’s main purpose is to provide helpful information using blood samples from COVID-19 patients as a non-medical approach for helping healthcare systems during the pandemic. Also, this paper aims to evaluate machine learning algorithms for predicting the survival or death of COVID-19 patients. We use a blood sample dataset of 306 infected patients in Wuhan, China, compiled by Tangji Hospital. The dataset consists of blood’s clinical indicators and information about whether patients are recovering or not. The used methods include K-nearest neighbor (KNN), decision tree (DT), logistic regression (LR), support vector machine (SVM), random forest (RF), stochastic gradient descent (SGD), bagging classifier (BC), and adaptive boosting (AdaBoost). We compare the performance of machine learning algorithms using statistical hypothesis testing. The results show that the most critical feature is age, and there is a high correlation between LD and CRP, and leukocytes and CRP. Furthermore, RF, SVM, DT, AdaBoost, DT, and KNN outperform other machine learning algorithms in predicting the survival or death of COVID-19 patients.},
  archive      = {J_NCA},
  author       = {Mazloumi, Rahil and Abazari, Seyed Reza and Nafarieh, Farnaz and Aghsami, Amir and Jolai, Fariborz},
  doi          = {10.1007/s00521-022-07325-y},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14729-14743},
  shortjournal = {Neural Comput. Appl.},
  title        = {Statistical analysis of blood characteristics of COVID-19 patients and their survival or death prediction using machine learning algorithms},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Short-term prediction of culex quinquefasciatus abundance in
central north georgia, USA, based on the meteorological variability.
<em>NCA</em>, <em>34</em>(17), 14717–14728. (<a
href="https://doi.org/10.1007/s00521-022-07324-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Culex quinquefasciatus is the main vector of West Nile Virus (WNV) in the southeast USA, and inter-annual variation in this vector abundance is mainly related to meteorological variability. In this study, short-term effects of meteorological conditions on seasonal variation in the vector abundance in the central north part of the State of Georgia, USA, from 2002 to 2009 were assessed. Four weeks moving average temperature, precipitation, potential evapotranspiration, and available moisture in the surface layer of soil were considered as risk factors. Cross-correlation maps were developed to investigate influences of preceding environmental conditions during a time-lagged interval on mosquito count data. The Poisson regression model and Artificial Neural Network (ANN) model were used for prediction purposes. Two sets of predictors were used: (1) the interval lagged climate data with the highest correlation and (2) single time lag antecedent Culex mosquito abundance up to 10 weeks prior to the events combined with lagged climate data. Results revealed that both models predicted the seasonal cycle of vector abundance fairly accurately, with ANN performing better than the regression model. The addition of antecedent mosquito data as input improved the prediction power of both models. The developed predictive models can be helpful in informed decision-making when high WNV activities are anticipated.},
  archive      = {J_NCA},
  author       = {Noori, Navideh and Kalin, Latif and Lockaby, B. Graeme and Magori, Krisztian},
  doi          = {10.1007/s00521-022-07324-z},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14717-14728},
  shortjournal = {Neural Comput. Appl.},
  title        = {Short-term prediction of culex quinquefasciatus abundance in central north georgia, USA, based on the meteorological variability},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsteady mixed convective stagnation point flow of hybrid
nanofluid in porous medium. <em>NCA</em>, <em>34</em>(17), 14699–14715.
(<a href="https://doi.org/10.1007/s00521-022-07323-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new kind of heat transfer fluid called hybrid nanofluid was introduced to enhance the performance of heat exchangers. The flow behavior may be investigated numerically to better comprehend the fluid features. This investigation aspires to unravel the boundary layer flow problem near the stagnation point of unsteady hybrid nanofluid. Such fluid is saturated in a porous medium on a vertical plate with the exertion of mixed convection. The governing model of the flow problem in the form of partial differential equations is simplified into ordinary differential equations by incorporating the appropriate similarity transformation. A built-in finite difference code in MATLAB known as boundary value problem of fourth-order code (bvp4c) is employed to solve the flow problem and execute the numerical solutions. The dual solutions generated by the solver necessitate the implementation of stability analysis, where this analysis indicates only the first solution is stable. As per stable solution, the heat transfer is augmented when the volume concentration of copper is increasingly added to the alumina–water nanofluid suspension. The conversion of the fluid state from laminar to turbulent also can be prevented with the inclusion of a suitable higher volume concentration of copper. The higher value of the first and second resistant parameters due to porous media is considered in this investigation which concludes that these parameters aid in improving the heat transfer and skin friction rates. This investigation has proven hybrid nanofluid&#39;s ability to reinforce the heat transfer with the embedment of a porous medium.},
  archive      = {J_NCA},
  author       = {Wahid, Nur Syahirah and Arifin, Norihan Md and Khashi’ie, Najiyah Safwa and Pop, Ioan and Bachok, Norfifah and Hafidzuddin, Mohd Ezad Hafidz},
  doi          = {10.1007/s00521-022-07323-0},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14699-14715},
  shortjournal = {Neural Comput. Appl.},
  title        = {Unsteady mixed convective stagnation point flow of hybrid nanofluid in porous medium},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). VisPro: A prognostic SqueezeNet and non-stationary gaussian
process approach for remaining useful life prediction with uncertainty
quantification. <em>NCA</em>, <em>34</em>(17), 14683–14698. (<a
href="https://doi.org/10.1007/s00521-022-07316-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotating machinery is essential to modern life, from power generation to transportation and a host of other industrial applications. Since such equipment generally operates under challenging working conditions which can lead to untimely failures, accurate remaining useful life (RUL) prediction is essential for maintenance planning and prevention of catastrophic failures. In this work, we address current challenges in data-driven RUL prediction for rotating machinery. The challenges revolve around the accuracy and uncertainty quantification of the prediction, and the non-stationarity of the system degradation and RUL estimation given sensor data. We devise a novel computational architecture and RUL prediction model with uncertainty quantification, termed VisPro, which integrates time–frequency analysis, deep learning image recognition, and nonstationary Gaussian process regression. We analyze and benchmark the results obtained with our model against those of other advanced data-driven RUL prediction models using the PHM12 bearing vibration dataset. The computational experiments show that (1) the VisPro predictions are highly accurate and provide significant improvements over existing prediction models (three times more accurate than the second-best model), and (2) the RUL uncertainty bounds are valid and informative. We identify and discuss the architectural and modeling choices made that explain this predictive performance of VisPro.},
  archive      = {J_NCA},
  author       = {Xu, Zhaoyi and Guo, Yanjie and Saleh, Joseph Homer},
  doi          = {10.1007/s00521-022-07316-z},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14683-14698},
  shortjournal = {Neural Comput. Appl.},
  title        = {VisPro: A prognostic SqueezeNet and non-stationary gaussian process approach for remaining useful life prediction with uncertainty quantification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel meta-graph-based attention model for event
recommendation. <em>NCA</em>, <em>34</em>(17), 14659–14682. (<a
href="https://doi.org/10.1007/s00521-022-07301-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the popular trend of combining online and offline interactions among users in event-based social networks (EBSNs), event recommendation which helps users discover their interesting events has become progressively urgent. Different from classic item recommendation, candidate events usually have short life cycle and occur in the future, resulting in severe challenges of data sparsity and cold-start. However, these problems are not well studied by previous works. In this article, we propose a Meta-Graph-based Attention Recommendation (MGAR) model to tackle aforementioned challenges by fully exploring complex semantic information based on meta-graphs extracted from EBSNs. First, we model the interactions between different entities as a heterogeneous information network and construct multiple meta-graphs to characterize the latent semantic preferences of users. Subsequently, we utilize convolutional neural networks and attention mechanisms to learn user and event latent factors by extracting semantic features of meta-graphs. Furthermore, the fused latent features are utilized to predict the ratings of a user to events and the events with top-k scores are recommended to the user. We collect several real-world datasets from a popular EBSN platform and conduct extensive experiments on the datasets. Our proposed model attains superior recommendation performance over several state-of-the-art approaches. Moreover, the results demonstrate that meta-graphs can reveal the semantic properties between users and events and improve event recommendation performance.},
  archive      = {J_NCA},
  author       = {Jiang, Xiaolong and Sun, Heli and Zhang, Bo and He, Liang and Jia, Xiaolin},
  doi          = {10.1007/s00521-022-07301-6},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14659-14682},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel meta-graph-based attention model for event recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-strategy random weighted gray wolf optimizer-based
multi-layer perceptron model for short-term wind speed forecasting.
<em>NCA</em>, <em>34</em>(17), 14627–14657. (<a
href="https://doi.org/10.1007/s00521-022-07303-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gray wolf optimizer (GWO) that is one of the meta-heuristic optimization algorithms is principally based on the hunting method and social hierarchy of the gray wolves in the nature. This paper presents the Multi-strategy Random weighted Gray Wolf Optimizer (MsRwGWO) including some effective and novel mechanisms added to the original GWO algorithm to improve the search performance. These are a transition mechanism for updating the parameter $$\overrightarrow{a}$$ , a weighted updating mechanism, a mutation operator, a boundary checking mechanism, a greedy selection mechanism, and an updating mechanism of leader three wolves (alpha, beta, and delta wolves). We utilized some benchmark functions known as CEC 2014 test suite to evaluate the performance of MsRwGWO algorithm in this study. Firstly, during the solution of optimization problems, the MsRwGWO algorithm&#39;s behaviors such as convergence, search history, trajectory, and average distance were analyzed. Secondly, the comparison statistical results of MsRwGWO and GWO algorithms were presented for CEC 2014 benchmarks with 10, 30, and 50 dimensions. In addition, some of the popular meta-heuristic algorithms taken from the literature were compared with the proposed MsRwGWO algorithm for 30D CEC 2014 test problems. Finally, MsRwGWO algorithm was adapted to the training process of a Multi-Layer Perceptron (MLP) used in wind speed estimation and comparative results with GWO-based MLP were obtained. The statistical results of the benchmark problems and training performance of MLP model for short-term wind speed forecasting show that the proposed MsRwGWO algorithm has better performance than GWO algorithm. Source code of MsRwGWO is publicly available at https://github.com/uguryuzgec/MsRwGWO .},
  archive      = {J_NCA},
  author       = {İnaç, Tufan and Dokur, Emrah and Yüzgeç, Uğur},
  doi          = {10.1007/s00521-022-07303-4},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14627-14657},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-strategy random weighted gray wolf optimizer-based multi-layer perceptron model for short-term wind speed forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic fuzzy clustering for probability density functions
using the genetic algorithm. <em>NCA</em>, <em>34</em>(17), 14609–14625.
(<a href="https://doi.org/10.1007/s00521-022-07265-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the genetic algorithm, this study develops the new fuzzy clustering method for probability density functions (pdfs) with the important improvements. First, the $$L^1$$ -distance is proposed as the measure to evaluate the level similar of the pdfs. It is surveyed to find the bounds and established the methods to compute. Second, we propose the new objective for the genetic algorithm. This objective measures both the similarity of elements in each group and the quality of clustering. Finally, the operators such as crossover, mutation, and selection of the traditional genetic algorithm are improved. Combining these improvements, we have an efficient cluster analysis algorithm for pdfs. In this algorithm, the proper number of groups, the specific pdfs in each cluster, and the fuzzy relationship between the pdf to the established clusters are determined at the same time. The convergence of the proposed algorithm is proved by theory and performed by the established MATLAB program. The experiments and applications show superiority of the developed algorithm in comparing to the existing algorithms. The proposed algorithm is also applied in recognizing images to certify the feasibility and applicability of the studied problem.},
  archive      = {J_NCA},
  author       = {Phamtoan, Dinh and Vovan, Tai},
  doi          = {10.1007/s00521-022-07265-7},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14609-14625},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic fuzzy clustering for probability density functions using the genetic algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Memory-enhanced deep reinforcement learning for UAV
navigation in 3D environment. <em>NCA</em>, <em>34</em>(17),
14599–14607. (<a
href="https://doi.org/10.1007/s00521-022-07244-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a long-term challenging task to develop an intelligent agent that is able to navigate in 3D environment using only visual input in an end-to-end manner. In this paper, we introduce a goal-conditioned reinforcement learning framework for vision-based UAV navigation, and then develop a Memory Enhanced DRL agent with dynamic relative goal, extra action penalty and non-sparse reward to tackle the UAV navigation problem. This enables the agent to escape from the objective-obstacle dilemma. By performing experimental evaluations in high-fidelity visual environments simulated by Airsim, we show that our proposed memory-enhanced model can achieve higher success rate with less training steps compared to the DRL agents without memories.},
  archive      = {J_NCA},
  author       = {Fu, Chenchen and Xu, Xueyong and Zhang, Yuntao and Lyu, Yan and Xia, Yu and Zhou, Zining and Wu, Weiwei},
  doi          = {10.1007/s00521-022-07244-y},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14599-14607},
  shortjournal = {Neural Comput. Appl.},
  title        = {Memory-enhanced deep reinforcement learning for UAV navigation in 3D environment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sustainable project portfolio selection and optimization
with considerations of outsourcing decisions, financing options and
staff assignment under interval type-2 fuzzy uncertainty. <em>NCA</em>,
<em>34</em>(17), 14577–14598. (<a
href="https://doi.org/10.1007/s00521-022-07207-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting the best portfolio of projects by considering several objectives, including financial, social, and environmental goals, is the main goal in sustainable project portfolio selection problems while addressing staff assignment and financing options. Issues, such as global warming or social unrests, have made the problem of sustainable project portfolio selection a vital process for many firms. In other words, the success of firms in reaching their stated goals requires a selection of the best portfolio of projects. Given the importance of this topic, this paper presents a novel mathematical modeling approach for sustainable project portfolio selection. The model regards staff assignment based on learning and forgetting effects. Moreover, financing each phase of the projects is determined while addressing the possibility of outsourcing. To make it possible to consider uncertain decision-making environments, interval type-2 fuzzy sets are used, and a new uncertain optimization process is extended. The application of the model shows that it is capable of assisting the main decision makers in finding the best portfolio of sustainable projects while performing staff assignments based on learning and forgetting effects, finding a proper outsourcing plan, and selecting the best financing option for projects under uncertainty.},
  archive      = {J_NCA},
  author       = {Mohagheghi, Vahid and Mousavi, Seyed Meysam and Shahabi-Shahmiri, Reza},
  doi          = {10.1007/s00521-022-07207-3},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14577-14598},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sustainable project portfolio selection and optimization with considerations of outsourcing decisions, financing options and staff assignment under interval type-2 fuzzy uncertainty},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid projection method for resource-constrained project
scheduling problem under uncertainty. <em>NCA</em>, <em>34</em>(17),
14557–14576. (<a
href="https://doi.org/10.1007/s00521-022-07321-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource constraint project scheduling problem (RCPSP) is one of the most important problems in the scheduling environment. This paper introduces a new framework to collect the activities’ duration and resource requirement by group decision-making, solve the RCPSP with variable durations, and obtain the buffer to protect the schedule. Firstly, the duration and resources of the project’s activities are determined by a new expert weighting method. In the group decision-making, hybrid projection measure is introduced to construct the aggregated decision about some RCPSP parameters. The hybrid projection includes the projection, normalized projection, and bi-directional projection. In the second step, a RCPSP model is presented where the duration of activities can change within certain intervals. Thus, the problem is called the RCPSP with variable durations. The intervals for activities’ duration and resource requirements are obtained from the group decision-making in the first step. Genetic algorithm and vibration damping optimization are applied to solve the RCPSP with variable durations. In the third step, the project’s buffer is determined to protect the schedule. In this step, the intervals for activities’ duration are converted into interval-valued fuzzy (IVF) numbers and the buffer sizing method is extended using IVF numbers. Finally, the presented framework is solved for a practical example and the results are reported.},
  archive      = {J_NCA},
  author       = {Aramesh, Saeed and Aickelin, Uwe and Akbarzadeh Khorshidi, Hadi},
  doi          = {10.1007/s00521-022-07321-2},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14557-14576},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid projection method for resource-constrained project scheduling problem under uncertainty},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lexicon enhanced chinese named entity recognition with
pointer network. <em>NCA</em>, <em>34</em>(17), 14535–14555. (<a
href="https://doi.org/10.1007/s00521-022-07287-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent time, lexicon-based LSTM and pre-training language models are combined to explore the Chinese Named Entity Recognition (NER) and achieve the current state-of-the-art (SOTA) performance on several Chinese benchmark datasets. However, existing lexicon-based models only conform lexicon features through shallow and randomly initialized coding layers and do not integrate them into the bottom layer of the pre-training language model to mine the deep lexicon knowledge. To address the above issue, we propose a novel BERT-based Enhanced Lexicon Adapter (BLA) model that fuses external lexicon feature into the pre-training language model BERT in-depth. Specifically, the external lexicon knowledge is integrated into the deep Transformer layers of BERT by the lexicon adapter mechanism. With the comparison of existing methods, our model achieves the genuine deep fusion of the lexicon knowledge and BERT representation, effectively obtaining entity boundaries and word information.Besides, given the value of high-level global semantic features in alleviating word ambiguity and segmenting precisely the entity boundary in Chinese NER, transforming the sequence labeling task into sequence generation task provides the new cogitation for extracting global semantic features. Therefore, we explore the strategies of local lexicon information’s fusion and global semantic features extraction for entity category labeling. Specifically, we utilize the sequence-to-sequence (Seq2Seq) framework with pointer network as the prominent model architecture, in which the pointing function implements a custom attention mechanism and models different interactions between the source text and the semantic embedding by the generated probability $$p_{point}$$ . Furthermore, the decoder with the pointer mechanism generates the target sequence autoregressively. Experiments on several different benchmark Chinese datasets indicate that the proposed model achieves remarkable improvement compared with the current lexicon-based methods, and the results significantly outperform the current SOTA models.},
  archive      = {J_NCA},
  author       = {Guo, Qian and Guo, Yi},
  doi          = {10.1007/s00521-022-07287-1},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14535-14555},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lexicon enhanced chinese named entity recognition with pointer network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). A novel meta-learning initialization method for
physics-informed neural networks. <em>NCA</em>, <em>34</em>(17),
14511–14534. (<a
href="https://doi.org/10.1007/s00521-022-07294-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks (PINNs) have been widely used to solve various scientific computing problems. However, large training costs limit PINNs for some real-time applications. Although some works have been proposed to improve the training efficiency of PINNs, few consider the influence of initialization. To this end, we propose a New Reptile initialization-based Physics-Informed Neural Network (NRPINN). The original Reptile algorithm is a meta-learning initialization method based on labeled data. PINNs can be trained with less labeled data or even without any labeled data by adding partial differential equations (PDEs) as a penalty term into the loss function. Inspired by this idea, we propose the new Reptile initialization to sample more tasks from the parameterized PDEs and adapt the penalty term of the loss. The new Reptile initialization can acquire initialization parameters from related tasks by supervised, unsupervised, and semi-supervised learning. Then, PINNs with initialization parameters can efficiently solve PDEs. Besides, the new Reptile initialization can also be used for the variants of PINNs. Finally, we demonstrate and verify the NRPINN considering both forward problems, including solving Poisson, Burgers, and Schrödinger equations, as well as inverse problems, where unknown parameters in the PDEs are estimated. Experimental results show that the NRPINN training is much faster and achieves higher accuracy than PINNs with other initialization methods.},
  archive      = {J_NCA},
  author       = {Liu, Xu and Zhang, Xiaoya and Peng, Wei and Zhou, Weien and Yao, Wen},
  doi          = {10.1007/s00521-022-07294-2},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14511-14534},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel meta-learning initialization method for physics-informed neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-stage deep learning model for alzheimer’s disease
detection and prediction of the mild cognitive impairment time.
<em>NCA</em>, <em>34</em>(17), 14487–14509. (<a
href="https://doi.org/10.1007/s00521-022-07263-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is an irreversible neurodegenerative disease characterized by thinking, behavioral and memory impairments. Early prediction of conversion from mild cognitive impairment (MCI) to AD is still a challenging task. No study has been able to predict the exact conversion time of MCI patients. In addition, most studies have achieved poor performance making this prediction using only a small number of features (e.g., using only MRI images). Therefore, previous approaches have not gained the trust of medical experts. This study proposes a novel two-stage deep learning AD progression detection framework based on information fusion of several patient longitudinal multivariate modalities, including neuroimaging data, cognitive scores, cerebrospinal fluid biomarkers, neuropsychological battery markers, and demographics. The first stage of the progression detection framework employs a multiclass classification task that predicts a patient’s diagnosis (i.e., cognitively normal, MCI, or AD). In the second stage, a regression task that predicts the exact conversion time of MCI patients is used. The study is based on data of 1,371 subjects collected by the Alzheimer’s Disease Neuroimaging Initiative (ADNI). Comprehensive experiments were carried out to evaluate the framework stages and find the optimal model for each stage. Proposed model was compared with various machine learning models, including decision tree (DT), random forest (RF), support vector machine (SVM), logistic regression (LR), and K-nearest neighbor (KNN). In the classification stage, the proposed long-short term memory (LSTM) model achieved an accuracy of 93.87\%, precision of 94.070\%, recall of 94.07\%, and F1-score of 94.07\%. The results showed that the LSTM model outperformed other machine learning models (i.e., decision tree by 2.48\%, random forest by 1.27\%, support vector machine by 1.86\%, logistic regression by 1.59\%, and K-nearest neighbor by 14.77\%). In the regression stage, the proposed LSTM model achieved the best results (i.e., mean absolute error of 0.1375). Compared to other regular regressors, this LSTM model achieved less errors (i.e., 0.0064, 0.0152, 0.0338, 0.0118, 0.0198, and 0.0066, compared to DT, RF, SVM, LR, and KNN, respectively). By learning deep representation from patient high-dimensional longitudinal time-series data, the proposed LSTM model was more stable and medically acceptable. The framework may have a clinical impact as a predictive tool for AD progression detection due to its accurate results to predict the exact conversion time of MCI cases using patient time-series multimodalities data.},
  archive      = {J_NCA},
  author       = {El-Sappagh, Shaker and Saleh, Hager and Ali, Farman and Amer, Eslam and Abuhmed, Tamer},
  doi          = {10.1007/s00521-022-07263-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14487-14509},
  shortjournal = {Neural Comput. Appl.},
  title        = {Two-stage deep learning model for alzheimer’s disease detection and prediction of the mild cognitive impairment time},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GRaNN: Feature selection with golden ratio-aided neural
network for emotion, gender and speaker identification from voice
signals. <em>NCA</em>, <em>34</em>(17), 14463–14486. (<a
href="https://doi.org/10.1007/s00521-022-07261-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to other features of the human body, voice is quite complex and dynamic, in a sense that a speech can be spoken in various languages with different accents and in different emotional states. Recognizing the gender, i.e. male or female from the voice of an individual, is by all accounts a minor errand for human beings. Similar goes for speaker identification if we are well accustomed with the speaker for a long time. Our ears function as the front end, accepting the sound signs which our cerebrum processes and settles on our disposition. Although being trivial for us, it becomes a challenging task to mimic for any computing device. Automatic gender, emotion and speaker identification systems have many applications in surveillance, multimedia technology, robotics and social media. In this paper, we propose a Golden Ratio-aided Neural Network (GRaNN) architecture for the said purposes. As deciding the number of units for each layer in deep NN is a challenging issue, we have done this using the concept of Golden Ratio. Prior to that, an optimal subset of features are selected from the feature vector extracted, common for all three tasks, from spectral images obtained from the input voice signals. We have used a wrapper-filter framework where minimum redundancy maximum relevance selected features are fed to Mayfly algorithm combined with adaptive beta hill climbing (A $$\beta$$ HC) algorithm. Our model achieves accuracies of 99.306\% and 95.68\% for gender identification in RAVDESS and Voice Gender datasets, 95.27\% for emotion identification in RAVDESS dataset and 67.172\% for speaker identification in RAVDESS dataset. Performance comparison of this model with existing models on the publicly available datasets confirms its superiority over those models. Results also ensure that we have chosen the common feature set meticulously, which works equally well on three different pattern classification tasks. The proposed wrapper-filter framework reduces the feature dimension significantly, thereby lessening the storage requirement and training time. Finally, strategically selecting the number units in each layer in NN help increases the overall performance of all three pattern classification tasks.},
  archive      = {J_NCA},
  author       = {Garain, Avishek and Ray, Biswarup and Giampaolo, Fabio and Velasquez, Juan D. and Singh, Pawan Kumar and Sarkar, Ram},
  doi          = {10.1007/s00521-022-07261-x},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14463-14486},
  shortjournal = {Neural Comput. Appl.},
  title        = {GRaNN: Feature selection with golden ratio-aided neural network for emotion, gender and speaker identification from voice signals},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Event-based adaptive neural network asymptotic control
design for nonstrict feedback nonlinear system with state constraints.
<em>NCA</em>, <em>34</em>(17), 14451–14462. (<a
href="https://doi.org/10.1007/s00521-022-07247-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an event-triggered adaptive neural network (ANN) asymptotic tracking control scheme for nonstrict feedback nonlinear systems with state constraints. The neural networks are explored to address the unknown dynamics and nonstrict feedback structure. With the help of barrier Lyapunov functions, the state constraints are properly addressed. By employing some well defined smooth functions and backstepping technique, the asymptotic tracking controller is recursively constructed. In addition, event-triggered mechanism is incorporated into the asymptotic tracking design framework to reduce the data transmission. Through Lyapunov stability analysis, the tracking errors can converge to zero asymptotically and the boundedness of the considered systems are guaranteed. Simulation results are given to elucidate the validity of the proposed ANN asymptotic controller.},
  archive      = {J_NCA},
  author       = {Liu, Yongchao and Zhu, Qidan and Liu, Zixuan},
  doi          = {10.1007/s00521-022-07247-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14451-14462},
  shortjournal = {Neural Comput. Appl.},
  title        = {Event-based adaptive neural network asymptotic control design for nonstrict feedback nonlinear system with state constraints},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cooperative learning from adaptive neural control for a
group of strict-feedback systems. <em>NCA</em>, <em>34</em>(17),
14435–14449. (<a
href="https://doi.org/10.1007/s00521-022-07239-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the distributed cooperative learning (DCL) from adaptive neural network (NN) control for a group of strict-feedback systems, where the structure of all strict-feedback systems is identical. In order to achieve DCL easily, the system transformation method is employed for the strict-feedback systems. For an agent, only one radial basis function NN is used to approximate the lumped uncertainty in control design. Then the output tracking performance of all strict-feedback systems is guaranteed. What’s more, we prove that weights of all NNs in a multi-agent system converge to a small neighborhood around their common optimal value if the topology of the multi-agent system is connected and undirected. Thus, the approximation domain of all NNs is enlarged. Further, the previous learned NNs are used to improve the control performance. Finally, we provide two examples to demonstrate the effectiveness of the proposed scheme.},
  archive      = {J_NCA},
  author       = {Gao, Fei and Bai, Fengshan and Weng, Zhi and Na, Xitai and Li, Jing},
  doi          = {10.1007/s00521-022-07239-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14435-14449},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cooperative learning from adaptive neural control for a group of strict-feedback systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel sagittal craniosynostosis classification system
based on multi-view learning algorithm. <em>NCA</em>, <em>34</em>(17),
14427–14434. (<a
href="https://doi.org/10.1007/s00521-022-07310-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sagittal craniosynostosis (CSO) occurs when the sagittal suture of a growing child’s skull is fused prematurely. Surgery, which involves re-moving the affected bones and increasing the volume of the cranium by repositioning the bone segments or using external forces to guide, is the primary treatment for CSO. For preparation of the surgery, physicians usually classify sagittal CSO subtypes by examining the reconstruction of skulls from CT images or the laser scans of the patients’ 3D skull. We have proposed an automated sagittal CSO classification algorithm based on features extracted from projected 3D skull images. However, these features would become invalid if they were extracted from irregular skulls or skulls with completely closed sutures. In order to tackle this problem, we proposed a 3D skull multi-view images-based algorithm to classify the subtypes of sagittal CSO, like the physicians diagnosing these 3D reconstruction images of skulls or laser scans. Our innovations include: 1) the first to propose a multi-view learning algorithm to classify the subtypes of sagittal CSO cases, 2) 3D rendering and a patch-based erosion method are adopted for data augmentation to keep the original ratio and shape of the images, and 3) utilizing a transfer leaning training strategy to train the convolutional neural network (CNN) and a multi-view-based prediction strategy for classifying the cases.},
  archive      = {J_NCA},
  author       = {You, Lei and Deng, Yang and Zhang, Guangming and Wang, Yanfei and Bins, Griffin Patrick and Runyan, Christopher Michael and David, Lisa and Zhou, Xiaobo},
  doi          = {10.1007/s00521-022-07310-5},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14427-14434},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel sagittal craniosynostosis classification system based on multi-view learning algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance estimation of tubular solar still with a wicked
rotating drum using DT, LR, and KNN techniques of machine learning.
<em>NCA</em>, <em>34</em>(17), 14415–14425. (<a
href="https://doi.org/10.1007/s00521-022-07293-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decision tree (DT), linear regression (LR), and K-nearest neighbours (KNN) models were employed in this work to estimate the thermal performance of tubular solar still with a wicked rotating drum. These three models were developed using real-world experimental data and calculated values. This study used a dataset containing 95 experimental iterations in total. Five input parameters, including solar intensity, basin water temperature, wind speed, ambient temperature, and glass temperature, were used as the independent variables of the DT, LR, and KNN models, and two dependent variables, thermal efficiency and productivity, were predicted. The DT model was the most significant model due to its lowest error and most incredible R2 value compared to the LR and KNN model performances. The MAE, RMSE, and R2 values for the DT model were 0.566828, 0.85135, and 0.9602, respectively, with the model efficiency of 0.961, which is the most significant value compared to other models. These results suggest that the DT model is a good fit for forecasting the thermal performance of tubular solar stills.},
  archive      = {J_NCA},
  author       = {Saravanan, A. and Parida, Satyajeet and Murugan, M. and Reddy, M. Sreenivasa and Bora, Purabi and Sree, S. Rama},
  doi          = {10.1007/s00521-022-07293-3},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14415-14425},
  shortjournal = {Neural Comput. Appl.},
  title        = {Performance estimation of tubular solar still with a wicked rotating drum using DT, LR, and KNN techniques of machine learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Topology-based representative datasets to reduce neural
network training resources. <em>NCA</em>, <em>34</em>(17), 14397–14413.
(<a href="https://doi.org/10.1007/s00521-022-07252-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main drawbacks of the practical use of neural networks is the long time required in the training process. Such a training process consists of an iterative change of parameters trying to minimize a loss function. These changes are driven by a dataset, which can be seen as a set of labeled points in an n-dimensional space. In this paper, we explore the concept of a representative dataset which is a dataset smaller than the original one, satisfying a nearness condition independent of isometric transformations. Representativeness is measured using persistence diagrams (a computational topology tool) due to its computational efficiency. We theoretically prove that the accuracy of a perceptron evaluated on the original dataset coincides with the accuracy of the neural network evaluated on the representative dataset when the neural network architecture is a perceptron, the loss function is the mean squared error, and certain conditions on the representativeness of the dataset are imposed. These theoretical results accompanied by experimentation open a door to reducing the size of the dataset to gain time in the training process of any neural network.},
  archive      = {J_NCA},
  author       = {Gonzalez-Diaz, Rocio and Gutiérrez-Naranjo, Miguel A. and Paluzo-Hidalgo, Eduardo},
  doi          = {10.1007/s00521-022-07252-y},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14397-14413},
  shortjournal = {Neural Comput. Appl.},
  title        = {Topology-based representative datasets to reduce neural network training resources},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatial-temporal attention-based convolutional network with
text and numerical information for stock price prediction. <em>NCA</em>,
<em>34</em>(17), 14387–14395. (<a
href="https://doi.org/10.1007/s00521-022-07234-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the financial market, the stock price prediction is a challenging task which is influenced by many factors. These factors include economic change, politics and global events that are usually recorded in text format, such as the daily news. Therefore, we assume that real-world text information can be used to forecast stock market activity. However, only a few works considered both text and numerical information to predict or analyse stock trends. These works used preprocessed text features as the model inputs; therefore, latent information in text may be lost because the relationships between the text and stock price are not considered. In this paper, we propose a fusion network, i.e. a spatial-temporal attention-based convolutional network (STACN) that can leverage the advantages of an attention mechanism, a convolutional neural network and long short-term memory to extract text and numerical information for stock price prediction. Benefiting from the utilisation of an attention mechanism, reliable text features that are highly relevant to stock value can be extracted, which improves the overall model performance. The experimental results on real-world stock data demonstrate that our STACN model and training scheme can handle both text and numerical data and achieve high accuracy on stock regression tasks. The STACN is compared with CNNs and LSTMs with different settings, e.g. a CNN with only stock data, a CNN with only news titles and LSTMs with only stock data. CNNs considering only stock data and news titles have mean squared errors of 28.3935 and 0.1814, respectively. The accuracy of LSTMs is 0.0763. The STACN can achieve an accuracy of 0.0304, outperforming CNNs and LSTMs in stock regression tasks.},
  archive      = {J_NCA},
  author       = {Lin, Chin-Teng and Wang, Yu-Ka and Huang, Pei-Lun and Shi, Ye and Chang, Yu-Cheng},
  doi          = {10.1007/s00521-022-07234-0},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14387-14395},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatial-temporal attention-based convolutional network with text and numerical information for stock price prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using ANN and OA techniques to determine the specific wear
rate effectors of a356 al-si/Al2O3 MMC. <em>NCA</em>, <em>34</em>(17),
14373–14386. (<a
href="https://doi.org/10.1007/s00521-022-07215-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present work, it’s required to obtained the wear rate effectors’ values of A356 Al-Si/Al2O3 composite (Al2O3 wt\%, applied load, hardness, and sliding distance) required to obtain a certain specific wear rate. So, the specific wear behavior of cast and heat-treated A356 Al-Si/Al2O3 metal matrix composites (MMC) were investigated as a function of its effectors. Five weight fractions of Al2O3 particles were used to produce specimens using stir casting. Two different hardness are obtained for each fraction (casted and heat-treated specimens). Sliding wear tests were done under three loads (20, 30, and 40 N), four sliding distances (310, 620, 930 and 1240 m) at constant speed (1 m/min). Experimental results indicated that the specific wear rate is generally reversed proportional to Al2O3 percentage. The impact of Al2O3 percentage was eliminated with the grown of applied load. Increasing the applied load decreases the specific wear rate, up to 20\% Al2O3. However, at 25\% Al2O3 the applied load increases the specific wear rate with a small graduation. Moreover, the heat treatment process improves the hardness and specific wear behavior of the casted MMC. Both Artificial neural network (ANN) and multiple regression techniques were used to predict the wear rate. The orthogonal array technique (OA) used in selecting the data set to train ANN and obtained a 2nd degree regression equation. ANN gives more realistic prediction then the regression equation. So, at the end, an algorithm is designed and tested to determine the weight fraction and other wear rate effectors for A356 Al-Si/Al2O3 MMC to obtain a certain wear rate, according to the uncertainty of the ANN. The used algorithm for obtaining the wear rate effectors provides a very good choices to produce a certain wear rate’s value, with error less than 1\%.},
  archive      = {J_NCA},
  author       = {Atta, M. and Megahed, M. and Saber, D.},
  doi          = {10.1007/s00521-022-07215-3},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14373-14386},
  shortjournal = {Neural Comput. Appl.},
  title        = {Using ANN and OA techniques to determine the specific wear rate effectors of a356 al-Si/Al2O3 MMC},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DVPPIR: Privacy-preserving image retrieval based on DCNN and
VHE. <em>NCA</em>, <em>34</em>(17), 14355–14371. (<a
href="https://doi.org/10.1007/s00521-022-07286-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With 5G and Internet technologies developing rapidly, outsourcing images to cloud servers has attracted growing attention. In existing technologies, images are often outsourced to cloud servers to reduce storage and computing burdens. However, outsourcing images to cloud servers without any processing may reveal the users’ privacy, because the images may contain sensitive information about users, such as faces and locations, especially in electronic investigation. To overcome the security problems in image retrieval, we propose a privacy-preserving image retrieval scheme based on deep convolutional neural network (DCNN) and vector homomorphic encryption (VHE). We adopt DCNN and hash algorithms to extract image feature vectors, which improves retrieval accuracy. By combining VHE and K-means outsourcing clustering algorithms, the cloud server can build encrypted index trees, which speeds up the search and reduces the computational cost. In addition, a lightweight access control technique is used to allow image owners to set access policies for datasets flexibly. We prove the security of the proposed scheme and show the effectiveness of the scheme through experiments. Our scheme is suitable for application in electronic image investigation systems (EIIs) to optimize the storage and search of police data.},
  archive      = {J_NCA},
  author       = {Li, Su and Wu, Lei and Meng, Weizhi and Xu, Zihui and Qin, Chengyi and Wang, Hao},
  doi          = {10.1007/s00521-022-07286-2},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14355-14371},
  shortjournal = {Neural Comput. Appl.},
  title        = {DVPPIR: Privacy-preserving image retrieval based on DCNN and VHE},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised optical flow estimation method based on
transformer and occlusion compensation. <em>NCA</em>, <em>34</em>(17),
14341–14353. (<a
href="https://doi.org/10.1007/s00521-022-07483-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the problems that still adversely affect the optical flow accuracy is the missing parts or the loss of some details in the flow map that is estimated by the flow estimation network. The main reasons are the feature maps that are extracted by the local kernels of the convolution neural networks (CNN), which cause feature loss and provide low-quality features, and the occluded parts after the image reconstruction. This loss in the encoder part becomes hard to recover in the flow estimation network. To overcome this problem, we propose a CNN with transformer architecture to emphasize the important features and model the long-range dependencies to produce a better feature representation that can provide the flow map with strong details. In addition, we propose an occlusion compensation loss to rectify the occlusion map and assist the network in learning how to predict the flow in the occluded regions. Extensive experiments are conducted on Sintel and KITTI benchmarks, and the results demonstrate the efficiency of our model in increasing the accuracy of the optical flow and improving the flow in the occluded regions.},
  archive      = {J_NCA},
  author       = {Xiang, Xuezhi and Abdein, Rokia and Lv, Ning},
  doi          = {10.1007/s00521-022-07483-z},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14341-14353},
  shortjournal = {Neural Comput. Appl.},
  title        = {Unsupervised optical flow estimation method based on transformer and occlusion compensation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning-driven credit risk: A systemic review.
<em>NCA</em>, <em>34</em>(17), 14327–14339. (<a
href="https://doi.org/10.1007/s00521-022-07472-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit risk assessment is at the core of modern economies. Traditionally, it is measured by statistical methods and manual auditing. Recent advances in financial artificial intelligence stemmed from a new wave of machine learning (ML)-driven credit risk models that gained tremendous attention from both industry and academia. In this paper, we systematically review a series of major research contributions (76 papers) over the past eight years using statistical, machine learning and deep learning techniques to address the problems of credit risk. Specifically, we propose a novel classification methodology for ML-driven credit risk algorithms and their performance ranking using public datasets. We further discuss the challenges including data imbalance, dataset inconsistency, model transparency, and inadequate utilization of deep learning models. The results of our review show that: 1) most deep learning models outperform classic machine learning and statistical algorithms in credit risk estimation, and 2) ensemble methods provide higher accuracy compared with single models. Finally, we present summary tables in terms of datasets and proposed models.},
  archive      = {J_NCA},
  author       = {Shi, Si and Tse, Rita and Luo, Wuman and D’Addona, Stefano and Pau, Giovanni},
  doi          = {10.1007/s00521-022-07472-2},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14327-14339},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning-driven credit risk: A systemic review},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep pattern-based tumor segmentation in brain MRIs.
<em>NCA</em>, <em>34</em>(17), 14317–14326. (<a
href="https://doi.org/10.1007/s00521-022-07422-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is still hard to deal with artifacts in magnetic resonance images (MRIs), particularly when the latter are to be segmented. This paper introduces a novel deep-based scheme for tumor segmentation in brain MRIs. According to the proposed scheme, a large set of partial sub-images are paved form sliced from an MRI volume then inputted to an ensemble of convolutional neural networks (CNNs) in order to label the voxels in the centers of the sub-images, according to the classes to which they should belong. Partial sub-images, that capture local patterns around central voxels, have allowed to speed-up both the training and the prediction steps, allowing efficient use of such a scheme for real MRI-based tumor diagnosis. Experiments were performed using the BraTS (brain tumor segmentation) database, where the obtained results show that the proposed scheme allows both fast and accurate brain tumor detection and segmentation in pathological MRIs.},
  archive      = {J_NCA},
  author       = {Bouchaour, Nadjet and Mazouzi, Smaine},
  doi          = {10.1007/s00521-022-07422-y},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14317-14326},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep pattern-based tumor segmentation in brain MRIs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel activation functions-based ZNN models for fixed-time
solving dynamirc sylvester equation. <em>NCA</em>, <em>34</em>(17),
14297–14315. (<a
href="https://doi.org/10.1007/s00521-022-06905-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A lot of research has validated that zeroing neural network (ZNN) model is a reliable tool for solving time-varying problems. Generally, convergent performance is often one of the most important measures for the practicability of the ZNN model. Besides, its practicability is also up to its anti-noise ability in the process of solving time-varying problems. It is worth noting that numerous existing ZNN models perform well in terms of the above two issues. In order to further enhance the robustness and convergence of the ZNN model, two novel activation functions (novel activation function-1 (NAF-1) and novel activation function-2 (NAF-2)) are designed. Based on the above two NAFs, two robust ZNN models (zeroing neural network-1 (ZNN-1) and zeroing neural network-2 (ZNN-2)) with fixed time convergence and strong robustness to noise for solving time-varying Sylvester equation (TVSE) are proposed in this paper. The robustness and convergence of the two proposed ZNN models are verified by rigorous mathematical analysis, and their practicability are validated by three simulation experiments (second-order and third-order TVSE solving and manipulator trajectory tracking). All the studies indicate that the two ZNN models can quickly find the accurate solution of TVSE in noiseless and noisy environment.},
  archive      = {J_NCA},
  author       = {Jin, Jie and Zhu, Jingcan and Gong, Jianqing and Chen, Weijie},
  doi          = {10.1007/s00521-022-06905-2},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14297-14315},
  shortjournal = {Neural Comput. Appl.},
  title        = {Novel activation functions-based ZNN models for fixed-time solving dynamirc sylvester equation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge distillation in plant disease recognition.
<em>NCA</em>, <em>34</em>(17), 14287–14296. (<a
href="https://doi.org/10.1007/s00521-021-06882-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing the plant disease and pests in its golden time is a highly critical problem to be addressed, since the herbalist can apply treatments within this period and save the agricultural product. In this paper, a deep learning approach to recognize the disease from the leaves of the plants has been pursued. A client-server system is proposed in which the server-side model can leverage huge deep CNN architectures to classify the diseases, whereas the client-side model is to be chosen among small deep CNN architectures with low number of parameters in order to be easily deployed on the end-user mobile devices with poor processing powers. Here, a novel knowledge distillation technique has been leveraged that improves the accuracy level of the small client-side model significantly. This technique distills the perception knowledge of a large model classifier and transfers this knowledge to the small model in order to perform a similar prediction capability. By applying this idea on Plantvillage dataset, we could achieve $$97.58\%$$ accuracy on a small MobileNet architecture which is very close to the accuracy of a large Xception model on the server with $$99.73\%$$ accuracy. Through applying this teacher-student idea, we could improve the classification rate of the state-of-the-art tiny model by $$2.12\%$$ .},
  archive      = {J_NCA},
  author       = {Ghofrani, Ali and Mahdian Toroghi, Rahil},
  doi          = {10.1007/s00521-021-06882-y},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14287-14296},
  shortjournal = {Neural Comput. Appl.},
  title        = {Knowledge distillation in plant disease recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Expectation propagation learning of finite multivariate beta
mixture models and applications. <em>NCA</em>, <em>34</em>(17),
14275–14285. (<a
href="https://doi.org/10.1007/s00521-021-06839-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is an attractive method to handle large-scale data which are explosively generated through digitization. This approach is specifically appropriate when labeling is very costly. In this paper, we constructed an unsupervised learning algorithm and focused on a finite mixture model based on multivariate Beta distribution. Our motivation is the flexibility and high potential that this distribution offers in modeling data. To learn this mixture model, we used an expectation propagation inference framework in which the parameters and the complexity of the model were evaluated concurrently in a single optimization framework. We evaluated the performance of our framework on publicly available datasets related to forgery detection, EEG-based sentiment analysis and human activity recognition. Our proposed model demonstrates comparable results to similar alternatives.},
  archive      = {J_NCA},
  author       = {Manouchehri, Narges and Bouguila, Nizar and Fan, Wentao},
  doi          = {10.1007/s00521-021-06839-1},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14275-14285},
  shortjournal = {Neural Comput. Appl.},
  title        = {Expectation propagation learning of finite multivariate beta mixture models and applications},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification and pattern extraction of incidents: A deep
learning-based approach. <em>NCA</em>, <em>34</em>(17), 14253–14274. (<a
href="https://doi.org/10.1007/s00521-021-06780-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifying or predicting occupational incidents using both structured and unstructured (text) data are an unexplored area of research. Unstructured texts, i.e., incident narratives are often unutilized or underutilized. Besides the explicit information, there exist a large amount of hidden information present in a dataset, which cannot be explored by the traditional machine learning (ML) algorithms. There is a scarcity of studies that reveal the use of deep neural networks (DNNs) in the domain of incident prediction, and its parameter optimization for achieving better prediction power. To address these issues, initially, key terms are extracted from the unstructured texts using LDA-based topic modeling. Then, these key terms are added with the predictor categories to form the feature vector, which is further processed for noise reduction and fed to the adaptive moment estimation (ADAM)-based DNN (i.e., ADNN) for classification, as ADAM is superior to GD, SGD, and RMSProp. To evaluate the effectiveness of our proposed method, a comparative study has been conducted using some state-of-the-arts on five benchmark datasets. Moreover, a case study of an integrated steel plant in India has been demonstrated for the validation of the proposed model. Experimental results reveal that ADNN produces superior performance than others in terms of accuracy. Therefore, the present study offers a robust methodological guide that enables us to handle the issues of unstructured data and hidden information for developing a predictive model.},
  archive      = {J_NCA},
  author       = {Sarkar, Sobhan and Vinay, Sammangi and Djeddi, Chawki and Maiti, J.},
  doi          = {10.1007/s00521-021-06780-3},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14253-14274},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification and pattern extraction of incidents: A deep learning-based approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive context-aware optimization framework for
multimedia adaptation service selection. <em>NCA</em>, <em>34</em>(17),
14239–14251. (<a
href="https://doi.org/10.1007/s00521-021-06644-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In pervasive systems, context is a direct cause to adapt the content of multimedia documents so that they comply, as far as possible, with the current constraints. In this respect, several adaptation approaches have already been proposed, in which adaptation services are often selected from shortlists of services. Practically speaking, adaptation services are provided in various instances and ways, thus making the selection task more difficult. Furthermore, existing approaches for the service selection paradigm cannot be properly applied mainly because constraints on execution time and the availability of computation resources must be considered. To deal with this issue, we propose a framework for adaptive service selection using a bag of metaheuristics ranging from local to global search methods. Depending on the contextual constraints, a sub-bag of algorithms is selected, for which the budget is distributed, using a reinforcement learning mechanism related to their performances. The proposal is validated through a set of experiments and comparisons. The obtained results are satisfactory and encouraging.},
  archive      = {J_NCA},
  author       = {Laboudi, Zakaria and Moudjari, Abdelkader and Saighi, Asma and Draa, Amer and Hadjadj, Selma},
  doi          = {10.1007/s00521-021-06644-w},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14239-14251},
  shortjournal = {Neural Comput. Appl.},
  title        = {An adaptive context-aware optimization framework for multimedia adaptation service selection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A generalized deep learning-based framework for assistance
to the human malaria diagnosis from microscopic images. <em>NCA</em>,
<em>34</em>(17), 14223–14238. (<a
href="https://doi.org/10.1007/s00521-021-06604-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malaria is an infectious disease caused by Plasmodium parasites and is potentially human life-threatening. Children under 5 years old are the most vulnerable group with approximately one death every two minutes, accounting for more than 65\% of all malaria deaths. The World Health Organization (WHO) encourages the research of appropriate methods to treat malaria through rapid and economical diagnostic. In this paper, we present a deep learning-based framework for diagnosing human malaria infection from microscopic images of thin blood smears. The framework is based on a direct segmentation and classification approach which relies on the analysis of the parasite itself. The framework permits to segment the Plasmodium parasite in the images and to predict its species among four dominant classes: P. Falciparum, P. Malaria, P. Ovale, and P. Vivax. A high potential of generalization with a competitive performance of our framework on inter-class data is demonstrated through an experimental study considering several datasets. Our source code is publicly available on https://github.com/Benhabiles-JUNIA/MalariaNet.},
  archive      = {J_NCA},
  author       = {Yang, Ziheng and Benhabiles, Halim and Hammoudi, Karim and Windal, Feryal and He, Ruiwen and Collard, Dominique},
  doi          = {10.1007/s00521-021-06604-4},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14223-14238},
  shortjournal = {Neural Comput. Appl.},
  title        = {A generalized deep learning-based framework for assistance to the human malaria diagnosis from microscopic images},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Expressive top-k matching for conditional graph patterns.
<em>NCA</em>, <em>34</em>(17), 14205–14221. (<a
href="https://doi.org/10.1007/s00521-021-06590-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose conditional graph patterns (CGPs) that make conventional patterns more expressive, especially with positive and negative predicates. In emerging applications, CGPs allow to express complex search conditions and to find more sensible information than their traditional counterparts. We show that this expressivity does not come with a much higher price. Indeed, we propose a (parallel) matching algorithm that allows to match CGPs over any data graphs in quadratic time, as opposed to the prohibitive solutions based on subgraph isomorphism. In the second part of this article, we study the problem of top-k CGP matching algorithm. We propose the notion of relevance schema that allows users to define relevance criteria according to their preferences. We propose an early termination algorithm that finds the top-k relevant matches by requiring only $$3\%$$ of the time spent by the naive algorithm. To our knowledge, this is the first effort that investigates an expressive top-k graph pattern matching under simulation semantic. An extensive experimental study has been conducted to prove effectiveness and efficiency of our results.},
  archive      = {J_NCA},
  author       = {Mahfoud, Houari},
  doi          = {10.1007/s00521-021-06590-7},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14205-14221},
  shortjournal = {Neural Comput. Appl.},
  title        = {Expressive top-k matching for conditional graph patterns},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary NAS for aerial image segmentation with gene
expression programming of cellular encoding. <em>NCA</em>,
<em>34</em>(17), 14185–14204. (<a
href="https://doi.org/10.1007/s00521-021-06564-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, neural architecture search (NAS) has gained a lot of attention as a tool for constructing deep neural networks automatically. NAS methods have successfully found convolutional neural networks (CNNs) that exceed human expert-designed networks on image classification in computer vision. However, there are growing demands for semantic segmentation in several areas including remote sensing image analysis. In this paper, we introduce an evolutionary NAS method for semantic segmentation of high-resolution aerial images. The proposed method leverages the complementary strengths of gene expression programming and cellular encoding to develop an encoding scheme, called symbolic linear generative encoding (SLGE), for evolving cells (directed acyclic graphs) as building-blocks to construct modularized encoder-decoder CNNs via an evolutionary process. SLGE can evolve cells with multi-branch and shortcut connections similar to the Inception-ResNet-like modules which can improve training and inference performance in deep neural networks. In experiments, we demonstrate the effectiveness of the proposed method on the challenging ISPRS Vaihingen, Potsdam and UAVid semantic segmentation benchmarks. Compared with recent state-of-the-art systems, our network, dubbed SLGENet, improves the overall accuracy performance on Vaihingen and Potsdam; and achieves a competitive overall accuracy on UAVid using fewer parameters. Our method achieves promising results in a little time of 2.5 GPU days.},
  archive      = {J_NCA},
  author       = {Broni-Bediako, Clifford and Murata, Yuki and Mormille, Luiz H. and Atsumi, Masayasu},
  doi          = {10.1007/s00521-021-06564-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14185-14204},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evolutionary NAS for aerial image segmentation with gene expression programming of cellular encoding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MEBeauty: A multi-ethnic facial beauty dataset in-the-wild.
<em>NCA</em>, <em>34</em>(17), 14169–14183. (<a
href="https://doi.org/10.1007/s00521-021-06535-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although facial beauty prediction (FBP) has achieved high accuracy on images captured in a constrained environment, it is still a challenging task on face images in-the-wild. Moreover, there is no FBP benchmark dataset that includes images with various ethnic, age, gender properties and unrestricted in terms of face expression and pose. In this work, the issue of FBP in real-life scenario is addressed and a multi-ethnic facial beauty dataset, namely MEBeauty, is introduced. All face images are captured in an unconstrained environment and rated by volunteers with various ethnicity, age and gender in order to avoid any cultural and social biases in beauty perception. Different well-known CNNs with layer-wise transfer learning are performed on the dataset. Moreover, the evaluation of knowledge learning from the face recognition task across FBP is conducted. The expected high number of aberrant and outlier faces is considered and the use of various robust loss functions in order to learn deep regression networks for facial beauty prediction is evaluated. Several FBP frameworks are performed on the proposed dataset and widely-used SCUT-FBP 5500 in order to compare their effectiveness on face images in constrained and unconstrained environments.},
  archive      = {J_NCA},
  author       = {Lebedeva, Irina and Guo, Yi and Ying, Fangli},
  doi          = {10.1007/s00521-021-06535-0},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14169-14183},
  shortjournal = {Neural Comput. Appl.},
  title        = {MEBeauty: A multi-ethnic facial beauty dataset in-the-wild},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Possibilistic rank-level fusion method for person
re-identification. <em>NCA</em>, <em>34</em>(17), 14151–14168. (<a
href="https://doi.org/10.1007/s00521-021-06502-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of multiple classifiers may generate a more efficient classification than each of the individual ones. Possibility theory is particularly efficient in combining multiple information sources providing incomplete, imprecise, and conflicting knowledge. In this work, we focus on the enhancement of the person re-identification performance by combining multiple deep learning classifiers’ outputs trained on different body part streams. We propose a possibilistic rank-level late fusion method that allows us to deal with imprecision and uncertainty factors that may arise in the predictions of poor classifiers. The proposed fusion method takes place in the framework of possibility theory and combines the ranking identities generated by each classifier based on their possibility distributions. This fusion method can take advantage of the complementary information given by each classifier, even the weak ones. We demonstrate the effectiveness of our proposed fusion method by presenting experimental results on two benchmark datasets (Market-1501 and DukeMTMC-reID). The obtained results show consistent accuracy improvements in comparison with state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Ben Slima, Ilef and Ammar, Sourour and Ghorbel, Mahmoud},
  doi          = {10.1007/s00521-021-06502-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14151-14168},
  shortjournal = {Neural Comput. Appl.},
  title        = {Possibilistic rank-level fusion method for person re-identification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning-based video quality enhancement for the new
versatile video coding. <em>NCA</em>, <em>34</em>(17), 14135–14149. (<a
href="https://doi.org/10.1007/s00521-021-06491-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimedia IoT (M-IoT) is an emerging type of Internet of things (IoT) relaying multimedia data (images, videos, audio and speech, etc.). The rapid growth of M-IoT devices enables the creation of a massive volume of multimedia data with different characteristics and requirements. With the development of artificial intelligence (AI), AI-based multimedia IoT systems have been recently designed and deployed for various video-based services for contemporary daily life, like video surveillance with high definition (HD) and ultra-high definition (UHD) and mobile multimedia streaming. These new services need higher video quality in order to meet the quality of experience (QoE) required by the users. Versatile video coding (VVC) is the new video coding standard that achieves significant coding efficiency over its predecessor high-efficiency video coding (HEVC). Moreover, VVC can achieve up to 30\% BD rate savings compared to HEVC. Inspired by the rapid advancements in deep learning, we propose in this paper a wide-activated squeeze-and-excitation deep convolutional neural network (WSE-DCNN) technique-based video quality enhancement for VVC. Therefore, we replace the conventional in-loop filtering in VVC by the proposed WSE-DCNN model that eliminates the compression artifacts in order to improve visual quality and hence increase the end user QoE. The obtained results prove that the proposed in-loop filtering technique achieves $$-2.85$$\%, $$-8.89$$\%, and $$-10.05$$\% BD rate reduction for luma and both chroma components under random access configuration. Compared to the traditional CNN-based filtering approaches, the proposed WSE-DCNN-based in-loop filtering framework achieves efficient performance in terms of RD cost.},
  archive      = {J_NCA},
  author       = {Bouaafia, Soulef and Khemiri, Randa and Messaoud, Seifeddine and Ben Ahmed, Olfa and Sayadi, Fatma Ezahra},
  doi          = {10.1007/s00521-021-06491-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14135-14149},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-based video quality enhancement for the new versatile video coding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bayesian sampling framework for asymmetric generalized
gaussian mixture models learning. <em>NCA</em>, <em>34</em>(17),
14123–14134. (<a
href="https://doi.org/10.1007/s00521-021-06483-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an effective unsupervised Bayesian framework for learning a finite mixture of asymmetric generalized Gaussian distributions (AGGD). The parameters are estimated by a hybrid Markov Chain Monte Carlo (MCMC) approach, which is a combination of Metropolis-Hastings and Gibbs sampling techniques. The motivation of this research is to add modeling flexibility to Gaussian distribution and enhance its ability to fit asymmetric and non-Gaussian data by introducing additional parameters. In order to examine the performance of the proposed model, several experiments are conducted, and the model is evaluated on various real world applications. The performance of our model is measured using a wide range of evaluation techniques and compared with the performance of benchmark models to investigate the goodness of fit. From the results, it is observed that proposed model has performed better in clustering applications as compared to Bayesian Gaussian and Bayesian asymmetric Gaussian mixture models.},
  archive      = {J_NCA},
  author       = {Vemuri, Ravi Teja and Azam, Muhammad and Bouguila, Nizar and Patterson, Zachary},
  doi          = {10.1007/s00521-021-06483-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14123-14134},
  shortjournal = {Neural Comput. Appl.},
  title        = {A bayesian sampling framework for asymmetric generalized gaussian mixture models learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial for topical collections on emerging trends in
artificial intelligence and machine learning. <em>NCA</em>,
<em>34</em>(17), 14121. (<a
href="https://doi.org/10.1007/s00521-022-07636-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Kessentini, Yousri and Laga, Hamid and Tabia, Hedi},
  doi          = {10.1007/s00521-022-07636-0},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {14121},
  shortjournal = {Neural Comput. Appl.},
  title        = {Editorial for topical collections on emerging trends in artificial intelligence and machine learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DDSS: Denge decision support system to recommend the
athlete-specific workouts on balance data. <em>NCA</em>,
<em>34</em>(16), 13969–13986. (<a
href="https://doi.org/10.1007/s00521-022-07208-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring the balance conditions and physical abilities of athletes is important to track their current situations which enables us to apply appropriate training programs for recovery. For different branches of sports, there are three main balance board types to be used; not swaying board (i.e. Wii board), semi-spherical fulcrum (i.e. Wobble board), and springboard (i.e. Spring Balance Board). In this study, the Balance springboard, which is new to the literature, is used. The springboard equipped with sensors uses Bluetooth technology to transmit collected balance data. There are various previous studies developed for assessing the balance performance of athletes regarding the first two types of balance-boards. Most of them are based on statistical analysis and machine learning (ML) techniques. In this study, the usage of a shallow deep learning model trained with the balance data, which is a contribution to the literature, gathered from the springboard is introduced. This model (DDSS, Denge Decision Support System) is compared with the base ANN model -which leads the study to tend our DDSS model- and ML techniques. Our DDSS model outperforms when compared with the base ANN and ML techniques, Sequential Minimal Optimization and Random Forest, and offers appropriate training program suggestions with a success rate of 92.11\%.},
  archive      = {J_NCA},
  author       = {Abidin, Didem and Cinsdikici, Muhammet G.},
  doi          = {10.1007/s00521-022-07208-2},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13969-13986},
  shortjournal = {Neural Comput. Appl.},
  title        = {DDSS: Denge decision support system to recommend the athlete-specific workouts on balance data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On fine-tuning deep learning models using transfer learning
and hyper-parameters optimization for disease identification in maize
leaves. <em>NCA</em>, <em>34</em>(16), 13951–13968. (<a
href="https://doi.org/10.1007/s00521-022-07246-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maize is one of the world&#39;s most important food crops, but its cultivation is hampered by diseases. Rapid disease identification remains a challenge due to a lack of the necessary infrastructure. This necessitates the development of automated methods to identify diseases. In this research, the use of deep learning models to identify maize leaf diseases is proposed. In this article, we investigate the transfer learning of deep convolutional neural networks for the detection of maize leaf diseases and explore employing the knowledge of pre-trained models and then transferring the knowledge to our dataset. In this attempt, we employ pre-trained VGG16, ResNet50, InceptionV3, and Xception models to classify three common maize leaf diseases using a dataset of 18,888 images of healthy and diseased leaves. Besides, Bayesian optimization is used to choose optimal values for hyperparameters, and image augmentation is used to improve the model&#39;s ability to generalize. The work includes a comparative study and analysis of the proposed models. The results demonstrate that all trained models have an accuracy of more than 93\% in classifying maize leaf diseases. In particular, VGG16, InceptionV3, and Xception achieved an accuracy of more than 99\%. Furthermore, our methodology provides new avenues for the detection of maize leaf diseases.},
  archive      = {J_NCA},
  author       = {Subramanian, Malliga and Shanmugavadivel, Kogilavani and Nandhini, P. S.},
  doi          = {10.1007/s00521-022-07246-w},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13951-13968},
  shortjournal = {Neural Comput. Appl.},
  title        = {On fine-tuning deep learning models using transfer learning and hyper-parameters optimization for disease identification in maize leaves},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved semantic segmentation with region proposal
network for cardiac defect interpretation. <em>NCA</em>,
<em>34</em>(16), 13937–13950. (<a
href="https://doi.org/10.1007/s00521-022-07217-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting cardiac abnormalities between 14 and 28 weeks of gestation with an apical four-chamber view is a difficult undertaking. Several unfavorable factors can prevent such detection, such as the fetal heart’s relatively small size, unclear appearances in anatomical structures (e.g., shadows), and incomplete tissue boundaries. Cardiac defects without segmentation are not always straightforward to detect, so using only segmentation cannot produce defect interpretation. This paper proposes an improved semantic segmentation approach that uses a region proposal network for septal defect detection and combines two processes: contour segmentation with U-Net architecture and defect detection with Faster-RCNN architecture. The model is trained using 764 ultrasound images that include three abnormal conditions (i.e., atrial septal defect, ventricular septal defect, and atrioventricular septal defect) and normal conditions from an apical four-chamber view. The proposed model produces a satisfactory mean intersection over union, mean average precision, and dice similarity component metrics of about 75\%, 87.80\%, and 96.37\%, respectively. Furthermore, the proposed model has also been validated on 71 unseen images in normal conditions and produces 100\% sensitivity, which means that all normal conditions without septal defects can be detected effectively. The developed model has the potential to identify the fetal heart in normal and pathological settings accurately. The developed deep learning model&#39;s practical use in identifying congenital heart disorders has substantial future promise.},
  archive      = {J_NCA},
  author       = {Nurmaini, Siti and Tama, Bayu Adhi and Rachmatullah, Muhammad Naufal and Darmawahyuni, Annisa and Sapitri, Ade Iriani and Firdaus, Firdaus and Tutuko, Bambang},
  doi          = {10.1007/s00521-022-07217-1},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13937-13950},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved semantic segmentation with region proposal network for cardiac defect interpretation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pre-trained deep learning-based classification of jujube
fruits according to their maturity level. <em>NCA</em>, <em>34</em>(16),
13925–13935. (<a
href="https://doi.org/10.1007/s00521-022-07213-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessment of crop maturity and quality is pivotal in the food industry and for harvesting. The manual classification of crops based on their maturity levels for harvesting and packaging purpose is a tedious process. However, the emergence of machine learning/deep learning techniques has opened up the ways in this direction, but its practical success is still limited. In this research, we examined two convolutional neural network paradigms (i.e., AlexNet and VGG16) utilizing a transfer-learning approach for classifying the jujube fruits based on their maturity level (i.e., unripe, ripe, and over-ripe). The training/testing of models was performed over the collected dataset of around 400 images, which was further augmented to 4398 images collectively for the three maturity classes. The best accuracy achieved for the correct classification of maturity classes with AlexNet and VGG16 for the actual and augmented images are 94.17\% &amp; 97.65\%, and 98.26\% &amp; 99.17\% respectively. The examined models were compared with two existing methods for jujube maturity classification and found to be performing better. The significantly improved success rate of VGG16 models over the AlexNet and existing proposed models for jujube classification makes the model recommendable for developing an efficient system for the automated harvesting and sorting of jujube fruits.},
  archive      = {J_NCA},
  author       = {Mahmood, Atif and Singh, Sanjay Kumar and Tiwari, Amod Kumar},
  doi          = {10.1007/s00521-022-07213-5},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13925-13935},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pre-trained deep learning-based classification of jujube fruits according to their maturity level},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). KAF + RSigELU: A nonlinear and kernel-based activation
function for deep neural networks. <em>NCA</em>, <em>34</em>(16),
13909–13923. (<a
href="https://doi.org/10.1007/s00521-022-07211-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Activation functions (AFs) are the basis for neural network architectures used in real-world problems to accurately model and learn complex relationships between variables. They are preferred to process the input information coming to the network and to produce the corresponding output. The kernel-based activation function (KAF) offers an extended version of ReLU and sigmoid AFs. Therefore, KAF faced with the problems of bias shift originating from the negative region, vanishing gradient, adaptability, flexibility, and neuron death in parameters during the learning process. In this study, hybrid KAF + RSigELUS and KAF + RSigELUD AFs, which are extended versions of KAF, are proposed. In the proposed AFs, the gauss kernel function is used. The proposed KAF + RSigELUS and KAF + RSigELUD AFs are effective in the positive, negative, and linear activation regions. Performance evaluations of them were conducted on the MNIST, Fashion MNIST, CIFAR-10, and SVHN benchmark datasets. The experimental evaluations show that the proposed AFs overcome existing problems and outperformed ReLU, LReLU, ELU, PReLU, and KAF AFs.},
  archive      = {J_NCA},
  author       = {Kiliçarslan, Serhat and Celik, Mete},
  doi          = {10.1007/s00521-022-07211-7},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13909-13923},
  shortjournal = {Neural Comput. Appl.},
  title        = {KAF + RSigELU: A nonlinear and kernel-based activation function for deep neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comparative study on prediction of survival event of heart
failure patients using machine learning algorithms. <em>NCA</em>,
<em>34</em>(16), 13895–13908. (<a
href="https://doi.org/10.1007/s00521-022-07201-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases cause approximately 17 million deaths each year and 31\% of deaths worldwide. These diseases generally occur as myocardial infarction and heart failure. The survival status, which we used as a target in our classification study, indicates that the patient died or survived before the end of the follow-up period, which is a mean of 130 days. Various machine learning classifiers have been preferred to both predict survival of patients and rank the characteristics corresponding to the most important risk factors. For this purpose, the data set that is occurred totally 299 samples is traditionally divided into 70\% for training and 30\% for test cluster to be used in machine learning algorithms, with have been analyzed with many methods such as Artificial Neural Networks, Fine Gaussian SVM, Fine KNN, Weighted KNN, Subspace KNN, Boosted Trees, and Bagged Trees. As a result, according to the data obtained, it has been seen that there are algorithms that can predict heart failure diagnosis with full accuracy (100\%). Thus, it was concluded that it is appropriate to use machine learning algorithms to predict whether a heart failure patient will survive. This study has the potential to be used as a new supportive tool for doctors when predicting whether a heart failure patient will survive.},
  archive      = {J_NCA},
  author       = {Özbay Karakuş, Mücella and Er, Orhan},
  doi          = {10.1007/s00521-022-07201-9},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13895-13908},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comparative study on prediction of survival event of heart failure patients using machine learning algorithms},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel drowsiness detection model using composite features
of head, eye, and facial expression. <em>NCA</em>, <em>34</em>(16),
13883–13893. (<a
href="https://doi.org/10.1007/s00521-022-07209-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drowsiness is the principal cause of road crashes nowadays, as per the existing data. Drowsiness may put many precious lives in jeopardy. Drowsiness may be detected early and accurately, which can save lives. Using computer vision and deep learning techniques, this research proposes a new approach to detect driver drowsiness at an early stage with improved accuracy. In our developed model, we have considered the most significant temporal features such as head pose angles (Yaw, Pitch, and Roll), centers of pupil movement, and distance for the emotional feature that help in the detection of drowsiness state more accurately. Our method solves the possibility of occluded frames at initial stage via imposing the occlusion criteria depending on the relationship of distance between pupil centers and the horizontal length of the eye. As a result, it outperformed existing approaches in terms of overall system accuracy and consistency. Furthermore, retrieved features from correct frames are used as training and test data by the long short-term memory network to classify the driver&#39;s state. Here, results are elaborated in terms of area under the curve-receiver operating characteristic curve scores.},
  archive      = {J_NCA},
  author       = {Pandey, Nageshwar Nath and Muppalaneni, Naresh Babu},
  doi          = {10.1007/s00521-022-07209-1},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13883-13893},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel drowsiness detection model using composite features of head, eye, and facial expression},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Customer satisfaction analysis and preference prediction in
historic sites through electronic word of mouth. <em>NCA</em>,
<em>34</em>(16), 13867–13881. (<a
href="https://doi.org/10.1007/s00521-022-07186-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cultural tourism is a continuously rapidly developing product which the global travel sector has experienced. Cultural products are a vital part of the economy and post-modern society. Satisfaction is a prominent factor in tourism and marketing literature. This paper aims to analyze customer satisfaction in historic sites through electronic word-of-mouth. We developed a new method through text mining, clustering and supervised learning techniques. The method is developed through latent dirichlet allocation for customer online reviews analysis, learning vector quantization to find important customers segments and Adaptive Neuro-Fuzzy Inference System for customer preference prediction in historic sites. The data are collected from TripAdvisor which is a comprehensive online review system in tourism and hospitality. The results revealed that electronic word-of-mouth (eWOM) effectively reveals customer satisfaction in historic sites through data analytical approaches.},
  archive      = {J_NCA},
  author       = {Nilashi, Mehrbakhsh and Fallahpour, Alireza and Wong, Kuan Yew and Ghabban, Fahad},
  doi          = {10.1007/s00521-022-07186-5},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13867-13881},
  shortjournal = {Neural Comput. Appl.},
  title        = {Customer satisfaction analysis and preference prediction in historic sites through electronic word of mouth},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stacked ResNet-LSTM and CORAL model for multi-site air
quality prediction. <em>NCA</em>, <em>34</em>(16), 13849–13866. (<a
href="https://doi.org/10.1007/s00521-022-07175-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the global economy is booming, and the industrialization and urbanization are being expedited, particulate matter 2.5 (PM2.5) turns out to be a major air pollutant jeopardizing public health. Numerous researchers are committed to employing various methods to address the problem of the nonlinear correlation between PM2.5 concentration and several factors to achieve more effective forecasting. However, a considerable space remains for the improvement of forecasting accuracy, and the problem of missing air pollution data on certain target areas also needs to be solved. Our research work is divided into two parts. First, this study presents a novel stacked ResNet-LSTM model to enhance prediction accuracy for PM2.5 concentration level forecast. As revealed from the experimental results, the proposed model outperforms other models such as boosting algorithms or general recurrent neural networks, and the advantage of feature extraction through residual network (ResNet) combined with a model stacking strategy is shown. Second, to solve the problem of insufficient air quality and meteorological data on some research areas, this study proposes the use of a correlation alignment (CORAL) method to carry out a prediction on the target area by aligning the second-order statistics between source area and target area. As indicated from the results, this model exhibits a considerable accuracy even in the absence of historical PM2.5 data in the target forecast area.},
  archive      = {J_NCA},
  author       = {Cheng, Xiangwei and Zhang, Wenwen and Wenzel, Adrian and Chen, Jia},
  doi          = {10.1007/s00521-022-07175-8},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13849-13866},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stacked ResNet-LSTM and CORAL model for multi-site air quality prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design of large-scale real-size steel structures using
various modified grasshopper optimization algorithms. <em>NCA</em>,
<em>34</em>(16), 13825–13848. (<a
href="https://doi.org/10.1007/s00521-022-07196-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, to improve the algorithmic performance of standard grasshopper optimization algorithm (GOA) that mimics the foraging characterizations of grasshoppers as in swarms, four modified versions of which are proposed to solve large-scale real-size complex both truss and frame type steel structures. All proposed GOA encoded are supplied reciprocatively data transfer with structural analysis software (SAP2000) to easily get the structural responses via open application programming interface functions. Initially, the algorithmic performances of standard GOA and its proposed modified versions are evaluated on two small-size benchmark engineering design problems, namely pressure vessel and grain train design problems. And then, a 160-bar space steel pyramid, a 693-bar space braced steel barrel vault, and a 455-member spatial braced steel frame are considered as large-scale real-size structural design problems. These structures are optimally designed to reach the best feasible economic structures with minimum design weights while satisfying the structural behavior limitations such as displacement, drift, strength, and stability that are taken from specifications of the American Institute of Steel Construction-Load and Resistance Factor Design. Consequently, the performances of all proposed GO algorithms in finding the optimum designs of large-scale real-size steel structures are compared and evaluated in detail.},
  archive      = {J_NCA},
  author       = {Aydogdu, Ibrahim and Ormecioglu, Tevfik Oguz and Tunca, Osman and Carbas, Serdar},
  doi          = {10.1007/s00521-022-07196-3},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13825-13848},
  shortjournal = {Neural Comput. Appl.},
  title        = {Design of large-scale real-size steel structures using various modified grasshopper optimization algorithms},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gravitation balanced multiple kernel learning for imbalanced
classification. <em>NCA</em>, <em>34</em>(16), 13807–13823. (<a
href="https://doi.org/10.1007/s00521-022-07187-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a category of classification problems where the samples of different classes are not represented equally. It arises in a variety of application areas and has been widely studied in pattern recognition. This paper focuses on enhancing the original data representation by combining the gravitation-based method with multiple empirical kernel approach, this paper proposes a sample level method known as the gravitational balanced multiple kernel learning (GBMKL) method. Our proposed GBMKL method integrates gravity strategy to generate the gravitation balanced midpoint samples (GBMS) located on the classification boundary; meanwhile, the classification boundary can be rectified by the nearest neighbors of the boundary (NNB) samples, which can improve the generalization performance. We further design two regularization terms corresponding to GBMS and NNB to avoid overfitting. In the training and testing process, the samples are mapped into multiple empirical kernel spaces to obtain more sufficient data representation. We conduct extensive computational experiments on 54 imbalanced datasets including both artificial and real-word datasets selected from knowledge extraction based on evolutionary learning datasets, the experimental results reveal interesting insights and show the advantages of the proposed GBMKL approach for dealing with the imbalanced classification problems. In addition, parameter analysis of two regularization terms confirms their positive impacts on the classification performance.},
  archive      = {J_NCA},
  author       = {Yang, Mengping and Wang, Zhe and Li, Yanqiong and Zhou, Yangming and Li, Dongdong and Du, Wenli},
  doi          = {10.1007/s00521-022-07187-4},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13807-13823},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gravitation balanced multiple kernel learning for imbalanced classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A parametric likelihood measure with beta distributions for
pythagorean fuzzy decision-making. <em>NCA</em>, <em>34</em>(16),
13757–13806. (<a
href="https://doi.org/10.1007/s00521-022-07151-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this research is to introduce a parametric likelihood measure based on the beta distribution and develop a likelihood-oriented methodology for solving multiple criteria decision analysis (MCDA) problems with Pythagorean fuzzy (PF) sets. With the rapid advancement of PF theory, exploring an effective approach to compare PF information is indispensable in resolving MCDA issues. The beta distribution is one the most commonly used distributions to simulate the theoretical distribution. By changing the parameter values, the beta distribution can generate symmetrical or asymmetrical patterns and various shapes, including flat or steep. Due to its flexibility and adaptability, the beta distribution is able to effectively solve complex real-world problems. To make a major contribution to the technical development of decision support applications, this paper utilizes beta distributions as a parameterization tool to introduce a new parametric likelihood measure for evaluating the outranking relationships among PF information (signified by Pythagorean membership grades). Based on the evolved likelihood-based concepts (e.g., mean outranking indices, weighted outranking grades, and comprehensive outranking measures and indices), this paper proposes a pragmatic PF likelihood-oriented method to prioritize competing alternatives under uncertain and ambiguous Pythagorean fuzzy conditions. To carefully examine the practicality and suitability of the proposed methodology in realistic decision-making environments, this paper utilizes the evolved methods to solve a realistic MCDA problem of selecting pilot hospitals in relation to postacute care. The main results that are generated by the practical application and subsequent experimental analysis and comparative study demonstrate the effectivity and superiority of the developed technique and can be used for practical purposes in flexible and convenient ways. This most important conclusion of this paper is the great aptitude and dominance of the proposed methodology based on the corroboration of the experimental and comparative results of the application. Furthermore, this study has a noticeable originality in the utilization of the generic beta distribution-based approach and the construction of an effective PF likelihood-oriented decision model, which enriches the development of decision-making applications with PF theory.},
  archive      = {J_NCA},
  author       = {Tsao, Chueh-Yung and Chen, Ting-Yu},
  doi          = {10.1007/s00521-022-07151-2},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13757-13806},
  shortjournal = {Neural Comput. Appl.},
  title        = {A parametric likelihood measure with beta distributions for pythagorean fuzzy decision-making},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing firefly algorithm with sliding window for
continuous optimization problems. <em>NCA</em>, <em>34</em>(16),
13733–13756. (<a
href="https://doi.org/10.1007/s00521-022-07193-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firefly algorithm (FA) is a simple and effective swarm intelligence algorithm, which has received wide attention from scholars. In original FA, each firefly must be compared with other fireflies in brightness, but it may not move, which may result in waste of system resources. Therefore, an enhancing firefly algorithm with sliding window (SWFA) is proposed in this paper to address the above problem. SWFA introduces sliding window mechanism to improve the attraction model of the FA, which is a technology used to ensure the reliability of data transmission in computer networks. The sliding window mechanism is essentially an archive mechanism, where the window denotes a form of archive, and sliding is the way the window updates. The update of the population is guided through the method of information exchange among individuals inside and outside the window. SWFA also combines the sliding window mechanism with reverse learning to reduce the number of comparisons and ensure every comparison is effective. Moreover, a novel adaptive step adjustment strategy is designed, which balances exploration and exploitation of FA. In order to verify the effectiveness of SWFA, extensive experiments are conducted on the CEC 2015 and CEC2013 test suite. Additionally, experiments are conducted on parameters estimation of chaotic systems and three practical engineering optimization problems. The results of the experiments show that the proposed algorithm has better performance.},
  archive      = {J_NCA},
  author       = {Peng, Hu and Qian, Jiayao and Kong, Fanrong and Fan, Debin and Shao, Peng and Wu, Zhijian},
  doi          = {10.1007/s00521-022-07193-6},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13733-13756},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing firefly algorithm with sliding window for continuous optimization problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards an end-to-end isolated and continuous deep gesture
recognition process. <em>NCA</em>, <em>34</em>(16), 13713–13732. (<a
href="https://doi.org/10.1007/s00521-022-07165-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavior recognition in video sequences is an interesting task in the computer vision field. Human action recognition, allows machines to analyze and comprehend several human activities from input data sources, such as sensors, and multimedia contents. It has been widely applied in public security, video surveillance, robotics and video games control, and industrial automation fields. However, in these applications, gestures are formed by complex temporal sequences of motions. This representation imposes many problems such as variations in action/gesture performers style, body shape and size and even the way that the same signer realize the motion, and various problems related to the scene environment like illumination changes and background complexity. Moreover, processing on large-scale continuous gesture data make these problems more challenging due to the unknown boundaries limit of each gesture embedded in the continuous sequence. In this work, we present a novel deep architecture for isolated actions and large scale continuous hand gesture recognition using RGB, depth, and gray-scale video sequences. The proposed approach, called End-to-End Deep Gesture Recognition Process (E2E-DGRP), considers a new representation of the data by extracting gesture characteristics. This is followed by an analysis of each sequence to detect and recognize the corresponding actions. Firstly, segmentation module spot each start and end gesture boundaries and segment continuous gesture sequences into several isolated gestures based on motion indicator method. Then, a set of discriminating features is generated characterizing motion location, motion velocity and motion orientation using a proposed method named “Deep Signature”. Generated features are fed to an additional neural network layer formed by a Softmax classifier which is an output layer for gesture classification purpose. The high performance of our approach is obtained by the experiments carried out on three well-known datasets KTH and Weizman for isolated actions in RGB and grayscale modality and Chalearn LAP ConGD dataset for continuous gesture in depth. A first experimental study shows that, the recognition results obtained by our method outperform those obtained by previously published approaches and it achieves 97.5 and 98.7\% in terms of accuracy with KTH and Weizmann datasets, respectively. A second experimental study, conducted using the Chalearn LAP ConGD data set, shows that our strategy outperforms other methods in terms of precision reaching 0.6661 as mean Jaccard Index.},
  archive      = {J_NCA},
  author       = {Mahmoud, Rihem and Belgacem, Selma and Omri, Mohamed Nazih},
  doi          = {10.1007/s00521-022-07165-w},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13713-13732},
  shortjournal = {Neural Comput. Appl.},
  title        = {Towards an end-to-end isolated and continuous deep gesture recognition process},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An axially decomposed self-attention network for the precise
segmentation of surface defects on printed circuit boards. <em>NCA</em>,
<em>34</em>(16), 13697–13712. (<a
href="https://doi.org/10.1007/s00521-022-07192-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The self-attention mechanism has been widely used to capture long-range relationships in various computer-vision tasks and is designed to update the representation of each pixel using a weighted sum of the features of all pixels in an image. However, it is computationally expensive, due to its potentially large matrix multiplication. It also does not make full use of position information, although this is crucial for modeling position-dependent interactions. To deal with these problems, the commonly used dot-product similarity is replaced by a position-aware similarity in this paper, which is introduced as a metric to evaluate the correlation between any two spatial positions. Then, on the basis of an axial decomposition operation, two concise and lightweight variants of self-attention are carefully constructed in sequence, namely the axial attention module and the complete decomposition module. The former decomposes only the first matrix multiplication of the self-attention mechanism, but the latter decomposes the entire process. Detailed experiments conducted on a real-world dataset of printed circuit board surface defects demonstrate the effectiveness and efficiency of the two variants. Their performance is comparable to that of state-of-the-art methods, and their computational costs is lower, which suggests that they could be widely utilized in various industrial inspection tasks based on computer vision.},
  archive      = {J_NCA},
  author       = {Kang, Danqing and Han, Yu and Zhu, Junyong and Lai, Jianhuang},
  doi          = {10.1007/s00521-022-07192-7},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13697-13712},
  shortjournal = {Neural Comput. Appl.},
  title        = {An axially decomposed self-attention network for the precise segmentation of surface defects on printed circuit boards},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantic-aware conditional variational autoencoder for
one-to-many dialogue generation. <em>NCA</em>, <em>34</em>(16),
13683–13695. (<a
href="https://doi.org/10.1007/s00521-022-07182-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the miscellaneous ambiguity of semantics in open-domain conversation, current deep dialogue models disregard to detect potential emotional and action response features in the latent space, which leads to the general tendency to produce inaccurate and irrelevant sentences. To address this problem, we propose a semantic-aware conditional variational autoencoder that discriminates the sentiment and action responses features in the latent space for one-to-many open-domain dialogue generation. Specifically, explicit controllable variables are leveraged from the proposed module to create diverse conversational texts. This controllable variable can constrain the distribution of the latent space, disentangling the latent space features during training. Furthermore, the feature disentanglement improves the dialogue generation in terms of deep learning interpretability and text quality, which also reveals the latent features of different emotions on the logic of text generation.},
  archive      = {J_NCA},
  author       = {Wang, Ye and Liao, Jingbo and Yu, Hong and Leng, Jiaxu},
  doi          = {10.1007/s00521-022-07182-9},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13683-13695},
  shortjournal = {Neural Comput. Appl.},
  title        = {Semantic-aware conditional variational autoencoder for one-to-many dialogue generation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Memristor-based affective associative memory neural network
circuit with emotional gradual processes. <em>NCA</em>, <em>34</em>(16),
13667–13682. (<a
href="https://doi.org/10.1007/s00521-022-07170-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the existing affective associative memory neural network circuits, the change of emotions in the affective associative learning and forgetting processes is abrupt and the intensity of emotions is invariable. In fact, the transition from one emotion to another is a gradual process. In this paper, to realize the progressive changes of emotional intensity in the affective associative memory neural network, the gradual learning, gradual forgetting and gradual transferring processes of emotions are proposed and the memristor-based circuit of the affective associative memory neural network is designed. In the designed circuit, the firing frequency of output neurons is closely correlated with the intensity of emotions. The higher the firing frequency of output neurons, the stronger the emotional intensity. Based on the associative memory rule, the dynamical change of the synaptic weights leads to the gradual variation of the frequencies of output neurons. Thus, the function of variable emotional intensity can be realized and the gradual processes can be achieved. The PSPICE simulation results are given to verify that the proposed circuit could realize the affective learning, forgetting and transferring functions with gradual processes.},
  archive      = {J_NCA},
  author       = {Liao, Meiling and Wang, Chunhua and Sun, Yichuang and Lin, Hairong and Xu, Cong},
  doi          = {10.1007/s00521-022-07170-z},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13667-13682},
  shortjournal = {Neural Comput. Appl.},
  title        = {Memristor-based affective associative memory neural network circuit with emotional gradual processes},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic stability for delayed semi-markovian genetic
regulatory networks with partly unknown transition rates by employing
new integral inequalities. <em>NCA</em>, <em>34</em>(16), 13649–13666.
(<a href="https://doi.org/10.1007/s00521-022-07177-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the stochastic stability for genetic regulatory networks (GRNs) with semi-Markov switching and time-varying delays where the transition rates (TRs) of the modes are partially unknown. By proposing vectors with three Legendre polynomials and three weighted Legendre polynomials, two free-matrix-based integral inequalities are derived, which involves several existing ones as their special cases. Then, two appropriate Lyapunov–Krasovskii functionals (LKFs) are established to be apt for the acquired inequalities. By introducing some free-weight matrices and utilizing the acquired integral inequalities, new sufficient conditions are proposed to ensure the stochastically asymptotic stability of analyzed networks in the mean-square sense. Finally, two simulation examples are put forward to show the effectiveness and less conservatism of the presented criteria.},
  archive      = {J_NCA},
  author       = {Zheng, Cheng-De and Zhang, Zeda and Lu, Yu and Zhang, Huaguang},
  doi          = {10.1007/s00521-022-07177-6},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13649-13666},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stochastic stability for delayed semi-markovian genetic regulatory networks with partly unknown transition rates by employing new integral inequalities},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Understanding users’ requirements precisely: A double
bi-LSTM-CRF joint model for detecting user’s intentions and slot tags.
<em>NCA</em>, <em>34</em>(16), 13639–13648. (<a
href="https://doi.org/10.1007/s00521-022-07171-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding users’ requirements are essential to developing an effective AI service system, in which requirement expressions of users can be resolved into intent detection and slot filling tasks. In a lot of literature, the two tasks are normally considered as independent tasks and obtain satisfactory performance. Recently, many researchers have found that intent detection and slot filling can benefit each other since they always appear together in a sentence and may include shared information. Most of the existing joint models employ the structures of encoder and decoder and capture the cross-impact between two tasks by concatenation of hidden state information from two encoders, which ignore the dependencies among slot tags in specific intent. In this paper, we propose a novel Double-Bi-LSTM-CRF Model (DBLC), which can fit the dependency among hidden slot tags while considering the cross-impact between intent detection and slot filling. We also design and implement an intention chatbot on the tourism area, which can assist users to complete a travel plan through human-computer interaction. Extensive experiments show that our DBLC achieves state-of-the-art results on the benchmark ATIS, SNIPS, and multi-domain datasets.},
  archive      = {J_NCA},
  author       = {Li, Chunshan and Zhou, Yingli and Chao, Guoqing and Chu, Dianhui},
  doi          = {10.1007/s00521-022-07171-y},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13639-13648},
  shortjournal = {Neural Comput. Appl.},
  title        = {Understanding users’ requirements precisely: A double bi-LSTM-CRF joint model for detecting user’s intentions and slot tags},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fuzzy approach for multi criteria decision making in diet
plan ranking system using cuckoo optimization. <em>NCA</em>,
<em>34</em>(16), 13625–13638. (<a
href="https://doi.org/10.1007/s00521-022-07163-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent days, people have easily adapted to unhealthy diets due to their busy lifestyles. Inappropriate and unhealthy food intake leads to various health problems. As a result of poor health and lack of information about a healthy diet, people depend on medicines rather than concentrating on improving their food intake. Due to the wide range of dietary advice, it is difficult to choose the appropriate diet plan that satisfies their personalized nutritional needs. The proposed system ranks the diet plan by considering personal information like age, gender, height, weight, pressure and heart rate. Various diet plans like intermittent fasting, plant-based diets, low-carb diets, paleo diet, low-fat diets, Mediterranean diet, DASH diet, vegan diet, gluten-free diet, GM diet and egg diet are considered. Multi-criteria decision-making methods such as fuzzy AHP and fuzzy TOPSIS are also applied for the decision-making process to rank the best diet plan. Fuzzy AHP is used for weight generation, which is given to the cuckoo algorithm for optimization, and then, the fuzzy TOPSIS method helps in ranking the diet plan. Personal information is considered as criteria, and the diet plans are considered as alternatives for the decision-making process.},
  archive      = {J_NCA},
  author       = {Haseena, S. and Saroja, S. and Revathi, T.},
  doi          = {10.1007/s00521-022-07163-y},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13625-13638},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fuzzy approach for multi criteria decision making in diet plan ranking system using cuckoo optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rules embedded harris hawks optimizer for large-scale
optimization problems. <em>NCA</em>, <em>34</em>(16), 13599–13624. (<a
href="https://doi.org/10.1007/s00521-022-07146-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harris Hawks Optimizer (HHO) is a recent optimizer that was successfully applied for various real-world problems. However, working under large-scale problems requires an efficient exploration/exploitation balancing scheme that helps HHO to escape from possible local optima stagnation. To achieve this objective and boost the search efficiency of HHO, this study develops embedded rules used to make adaptive switching between exploration/exploitation based on search performances. These embedded rules were formulated based on several parameters such as population status, success rate, and the number of consumed search iterations. To verify the effectiveness of these embedded rules in improving HHO performances, a total of six standard high-dimensional functions ranging from 1000-D to 10,000-D and CEC’2010 large-scale benchmark were employed in this study. In addition, the proposed Rules Embedded Harris Hawks Optimizer (REHHO) applied for one real-world high dimensional wavelength selection problem. Conducted experiments showed that these embedded rules significantly improve HHO in terms of accuracy and convergence curve. In particular, REHHO was able to achieve superior performances against HHO in all conducted benchmark problems. Besides that, results showed that faster convergence was obtained from the embedded rules. Furthermore, REHHO was able to outperform several recent and state-of-the-art optimization algorithms.},
  archive      = {J_NCA},
  author       = {Samma, Hussein and Sama, Ali Salem Bin},
  doi          = {10.1007/s00521-022-07146-z},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13599-13624},
  shortjournal = {Neural Comput. Appl.},
  title        = {Rules embedded harris hawks optimizer for large-scale optimization problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recurrent neural network variants based model for
cassini-huygens spacecraft trajectory modifications recognition.
<em>NCA</em>, <em>34</em>(16), 13575–13598. (<a
href="https://doi.org/10.1007/s00521-022-07145-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last 13.7 years period of the Cassini mission, amendments to the spacecraft’s flight path were needed. This research is being carried out as there is a limited number of studies that use a temporal discrimination analysis to handle raw data. More complex inspection and analysis of the collected broad trajectory dataset is necessary to classify orbital events in the signal travel period (approximately 88 minutes on the Earth-Cassini travel channel length). This paper provides an innovative, in-depth learning method to identify offline modifications in the Cassini spacecraft trajectory. The models are based on variants of Recurrent Neural Networks (RNNs: Gated Recurrent Unit (GRU)/ Long Short-Term Memory (LSTM)/ Bidirectional Long Short-Term Memory (BiLSTM)) to derive valuable data and learn the inner data structure of the time sequence, along with the penetration of long-term and short-term phase-dependencies of the RNNs layers. To validate our models, we used a variety of statistical approaches in our analysis. A considerable number of tests have been carried out, and the findings obtained have shown that the GRU and LSTM give a substantial boost to increasing the efficiency of the detection mechanism. The proposed model would consolidate potential exploration in outer space exploration to accommodate massive databases, search for correlations, and recognize complex events and outliers with an accuracy that exceeds 99\%. This method can be utilized for similar detection processes within the future outer space expedition. The results show that binary classifications of Matthews Correlation Coefficient (MCC) are more accurate than $$F_1$$ score.},
  archive      = {J_NCA},
  author       = {ALDabbas, Ashraf and Gal, Zoltan},
  doi          = {10.1007/s00521-022-07145-0},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13575-13598},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recurrent neural network variants based model for cassini-huygens spacecraft trajectory modifications recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel prostate segmentation method: Triple fusion model
with hybrid loss. <em>NCA</em>, <em>34</em>(16), 13559–13574. (<a
href="https://doi.org/10.1007/s00521-022-07188-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early and rapid diagnosis of prostate cancer, the horsehead disease among men, has become increasingly important. Nowadays, many methods are used in the early diagnosis of prostate cancer. Compared to other imaging methods, magnetic resonance imaging (MRI) based on prostate gland imaging is preferred because angular imaging (axial, sagittal, and coronal) provides precise information. But diagnosing the disease from these MR images is time-consuming. For example, imaging differences between MR devices for prostate segmentation and inhomogeneous and inconsistent prostate appearance are significant challenges. Because of these segmentation difficulties, manual segmentation of prostate images is challenging. In recent years, computer-aided intelligent architectures (deep learning-based architecture) have been used to overcome the manual segmentation of prostate images. These architectures can now perform manual prostate segmentation in seconds that used to take days thanks to their end-to-end automatic deep convolutional neural networks (DCNN). Inspired by the studies mentioned above, this study proposes a novel DCNN approach for prostate segmentation by combining ResUnet 2D with residual blocks and Edge Attention Vnet 3D architectures. In addition, the weighted foal Twersky loss function, which was proposed for the first time, significantly increased the architecture&#39;s performance. Evaluation experiments were performed on the MICCAI 2012 Prostate Segmentation Challenge Dataset (PROMISE12) and the NCI-ISBI 2013(NCI_ISBI-13) Prostate Segmentation Challenge Dataset. As a result of the tests performed, Dice scores of 91.92 and 91.15\% in the whole prostate volume were obtained in the Promise 12 and NCI_ISBI 13 datasets, respectively. Comparative analyses show that the advantages and robustness of our method are superior to the state-of-the-art approaches.},
  archive      = {J_NCA},
  author       = {Ocal, Hakan and Barisci, Necaattin},
  doi          = {10.1007/s00521-022-07188-3},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13559-13574},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel prostate segmentation method: Triple fusion model with hybrid loss},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-performance UAVs visual tracking using deep
convolutional feature. <em>NCA</em>, <em>34</em>(16), 13539–13558. (<a
href="https://doi.org/10.1007/s00521-022-07181-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of visual tracking down unmanned aerial vehicles (UAVs) is an important research direction. Although many existing UAVs visual trackers exploit the features of deep convolution to effectively improve the robustness of trackers, the target features extracted by convolutional neural network (CNN) are difficult to distinguish when facing occlusion, illumination variation, viewpoint change, deformation, and scale variation. Especially for distractors (such as similar objects), these trackers cannot capture temporary appearance changes. In this work, we propose an efficient UAVs visual tracker, which can effectively alleviate the impact of occlusion, viewpoint change, and illumination. First, we stretch the width of the network to acquire affluent target appearance feature information. Then, we design an attention information fusion module (AIFM) to enhance feature extraction, which can effectively establish the correspondence relationship of long-range pixel pairs between the template frame and the detection frame. The ability of the tracker to distinguish the target can be effectively improved through suppressing the global background response. Furthermore, we design a multi-spectral information fusion module (MSIFM) to dynamically learn the appearance features of the detection frame target corresponding to the template frame features, which can improve the prediction accuracy of the bounding box. Finally, the distance intersection over union is employed to evaluate the object location and complete the prediction of the bounding box. Abundant experiments demonstrate that the proposed method has powerful tracking performance in a diversity of UAVs scenarios.},
  archive      = {J_NCA},
  author       = {Yang, Shuaidong and Xu, Jin and Chen, Haiyun and Wang, Min},
  doi          = {10.1007/s00521-022-07181-w},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13539-13558},
  shortjournal = {Neural Comput. Appl.},
  title        = {High-performance UAVs visual tracking using deep convolutional feature},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). One-step model agnostic meta-learning using two-phase
switching optimization strategy. <em>NCA</em>, <em>34</em>(16),
13529–13537. (<a
href="https://doi.org/10.1007/s00521-022-07160-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional training mechanisms often encounter limited classification performance due to the need of large training samples. To counter such an issue, the field of meta-learning has shown great potential in fine tuning and generalizing to new tasks using mini dataset. As a variant derived from the concept of Model Agnostic Meta-Learning (MAML), an one-step MAML incorporated with the two-phase switching optimization strategy is proposed in this paper to improve performance using less iterations. One-step MAML uses two loops to conduct the training, known as the inner and the outer loop. During the inner loop, gradient update is performed only once per task. At the outer loop, gradient is updated based on losses accumulated by the evaluation set during each inner loop. Several experiments using the BERT-Tiny model are conducted to analyze and compare the performance of the one-step MAML with five benchmark datasets. The performance of evaluation shows that the best loss and accuracy can be achieved using one-step MAML that is coupled with the two-phase switching optimizer. It is also observed that this combination reaches its peak accuracy with the fewest number of steps.},
  archive      = {J_NCA},
  author       = {Mahmud, Saad and Lim, King Hann},
  doi          = {10.1007/s00521-022-07160-1},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13529-13537},
  shortjournal = {Neural Comput. Appl.},
  title        = {One-step model agnostic meta-learning using two-phase switching optimization strategy},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimized feature selection method using particle swarm
intelligence with ensemble learning for cancer classification based on
microarray datasets. <em>NCA</em>, <em>34</em>(16), 13513–13528. (<a
href="https://doi.org/10.1007/s00521-022-07147-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is considered a leading cause of mortality in both developed and developing countries. Cancer classification based on the microarray dataset has provided insight into possible treatment strategies. A complicated and high-dimensional number of genes and a few numbers of instances are characteristics of the microarray datasets. Gene selection is therefore a challenging and required task for the data analysis of microarray expression. The selection of genes may reveal insight into the underlying mechanism of a particular biological phenomenon. Several academics have recently developed methods of feature selection, utilizing metaheuristic algorithms for interpreting and analyzing microarray data. Nevertheless, due to the few numbers of samples in microarray data compared to the high dimensionality, several data mining approaches have been unsuccessful to select the most relevant and informatics genes. As a result, incorporating various classifiers can enhance feature selection and classification performance. The current study aims to propose a method for cancer classification by employing ensemble learning. Hence, in this paper, particle swarm optimization and an ensemble learning method collaborate for feature selection and cancer classification. As a result, the analysis indicates the effectiveness of the proposed method for cancer classification based on microarray datasets, and in terms of accuracy, the performance outcomes are 100\%, 92.86\%, 86.36\%, 100\%, 85.71\% for leukemia, colon, breast cancer, ovarian, and central nervous system, respectively, which overcome most of the state-of-the-art methods and also dominance on the baseline ensemble method with 12\% enhancement.},
  archive      = {J_NCA},
  author       = {Alrefai, Nashat and Ibrahim, Othman},
  doi          = {10.1007/s00521-022-07147-y},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13513-13528},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimized feature selection method using particle swarm intelligence with ensemble learning for cancer classification based on microarray datasets},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection of ring cell cancer in histopathological images
with region of interest determined by SLIC superpixels method.
<em>NCA</em>, <em>34</em>(16), 13499–13512. (<a
href="https://doi.org/10.1007/s00521-022-07183-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gastric cancer is the sixth most common cancer and the fourth leading cause of cancer deaths worldwide. Gastric cancer presents with a more insidious onset and is most frequently discovered at an advanced stage. Early diagnosis is critical since the stage of the disease is determinant in the severity, treatment, and survival rate of cancer. In the study, the Region of Interest (RoI) was determined in histopathological images using image preprocessing techniques and signet ring cell carcinoma (SRCC) was detected with popular deep learning models VGG16, VGG19, and InceptionV3. The fine-tuning strategy was applied by customizing the last five layers of deep network models based on the target data. The parameters of accuracy, precision, recall, and F1-score were used to evaluate the model performance. Signet ring cell dataset taken from the competition “Digestive System Pathological Detection, and Segmentation Challenge 2019” was employed. When compared to results of the DigestPath2019 Grand challenge ring cell gastric cancer competition, higher accuracy rates were obtained using deep learning models with the accurate defined RoI images. VGG16 model exhibited a higher performance with accuracy of 95\% and a F1-score of 95\% among the models. The results obtained by the algorithm were analyzed and confirmed by the experienced pathologist.},
  archive      = {J_NCA},
  author       = {Budak, Cafer and Mençik, Vasfiye},
  doi          = {10.1007/s00521-022-07183-8},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13499-13512},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection of ring cell cancer in histopathological images with region of interest determined by SLIC superpixels method},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ViRFD: A virtual-realistic fused dataset for rock size
analysis in TBM construction. <em>NCA</em>, <em>34</em>(16),
13485–13498. (<a
href="https://doi.org/10.1007/s00521-022-07179-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In TBM (Tunnel Boring Machine) construction process, the rock size analysis system plays an important role in assisting driving. Its core algorithm is based on semantic segmentation, and it brings challenges to dataset acquisition in real applications. To relieve this problem, this paper proposes a virtual-realistic fused dataset, short for ViRFD. The R-part is composed of a realistic dataset from our previous work, and the V-part is simulated by a learning-based method proposed in this paper. Unlike traditional manual methods, we use a virtual engine (Unity) to simulate datasets, since the corresponding ground-truth labels can be automatically extracted by the engine. Specifically, we propose a novel synthetic dataset simulator, named RockSegX. It contains abundant virtual 3D resources to ensure the diversity and fidelity of generated datasets. The main feature of RockSegX lies in its content flexibility, i.e., we are able to control the content of dataset by adjusting the values of several attributes. These attributes are carefully designed for reducing the content difference between V-part and R-part datasets. And we employ a learning-based method to automatically adjust the attributes so that the V-part dataset has the smallest content difference with the R-part. Experimental results show the effectiveness of our method in improving the quality of simulated dataset, and it further boosts the test accuracy for real-world segmentation.},
  archive      = {J_NCA},
  author       = {Xue, Zhenfeng and Chen, Liang and Liu, Zhitao and Liu, Yong and Mao, Weijie},
  doi          = {10.1007/s00521-022-07179-4},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13485-13498},
  shortjournal = {Neural Comput. Appl.},
  title        = {ViRFD: A virtual-realistic fused dataset for rock size analysis in TBM construction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep cross-modal discriminant adversarial learning for
zero-shot sketch-based image retrieval. <em>NCA</em>, <em>34</em>(16),
13469–13483. (<a
href="https://doi.org/10.1007/s00521-022-07169-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot sketch-based image retrieval (ZS-SBIR) is an extension of sketch-based image retrieval (SBIR) that aims to search relevant images with query sketches of the unseen categories. Most previous methods focus more on preserving semantic knowledge and improving domain alignment performance, but neglect to capture the correlation between inter-modal features, resulting in unsatisfactory performance. Hence, a sketch-image cross-modal retrieval framework is proposed to maximize the sketch-image correlation. For this framework, we develop a discriminant adversarial learning method that incorporates intra-modal discrimination, inter-modal consistency, and inter-modal correlation into a deep learning network for common feature representation learning. Specifically, sketch and image features are first projected into a shared feature subspace to achieve modality-invariance. Subsequently, we adopt a category label predictor to achieve intra-modal discrimination, use adversarial learning to confuse modal information for inter-modal consistency, and introduce correlation learning to maximize inter-modal correlation. Finally, the trained deep learning model is used to test unseen categories. Extensive experiments conducted on three zero-shot datasets show that this method outperforms state-of-the-art methods. For retrieval accuracy of unseen categories, this method exceeds the state-of-the-art methods by approximately 0.6\% on the RSketch dataset, 5\% on the Sketchy dataset, and 7\% on the TU-Berlin dataset. We also conduct experiments on the dataset of image-based 3D model scene retrieval, the proposed method significantly outperforms the state-of-the-art approaches in all standard metrics.},
  archive      = {J_NCA},
  author       = {Jiao, Shichao and Han, Xie and Xiong, Fengguang and Yang, Xiaowen and Han, Huiyan and He, Ligang and Kuang, Liqun},
  doi          = {10.1007/s00521-022-07169-6},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13469-13483},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep cross-modal discriminant adversarial learning for zero-shot sketch-based image retrieval},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An information propagation model for social networks based
on continuous-time quantum walk. <em>NCA</em>, <em>34</em>(16),
13455–13468. (<a
href="https://doi.org/10.1007/s00521-022-07168-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing social network simulation models exhibit several limitations, including extensive iteration requirements and multiple control parameters. In this study, an information propagation model based on continuous-time quantum walk (CTQW-IPM) is introduced to rank crucial individuals in undirected social networks. In the proposed CTQW-IPM, arbitrary individuals (or groups) can be specified as initial diffusion dynamic elements through preset probability amplitudes. Information diffusion on a global reachable path is then simulated by an evolution operator, as individual degrees of cruciality are estimated from probability distributions acquired from quantum observations. CTQW-IPM does not require iterations, due to the non-randomness of CTQW, and does not include extensive computations as complex cascade diffusion processes are replaced by evolution operators. Experimental comparisons of CTQW-IPM and several conventional models showed their ranking of crucial individuals exhibited a strong correlation, with nearly every individual in the social network assigned a unique measured value based on the rate of distinguishability. CTQW-IPM also outperformed other algorithms in influence maximization problems, as measured by the resulting spread size.},
  archive      = {J_NCA},
  author       = {Yan, Fei and Liang, Wen and Hirota, Kaoru},
  doi          = {10.1007/s00521-022-07168-7},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13455-13468},
  shortjournal = {Neural Comput. Appl.},
  title        = {An information propagation model for social networks based on continuous-time quantum walk},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Brain–computer interface for amyotrophic lateral sclerosis
patients using deep learning network. <em>NCA</em>, <em>34</em>(16),
13439–13453. (<a
href="https://doi.org/10.1007/s00521-020-05026-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individuals with Motor Neuron Disease were unable to move from one place to another because it gradually reduced all the voluntarily movement due to the degeneration of upper and lower motors neurons. The solution to this problem was to develop rehabilitating devices using biosignals. In this study, we have designed and developed electrooculogram-based wheelchair control using Cross Power Spectral Density. The convolution neural network to verify the performance and recognition accuracy of the wheelchair navigation in the indoor environment by using four trained users and four untrained users between the different age-groups and obtained the accuracy of 91.18\% and 86.88\% by using four fundamental tasks. From the indoor performance, the subject S4 from trained users outperforms all the trained subjects with an average classification accuracy of 93.51\%. To verify the recognition accuracy, we conducted the online performance from the online performances subject S4 from trained subjects outperforms remaining trained subjects at the same time the subject S6 from untrained subjects outperforms all the untrained subjects. From the entire study, we analyzed that classification accuracy of subjects S4 was appreciated compared to other subjects. Through the research, we confirmed that the entire trained subject’s performance was maximum compared to the untrained subjects in all the circumstances.},
  archive      = {J_NCA},
  author       = {Ramakrishnan, Jayabrabu and Mavaluru, Dinesh and Sakthivel, Ramkumar Siva and Alqahtani, Abdulrahman Saad and Mubarakali, Azath and Retnadhas, Mervin},
  doi          = {10.1007/s00521-020-05026-y},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13439-13453},
  shortjournal = {Neural Comput. Appl.},
  title        = {Brain–computer interface for amyotrophic lateral sclerosis patients using deep learning network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A real-time embedded drogue detection method based on
lightweight convolution neural network for autonomous aerial refueling.
<em>NCA</em>, <em>34</em>(16), 13425–13437. (<a
href="https://doi.org/10.1007/s00521-022-07153-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drogue detection is a crucial component for autonomous aerial refueling. Drogue detection requires robust detection of the drogue in real time and different environments. A real-time embedded drogue detection method based on quantized convolutional neural networks is proposed in this paper to cope with this issue. A backbone network that is based on a multi-receptive field stem and multi-receptive field dense blocks are designed to quickly extract the features of images. An optimized detection network that is based on a depth-wise separable residual prediction block is used to achieve drogue detection in real time. A real aerial refueling dataset was built for training network model. A ground test and video sequences experiment were conducted to demonstrate the effectiveness, robustness, and real time of the proposed approach.},
  archive      = {J_NCA},
  author       = {Ma, Yuebo and Zhao, Rujin and Yan, Kun and Liu, Enhai},
  doi          = {10.1007/s00521-022-07153-0},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13425-13437},
  shortjournal = {Neural Comput. Appl.},
  title        = {A real-time embedded drogue detection method based on lightweight convolution neural network for autonomous aerial refueling},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fuzzy-based adaptive multi-input–output scheme in lieu of
diabetic and hypertension management for post-operative patients: An
human–machine interface approach with its continuum. <em>NCA</em>,
<em>34</em>(16), 13407–13423. (<a
href="https://doi.org/10.1007/s00521-020-04975-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Here, a multi-input–output control strategy-based adaptive system is implemented to regulate the glycaemic and hypertension (HT) level concurrently for post-operative patients. The current medical research identifies the relationship between diabetes and HT, and these two diseases have possible overlap in their disease aetiology. Based on the continuum, the blood glucose and blood pressure (BP) have to be measured independently and control the infusion to maintain optimally based on the variations of diabetic mellitus and HT to avoid the major complications for the perioperative condition. Based on the analysis, the post-operative strain may increase HT and may increase the glycaemic level, and this uncertainty of disparity may lead to BP, hyperinsulinemia, cardio diseases, and osmotic diuresis along with hyperglycaemia. The proposed adaptive cascade control strategy illustrates two different types of control loops independently, and these loops adopt an adaptive control strategy with parametric compensation. This adaptive control algorithm integrates the cascade methodology along with expert knowledge to treat these diseases by using adaptation laws with the help of fuzzy logic to regulate the proper insulin and sodium nitroprusside (SNP) infusion. The output response of the plasma glucose concentration and HT regulation was shown along with insulin infusion rate and SNP infusion rate based on the extensive simulation readings. The attained simulation results demonstrate that the adaptive control strategy shows better outcomes for the infusion and may achieve potentially better control on HT and glycaemic levels for post-operative patients.},
  archive      = {J_NCA},
  author       = {Alavudeen Basha, A. and Vivekanandan, S.},
  doi          = {10.1007/s00521-020-04975-8},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13407-13423},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fuzzy-based adaptive multi-input–output scheme in lieu of diabetic and hypertension management for post-operative patients: An human–machine interface approach with its continuum},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Applications of graph convolutional networks in computer
vision. <em>NCA</em>, <em>34</em>(16), 13387–13405. (<a
href="https://doi.org/10.1007/s00521-022-07368-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Network (GCN) which models the potential relationship between non-Euclidean spatial data has attracted researchers’ attention in deep learning in recent years. It has been widely used in different computer vision tasks by modeling the latent space, topology, semantics, and other information in Euclidean spatial data and has achieved significant success. To better understand the work principles and future GCN applications in the computer vision field, this study reviewed the basic principles of GCN, summarized the difficulties and solutions using GCN in different visual tasks, and introduced in detail the methods for constructing graphs from the Euclidean spatial data in different visual tasks. At the same time, the review divided the application of GCN in basic visual tasks into image recognition, object detection, semantic segmentation, instance segmentation and object tracking. The role and performance of GCN in basic visual tasks were summarized and compared in detail for different tasks. This review emphasizes that the application of GCN in computer vision faces three challenges: computational complexity, the paradigm of constructing graphs from the Euclidean spatial data, and the interpretability of the model. Finally, this review proposes two future trends of GCN in the vision field, namely model lightweight and fusing GCN with other models to improve the performance of the visual model and meet the higher requirements of vision tasks.},
  archive      = {J_NCA},
  author       = {Cao, Pingping and Zhu, Zeqi and Wang, Ziyuan and Zhu, Yanping and Niu, Qiang},
  doi          = {10.1007/s00521-022-07368-1},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13387-13405},
  shortjournal = {Neural Comput. Appl.},
  title        = {Applications of graph convolutional networks in computer vision},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attention mechanism in neural networks: Where it comes and
where it goes. <em>NCA</em>, <em>34</em>(16), 13371–13385. (<a
href="https://doi.org/10.1007/s00521-022-07366-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A long time ago in the machine learning literature, the idea of incorporating a mechanism inspired by the human visual system into neural networks was introduced. This idea is named the attention mechanism, and it has gone through a long development period. Today, many works have been devoted to this idea in a variety of tasks. Remarkable performance has recently been demonstrated. The goal of this paper is to provide an overview from the early work on searching for ways to implement attention idea with neural networks until the recent trends. This review emphasizes the important milestones during this progress regarding different tasks. By this way, this study aims to provide a road map for researchers to explore the current development and get inspired for novel approaches beyond the attention.},
  archive      = {J_NCA},
  author       = {Soydaner, Derya},
  doi          = {10.1007/s00521-022-07366-3},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13371-13385},
  shortjournal = {Neural Comput. Appl.},
  title        = {Attention mechanism in neural networks: Where it comes and where it goes},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Differentially private multivariate time series forecasting
of aggregated human mobility with deep learning: Input or gradient
perturbation? <em>NCA</em>, <em>34</em>(16), 13355–13369. (<a
href="https://doi.org/10.1007/s00521-022-07393-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of forecasting multivariate aggregated human mobility while preserving the privacy of the individuals concerned. Differential privacy, a state-of-the-art formal notion, has been used as the privacy guarantee in two different and independent steps when training deep learning models. On one hand, we considered gradient perturbation, which uses the differentially private stochastic gradient descent algorithm to guarantee the privacy of each time series sample in the learning stage. On the other hand, we considered input perturbation, which adds differential privacy guarantees in each sample of the series before applying any learning. We compared four state-of-the-art recurrent neural networks: Long Short-Term Memory, Gated Recurrent Unit, and their Bidirectional architectures, i.e., Bidirectional-LSTM and Bidirectional-GRU. Extensive experiments were conducted with a real-world multivariate mobility dataset, which we published openly along with this paper. As shown in the results, differentially private deep learning models trained under gradient or input perturbation achieve nearly the same performance as non-private deep learning models, with loss in performance varying between $$0.57$$ and $$2.8\%$$ . The contribution of this paper is significant for those involved in urban planning and decision-making, providing a solution to the human mobility multivariate forecast problem through differentially private deep learning models.},
  archive      = {J_NCA},
  author       = {Arcolezi, Héber Hwang and Couchot, Jean-François and Renaud, Denis and Al Bouna, Bechara and Xiao, Xiaokui},
  doi          = {10.1007/s00521-022-07393-0},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13355-13369},
  shortjournal = {Neural Comput. Appl.},
  title        = {Differentially private multivariate time series forecasting of aggregated human mobility with deep learning: Input or gradient perturbation?},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CGAN-based synthetic multivariate time-series generation: A
solution to data scarcity in solar flare forecasting. <em>NCA</em>,
<em>34</em>(16), 13339–13353. (<a
href="https://doi.org/10.1007/s00521-022-07361-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the major bottlenecks in refining supervised algorithms is data scarcity. This might be caused by a number of reasons often rooted in extremely expensive and lengthy data collection processes. In natural domains such as Heliophysics, it may take decades for sufficiently large samples for machine learning purposes. Inspired by the massive success of generative adversarial networks (GANs) in generating synthetic images, in this study we employed the conditional GAN (CGAN) on a recently released benchmark dataset tailored for solar flare forecasting. Our goal is to generate synthetic multivariate time-series data that (1) are statistically similar to the real data and (2) improve the performance of flare prediction when used to remedy the scarcity of strong flares. To evaluate the generated samples, first, we used the Kullback–Leibler divergence and adversarial accuracy measures to quantify the similarity between the real and synthetic data in terms of their descriptive statistics. Second, we evaluated the impact of the generated samples by training a predictive model on their descriptive statistics, which resulted in a significant improvement (over 1100\% in TSS and 350\% in HSS). Third, we used the generated time series to examine their high-dimensional contribution to mitigating the scarcity of the strong flares, which we also observed a significant improvement in terms of TSS (4\%, 7\%, and 31\%) and HSS (75\%, 35\%, and 72\%), compared to oversampling, undersampling, and synthetic oversampling methods, respectively. We believe our findings can open new doors toward more robust and accurate flare forecasting models.},
  archive      = {J_NCA},
  author       = {Chen, Yang and Kempton, Dustin J. and Ahmadzadeh, Azim and Wen, Junzhi and Ji, Anli and Angryk, Rafal A.},
  doi          = {10.1007/s00521-022-07361-8},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13339-13353},
  shortjournal = {Neural Comput. Appl.},
  title        = {CGAN-based synthetic multivariate time-series generation: A solution to data scarcity in solar flare forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A convolutional neural network based approach to financial
time series prediction. <em>NCA</em>, <em>34</em>(16), 13319–13337. (<a
href="https://doi.org/10.1007/s00521-022-07143-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial time series are chaotic that, in turn, leads their predictability to be complex and challenging. This paper presents a novel financial time series prediction hybrid that involves Chaos Theory, Convolutional neural network (CNN), and Polynomial Regression (PR). The financial time series is first checked in this hybrid for the presence of chaos. The chaos in the series of times is later modeled using Chaos Theory. The modeled time series is input to CNN to obtain initial predictions. The error series obtained from CNN predictions is fit by PR to get error predictions. The error predictions and initial predictions from CNN are added to obtain the final predictions of the hybrid model. The effectiveness of the proposed hybrid (Chaos+CNN+PR) is tested by using three types of Foreign exchange rates of financial time series (INR/USD, JPY/USD, SGD/USD), commodity prices (Gold, Crude Oil, Soya beans), and stock market indices (S&amp;P 500, Nifty 50, Shanghai Composite). The proposed hybrid is superior to Auto-regressive integrated moving averages (ARIMA), Prophet, Classification and Regression Tree (CART), Random Forest (RF), CNN, Chaos+CART, Chaos+RF and Chaos+CNN in terms of MSE, MAPE, Dstat, and Theil’s U.},
  archive      = {J_NCA},
  author       = {Durairaj, Dr. M. and Mohan, B. H. Krishna},
  doi          = {10.1007/s00521-022-07143-2},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13319-13337},
  shortjournal = {Neural Comput. Appl.},
  title        = {A convolutional neural network based approach to financial time series prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recurrent neural network model for high-speed train
vibration prediction from time series. <em>NCA</em>, <em>34</em>(16),
13305–13318. (<a
href="https://doi.org/10.1007/s00521-022-06949-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we want to discuss the use of deep learning model to predict potential vibrations of high-speed trains. In our research, we have tested and developed deep learning model to predict potential vibrations from time series of recorded vibrations during travel. We have tested various training models, different time steps and potential error margins to examine how well we are able to predict situation on the track. Summarizing, in our article we have used the RNN-LSTM neural network model with hyperbolic tangent in hidden layers and rectified linear unit gate at the final layer in order to predict future values from the time series data. Results of our research show the our system is able to predict vibrations with Accuracy of above 99\% in series of values forward.},
  archive      = {J_NCA},
  author       = {Siłka, Jakub and Wieczorek, Michał and Woźniak, Marcin},
  doi          = {10.1007/s00521-022-06949-4},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13305-13318},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recurrent neural network model for high-speed train vibration prediction from time series},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Time series-dependent feature of EEG signals for improved
visually evoked emotion classification using EmotionCapsNet.
<em>NCA</em>, <em>34</em>(16), 13291–13303. (<a
href="https://doi.org/10.1007/s00521-022-06942-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent studies, machine learning and deep learning strategies have been explored in many EEG-based application for best performance. More specifically, convolutional neural networks (CNNs) have demonstrated incredible capacity in electroencephalograph (EEG)-evoked emotion classification tasks. In preexisting case, CNN-based emotion classification techniques using EEG signals mostly involve a moderately intricate phase of feature extrication before any network model implementation. The CNNs are not able to well describe the natural interrelation among the various EEG channels, which basically provides essential data for the classification of different emotion states. In this paper, an efficacious and advanced version of CNN called Emotion-based Capsule Network (EmotionCapsNet) for multi-channel EEG-based emotion classification to achieve better classification accuracy is presented. EmotionCapsNet has been applied to the raw EEG signals as well as 2D image representation generated from EEG signals which can extricate descriptive and complex features from the EEG signals and decide the different emotional states. The proposed system is then compared with the other conventional machine learning and deep learning-based CNN model. Our strategy accomplishes an average accuracy of 77.50\%, 78.44\% and 79.38\% for valence, arousal and dominance on the DEAP, 79.06\%, 78.90\% and 79.69\% on AMIGOS and attains an average accuracy of 80.34\%, 83.04\% and 82.50\% for valence, arousal and dominance on the DREAMER, respectively. These outcomes demonstrate that adapted strategy yields comparable precision on raw EEG signal and it also provides better classification results on spatiotemporal feature of EEG signal for emotion classification task.},
  archive      = {J_NCA},
  author       = {Kumari, Nandini and Anwar, Shamama and Bhattacharjee, Vandana},
  doi          = {10.1007/s00521-022-06942-x},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13291-13303},
  shortjournal = {Neural Comput. Appl.},
  title        = {Time series-dependent feature of EEG signals for improved visually evoked emotion classification using EmotionCapsNet},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-stream convolutional LSTM for precipitation nowcasting.
<em>NCA</em>, <em>34</em>(16), 13281–13290. (<a
href="https://doi.org/10.1007/s00521-021-06877-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable precipitation nowcasting is essential to many fields, which can guide people to reasonably carry out production activities and respond to rainstorm disasters. However, precipitation nowcasting is a very challenging task because of correlation and heterogeneity both in space and in time. Most previous studies have not adequately captured the long-term and long-range spatiotemporal dependencies in the data, leading to insufficient modeling and poor prediction performance. To make more accurate prediction, we propose a novel deep learning model for precipitation nowcasting, called two-stream convolutional LSTM which includes short-term sub-network and long-term sub-network. The two sub-networks, respectively, make predictions on inputs at different time intervals to capture the heterogeneity of rainfall data. On this basis, an innovative recombination module is proposed to fuse the outputs of two sub-networks. In addition, we embed the 3D convolutions and self-attention mechanism to construct a new memory cell, named 3D-SA-LSTM, to extract the spatiotemporal feature. Two-stream convolutional LSTM achieves the state-of-the-art prediction performance on a real-world large-scale dataset and is a more flexible framework that can be conveniently applied to other similarly time series prediction tasks: traffic forecasting and planning, financial analysis and management, actions recognition and prediction, etc.},
  archive      = {J_NCA},
  author       = {Chen, Suting and Xu, Xin and Zhang, Yanyan and Shao, Dongwei and Zhang, Song and Zeng, Mingjian},
  doi          = {10.1007/s00521-021-06877-9},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13281-13290},
  shortjournal = {Neural Comput. Appl.},
  title        = {Two-stream convolutional LSTM for precipitation nowcasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Applying attention-based BiLSTM and technical indicators in
the design and performance analysis of stock trading strategies.
<em>NCA</em>, <em>34</em>(16), 13267–13279. (<a
href="https://doi.org/10.1007/s00521-021-06828-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the Internet, information on the stock market has gradually become transparent, and stock information is easy to obtain. For investors, investment performance depends on the amount of capital and effective trading strategies. The analysis tool commonly used by investors and securities analysts is technical analysis (TA). Technical analysis is the study of past and current financial market information, and a large amount of statistical data is used to predict price trends and determine trading strategies. Technical indicators (TIs) are a type of technical analysis that summarizes possible future trends of stock prices based on historical statistical data to assist investors in making decisions. The stock price trend is a typical time series data with special characteristics such as trend, seasonality, and periodicity. In recent years, time series deep neural networks (DNNs) have demonstrated their powerful performance in machine translation, speech processing, and natural language processing fields. This research proposes the concept of attention-based BiLSTM (AttBiLSTM) applied to trading strategy design and verified the effectiveness of a variety of TIs, including stochastic oscillator, RSI, BIAS, W\%R, and MACD. This research also proposes two trading strategies that suitable for DNN, combining with TIs and verifying their effectiveness. The main contributions of this research are as follows: (1) As our best knowledge, this is the first research to propose the concept of applying TIs to the LSTM-attention time series model for stock price prediction. (2) This study introduces five well-known TIs, which reached a maximum of 68.83\% in the accuracy of stock trend prediction. (3) This research introduces the concept of exporting the probability of the deep model to the trading strategy. On the backtest of TPE0050, the experimental results reached the highest return on investment of 42.74\%. (4) This research concludes from an empirical point of view that technical analysis combined with time series deep neural network has significant effects in stock price prediction and return on investment.},
  archive      = {J_NCA},
  author       = {Lee, Ming-Che and Chang, Jia-Wei and Yeh, Sheng-Cheng and Chia, Tsorng-Lin and Liao, Jie-Shan and Chen, Xu-Ming},
  doi          = {10.1007/s00521-021-06828-4},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13267-13279},
  shortjournal = {Neural Comput. Appl.},
  title        = {Applying attention-based BiLSTM and technical indicators in the design and performance analysis of stock trading strategies},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hydropower production prediction using artificial neural
networks: An ecuadorian application case. <em>NCA</em>, <em>34</em>(16),
13253–13266. (<a
href="https://doi.org/10.1007/s00521-021-06746-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydropower is among the most efficient technologies to produce renewable electrical energy. Hydropower systems present multiple advantages since they provide sustainable and controllable energy. However, hydropower plants’ effectiveness is affected by multiple factors such as river/reservoir inflows, temperature, electricity price, among others. The mentioned factors make the prediction and recommendation of a station’s operational output a difficult challenge. Therefore, reliable and accurate energy production forecasts are vital and of great importance for capacity planning, scheduling, and power systems operation. This research aims to develop and apply artificial neural network (ANN) models to predict hydroelectric production in Ecuador’s short and medium term, considering historical data such as hydropower production and precipitations. For this purpose, two scenarios based on the prediction horizon have been considered, i.e., one-step and multi-step forecasted problems. Sixteen ANN structures based on multilayer perceptron (MLP), long short-term memory (LSTM), and sequence-to-sequence (seq2seq) LSTM were designed. More than 3000 models were configured, trained, and validated using a grid search algorithm based on hyperparameters. The results show that the MLP univariate and differentiated model of one-step scenario outperforms the other architectures analyzed in both scenarios. The obtained model can be an important tool for energy planning and decision-making for sustainable hydropower production.},
  archive      = {J_NCA},
  author       = {Barzola-Monteses, Julio and Gómez-Romero, Juan and Espinoza-Andaluz, Mayken and Fajardo, Waldo},
  doi          = {10.1007/s00521-021-06746-5},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13253-13266},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hydropower production prediction using artificial neural networks: An ecuadorian application case},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An active adaptation strategy for streaming time series
classification based on elastic similarity measures. <em>NCA</em>,
<em>34</em>(16), 13237–13252. (<a
href="https://doi.org/10.1007/s00521-022-07358-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In streaming time series classification problems, the goal is to predict the label associated to the most recently received observations over the stream according to a set of categorized reference patterns. In on-line scenarios, data arise from non-stationary processes, which results in a succession of different patterns or events. This work presents an active adaptation strategy that allows time series classifiers to accommodate to the dynamics of streamed time series data. Specifically, our approach consists of a classifier that detects changes between events over streaming time series. For this purpose, the classifier uses features of the dynamic time warping measure computed between the streamed data and a set of reference patterns. When classifying a streaming series, the proposed pattern end detector analyzes such features to predict changes and adapt off-line time series classifiers to newly arriving events. To evaluate the performance of the proposed scheme, we employ the pattern end detection model along with dynamic time warping-based nearest neighbor classifiers over a benchmark of ten time series classification problems. The obtained results present exciting insights into the detection accuracy and latency performance of the proposed strategy.},
  archive      = {J_NCA},
  author       = {Oregi, Izaskun and Pérez, Aritz and Del Ser, Javier and Lozano, Jose A.},
  doi          = {10.1007/s00521-022-07358-3},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13237-13252},
  shortjournal = {Neural Comput. Appl.},
  title        = {An active adaptation strategy for streaming time series classification based on elastic similarity measures},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FEBDNN: Fusion embedding-based deep neural network for user
retweeting behavior prediction on social networks. <em>NCA</em>,
<em>34</em>(16), 13219–13235. (<a
href="https://doi.org/10.1007/s00521-022-07174-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the fast growing amount of user generated content (UGC) on social networks, the prediction of retweeting behavior is attracting significant attention in recent years. However, the existing studies tend to ignore the influence of implicit social influence and group retweeting factor factors. Also, it is still challenging to consider all related factors into a unified framework. To solve the above disadvantages, we propose a novel deep neural network fusion embedding-based deep neural network (FEBDNN) through the perspective of user embedding and tweets embedding for the author and the user’s historical tweets. Firstly, we propose dual auto-encoder (DAE) network for user embedding by integrating user’s basic features, explicit and implicit social influence and group retweeting factor. Then, we utilize the attention-based F_BLSTM_CNN(A_F_BLSTM_CNN) model for historical tweets’ representative embedding based on the combination of convolutional neural network (CNN) and bidirectional long short-term memory (BLSTM). Finally, we concatenate these embedding features into a vector and design a hidden layer and a fully connected softmax layer to predict the retweeting label. The experimental results demonstrate that the FEBDNN model compares favorably performance against the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Wang, Lidong and Zhang, Yin and Yuan, Jie and Hu, Keyong and Cao, Shihua},
  doi          = {10.1007/s00521-022-07174-9},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13219-13235},
  shortjournal = {Neural Comput. Appl.},
  title        = {FEBDNN: Fusion embedding-based deep neural network for user retweeting behavior prediction on social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reservoir weights learning based on adaptive dynamic
programming and its application in time series classification.
<em>NCA</em>, <em>34</em>(16), 13201–13217. (<a
href="https://doi.org/10.1007/s00521-021-06827-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series classification (TSC) has been addressed and analysed through a wide spectrum of algorithms. Nevertheless, few have considered the notion of spiking or non-spiking neural networks (NNs) and their performance in TSC tasks. Seminal Reservoir Computing (s-RC) with random connected recurrent neural networks is categorized among the fastest and most efficient end-to-end NNs that have been applied to TSC problems. Although the s-RC architecture is absolutely suited for dynamic (temporal) data processing, it fails to achieve significant improvement compared to state-of-the-art fully trainable NNs. Along this thread, the present study proposes a novel algorithm for training the reservoir by fusing nonlinear optimal control theory with reservoir computing (RC) theory, which opens a new approach to optimizing RC predicted values (estimated class) in a specific timestamp along the desired trajectory (true class). For this purpose, TSC tasks were reformulated as a nonlinear optimal control problem, conducive to an approximate solution to a learning rule for the reservoir of spiking or non-spiking neurons, using the adaptive/approximate dynamic programming (ADP) method. The proposed framework that known as Trainable Reservoir Computing (t-RC) involves an online actor–critic method which is used to project the effect of the output error into the reservoir’s parameters adjusting rule so as to ensure the classification error is minimized. To evaluate the TSC adaptability of the newly proposed RC framework and state-of-the-art NN-based methods, varying experiments on 22 univariate and multivariate time series datasets (UCR and UEA datasets) were performed. The findings divulge that the proposed framework outperforms other RC methods in learning capacity and accuracy and attains classification accuracy comparable with the best fully trainable deep neural networks.},
  archive      = {J_NCA},
  author       = {Modiri, Mohammad and Homayounpour, Mohammad Mehdi and Ebadzadeh, Mohammad Mehdi},
  doi          = {10.1007/s00521-021-06827-5},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13201-13217},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reservoir weights learning based on adaptive dynamic programming and its application in time series classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A heuristic approach to the hyperparameters in training
spiking neural networks using spike-timing-dependent plasticity.
<em>NCA</em>, <em>34</em>(16), 13187–13200. (<a
href="https://doi.org/10.1007/s00521-021-06824-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The third type of neural network called spiking is developed due to a more accurate representation of neuronal activity in living organisms. Spiking neural networks have many different parameters that can be difficult to adjust manually to the current classification problem. The analysis and selection of coefficients’ values in the network can be analyzed as an optimization problem. A practical method for automatic selection of them can decrease the time needed to develop such a model. In this paper, we propose the use of a heuristic approach to analyze and select coefficients with the idea of collaborative working. The proposed idea is based on parallel analyzing of different coefficients and choosing the best of them or average ones. This type of optimization problem allows the selection of all variables, which can significantly affect the convergence of the accuracy. Our proposal was tested using network simulators and popular databases to indicate the possibilities of the described approach. Five different heuristic algorithms were tested and the best results were reached by Cuckoo Search Algorithm, Grasshopper Optimization Algorithm, and Polar Bears Algorithm.},
  archive      = {J_NCA},
  author       = {Połap, Dawid and Woźniak, Marcin and Hołubowski, Waldemar and Damaševičius, Robertas},
  doi          = {10.1007/s00521-021-06824-8},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13187-13200},
  shortjournal = {Neural Comput. Appl.},
  title        = {A heuristic approach to the hyperparameters in training spiking neural networks using spike-timing-dependent plasticity},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving temporal predictions through time-series labeling
using matrix profile and motifs. <em>NCA</em>, <em>34</em>(16),
13169–13185. (<a
href="https://doi.org/10.1007/s00521-021-06744-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most challenging tasks in time-series prediction is a model’s capability to accurately learn the repeating granular trends in the data’s structure to generate effective predictions. Traditionally specially tuned statistical models and deep learning models like recurrent neural networks and long short-term memory networks are used to tackle such problem of sequence modeling. However in practice, factors like inadequate parameters in case of statistical models, random weight initializations, and data inadequacy in case of deep learning models affect the resulting final predictions. As a possible solution to these known problems, this paper introduces a novel method of time-series labeling (TSL) comprising a combination of encoding and decoding methodologies that not only takes into account the granular structure of a time-series data but also its underlying meta-learners for better predictive accuracy. To demonstrate the approach’s effectiveness and capability of handling wide range of scenarios, comparisons are drawn first over different widely used statistical and deep learning models and then applying TSL to each of them in order to showcase the resulting performance improvement when implemented over a wide variety of real-world datasets. The experimental findings reflect an average of 25\% increase in overall performance when using TSL along with mostly similar performance of different combinations regardless of model complexity thereby proving its efficacy in predicting periodic data.},
  archive      = {J_NCA},
  author       = {Saha, Pratik and Nath, Pritthijit and Middya, Asif Iqbal and Roy, Sarbani},
  doi          = {10.1007/s00521-021-06744-7},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13169-13185},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving temporal predictions through time-series labeling using matrix profile and motifs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Observation error covariance specification in dynamical
systems for data assimilation using recurrent neural networks.
<em>NCA</em>, <em>34</em>(16), 13149–13167. (<a
href="https://doi.org/10.1007/s00521-021-06739-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data assimilation techniques are widely used to predict complex dynamical systems with uncertainties, based on time-series observation data. Error covariance matrices modeling is an important element in data assimilation algorithms which can considerably impact the forecasting accuracy. The estimation of these covariances, which usually relies on empirical assumptions and physical constraints, is often imprecise and computationally expensive, especially for systems of large dimensions. In this work, we propose a data-driven approach based on long short term memory (LSTM) recurrent neural networks (RNN) to improve both the accuracy and the efficiency of observation covariance specification in data assimilation for dynamical systems. Learning the covariance matrix from observed/simulated time-series data, the proposed approach does not require any knowledge or assumption about prior error distribution, unlike classical posterior tuning methods. We have compared the novel approach with two state-of-the-art covariance tuning algorithms, namely DI01 and D05, first in a Lorenz dynamical system and then in a 2D shallow water twin experiments framework with different covariance parameterization using ensemble assimilation. This novel method shows significant advantages in observation covariance specification, assimilation accuracy, and computational efficiency.},
  archive      = {J_NCA},
  author       = {Cheng, Sibo and Qiu, Mingming},
  doi          = {10.1007/s00521-021-06739-4},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13149-13167},
  shortjournal = {Neural Comput. Appl.},
  title        = {Observation error covariance specification in dynamical systems for data assimilation using recurrent neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on deep learning for time series data.
<em>NCA</em>, <em>34</em>(16), 13147–13148. (<a
href="https://doi.org/10.1007/s00521-022-07536-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ma, Ruizhe and Angryk, Rafal and Scherer, Rafal},
  doi          = {10.1007/s00521-022-07536-3},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {13147-13148},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on deep learning for time series data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised anomaly detection for network traffic using
artificial immune network. <em>NCA</em>, <em>34</em>(15), 13007–13027.
(<a href="https://doi.org/10.1007/s00521-022-07156-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the existing approaches of multifarious knowledge based anomaly detection for network traffic, the priori knowledge labelled by human experts has to be consecutively updated for identification of new anomalies. Because anomalies usually show different patterns from the majority of network activities, it is hard to detect them based on the priori knowledge. Unsupervised anomaly detection using autonomous techniques without any priori knowledge is an effective strategy to overcome this drawback. In this paper, we propose a novel model of Unsupervised Anomaly Detection approach based on Artificial Immune Network (UADAIN) that consists of unsupervised clustering, cluster partition and anomaly detection. Our model uses the aiNet based unsupervised clustering approach to generate cluster centroids from network traffic, and the Cluster Centroids based Partition algorithm (CCP) then coarsely partition cluster centroids in the training phase as the self set (normal rules) and antibody set (anomalous rules). In test phase, to keep consecutive evolution of selves and antibodies, we introduce the Immune Network based Anomaly Detection model (INAD) to automatically learn and evolve the self set and antibody set. To evaluate the effectiveness of UADAIN, we conduct simulation experiments on ISCX 2012 IDS dataset and NSL-KDD dataset. In comparison with two popular anomaly detection approaches based on K-means clustering and aiNet-HC clustering, respectively, the experiment results demonstrate that UADAIN achieves better detection performance in detecting anomalies of network traffic.},
  archive      = {J_NCA},
  author       = {Shi, Yuanquan and Shen, Hong},
  doi          = {10.1007/s00521-022-07156-x},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {13007-13027},
  shortjournal = {Neural Comput. Appl.},
  title        = {Unsupervised anomaly detection for network traffic using artificial immune network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dsa-PAML: A parallel automated machine learning system via
dual-stacked autoencoder. <em>NCA</em>, <em>34</em>(15), 12985–13006.
(<a href="https://doi.org/10.1007/s00521-022-07119-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding a high-performance machine learning pipeline (ML pipeline) for a supervised learning task takes much time. It requires many choices, including preprocessing datasets, selecting algorithms, tuning hyperparameters, and ensembling candidate models. With increasing pipelines arises a combination explosion problem. This work presents a new automated machine learning (AutoML) system called Dsa-PAML to address this challenge by recommending, training, and ensembling suitable models for supervised learning tasks. Dsa-PAML is a parallel automated system based on a dual-stacked autoencoder (Dsa). Firstly, meta-features of datasets and ML pipelines are used to alleviate cold-start recommendation problems. Secondly, a novel dual-stacked autoencoder is used to simultaneously learn the latent features of datasets and ML pipelines, efficiently learning collaborations of both datasets and ML pipelines and recommending suitable ML pipelines for a new dataset. Thirdly, Dsa-PAML can train the recommended ML pipelines on the new dataset in a parallel method, which substantially reduces the time complexity of the proposed method. Finally, a parallel selective ensemble system is embedded into Dsa-PAML. It selects base models from candidate ML pipelines according to their runtime, classification performance, and diversity on the validation set, enhancing Dsa-PAML’s stability for most datasets. Amounts of experiments on 30 UCI datasets show that our approach outperforms current state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Liu, Pengjie and Pan, Fucheng and Zhou, Xiaofeng and Li, Shuai and Zeng, Pengyu and Liu, Shurui and Jin, Liang},
  doi          = {10.1007/s00521-022-07119-2},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12985-13006},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dsa-PAML: A parallel automated machine learning system via dual-stacked autoencoder},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning analysis for the effect of individual player
performances on match results. <em>NCA</em>, <em>34</em>(15),
12967–12984. (<a
href="https://doi.org/10.1007/s00521-022-07178-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Player performance is the most important factor that affects match scores. Factors affecting player performance are not the same for all players, and vary according to pitch positions. Analyzing these performance factors in relation to pitch positions can help understand which characteristics of players need to be developed in order to win. Player training can be arranged accordingly, and team tactics can be changed or improved. Although the importance of analyzing the individual performances of players according to pitch positions has been emphasized in various studies, a large amount of data available has made this analysis difficult. Machine learning can be used to overcome this difficulty. However, machine learning studies in sports mostly focus on score prediction. There is a lack of traditional and machine learning studies that examine the effect of individual player performances on game results. In this context, the datasets of the 2010 and 2014 FIFA World Cups were analyzed through multi-layer artificial neural networks. A specific model was established for each dataset by organizing relevant datasets according to year, player positions, and match levels (group–final). Rectifier Linear Unit was selected as the activation function for each model. Architecture and hyper-parameters for each model were determined through grid optimization. The factors affecting player performances were ranked by the Gedeon’s relative importance calculation. The average performance indicators for the group matches are 81.34\% precision, 87\% recall, and 0.84 F1 score. The area under curve for the final series is 0.798.},
  archive      = {J_NCA},
  author       = {Yücebaş, Sait Can},
  doi          = {10.1007/s00521-022-07178-5},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12967-12984},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning analysis for the effect of individual player performances on match results},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward multi-category garments virtual try-on method by
coarse to fine TPS deformation. <em>NCA</em>, <em>34</em>(15),
12947–12965. (<a
href="https://doi.org/10.1007/s00521-022-07173-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual try-on facilitates users to evaluate the wearing effect of garments on their bodies. As online clothing shopping develops, the category and style of garments constantly enrich. It is an issue to warp multi-category garments as the user shape without three-dimensional (3d) garment models. To tackle this issue, we propose a novel virtual try-on method toward multi-category garments by coarse to fine thin plate spline (TPS) deformation. To embody the user shape, 3d human body model is reconstructed with the garment pose. With the orientation and width classification criteria, the human body part mask is projected from 3d human body model, then it is adapted to the category and feature of garments. The spatial gradients with various scales are generated by comparing the shape difference between the garment mask and the human body part mask. To eliminate this shape difference, the coarse to fine TPS deformation is utilized to warp garment images from global to local. Ultimately, the warped garment images are worn on the virtual human body to preview the try-on effect. Experiments demonstrated that our method is robust to different human body shapes with different garments. Compared with state-of-the-art VITON methods, our method is superior in preserving the texture details and overall style in the virtual try-on for multi-category garments. The code is available at https://github.com/NerdFNY/MCG-VITON .},
  archive      = {J_NCA},
  author       = {Fang, Naiyu and Qiu, Lemiao and Zhang, Shuyou and Wang, Zili and Hu, Kerui and Li, Heng},
  doi          = {10.1007/s00521-022-07173-w},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12947-12965},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward multi-category garments virtual try-on method by coarse to fine TPS deformation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Control of adaptive running platform based on machine vision
technologies and neural networks. <em>NCA</em>, <em>34</em>(15),
12919–12946. (<a
href="https://doi.org/10.1007/s00521-022-07166-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper considers the problem of selection of the optimal method for controlling an adaptive running platform for movement organization in virtual reality. The analysis of existing approaches for the control of such systems is carried out, a list of existing methods is formed, and new functions are developed. In order to solve the problem of user positioning within the framework of an adaptive running platform, two approaches, based on virtual reality trackers and using a machine vision, are considered and implemented. The problem of the study includes the choice of the optimal method of controlling an adaptive running platform to ensure maximum user comfort when walking on it. The study methodology includes the creation of a simplified model of human interaction with a running platform, the formalization of the assessment of the quality of movement, various methods of human positioning and platform control functions, followed by an experimental part on their comparison and the search for an optimal approach to running platform control. It was proved that machine vision technologies and neural networks allow positioning a person with sufficient accuracy, and they are deprived of the disadvantages of trackers. Moreover, comparative studies of six different control functions were carried out with the tracker-based positioning method and with the use of machine vision technologies. The most universal is the nonlinear one, a detailed zonal and proportional–differential functions are recommended for the tracker-based positioning method, linear and proportional–differential functions are recommended for positioning based on machine vision. The scientific novelty of the study consists in the formalization and comparison of various control methods of adaptive running platforms (based on linear and nonlinear functions, proportional differential law and neural networks), methods of positioning a person on them (using cameras and trackers), which will expand the area of knowledge about the optimal control functions of this class of devices. The practical significance of the research lies in a comprehensive description of the solution of the problems of organizing the control of adaptive running platforms and positioning a person by various methods.},
  archive      = {J_NCA},
  author       = {Obukhov, Artem D. and Krasnyanskiy, Mikhail N. and Dedov, Denis L. and Vostrikova, Victoria V. and Teselkin, Daniil V. and Surkova, Ekaterina O.},
  doi          = {10.1007/s00521-022-07166-9},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12919-12946},
  shortjournal = {Neural Comput. Appl.},
  title        = {Control of adaptive running platform based on machine vision technologies and neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid sigma-pi neural network for combined intuitionistic
fuzzy time series prediction model. <em>NCA</em>, <em>34</em>(15),
12895–12917. (<a
href="https://doi.org/10.1007/s00521-022-07138-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy time series models consider observations hesitation degree but they use memberships and non-membership values together as inputs in the prediction system. The usage of membership and non-membership values as inputs in separate prediction models and combining the outputs of these separate models will provide a more flexible computational approach. Thus, different effects of membership and non-membership degrees on the predictions can be revealed. In this paper, an intuitionistic fuzzy time series prediction model (IFTS-PM) has been proposed. The proposed IFTS-PM uses a new hybrid sigma-pi neural network (HSP-NN), introduced for the first time in the literature, to determine nonlinear relationships between inputs and outputs. In addition, this newly proposed HSP-NN has the ability to multiply linear functions of inputs by unequal weights and convert them to nonlinear relationships. The structure of the proposed IFTS-PM consists of three parts. Two different HSP-NNs generate predictions by taking into account the different contribution levels of memberships and non-memberships. The last part is the part where these predictions are combined. Modified particle swarm optimization is performed to obtain optimal weights of HSP-NNs as well as the combination weights. And by taking the advantage of intuitionistic fuzzy C-means, fuzzy clusters, membership and non-membership values of observations are obtained. Performance of the proposed model is verified by applying it on 48 time series data sets. With all used indications, it has been clearly observed that proposed model has produced outstanding predictions compared to some other state-of-the-art prediction tools.},
  archive      = {J_NCA},
  author       = {Arslan, Sule Nazlı and Cagcag Yolcu, Ozge},
  doi          = {10.1007/s00521-022-07138-z},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12895-12917},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid sigma-pi neural network for combined intuitionistic fuzzy time series prediction model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Image fairness in deep learning: Problems, models, and
challenges. <em>NCA</em>, <em>34</em>(15), 12875–12893. (<a
href="https://doi.org/10.1007/s00521-022-07136-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, it has been revealed that machine learning models can produce discriminatory predictions. Hence, fairness protection has come to play a pivotal role in machine learning. In the past, most studies on fairness protection have used traditional machine learning methods to enforce fairness. However, these studies focus on low dimensional inputs, such as numerical inputs, whereas more recent deep learning technologies have encouraged fairness protection with image inputs through deep model methods. These approaches involve various object functions and structural designs that break the spurious correlations between targets and sensitive features. With these connections broken, we are left with fairer predictions. To better understand the proposed methods and encourage further development in the field, this paper summarizes fairness protection methods in terms of three aspects: the problem settings, the models, and the challenges. Through this survey, we hope to reveal research trends in the field, discover the fundamentals of enforcing fairness, and summarize the main challenges to producing fairer models.},
  archive      = {J_NCA},
  author       = {Tian, Huan and Zhu, Tianqing and Liu, Wei and Zhou, Wanlei},
  doi          = {10.1007/s00521-022-07136-1},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12875-12893},
  shortjournal = {Neural Comput. Appl.},
  title        = {Image fairness in deep learning: Problems, models, and challenges},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). VDNet: Video deinterlacing network based on coarse adaptive
module and deformable recurrent residual network. <em>NCA</em>,
<em>34</em>(15), 12861–12874. (<a
href="https://doi.org/10.1007/s00521-022-07116-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interlacing is the technique that overlaps odd lines from an odd frame and even lines from an even frame to increase the perceived frame rate in TV displays without increasing bandwidth. On the other hand, since original frames are not stored, deinterlacing is the technique introduced for reversing this process and restore the original or progressive video. Existing deinterlacing approaches focus on restoring a single interlaced frame without optimally leveraging the temporal information available. In this paper, we propose VDNet, which to the best of our knowledge, is the first deep learning-based deinterlacing framework that considers inter-frame correlation. Our proposed method addresses deinterlacing by splitting the frames and regenerating the missing lines using a simple coarse method (base image sequence) before combining them with the residual image sequence for refinement. For the deinterlaced base image sequence, our data module uses spatial and temporal information to fill in the missing areas and leverages our coarse adaptive module to interpolate them. The residual module then leverages our proposed Deformable Recurrent Residual Network to optimally enhance and aggregate the features extracted from the interlaced video. Our method then refines the base image sequence using the residual image sequence generated from the residual module. After reconstructing the progressive frames, our proposed Spatial-Temporal Correlation Loss uses the information provided by the existing interlaced video to further smooth and boost the deinterlaced output. We perform extensive experiments to demonstrate our proposed VDNet’s incredible quantitative performance. Moreover, we design our model to be lightweight and efficient.},
  archive      = {J_NCA},
  author       = {Yeh, Yin-Chen and Dy, Jilyan and Huang, Tai-Ming and Chen, Yung-Yao and Hua, Kai-Lung},
  doi          = {10.1007/s00521-022-07116-5},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12861-12874},
  shortjournal = {Neural Comput. Appl.},
  title        = {VDNet: Video deinterlacing network based on coarse adaptive module and deformable recurrent residual network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A utilization of the inverse response surface method for the
reliability-based design of structures. <em>NCA</em>, <em>34</em>(15),
12845–12859. (<a
href="https://doi.org/10.1007/s00521-022-07149-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the pitfalls of using response surface methods when solving inverse problems and presents an adaptive artificial neural network-based inverse response surface method. The procedure is based on a coupling of the adaptive response surface method and artificial neural network-based inverse reliability analysis. The validity and accuracy of the method are tested on several examples. The first is a problem with a theoretical explicit nonlinear limit state function and one design parameter. Here, the accuracy of surrogate models for design parameter identification was tested for cases with the target values of the identified parameter both inside and outside of the initial range of values. The absolute percentage errors were 11.79\% and 0.19\% after the first and the last iteration of the identification process, respectively. The other two examples represent practical applications of the reliability design of structures with multiple design parameters and multiple reliability constraints. In the former, the limit state functions are defined explicitly, while in the latter, they are defined implicitly in the form of a structural analysis using the nonlinear finite element method. When assessing the reliability index values, very low absolute percentage error values were obtained in both examples. For the explicit form of the limit state function, the values were up to 0.50\% in all iterations. In the case of the implicitly defined limit state function, the absolute percentage error was equal to 6.45\% after the fist iteration and 0.79\% after the second iteration.},
  archive      = {J_NCA},
  author       = {Lehký, David and Šomodíková, Martina and Lipowczan, Martin},
  doi          = {10.1007/s00521-022-07149-w},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12845-12859},
  shortjournal = {Neural Comput. Appl.},
  title        = {A utilization of the inverse response surface method for the reliability-based design of structures},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parameter estimation of photovoltaic cell and module models
relied on metaheuristic algorithms including artificial ecosystem
optimization. <em>NCA</em>, <em>34</em>(15), 12819–12844. (<a
href="https://doi.org/10.1007/s00521-022-07142-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the nonlinear characteristic of the power-voltage (P–V) and current–voltage (I–V) relationship of the photovoltaic systems, building accurate mathematical models of photovoltaic cell and module is essential for validation and optimization performance of photovoltaic systems. However, determination of the unknown parameters of photovoltaic cell and module models is a complex nonlinear optimization problem that requires effective solving methods. This paper proposes an approach of parameter estimation of photovoltaic cell and module models based on artificial ecosystem-based optimization (AEO). The AEO is a new developed metaheuristic algorithm taken idea of the mechanisms of ecosystem consisting of production, consumption and decomposition. The advanced feature of AEO is the diversity of exploration and exploitation mechanisms without special control parameters. The performance of AEO is discussed in two photovoltaic cell models and two photovoltaic module models. Its performances compared to five algorithms consisting of backtracking search algorithm (BSA), cuckoo search algorithm (CSA), equilibrium optimizer (EO), genetic algorithm (GA) and particle swarm optimization (PSO) as well as the previous methods. The numerical results show that AEO has given the better performance than BSA, CSA, EO, GA and PSO for the problem of parameter estimation of photovoltaic models in terms of aspects such as reaching the lower error between the experimental and estimated values and having the better statistical results in several runs than the above methods. Thus, AEO can be an effective method for estimating the unknown parameters of photovoltaic cell and module models.},
  archive      = {J_NCA},
  author       = {Nguyen, Thuan Thanh and Nguyen, Thang Trung and Tran, Thanh Ngoc},
  doi          = {10.1007/s00521-022-07142-3},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12819-12844},
  shortjournal = {Neural Comput. Appl.},
  title        = {Parameter estimation of photovoltaic cell and module models relied on metaheuristic algorithms including artificial ecosystem optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Filter pruning via expectation-maximization. <em>NCA</em>,
<em>34</em>(15), 12807–12818. (<a
href="https://doi.org/10.1007/s00521-022-07127-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The redundancy in convolutional neural networks (CNNs) causes a significant number of extra parameters resulting in increased computation and less diverse filters. In this paper, we introduce filter pruning via expectation-maximization (FPEM) to trim redundant structures and improve the diversity of remaining structures. Our method is designed based on the discovery that the filter diversity of pruned networks is positively correlated with its performance. The expectation step divides filters into groups by maximum likelihood layer-wisely, and averages the output feature maps for each cluster. The maximization step calculates the likelihood estimation of clusters and formulates a loss function to make the distributions in the same cluster consistent. After training, the intra-cluster redundant filters can be trimmed and only intra-cluster diverse filters are retained. Experiments conducted on CIFAR-10 have outperformed the corresponding full models. On ImageNet ILSVRC12, FPEM reduces $$46.5\%$$ FLOPs on ResNet-50 with only $$0.36\%$$ Top-1 accuracy decrease, which advances the state-of-arts. In particular, the FPEM offers strong generalization performance on the object detection task.},
  archive      = {J_NCA},
  author       = {Xu, Sheng and Li, Yanjing and Yang, Linlin and Zhang, Baochang and Sun, Dianmin and Liu, Kexin},
  doi          = {10.1007/s00521-022-07127-2},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12807-12818},
  shortjournal = {Neural Comput. Appl.},
  title        = {Filter pruning via expectation-maximization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Observer-based adaptive finite-time prescribed performance
NN control for nonstrict-feedback nonlinear systems. <em>NCA</em>,
<em>34</em>(15), 12789–12805. (<a
href="https://doi.org/10.1007/s00521-022-07123-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on an adaptive neural network (NN) finite-time prescribed performance control problem for nonstrict-feedback nonlinear systems subject to full-state constraints. Specifically, a finite-time performance function is employed, which can guarantee that the tracking error converges to a prescribed region within a finite-time. Neural networks (NNs) are used to approximate the unknown nonlinear function. The unmeasurable states are estimated via constructing a state observer. By using the dynamic surface control (DSC) technique, the complexity problem has been avoided in traditional backstepping control. In order to satisfy the state constraint condition, the barrier Lyapunov function (BLF) is incorporated in the process of backstepping. The developed adaptive finite-time NN backstepping control strategy can make that the closed-loop system is semiglobally practical finite-time stability (SGPFS). Meanwhile, all states can be guaranteed to remain in the constrained space. Simulation results demonstrate the validity of the control method.},
  archive      = {J_NCA},
  author       = {Tong, Dongbing and Liu, Xiang and Chen, Qiaoyu and Zhou, Wuneng and Liao, Kaili},
  doi          = {10.1007/s00521-022-07123-6},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12789-12805},
  shortjournal = {Neural Comput. Appl.},
  title        = {Observer-based adaptive finite-time prescribed performance NN control for nonstrict-feedback nonlinear systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Damage detection at storey and element levels of high-rise
buildings: A hybrid method. <em>NCA</em>, <em>34</em>(15), 12765–12788.
(<a href="https://doi.org/10.1007/s00521-022-07111-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Storey-level detection of high-rise buildings has become a subject of focus but still inadequate, whereas element-level detection is by far not reached because of the complexity of tall buildings, especially in a three-dimensional (3D) problem. In this study, element-level detection of two 3D 30-storey 90-m-high RC buildings (symmetrical and asymmetrical) composed of 2880 degrees of freedom (DOFs) is aimed. Only one biaxial accelerometer per floor is required to measure lateral displacements, making the number of measured DOFs equal to about 2\% of the full system. To circumvent the complicated problem, a two-step procedure is proposed to detect damage at storey and then element levels. The backbone idea lies in the similarities in terms of bending behaviour at low modes between tall buildings and beam-like systems. Particularly, in Step 1, in each direction, a full 3D building is approximately simplified to a beam-like system using the Guyan static condensation procedure based on the measured DOFs. Thereafter, an eigenvalue problem-based inverse solution is implemented directly on the simplified system to detect damaged storeys using only the first two bending modes. In Step 2, an artificial neural network model is designed to indicate ruined shear walls and columns focusing only on the preliminarily identified storeys, effectively reducing the number of desired variables. Only modal data at the lowest three swaying modes are accounted for. As a result, storey- and element-level detection is accurately achieved as long as the identified modal data are noise-free or low-level noise polluted.},
  archive      = {J_NCA},
  author       = {Nguyen, Quy Thue and Livaoğlu, Ramazan},
  doi          = {10.1007/s00521-022-07111-w},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12765-12788},
  shortjournal = {Neural Comput. Appl.},
  title        = {Damage detection at storey and element levels of high-rise buildings: A hybrid method},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ApplianceNet: A neural network based framework to recognize
daily life activities and behavior in smart home using smart plugs.
<em>NCA</em>, <em>34</em>(15), 12749–12763. (<a
href="https://doi.org/10.1007/s00521-022-07144-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A smart plug can transform the typical electrical appliance into a smart multi-functional device, which can communicate over the Internet. It has the ability to report the energy consumption pattern of the attached appliance which offer the further analysis. Inside the home, smart plugs can be utilized to recognize daily life activities and behavior. These are the key elements to provide human-centered applications including healthcare services, power consumption footprints, and household appliance identification. In this research, we propose a novel framework ApplianceNet that is based on energy consumption patterns of home appliances attached to smart plugs. Our framework can process the collected univariate time-series data intelligently and classifies them using a multi-layer, feed-forward neural network. The performance of this approach is evaluated on publicly available real homes collected dataset. The experimental results have shown the ApplianceNet as an effective and practical solution for recognizing daily life activities and behavior. We measure the performance in terms of precision, recall, and F1-score, and the obtained score is 87\%, 88\%, 88\%, respectively, which is 11\% higher than the existing method in terms of F1-score. Furthermore, our scheme is simple and easy to adopt in the existing home infrastructure.},
  archive      = {J_NCA},
  author       = {Fahim, Muhammad and Kazmi, S. M. Ahsan and Khattak, Asad Masood},
  doi          = {10.1007/s00521-022-07144-1},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12749-12763},
  shortjournal = {Neural Comput. Appl.},
  title        = {ApplianceNet: A neural network based framework to recognize daily life activities and behavior in smart home using smart plugs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dual-stream encoder neural networks with spectral constraint
for clustering functional brain connectivity data. <em>NCA</em>,
<em>34</em>(15), 12737–12747. (<a
href="https://doi.org/10.1007/s00521-022-07122-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional brain connectivity data extracted from functional magnetic resonance imaging (fMRI), characterized by high dimensionality and nonlinear structure, has been widely used to mine the organizational structure for different brain diseases. It is difficult to achieve effective performance by directly using these data for unsupervised clustering analysis of brain diseases. To tackle this problem, in this paper, we propose a dual-stream encoder neural networks with spectral constraint framework for clustering the functional brain connectivity data. Specifically, we consider two different information while encoding the input data: (1) the information between the neighboring nodes, (2) the discriminative features, then design a spectral constraint module to guide the clustering of embedded nodes. The framework contains four modules, Graph Convolutional Encoder, Hard Assignment Optimization Network, Decoder module, and Spectral Constraint module. We train four modules jointly and implement a deep clustering network framework. We conducted experimental analysis on different public functional brain connectivity datasets for evaluating the proposed deep learning clustering model. Compared with the existing unsupervised clustering analysis methods for the brain connectivity data and related deep learning clustering methods, experiments on seven real brain connectivity datasets demonstrate the effectiveness and advantages of our proposed method. The source code is available at https://github.com/hulu88/DENs-SCC .},
  archive      = {J_NCA},
  author       = {Lu, Hu and Jin, Tingting},
  doi          = {10.1007/s00521-022-07122-7},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12737-12747},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dual-stream encoder neural networks with spectral constraint for clustering functional brain connectivity data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The impact assessments of the ACF shape on time series
forecasting by the ANFIS model. <em>NCA</em>, <em>34</em>(15),
12723–12736. (<a
href="https://doi.org/10.1007/s00521-022-07140-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series modelling and control of hydrological parameters are the most critical issues in water resources management. The subject matter of this study is finding the significant relationship between natural properties of time series like correlogram and selecting the best combination set of inputs for the fuzzy-neural adaptive network model. In this regard, two different types of the ACF, including sinusoidal and descending shapes, are considered in different climate. Selecting model inputs from the stability range of the ACF diagram for any shape types and model fine tuning lead to inferior results in testing stage. The best R-value of the original temperature and groundwater time series in stability range is 0.2 (|SI|= 1.23, RMSE = 11.91) and 0.2 (SI = 0.14, RMSE = 3.32), respectively. When they choose from the non-stationary range of the ACF, the powerful results for sinusoidal and descending ACF shapes would be achieved. In case, the R-value is more than 94\% (|SI|&lt; 0.57, 2.57 &lt; RMSE &lt; 5.5]) and 78\% (SI = 0.03 and RMSE = 0.71), respectively. Whether they are picked up from the absolute maximum of ρ value in the ACF diagram, the best model results would have appeared. By applying the inverse of standardization and reforming the shape of the descending ACF to sinusoidal form, R-value is upgraded about 18\%, from 78 to 96\% the case. Finally, using preprocessing, in particular, standardization on time series does not always lead to improve forecasting model accuracy, but it depends on the shape of the ACF diagram. If it has the sine periodic shape, applying this action leads to poor results. In opposite, by descending ACF shape, using the inverse of standardization can improve the model accuracy in case. Finally, choosing ANFIS model inputs using the ACF diagram and appropriate input sets are more effective than using the model tuning and different fuzzy generators.},
  archive      = {J_NCA},
  author       = {Fatemi, Seyed Ehsan and Parvini, Hosna},
  doi          = {10.1007/s00521-022-07140-5},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12723-12736},
  shortjournal = {Neural Comput. Appl.},
  title        = {The impact assessments of the ACF shape on time series forecasting by the ANFIS model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multitask transfer learning with kernel representation.
<em>NCA</em>, <em>34</em>(15), 12709–12721. (<a
href="https://doi.org/10.1007/s00521-022-07126-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world applications, collecting and labeling the data is expensive and time-consuming. Thus, there is a need to obtain a high-performance learner by leveraging the data or knowledge from other domains. Transfer learning is a promising method to solve the above problems. In this paper, we propose a multitask transfer learning method, which aims to improve the performance of the target learner by transferring knowledge from the related source tasks. First, we formulate the target learner as a nonlinear function, which is approximated by the linear combination of the eigenfunctions. Further, to transfer knowledge from the source tasks, we constrain the target model to be the linear combination of the source models according to the previous work. However, knowledge from some source tasks may not be useful for adaptation, so we add a sparse constraint to the objective function to select the related source tasks. Different from previous transfer learning methods, our method transfers knowledge by jointly learning the source tasks and the target task. Besides, it can select the source tasks associated with the target task by the sparse constraint. Empirically, the method exhibits protection against negative transfer. Finally, we compare our proposed method with three single-task learning methods and six state-of-the-art multitask learning methods on two data sets. When compared with the second best results, the nMSE of our method achieves a relative improvement of $$10.85\%$$ with a training size of 100 on the SARCOS data set and a relative improvement of $$4.26\%$$ with a training ratio of $$20\%$$ on the Isolet data set. Experimental results show that our proposed method can effectively improve the performance of the target task by transferring knowledge from the related source tasks.},
  archive      = {J_NCA},
  author       = {Zhang, Yulu and Ying, Shihui and Wen, Zhijie},
  doi          = {10.1007/s00521-022-07126-3},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12709-12721},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multitask transfer learning with kernel representation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A decision support model based on q-rung orthopair fuzzy
number for glove design application. <em>NCA</em>, <em>34</em>(15),
12695–12708. (<a
href="https://doi.org/10.1007/s00521-022-07118-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality function deployment (QFD) method allows reviewing of customer requirements (CRs) and design requirements (DRs) simultaneously in order to handle the correlations and relationships of CRs and DRs in calculations. It has been often combined with fuzzy numbers because it provides to gather the judgments of experts in vagueness environment more correctly and easily. This paper suggests employing q-rung orthopair fuzzy number (q-ROFN) for improving the fuzzy QFD approach. The proposed q-ROFN based QFD method uses q-ROFN to adjust the weights of CRs based the relationships between CRs and DRs with the help of the correlations and relationships of CRs and DRs. q-ROFN presents more information than numbers such as intuitionistic fuzzy number and Pythagorean fuzzy number about the correlations and relationships of CRs and DRs. VIKOR (VIsekriterijumska optimizacija i KOm-promisno Resenje) approach based on q-ROFN is also used to rank DRs. The new proposed integrated method has been applied for evaluating the anthropometry based glove design. The results show that the most important DR for anthropometry based glove design is ease of hand motion perception.},
  archive      = {J_NCA},
  author       = {Efe, Ömer Faruk and Efe, Burak},
  doi          = {10.1007/s00521-022-07118-3},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12695-12708},
  shortjournal = {Neural Comput. Appl.},
  title        = {A decision support model based on q-rung orthopair fuzzy number for glove design application},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A meta learning approach for open information extraction.
<em>NCA</em>, <em>34</em>(15), 12681–12694. (<a
href="https://doi.org/10.1007/s00521-022-07114-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most important research topics in the field of natural language processing, open information extraction has achieved gratifying research findings in recent years. Even if so much effort is put into the work of open information extraction, there are still many shortcomings and great room for improvement in the existing system. The traditional open information extraction task relies heavily on the artificially defined extraction paradigm, and it will produce error accumulation and propagation. The end-to-end model relies on a large number of training data, and it is hard to re-train with the increase of the model. To cope with the difficulty of updating parameters of large neural network models, in this paper, we propose a solution based on the meta-learning framework, we design a neural network-based converter module, which effectively combines the learned model parameters with the new model parameters. Then update the parameters of the original open information extraction model using the parameters calculated by the converter. This can not only avoid the problem of error propagation of traditional models but also effectively deal with the iterative updating of open information extraction models. We employ a large and public Open IE benchmark to demonstrate the performance of our approach. The experimental results show that our model can achieve better performance than existing baselines, and compared with the re-training model, our strategy can not only greatly shorten the update time of the model, but also not lose the performance of the model completely re-trained with all the training data.},
  archive      = {J_NCA},
  author       = {Han, Jiabao and Wang, Hongzhi},
  doi          = {10.1007/s00521-022-07114-7},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12681-12694},
  shortjournal = {Neural Comput. Appl.},
  title        = {A meta learning approach for open information extraction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GPLFR—global perspective and local flow registration-for
forward-looking sonar images. <em>NCA</em>, <em>34</em>(15),
12663–12679. (<a
href="https://doi.org/10.1007/s00521-022-07113-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forward-looking sonar (FLS) image registration is a key step in many underwater applications such as underwater target detection, ocean observation, and mapping. However, low resolution, low signal-to-noise ratio, and the complex nonlinear transformation relationship between FLS images from two different viewpoints have brought great challenges to register them. In order to better cope with this challenge, we propose a global perspective and local flow registration (GPLFR) method for FLS images. GPLFR consists of two networks, i.e., a regression correction network (RCNet) and a deformable network (IRRDNet) with the iterative refinement of the residual. For a given pair of FLS images, RCNet is used to estimate the global transformation parameters to achieve global registration, and then, IRRDNet is used to estimate the deformation field or flow field to realize local alignment. The experimental results on real FLS image and 2D face expression image registration tasks demonstrate the effectiveness and robustness of the proposed method.},
  archive      = {J_NCA},
  author       = {Huang, Peng and Guo, Chunsheng and Fu, Xingbing and Xu, Lingyun and Zhou, Di},
  doi          = {10.1007/s00521-022-07113-8},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12663-12679},
  shortjournal = {Neural Comput. Appl.},
  title        = {GPLFR—Global perspective and local flow registration-for forward-looking sonar images},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid convolutional bi-LSTM autoencoder framework for
short-term wind speed prediction. <em>NCA</em>, <em>34</em>(15),
12653–12662. (<a
href="https://doi.org/10.1007/s00521-022-07125-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wind speed prediction is essential for optimal operation and planning. The unstable and stochastic nature of the wind makes the task complicated and challenging. As a result, a hybrid approach is implemented to enhance prediction accuracy and to overcome the difficulties and challenges in uncertainty modelling. Encoder and decoder are the two parts of the proposed hybrid model. In this study, a one-dimensional convolutional neural network (1D-CNN) is used as the encoder, and a bidirectional long short term memory network (Bi-LSTM) is used as the decoder. Encoder extracts the important characteristics and forms a latent representation. Then, wind speed is predicted by the decoder network by interpreting the characteristics of the encoded representation. The hybrid approach is validated using several regular and widely used benchmark forecasting models to assess and examine its prediction performance. The prediction results using the real-time dataset obtained from a wind measuring station in Idalia, Colorado are used for performance evaluation. The performance validation analysis showed that the proposed hybrid approach has an improvement of 42\% over the reference approaches.},
  archive      = {J_NCA},
  author       = {Kosana, Vishalteja and Teeparthi, Kiran and Madasthu, Santhosh},
  doi          = {10.1007/s00521-022-07125-4},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12653-12662},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid convolutional bi-LSTM autoencoder framework for short-term wind speed prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An effective integrated genetic programming and neural
network model for electronic nose calibration of air pollution
monitoring application. <em>NCA</em>, <em>34</em>(15), 12633–12652. (<a
href="https://doi.org/10.1007/s00521-022-07129-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air quality control requires real-time monitoring of pollutant concentration distributions in large urban areas. Estimation models are used for the soft-calibration of low-cost multisensor data to improve precision of pollutant concentration measurements. This study introduces an integrated genetic programming dynamic neural network model for more accurate estimation of carbon monoxide and nitrogen dioxide pollutant concentrations from the multisensor measurement data. This model combines a genetic programming-based estimation model with a neural estimator model and improves estimation performances. In this structure, a genetic programming-based polynomial model works as a former estimator and it feeds the neural estimator model via a short-term former estimation memory. Then, the neural model utilizes this former estimation memory in order to enhance pollutant concentration estimations. This integration approach benefits from the correlation enrichment strategy that is performed by the former model. The proposed two-stage training procedure facilitates the training of the integrated models. In experimental study, the standalone genetic programming model, artificial neural network model, and the proposed integrated model are implemented to estimate carbon monoxide and nitrogen dioxide pollutant concentrations from the experimental multisensor air quality data. Results demonstrate that the proposed integrated model can decrease mean relative error about 10\% compared to the standalone artificial neural network and about 28\% compared to the standalone genetic programming estimation models. Authors suggested that the integrated estimation model can be used for more accurate soft-calibration of multisensor electronic noses in a wide-area air-quality monitoring application.},
  archive      = {J_NCA},
  author       = {Ari, Davut and Alagoz, Baris Baykant},
  doi          = {10.1007/s00521-022-07129-0},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12633-12652},
  shortjournal = {Neural Comput. Appl.},
  title        = {An effective integrated genetic programming and neural network model for electronic nose calibration of air pollution monitoring application},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anomaly detection based on superpixels in videos.
<em>NCA</em>, <em>34</em>(15), 12617–12631. (<a
href="https://doi.org/10.1007/s00521-022-07120-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on superpixels, we propose a novel method for detecting abnormal events in videos. The conventional methods divide the frames into regular grids and consider the grids with low probability as abnormal events. By contrast with traditional approaches, we divide frames into superpixels according to their similarity and compactness, and the superpixels under the scene model mask are used as the anomaly candidates. The anomaly detection is carried out at two scales: the basic grids covered by the superpixel candidates and the actual superpixel itself. Anomaly scores are calculated by comparing the test samples with corresponding templates. Experiments on the public databases show that our method can effectively detect abnormal events in complex scenes.},
  archive      = {J_NCA},
  author       = {Li, Shifeng and Cheng, Yan and Tian, Ye and Liu, Yunfeng},
  doi          = {10.1007/s00521-022-07120-9},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12617-12631},
  shortjournal = {Neural Comput. Appl.},
  title        = {Anomaly detection based on superpixels in videos},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent flow discharge computation in a rectangular
channel with free overfall condition. <em>NCA</em>, <em>34</em>(15),
12601–12616. (<a
href="https://doi.org/10.1007/s00521-022-07112-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The free overfall is a simple and widely used device for measuring discharge in open irrigation channels and agricultural research projects. However, the direct measurement of discharge can be difficult and time-consuming with care needed to minimize potential inaccuracies of empirical equations applied to site-specific conditions. Thus, in the present study four standalone algorithms of Isotonic Regression (ISO), Least Median of Square Regression (LMS), M5Prime (M5P) and REPT and four novel hybrid algorithms of rotation forest (ROF) combined with those four standalone models (i.e., ROF-ISO, ROF-LMS, ROF-M5P and ROF-REPT) were applied for the intelligent prediction of discharge per unit width for the free overfall condition in rectangular channels. This was accomplished via six data sets (355 data) collected from the published literature including end depth, Manning&#39;s roughness coefficient, channel width, bed slope and unit discharge. The dataset was partitioned in a 70:30 ratio randomly, 70\% (248 data) of data used for model development while 30\% (107 data) applied for model validation. Also, four different input combinations were constructed to identify the most effective prediction method. Furthermore, results were validated using several visually based (line graph, scatter plot, violin plot and Taylor diagram) and quantitative-based [root mean square error (RMSE), Nash–Sutcliffe efficiency (NSE), Willmott’s index of agreement, Legates and McCabe coefficient of efficiency (LM)] approaches. Results of the sensitivity analysis revealed that end depth had the highest effect on the results, while channel width was least influential. Results also showed that the best input combination incorporated all four input parameters. According to the results, ROF-REPT had the best performance with RMSE of 0.0035 (m3/s/m), NSE of 0.990, WI of 0.997\% and LM of 0.905\% followed by ROF-M5P REPT, M5P, ROF-LMS, ISO and LMS.},
  archive      = {J_NCA},
  author       = {Khosravi, Khabat and Khozani, Zohreh Sheikh and M.Melesse, Assefa and Crookston, Brian Mark},
  doi          = {10.1007/s00521-022-07112-9},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12601-12616},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intelligent flow discharge computation in a rectangular channel with free overfall condition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning model for identification of diabetes type 2
based on nucleotide signals. <em>NCA</em>, <em>34</em>(15), 12587–12599.
(<a href="https://doi.org/10.1007/s00521-022-07121-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Genome-Wide Association Studies (GWAS), detection of T2D-related variants in genome sequences and accurate modeling of the complex structure of the relevant gene are of great importance for the diagnosis of diabetes. For this purpose, this paper presents a novel strong algorithm to accurately and effectively identify Type 2 Diabetes (T2D) risk variants at high-performance rates. The proposed algorithm consists of five important phases. The first stage is to collect T2D-associated DNA sequences and to digitize them by the Entropy-based technique. The second stage is to transform these digitized DNA sequences into 224 × 224 pixels size spectrum images. The third is to extract a distinctive feature set from these spectrum images using the ResNet and VGG19 architectures. The fourth is to classify the effective feature set using SVM and k-NN methods. The last stage is to evaluate the system with k-fold cross-validation. As a result of the developed algorithm, the performances of the used Convolutional Neural Network (CNN) methods, the Entropy-based technique, and the classifiers were compared in relation. As a result of the study a combination model of the proposed Entropy-based technique, ResNet and Support Vector Machine (SVM) achieved the highest accuracy rate with 99.09\%. With this study, the performance of the system in the extraction of epigenetic features and prediction of T2D from spectrogram images was investigated. The results show that the system will contribute to the identification of all genes in diabetes-related tissue and studies on new drug targets.},
  archive      = {J_NCA},
  author       = {Das, Bihter},
  doi          = {10.1007/s00521-022-07121-8},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12587-12599},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning model for identification of diabetes type 2 based on nucleotide signals},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transformers only look once with nonlinear combination for
real-time object detection. <em>NCA</em>, <em>34</em>(15), 12571–12585.
(<a href="https://doi.org/10.1007/s00521-022-07333-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a novel real-time object detector called Transformers Only Look Once (TOLO) is proposed to resolve two problems. The first problem is the inefficiency of building long-distance dependencies among local features for amounts of modern real-time object detectors. The second one is the lack of inductive biases for vision Transformer networks with heavily computational cost. TOLO is composed of Convolutional Neural Network (CNN) backbone, Feature Fusion Neck (FFN), and different Lite Transformer Heads (LTHs), which are used to transfer the inductive biases, supply the extracted features with high-resolution and high-semantic properties, and efficiently mine multiple long-distance dependencies with less memory overhead for detection, respectively. Moreover, to find the massive potential correct boxes during prediction, we propose a simple and efficient nonlinear combination method between the object confidence and the classification score. Experiments on the PASCAL VOC 2007, 2012, and the MS COCO 2017 datasets demonstrate that TOLO significantly outperforms other state-of-the-art methods with a small input size. Besides, the proposed nonlinear combination method can further elevate the detection performance of TOLO by boosting the results of potential correct predicted boxes without increasing the training process and model parameters.},
  archive      = {J_NCA},
  author       = {Xia, Ruiyang and Li, Guoquan and Huang, Zhengwen and Pang, Yu and Qi, Man},
  doi          = {10.1007/s00521-022-07333-y},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12571-12585},
  shortjournal = {Neural Comput. Appl.},
  title        = {Transformers only look once with nonlinear combination for real-time object detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-supervised graph representation learning using
multi-scale subgraph views contrast. <em>NCA</em>, <em>34</em>(15),
12559–12569. (<a
href="https://doi.org/10.1007/s00521-022-07299-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation learning has received widespread attention in recent years. Most of the existing graph representation learning methods are based on supervised learning and require the complete graph as input. It needs a lot of computation memory cost. Besides, real-world graph data lacks labels and the cost of manually labeling data is expensive. Self-supervised learning provides a potential solution for graph representation learning to address these issues. Recently, multi-scale and multi-level self-supervised contrastive methods have been successfully applied. But most of these methods operate on complete graph data. Although the subgraph contrastive strategy improves the shortcomings of the previous self-supervised contrastive learning method, these subgraph contrastive methods only use a single contrastive strategy, which cannot fully extract the information in the graph. To approach these problems, in this paper, we introduce a novel self-supervised contrastive framework for graph representation learning. We generate multi-subgraph views for all nodes by a mixed sampling method. Our method learns node representation by a multi-scale contrastive loss. Specifically, we employ two objectives called bootstrapping contrastive loss and node-level agreement contrastive loss to maximize the node agreement between different subgraph views of the same node. Extensive experiments prove that compared with the state-of-the-art graph representation learning methods, our method is superior to a range of existing models in node classification task and computation memory costs.},
  archive      = {J_NCA},
  author       = {Chen, Lei and Huang, Jin and Li, Jingjing and Cao, Yang and Xiao, Jing},
  doi          = {10.1007/s00521-022-07299-x},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12559-12569},
  shortjournal = {Neural Comput. Appl.},
  title        = {Self-supervised graph representation learning using multi-scale subgraph views contrast},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human emotion recognition from EEG-based brain–computer
interface using machine learning: A comprehensive review. <em>NCA</em>,
<em>34</em>(15), 12527–12557. (<a
href="https://doi.org/10.1007/s00521-022-07292-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affective computing, a subcategory of artificial intelligence, detects, processes, interprets, and mimics human emotions. Thanks to the continued advancement of portable non-invasive human sensor technologies, like brain–computer interfaces (BCI), emotion recognition has piqued the interest of academics from a variety of domains. Facial expressions, speech, behavior (gesture/posture), and physiological signals can all be used to identify human emotions. However, the first three may be ineffectual because people may hide their true emotions consciously or unconsciously (so-called social masking). Physiological signals can provide more accurate and objective emotion recognition. Electroencephalogram (EEG) signals respond in real time and are more sensitive to changes in affective states than peripheral neurophysiological signals. Thus, EEG signals can reveal important features of emotional states. Recently, several EEG-based BCI emotion recognition techniques have been developed. In addition, rapid advances in machine and deep learning have enabled machines or computers to understand, recognize, and analyze emotions. This study reviews emotion recognition methods that rely on multi-channel EEG signal-based BCIs and provides an overview of what has been accomplished in this area. It also provides an overview of the datasets and methods used to elicit emotional states. According to the usual emotional recognition pathway, we review various EEG feature extraction, feature selection/reduction, machine learning methods (e.g., k-nearest neighbor), support vector machine, decision tree, artificial neural network, random forest, and naive Bayes) and deep learning methods (e.g., convolutional and recurrent neural networks with long short term memory). In addition, EEG rhythms that are strongly linked to emotions as well as the relationship between distinct brain areas and emotions are discussed. We also discuss several human emotion recognition studies, published between 2015 and 2021, that use EEG data and compare different machine and deep learning algorithms. Finally, this review suggests several challenges and future research directions in the recognition and classification of human emotional states using EEG.},
  archive      = {J_NCA},
  author       = {Houssein, Essam H. and Hammad, Asmaa and Ali, Abdelmgeid A.},
  doi          = {10.1007/s00521-022-07292-4},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12527-12557},
  shortjournal = {Neural Comput. Appl.},
  title        = {Human emotion recognition from EEG-based brain–computer interface using machine learning: A comprehensive review},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Emergency lane vehicle detection and classification method
based on logistic regression and a deep convolutional network.
<em>NCA</em>, <em>34</em>(15), 12517–12526. (<a
href="https://doi.org/10.1007/s00521-021-06468-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the ever-improving degree of car privatization, the number of car-owning residents has repeatedly reached new highs, but it has also caused traffic congestion, especially lane congestion. To reduce emergency lane congestion, and realize the intelligent detection and classification of emergency lanes, this paper introduces logistic regression theory and proposes a vehicle detection method based on logistic regression. Based on the powerful feature abstraction and automatic learning capabilities of convolutional networks, it studies vehicles based on convolutional networks. The recognition algorithm analyses the contribution of the convolution kernel in the convolutional network, and transforms the original emergency lane vehicle detection. The research results show that the emergency lane vehicle detection rate based on logistic regression and a deep convolutional network designed in this paper can reach approximately 98\%, which is higher than the detection methods based on SVM and AdaBoost, and the detection time is not different from SVM and AdaBoost. After training, the convolution kernel of the deep convolutional network, the detection time and detection accuracy improved to a certain extent. This shows that the emergency lane vehicle detection and classification method based on logistic regression and a deep convolutional network, can play an important role in emergency lane intelligence.},
  archive      = {J_NCA},
  author       = {Li, Guangming and Wang, Qingjun and Zuo, Congrui},
  doi          = {10.1007/s00521-021-06468-8},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12517-12526},
  shortjournal = {Neural Comput. Appl.},
  title        = {Emergency lane vehicle detection and classification method based on logistic regression and a deep convolutional network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on the effect of government media and users’
emotional experience based on LSTM deep neural network. <em>NCA</em>,
<em>34</em>(15), 12505–12516. (<a
href="https://doi.org/10.1007/s00521-021-06567-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different government media have different communication effects and users&#39; emotional experience. It carries on a comparative research on government media selecting three different types of government media which include China’s Police Online, Central Committee of the Communist Youth League, and China’s Fire Control in the context of public health emergencies. Based on the deep learning technique, the emotion classification model of long-term memory network is constructed to analyze the emotion of the users’ comments of different government media; taking the number of contents, the number of retweets, the number of praises, and the number of comments as evaluating indicators to do comparative analysis to cross platform government medias. Through the comparative results, it is found that different types and platforms of government media have great differences in users’ emotional experience; the emotion performance of users’ comments is strongly related to the information communication power and effectiveness of government media.},
  archive      = {J_NCA},
  author       = {Wang, Nan and Lv, Xinlong and Sun, Shanwu and Wang, Qingjun},
  doi          = {10.1007/s00521-021-06567-6},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12505-12516},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on the effect of government media and users’ emotional experience based on LSTM deep neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enterprise management heterogeneity and enterprise
investment behavior based on intelligent scheduling system.
<em>NCA</em>, <em>34</em>(15), 12491–12504. (<a
href="https://doi.org/10.1007/s00521-021-06463-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The heterogeneity of enterprise management will have a certain impact on enterprise investment. In order to explore the strength of this correlation, this paper builds an intelligent system that can be used for enterprise analysis with the support of machine learning technology, uses embedded algorithms to improve the traditional algorithm structure, and combines machine learning to optimize and analyze data processing. Moreover, this paper combines the heterogeneity of enterprise management and the actual needs of enterprise management, the current financial market investment status to analyze the system&#39;s functional structure, and combine the actual needs to construct the overall system architecture. In addition, this paper adopts algorithm analysis to the system process, analyzes the system logic layer structure, and builds the overall system structure framework. Finally, this paper designs an experiment to analyze the performance of the system constructed in this paper. From the experimental research, it can be seen that the system constructed in this paper basically meets the expected requirements.},
  archive      = {J_NCA},
  author       = {Wang, Jingjuan and Xia, Weili},
  doi          = {10.1007/s00521-021-06463-z},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12491-12504},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enterprise management heterogeneity and enterprise investment behavior based on intelligent scheduling system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of geosteering system based on GWO–SVM model.
<em>NCA</em>, <em>34</em>(15), 12479–12490. (<a
href="https://doi.org/10.1007/s00521-021-06583-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two geological steering models, the particle swarm support vector machine (PSO-SVM) and the gray wolf support vector machine (GWO–SVM), were analyzed to determine the models’ optimal global parameters. The fitness function was used to compare and analyze the models, while the original data and feature reconstruction data were used to simulate and analyze the models. The most suitable model for shale gas geosteering identification was selected; the multi-source information fusion for the shale gas geosteering design was completed; and a complete geosteering discrimination model was established. Research on the shale gas geosteering identification system with multi-source information fusion was conducted, and we completed the technical scheme design of shale gas geosteering discrimination system with multi-source information fusion, supported the ground real-time data acquisition system, processed the geosteering discrimination, and completed the demand analysis of the shale gas geosteering discrimination system with multi-source information fusion. In the process of drilling, the relationship between the trajectory and the formation position was analyzed, and the drilling trajectory was monitored. The system mainly included the software main interface, data, and geosteering identification module.},
  archive      = {J_NCA},
  author       = {Mao, Min and Yang, Hai and Xu, Fengyang and Ni, Pengbo and Wu, Haosheng},
  doi          = {10.1007/s00521-021-06583-6},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12479-12490},
  shortjournal = {Neural Comput. Appl.},
  title        = {Development of geosteering system based on GWO–SVM model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Credit risk assessment of small and medium-sized
enterprises in supply chain finance based on SVM and BP neural network.
<em>NCA</em>, <em>34</em>(15), 12467–12478. (<a
href="https://doi.org/10.1007/s00521-021-06682-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our country’s market economy is composed of enterprises. However, due to their inherent credit deficiencies and high risks of management, it is very difficult for them to obtain financing support. Based on this, this article studies Error Back Propagation (BP) to establish (SMEs). Based on the relevant concepts of the supply chain management budget model, it explores the main factors influencing the financial impact of SMEs and the benefits of the supply chain budget in solving problems expenditure of SMEs, support vector machine is mainly based on solving the main credit risks of small and medium-sized enterprises, such as poor information transparency, low credit and various risk unknown factors. BP neural network is an algorithm that takes into account the components of supply chain financial financing. This article first gives a simple background and theoretical introduction to the under the current supply chain finance model, and then proposes to use SVM and BP neural network algorithms to build and the model has been trained and tested. After collecting relevant references, we will establish authoritative risk assessment rules in accordance with this article according to these standards. These experts are mainly people with many years of experience in the financial industry, and they also have a certain influence in the industry. The risk assessment established for this can be the analysis of factors such as risk indicators and government intervention in this experiment.},
  archive      = {J_NCA},
  author       = {Zhao, Jingfeng and Li, Bo},
  doi          = {10.1007/s00521-021-06682-4},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12467-12478},
  shortjournal = {Neural Comput. Appl.},
  title        = {Credit risk assessment of small and medium-sized enterprises in supply chain finance based on SVM and BP neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effect of artificial intelligence auxiliary equipment in the
process of cognitive learning. <em>NCA</em>, <em>34</em>(15),
12453–12466. (<a
href="https://doi.org/10.1007/s00521-021-06470-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People’s cognition of objectively existing things is developing in the direction of digitization, and more and more objectively existing things are constantly being presented in the form of data. In order to realize the analysis of constantly changing large-scale data and the automatic extraction of valuable information, this paper analyzes the application of artificial intelligence auxiliary equipment based on machine learning in the cognitive learning process, and proposes a collaborative filtering method based on fusion of global and local parameters. Moreover, this paper studies a cognitive computing model based on context-aware data stream to realize effective analysis of context-aware data and obtain effective cognitive results. In addition, this paper proposes a task scheduling algorithm based on improved queue matching to solve the task scheduling problem in a distributed computing environment. Finally, this paper constructs an improved algorithmic cognitive system architecture, and verifies the performance of the system through experimental research. The research results show that the system constructed in this paper is highly reliable.},
  archive      = {J_NCA},
  author       = {Wu, Fenglang and Liu, Xinran and Wang, Yudan},
  doi          = {10.1007/s00521-021-06470-0},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12453-12466},
  shortjournal = {Neural Comput. Appl.},
  title        = {Effect of artificial intelligence auxiliary equipment in the process of cognitive learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human motion tracking and 3D motion track detection
technology based on visual information features and machine learning.
<em>NCA</em>, <em>34</em>(15), 12439–12451. (<a
href="https://doi.org/10.1007/s00521-021-06703-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion detection is a major subject of investigation in the field of machine visualization and synthetic integration. It serves a wide and important spectrum of applications in terms of visual surveillance, cross-functional simulation, movement acquisition, and high-level man-computer interface. In order to improve the accuracy of human tracking, this paper starts from the geometric flow characteristics of the image, and proposes a Gaussian algorithm to process human motion images, and applies it to the video human motion tracking of machine learning methods. Using the statistical features of the optimized transformation as the features of the image, regression learning and prediction of the three-dimensional human body movement posture in the monocular video image. First, the optimal parameters and additional statistical features of the transformation used in the extraction of human image features are verified through experiments, and then various regression methods are used for parameter learning, and the prediction performance and human tracking tests are carried out. The final test results found that the accuracy of the method based on visual information features and machine learning is 5\% higher than the previous method, and the recognition rate of human motion tracking is as high as 95\%. The processing capability of the detection technology of 3D motion trajectory has also increased by nearly 7\%.},
  archive      = {J_NCA},
  author       = {Zhang, Xin and Xu, Zhongqiu and Liao, Hongbo},
  doi          = {10.1007/s00521-021-06703-2},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12439-12451},
  shortjournal = {Neural Comput. Appl.},
  title        = {Human motion tracking and 3D motion track detection technology based on visual information features and machine learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sparse representation optimization of image gaussian mixture
features based on a convolutional neural network. <em>NCA</em>,
<em>34</em>(15), 12427–12437. (<a
href="https://doi.org/10.1007/s00521-021-06521-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes the inherent relationship between convolutional neural networks and sparse representation and proposes an improved convolutional neural network model for image synthesis in response to problems with current methods. In the testing phase, the calculation of the sparse coefficients involves the solution of complex optimization problems, which greatly reduce the operating efficiency, inspired by the successful application of convolutional neural networks in the field of image reconstruction. Compared with the traditional image portrait synthesis method, this model not only has an end-to-end closed form but also does not need to solve complex optimization problems in the synthesis stage. The synthesis experiment on an image dataset shows that this method not only improves the synthesis effect but also improves the efficiency of the traditional method by one to two orders of magnitude, demonstrating its potential application value. Blocking processing is a common method for sparse domain image modeling. It improves the computational efficiency but also decreases the global structure of the image, which is difficult to compensate for through the aggregation and overlap of image blocks. In response to this problem, this paper proposes a low-rank image inpainting method based on a Gaussian mixture model. This method embeds the local statistical characteristics of image blocks into the kernel norm model and not only uses the Gaussian mixture model to maintain the local details of the image but also describes the global low-rank structure of the image through the kernel norm, thus restoring a class of image data with a potential low-rank structure and theoretically revealing the structured sparse nature of the Gaussian mixture model. This paper optimizes the strategy based on random hidden neuron nodes and proposes a dropout anti-overfitting strategy based on sparsity. The experiments show that this strategy can effectively improve the convergence speed while ensuring good performance and can effectively prevent overfitting.},
  archive      = {J_NCA},
  author       = {Ye, Fangfang and Ren, Tiaojuan and Wang, Zhangquan and Wang, Ting},
  doi          = {10.1007/s00521-021-06521-6},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12427-12437},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sparse representation optimization of image gaussian mixture features based on a convolutional neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A progressive hierarchical analysis model for collective
activity recognition. <em>NCA</em>, <em>34</em>(15), 12415–12425. (<a
href="https://doi.org/10.1007/s00521-021-06585-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a progressive hierarchical analysis model to perceive the collective activities. Compared with previous activity recognition works, it not only recognizes the collective activities, but also perceives the location and the action category of each individual. At first, we perform the person temporal consistency detection procedure for each individual of the collective activities. A person detection network and conditional random field are used to receive the bounding box sequences of the activity participators. Then, we recognize the individual actions using the learned spatial features and the motion features based on LSTM. At last, the combination of the recognized person-level action category vector, the scene context features and the interaction Context features are used to recognize the collective activities. We evaluate the proposed approach on benchmark collective activity datasets. Extensive experiments demonstrate the effects of the progressive hierarchical analysis model.},
  archive      = {J_NCA},
  author       = {Pei, Lishen and Zhao, Xuezhuan and Li, Tao and Zhang, Zheng},
  doi          = {10.1007/s00521-021-06585-4},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12415-12425},
  shortjournal = {Neural Comput. Appl.},
  title        = {A progressive hierarchical analysis model for collective activity recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The correlation between green finance and carbon emissions
based on improved neural network. <em>NCA</em>, <em>34</em>(15),
12399–12413. (<a
href="https://doi.org/10.1007/s00521-021-06514-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of green finance and the quantitative evaluation of its impact on the ecological environment provide empirical evidence for the construction of the carbon trading accounting system. Among them, carbon trading is an important part of green finance, and the accounting of businesses related to carbon emission rights has promoted the development of regional green finance. In order to explore the relationship between green finance and carbon emissions, this paper builds an analysis model of the relationship between green finance and carbon emissions based on big data and machine learning based on big data technology and machine learning technology. Moreover, this paper conducts simulation tests through the system and compares the output results with the actual situation after system simulation to verify the effectiveness of the model in this paper. From the experimental research results, it can be seen that the correlation analysis model of green finance and carbon emissions based on big data and machine learning constructed in this paper has a good performance in the correlation analysis of green finance and carbon emissions. Moreover, it is not difficult to see through the model of this paper that there is a clear correlation between green finance and carbon emissions.},
  archive      = {J_NCA},
  author       = {Sun, Chenghao},
  doi          = {10.1007/s00521-021-06514-5},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12399-12413},
  shortjournal = {Neural Comput. Appl.},
  title        = {The correlation between green finance and carbon emissions based on improved neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vehicle local path planning and time consistency of unmanned
driving system based on convolutional neural network. <em>NCA</em>,
<em>34</em>(15), 12385–12398. (<a
href="https://doi.org/10.1007/s00521-021-06479-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The path planning system is an important part of unmanned vehicles, and the development of path planning technology will surely promote the rapid development of unmanned vehicle technology. In order to prevent the node from continuously monitoring its state, a self-triggering control strategy is proposed. Before the trigger moment, the node does not need to monitor its state. Moreover, considering the unpredictable problem of the node state, a control strategy triggered by the observed event is proposed, that is, only the output state information is used to determine the trigger time. In addition, this paper analyzes and models the two major factors that affect the local planning results, the environment and the vehicle, and uses the path smoothing and optimization method based on B-spline curve and the path optimization method based on the steering controller. Finally, this paper designs experiments to analyze the vehicle local path planning method and time consistency of the unmanned driving system. From the experimental results, it can be seen that the unmanned driving system constructed in this paper has a certain effect.},
  archive      = {J_NCA},
  author       = {Yang, Gang and Yao, Yuan},
  doi          = {10.1007/s00521-021-06479-5},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12385-12398},
  shortjournal = {Neural Comput. Appl.},
  title        = {Vehicle local path planning and time consistency of unmanned driving system based on convolutional neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient but lightweight network for vehicle
re-identification with center-constraint loss. <em>NCA</em>,
<em>34</em>(15), 12373–12384. (<a
href="https://doi.org/10.1007/s00521-021-06658-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle re-identification aims to retrieve the target vehicle from the image gallery quickly and accurately. Vehicle re-identification with deep learning has achieved considerable performance. However, most popular methods need construct complex network, which increases the calculation of network and difficulty of training. To balance performance and complexity, an efficient but lightweight network is proposed in this work. The designed network utilizes the global branch and the mask branch to extract the feature. The former can extract global feature efficiently. The latter can remove the changeable background based on the proposed mask-mapping module, which can map mask to feature map and adjust feature map dynamically. And then, the features from the original image and the mask-mapping module are fused to generate the final feature for vehicle re-identification. Besides, a novel center-constraint triplet loss is designed to optimize the proposed network and excavate more discriminate feature. Different from triplet loss, the proposed loss can consider more extra samples and constrain the center from positive sample set as well as negative sample set. To enhance the difference between hard samples and simple samples, an unequal weight strategy is embedded in this loss. The proposed method achieves 78.7\% mAP with 95.4\% Rank-1 on VeRi-776, and 84.3\%, 80.7\%, and 80.1\% Rank-1 on three subsets from VehicleID, which demonstrates the effectiveness of the proposed method.},
  archive      = {J_NCA},
  author       = {Yu, Zhi and Zhu, Mingpeng},
  doi          = {10.1007/s00521-021-06658-4},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12373-12384},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient but lightweight network for vehicle re-identification with center-constraint loss},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Road rage detection algorithm based on fatigue driving and
facial feature point location. <em>NCA</em>, <em>34</em>(15),
12361–12371. (<a
href="https://doi.org/10.1007/s00521-021-06856-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to monitor whether a driver is tired or prone to road rage in real time and avoid some traffic accidents, a real-time detection method of driver&#39;s facial expression based on the facial feature point location is proposed. First, we use the AdaBoost face detection algorithm based on Haar characteristics to detect the presence of a face and use the face feature point localization algorithm to obtain the required face feature points. Then, the value of eye aspect ratio is calculated according to the feature point data of the face-eye region, which indicates the opening degree of eyes. The driver is detected whether he (she) is in fatigue driving according to the appropriate threshold. We improve the detection method of fatigue driving and apply it to the road rage detection algorithm. We first propose the ratios of the brow-eye distance and mouth closure (RBEM) as indicators to determine whether the driver has road rage characteristics. Experimental results verify the effectiveness of the method.},
  archive      = {J_NCA},
  author       = {Shulei, Wu and Zihang, Suo and Huandong, Chen and Yuchen, Zhao and Yang, Zhang and Jinbiao, Chen and Qiaona, Meng},
  doi          = {10.1007/s00521-021-06856-0},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12361-12371},
  shortjournal = {Neural Comput. Appl.},
  title        = {Road rage detection algorithm based on fatigue driving and facial feature point location},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved spatial point cloud simplification algorithm.
<em>NCA</em>, <em>34</em>(15), 12345–12359. (<a
href="https://doi.org/10.1007/s00521-021-06582-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional data simplification algorithms depend much on scanning technology. However, with the development of the scanning technology, the conventional algorithm is unable to process numerous redundant data, leading to increased noise of point cloud data, failure of locating split center, and low simplification efficiency. In order to remove the noise in point cloud data, improve randomness for choosing the segmentation center, and obtain robust curvature information of the point cloud data and accurate segmentation results, the following improvements are made to the conventional spatial segmentation algorithms in this paper. Firstly, on the basis of denoising by B-spline wavelet filtering, voxel grid of point cloud data is carried out to select the effective segmentation center. Secondly, through the improvement of the subspace clustering algorithm, reasonable space division can be realized. Thirdly, based on the first-order neighbourhood surface of the vertices of the mesh surface, the curvature of sample points can be estimated. Fourthly, by introducing the distance between the neighbourhood sample and the target sample, the distance between the two points is taken as the geodesic distance, the smooth correction of the estimated result can be realized and the finally simplified point cloud segmentation result can be obtained. Finally, a robust spatial data simplification method is implemented. The experimental results show that this method can further segment spatial data and obtain simplified segmentation results while ensuring segmentation efficiency. Compared with the unified sampling method, the curvature simplification method, the isometric sampling method, and the random sampling method, the proposed method can reduce the sensitivity to boundary noise data, solve the problem of fuzzy boundary division, and overcome the disadvantage of poor accuracy caused by too high dimension.},
  archive      = {J_NCA},
  author       = {Sun, Yi and Zhang, Shenhu and Wang, Tianqi and Lou, Feng and Ma, Jingjin and Wang, Chunying and Gui, Chengrong},
  doi          = {10.1007/s00521-021-06582-7},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12345-12359},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved spatial point cloud simplification algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ECNN: Evaluating a cluster-neural network model for city
innovation capability. <em>NCA</em>, <em>34</em>(15), 12331–12343. (<a
href="https://doi.org/10.1007/s00521-021-06471-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Innovation capability is a great driving force leading city development. It is also important to evaluate the innovation capability of a city for city development. In this paper, we propose an ECNN model to evaluate city innovation capability. This model studies innovation capability from the perspective of machine learning. Compared with the existing statistical methods, it is a novel model, to the best of our knowledge, to evaluate the city’s innovation capability in terms of machine learning. It overcomes the shortcomings of the original statistical methods for studying the relationship between indicators without considering the relationship between indicators and innovation capabilities. This model first clusters all samples, and the sample categories are marked as clusters. Second, the weight of each indicator is calculated by the entropy gain rate, and the total score is calculated by adding the weighted values of each indicator. To obtain more precise results, the neural network calculates the sample scores, which have the same score but belong to the cluster, with good clustering data as the training set. In this way, different clusters represent different innovation capabilities. Each sample has an innovation capability score. Therefore, the ECNN model has high practicability in evaluating the innovation capability of cities.},
  archive      = {J_NCA},
  author       = {Pei, Jiaming and Zhong, Kaiyang and Li, Jinhai and Xu, Jiyuan and Wang, Xinyi},
  doi          = {10.1007/s00521-021-06471-z},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12331-12343},
  shortjournal = {Neural Comput. Appl.},
  title        = {ECNN: Evaluating a cluster-neural network model for city innovation capability},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LGWO-SVM geological steering identification method for shale
gas based on a gamma spectral dataset. <em>NCA</em>, <em>34</em>(15),
12317–12329. (<a
href="https://doi.org/10.1007/s00521-021-06570-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the problem in traditional technology of the time lag in determining formation information based on drilling time and rock physical characteristics, which leads to the failure of the guided drilling tool, a Levy flight optimized gray wolf support vector machine (LGWO-SVM) shale gas geosteering identification method based on gamma spectrum dataset was proposed. First, the gamma spectrum dataset was processed using mapminmax normalization to eliminate the feature confusion caused by data modeling. Second, principal component analysis (PCA) feature reconstruction was carried out on the gamma spectrum dataset to provide an excellent data basis for the subsequent establishment of a multiclassification support vector machine (SVM) model. Then, the Levy distribution was adopted into gray wolf optimization for the multiclassification SVM model to obtain the LGWO-SVM model for geosteering discriminant prediction. Finally, the experimental results corresponding to the particle swarm optimization support vector machine (PSO-SVM) and the gray wolf optimizer support vector machine (GWO-SVM) models were summarized and compared. The experimental results show that after the data processing and feature extraction of the gamma spectrum dataset, the established LGWO-SVM model can accurately distinguish the formation information and effectively improve the reservoir drilling rate.},
  archive      = {J_NCA},
  author       = {Xu, Fengyang and Li, Zhongbing and Mao, Min and Ni, Pengbo and Jing, Wenming},
  doi          = {10.1007/s00521-021-06570-x},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12317-12329},
  shortjournal = {Neural Comput. Appl.},
  title        = {LGWO-SVM geological steering identification method for shale gas based on a gamma spectral dataset},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Target recognition method of small UAV remote sensing image
based on fuzzy clustering. <em>NCA</em>, <em>34</em>(15), 12299–12315.
(<a href="https://doi.org/10.1007/s00521-021-06650-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the target recognition effect of small UAV (unmanned aerial vehicle) remote sensing image, this paper proposes a new super-resolution reconstruction method based on the recurrent convolutional network, which can achieve different degrees of super-resolution effect by controlling the number of cycles. Moreover, it can control the number of iterations of small UAVs with different degrees of blur and can be better adapted to the recognition scenarios of UAVs. In addition, this paper studies the target recognition method of small UAV remote sensing image, combines fuzzy clustering method to construct the intelligent remote sensing image target recognition model, combines it with the UAV structure, realizes remote sensing recognition by UAV, and designs experiments to analyze the effect of remote sensing recognition. Further, this paper improves the recognition algorithm and positioning algorithm of remote sensing image, so that recognition and positioning of UAV video remote sensing image can get better results. Finally, this paper verifies the performance of the system through simulation experiments. The research results show that the method proposed in this paper has certain reliability.},
  archive      = {J_NCA},
  author       = {Guo, Linyang and Yang, Runxian and Zhong, Zhichao and Zhang, Ran and Zhang, Bo},
  doi          = {10.1007/s00521-021-06650-y},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12299-12315},
  shortjournal = {Neural Comput. Appl.},
  title        = {Target recognition method of small UAV remote sensing image based on fuzzy clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Extraction of landslide features in UAV remote sensing
images based on machine vision and image enhancement technology.
<em>NCA</em>, <em>34</em>(15), 12283–12297. (<a
href="https://doi.org/10.1007/s00521-021-06523-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the effect of landslide feature extraction, this paper improves the remote sensing image recognition algorithm with the support of a machine learning algorithm. Moreover, this paper combines UAV remote sensing images to extract landslide features, classifies and introduces the evaluation criteria for target detection and several representative target detectors. This paper also constructs the functional structure of the system according to the landslide feature extraction requirements and designs a set of optimization schemes for landslide feature data collection and control measurement suitable for field operations. In addition, this paper analyses the system kernel algorithm process and analyses the system function realization through simulation research. Finally, this paper designs an experiment to evaluate the practicability of the system constructed in this paper. From the results of experimental statistics, we can see that the system constructed in this paper has good practicability.},
  archive      = {J_NCA},
  author       = {Qi, Jianhua and Chen, Hong and Chen, Fengping},
  doi          = {10.1007/s00521-021-06523-4},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12283-12297},
  shortjournal = {Neural Comput. Appl.},
  title        = {Extraction of landslide features in UAV remote sensing images based on machine vision and image enhancement technology},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Supply chain security evaluation model and index system
based on a 5G information system. <em>NCA</em>, <em>34</em>(15),
12271–12281. (<a
href="https://doi.org/10.1007/s00521-021-06584-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the supply chain management model has been widely adopted worldwide. Internationally renowned companies such as IBM and Walmart have made significant achievements in supply chain management and have played a greater role in promoting the growth of their interests. However, while they are enjoying their own interests, they are also facing various risks in the supply chain. From the perspective of systems engineering, this paper uses complex network theory as a research tool to study supply chain networks and systematically study the important issues of supply chain network risks. This paper analyzes the new characteristics of the relationship between enterprises and suppliers in the supply chain and which indicators should be selected as the basis for evaluating suppliers from the perspective of cooperation and development, which more comprehensively reflects the characteristics of the new enterprise–supplier relationship in the supply chain environment. This highlights the evaluation of the supplier’s cooperation ability and development ability. Aiming at the problem of supply chain network system identification and integrated evaluation, a supply chain security evaluation model and index system research framework model are proposed, and the intercompany business risk and supply chain in supply chain network evaluation are introduced. As a model for evaluating transition parameters, the study of supply chain risk propagation introduces the theory of dynamic propagation in complex networks, the law of evolution, and the supplier&#39;s dynamic supply chain risk model. The experimental results of this paper show that when the global reputation value is 0.5 and the local reputation value is 0.8 and 0.7, the trust degree changes with the change of the confidence factor; when the value of the confidence factor decreases, the degree of trust converges more and more to the global reputation and vice versa. It can be seen that this model has high feasibility.},
  archive      = {J_NCA},
  author       = {Zhao, Jingfeng and Li, Yan},
  doi          = {10.1007/s00521-021-06584-5},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12271-12281},
  shortjournal = {Neural Comput. Appl.},
  title        = {Supply chain security evaluation model and index system based on a 5G information system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent analysis system for signal processing tasks
based on LSTM recurrent neural network algorithm. <em>NCA</em>,
<em>34</em>(15), 12257–12269. (<a
href="https://doi.org/10.1007/s00521-021-06478-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the effectiveness of signal processing, according to the actual needs of signal processing and the current problems in signal processing, this paper introduces an improved LSTM recurrent neural network algorithm to construct the signal processing algorithm. Moreover, this paper sets up the functional structure of this paper based on the neural network model structure, and builds an intelligent analysis system for signal processing tasks based on the LSTM recurrent neural network algorithm. In addition, this paper analyzes the system algorithm flow in detail, and combines experimental research to carry out the effectiveness of the system constructed in this paper, and conducts quantitative analysis from two aspects of signal threshold prediction and signal processing effect. Finally, this paper conducts experimental results research with the support of mathematical statistics methods. From the research point of view, it can be known that the system constructed in this paper has good signal processing functions.},
  archive      = {J_NCA},
  author       = {Zhou, Ya and Jiao, Xiaobo},
  doi          = {10.1007/s00521-021-06478-6},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12257-12269},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intelligent analysis system for signal processing tasks based on LSTM recurrent neural network algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent analysis of e-government influence factors based
on improved machine learning. <em>NCA</em>, <em>34</em>(15),
12241–12256. (<a
href="https://doi.org/10.1007/s00521-021-06657-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the effect of e-government work, it is necessary to analyze its influencing factors. E-government is affected by many social factors, so it is necessary to combine intelligent models to improve the effect of factor analysis. This paper combines the essence of e-government influencing factor data to improve the machine learning algorithm and uses the EM algorithm to derive the parameter estimation formula of the data in the case of missing data to improve the accuracy of data analysis. Moreover, this article combines the structure of the e-government system to build the main structure of the intelligent analysis model of the influence factors of e-government. According to the key influencing factor model of e-government adoption and multi-dimensional research on technology, organization and implementation, this paper puts forward the model and promotion mode of the e-government system based on cloud computing and conducts a simulation. From the simulation results, the effect of the model proposed in this paper is more significant.},
  archive      = {J_NCA},
  author       = {Wei, Lili},
  doi          = {10.1007/s00521-021-06657-5},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12241-12256},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intelligent analysis of e-government influence factors based on improved machine learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Topical collections on machine learning based semantic
representation and analytics for multimedia application. <em>NCA</em>,
<em>34</em>(15), 12239–12240. (<a
href="https://doi.org/10.1007/s00521-022-07443-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Yan, Yuwei and Liu, Weidong},
  doi          = {10.1007/s00521-022-07443-7},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {12239-12240},
  shortjournal = {Neural Comput. Appl.},
  title        = {Topical collections on machine learning based semantic representation and analytics for multimedia application},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient palmprint biometric identification systems using
deep learning and feature selection methods. <em>NCA</em>,
<em>34</em>(14), 12119–12141. (<a
href="https://doi.org/10.1007/s00521-022-07098-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past two decades, several studies have paid great attention to biometric palmprint recognition. Recently, most methods in literature adopted deep learning due to their high recognition accuracy and the capability to adapt with different acquisition palmprint images. However, high-dimensional data with a large number of uncorrelated and redundant features remain a challenge due to computational complexity issues. Feature selection is a process of selecting a subset of relevant features, which aims to decrease the dimensionality, reduce the running time, and improve the accuracy. In this paper, we propose efficient unimodal and multimodal biometric systems based on deep learning and feature selection. Our approach called simplified PalmNet–Gabor concentrates on the improvement of the PalmNet for fast recognition of multispectral and contactless palmprint images. Therefore, we used Log-Gabor filters in the preprocessing to increase the contrast of palmprint features. Then, we reduced the number of features using feature selection and dimensionality reduction procedures. For the multimodal system, we fused modalities at the matching score level to improve system performance. The proposed method effectively improves the accuracy of the PalmNet and reduces the number of features as well the computational time. We validated the proposed method on four public palmprint databases, two multispectral databases, CASIA and PolyU, and two contactless databases, Tongji and PolyU 2D/3D. Experiments show that our approach achieves a high recognition rate while using a substantially lower number of features.},
  archive      = {J_NCA},
  author       = {Trabelsi, Selma and Samai, Djamel and Dornaika, Fadi and Benlamoudi, Azeddine and Bensid, Khaled and Taleb-Ahmed, Abdelmalik},
  doi          = {10.1007/s00521-022-07098-4},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {12119-12141},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient palmprint biometric identification systems using deep learning and feature selection methods},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A bagging-based surrogate-assisted evolutionary algorithm
for expensive multi-objective optimization. <em>NCA</em>,
<em>34</em>(14), 12097–12118. (<a
href="https://doi.org/10.1007/s00521-022-07097-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a big challenge for multi-objective evolutionary algorithms to solve expensive multi-objective optimization due to high computational cost. To effectively address expensive multi-objective optimization, this work proposes a novel surrogate-assisted evolutionary algorithm (SAEA), named bagging-based SAEA (B-SAEA). In the proposed method, bagging is introduced to construct high-quality surrogate ensembles for each expensive objective under a limited number of training points. Thereafter, an evolutionary search is applied to fully search for the constructed surrogate ensembles with the help of generation-based search strategy. Thus, surrogate ensembles and evolutionary search can be seamlessly integrated. In addition, a niche-based infill solutions selection strategy is proposed to select the promising points as the infill solutions for real fitness evaluations. As a result, a good balance between convergence and diversity can be achieved within a limited computational budget. Experimental results on commonly used benchmark test problems and real-world engineering application have demonstrated that the proposed method performs competitively compared with other state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Liu, Yuanchao and Liu, Jianchang and Tan, Shubin and Yang, Yongkuan and Li, Fei},
  doi          = {10.1007/s00521-022-07097-5},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {12097-12118},
  shortjournal = {Neural Comput. Appl.},
  title        = {A bagging-based surrogate-assisted evolutionary algorithm for expensive multi-objective optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evading behavioral classifiers: A comprehensive analysis on
evading ransomware detection techniques. <em>NCA</em>, <em>34</em>(14),
12077–12096. (<a
href="https://doi.org/10.1007/s00521-022-07096-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in machine learning has led to promising results in behavioral malware detection. Behavioral modeling identifies malicious processes via features derived by their runtime behavior. Behavioral features hold great promise as they are intrinsically related to the functioning of each malware, and are therefore considered difficult to evade. Indeed, while a significant amount of results exists on evasion of static malware features, evasion of dynamic features has seen limited work. This paper examines the robustness of behavioral ransomware detectors to evasion and proposes multiple novel techniques to evade them. Ransomware behavior differs significantly from that of benign processes, making it an ideal best case for behavioral detectors, and a difficult candidate for evasion. We identify and propose a set of novel attacks that distribute the overall malware workload across a small set of independent, cooperating processes in order to avoid the generation of significant behavioral features. Our most effective attack decreases the accuracy of a state-of-the-art classifier from 98.6 to 0\% using only 18 cooperating processes. Furthermore, we show our attacks to be effective against commercial ransomware detectors in a black-box setting. Finally, we evaluate a detector designed to identify our most effective attack, as well as discuss potential directions to mitigate our most advanced attack.},
  archive      = {J_NCA},
  author       = {De Gaspari, Fabio and Hitaj, Dorjan and Pagnotta, Giulio and De Carli, Lorenzo and Mancini, Luigi V.},
  doi          = {10.1007/s00521-022-07096-6},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {12077-12096},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evading behavioral classifiers: A comprehensive analysis on evading ransomware detection techniques},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Toward robust and adaptive pedestrian monitoring using CSI:
Design, implementation, and evaluation. <em>NCA</em>, <em>34</em>(14),
12063–12075. (<a
href="https://doi.org/10.1007/s00521-022-07094-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work puts the first effort on investigating robust and adaptive pedestrian passing detection and direction recognition based on WiFi Channel State Information (CSI). Specifically, we first give an insight into the challenges as well as opportunities of realizing cross-scenario pedestrian monitoring based on comprehensive analysis of CSI patterns. In light of the findings, we design a novel system framework, which consists of an offline pattern clustering and training module for constructing a unified offline database, and an online adaptive monitoring module for enabling real-time pedestrian passing detection and direction recognition. Further, we propose four mechanisms, including a CSI pre-processing method to enhance system robustness by extracting stable and distinct CSI features, a Two-stage Clustering (TC) method to enable cross-scenario CSI feature classification by segmenting the offline datasets automatically, a unified segmenting and detecting (USD) method to enable adaptive pedestrian passing detection by training a component classifier and a sample classifier, and a dynamic direction calculation (DDC) method to recognize the passing direction based on time of passing estimation, link confidence calculation, and direction indicator calculation. Finally, we implement the system prototype and evaluate the system performance in real-world scenarios. A comprehensive experimental study demonstrates that the proposed framework and the mechanisms can effectively enhance system robustness and adaptiveness on pedestrian monitoring.},
  archive      = {J_NCA},
  author       = {Liu, Jialai and Liu, Kai and Jin, Feiyu and Gong, Liangyi},
  doi          = {10.1007/s00521-022-07094-8},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {12063-12075},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward robust and adaptive pedestrian monitoring using CSI: Design, implementation, and evaluation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of boundary-fitted convolutional neural network
to simulate non-newtonian fluid flow behavior in eccentric annulus.
<em>NCA</em>, <em>34</em>(14), 12043–12061. (<a
href="https://doi.org/10.1007/s00521-022-07092-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical simulation of non-Newtonian fluid flow is an enduring problem with imperative influence on numerous industrial processes such as oil and gas drilling, food processing, etc. The relation between shear rate and shear stress is nonlinear for non-Newtonian fluids, which results in a highly nonlinear governing equation for fluid flow in an irregular geometry. Analytical solution does not exist for such governing equations and is generally solved by algebraic and iterative methods, which is computationally intensive. Convolutional Networks can learn a complex and high-dimensional functional space solution and may have high accuracy but depend significantly on the quality of training data. One of the prominent challenges in using a Convolutional network is the limiting performance, and the proposed solution may become inconclusive in a small data regime over an irregular geometry. A novel algorithm, Boundary Fitted Convolutional Network, is proposed in this research, which can proficiently solve a partial differential equation for an irregular geometry. This research aims to simulate a Power-Law non-Newtonian fluid in an eccentric annulus with a convolutional network without using training data. The governing equations are transformed from physical domain to computational plane using boundary-fitted coordinate system and then solved by minimizing physics-based residuals. Thus, establishing a benchmark investigation in non-Newtonian fluid flow. The Dirichlet and Neumann boundary conditions are applied in a ‘hard’ manner. The simulated results and parametric analysis conclude that the proposed algorithm can decipher the non-Newtonian fluid mechanics from the governing equations. The algorithms also explain the effect of geometric and rheological parameters on the fluid flow attributes. The performance of the algorithm is validated with experimental data available from published studies. The statistical error estimation exhibits an average root mean squared error of 0.228 and mean absolute percentage error of 8.21\% for four different samples of Power-Law fluid, with varying eccentricities. A comprehensive discussion to train the unsupervised convolutional network, and the spectrum of hyperparameters considered to expedite convergence is also highlighted.},
  archive      = {J_NCA},
  author       = {Kumar, Abhishek and Ridha, Syahrir and Ilyas, Suhaib Umer and Dzulkarnain, Iskandar and Pratama, Agus},
  doi          = {10.1007/s00521-022-07092-w},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {12043-12061},
  shortjournal = {Neural Comput. Appl.},
  title        = {Application of boundary-fitted convolutional neural network to simulate non-newtonian fluid flow behavior in eccentric annulus},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Binary cross-entropy with dynamical clipping. <em>NCA</em>,
<em>34</em>(14), 12029–12041. (<a
href="https://doi.org/10.1007/s00521-022-07091-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the adverse effect of noisy labels in a training dataset on a neural network’s precision in an image classification task. The importance of this research lies in the fact that most datasets include noisy labels. To reduce the impact of noisy labels, we propose to extend the binary cross-entropy by dynamical clipping, which clips all samples’ loss values in a mini-batch by a clipping constant. Such a constant is dynamically determined for every single mini-batch using its statistics. The advantage is the dynamic adaptation to any number of noisy labels in a training dataset. Thanks to that, the proposed binary cross-entropy with dynamical clipping can be used in any model utilizing cross-entropy or focal loss, including pre-trained models. We prove that the proposed loss function is an $$\alpha $$ -calibrated classification loss, implying consistency and robustness to noise misclassification in more general asymmetric problems. We demonstrate our loss function’s usefulness on Fashion MNIST, CIFAR-10, CIFAR-100 datasets, where we heuristically create training data with noisy labels and achieve a nice performance boost compared to the standard binary cross-entropy. These results are also confirmed in the second experiment, where we use a trained model on Google Images to classify the ImageWoof dataset, and the third experiment, where we deal with the WebVision and ANIMAL-10N datasets. We also show that the proposed technique yields significantly better performance than the gradient clipping. Code: gitlab.com/irafm-ai/clipping_cross_entropy},
  archive      = {J_NCA},
  author       = {Hurtik, Petr and Tomasiello, Stefania and Hula, Jan and Hynar, David},
  doi          = {10.1007/s00521-022-07091-x},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {12029-12041},
  shortjournal = {Neural Comput. Appl.},
  title        = {Binary cross-entropy with dynamical clipping},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RESC: REfine the SCore with adaptive transformer head for
end-to-end object detection. <em>NCA</em>, <em>34</em>(14), 12017–12028.
(<a href="https://doi.org/10.1007/s00521-022-07089-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most detection models employ many detection heads to output their prediction results independently. However, the locality of convolutional neural networks (CNN) causes the features extracted by adjacent convolution kernels to be very similar, which leads to duplicate prediction results. To tackle this issue, the hand-designed non-maximum suppression (NMS) procedure is proposed to remove the duplicate results. However, the NMS procedure cannot be applied to certain scenarios, such as the crowd scenarios, and requires careful adjustment of hyper-parameters. Therefore, end-to-end training is necessary to improve the detection ability on more scenarios. To this end, we propose a model that enables the network to adaptively identify duplicate objects and output non-repetitive results, which can effectively replace the hand-designed non-maximum suppression procedure. By adding differentiated priors to image features, and using Multi-Head Attention to enhance the global communication between features, our model can detect objects in an end-to-end manner. Our model can be easily applied to traditional one-stage detectors, e.g., FCOS and RetinaNet. While fast convergence and high recall rate are achieved, the accuracy is also significantly better than the baseline and outperforms many one-stage and two-stage methods. It also achieves the comparable performance as traditional detectors under the dense scene datasets CrowdHuman. Evaluation results demonstrate that our model with ResNet-50 can achieve 40.5\% in $${\mathrm{AP}}$$ on COCO dataset and 89.2\% in $${\mathrm{AP}}_{50}$$ on CrowdHuman dataset.},
  archive      = {J_NCA},
  author       = {Wang, Honglie and Jiang, Rong and Xu, Jian and Sun, Shouqian},
  doi          = {10.1007/s00521-022-07089-5},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {12017-12028},
  shortjournal = {Neural Comput. Appl.},
  title        = {RESC: REfine the SCore with adaptive transformer head for end-to-end object detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Res2Unet: A multi-scale channel attention network for
retinal vessel segmentation. <em>NCA</em>, <em>34</em>(14), 12001–12015.
(<a href="https://doi.org/10.1007/s00521-022-07086-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal diseases can be found timely by observing retinal fundus images. So extracting blood vessels from retinal images is an important part because it is the way to show the changes of vessels. However, most of the previous methods based on deep learning cared more about accuracy and ignored the complexity of the model for segmenting retinal vessels, which makes these methods difficult to apply to medical equipment. Besides, due to the great differences in the width of retinal vessels, some methods cannot well-extract all blood vessels at the same time. Based on above limitations, we propose a new lightweight network, called Res2Unet. It applies a multi-scale strategy to extract blood vessels of different widths and integrates the strategy into the channels to greatly reduce parameters and computation resources. Res2Unet also uses channel-attention mechanism to promote the communication between channels and recalibrate the relationship of channel features. Then, we propose two post-processing methods. One called the local threshold method(LTM) uses a lower local threshold to excavate hidden blood vessels in discontinuous blood vessels of the probability maps. The other named weighted correction method (WCM) combines the probability maps of Unet and Res2Unet to remove false positive and false negative samples. On the DRIVE dataset, the Dice, IOU and AUC of our Res2Unet reach 0.8186, 0.6926 and 0.9772, respectively, which are better than that of Unet with 0.8109, 0.6817 and 0.9751. Importantly, the number of parameters of Res2Unet are about one-third of Unet. It means that Res2Unet has less hardware requirements.},
  archive      = {J_NCA},
  author       = {Li, Xuejian and Ding, Jiaqi and Tang, Jijun and Guo, Fei},
  doi          = {10.1007/s00521-022-07086-8},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {12001-12015},
  shortjournal = {Neural Comput. Appl.},
  title        = {Res2Unet: A multi-scale channel attention network for retinal vessel segmentation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intuitionistic fuzzy inference system with weighted
comprehensive evaluation considering standard deviation-cosine entropy:
A fused forecasting model. <em>NCA</em>, <em>34</em>(14), 11977–11999.
(<a href="https://doi.org/10.1007/s00521-022-07082-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent development in intuitionistic fuzzy inference system (IFIS) has been emerged with promising results in defining uncertain information and improving its capacity to forecast real-world time series data. Nonetheless, many factors such as non-linearity data, stochastic dynamic problems and weights of attributes are explicitly affect the performance of IFIS. In this paper, we introduce a new method of determining weight of variable to perform an intuitionistic fuzzy comprehensive evaluation that to be fused with an IFIS. In order to weight the credibility of each causal variable in the experimental of particulate matter (PM10) data, a synthesized weight that is established from two different methods of weighting is developed. Two objective weightings known as the intuitionistic fuzzy-standard deviation and intuitionistic fuzzy-cosine entropy are combined as to consider statistical properties and trigonometric properties within the intuitionistic fuzzy set environment. This paper also investigates whether the two weighting methods have the same impact on the forecasting. The experimental results show that our proposed synthesized weighting method outperforms other three weight methods in PM10 forecasting under IFIS environment. The experimental results also verify that different methods of weighting have different influence on performance of the forecasting. This is the first identifiable synthesized weighted comprehensive evaluation that fused in IFIS and its application to PM10 forecasting. Finally, some consideration regarding the limitations of the study and potential research direction is presented.},
  archive      = {J_NCA},
  author       = {Mohd Pauzi, Herrini and Abdullah, Lazim},
  doi          = {10.1007/s00521-022-07082-y},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11977-11999},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intuitionistic fuzzy inference system with weighted comprehensive evaluation considering standard deviation-cosine entropy: A fused forecasting model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new stochastic multi-objective framework for the reactive
power market considering plug-in electric vehicles using a novel
metaheuristic approach. <em>NCA</em>, <em>34</em>(14), 11937–11975. (<a
href="https://doi.org/10.1007/s00521-022-07081-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a new stochastic multi-objective framework for reactive power market (QPM) employing the plug-in electric vehicles (PEVs) for the reactive power compensation process in a distribution grid. The PEVs as the local compensators should be used in the distribution grid due to obviate the challenges of the reactive power compensation by the generators such as the great incurred costs and losses. On the other hand, due to the multiplicity of the PEVs and their uncertainties, various objectives under different circumstances, the deterministic single-objective framework of the QPM cannot be considered as the valid model to accurately decide for the distribution system operator. Hence, it is indispensable to utilize the contingency-based Monte Carlo method to cover the uncertainty of the PEVs. The proposed multi-objective framework is capable of simultaneously optimizing contradict objective functions, consisting of the expected total payment function based on the reactive capability curve and the expected total network loss while fulfilling the constraints concerned with the grid, vehicle, and market price. This study holistically demonstrates that the proposed framework economically and technically outperforms the other previous frameworks. Furthermore, due to the nonlinearity and non-convexity, a novel hybrid algorithm consisting of gray wolf optimization and the differential evolution algorithm for settling the multi-objective QPM is presented and the best compromise solution is selected according to the fuzzy decision-making approach. This paper comprehensively illustrates that the introduced algorithm has the best performance compared with the other methods under different circumstances and cases.},
  archive      = {J_NCA},
  author       = {Jafari Siahroodi, Hossein and Mojallali, Hamed and Mohtavipour, Seyed Saeid},
  doi          = {10.1007/s00521-022-07081-z},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11937-11975},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new stochastic multi-objective framework for the reactive power market considering plug-in electric vehicles using a novel metaheuristic approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new hybrid algorithm based on golden eagle optimizer and
grey wolf optimizer for 3D path planning of multiple UAVs in power
inspection. <em>NCA</em>, <em>34</em>(14), 11911–11936. (<a
href="https://doi.org/10.1007/s00521-022-07080-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging power inspection method, unmanned aerial vehicle (UAV) inspection has the advantages of high safety, high efficiency, and low cost. In the process of power inspection, UAVs need to inspect multiple task points in a complex environment and plan an efficient and feasible path. In this research, the multiple UAVs inspection in the two cases of initial task points and newly added task points is considered. Aiming at these two cases, a hybrid algorithm is proposed in this paper. Firstly, the personal example learning strategy is applied to the golden eagle optimizer (GEO) to get a personal example learning GEO called PELGEO to improve the search ability of the GEO and reduce the possibility of GEO falling into a local optimum. Secondly, the grey wolf optimizer (GWO) is simplified and the differential mutation strategy is introduced to create the simplified GWO with differential mutation called DMSGWO. Finally, to give full play to the advantages of the PELGEO and the DMSGWO, an adaptive hybridization strategy is used to hybridize PELGEO and DMSGWO. The new hybrid algorithm based on GEO and GWO named HGEOGWO is proposed. The HGEOGWO and other algorithms are tested under the CEC2013 test suite. The experimental results show that the HGEOGWO has better optimization performance and stability than some popular algorithms. For the 3D path planning problem of multiple UAVs in power inspection, the proposed algorithm also has obvious advantages compared with some popular algorithms. The code of HGEOGWO can be publicly available at https://www.mathworks.com/matlabcentral/fileexchange/97807-a-new-hybrid-algorithm-based-on-geo-and-gwo .},
  archive      = {J_NCA},
  author       = {Lv, Ji-Xiang and Yan, Li-Jun and Chu, Shu-Chuan and Cai, Zhi-Ming and Pan, Jeng-Shyang and He, Xian-Kang and Xue, Jian-Kai},
  doi          = {10.1007/s00521-022-07080-0},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11911-11936},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new hybrid algorithm based on golden eagle optimizer and grey wolf optimizer for 3D path planning of multiple UAVs in power inspection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DSLN: Dual-tutor student learning network for multiracial
glaucoma detection. <em>NCA</em>, <em>34</em>(14), 11885–11910. (<a
href="https://doi.org/10.1007/s00521-022-07078-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate early glaucoma detection is crucial to prevent further vision loss. However, using the off-the-shelf models against fundus image datasets of different races may lead to degraded performance due to domain shift. To address the issue, this paper proposes a dual-tutor student learning network (DSLN) for multiracial glaucoma detection. The proposed DSLN consists of an inter-image tutor, an intra-image tutor, student model and backbone network, which combines the advantages of domain adaptation and semi-supervised learning. The inter-image tutor uses CycleGAN for style transfer to reduce the appearance differences between labeled source domain and labeled target domain images, and transfers the learned knowledge to the student model by minimizing knowledge distillation loss. The intra-image tutor adopts the exponential moving average to leverage the unlabeled target domain and transfers the knowledge to the student model by minimizing prediction consistency loss. Moreover, the student model not only directly learns knowledge from the labeled target domain images, but also learns the intra-image knowledge and inter-image knowledge transfer by two tutors. Furthermore, the backbone integrates the context features of the local optic disc region and global fundus image via modified ResNet50. We conduct extensive experiments on three scenarios constructed from nine public fundus image datasets of three races. Comprehensive experimental results show that the proposed DSLN framework outperforms the state-of-the-art models and has good robustness and generalization: it can effectively overcome domain shift and accurately detect glaucoma from multi-ethnic fundus images.},
  archive      = {J_NCA},
  author       = {Guo, Yanfei and Peng, Yanjun and Sun, Jindong and Li, Dapeng and Zhang, Bin},
  doi          = {10.1007/s00521-022-07078-8},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11885-11910},
  shortjournal = {Neural Comput. Appl.},
  title        = {DSLN: Dual-tutor student learning network for multiracial glaucoma detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient combination of quadruple biomarkers in binary
classification using ensemble machine learning technique for early onset
of alzheimer disease. <em>NCA</em>, <em>34</em>(14), 11865–11884. (<a
href="https://doi.org/10.1007/s00521-022-07076-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundAlzheimer’s disease (AD) is a degenerated condition of the brain where memory loss is fully depleted for elderly individual. Efficient machine learning methods are accessible, producing low classification accuracy since single modality features are being evaluated. In this paper, the multimodal approach is developed and execution of comprehensive validation for structural atrophy through Magnetic Resonance Imaging decreases metabolism through Fluorodeoxyglucose Positron Emission Tomography (FDG-PET), and accumulation of amyloid plaques through Pittsburgh compound B (PiB-PET), as well as cognitive assessment for identifying the early onset of AD. It has been stated that additional information from multiple image modalities would ameliorate the classification accuracy while diagnosing early AD. The novel classifier, Adaptive Hyperparameter Tuning Random Forest Ensemble Classifier (HPT-RFE), is proposed for three binary classifications. In this classifier, the tunning of hyperparameters is automated for computing the best features while constructing the optimum size of Random Forest. The advantage of using the classifier is computationally much faster when compared with Support Vector Machine, Naïve Bayes, K-Nearest Neighbour and Artificial Neural Network. Simulation results show that the performance of the Adaptive HPT-RFE classifier has been regarded as best among all binary classifications in the ADNI dataset. For AD versus Normal Control (NC) binary classification, 100\% accuracy, sensitivity, and specificity have been achieved, whereas the accuracy of 91\% and 100\% specificity for NC versus Mild Cognitive Impairment (MCI) classification and 95\% accuracy, 100\% specificity, 80\% sensitivity for AD versus MCI classification are compared with four state-of-the-art techniques.},
  archive      = {J_NCA},
  author       = {Kumari, Rashmi and Nigam, Akriti and Pushkar, Shashank},
  doi          = {10.1007/s00521-022-07076-w},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11865-11884},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient combination of quadruple biomarkers in binary classification using ensemble machine learning technique for early onset of alzheimer disease},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Annual dilated convolution neural network for newbuilding
ship prices forecasting. <em>NCA</em>, <em>34</em>(14), 11853–11863. (<a
href="https://doi.org/10.1007/s00521-022-07075-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anticipating newbuilding ship prices is crucial for participants in the dynamic shipping market. Although the researchers from forecasting and shipping have shown that the machine learning models outperform statistical ones, convolution neural networks are not investigated. The convolution neural networks are proposed for image processing, rendering difficulty when handling monthly time series. This paper presents a light neural network with annual dilated convolution filters while extracting the newbuilding market’s short-term and long-term temporal knowledge. The multivariate shipping data are fed into multiple convolutional filters with nonlinear activations. Finally, the convoluted features are fed into a linear layer which maps the features to future values. The annual dilated convolution filter owns a vision across one year and integrates all variables’ temporal information. Besides, the dilation rate renders a parsimonious structure, preventing the model from overfitting. The proposed model is compared with statistical models, Naïve forecasts, and various machine learning models on the newbuilding prices of three tanker markets. The empirical results highlight the superiority of the proposed convolutional neural networks.},
  archive      = {J_NCA},
  author       = {Gao, Ruobin and Liu, Jiahui and Bai, Xiwen and Yuen, Kum Fai},
  doi          = {10.1007/s00521-022-07075-x},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11853-11863},
  shortjournal = {Neural Comput. Appl.},
  title        = {Annual dilated convolution neural network for newbuilding ship prices forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mutually improved dense retriever and GNN-based reader for
arbitrary-hop open-domain question answering. <em>NCA</em>,
<em>34</em>(14), 11831–11851. (<a
href="https://doi.org/10.1007/s00521-022-07072-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open-domain question answering (OpenQA) requires not only a high-precision reader, but also high-quality retrieval of related passages. Particularly, real-world OpenQA usually involves multi-hop retrieval and reading to deal with complex questions that need bridging information. In this paper, we investigate the mutual promotion of dense retrievers and Graph Neural Network-based readers to improve OpenQA. Specifically, we introduce an alternate training strategy where the scores of the dense retriever and the GNN-based reader are used as correction weights to enhance the performance of each other. We leverage off-the-shelf strong dense retrievers such as Dense Passage Retriever (DPR) and Multi-hop Dense Retriever for retrieval. For the reader, we extend the Asynchronous Multi-grained Graph Network (AMGN) by defining passage nodes and passage-level relationships to cater to the retrieval. It is worth mentioning that through the Recurrent Neural Networks based question reformulation mechanism in AMGN and appropriate preprocessing, the proposed training strategy can be free from the constraints of fixed-hop question answering. We evaluate the proposed framework on several prevalent OpenQA datasets, Natural Questions, TriviaQA, and HotpotQA, achieving competitive results compared with other published models. Extensive experimental analyses illustrate the effectiveness of enhanced passage-aware AMGN and mutual promotion.},
  archive      = {J_NCA},
  author       = {Li, Ronghan and Wang, Lifang and Jiang, Zejun and Hu, Zhongtian and Zhao, Meng and Lu, Xinyu},
  doi          = {10.1007/s00521-022-07072-0},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11831-11851},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mutually improved dense retriever and GNN-based reader for arbitrary-hop open-domain question answering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Person re-identification with pose variation aware data
augmentation. <em>NCA</em>, <em>34</em>(14), 11817–11830. (<a
href="https://doi.org/10.1007/s00521-022-07071-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (Re-ID) aims to match a person of interest across multiple non-overlapping camera views. This is a challenging task, partly because a person captured in surveillance video often undergoes intense pose variations. Consequently, differences in their appearance are typically obvious. In this paper, we propose a pose variation aware data augmentation ( $$\hbox {PA}^4$$ ) method, which is composed of a pose transfer generative adversarial network (PTGAN) and person re-identification with improved hard example mining (Pre-HEM). Specifically, PTGAN introduces a similarity measurement module to synthesize realistic person images that are conditional on the pose, and with the original images, form an augmented training dataset. Pre-HEM presents a novel method of using the pose-transferred images with the learned pose transfer model for person Re-ID. It replaces the invalid samples that are caused by pose variations and constrains the proportion of the pose-transferred samples in each mini-batch. We conduct extensive comparative evaluations to demonstrate the advantages and superiority of our proposed method over state-of-the-art approaches on Market-1501, DukeMTMC-reID, and CUHK03 dataset.},
  archive      = {J_NCA},
  author       = {Zhang, Lei and Jiang, Na and Diao, Qishuai and Zhou, Zhong and Wu, Wei},
  doi          = {10.1007/s00521-022-07071-1},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11817-11830},
  shortjournal = {Neural Comput. Appl.},
  title        = {Person re-identification with pose variation aware data augmentation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Brain tumor segmentation using river formation dynamics and
active contour model in magnetic resonance images. <em>NCA</em>,
<em>34</em>(14), 11807–11816. (<a
href="https://doi.org/10.1007/s00521-022-07070-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human brain is quite complex in structure due to which it becomes quite challenging for a radiologist to differentiate tumor from normal tissues, blood clots, and edema. This paper presents a technique to segment the brain tumor from magnetic resonance images using the river formation dynamics (RFD) algorithm and active contour model. The brain tumor segmentation problem is modeled as a combinatorial optimization problem. It searches the tumor boundary using the active contour model which further uses RFD to search the optimized path in a region. RFD is heuristic optimization algorithm that mimics the way the water leads to the formation of rivers through erosion of ground and deposition of sediments. As a result, the best possible boundary with the minimum value of energy function is obtained. The technique has been evaluated quantitatively and qualitatively on the BrainWeb dataset. The results indicate the remarkable improvement over a few metaheuristic techniques, namely ant colony optimization algorithm, bacterial foraging optimization, particle swarm optimization algorithm, genetic algorithm, firefly algorithm, and cuckoo search optimization algorithm in terms of specificity, sensitivity, dice index, Hausdorff distance, Jaccard index, and accuracy. The presented approach gives continuous and smooth contours with an accuracy of 98.1\% and is computationally faster in comparison to other metaheuristic techniques.},
  archive      = {J_NCA},
  author       = {Pruthi, Jyotika and Arora, Shaveta and Khanna, Kavita},
  doi          = {10.1007/s00521-022-07070-2},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11807-11816},
  shortjournal = {Neural Comput. Appl.},
  title        = {Brain tumor segmentation using river formation dynamics and active contour model in magnetic resonance images},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TF-SOD: A novel transformer framework for salient object
detection. <em>NCA</em>, <em>34</em>(14), 11789–11806. (<a
href="https://doi.org/10.1007/s00521-022-07069-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of existing salient object detection models are based on fully convolutional network (FCN), which learn multi-scale/level semantic information through convolutional layers to obtain high-quality predicted saliency maps. However, convolution is locally interactive, it is difficult to capture remote dependencies, and FCN-based methods suffer from coarse object boundaries. In this paper, to solve these problems, we propose a novel transformer framework for salient object detection (named TF-SOD), which mainly consists of the encoder part of the FCN, fusion module (FM), transformer module (TM) and feature decoder module (FDM). Specifically, FM is a bridge connecting the encoder and TM and provides some foresight for the non-local interaction of TM. Besides, FDM can efficiently decode the non-local features output by TM and achieve deep fusion with local features. This architecture enables the network to achieve a close integration of local and non-local interactions, making information complementary to each other, deeply mining the associated information between features. Furthermore, we also propose a novel edge reinforcement learning strategy, which can effectively suppress edge blurring from local and global aspects by means of powerful network architecture. Extensive experiments using five datasets demonstrate that the proposed method outperforms 19 state-of-the-art methods},
  archive      = {J_NCA},
  author       = {Wang, Zhenyu and Zhang, Yunzhou and Liu, Yan and Wang, Zhuo and Coleman, Sonya and Kerr, Dermot},
  doi          = {10.1007/s00521-022-07069-9},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11789-11806},
  shortjournal = {Neural Comput. Appl.},
  title        = {TF-SOD: A novel transformer framework for salient object detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-adaptive differential evolution with gaussian–cauchy
mutation for large-scale CHP economic dispatch problem. <em>NCA</em>,
<em>34</em>(14), 11769–11787. (<a
href="https://doi.org/10.1007/s00521-022-07068-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread application of co-generation units, the combined heat and power economic dispatch (CHPED) has become an important issue in the power system operation. Existing research work mostly focuses on small- or medium-scale CHPED problem, and there is very little research work on large-scale CHPED problems. Considering the characteristics of high-dimensional variables and huge search space in large-scale CHPED problem, it brings great challenge to the existing algorithms. In this paper, an improved differential evolution algorithm, called self-adaptive differential evolution with Gaussian–Cauchy mutation (SDEGCM), is proposed to solve the large-scale CHPED problem. In SDEGCM, in order to improve the performance, two strategies namely Gaussian–Cauchy mutation and parameter self-adaptation are introduced. Moreover, a constraint repair technique is used in SDEGCM to deal with complex operating constraints. The SDEGCM is applied to solve three large-scale CHPED problems with 48, 84 and 96 units, and compared with three well-established differential evolution and other methods in the literature. It is found that the proposed SDEGCM has advantages in terms of solution accuracy and stability for the large-scale CHPED problem.},
  archive      = {J_NCA},
  author       = {Chen, Xu and Shen, Anning},
  doi          = {10.1007/s00521-022-07068-w},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11769-11787},
  shortjournal = {Neural Comput. Appl.},
  title        = {Self-adaptive differential evolution with Gaussian–Cauchy mutation for large-scale CHP economic dispatch problem},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Propension to customer churn in a financial institution: A
machine learning approach. <em>NCA</em>, <em>34</em>(14), 11751–11768.
(<a href="https://doi.org/10.1007/s00521-022-07067-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines churn prediction of customers in the banking sector using a unique customer-level dataset from a large Brazilian bank. Our main contribution is in exploring this rich dataset, which contains prior client behavior traits that enable us to document new insights into the main determinants predicting future client churn. We conduct a horserace of many supervised machine learning algorithms under the same cross-validation and evaluation setup, enabling a fair comparison across algorithms. We find that the random forests technique outperforms decision trees, k-nearest neighbors, elastic net, logistic regression, and support vector machines models in several metrics. Our investigation reveals that customers with a stronger relationship with the institution, who have more products and services, who borrow more from the bank, are less likely to close their checking accounts. Using a back-of-the-envelope estimation, we find that our model has the potential to forecast potential losses of up to 10\% of the operating result reported by the largest Brazilian banks in 2019, suggesting the model has a significant economic impact. Our results corroborate the importance of investing in cross-selling and upselling strategies focused on their current customers. These strategies can have positive side effects on customer retention.},
  archive      = {J_NCA},
  author       = {de Lima Lemos, Renato Alexandre and Silva, Thiago Christiano and Tabak, Benjamin Miranda},
  doi          = {10.1007/s00521-022-07067-x},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11751-11768},
  shortjournal = {Neural Comput. Appl.},
  title        = {Propension to customer churn in a financial institution: A machine learning approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An interpretable CNN model for classification of partial
discharge waveforms in 3D-printed dielectric samples with different void
sizes. <em>NCA</em>, <em>34</em>(14), 11739–11750. (<a
href="https://doi.org/10.1007/s00521-022-07066-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular maintenance of power equipment in high voltage power systems is essential for avoiding outages. An effective way to maintain such systems is the measurement of partial discharges in the insulation material. Voids in solid dielectrics may result from many causes including defects taking place during the manufacturing of the dielectric. These voids induce PDs. Classifying different void sizes is challenging since traditional classification tools used for partial discharge (PD) classification do not work properly. For instance, phase resolved partial discharge (PRPD) patterns resulting from different void sizes will be roughly the same since the source of the partial discharge is the same. Using existing clustering techniques such as Time–Frequency (T–F) map or analysis of statistical features extracted from the PRPD patterns presents their own limitations. T–F map restricts the use of Fast Fourier Transform, while working with PRPDs is only applicable for AC measurements. In this paper, a convolutional neural network (CNN) attention-based model has shown superior capability over traditional classification technique (T–F map) to classify partial discharge (PD) waveforms resulting from different voids in PLA 3D-printed samples. 1D-CNN has classification accuracy of 98.7\% with an increase of 21.42\% compared to the T–F map technique. Extensive investigation of the learned model has been conducted in order to interpret the decisions made by the proposed neural network. In particular, adding an interpretable attention model such as GRAD-CAM to our CNN shows that while making the decision the neural network learns to focus more on the regions of the waveform corresponding to the rise of the pulse.},
  archive      = {J_NCA},
  author       = {Mantach, Sara and Gill, Puneet and Oliver, Derek R. and Ashraf, Ahmed and Kordi, Behzad},
  doi          = {10.1007/s00521-022-07066-y},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11739-11750},
  shortjournal = {Neural Comput. Appl.},
  title        = {An interpretable CNN model for classification of partial discharge waveforms in 3D-printed dielectric samples with different void sizes},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Clustering uncertain graphs using ant colony optimization
(ACO). <em>NCA</em>, <em>34</em>(14), 11721–11738. (<a
href="https://doi.org/10.1007/s00521-022-07063-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In deterministic graphs, an edge between two vertices denotes a certain link. In contrast, in probabilistic graph, a link between two vertices merely implies the possibility of its existence based on probability. Probabilistic data results from uncertainties due to the preprocessing, data collection process, or the inherent nature of the problem which results in uncertain outcomes. These types of graphs are common in the real-world applications such as protein–protein interactions and identifying links in social media. Clustering probabilistic graphs is a challenging task since computing traditional metrics (like distance, paths, etc.) will all be probabilistic. Therefore, determining a valid clustering or making the data deterministic is an important research problem. We propose a new clustering algorithm for probabilistic graphs using the ant colony optimization (ACO) technique. The algorithm uses multiple versions of the probabilistic graph and employs a modified ACO to optimize the objective function. Moreover, heuristics are proposed to guide the algorithm for better accuracy and faster convergence. The proposed approach is tested against two real-world probabilistic graphs and five synthetic datasets using multiple cluster validity indices. Results show that ACO with heuristic guidance can produce good solutions that are comparable to or better than other traditional approaches.},
  archive      = {J_NCA},
  author       = {Hussain, Syed Fawad and Butt, Ifra Arif and Hanif, Muhammad and Anwar, Sajid},
  doi          = {10.1007/s00521-022-07063-1},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11721-11738},
  shortjournal = {Neural Comput. Appl.},
  title        = {Clustering uncertain graphs using ant colony optimization (ACO)},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reference modification for trajectory tracking using hybrid
offline and online neural networks learning. <em>NCA</em>,
<em>34</em>(14), 11707–11719. (<a
href="https://doi.org/10.1007/s00521-022-07062-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a hybrid offline/online neural networks learning method, which combines complementary advantages of two types of neural networks (NNs): deep NN (DNN) and single-layer radial basis function NN (RBFNN). Firstly, after analyzing the mechatronic system’s model, we select reasonable features as the input of the DNN to learn the inverse dynamic characteristics of the closed-loop system offline, so as to establish the mapping between the desired trajectory and the reference trajectory of the system. The trained DNN is used to generate a new reference trajectory and compensate for the tracking error in advance, which can speed up the convergence of online learning control based on RBFNN. This reference trajectory is further modified iteratively when the tracking task is repeated. For this purpose, a single-layer RBFNN model is established, and an online learning algorithm is developed to update the RBFNN parameters. The proposed hybrid offline/online NN method can improve the tracking performance of mechatronic systems by modifying the reference trajectory on top of the baseline controller without affecting the system stability. To verify the effectiveness of this method, we conduct experiments on a piezoelectric drive platform.},
  archive      = {J_NCA},
  author       = {Li, Jiangang and Huang, Youhua and Zhong, Ganggang and Li, Yanan},
  doi          = {10.1007/s00521-022-07062-2},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11707-11719},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reference modification for trajectory tracking using hybrid offline and online neural networks learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AI-based user authentication reinforcement by continuous
extraction of behavioral interaction features. <em>NCA</em>,
<em>34</em>(14), 11691–11705. (<a
href="https://doi.org/10.1007/s00521-022-07061-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we conduct an experiment to analyze the feasibility of a continuous authentication method based on the monitorization of the users’ activity to verify their identities through specific user profiles modeled via Artificial Intelligence techniques. In order to conduct the experiment, a custom application was developed to gather user records in a guided scenario where some predefined actions must be completed. This dataset has been anonymized and will be available to the community. Additionally, a public dataset was also used for benchmarking purposes so that our techniques could be validated in a non-guided scenario. Such data were processed to extract a number of key features that could be used to train three different Artificial Intelligence techniques: Support Vector Machines, Multi-Layer Perceptrons, and a Deep Learning approach. These techniques demonstrated to perform well in both scenarios, being able to authenticate users in an effective manner. Finally, a rejection test was conducted, and a continuous authentication system was proposed and tested using weighted sliding windows, so that an impostor could be detected in a real environment when a legitimate user session is hijacked.},
  archive      = {J_NCA},
  author       = {Garabato, Daniel and Dafonte, Carlos and Santoveña, Raúl and Silvelo, Arturo and Nóvoa, Francisco J. and Manteiga, Minia},
  doi          = {10.1007/s00521-022-07061-3},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11691-11705},
  shortjournal = {Neural Comput. Appl.},
  title        = {AI-based user authentication reinforcement by continuous extraction of behavioral interaction features},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep GraphSAGE-based recommendation system: Jumping
knowledge connections with ordinal aggregation network. <em>NCA</em>,
<em>34</em>(14), 11679–11690. (<a
href="https://doi.org/10.1007/s00521-022-07059-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems have become based on graph neural networks (GNN) as many fields, and this is due to the advantages that represent this kind of neural networks compared to the classical ones; notably, the representation of concrete realities by taking the relationships between data into consideration and understanding them in a better way. In this paper, we have proposed an item-based recommender system using a deep GraphSAGE model, which learns item embeddings from the user–item matrix and uses them for recommending items that are similar to the ones that users have interacted with before. Furthermore, we have discussed the common problems that usually arise when using deep GNN-based architectures, and which can negatively affect the performance of our recommender system, in particular, the over-smoothing problem. To this end, we have integrated the Jumping Knowledge connections (JK) strategy in our system, using a new method called Ordinal Aggregation Network (OAN) as a layer aggregator to tackle this kind of problem. To evaluate the recommendations, we have used the required metrics that are designated for this purpose: Hits@n and NDCG@n, and we have also measured the duration of training of every model. The experimental results that we have made show that our method has improved the performance of a recommender system concretely and efficiently compared to other aggregation methods. In addition, they have suggested that deep GraphSAGE with Jumping Knowledge connections (JK) would be empirically promising.},
  archive      = {J_NCA},
  author       = {El Alaoui, Driss and Riffi, Jamal and Sabri, Abdelouahed and Aghoutane, Badraddine and Yahyaouy, Ali and Tairi, Hamid},
  doi          = {10.1007/s00521-022-07059-x},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11679-11690},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep GraphSAGE-based recommendation system: Jumping knowledge connections with ordinal aggregation network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ZoKa: A fake news detection method using edge-weighted graph
attention network with transfer models. <em>NCA</em>, <em>34</em>(14),
11669–11677. (<a
href="https://doi.org/10.1007/s00521-022-07057-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in social networks enable users to communicate and share their ideas. While social networks are beneficial to our society, it can lead to exponential disinformation growth. The extensive spread of such unreliable information and fake news can lead an adverse impact on the public opinion and cause uncertain outcomes of public events. Despite the recent progress in identifying fake news, it is still a time-consuming, complex, and diverse task. To address these challenges, we first generate a user friendship and retweet propagation graph to filter the potential fake users by leveraging Graph Attention Network. The underlying user graph is built by the functional connectivity matrices and the node features including both the user–user connections regarding their activities on the Twitter social network. Also, we generate a content graph including comments, profile descriptions of potential fake users along with their shared news contents. Then, we employ a novel fake news detection method on the generated content graph based on the Edge-weighted Graph Attention Network) using pre-trained encoders. The results from the experiments conducted on two real-world datasets show that our method achieves remarkable results when compared to the existing approaches in terms of Accuracy and F1 scores.},
  archive      = {J_NCA},
  author       = {Inan, Emrah},
  doi          = {10.1007/s00521-022-07057-z},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11669-11677},
  shortjournal = {Neural Comput. Appl.},
  title        = {ZoKa: A fake news detection method using edge-weighted graph attention network with transfer models},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-agent learning algorithms for content placement in
cache-enabled small cell networks: 4G and 5G use cases. <em>NCA</em>,
<em>34</em>(14), 11641–11668. (<a
href="https://doi.org/10.1007/s00521-022-07051-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Caching popular files at the small base stations (SBSs) has proved to be an effective strategy to reduce the content delivery delay in cellular networks and to alleviate the backhaul congestion. In the optimization of the placement of contents into SBS caches (the so-called content placement problem), several key parameters play an important role, such as content popularity, the mobile users’ (MUs’) channel state information (CSI), as well as the capacity of the backhaul links. These parameters are random in general, and their instantaneous values over time give rise to a stochastic process. In this paper, we propose a mathematical formulation for the distributed optimization of content placement with the objective of minimizing the average content delivery latency. Our formulation is applicable to both conventional 4G small cell networks (SCNs) as well as 5G-compatiable mmWave integrated access and backhaul (IAB) cellular communications. In particular, the placement problem is modeled as a potential game among SBSs in which the objective of each SBS is to minimize the average delay of the MUs within its coverage range. In order to compute the Nash equilibrium (NE) of the game, we adopt the learning-theoretic approach that only relies on incomplete information (or implicit feedback) of the system’s underlying stochastic processes; i.e., the content placement is optimized in run-time by gaining experience and through the immediate noisy feedbacks of the actions actually taken in the operating environment. We propose an algorithm based on multi-agent reinforcement learning (MARL) techniques for potential games. It operates in the independent action space and can learn the optimal strategy profile of the SBSs in larger-scale scenarios, even when the actions of its peers are not observable by each SBS. Simulation experiments are conducted to investigate the convergence of the learning algorithm as well as to compare against some schemes using prior knowledge.},
  archive      = {J_NCA},
  author       = {Rashidi, Zahra and Hakami, Vesal and Geranmayeh, Parmida and Rajaee, Sara},
  doi          = {10.1007/s00521-022-07051-5},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11641-11668},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-agent learning algorithms for content placement in cache-enabled small cell networks: 4G and 5G use cases},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel deep ordinal classification approach for aesthetic
quality control classification. <em>NCA</em>, <em>34</em>(14),
11625–11639. (<a
href="https://doi.org/10.1007/s00521-022-07050-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, decision support systems (DSSs) are widely used in several application domains, from industrial to healthcare and medicine fields. Concerning the industrial scenario, we propose a DSS oriented to the aesthetic quality control (AQC) task, which has quickly established itself as one of the most crucial challenges of Industry 4.0. Taking into account the increasing amount of data in this domain, the application of machine learning (ML) and deep learning (DL) techniques offers great opportunities to automatize the overall AQC process. State-of-the-art is mainly oriented to approach this problem with a nominal DL classification method which does not exploit the ordinal structure of the AQC task, thus not penalizing the error among distant AQC classes (which is a relevant aspect for the real use case). The paper introduces a DL ordinal methodology for the AQC classification. Differently from other deep ordinal methods, we combined the standard categorical cross-entropy with the cumulative link model and we imposed the ordinal constraint via the thresholds and slope parameters. Experimental results were performed for solving an AQC task on a novel image dataset originated from a specific company’s demand (i.e., aesthetic assessment of wooden stocks). We demonstrated how the proposed methodology is able to reduce misclassification errors (up to 0.937 quadratic weight kappa loss) among distant classes while overcoming other state-of-the-art deep ordinal models and reducing the bias factor related to the item geometry. The proposed DL approach was integrated as the main core of a DSS supported by Internet of Things (IoT) architecture that can support the human operator by reducing up to 90\% the time needed for the qualitative analysis carried out manually in this specific domain.},
  archive      = {J_NCA},
  author       = {Rosati, Riccardo and Romeo, Luca and Vargas, Víctor Manuel and Gutiérrez, Pedro Antonio and Hervás-Martínez, César and Frontoni, Emanuele},
  doi          = {10.1007/s00521-022-07050-6},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11625-11639},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel deep ordinal classification approach for aesthetic quality control classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Zero root-mean-square error for single- and double-diode
photovoltaic models parameter determination. <em>NCA</em>,
<em>34</em>(14), 11603–11624. (<a
href="https://doi.org/10.1007/s00521-022-07047-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The parameter determination based on experimental data aids in providing an accurate assessment for predicting the output current of the PV cells. This may be extremely helpful both practically and theoretically in the PV system simulation, optimization, and evaluation. Numerous stochastic methods have been widely utilized in recent decades to tackle the parameter extraction optimization problem. Hybrid methods that take advantage of two or more algorithms have been proposed by many to further enhance their accuracy, stability, and overall performance. However, the majority of the methods in the literature concentrate on the methodology, with few studies considering the formulation of the objective function, resulting in a theoretical gap in this area of study. In this work, a new improved arithmetic optimization method based on the adaption of Newton–Raphson and Levenberg–Marquardt damping parameter (IAOANRaLMp) is presented to globally extract the parameter of the single- and double-diode PV models. The experimental findings demonstrate that the proposed IAOANRaLMp approach performs exceptionally well in terms of minimizing error to zero for both models, as indicated by various statistical criteria and comparison with experimental data.},
  archive      = {J_NCA},
  author       = {Ridha, Hussein Mohammed and Hizam, Hashim and Mirjalili, Seyedali and Othman, Mohammad Lutfi and Ya’acob, Mohammad Effendy},
  doi          = {10.1007/s00521-022-07047-1},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11603-11624},
  shortjournal = {Neural Comput. Appl.},
  title        = {Zero root-mean-square error for single- and double-diode photovoltaic models parameter determination},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneous face quality assessment. <em>NCA</em>,
<em>34</em>(14), 11589–11602. (<a
href="https://doi.org/10.1007/s00521-022-07045-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Face Recognition (FR) research has attained a mature stage in the last decade. However, evaluating face quality before recognition can enhance the performance of these algorithms. We proposed a new Face Quality Assessment (FQA) algorithm for face images of multiple modalities and examined its effects on Heterogeneous Face Recognition in this paper (HFR). The proposed work comprises two segments. In the first part of the work, an image descriptor is proposed. The descriptor captures the quality-sensitive features. It is named Local Quality Descriptor (LQD). The paper then proposed a model for measuring the quality from the LQD feature using a subspace projection. The Face Quality Score (FQS) obtained is scaled between 0 and 100. The effects of the gallery and probe image quality on the recognition algorithm’s performance are also discussed in the paper. The proposed model was trained with the data with quality variations. These variations are generated with factors like blurring, Gaussian white noise, low illumination, etc. The Face Quality Confidence Score is computed by considering the quality of the probe and gallery images (FQCS). The impacts of FQS and FQCS on face recognition and face verification are studied with publicly available databases, namely: CASIA, FERET, LDHF, and QDF.},
  archive      = {J_NCA},
  author       = {Bhattacharya, Shubhobrata and Routray, Aurobinda},
  doi          = {10.1007/s00521-022-07045-3},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11589-11602},
  shortjournal = {Neural Comput. Appl.},
  title        = {Heterogeneous face quality assessment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Polynomial dendritic neural networks. <em>NCA</em>,
<em>34</em>(14), 11571–11588. (<a
href="https://doi.org/10.1007/s00521-022-07044-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although many artificial neural networks have achieved success in practical applications, there is still a concern among many over their “black box” nature. Why and how do they work? Recently, some interesting interpretations have been made through polynomial regression as an alternative to neural networks. Polynomial networks have thus received more and more attention as generators of polynomial regression. Furthermore, some special polynomial works, such as dendrite net (DD) and Kileel et al.’s deep polynomial neural networks, showed that some single neurons have powerful computability. This agrees with a recent discovery on biological neurons, that is, a single biological neuron can perform XOR operations. Inspired by such works, we propose a new model called the polynomial dendritic neural network (PDN) in this article. The PDN achieves powerful computability on a single neuron in a neural network. The output of a PDN is a high degree polynomial of the inputs. To obtain its parameter values, we took PDN as a neural network and employed the back-propagation method. As shown in this context, PDN contains more polynomial outputs than DD and deep polynomial neural networks. We deliberately studied two special PDNs called the exponential PDN (EPDN) and asymptotic PDN (APDN). For interpretability, we proposed a feature analysis method based on the coefficients of the polynomial outputs of such PDNs. The EPDN and APDN showed satisfactory accuracy, precision, recall, F1 score, and AUC in several experiments. Furthermore, we found the coefficient-based interpretability to be effective on some actual health cases.},
  archive      = {J_NCA},
  author       = {Chen, Yuwen and Liu, Jiang},
  doi          = {10.1007/s00521-022-07044-4},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11571-11588},
  shortjournal = {Neural Comput. Appl.},
  title        = {Polynomial dendritic neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancement and segmentation of medical images through
pythagorean fuzzy sets-an innovative approach. <em>NCA</em>,
<em>34</em>(14), 11553–11569. (<a
href="https://doi.org/10.1007/s00521-022-07043-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation has attracted a lot of attention due to its potential biomedical applications. Based on these, in the current research, an attempt has been made to explore object enhancement and segmentation for CT images of lungs infected with COVID-19. By implementing Pythagorean fuzzy entropy, the considered images were enhanced. Further, by constructing Pythagorean fuzzy measures and utilizing the thresholding technique, the required values of thresholds for the segmentation of the proposed scheme are assessed. The object extraction ability of the five segmentation algorithms including current sophisticated, and proposed schemes are evaluated by applying the quality measurement factors. Ultimately, the proposed scheme has the best effect on object separation as well as the quality measurement values.},
  archive      = {J_NCA},
  author       = {Premalatha, R. and Dhanalakshmi, P.},
  doi          = {10.1007/s00521-022-07043-5},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11553-11569},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancement and segmentation of medical images through pythagorean fuzzy sets-an innovative approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Navier–stokes generative adversarial network: A
physics-informed deep learning model for fluid flow generation.
<em>NCA</em>, <em>34</em>(14), 11539–11552. (<a
href="https://doi.org/10.1007/s00521-022-07042-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical simulation in Computational Fluid Dynamics mainly relies on discretizing the governing equations in time or space to obtain numerical solutions, which is expensive and time-consuming. Deep learning significantly reduces the computational cost due to its great nonlinear curve fitting capability, however, the data-driven models is agnostic to latent relationships between input and output. In this paper, a novel deep learning named Navier–Stokes Generative Adversarial Network integrated with physical information is proposed. The Navier–Stokes Equation is added to the loss function of the generator in the form of residuals, which means physics loss in this paper. Then, the proposed model is trained in the framework of generative adversarial network. Experimental results show that proposed model significantly outperform similar models, mean absolute error are decreased by 62.29, 78.42 and 78.61\% on pressure and velocity components. What’s more, effectiveness of introducing physics loss is also verified.},
  archive      = {J_NCA},
  author       = {Wu, Pin and Pan, Kaikai and Ji, Lulu and Gong, Siquan and Feng, Weibing and Yuan, Wenyan and Pain, Christopher},
  doi          = {10.1007/s00521-022-07042-6},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11539-11552},
  shortjournal = {Neural Comput. Appl.},
  title        = {Navier–stokes generative adversarial network: A physics-informed deep learning model for fluid flow generation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel grey bass extended model considering price factors
for the demand forecasting of european new energy vehicles.
<em>NCA</em>, <em>34</em>(14), 11521–11537. (<a
href="https://doi.org/10.1007/s00521-022-07041-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vigorous development of new energy vehicles (NEVs) has become an effective approach for achieving carbon emission reduction and carbon neutrality goals. The prediction of the demand for NEVs can provide quantitative decision-making basis for governments and enterprises. In consideration of the condition under which the demand for NEVs is affected by subsidy policy and limited samples, a novel demand forecasting model for NEVs is constructed based on the improved Bass model and grey theory in this study. First, the price function is introduced into the improved Bass model to establish a differential equation of demand for NEVs. Considering the limited samples, the differential equation model is transformed into a grey Bass extended model (GBEM). Second, the parameters of GBEM are estimated using the least squares method, the time response sequence is obtained through the Gaussian hypergeometric function, and the background value is optimized using the particle swarm optimization algorithm. Third, three data sets from Norway, France, and Europe are studied to confirm the validity. The calculation results show that the proposed model achieves higher accuracy than six existing models, and the MAPE of the model are all below 10\% in three cases. Lastly, GBEM is applied to predict the demand for NEVs in the three aforementioned regions from 2020 to 2023. The results show that the demand for NEVs in Norway, France, and Europe in 2023 are 343,860, 280,685 and 2,157,908, with an average annual growth rate of 46.3133\%, 47.1837\% and 40.0457\%, respectively, which provide a certain reference value for the formulation of national government policies and the production activities of NEV enterprises.},
  archive      = {J_NCA},
  author       = {Li, Xue and Xiao, Xinping and Guo, Huan},
  doi          = {10.1007/s00521-022-07041-7},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11521-11537},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel grey bass extended model considering price factors for the demand forecasting of european new energy vehicles},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on covert communication channel based on modulation
of common compressed speech codec. <em>NCA</em>, <em>34</em>(14),
11507–11520. (<a
href="https://doi.org/10.1007/s00521-020-04882-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As is well known, multimedia has been widely used in VoIP and mobile communications. Research on how to establish covert communication channel over the above popular public applications has been flourishing in recent years. This paper tries to present a novel and effective method to construct a covert channel over common compressed speech stream by embedding sense information into it. In our method, after analysing the characteristic features of the excitation pulse positions of the ITU-T G.723.1 and G.729A speech codec, we design a novel and effective covert communication channel by finely modulating the codes of excitation pulse positions of the above two codecs in line with the secret information to be hidden. To improve the embedding capacity of the proposed method, we also use all the odd/even characteristics of pulse code positions to conduct information hiding. To test and verify the proposed approach, experiments are conducted on several different scenarios. Experimental results show that our methods and algorithms perform a higher degree of secrecy and sound information embedding efficacy compared with exiting similar methods.},
  archive      = {J_NCA},
  author       = {Li, Fufang and Li, Binbin and Huang, Yongfeng and Feng, Yuanyong and Peng, Lingxi and Zhou, Naqin},
  doi          = {10.1007/s00521-020-04882-y},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11507-11520},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on covert communication channel based on modulation of common compressed speech codec},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MNSSp3: Medical big data privacy protection platform based
on internet of things. <em>NCA</em>, <em>34</em>(14), 11491–11505. (<a
href="https://doi.org/10.1007/s00521-020-04873-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to transform the growing medical big data into medical knowledge is a global topic. However, medical data contains a large amount of personal privacy information, especially electronic medical records, gene data and electroencephalography data; the current methods and tools for data sharing are not efficient or cannot be applied in real-life applications. Privacy disclosure has become the bottleneck of medical big data sharing. In this context, we conducted research of medical data from the data collection, data transport and data sharing to solve the key problems of privacy protection and put forward a privacy protection sharing platform called MNSSp3 (medical big data privacy protection platform based on Internet of things), which attempts to provide an effective medical data sharing solution with the privacy protection algorithms for different data types and support for data analytics. The platform focuses on the transmission and sharing security of medical big data to provide users with mining methods and realizes the separation of data and users to ensure the security of medical data. Moreover, the platform also provides users with the capacity to upload privacy algorithms independently. We discussed the requirements and the design components of the platform, then three case studies were presented to verify the functionality of the platform, and the results of the experiments show clearly the benefit and practicality of the proposed platform.},
  archive      = {J_NCA},
  author       = {Wu, Xiang and Zhang, Yongting and Wang, Aming and Shi, Minyu and Wang, Huanhuan and Liu, Lian},
  doi          = {10.1007/s00521-020-04873-z},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11491-11505},
  shortjournal = {Neural Comput. Appl.},
  title        = {MNSSp3: Medical big data privacy protection platform based on internet of things},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Blockchain for healthcare data management: Opportunities,
challenges, and future recommendations. <em>NCA</em>, <em>34</em>(14),
11475–11490. (<a
href="https://doi.org/10.1007/s00521-020-05519-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today&#39;s healthcare data management systems are facing key challenges in terms of data transparency, traceability, immutability, audit, data provenance, flexible access, trust, privacy, and security. Also, a large portion of existing healthcare systems leveraged for managing data are centralized that pose potential risks of single point of failures in case of natural disasters. Blockchain is an emerging and disruptive decentralized technology that has the potential to significantly revolutionize, reshape, and transform the way data are being handled in healthcare industries. In this paper, we discuss how leveraging blockchain for healthcare data management systems can lead to stimulate innovations and bring major improvements. We present the key blockchain features and characteristics. We discuss the premier advantages of adopting blockchain technology along with opportunities for healthcare industries. We present recent on-going projects and case studies to show the practicality of blockchain technology for various healthcare applications. We identify and discuss important open research challenges hindering the successful adoption of blockchain in the healthcare sector. Finally, we outline several future research directions.},
  archive      = {J_NCA},
  author       = {Yaqoob, Ibrar and Salah, Khaled and Jayaraman, Raja and Al-Hammadi, Yousof},
  doi          = {10.1007/s00521-020-05519-w},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11475-11490},
  shortjournal = {Neural Comput. Appl.},
  title        = {Blockchain for healthcare data management: Opportunities, challenges, and future recommendations},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel binary chaotic genetic algorithm for feature
selection and its utility in affective computing and healthcare.
<em>NCA</em>, <em>34</em>(14), 11453–11474. (<a
href="https://doi.org/10.1007/s00521-020-05347-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic algorithm (GA) is a nature-inspired algorithm to produce best possible solution by selecting the fittest individual from a pool of possible solutions. Like most of the optimization techniques, the GA can also stuck in the local optima, producing a suboptimal solution. This work presents a novel metaheuristic optimizer named as the binary chaotic genetic algorithm (BCGA) to improve the GA performance. The chaotic maps are applied to the initial population, and the reproduction operations follow. To demonstrate its utility, the proposed BCGA is applied to a feature selection task from an affective database, namely AMIGOS (A Dataset for Affect, Personality and Mood Research on Individuals and Groups) and two healthcare datasets having large feature space. Performance of the BCGA is compared with the traditional GA and two state-of-the-art feature selection methods. The comparison is made based on classification accuracy and the number of selected features. Experimental results suggest promising capability of BCGA to find the optimal subset of features that achieves better fitness values. The obtained results also suggest that the chaotic maps, especially sinusoidal chaotic map, perform better as compared to other maps in enhancing the performance of raw GA. The proposed approach obtains, on average, a fitness value twice as better than the one achieved through the raw GA in the identification of the seven classes of emotions.},
  archive      = {J_NCA},
  author       = {Tahir, Madiha and Tubaishat, Abdallah and Al-Obeidat, Feras and Shah, Babar and Halim, Zahid and Waqas, Muhammad},
  doi          = {10.1007/s00521-020-05347-y},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11453-11474},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel binary chaotic genetic algorithm for feature selection and its utility in affective computing and healthcare},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CircNet: An encoder–decoder-based convolution neural network
(CNN) for circular RNA identification. <em>NCA</em>, <em>34</em>(14),
11441–11452. (<a
href="https://doi.org/10.1007/s00521-020-05673-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrimination of circular RNA from long non-coding RNA is important to understand its role in different biological processes, disease prediction and cure. Identifying circular RNA through manual laboratories work is expensive, time-consuming and prone to errors. Development of computational methodologies for identification of circular RNA is an active area of research. State-of-the-art circular RNA identification methodologies make use of handcrafted features, which not only increase the feature space, but also extract irrelevant and redundant features. The paper in hand proposes an end-to-end deep learning-based framework named as CircNet, which does not require any handcrafted features. It takes raw RNA sequence as an input and utilises encoder–decoder based convolutional operations to learn lower-dimensional latent representation. This latent representation is further passed to another convolutional architecture to extract discriminative features followed by a classification layer. We performed extensive experimentation to highlight different regions of genome sequence that preserve the most important information for identifying circular RNAs. CircNet significantly outperforms state-of-the-art approaches with a considerable margin 10.29\% in terms F1 measure.},
  archive      = {J_NCA},
  author       = {Stricker, Marco and Asim, Muhammad Nabeel and Dengel, Andreas and Ahmed, Sheraz},
  doi          = {10.1007/s00521-020-05673-1},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11441-11452},
  shortjournal = {Neural Comput. Appl.},
  title        = {CircNet: An encoder–decoder-based convolution neural network (CNN) for circular RNA identification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient deep learning approach for augmented detection of
coronavirus disease. <em>NCA</em>, <em>34</em>(14), 11423–11440. (<a
href="https://doi.org/10.1007/s00521-020-05410-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The new Coronavirus disease 2019 (COVID-19) is rapidly affecting the world population with statistics quickly falling out of date. Due to the limited availability of annotated Coronavirus X-ray and CT images, the detection of COVID-19 remains the biggest challenge in diagnosing this disease. This paper provides a promising solution by proposing a COVID-19 detection system based on deep learning. The proposed deep learning modalities are based on convolutional neural network (CNN) and convolutional long short-term memory (ConvLSTM). Two different datasets are adopted for the simulation of the proposed modalities. The first dataset includes a set of CT images, while the second dataset includes a set of X-ray images. Both of these datasets consist of two categories: COVID-19 and normal. In addition, COVID-19 and pneumonia image categories are classified in order to validate the proposed modalities. The proposed deep learning modalities are tested on both X-ray and CT images as well as a combined dataset that includes both types of images. They achieved an accuracy of 100\% and an F1 score of 100\% in some cases. The simulation results reveal that the proposed deep learning modalities can be considered and adopted for quick COVID-19 screening.},
  archive      = {J_NCA},
  author       = {Sedik, Ahmed and Hammad, Mohamed and Abd El-Samie, Fathi E. and Gupta, Brij B. and Abd El-Latif, Ahmed A.},
  doi          = {10.1007/s00521-020-05410-8},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11423-11440},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient deep learning approach for augmented detection of coronavirus disease},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fuzzy universum least squares twin support vector machine
(FULSTSVM). <em>NCA</em>, <em>34</em>(14), 11411–11422. (<a
href="https://doi.org/10.1007/s00521-021-05721-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Universum based twin support vector machines give prior information about the distribution of data to the classifier. This leads to better generalization performance of the model, due to the universum. However, in many applications the data points are not equally useful for the classification task. This leads to the use of fuzzy membership functions for the datasets. Similarly, in universum based algorithms, all the universum data points are not equally important for the classifier. To solve these problems, a novel fuzzy universum least squares twin support vector machine (FULSTSVM) is proposed in this work. In FULSTSVM, the membership values are used to provide weights for the data samples of the classes, as well as to the universum data. Further, the optimization problem of proposed FULSTSVM is obtained by solving a system of linear equations. This leads to an efficient fuzzy based algorithm. Numerical experiments are performed on various benchmark datasets, with discussions on generalization performance, and computational cost of the algorithms. The proposed FULSTSVM outperformed the existing algorithms on most datasets. A comparison is presented for the performance of the proposed and other baseline algorithms using statistical significance tests. To show the applicability of FULSTSVM, applications are also presented, such as detection of Alzheimer’s disease, and breast cancer.},
  archive      = {J_NCA},
  author       = {Richhariya, B. and Tanveer, M.},
  doi          = {10.1007/s00521-021-05721-4},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11411-11422},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fuzzy universum least squares twin support vector machine (FULSTSVM)},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Beyond traditional approaches: A partial directed coherence
with graph theory-based mental load assessment using EEG modality.
<em>NCA</em>, <em>34</em>(14), 11395–11410. (<a
href="https://doi.org/10.1007/s00521-020-05408-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain connectivity-based methods are efficient and reliable for assessing the mental workload during high task demands as the human brain is functionally interconnected during any psychological task. On the other hand, the graph theory approach is a mathematical study that draws the pairwise relationships between objects. This paper covers the deployment of graph theory concepts on the brain connectivity methods to find the complex underlying behaviors of the brain in the simplest way. Furthermore, in this work, mental workload assessments on multimedia animations were performed using a brain connectivity approach based on partial directed coherence (PDC) with graph theory analysis. Electroencephalography (EEG) data were collected from 34 adult participants at baseline and during multimedia learning tasks. The results revealed that the EEG-based connectivity approach with graph theory offers more promising results than the traditional feature extraction techniques. The connectivity approach achieved an accuracy of 85.77\% in comparison with the 78.50\% accuracy achieved by the existing feature extraction techniques. It is concluded that the proposed PDC method with graph theory network analysis is a better solution for cognitive load assessment during any cognitive task.},
  archive      = {J_NCA},
  author       = {Mazher, Moona and Qayyum, Abdul and Ahmad, Iftikhar and Alassafi, Madini O.},
  doi          = {10.1007/s00521-020-05408-2},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11395-11410},
  shortjournal = {Neural Comput. Appl.},
  title        = {Beyond traditional approaches: A partial directed coherence with graph theory-based mental load assessment using EEG modality},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convolutional neural network-based models for diagnosis of
breast cancer. <em>NCA</em>, <em>34</em>(14), 11383–11394. (<a
href="https://doi.org/10.1007/s00521-020-05394-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is the most prevailing cancer in the world and each year affecting millions of women. It is also the cause of largest number of deaths in women dying in cancers. During the last few years, researchers are proposing different convolutional neural network models in order to facilitate diagnostic process of breast cancer. Convolutional neural networks are showing promising results to classify cancers using image datasets. There is still a lack of standard models which can claim the best model because of unavailability of large datasets that can be used for models’ training and validation. Hence, researchers are now focusing on leveraging the transfer learning approach using pre-trained models as feature extractors that are trained over millions of different images. With this motivation, this paper considers eight different fine-tuned pre-trained models to observe how these models classify breast cancers applying on ultrasound images. We also propose a shallow custom convolutional neural network that outperforms the pre-trained models with respect to different performance metrics. The proposed model shows 100\% accuracy and achieves 1.0 AUC score, whereas the best pre-trained model shows 92\% accuracy and 0.972 AUC score. In order to avoid biasness, the model is trained using the fivefold cross validation technique. Moreover, the model is faster in training than the pre-trained models and requires a small number of trainable parameters. The Grad-CAM heat map visualization technique also shows how perfectly the proposed model extracts important features to classify breast cancers.},
  archive      = {J_NCA},
  author       = {Masud, Mehedi and Eldin Rashed, Amr E. and Hossain, M. Shamim},
  doi          = {10.1007/s00521-020-05394-5},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11383-11394},
  shortjournal = {Neural Comput. Appl.},
  title        = {Convolutional neural network-based models for diagnosis of breast cancer},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fuzzy rule-based efficient hospital bed management
approach for coronavirus disease-19 infected patients. <em>NCA</em>,
<em>34</em>(14), 11361–11382. (<a
href="https://doi.org/10.1007/s00521-021-05719-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus disease-19 (COVID-19) is a very dangerous infectious disease for the entire world in the current scenario. Coronavirus spreads from one person to another person very rapidly. It spreads exponentially throughout the globe. Everyone should be cautious to avoid the spreading of this novel disease. In this paper, a fuzzy rule-based approach using priority-based method is proposed for the management of hospital beds for COVID-19 infected patients in the worst-case scenario where the number of hospital beds is very less as compared to the number of COVID-19 infected patients. This approach mainly attempts to minimize the number of hospital beds as well as emergency beds requirement for the treatment of COVID-19 infected patients to handle such a critical situation. In this work, higher priority has given to severe COVID-19 infected patients as compared to mild COVID-19 infected patients to handle this critical situation so that the survival probability of the COVID-19 infected patients can be increased. The proposed method is compared with first-come first-serve (FCFS)-based method to analyze the practical problems that arise during the assignment of hospital beds and emergency beds for the treatment of COVID-19 patients. The simulation of this work is carried out using MATLAB R2015b.},
  archive      = {J_NCA},
  author       = {Jena, Kalyan Kumar and Bhoi, Sourav Kumar and Prasad, Mukesh and Puthal, Deepak},
  doi          = {10.1007/s00521-021-05719-y},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11361-11382},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fuzzy rule-based efficient hospital bed management approach for coronavirus disease-19 infected patients},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel explainable machine learning approach for EEG-based
brain-computer interface systems. <em>NCA</em>, <em>34</em>(14),
11347–11360. (<a
href="https://doi.org/10.1007/s00521-020-05624-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalographic (EEG) recordings can be of great help in decoding the open/close hand’s motion preparation. To this end, cortical EEG source signals in the motor cortex (evaluated in the 1-s window preceding movement onset) are extracted by solving inverse problem through beamforming. EEG sources epochs are used as source-time maps input to a custom deep convolutional neural network (CNN) that is trained to perform 2-ways classification tasks: pre-hand close (HC) versus resting state (RE) and pre-hand open (HO) versus RE. The developed deep CNN works well (accuracy rates up to $$89.65 \pm 5.29\%$$ for HC versus RE and $$90.50 \pm 5.35\%$$ for HO versus RE), but the core of the present study was to explore the interpretability of the deep CNN to provide further insights into the activation mechanism of cortical sources during the preparation of hands’ sub-movements. Specifically, occlusion sensitivity analysis was carried out to investigate which cortical areas are more relevant in the classification procedure. Experimental results show a recurrent trend of spatial cortical activation across subjects. In particular, the central region (close to the longitudinal fissure) and the right temporal zone of the premotor together with the primary motor cortex appear to be primarily involved. Such findings encourage an in-depth study of cortical areas that seem to play a key role in hand’s open/close preparation.},
  archive      = {J_NCA},
  author       = {Ieracitano, Cosimo and Mammone, Nadia and Hussain, Amir and Morabito, Francesco Carlo},
  doi          = {10.1007/s00521-020-05624-w},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11347-11360},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel explainable machine learning approach for EEG-based brain-computer interface systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven mechanism based on fuzzy lagrangian twin
parametric-margin support vector machine for biomedical data analysis.
<em>NCA</em>, <em>34</em>(14), 11335–11345. (<a
href="https://doi.org/10.1007/s00521-021-05866-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a fuzzy-based Lagrangian twin parametric-margin support vector machine (FLTPMSVM) to reduce the effect of the outliers presented in biomedical data. The proposed FLTPMSVM assigns the weights to each data sample on the basis of fuzzy membership values to reduce the effect of outliers. This paper also adopts the square of the 2-norm of slack variables to make the objective function more convex. The proposed FLTPMSVM solves simple linearly convergent iterative schemes instead of solving a pair of quadratic programming problems. No external toolbox is required for the proposed FLTPMSVM as compared to the other methods. To establish the applicability of the proposed FLTPMSVM in the area of biomedical data classification, numerical experiments are performed on several biomedical datasets. The proposed FLTPMSVM gives an improved generalization performance and reduced training cost as compared to support vector machine (SVM), twin support vector machine (TWSVM), fuzzy twin support vector machine (FTSVM), twin parametric-margin support vector machine (TPMSVM) and new fuzzy twin support vector machine (NFTSVM).},
  archive      = {J_NCA},
  author       = {Gupta, Deepak and Borah, Parashjyoti and Sharma, Usha Mary and Prasad, Mukesh},
  doi          = {10.1007/s00521-021-05866-2},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11335-11345},
  shortjournal = {Neural Comput. Appl.},
  title        = {Data-driven mechanism based on fuzzy lagrangian twin parametric-margin support vector machine for biomedical data analysis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Global research on artificial intelligence-enhanced human
electroencephalogram analysis. <em>NCA</em>, <em>34</em>(14),
11295–11333. (<a
href="https://doi.org/10.1007/s00521-020-05588-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of artificial intelligence (AI) technologies in assisting human electroencephalogram (EEG) analysis has become an active scientific field. This study aims to present a comprehensive review of the research field of AI-enhanced human EEG analysis. Using bibliometrics and topic modeling, research articles concerning AI-enhanced human EEG analysis collected from the Web of Science database during the period 2009–2018 were analyzed. After examining 2053 research articles published around the world, it was found that the annual number of articles had significantly grown from 78 to 468, with the USA and China being the most influential and prolific. The results of the keyword analysis showed that “electroencephalogram,” “brain–computer interface,” “classification,” “support vector machine,” “electroencephalography,” and “signal” were the most frequently used. The results of topic modeling and evolution analyses highlighted several important issues, including epileptic seizure detection, brain–machine interface, EEG classification, mental disorders, emotion, and alcoholism and anesthesia. The findings suggest that such visualization and analysis of the research articles could provide a comprehensive overview of the field for communities of practice and inquiry worldwide.},
  archive      = {J_NCA},
  author       = {Chen, Xieling and Tao, Xiaohui and Wang, Fu Lee and Xie, Haoran},
  doi          = {10.1007/s00521-020-05588-x},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11295-11333},
  shortjournal = {Neural Comput. Appl.},
  title        = {Global research on artificial intelligence-enhanced human electroencephalogram analysis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning system for health care IoT and smartphone
malware detection. <em>NCA</em>, <em>34</em>(14), 11283–11294. (<a
href="https://doi.org/10.1007/s00521-020-05429-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of smart and connected devices, such as Android and Internet of Things (IoT) have increased exponentially. In the last 10 years, mobiles and IoT devices have surpassed PC’s utilization. Android hosts an array of connected sensors like IoT. It has transformed a simple gadget into a hub of mobile phone with IoT. With a high number of clients and enormous assortment of Android applications it has been an appealing target for many security threats including malware attacks. To monitor a host of the applications that runs on Android and IoT devices, this study employs a deep learning based feature detector for malware detection which can easily be trained and be used with different classifiers to assess an application’s behavior. The features learnt by the detector can be reused to transfer their learning to any future endeavors toward malware detection. To test the accuracy and effectiveness of the feature detector we test it in two phases: (i) first the features extracted are fed to a fully connected network (FCN) with Softmax activation and in (ii) second scheme we use recurrent layers of attentions to classify the Applications either as malicious or benign. Our findings reveal that the proposed feature detector achieves significant results with an F1-Score of 98.97\% and an accuracy of 98\%.},
  archive      = {J_NCA},
  author       = {Amin, Muhammad and Shehwar, Duri and Ullah, Abrar and Guarda, Teresa and Tanveer, Tamleek Ali and Anwar, Sajid},
  doi          = {10.1007/s00521-020-05429-x},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11283-11294},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning system for health care IoT and smartphone malware detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The monarch butterfly optimization algorithm for solving
feature selection problems. <em>NCA</em>, <em>34</em>(14), 11267–11281.
(<a href="https://doi.org/10.1007/s00521-020-05210-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is considered to be a hard optimization problem in data mining and some artificial intelligence fields. It is a process where rather than studying all of the features of a whole dataset, some associated features of a problem are selected, the aim of which is to increase classification accuracy and reduce computational time. In this paper, a recent optimization algorithm, the monarch butterfly optimization (MBO) algorithm, is implemented with a wrapper FS method that uses the k-nearest neighbor (KNN) classifier. Experiments were implemented on 18 benchmark datasets. The results showed that, in comparison with four metaheuristic algorithms (WOASAT, ALO, GA and PSO), MBO was superior, giving a high rate of classification accuracy of, on average, 93\% for all datasets as well as reducing the selection size significantly. Therefore, the use of the MBO to solve the FS problems has been proven through the results obtained to be effective and highly efficient in this field, and the results have also proven the strength of the balance between global and local search of MBO.},
  archive      = {J_NCA},
  author       = {Alweshah, Mohammed and Khalaileh, Saleh Al and Gupta, Brij B. and Almomani, Ammar and Hammouri, Abdelaziz I. and Al-Betar, Mohammed Azmi},
  doi          = {10.1007/s00521-020-05210-0},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11267-11281},
  shortjournal = {Neural Comput. Appl.},
  title        = {The monarch butterfly optimization algorithm for solving feature selection problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An IoT-based smart healthcare system to detect dysphonia.
<em>NCA</em>, <em>34</em>(14), 11255–11265. (<a
href="https://doi.org/10.1007/s00521-020-05558-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart healthcare systems for the internet of things (IoT) platform are cost-efficient and facilitate continuous remote monitoring of patients to avoid unnecessary hospital visits and long waiting times to see practitioners. Presenting a smart healthcare system for the detection of dysphonia can reduce the suffering and pain of patients by providing an initial evaluation of voice. This preliminary feedback of voice could minimize the burden on ENT specialists by referring only genuine cases to them as well as giving an early alarm of potential voice complications to patients. Any possible delay in the treatment and/or inaccurate diagnosis using the subjective nature of tools may lead to severe circumstances for an individual because some types of dysphonia are life-threatening. Therefore, an accurate and reliable smart healthcare system for IoT platform to detect dysphonia is proposed and implemented in this study. Higher-order directional derivatives are used to analyze the time–frequency spectrum of signals in the proposed system. The computed derivatives provide essential and vital information by analyzing the spectrum along different directions to capture the changes that appeared due to malfunctioning the vocal folds. The proposed system provides 99.1\% accuracy, while the sensitivity and specificity are 99.4 and 98.1\%, respectively. The experimental results showed that the proposed system could provide better classification accuracy than the traditional non-directional first-order derivatives. Hence, the system can be used as a reliable tool for detecting dysphonia and implemented in edge devices to avoid latency issues and protect privacy, unlike cloud processing.},
  archive      = {J_NCA},
  author       = {Ali, Zulfiqar and Imran, Muhammad and Shoaib, Muhammad},
  doi          = {10.1007/s00521-020-05558-3},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {11255-11265},
  shortjournal = {Neural Comput. Appl.},
  title        = {An IoT-based smart healthcare system to detect dysphonia},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic detection of cyclic alternating pattern.
<em>NCA</em>, <em>34</em>(13), 11097–11107. (<a
href="https://doi.org/10.1007/s00521-018-3474-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cyclic alternating pattern is a microstructure phasic event, present in the non-rapid eye movement sleep, which has been associated with multiple pathologies, and is a marker of sleep instability that is detected using the electroencephalogram. However, this technique produces a large quantity of information during a full night test, making the task of manually scoring all the cyclic alternating pattern cycles unpractical, with a high probability of miss classification. Therefore, the aim of this work is to develop and test multiple algorithms capable of automatically detecting the cyclic alternating pattern. The employed method first analyses the electroencephalogram signal to extract features that are used as inputs to a classifier that detects the activation (A phase) and quiescent (B phase) phases of this pattern. The output of the classifier was then applied to a finite state machine implementing the cyclic alternating pattern classification. A systematic review was performed to determine the features and classifiers that could be more relevant. Nine classifiers were tested using features selected by a sequential feature selection algorithm and features produced by principal component analysis. The best performance was achieved using a feed-forward neural network, producing, respectively, an average accuracy, sensitivity, specificity and area under the curve of 79, 76, 80\% and 0.77 in the A and B phases classification. The cyclic alternating pattern detection accuracy, using the finite state machine, was of 79\%.},
  archive      = {J_NCA},
  author       = {Mendonça, Fábio and Fred, Ana and Mostafa, Sheikh Shanawaz and Morgado-Dias, Fernando and Ravelo-García, Antonio G.},
  doi          = {10.1007/s00521-018-3474-5},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {11097-11107},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic detection of cyclic alternating pattern},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scene guided colorization using neural networks.
<em>NCA</em>, <em>34</em>(13), 11083–11096. (<a
href="https://doi.org/10.1007/s00521-018-3828-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel, fully automatic method to grayscale images colorization using a scene guided neural network. In our proposed method, given a training set of both grayscale images and their corresponding color images, we first extract features of each grayscale pixel. These features, together with the corresponding RGB values of that pixel are input to train a colorization neural network for each given scene. To improve the performance of colorization, in both speed and results, we further classify the input and training images into different scene classes. We adopt a linear image classification method to generate a scene guided codebook and use it to determine the scene class of the input image. The preliminary colorization result is then generated by the corresponding trained neural network of the scene class of the input image. Finally, an image guided filter is used to refine colorized images. Inspired by the recent success in deep learning techniques which provide stabilizing modeling of large-scale medical image data, the proposed paper formulating the enhancement and colorization problem, so that colorization techniques can be directly used to ensure medical images with high quality. The experimental results on a broad range of images demonstrate that our method has better colorization performance as compared to that of the state-of-the-art algorithms.},
  archive      = {J_NCA},
  author       = {Xia, Yu and Qu, Shiru and Wan, Shaohua},
  doi          = {10.1007/s00521-018-3828-z},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {11083-11096},
  shortjournal = {Neural Comput. Appl.},
  title        = {Scene guided colorization using neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BinGSO: Galactic swarm optimization powered by binary
artificial algae algorithm for solving uncapacitated facility location
problems. <em>NCA</em>, <em>34</em>(13), 11063–11082. (<a
href="https://doi.org/10.1007/s00521-022-07058-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population-based optimization methods are frequently used in solving real-world problems because they can solve complex problems in a reasonable time and at an acceptable level of accuracy. Many optimization methods in the literature are either directly used or their binary versions are adapted to solve binary optimization problems. One of the biggest challenges faced by both binary and continuous optimization methods is the balance of exploration and exploitation. This balance should be well established to reach the optimum solution. At this point, the galactic swarm optimization (GSO) framework, which uses traditional optimization methods, stands out. In this study, the binary galactic swarm optimization (BinGSO) approach using binary artificial algae algorithm as the main search algorithm in GSO is proposed. The performance of the proposed binary approach has been performed on uncapacitated facility location problems (UFLPs), which is a complex problem due to its NP-hard structure. The parameter analysis of the BinGSO method was performed using the 15 Cap problems. Then, the BinGSO method was compared with both traditional binary optimization methods and the state-of-the-art methods which are used on Cap problems. Finally, the performance of the BinGSO method on the M* problems was examined. The results of the proposed approach on the M* problem set were compared with the results of the state-of-the-art methods. The results of the evaluation process showed that the BinGSO method is more successful than other methods through its ability to establish the balance between exploration and exploitation in UFLPs.},
  archive      = {J_NCA},
  author       = {Kaya, Ersin},
  doi          = {10.1007/s00521-022-07058-y},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {11063-11082},
  shortjournal = {Neural Comput. Appl.},
  title        = {BinGSO: Galactic swarm optimization powered by binary artificial algae algorithm for solving uncapacitated facility location problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structural recurrent neural network models for earthquake
prediction. <em>NCA</em>, <em>34</em>(13), 11049–11062. (<a
href="https://doi.org/10.1007/s00521-022-07030-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The earthquake prediction problem can be defined as given a minimum Richter magnitude scale and a specified geographic region, predicting the possibility of an earthquake in that region within a time interval. This is a long-time studied research problem but not much progress is achieved until the last decade. With the advancement of computational systems and deep learning models, significant results are achieved. In this study, we introduce novel models using the structural recurrent neural network (SRNN) that capture the spatial proximity and structural properties such as the existence of faults in regions. Experimental results are carried out using two distinct regions such as Turkey and China where the scale and earthquake zones differ greatly. SRNN models achieve better performance results compared with the baseline and the state-of-the-art models. Especially the $$\mathrm{SRNNClass}_\mathrm{near}$$ model, that captures the first-order spatial neighborhood and structural classification based on fault lines, results in the highest $$F_1$$ score.},
  archive      = {J_NCA},
  author       = {Doğan, Aydın and Demir, Engin},
  doi          = {10.1007/s00521-022-07030-w},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {11049-11062},
  shortjournal = {Neural Comput. Appl.},
  title        = {Structural recurrent neural network models for earthquake prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classifying nanostructured and heterogeneous materials from
transmission electron microscopy images using convolutional neural
networks. <em>NCA</em>, <em>34</em>(13), 11035–11047. (<a
href="https://doi.org/10.1007/s00521-022-07029-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence and nanotechnology are two areas of science that have changed the world and made life easier during this last decade. Both fields are undergoing significant knowledge expansion, and both bear the promise of a better future for humankind. This research study used convolutional neural networks to classify images of nanostructured materials of different chemical components, obtained through transmission electron microscopy (TEM). A total of 685 ground truth images from a reduced collection of nanostructured TEM images were analyzed. They were classified into three groups: silicate, silica, and coating, each type belonging to chemical compounds of yttrium silicate, silicon oxide nanoparticles, and silicon oxide nanoparticles as a thin layer (coating), respectively. The classification, location, and segmentation of chemical compounds were conducted using Mask R-CNN (Region-Convolution Neural Network) with ResNet101 as the backbone for convolutional neural networks and trained with the collection of images created. The results showed accuracy scores from 85 to 99\% for the three classes. The trained model was also able to classify overlapping and agglomerated clusters of these three compounds.},
  archive      = {J_NCA},
  author       = {Cabrera, Carlos and Cervantes, David and Muñoz, Franklin and Hirata, Gustavo and Juárez, Patricia and Flores, Dora-Luz},
  doi          = {10.1007/s00521-022-07029-3},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {11035-11047},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classifying nanostructured and heterogeneous materials from transmission electron microscopy images using convolutional neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SKG-learning: A deep learning model for sentiment knowledge
graph construction in social networks. <em>NCA</em>, <em>34</em>(13),
11015–11034. (<a
href="https://doi.org/10.1007/s00521-022-07028-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional sentiment analysis methods pay little attention to the inseparable relations between evaluation words and evaluation aspects, and the relations between evaluation words and topics. There have been many studies of knowledge graph (KG), which can effectively store and manage massive amounts of information and is suitable to associate emotion words with evaluation aspects and topics. This study proposes SKG-Learning based on a deep learning model to construct a sentiment knowledge graph (SKG) for sentiment analysis. Entity and relation are the cornerstones of SKG; thus, the task of SKG-Learning is divided into named entity recognition and relation extraction. We propose a bidirectional long short-term memory model (Bi-LSTM) with background knowledge embedding and co-extraction of features (BBC-LSTM) to extract entities. BBC-LSTM completes the embedding of background knowledge such as topic and emotion information and uses three-dimensional tensors to co-extract the deep features of aspect entities and sentiment entities. It solves the problems that it is difficult to recognize entities from insufficient context, and traditional models usually neglect the relevance between sentiment entities and aspect entities. A relation extraction model based on an encoder–decoder model (ED-Learning) is proposed to extract and classify the relation between sentiment and aspect entity, that is, the emotional tendency of sentiment entity toward aspect entity. Experiments show that the proposed methods can more efficiently extract entities and relations from social network texts. We confirm the validity of an SKG constructed by the SKG-Learning model in an emotional analysis task.},
  archive      = {J_NCA},
  author       = {Zhang, Bo and Hu, Yue and Xu, Duo and Li, Maozhen and Li, Meizi},
  doi          = {10.1007/s00521-022-07028-4},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {11015-11034},
  shortjournal = {Neural Comput. Appl.},
  title        = {SKG-learning: A deep learning model for sentiment knowledge graph construction in social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IEESEP: An intelligent energy efficient stable election
routing protocol in air pollution monitoring WSNs. <em>NCA</em>,
<em>34</em>(13), 10989–11013. (<a
href="https://doi.org/10.1007/s00521-022-07027-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, wireless sensor network (WSN) consists of insignificant and low-priced sensing hops (nodes) focusing on gathering eco-friendly information. It may be used in a variation of control systems, environment monitoring such as industrial pollution, disaster management, indoor and outdoor temperature. The comprehensive series of uses of WSNs is constantly growing despite the limitations of sensor nodes (SNs) resources like capacity, a range of communication, etc. The major problems faced in WSNs are the maximum energy consumption (EC) and end-to-end delay (E2D) in relaying information to the destination node. This research work proposes an enhanced Stable election protocol that provides intelligent ways to form an optimal route in the network with the FFBPNN algorithm called IEESEP. In this method, the wireless air pollution monitoring (WAPM) System is proficient on a large dataset comprising all scenarios to create WAPMS reliability and adaptability to the environment. Moreover, it is used for varying cluster-based research methodology to improve the network lifetime. A feed-forward, back propagation (FFBPNN) gives to form an optimal path. It enhances network stability by using parameters like advanced and normal nodes. This protocol provides an effective threshold value for selecting an optimal route on the FFBPNN method. So, our research method is highly energy-efficient, proficient at maximizing SNs packet delivery rate and network lifetime. Experimental outperforms define that it results in an IEESEP protocol delivery rate by 78\%, other protocols like SEP and ELDC Protocol by 50\% and 27\% delivery rate.},
  archive      = {J_NCA},
  author       = {Dixit, Ekta and Jindal, Vandana},
  doi          = {10.1007/s00521-022-07027-5},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10989-11013},
  shortjournal = {Neural Comput. Appl.},
  title        = {IEESEP: An intelligent energy efficient stable election routing protocol in air pollution monitoring WSNs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel convolutional neural network with interference
suppression for the fault diagnosis of mechanical rotating components.
<em>NCA</em>, <em>34</em>(13), 10971–10987. (<a
href="https://doi.org/10.1007/s00521-022-07022-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite some recent achievements in the intelligent data-driven fault diagnosis of mechanical rotating components, in most cases very large amounts of pure data are demanded for model training. However, the collected vibration signals of mechanical rotating components are inevitably contaminated with noise in real industries. To resolve the low fault diagnosis accuracy due to strong noise interference, a convolutional neural network with interference suppression (ISCNN) is proposed in this paper. First, a parallel convolutional structure with dilated wide convolution kernels is designed to extract long-time correlated fault features of multiple scales from a noise-contaminated signal by sparse sampling, and noise interference is suppressed by filtering operations. Then, a multiscale feature enhancement module is constructed to achieve adaptive tuning of time scale by employing a parallel selective kernel network to exploit weak fault features buried in noisy signals. Finally, a convolutional feature fusion method is adopted to integrate multidimensional fault features and feed them into the classifier, thus achieving accurate fault diagnosis of mechanical rotating components. Experimental results on two benchmark datasets indicate that the ISCNN model outperforms its counterparts in the fault diagnosis field and improves the fault discriminability of mechanical rotating components in strong noisy scenarios.},
  archive      = {J_NCA},
  author       = {Yang, Jingli and Yin, Shuangyan and Sun, Chao and Gao, Tianyu},
  doi          = {10.1007/s00521-022-07022-w},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10971-10987},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel convolutional neural network with interference suppression for the fault diagnosis of mechanical rotating components},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). An observer-based IT2 TSK FLS compensation controller for
PMSM servo systems: Design and evaluation. <em>NCA</em>,
<em>34</em>(13), 10949–10969. (<a
href="https://doi.org/10.1007/s00521-022-07020-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is hard to achieve precise displacement for the permanent-magnet synchronous motor (PMSM) servo systems due to the nonlinear friction and time-varying end-load. This paper proposes an observer-based compensation control strategy to cope with the above issues. First, an adaptive interval type-2 Takagi-Sugeno-Kang (TSK) fuzzy logic system is adopted to estimate the inherent friction. By utilizing the tracking and modeling error, the composite adaptive updating law is constructed to improve the tracking performance. Then, the residual reconstruction errors and the bounded end-load are estimated and compensated by the designed disturbance observer. Estimation of friction and disturbance observer, as compensation terms, are employed in traditional cascade control. Finally, the proposed controller guarantees the tracking error is uniformly ultimately bounded based on Lyapunov theory. Simulations and experiments are presented to verify the effectiveness and superiority of the proposed controller.},
  archive      = {J_NCA},
  author       = {Liu, Yan and Wang, Yongfu and Wang, Yunlong},
  doi          = {10.1007/s00521-022-07020-y},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10949-10969},
  shortjournal = {Neural Comput. Appl.},
  title        = {An observer-based IT2 TSK FLS compensation controller for PMSM servo systems: Design and evaluation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning of physically significant features from earth
observation data: An illustration for crop classification and irrigation
scheme detection. <em>NCA</em>, <em>34</em>(13), 10929–10948. (<a
href="https://doi.org/10.1007/s00521-022-07019-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Earth observation data processing requires interpretable deep learning (DL) models that learn physically significant and meaningful features. The current study proposes approaches to make the network to learn meaningful features. In addition, a set of interpretability- and explanation-based evaluation strategies are proposed to evaluate the DL models. Adversarial variational encoding along with constraints to regulate latent representations and embed label information are employed to learn interpretable manifold. The proposed architecture, called interpretable adversarial encoding network (IAENet), significantly improves the results compared to other main existing DL models. The proposed IAENet learns the features which are essential in distinguishing the different classes thereby improving the interpretability of the model. The explanations for the different models are generated through analysis of the concepts learned by each model using activation maximization. Besides, the relevance assigned by the model to input features is also estimated using the layer-wise relevance propagation approach. Experiments on the phenological curve-based crop classification illustrate that IAENet learn relevant features (giving importance to the non-rainy season) to distinguish different irrigation schemes. The performance can be attributed to the learned interpretable manifold, and the refinement of architectural units and convolutions considering the point-nature and irregular sampling of the input data. Experiments on learning crop-specific features from multispectral images for crop-type classification indicate that IAENet learns red and green edge features crucial in distinguishing the studied crops. The improvement in interpretability of the DL models is found to reduce the sensitivity toward network parameters. The proposed evaluation measures facilitate ascertaining the physical significance of the learned manifold.},
  archive      = {J_NCA},
  author       = {Arun, Pattathal V. and Karnieli, Arnon},
  doi          = {10.1007/s00521-022-07019-5},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10929-10948},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning of physically significant features from earth observation data: An illustration for crop classification and irrigation scheme detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). COMPOSV: Compound feature extraction and depthwise separable
convolution-based online signature verification. <em>NCA</em>,
<em>34</em>(13), 10901–10928. (<a
href="https://doi.org/10.1007/s00521-022-07018-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online signature verification (OSV) is a predominantly used verification framework, which is intended to authenticate the legitimacy of a test signature by learning the writer specific signing characteristics. The significant adoption of OSV in critical applications like E-Commerce, M-Payments, etc., emphasizes on a framework which addresses critical requirements: (1) The framework should be competent to classify a test signature with few training samples, as minimum as one per user and with the least number of features extracted per signature, and (2) The framework should accurately classify a test signature of an unseen user. Even though several OSV frameworks are proposed based on various advanced techniques, still there is a necessity for a holistic OSV framework which is able to accomplish the abovementioned requirement criteria. To realize the above requirements, we present a depthwise separable (DWS) convolution-based OSV framework which facilitate the classification of test signature samples from an unseen user. In addition to this, we introduce a novel dimensionality reduction-based feature extraction technique, which decrease the dimensionality of a set of features from 100 to 3 concerning to MCYT-330, MCYT-100 and 47 to 3 with regard to SVC, SUSIG datasets. To appraise the competence of our proposed COMPOSV framework, extensive experiments and ablation studies are conducted on four widely used datasets, i.e., MCYT-100, MCYT-330, SVC and SUSIG. The proposed framework, trained with signature samples of only 10\% of users (seen), can classify the signatures of 90\% of unseen users with higher accuracy than the frameworks trained with signature samples of all users.},
  archive      = {J_NCA},
  author       = {Vorugunti, Chandra Sekhar and Pulabaigari, Viswanath and Mukherjee, Prerana and Gautam, Avinash},
  doi          = {10.1007/s00521-022-07018-6},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10901-10928},
  shortjournal = {Neural Comput. Appl.},
  title        = {COMPOSV: Compound feature extraction and depthwise separable convolution-based online signature verification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-performance intrusion detection system for networked
UAVs via deep learning. <em>NCA</em>, <em>34</em>(13), 10885–10900. (<a
href="https://doi.org/10.1007/s00521-022-07015-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Unmanned Aerial Vehicles (UAVs) have become a widely popular technology with remarkable growth and unprecedented attention. However, UAV communication networks are susceptible to various cyber-intrusions/threats due to their limited computation and communication capabilities. Such intrusions/misbehaviors tend to be processed as normal packets through the UAV communication networks. In this work, we present an autonomous intrusion detection system that can efficiently detect the malicious threats invading UAV using deep convolutional neural networks (UAV-IDS-ConvNet). Specifically, the proposed system considers encrypted Wi-Fi traffic data records of three types of commonly used UAVs: Parrot Bebop UAVs, DBPower UDI UAVs, and DJI Spark UAVs. To evaluate the developed system, we employed the UAV-IDS-2020 dataset which includes various attacks on UAV networks in unidirectional and bidirectional communication flow modes. Moreover, we emulate the context of homogeneous and heterogeneous networked UAVs. Our best experimental outcomes exhibited a victorious intrusion detection accuracy of 99.50\% for the two-class classifier model (normal UAV vs. anomaly) with 2.77 ms prediction time. Besides, the proposed system was evaluated using other performance metrics including confusion matrix parameters, false alarm rate, detection precision, detection sensitivity, and prediction overhead. The performance analysis showed that our UAV-IDS-ConvNet system outperforms several recent existing intrusion detection systems developed to secure the UAV communication networks by (6–23)\%.},
  archive      = {J_NCA},
  author       = {Abu Al-Haija, Qasem and Al Badawi, Ahmad},
  doi          = {10.1007/s00521-022-07015-9},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10885-10900},
  shortjournal = {Neural Comput. Appl.},
  title        = {High-performance intrusion detection system for networked UAVs via deep learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predictive models for mechanical properties of expanded
polystyrene (EPS) geofoam using regression analysis and artificial
neural networks. <em>NCA</em>, <em>34</em>(13), 10845–10884. (<a
href="https://doi.org/10.1007/s00521-022-07014-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Initial elastic modulus and compressive strength are the two most important engineering properties for modeling and design of EPS geofoams, which are extensively used in civil engineering applications such as light-fill material embankments, retaining structures, and slope stabilization. Estimating these properties based on geometric and physical parameters is of great importance. In this study, the compressive strength and modulus of elasticity values are obtained by performing 356 unconfined compression tests on EPS geofoam samples with different shapes (cubic or disc), dimensions, loading rates, and density values. Using these test results, the mechanical properties of the specimens are predicted by linear regression and artificial neural network (ANN) methods. Both methods predicted the initial modulus of elasticity ( $${E}_{i}$$ ), 1\% strain $${(\sigma }_{1})$$ , 5\% strain $${(\sigma }_{5})$$ , and 10\% strain $${(\sigma }_{10})$$ strength values on a satisfactory level with a coefficient of correlation (R2) values of greater than 0.901. The only exception was in prediction of $${\sigma }_{1}$$ and $${E}_{i}$$ in disc-shaped samples by linear regression method where the R2 value was around 0.558. The results obtained from linear regression and ANN approaches show that ANN slightly outperform linear regression prediction for $${E}_{i}$$ and $${\sigma }_{1}$$ properties. The outcomes of the two methods are also compared with results of relevant studies, and it is observed that the calculated values are consistent with the results from the literature.},
  archive      = {J_NCA},
  author       = {Akis, E. and Guven, G. and Lotfisadigh, B.},
  doi          = {10.1007/s00521-022-07014-w},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10845-10884},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predictive models for mechanical properties of expanded polystyrene (EPS) geofoam using regression analysis and artificial neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of aerodynamic coefficients of a non-slender
delta wing under ground effect using artificial intelligence techniques.
<em>NCA</em>, <em>34</em>(13), 10823–10844. (<a
href="https://doi.org/10.1007/s00521-022-07013-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents machine learning techniques to estimate the aerodynamic coefficients of a 40° swept delta wing under the ground effect. For this purpose, three different approaches including feed-forward neural network (FNN), Elman neural network (ENN) and adaptive neuro-fuzzy interference system (ANFIS) have been used. The optimal configuration of these models was compared with each other, and the best accurate prediction model was determined. In the generated machine learning models, the lift CL and drag coefficients CD of the delta wing under the ground proximity of h/c = 0.4 were predicted by using the data of actual CL and CD of the delta wing under the ground proximities of h/c = 1, 0.7, 0.55, 0.25 and 0.1. In FNN, ENN and ANFIS models, the angle of attack α and ground distance h/c were utilized as input parameters, CL and CD as output parameters, separately. Although all three models estimate the CL and CD of the delta wing under h/c = 0.4 with very high accuracy, the ENN method predicts the CL and CD with much higher accuracy than the FNN and ANFIS models. For the estimation of CL, while optimal configuration of ENN resulted in 1.0709\% MAPE, 0.00595 RMSE and 0.00504 MAE, the best configurations of FNN and ANFIS end up with the results of 1.172\% and 1.1028\% MAPE, 0.00786 and 0.0071 RMSE, 0.00593 and 0.0054 MAE, respectively. Thus, results show that the developed FNN, ENN and ANFIS models can be accurately employed to forecast the aerodynamic coefficients of the delta wing under ground effect without the need of for many experimental measurements that causes extra time, labor and experimental costs.},
  archive      = {J_NCA},
  author       = {Tumse, Sergen and Bilgili, Mehmet and Sahin, Besir},
  doi          = {10.1007/s00521-022-07013-x},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10823-10844},
  shortjournal = {Neural Comput. Appl.},
  title        = {Estimation of aerodynamic coefficients of a non-slender delta wing under ground effect using artificial intelligence techniques},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DNN-MF: Deep neural network matrix factorization approach
for filtering information in multi-criteria recommender systems.
<em>NCA</em>, <em>34</em>(13), 10807–10821. (<a
href="https://doi.org/10.1007/s00521-022-07012-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalization systems have proved to be one of the most powerful tools for e-commerce sites, assisting users in discovering the most relevant products across enormous product catalogues. The formulation of product suggestions in the most widely used collaborative filtering is dependent on ratings contributed by the customer base. Though numerous domains consider allowing users to give an overall rating to products, a burgeoning number of online platforms are allowing users to rate products on a variety of dimensions. According to previous research, these multidimensional ratings offer valuable perceptions that can be used in generating a personalization list for users. Within the personalization systems research domain, multi-criteria systems have garnered significant attention since they use multiple criteria to predict rating scores. New strategies for leveraging information produced from multi-criteria scores to increase the prediction precision of multi-criteria (MC) systems are presented in this paper. In particular, we propose to fuse deep neural networks (DNN), matrix factorization (MF), and social spider optimization (SSO) to exploit nonlinear, non-trivial, and concealed interactions between users in terms of MC preferences. Experimenting on Yahoo! and TripAdvisor datasets reveals that our proposed approach outperforms both modern single-rating recommender systems based on MF and traditional multi-criteria systems. As a result, we believe that using multi-criteria customer evaluations can help e-commerce companies enhance the quality and specificity of their recommended services.},
  archive      = {J_NCA},
  author       = {Sinha, Bam Bahadur and Dhanalakshmi, R.},
  doi          = {10.1007/s00521-022-07012-y},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10807-10821},
  shortjournal = {Neural Comput. Appl.},
  title        = {DNN-MF: Deep neural network matrix factorization approach for filtering information in multi-criteria recommender systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel semi-supervised generative adversarial network based
on the actor-critic algorithm for compound fault recognition.
<em>NCA</em>, <em>34</em>(13), 10787–10805. (<a
href="https://doi.org/10.1007/s00521-022-07011-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vibration signals can be used to extract effective fault features for fault diagnosis. However, traditional supervised learning requires considerable manpower and time to mark samples manually, and this process is difficult to apply to practical fault diagnosis. Deep reinforcement learning which combines the perception ability of deep learning with the decision-making ability of reinforcement learning, can independently extract hidden fault features and effectively improve the accuracy of fault diagnosis. Semi-supervised learning can reduce the proportion of labeled samples to decrease the learning cost while improving the recognition accuracy with unlabeled samples. In this study, we propose a novel semi-supervised deep reinforcement learning method. A semi-supervised generative adversarial network combined with the improved actor-critic algorithm is proposed to perform fault diagnosis when the labeled sample size is small. In the experiment of rolling bearing fault and engineering application, three-channel time-frequency graphs extracted from raw signals with the wavelet packet are compressed into single channel gray graphs. Then, to simulate the less labeled sample dataset, 2\%, 5\%, 20\%, 50\% and 100\% sample labels are set by dislodging partial label from the processing sample. The results of the proposed method and other intelligent methods are listed to demonstrate that the proposed method could provide better performance over other methods even if the size of labeled sample is small in compound fault diagnosis.},
  archive      = {J_NCA},
  author       = {Wang, Zisheng and Xuan, Jianping and Shi, Tielin},
  doi          = {10.1007/s00521-022-07011-z},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10787-10805},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel semi-supervised generative adversarial network based on the actor-critic algorithm for compound fault recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Event-triggered adaptive integral reinforcement learning
method for zero-sum differential games of nonlinear systems with
incomplete known dynamics. <em>NCA</em>, <em>34</em>(13), 10775–10786.
(<a href="https://doi.org/10.1007/s00521-022-07010-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper designs a novel event-based adaptive learning method for solving zero-sum games (ZSGs) of nonlinear systems with incomplete known dynamics. Firstly, a discounted cost is introduced for the system with nonzero equilibrium point to obtain the near-optimal strategy pair. Then, the employment of integral reinforcement learning (IRL) makes it unnecessary to acquire the model of the drift dynamics. To approximate the solution of the Hamilton-Jacobi-Isaacs equations (HJIEs), single-critic network is constructed with the modified tuning law utilizing preprocessed data. For purpose of increasing algorithm efficiency, the event-triggered mechanism (ETM) is introduced which could obviate Zeno behavior. Furthermore, the state and critic weight vector error are proved to be uniform ultimate bounded (UUB) through Lyapunov approach. Finally, the effectiveness of the proposed method is validated by conducting a simulation experiment.},
  archive      = {J_NCA},
  author       = {Liu, Pengda and Zhang, Huaguang and Sun, Jiayue and Tan, Zilong},
  doi          = {10.1007/s00521-022-07010-0},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10775-10786},
  shortjournal = {Neural Comput. Appl.},
  title        = {Event-triggered adaptive integral reinforcement learning method for zero-sum differential games of nonlinear systems with incomplete known dynamics},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Groundwater level prediction using machine learning
algorithms in a drought-prone area. <em>NCA</em>, <em>34</em>(13),
10751–10773. (<a
href="https://doi.org/10.1007/s00521-022-07009-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Groundwater resources (GWR) play a crucial role in agricultural crop production, daily life, and economic progress. Therefore, accurate prediction of groundwater (GW) level will aid in the sustainable management of GWR. A comparative study was conducted to evaluate the performance of seven different ML models, such as random tree (RT), random forest (RF), decision stump, M5P, support vector machine (SVM), locally weighted linear regression (LWLR), and reduce error pruning tree (REP Tree) for GW level (GWL) prediction. The long-term prediction was conducted using historical GWL, mean temperature, rainfall, and relative humidity datasets for the period 1981–2017 obtained from two wells in the northwestern region of Bangladesh. The whole dataset was divided into training (1981–2008) and testing (2008–2017) datasets. The output of the seven proposed models was evaluated using the root mean square error (RMSE), mean absolute error (MAE), relative absolute error (RAE), root relative squared error (RRSE), correlation coefficient (CC), and Taylor diagram. The results revealed that the Bagging-RT and Bagging-RF models outperformed other ML models. The Bagging-RT models can effectively improve prediction precision as compared to other models with RMSE of 0.60 m, MAE of 0.45 m, RAE of 27.47\%, RRSE of 30.79\%, and CC of 0.96 for Rajshahi and RMSE of 0.26 m, MAE of 0.18 m, RAE of 19.87\%, RRSE of 24.17\%, and 0.97 for Rangpur during training, and RMSE of 0.60 m, MAE of 0.40 m, RAE of 24.25\%, RRSE of 29.99\%, and CC of 0.96 for Rajshahi and RMSE of 0.38 m, MAE of 0.24 m, RAE of 23.55\%, RRSE of 31.77\%, and CC of 0.95 for Rangpur during testing stages, respectively. Our study offers an effective and practical approach to the forecast of GWL that could help to formulate policies for sustainable GWR management.},
  archive      = {J_NCA},
  author       = {Pham, Quoc Bao and Kumar, Manish and Di Nunno, Fabio and Elbeltagi, Ahmed and Granata, Francesco and Islam, Abu Reza Md. Towfiqul and Talukdar, Swapan and Nguyen, X. Cuong and Ahmed, Ali Najah and Anh, Duong Tran},
  doi          = {10.1007/s00521-022-07009-7},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10751-10773},
  shortjournal = {Neural Comput. Appl.},
  title        = {Groundwater level prediction using machine learning algorithms in a drought-prone area},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dr.PathFinder: Hybrid fuzzing with deep reinforcement
concolic execution toward deeper path-first search. <em>NCA</em>,
<em>34</em>(13), 10731–10750. (<a
href="https://doi.org/10.1007/s00521-022-07008-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzing is an effective approach to discover bugs in programs, especially memory corruption bugs, using randomly generated test cases. However, without prior knowledge of the target program, the fuzzer can generate only a limited number of test cases because of sanity checks. To solve this problem, recent studies have proposed hybrid fuzzers that observe the context of a target program using symbolic execution; these fuzzers generate test cases to bypass the sanity check. While hybrid fuzzers explore “deep” bugs in the target program, they generate many ineffective test cases. In this paper, we propose a concolic execution algorithm that combines deep reinforcement learning with a hybrid fuzzing solution, Dr.PathFinder. When the reinforcement learning agent encounters a branch during concolic execution, it evaluates the state and determines the search path. In this process,“shallow” paths are pruned, and “deep” paths are searched first. This reduces unnecessary exploration, allowing the efficient memory usage and alleviating the state explosion problem. In experiments with the CB-multios dataset for deep bug cases, Dr.PathFinder discovered approximately five times more bugs than AFL and two times more than Driller-AFL. In addition to finding more bugs, Dr.PathFinder generated 19 times fewer test cases and used at least $$2\%$$ less memory than Driller-AFL. While it performed well in finding bugs located in deep paths, Dr.PathFinder had limitation to find bugs located at shallow paths, which we discussed.},
  archive      = {J_NCA},
  author       = {Jeon, Seungho and Moon, Jongsub},
  doi          = {10.1007/s00521-022-07008-8},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10731-10750},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dr.PathFinder: Hybrid fuzzing with deep reinforcement concolic execution toward deeper path-first search},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CDNet: A real-time and robust crosswalk detection network on
jetson nano based on YOLOv5. <em>NCA</em>, <em>34</em>(13), 10719–10730.
(<a href="https://doi.org/10.1007/s00521-022-07007-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Realizing real-time and robust crosswalk (zebra crossing) detection in complex scenarios and under limited computing power is one of the important difficulties of current intelligent traffic management systems (ITMS). Limited edge computing capabilities and real complex scenarios such as in cloudy, sunny, rainy, foggy and at night simultaneously challenge this task. In this study, the crosswalk detection network (CDNet) based on YOLOv5 is proposed to achieve fast and accurate crosswalk detection under the vision of the vehicle-mounted camera, and real-time detection is implemented on Jetson nano device. The powerful convolution neural network feature extractor is used to handle complex environments, the squeeze-and-excitation (SE) attention mechanism module is embedded into the network, the negative samples training (NST) method is used to improve the accuracy, the region of interest (ROI) algorithm is utilized to further improve the detection speed, and a novel slide receptive field short-term vector memory (SSVM) algorithm is proposed to improve vehicle-crossing behavior detection accuracy, the synthetic fog augmentation algorithm is used to allow the model adaptable to foggy scenario. Finally, with a detection speed of 33.1 FPS on Jetson nano, we obtained an average F1 score of 94.83\% in the above complex scenarios. For better weather condition such as sunny and cloudy days, the F1 score exceeds 98\%. This work provides a reference for the specific application of artificial neural network algorithm optimization methods on edge computing devices. The datasets, tutorials and source codes are available on GitHub.},
  archive      = {J_NCA},
  author       = {Zhang, Zheng-De and Tan, Meng-Lu and Lan, Zhi-Cai and Liu, Hai-Chun and Pei, Ling and Yu, Wen-Xian},
  doi          = {10.1007/s00521-022-07007-9},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10719-10730},
  shortjournal = {Neural Comput. Appl.},
  title        = {CDNet: A real-time and robust crosswalk detection network on jetson nano based on YOLOv5},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Single image super-resolution via deep progressive
multi-scale fusion networks. <em>NCA</em>, <em>34</em>(13), 10707–10717.
(<a href="https://doi.org/10.1007/s00521-022-07006-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural network-based single-image super-resolution (SR) models typically process either upsampled full-resolution or original low-resolution features, which suffer from context lack and spatially imprecision, respectively. To solve this, we propose a novel progressive SR network to preserve spatial precision through the original resolution and to receive rich contextual information from low-to-high resolution representations. Our proposed progressive, selective scale fusion network includes four key points: (a) parallel multi-scale convolution branches to extract multi-scale features, (b) information exchange across the multi-scale branches, (c) attention mechanism-based multi-scale feature fusion, and (d) gradual aggregation of multi-scale streams from low-to-high resolutions. The proposed method learns hierarchical features that aggregate contextual information from different resolution streams while maintaining high-resolution spatial details. Both quantitative and qualitative experiments on benchmark and real-world datasets show that our method offers a favorable performance against state-of-the-art methods for SR tasks with different scaling factors.},
  archive      = {J_NCA},
  author       = {Que, Yue and Lee, Hyo Jong},
  doi          = {10.1007/s00521-022-07006-w},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10707-10717},
  shortjournal = {Neural Comput. Appl.},
  title        = {Single image super-resolution via deep progressive multi-scale fusion networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Defect detection of photovoltaic glass based on level set
map. <em>NCA</em>, <em>34</em>(13), 10691–10705. (<a
href="https://doi.org/10.1007/s00521-022-07005-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defect detection of photovoltaic (PV) glass products is a challenge due to its complex optical properties and lack of defective samples. Aiming at this problem, a multi-task framework, in which an auxiliary semantic segmentation task based on the generative adversarial network assists the main defective classification task, is proposed. The auxiliary task guides the feature extractor to focus on the contour of the glass. Level set map (LSM), a new representation of contour which is the integration of a mask, is introduced into the framework to further improve the performance. Unlike level set loss, which is an indirect contour constraint on the segmentation loss in the form of a regular term, LSM is a direct annotation parallel with mask. Recovering LSM and mask simultaneously can affect each other positively. Two synthetic PV glass datasets, named SynSmall and SynBig, and two real-world PV glass datasets, named Mask3 and Defect3, are established to validate the proposed method. Two groups of experiments on the glass datasets are designed to inspect the feasibility and performance of the proposed framework from different aspects. Furthermore, a group of experiments involving separate segmentation tasks on SynSmall and Mask3, together with two public datasets TOMNet and Human, are executed to illustrate the performance of LSM. Experimental results show that the proposed framework can improve the accuracy of PV glass defective detection task significantly and LSM can improve the segmentation accuracy by filtering isolated wrongly recovered regions.},
  archive      = {J_NCA},
  author       = {Dong, Shuai and Chen, Chen and Liang, Yihui and Zou, Kun and Liu, Guisong},
  doi          = {10.1007/s00521-022-07005-x},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10691-10705},
  shortjournal = {Neural Comput. Appl.},
  title        = {Defect detection of photovoltaic glass based on level set map},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal power flow for an integrated
wind-solar-hydro-thermal power system considering uncertainty of wind
speed and solar radiation. <em>NCA</em>, <em>34</em>(13), 10655–10689.
(<a href="https://doi.org/10.1007/s00521-022-07000-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes two solution methods with the help of metaheuristic algorithms to reduce the electricity generation costs of power plants in an IEEE 30-node transmission power network. The first solution method considers the whole system simultaneously whereas the second method optimizes the generation of hydropower plants (HPs) in the first stage and deals with other remaining plants and parameters of the transmission power network in the second stage. The integrated system is comprised of thermal power plants, HPs, wind power plants and photovoltaic power plants (PVPs) considering the certainty and uncertainty of solar radiation and wind speed. In addition, the placement of a PVP is, respectively, tried at node 30 and node 3 based on loss sensitivity factor (LSF). The results from an effective Cuckoo search algorithm (ECSA) for the two solution methods indicate that the second solution method is much more effective than the first one. In addition, three other metaheuristics including equilibrium optimizer, Cuckoo search algorithm and Marine predators algorithm are also applied for the second solution method. The comparisons of result reveal that ECSA is more effective than these methods and the operation cost of the system can be minimized by ECSA. On the other hand, results from uncertainty and certainty of wind and solar also indicate that node 30 with higher LSF is more suitable than node 3 with lower LSF to place the PVP. As a result, it concludes that the second solution method and ECSA should be integrated to solve OPF for the integrated wind-solar-hydro-thermal power system.},
  archive      = {J_NCA},
  author       = {Pham, Ly Huu and Dinh, Bach Hoang and Nguyen, Thang Trung},
  doi          = {10.1007/s00521-022-07000-2},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10655-10689},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimal power flow for an integrated wind-solar-hydro-thermal power system considering uncertainty of wind speed and solar radiation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Proposed neural SAE-based medical image cryptography
framework using deep extracted features for smart IoT healthcare
applications. <em>NCA</em>, <em>34</em>(13), 10629–10653. (<a
href="https://doi.org/10.1007/s00521-022-06994-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image cryptography based on chaos algorithms is widely employed in modern security systems in telemedicine Internet of Things (IoT) applications. One of the main drawbacks of the state-of-the-art chaos encryption algorithms is that they are not sufficiently secure for image communications. When an image is only encrypted using traditional chaotic algorithms, it may be easily vulnerable to attackers. This paper presents a medical image cryptosystem, which uses a Stacked Auto-Encoder (SAE) network to produce two sets of chaotic random matrices. The first set is utilized to generate a complete shuffling matrix that changes the pixel locations in the digital input image. The second set generates an independent series of sequences employed to eradicate the correlation between the permuted encrypted medical image and the original image. The proposed cryptosystem is robust due to the benefits of parallel SAE computations, which significantly reduce the runtime and complexity. Moreover, the hybrid implementation of confusing and shuffling processes improves the ciphering performance. A comparative study between the proposed medical image cryptosystem and other related works is presented. The simulation tests reveal the security, efficiency, and immunity of the proposed cryptosystem for various forms of attacks compared to the traditional cryptosystems. The obtained results reveal that the suggested framework can be valuable and appropriate for medical sector services. It can be recommended for real-time healthcare cloud and IoT applications because of its superior accomplishments in terms of robustness, security, and computational complexity.},
  archive      = {J_NCA},
  author       = {El-Shafai, Walid and Khallaf, Fatma and El-Rabaie, El-Sayed M. and Abd El-Samie, Fathi E.},
  doi          = {10.1007/s00521-022-06994-z},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10629-10653},
  shortjournal = {Neural Comput. Appl.},
  title        = {Proposed neural SAE-based medical image cryptography framework using deep extracted features for smart IoT healthcare applications},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mineral deposit grade assessment using a hybrid model of
kriging and generalized regression neural network. <em>NCA</em>,
<em>34</em>(13), 10611–10627. (<a
href="https://doi.org/10.1007/s00521-022-06951-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks are powerful global approximators for mineral grade assessment. The techniques are capable of retaining nonlinearity and spatial heterogeneity of a feature variable and can even perform modelling with noisy and incomplete data. These qualifiers make neural networks strong contenders for mineral grade assessment. In the present research, the authors have proposed a hybrid model consisting of two unsupervised models, namely ordinary kriging (OK) and k-means clustering, used as pre-processing steps to feed data to supervised generalized regression neural network (GRNN) model. While OK models the spatial variability and provides estimation on local scale, k-means clustering has been used for dimensionality reduction. These steps support in achieving accuracy and speed of the modelling process. GRNN model prepares its training and validation datasets using the k-clusters. Testing and validation of the model have been carried out on five live iron-ore deposits. Once the validation is found adequate and acceptable generalization with validation dataset is achieved, the model is verified with testing dataset. Deposit-wise value of R2 of the hybrid GRNN model has been found to vary between 0.93 and 0.99. The model is observed to deliver improved performance when compared with multi-layer perceptron, radial basis function and recurrent neural network models. Spatially distributed estimation maps generated retain nonlinearity and spatial heterogeneity of the original Fe data values. Thus, the hybrid GRNN model provides an edge over the standalone classical geostatistics or standalone GRNN model.},
  archive      = {J_NCA},
  author       = {Singh, Rahul K. and Ray, D. and Sarkar, B. C.},
  doi          = {10.1007/s00521-022-06951-w},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10611-10627},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mineral deposit grade assessment using a hybrid model of kriging and generalized regression neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RETRACTED ARTICLE: Hybrid method for mining rules based on
enhanced apriori algorithm with sequential minimal optimization in
healthcare industry. <em>NCA</em>, <em>34</em>(13), 10597–10610. (<a
href="https://doi.org/10.1007/s00521-020-04862-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data mining may enable healthcare organizations, with analysis of the different prospects and connection between seemingly unrelated information, to anticipate trends in the patient’s medical condition and behavior. Raw data are large and heterogeneous from healthcare organizations. It needs to be collected and arranged, and its integration enables medical information systems to be integrated in a united way. Health data mining offers unlimited possibilities to evaluate numerous less obvious or secret data models utilizing common techniques for study. Association rule mining (ARM) is an effective technique for detecting the connection of the data which are the most commonly used and influential algorithms in ARM for an Apriori algorithm. However, it generates a large amount of rules and does not guarantee the efficiency and value of the knowledge created. In order to overcome this issue, an enhanced Apriori algorithm (EAA) based on the knowledge of a context ontology (EAA-SMO) methodology for sequential minimal optimization (SMO) is suggested. The simple knowledge is to establish the ideas of ontology as a hierarchical structure of the conceptual clusters of specific subjects, which comprises “similar” concepts that mean an exact category of the knowledge within the domain. There is an interesting rule for each cluster based on the correlation between the items. In addition, the rule developed is classified as a prediction model for anomaly detection based on SMO regression. The experimental analysis demonstrates the proposed method improved 2\% of accuracy and minimizes the execution time by 25\% when compared to semantic ontology.},
  archive      = {J_NCA},
  author       = {Sornalakshmi, M. and Balamurali, S. and Venkatesulu, M. and Navaneetha Krishnan, M. and Ramasamy, Lakshmana Kumar and Kadry, Seifedine and Manogaran, Gunasekaran and Hsu, Ching-Hsien and Muthu, Bala Anand},
  doi          = {10.1007/s00521-020-04862-2},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10597-10610},
  shortjournal = {Neural Comput. Appl.},
  title        = {RETRACTED ARTICLE: Hybrid method for mining rules based on enhanced apriori algorithm with sequential minimal optimization in healthcare industry},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep reinforcement learning process based on robotic
training to assist mental health patients. <em>NCA</em>,
<em>34</em>(13), 10587–10596. (<a
href="https://doi.org/10.1007/s00521-020-04855-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, robots are playing a vital role in healthcare applications to provide patients support and assistance in critical situations. The robots are trained by artificial intelligence systems which help to learn the robot according to their patient needs. However, the robots require the medical staff while diagnosing diseases with maximum accuracy, remote treatment, paralyzed patient treatment and so on. For these precise and accurate issues, an intelligent learning process is applied to train the robot to support the patient’s mental health and related task in this work. Initially, the patient health details are collected along with their simple daily routine, medical checkup information and other healthcare details. The gathered details are processed with the help of a deep reinforcement learning process used to get important information. The learning approach uses the state and action process to determine every patient’s needs and the respective assistance. Based on the information, robots are trained continuously to keep patient positive attitudes in their mental health problems. The excellence of the system is evaluated using experimental analysis in which the deep reinforcement system ensures a 0.083 error rate and 98.42\% accuracy.},
  archive      = {J_NCA},
  author       = {Altameem, Torki and Amoon, Mohammed and Altameem, Ayman},
  doi          = {10.1007/s00521-020-04855-1},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10587-10596},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep reinforcement learning process based on robotic training to assist mental health patients},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rule-based adversarial sample generation for text
classification. <em>NCA</em>, <em>34</em>(13), 10575–10586. (<a
href="https://doi.org/10.1007/s00521-022-07184-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Text Classification, modern neural networks have achieved great performance, but simultaneously, it is sensitive to adversarial examples. Existing studies usually use synonym replacement or token insertion strategies to generate adversarial examples. These strategies focus on obtaining semantically similar adversarial examples, but they ignore the richness of generating adversarial examples. To expand the richness of adversarial samples. Here, we propose a simple Rule-based Adversarial sample Generator (RAG) to generate adversarial samples by controlling the size of the perturbation added to the sentence matrix representation. Concretely, we introduce two methods to control the size of the added perturbation, i) Control the number of word replacements in sentences (RAG(R)); ii) Control the size of the offset value added to the sentence matrix representation (RAG(A)). Based on RAG, we will obtain numerous adversarial samples to make the model more robust to adversarial noise, and thereby improving the model’s generalization ability. Compared with the BERT and BiLSTM model baseline, experiments show that our method reduces the error rate by an average of 18\% on four standard training datasets. Especially in low-training data scenarios, the overall average accuracy is increased by 12\%. Extensive experimental results demonstrate that our method not only achieves excellent classification performance on the standard training datasets, but it still gets prominent performance on few-shot text classification.},
  archive      = {J_NCA},
  author       = {Zhou, Nai and Yao, Nianmin and Zhao, Jian and Zhang, Yanan},
  doi          = {10.1007/s00521-022-07184-7},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10575-10586},
  shortjournal = {Neural Comput. Appl.},
  title        = {Rule-based adversarial sample generation for text classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Frontal face reconstruction based on detail identification,
variable scale self-attention and flexible skip connection.
<em>NCA</em>, <em>34</em>(13), 10561–10573. (<a
href="https://doi.org/10.1007/s00521-022-07124-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstruction of the frontal face from the profile is of great significance for face recognition in complex scenes. The existing mainstream methods of face reconstruction, such as FF-GAN, CAPG-GAN, TP-GAN, etc., have made good progresses on improving the generator network, but fewer considerations on the identification of face details and the extraction of spatial context features. To address the problem, we propose the frontal face reconstruction based on the detail discrimination, variable scale self attention, and flexible skip connection (FR-DVF): designing a group of discriminators for multi-scale detail region identification, a novel encoder-decoder generator structure with a variable scale type of self-attention module, which inserts a max-pooling layer into the pathways of the traditional module to reduce its feature-dimension and computing-cost, and a flexible type of the skip-connections to alleviate the stiff property of the traditional connections between the encoder and decoder layers. After adding detail discrimination, variable scale self attention module, and flexible skip connection structure, the rank-1 recognition rate ( $$\%$$ ) of DVF-FR in the database of M2FPA increased by 2.94, 1.93 and 1.67 $$\%$$ , respectively, as well as that occurred in FERET.},
  archive      = {J_NCA},
  author       = {Luo, Haokun and Cen, Shengcai and Ding, Qichen and Chen, Xueyun},
  doi          = {10.1007/s00521-022-07124-5},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10561-10573},
  shortjournal = {Neural Comput. Appl.},
  title        = {Frontal face reconstruction based on detail identification, variable scale self-attention and flexible skip connection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FCSF-TABS: Two-stage abstractive summarization with
fact-aware reinforced content selection and fusion. <em>NCA</em>,
<em>34</em>(13), 10547–10560. (<a
href="https://doi.org/10.1007/s00521-021-06880-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, machine summarization models provide a new and efficient way for the rapid processing of massive text data. Generally, whether the fact descriptions in generated summaries are consistent with input text that is a critical metric in real-world tasks. However, most existing approaches based on standard likelihood training ignore this problem and only focus on improving the ROUGE scores. In this paper, we propose a two-stage Transformer-based abstractive summarization model to improve the factual correctness, denoted as FCSF-TABS. In the first stage, we use fine-tuned BERT classifier to perform content selection to select summary-worthy single sentences or adjacent sentence pairs in the input document. In the second stage, we feed the selected sentences into the Transformer-based summarization model to generate summary sentences. Furthermore, during the training, we also introduce the idea of reinforcement learning to jointly optimize a mixed-objective loss function. Specially, to train our model, we elaborately constructed two training sets by comprehensively considering informativeness and factual consistency. We conduct a lot of experiments on the CNN/DailyMail and XSum datasets. Experimental results show that our FCSF-TABS model not only improves the ROUGE scores, but also contains fewer factual errors in the generated summaries compared to some popular summarization models.},
  archive      = {J_NCA},
  author       = {Zhang, Mengli and Zhou, Gang and Yu, Wanting and Liu, Wenfen and Huang, Ningbo and Yu, Ze},
  doi          = {10.1007/s00521-021-06880-0},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10547-10560},
  shortjournal = {Neural Comput. Appl.},
  title        = {FCSF-TABS: Two-stage abstractive summarization with fact-aware reinforced content selection and fusion},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep LSTM network for the spanish electricity consumption
forecasting. <em>NCA</em>, <em>34</em>(13), 10533–10545. (<a
href="https://doi.org/10.1007/s00521-021-06773-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, electricity is a basic commodity necessary for the well-being of any modern society. Due to the growth in electricity consumption in recent years, mainly in large cities, electricity forecasting is key to the management of an efficient, sustainable and safe smart grid for the consumer. In this work, a deep neural network is proposed to address the electricity consumption forecasting in the short-term, namely, a long short-term memory (LSTM) network due to its ability to deal with sequential data such as time-series data. First, the optimal values for certain hyper-parameters have been obtained by a random search and a metaheuristic, called coronavirus optimization algorithm (CVOA), based on the propagation of the SARS-Cov-2 virus. Then, the optimal LSTM has been applied to predict the electricity demand with 4-h forecast horizon. Results using Spanish electricity data during nine years and half measured with 10-min frequency are presented and discussed. Finally, the performance of the proposed LSTM using random search and the LSTM using CVOA is compared, on the one hand, with that of recently published deep neural networks (such as a deep feed-forward neural network optimized with a grid search) and temporal fusion transformers optimized with a sampling algorithm, and, on the other hand, with traditional machine learning techniques, such as a linear regression, decision trees and tree-based ensemble techniques (gradient-boosted trees and random forest), achieving the smallest prediction error below 1.5\%.},
  archive      = {J_NCA},
  author       = {Torres, J. F. and Martínez-Álvarez, F. and Troncoso, A.},
  doi          = {10.1007/s00521-021-06773-2},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10533-10545},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep LSTM network for the spanish electricity consumption forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel convolutional neural networks for efficient
classification of rotated and scaled images. <em>NCA</em>,
<em>34</em>(13), 10519–10532. (<a
href="https://doi.org/10.1007/s00521-021-06645-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel method for improving the invariance of convolutional neural networks (CNNs) to selected geometric transformations in order to obtain more efficient image classifiers. A common strategy employed to achieve this aim is to train the network using data augmentation. Such a method alone, however, increases the complexity of the neural network model, as any change in the rotation or size of the input image results in the activation of different CNN feature maps. This problem can be resolved by the proposed novel convolutional neural network models with geometric transformations embedded into the network architecture. The evaluation of the proposed CNN model is performed on the image classification task with the use of diverse representative data sets. The CNN models with embedded geometric transformations are compared to those without the transformations, using different data augmentation setups. As the compared approaches use the same amount of memory to store the parameters, the improved classification score means that the proposed architecture is more optimal.},
  archive      = {J_NCA},
  author       = {Tarasiuk, Paweł and Szczepaniak, Piotr S.},
  doi          = {10.1007/s00521-021-06645-9},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10519-10532},
  shortjournal = {Neural Comput. Appl.},
  title        = {Novel convolutional neural networks for efficient classification of rotated and scaled images},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning and fuzzy logic to implement a hybrid wind
turbine pitch control. <em>NCA</em>, <em>34</em>(13), 10503–10517. (<a
href="https://doi.org/10.1007/s00521-021-06323-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on the control of the pitch angle of wind turbines. This is not an easy task due to the nonlinearity, the complex dynamics, and the coupling between the variables of these renewable energy systems. This control is even harder for floating offshore wind turbines, as they are subjected to extreme weather conditions and the disturbances of the waves. To solve it, we propose a hybrid system that combines fuzzy logic and deep learning. Deep learning techniques are used to estimate the current wind and to forecast the future wind. Estimation and forecasting are combined to obtain the effective wind which feeds the fuzzy controller. Simulation results show how including the effective wind improves the performance of the intelligent controller for different disturbances. For low and medium wind speeds, an improvement of 21\% is obtained respect to the PID controller, and 7\% respect to the standard fuzzy controller. In addition, an intensive analysis has been carried out on the influence of the deep learning configuration parameters in the training of the hybrid control system. It is shown how increasing the number of hidden units improves the training. However, increasing the number of cells while keeping the total number of hidden units decelerates the training.},
  archive      = {J_NCA},
  author       = {Sierra-Garcia, J. Enrique and Santos, Matilde},
  doi          = {10.1007/s00521-021-06323-w},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10503-10517},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning and fuzzy logic to implement a hybrid wind turbine pitch control},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimized convolutional neural network architectures for
efficient on-device vision-based object detection. <em>NCA</em>,
<em>34</em>(13), 10469–10501. (<a
href="https://doi.org/10.1007/s00521-021-06830-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks have pushed forward image analysis research and computer vision over the last decade, constituting a state-of-the-art approach in object detection today. The design of increasingly deeper and wider architectures has made it possible to achieve unprecedented levels of detection accuracy, albeit at the cost of both a dramatic computational burden and a large memory footprint. In such a context, cloud systems have become a mainstream technological solution due to their tremendous scalability, providing researchers and practitioners with virtually unlimited resources. However, these resources are typically made available as remote services, requiring communication over the network to be accessed, thus compromising the speed of response, availability, and security of the implemented solution. In view of these limitations, the on-device paradigm has emerged as a recent yet widely explored alternative, pursuing more compact and efficient networks to ultimately enable the execution of the derived models directly on resource-constrained client devices. This study provides an up-to-date review of the more relevant scientific research carried out in this vein, circumscribed to the object detection problem. In particular, the paper contributes to the field with a comprehensive architectural overview of both the existing lightweight object detection frameworks targeted to mobile and embedded devices, and the underlying convolutional neural networks that make up their internal structure. More specifically, it addresses the main structural-level strategies used for conceiving the various components of a detection pipeline (i.e., backbone, neck, and head), as well as the most salient techniques proposed for adapting such structures and the resulting architectures to more austere deployment environments. Finally, the study concludes with a discussion of the specific challenges and next steps to be taken to move toward a more convenient accuracy–speed trade-off.},
  archive      = {J_NCA},
  author       = {Rodriguez-Conde, Ivan and Campos, Celso and Fdez-Riverola, Florentino},
  doi          = {10.1007/s00521-021-06830-w},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10469-10501},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimized convolutional neural network architectures for efficient on-device vision-based object detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning-based ambient assisted living for
self-management of cardiovascular conditions. <em>NCA</em>,
<em>34</em>(13), 10449–10467. (<a
href="https://doi.org/10.1007/s00521-020-05678-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the World Health Organization, cardiovascular diseases contribute to 17.7 million deaths per year and are rising with a growing ageing population. In order to handle these challenges, the evolved countries are now evolving workable solutions based on new communication technologies such as ambient assisted living. In these solutions, the most well-known solutions are wearable devices for patient monitoring, telemedicine and mHealth systems. This systematic literature review presents the detailed literature on ambient assisted living solutions and helps to understand how ambient assisted living helps and motivates patients with cardiovascular diseases for self-management to reduce associated morbidity and mortalities. Preferred reporting items for systematic reviews and meta-analyses technique are used to answer the research questions. The paper is divided into four main themes, including self-monitoring wearable systems, ambient assisted living in aged populations, clinician management systems and deep learning-based systems for cardiovascular diagnosis. For each theme, a detailed investigation shows (1) how these new technologies are nowadays integrated into diagnostic systems and (2) how new technologies like IoT sensors, cloud models, machine and deep learning strategies can be used to improve the medical services. This study helps to identify the strengths and weaknesses of novel ambient assisted living environments for medical applications. Besides, this review assists in reducing the dependence on caregivers and the healthcare systems.},
  archive      = {J_NCA},
  author       = {Qureshi, Maria Ahmed and Qureshi, Kashif Naseer and Jeon, Gwanggil and Piccialli, Francesco},
  doi          = {10.1007/s00521-020-05678-w},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10449-10467},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-based ambient assisted living for self-management of cardiovascular conditions},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An ensemble-based convolutional neural network model powered
by a genetic algorithm for melanoma diagnosis. <em>NCA</em>,
<em>34</em>(13), 10429–10448. (<a
href="https://doi.org/10.1007/s00521-021-06655-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Melanoma is one of the main causes of cancer-related deaths. The development of new computational methods as an important tool for assisting doctors can lead to early diagnosis and effectively reduce mortality. In this work, we propose a convolutional neural network architecture for melanoma diagnosis inspired by ensemble learning and genetic algorithms. The architecture is designed by a genetic algorithm that finds optimal members of the ensemble. Additionally, the abstract features of all models are merged and, as a result, additional prediction capabilities are obtained. The diagnosis is achieved by combining all individual predictions. In this manner, the training process is implicitly regularized, showing better convergence, mitigating the overfitting of the model, and improving the generalization performance. The aim is to find the models that best contribute to the ensemble. The proposed approach also leverages data augmentation, transfer learning, and a segmentation algorithm. The segmentation can be performed without training and with a central processing unit, thus avoiding a significant amount of computational power, while maintaining its competitive performance. To evaluate the proposal, an extensive experimental study was conducted on sixteen skin image datasets, where state-of-the-art models were significantly outperformed. This study corroborated that genetic algorithms can be employed to effectively find suitable architectures for the diagnosis of melanoma, achieving in overall 11\% and 13\% better prediction performances compared to the closest model in dermoscopic and non-dermoscopic images, respectively. Finally, the proposal was implemented in a web application in order to assist dermatologists and it can be consulted at http://skinensemble.com .},
  archive      = {J_NCA},
  author       = {Pérez, Eduardo and Ventura, Sebastián},
  doi          = {10.1007/s00521-021-06655-7},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10429-10448},
  shortjournal = {Neural Comput. Appl.},
  title        = {An ensemble-based convolutional neural network model powered by a genetic algorithm for melanoma diagnosis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An ensemble of deep transfer learning models for handwritten
music symbol recognition. <em>NCA</em>, <em>34</em>(13), 10409–10427.
(<a href="https://doi.org/10.1007/s00521-021-06629-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In ancient times, there was no system to record or document music. A basic notation system to write European music was formulated around 14th century in the Baroque period which slowly evolved into the standard notation system that we have today. Later, the musical pieces from the classical and post-classical period of European music were documented as scores using this standard European staff notations. These notations are used by most of the modern genres of music due to their versatility. Hence, it is very important to develop a method that can store such music sheets containing handwritten music scores digitally. Optical music recognition (OMR) is a system that automatically interprets the scanned handwritten music scores. In this work, we have proposed a classifier ensemble of deep transfer learning models with support vector machine (SVM) as the aggregator for handwritten music symbol recognition. We have applied three pre-trained deep learning models, namely ResNet50, GoogleNet and DenseNet161 (each trained on ImageNet), and fine-tuned on our target datasets i.e., music symbol image datasets. The proposed ensemble technique can capture a more complex association of the base classifiers, thus improving the overall performance. We have evaluated the proposed model on five publicly available standard datasets, namely Handwritten Online Music Symbols (HOMUS), Capitan_Score_Uniform, Capitan_Score_Non-uniform, Rebelo_real and Fornés, and achieved state-of-the-art results for all these datasets. Additionally, we have evaluated our model on publicly available two non-music symbols datasets, namely CMATERdb 2.1.2 containing 120 handwritten Bangla city names and CMATERdb 3.1.1 dataset containing handwritten Bangla numerals to validate its effectiveness on diversified datasets. The source code of this present work is available at https://github.com/ashis0013/Music-Symbol-Recognition .},
  archive      = {J_NCA},
  author       = {Paul, Ashis and Pramanik, Rishav and Malakar, Samir and Sarkar, Ram},
  doi          = {10.1007/s00521-021-06629-9},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10409-10427},
  shortjournal = {Neural Comput. Appl.},
  title        = {An ensemble of deep transfer learning models for handwritten music symbol recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward hardware-aware deep-learning-based dialogue systems.
<em>NCA</em>, <em>34</em>(13), 10397–10408. (<a
href="https://doi.org/10.1007/s00521-020-05530-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few years, the use of transformer-based models has experienced increasing popularity as new state-of-the-art performance was achieved in several natural language processing tasks. As these models are often extremely large, however, their use for applications within embedded devices may not be feasible. In this work, we look at one such specific application, retrieval-based dialogue systems, that poses additional difficulties when deployed in environments characterized by limited resources. Research on building dialogue systems able to engage in natural sounding conversation with humans has attracted increasing attention in recent years. This has led to the rise of commercial conversational agents, such as Google Home, Alexa and Siri situated on embedded devices, that enable users to interface with a wide range of underlying functionalities in a natural and seamless manner. In part due to memory and computational power constraints, these agents necessitate frequent communication with a server in order to process the users’ queries. This communication may act as a bottleneck, resulting in delays as well as in the halt of the system should the network connection be lost or unavailable. We propose a new framework for hardware-aware retrieval-based dialogue systems based on the Dual-Encoder architecture, coupled with a clustering method to group candidates pertaining to a same conversation, that reduces storage capacity and computational power requirements.},
  archive      = {J_NCA},
  author       = {Pandelea, Vlad and Ragusa, Edoardo and Young, Tom and Gastaldo, Paolo and Cambria, Erik},
  doi          = {10.1007/s00521-020-05530-1},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10397-10408},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward hardware-aware deep-learning-based dialogue systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time polyp detection model using convolutional neural
networks. <em>NCA</em>, <em>34</em>(13), 10375–10396. (<a
href="https://doi.org/10.1007/s00521-021-06496-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer is a major health problem, where advances towards computer-aided diagnosis (CAD) systems to assist the endoscopist can be a promising path to improvement. Here, a deep learning model for real-time polyp detection based on a pre-trained YOLOv3 (You Only Look Once) architecture and complemented with a post-processing step based on an object-tracking algorithm to reduce false positives is reported. The base YOLOv3 network was fine-tuned using a dataset composed of 28,576 images labelled with locations of 941 polyps that will be made public soon. In a frame-based evaluation using isolated images containing polyps, a general F1 score of 0.88 was achieved (recall = 0.87, precision = 0.89), with lower predictive performance in flat polyps, but higher for sessile, and pedunculated morphologies, as well as with the usage of narrow band imaging, whereas polyp size &lt; 5 mm does not seem to have significant impact. In a polyp-based evaluation using polyp and normal mucosa videos, with a positive criterion defined as the presence of at least one 50-frames-length (window size) segment with a ratio of 75\% of frames with predicted bounding boxes (frames positivity), 72.61\% of sensitivity (95\% CI 68.99–75.95) and 83.04\% of specificity (95\% CI 76.70–87.92) were achieved (Youden = 0.55, diagnostic odds ratio (DOR) = 12.98). When the positive criterion is less stringent (window size = 25, frames positivity = 50\%), sensitivity reaches around 90\% (sensitivity = 89.91\%, 95\% CI 87.20–91.94; specificity = 54.97\%, 95\% CI 47.49–62.24; Youden = 0.45; DOR = 10.76). The object-tracking algorithm has demonstrated a significant improvement in specificity whereas maintaining sensitivity, as well as a marginal impact on computational performance. These results suggest that the model could be effectively integrated into a CAD system.},
  archive      = {J_NCA},
  author       = {Nogueira-Rodríguez, Alba and Domínguez-Carbajales, Rubén and Campos-Tato, Fernando and Herrero, Jesús and Puga, Manuel and Remedios, David and Rivas, Laura and Sánchez, Eloy and Iglesias, Águeda and Cubiella, Joaquín and Fdez-Riverola, Florentino and López-Fernández, Hugo and Reboiro-Jato, Miguel and Glez-Peña, Daniel},
  doi          = {10.1007/s00521-021-06496-4},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10375-10396},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time polyp detection model using convolutional neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Federated meta-learning for spatial-temporal prediction.
<em>NCA</em>, <em>34</em>(13), 10355–10374. (<a
href="https://doi.org/10.1007/s00521-021-06861-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial-temporal prediction is a fundamental problem for constructing smart city, and existing approaches by deep learning models have achieved excellent success based on a large volume of datasets. However, data privacy of cities becomes the public concerns in recent years. Therefore, how to develop accurate spatial-temporal prediction while preserving privacy is a significant problem. To address this challenge, we propose a privacy-preserving spatial-temporal prediction technique via federated learning (FL). Due to inherent non-independent identically distributed (non-IID) characteristic of spatial-temporal data, the basic FL-based method cannot deal with this data heterogeneity well by sharing global model; furthermore, we propose the personalized federated learning methods based on meta-learning. We automatically construct the global spatial-temporal pattern graph under a data federation. This global pattern graph incorporates and memorizes the local learned patterns of all of the clients, and each client leverages those global patterns to customize its own model by evaluating the difference between global and local pattern graph. Then, each client could use this customized parameters as its model initialization parameters for spatial-temporal prediction tasks. We conduct extensive experiments on bike sharing datasets to demonstrate the superiority and effectiveness of our methods in privacy protection settings.},
  archive      = {J_NCA},
  author       = {Li, Wenzhu and Wang, Shuang},
  doi          = {10.1007/s00521-021-06861-3},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10355-10374},
  shortjournal = {Neural Comput. Appl.},
  title        = {Federated meta-learning for spatial-temporal prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Combined angular margin and cosine margin softmax loss for
music classification based on spectrograms. <em>NCA</em>,
<em>34</em>(13), 10337–10353. (<a
href="https://doi.org/10.1007/s00521-022-06896-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectrograms provide rich feature information of music data. Significant progress has been made in music classification using spectrograms and Convolutional Neural Networks (CNNs). However, the softmax loss commonly used in existing CNNs lacks sufficient power to discriminate deep features of music. To overcome this limitation, we propose a Combined Angular Margin and Cosine Margin Softmax Loss (AMCM-Softmax) approach in this paper to enhance intra-class compactness and inter-class discrepancy simultaneously. Specifically, normalization on the weight vectors and feature vectors is adopted to eliminate radial variations. Then, an angular margin parameter and a cosine margin parameter are introduced to maximize the decision margin by enforcing angular and cosine margin constraints. Consequently, the discrimination of features is enhanced by normalization and margin maximization. The decision boundary and the target logit curve of AMCM-Softmax can provide a clear geometric interpretation. Extensive experiments on music datasets show that AMCM-Softmax consistently outperforms the current state-of-the-art approaches in classifying genre and emotion. Our work also shows that a margin loss function can lead to better performance and be used in an advanced CNN model for music classification.},
  archive      = {J_NCA},
  author       = {Li, Jingxian and Han, Lixin and Wang, Yang and Yuan, Baohua and Yuan, Xiaofeng and Yang, Yi and Yan, Hong},
  doi          = {10.1007/s00521-022-06896-0},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10337-10353},
  shortjournal = {Neural Comput. Appl.},
  title        = {Combined angular margin and cosine margin softmax loss for music classification based on spectrograms},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Iterative neural networks for adaptive inference on
resource-constrained devices. <em>NCA</em>, <em>34</em>(13),
10321–10336. (<a
href="https://doi.org/10.1007/s00521-022-06910-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computational cost of evaluating a neural network usually only depends on design choices such as the number of layers or the number of units in each layer and not on the actual input. In this work, we build upon deep Residual Networks (ResNets) and use their properties to design a more efficient adaptive neural network building block. We propose a new architecture, which replaces the sequential layers with an iterative structure where weights are reused multiple times for a single input image, reducing the storage requirements drastically. In addition, we incorporate an adaptive computation module that allows the network to adjust its computational cost at run time for each input sample independently. We experimentally validate our models on image classification, object detection and semantic segmentation tasks and show that our models only use their full capacity for the hardest input samples and are more efficient on average.},
  archive      = {J_NCA},
  author       = {Leroux, Sam and Verbelen, Tim and Simoens, Pieter and Dhoedt, Bart},
  doi          = {10.1007/s00521-022-06910-5},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10321-10336},
  shortjournal = {Neural Comput. Appl.},
  title        = {Iterative neural networks for adaptive inference on resource-constrained devices},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Suicidal ideation and mental disorder detection with
attentive relation networks. <em>NCA</em>, <em>34</em>(13), 10309–10319.
(<a href="https://doi.org/10.1007/s00521-021-06208-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mental health is a critical issue in modern society, and mental disorders could sometimes turn to suicidal ideation without effective treatment. Early detection of mental disorders and suicidal ideation from social content provides a potential way for effective social intervention. However, classifying suicidal ideation and other mental disorders is challenging as they share similar patterns in language usage and sentimental polarity. This paper enhances text representation with lexicon-based sentiment scores and latent topics and proposes using relation networks to detect suicidal ideation and mental disorders with related risk indicators. The relation module is further equipped with the attention mechanism to prioritize more critical relational features. Through experiments on three real-world datasets, our model outperforms most of its counterparts.},
  archive      = {J_NCA},
  author       = {Ji, Shaoxiong and Li, Xue and Huang, Zi and Cambria, Erik},
  doi          = {10.1007/s00521-021-06208-y},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10309-10319},
  shortjournal = {Neural Comput. Appl.},
  title        = {Suicidal ideation and mental disorder detection with attentive relation networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using a multi-view convolutional neural network to monitor
solar irradiance. <em>NCA</em>, <em>34</em>(13), 10295–10307. (<a
href="https://doi.org/10.1007/s00521-021-05959-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last years, there is an increasing interest for enhanced method for assessing and monitoring the level of the global horizontal irradiance (GHI) in photovoltaic (PV) systems, fostered by the massive deployment of this energy. Thermopile or photodiode pyranometers provide point measurements, which may not be adequate in cases when areal information is important (as for PV network or large PV plants monitoring). The use of All Sky Imagers paired convolutional neural networks, a powerful technique for estimation, has been proposed as a plausible alternative. In this work, a convolutional neural network architecture is presented to estimate solar irradiance from sets of ground-level Total Sky Images. This neural network is capable of combining images from three cameras. Results show that this approach is more accurate than using only images from a single camera. It has also been shown to improve the performance of two other approaches: a cloud fraction model and a feature extraction model.},
  archive      = {J_NCA},
  author       = {Huertas-Tato, Javier and Galván, Inés M. and Aler, Ricardo and Rodríguez-Benítez, Francisco Javier and Pozo-Vázquez, David},
  doi          = {10.1007/s00521-021-05959-y},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10295-10307},
  shortjournal = {Neural Comput. Appl.},
  title        = {Using a multi-view convolutional neural network to monitor solar irradiance},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cognitive name-face association through context-aware graph
neural network. <em>NCA</em>, <em>34</em>(13), 10279–10293. (<a
href="https://doi.org/10.1007/s00521-021-06617-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extraction of valuable insights from unstructured content has attracted much attention in the last decades. Main results lie in the area of text mining, while the understanding of multimedia contents, thanks to the improvements in computer vision, mainly relies on adopting emerging deep learning models. About image understanding, people’s name association in images is still an open issue. The approaches at the state of the art mainly use facial features and find the corresponding names by extracting the most recurring entities in the attached captions. These methods are experimented for celebrities and often fail when few labeled samples are available or there are particular poses. The proposed solution tries to improve the name–face association in such cases by defining a cognitive layer for a deep learning architecture embedding the surrounding context of the entities in the caption or the image. The method mainly focuses on name–face association as enabling technology for people recognition in open-source intelligence frameworks that mostly investigate not popular (or unknown) people. Given a face, the proposed system predicts the most likely corresponding name leveraging image features, caption, and context. The learning model embeds the knowledge graph of the context elicited in the open sources through a graph neural network. The experimentation highlights that the context improves the results of the name–face association, especially when other methods fail.},
  archive      = {J_NCA},
  author       = {Fenza, Giuseppe and Gallo, Mariacristina and Loia, Vincenzo and Volpe, Alberto},
  doi          = {10.1007/s00521-021-06617-z},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10279-10293},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cognitive name-face association through context-aware graph neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the post-hoc explainability of deep echo state networks
for time series forecasting, image and video classification.
<em>NCA</em>, <em>34</em>(13), 10257–10277. (<a
href="https://doi.org/10.1007/s00521-021-06359-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since their inception, learning techniques under the reservoir computing paradigm have shown a great modeling capability for recurrent systems without the computing overheads required for other approaches, specially deep neural networks. Among them, different flavors of echo state networks have attracted many stares through time, mainly due to the simplicity and computational efficiency of their learning algorithm. However, these advantages do not compensate for the fact that echo state networks remain as black-box models whose decisions cannot be easily explained to the general audience. This issue is even more involved for multi-layered (also referred to as deep) echo state networks, whose more complex hierarchical structure hinders even further the explainability of their internals to users without expertise in machine learning or even computer science. This lack of explainability can jeopardize the widespread adoption of these models in certain domains where accountability and understandability of machine learning models is a must (e.g., medical diagnosis, social politics). This work addresses this issue by conducting an explainability study of echo state networks when applied to learning tasks with time series, image and video data. Among these tasks, we stress on the latter one (video classification) which, to the best of our knowledge, has never been tackled before with echo state networks in the related literature. Specifically, the study proposes three different techniques capable of eliciting understandable information about the knowledge grasped by these recurrent models, namely potential memory, temporal patterns and pixel absence effect. Potential memory addresses questions related to the effect of the reservoir size in the capability of the model to store temporal information, whereas temporal patterns unveil the recurrent relationships captured by the model over time. Finally, pixel absence effect attempts at evaluating the effect of the absence of a given pixel when the echo state network model is used for image and video classification. The benefits of the proposed suite of techniques are showcased over three different domains of applicability: time series modeling, image and, for the first time in the related literature, video classification. The obtained results reveal that the proposed techniques not only allow for an informed understanding of the way these models work, but also serve as diagnostic tools capable of detecting issues inherited from data (e.g., presence of hidden bias).},
  archive      = {J_NCA},
  author       = {Barredo Arrieta, Alejandro and Gil-Lopez, Sergio and Laña, Ibai and Bilbao, Miren Nekane and Del Ser, Javier},
  doi          = {10.1007/s00521-021-06359-y},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10257-10277},
  shortjournal = {Neural Comput. Appl.},
  title        = {On the post-hoc explainability of deep echo state networks for time series forecasting, image and video classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep embedded refined clustering approach for breast
cancer distinction based on DNA methylation. <em>NCA</em>,
<em>34</em>(13), 10243–10255. (<a
href="https://doi.org/10.1007/s00521-021-06357-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epigenetic alterations have an important role in the development of several types of cancer. Epigenetic studies generate a large amount of data, which makes it essential to develop novel models capable of dealing with large-scale data. In this work, we propose a deep embedded refined clustering method for breast cancer differentiation based on DNA methylation. In concrete, the deep learning system presented here uses the levels of CpG island methylation between 0 and 1. The proposed approach is composed of two main stages. The first stage consists in the dimensionality reduction of the methylation data based on an autoencoder. The second stage is a clustering algorithm based on the soft assignment of the latent space provided by the autoencoder. The whole method is optimized through a weighted loss function composed of two terms: reconstruction and classification terms. To the best of the authors’ knowledge, no previous studies have focused on the dimensionality reduction algorithms linked to classification trained end-to-end for DNA methylation analysis. The proposed method achieves an unsupervised clustering accuracy of 0.9927 and an error rate (\%) of 0.73 on 137 breast tissue samples. After a second test of the deep-learning-based method using a different methylation database, an accuracy of 0.9343 and an error rate (\%) of 6.57 on 45 breast tissue samples are obtained. Based on these results, the proposed algorithm outperforms other state-of-the-art methods evaluated under the same conditions for breast cancer classification based on DNA methylation data.},
  archive      = {J_NCA},
  author       = {Amor, Rocío del and Colomer, Adrián and Monteagudo, Carlos and Naranjo, Valery},
  doi          = {10.1007/s00521-021-06357-0},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10243-10255},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep embedded refined clustering approach for breast cancer distinction based on DNA methylation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Citation recommendation employing heterogeneous
bibliographic network embedding. <em>NCA</em>, <em>34</em>(13),
10229–10242. (<a
href="https://doi.org/10.1007/s00521-021-06135-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The massive number of research articles on the Web makes it troublesome for researchers to identify related works that could meet their preferences and interests. Consequently, various network representation learning-based models have been proposed to produce citation recommendations. Nevertheless, these models do not exploit semantic relations and contextual information between the objects of bibliographic papers’ networks, which can result in inadequate citation recommendations. Moreover, existing citation recommendation methods face problems such as lack of personalization, cold-start, and network sparsity. To mitigate such problems and produce individualized citation recommendations, we propose a heterogeneous network embedding model that jointly learns node representations by exploiting semantics corresponding to the author, time, context, field of study, citations, and topics. Compared to baseline models, the results produced by the proposed model over the DBLP datasets prove 10\% and 12\% improvement on mean average precision (MAP) and normalized discounted cumulative gain (nDCG@10) metrics, respectively. Also, the effectiveness of our model is analyzed on the cold-start papers and network sparsity problems, where it gains 12\% and 9\% better MAP and recall@10 scores, respectively.},
  archive      = {J_NCA},
  author       = {Ali, Zafar and Qi, Guilin and Muhammad, Khan and Bhattacharyya, Siddhartha and Ullah, Irfan and Abro, Waheed},
  doi          = {10.1007/s00521-021-06135-y},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10229-10242},
  shortjournal = {Neural Comput. Appl.},
  title        = {Citation recommendation employing heterogeneous bibliographic network embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning-based resource usage prediction model for
resource provisioning in an autonomic cloud computing environment.
<em>NCA</em>, <em>34</em>(13), 10211–10228. (<a
href="https://doi.org/10.1007/s00521-021-06665-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing enables clients to acquire cloud resources dynamically and on demand for their cloud applications and services. For cloud providers, especially, Software as a Service (SaaS) providers, the prediction of future cloud resource requirements, such as CPU usage for their cloud applications, to implement client requests is a complex task because it depends on incoming workloads. Due to workload fluctuations, it is difficult for SaaS cloud providers to predict or forecast future demand for resource usage in the next time interval and, accordingly, to allocate the required resources. Furthermore, cloud computing systems consist of many virtual machines (VMs), which increases the complexity of the prediction problem due to the correlations that exist between the large workload data in these VMs. Therefore, accurate resource usage forecasting remains a challenge, and relatively few studies have explored the prediction of CPU usage for VMs in cloud data centers. This paper proposes an autonomic and intelligent workload forecasting method for cloud resource provisioning based on the concept of autonomic computing and a deep learning approach. In particular, to predict future demand for CPU usage and determine how to respond to workload fluctuations in the next interval, we propose an efficient deep learning model based on a diffusion convolutional recurrent neural network (DCRNN). Existing deep learning models that are widely applied cannot handle accurate real-time forecasting due to the presence of inconsistent and nonlinear workloads in cloud computing systems. The goal of the proposed deep learning model is to improve forecasting accuracy and minimize the error between the predicted and the actual workloads. The effectiveness of the proposed DCRNN-based deep learning model was evaluated using experiments on a real-world dataset of PlanetLab’s CPU usage traces. The results indicate that the proposed approach outperformed other existing deep learning models, achieving a mean absolute percentage error of 0.18 and root-mean-square error of 2.40.},
  archive      = {J_NCA},
  author       = {Al-Asaly, Mahfoudh Saeed and Bencherif, Mohamed A. and Alsanad, Ahmed and Hassan, Mohammad Mehedi},
  doi          = {10.1007/s00521-021-06665-5},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10211-10228},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning-based resource usage prediction model for resource provisioning in an autonomic cloud computing environment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent advances on effective and efficient deep
learning-based solutions. <em>NCA</em>, <em>34</em>(13), 10205–10210.
(<a href="https://doi.org/10.1007/s00521-022-07344-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This editorial briefly analyses, describes, and provides a short summary of a set of selected papers published in a special issue focused on deep learning methods and architectures and their application to several domains and research areas. The set of selected and published articles covers several aspects related to two basic aspects in deep learning (DL) methods, efficiency of the models and effectiveness of the architectures These papers revolve around different interesting application domains such as health (e.g. cancer, polyps, melanoma, mental health), wearable technologies solar irradiance, social networks, cloud computing, wind turbines, object detection, music, and electricity, among others. This editorial provides a short description of each published article and a brief analysis of their main contributions.},
  archive      = {J_NCA},
  author       = {Martín, Alejandro and Camacho, David},
  doi          = {10.1007/s00521-022-07344-9},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {10205-10210},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recent advances on effective and efficient deep learning-based solutions},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). STMG: Swin transformer for multi-label image recognition
with graph convolution network. <em>NCA</em>, <em>34</em>(12),
10051–10063. (<a
href="https://doi.org/10.1007/s00521-022-06990-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformer (ViT) has achieved promising single-label image classification results compared to conventional neural network-based models. Nevertheless, few ViT related studies have explored the label dependencies in the multi-label image recognition field. To this end, we propose STMG that combines transformer and graph convolution network (GCN) to extract the image features and learn the label dependencies for multi-label image recognition. STMG consists of an image representation learning module and a label co-occurrence embedding module. Firstly, in the image representation learning module, to avoid computing the similarity between each two patches, we adopt Swin transformer instead of ViT to generate the image feature for each input image. Secondly, in the label co-occurrence embedding module, we design a two-layer GCN to adaptively capture the label dependencies to output the label co-occurrence embeddings. At last, STMG fuses the image feature and label co-occurrence embeddings to produce the image classification results with the commonly-used multi-label classification loss function and a L2-norm loss function. We conduct extensive experiments on two multi-label image datasets including MS-COCO and FLICKR25K. Experimental results demonstrate STMG can achieve better performance including the convergence efficiency and classification results compared to the state-of-the-art multi-label image recognition methods. Our code is open-sourced and publicly available on GitHub: https://github.com/lzHZWZ/STMG.},
  archive      = {J_NCA},
  author       = {Wang, Yangtao and Xie, Yanzhao and Fan, Lisheng and Hu, Guangxing},
  doi          = {10.1007/s00521-022-06990-3},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {10051-10063},
  shortjournal = {Neural Comput. Appl.},
  title        = {STMG: Swin transformer for multi-label image recognition with graph convolution network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dual-stream shadow detection network: Biologically inspired
shadow detection for remote sensing images. <em>NCA</em>,
<em>34</em>(12), 10039–10049. (<a
href="https://doi.org/10.1007/s00521-022-06989-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has achieved state-of-the-art results in various image classification and image segmentation tasks. However, due to the lack of well-labeled datasets, the insufficiency of deep feature extraction, and the complexity of the distribution of shadows on remote sensing images, popular deep neural networks still fall short on satisfactory shadow detection from remote sensing images. Inspired by the brain&#39;s mechanism for processing visual signals, this paper proposes a new Dual-stream Shadow Detection Network (DSSDN) that is specifically designed for detecting shadows on remote sensing images. In DSSDN, the pooling stream extracts high-level features by merging multiple atrous pooling feature maps after the encoder, while the residual stream maintains low-level features and carries out the interaction of dual-stream features. This network is also featured with three new sub-modules. We manually labeled 1724 remote sensing images with shadows to form a new dataset for training and testing of DSSDN. In the quantitative contrast experiment on this dataset, DSSDN reaches the lowest Balanced Error Rate (BER) at 6.6\% across all compared models and networks. In the qualitative analysis, the detected shadows of DSSDN also show best contours and details in comparison with results from other approaches.},
  archive      = {J_NCA},
  author       = {Li, Dawei and Wang, Sifan and Xiang, Shiyu and Li, Jinsheng and Yang, Yanping and Tang, Xue-Song},
  doi          = {10.1007/s00521-022-06989-w},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {10039-10049},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dual-stream shadow detection network: Biologically inspired shadow detection for remote sensing images},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Improving actor-critic structure by relatively optimal
historical information for discrete system. <em>NCA</em>,
<em>34</em>(12), 10023–10037. (<a
href="https://doi.org/10.1007/s00521-022-06988-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, actor-critic structure based neural networks are widely used in many reinforcement learning tasks. It consists of two main parts: (i) an actor module which outputs the probability distribution of action, and (ii) a critic module which outputs the predicted value based on the current environment. Actor-critic structure based networks usually need expert demonstration to provide an appropriate pre-training for the actor module, but the demonstration data is often hard or even impossible to obtain. And most of them, such as those used in the maze and robot control tasks, suffer from a lack of proper pre-training and unstable error propagation from the critic module to the actor module, which would result in poor and unstable performance. Therefore, a specially designed module which is called relatively optimal historical information learning (ROHI) is proposed. The proposed ROHI module can record the historical explored information and obtain the relatively optimal information through a customized merging algorithm. Then, the relatively optimal historical information is used to assist in training the actor module during the main learning process. We introduce two complex experimental environments, including the complex maze problem and flipping game, to evaluate the effectiveness of the proposed module. The experimental results demonstrate that the extended models with ROHI can significantly improve the success rate of the original actor-critic structure based models and slightly decrease the number of iteration required to reach the stable phase of value-based networks.},
  archive      = {J_NCA},
  author       = {Zhang, Xinyu and Li, Weidong and Zhu, Xiaoke and Jing, Xiao-Yuan},
  doi          = {10.1007/s00521-022-06988-x},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {10023-10037},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving actor-critic structure by relatively optimal historical information for discrete system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Iterative facial image inpainting based on an
encoder-generator architecture. <em>NCA</em>, <em>34</em>(12),
10001–10021. (<a
href="https://doi.org/10.1007/s00521-022-06987-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial image inpainting is a challenging problem as it requires generating new pixels that include semantic information for masked key components in a face, e.g., eyes and nose. Recently, remarkable methods have been proposed in this field. Most of these approaches use encoder–decoder architectures and have different limitations such as allowing unique results for a given image and a particular mask. Alternatively, some optimization-based approaches generate promising results using different masks with generator networks. However, these approaches are computationally more expensive. In this paper, we propose an efficient solution to the facial image painting problem using the Cyclic Reverse Generator (CRG) architecture, which provides an encoder-generator model. We use the encoder to embed a given image to the generator space and incrementally inpaint the masked regions until a plausible image is generated; we trained a discriminator model to assess the quality of the generated images during the iterations and determine the convergence. After the generation process, for the post-processing, we utilize a Unet model that we trained specifically for this task to remedy the artifacts close to the mask boundaries. We empirically observed that even in the absence of important facial features, the encoder model is capable of embedding images in semantically rich regions in the latent space, utilizing the surrounding context in the images. Cultivating the feedback loop between the encoder and generator gradually improves the missing content in the images in an iterative fashion, and only a few iterations are sufficient to generate realistic content. Since the models are not trained for particular mask types, our method allows applying sketch-based inpaintings, using a variety of mask types, and producing multiple and diverse results. We compared our method with the state-of-the-art models both quantitatively and qualitatively, and observed that our method can compete with the other models in all mask types; it is particularly better in images where larger masks are utilized. Our code, dataset and models are available at: https://github.com/yahyadogan72/iterative_facial_image_inpainting.},
  archive      = {J_NCA},
  author       = {Dogan, Yahya and Keles, Hacer Yalim},
  doi          = {10.1007/s00521-022-06987-y},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {10001-10021},
  shortjournal = {Neural Comput. Appl.},
  title        = {Iterative facial image inpainting based on an encoder-generator architecture},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using neurocomputing techniques to determine microstructural
properties in a li-ion battery. <em>NCA</em>, <em>34</em>(12),
9983–9999. (<a
href="https://doi.org/10.1007/s00521-022-06985-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current ab-initio approaches such as Quantum Mechanics (QM) calculations or Molecular Dynamics (MD) simulations to study the doped cathode structures are computationally expensive. In this work, we present the development and application of neural computing models to study the crystal structure of the cathode materials in Lithium-ion batteries, Lithium Manganese Oxide (LMO) in particular. We do this using LMO crystal configurations doped with Aluminum. We successfully demonstrate the application of 8 multi-layer perceptron models that are capable of predicting the potential energy of LMO crystal configurations, with coefficients of determination ( $$R^2$$ ) ranging from 0.95 to 0.98. To achieve this, models were developed by training and testing them on the potential energy (eV) values of over 460,000 crystal configurations. In lithium-ion battery research, the developed Neural Network models could be utilized alongside existing atomic or molecular simulation tools to efficiently identify optimal crystal configurations that could be subjected to more detailed investigation. With the integration of the multi-layer perceptron models of this work, the total time to evaluate all possible crystal configurations can be reduced by approximately 88\% than when using just QM and MD simulations for such evaluations.},
  archive      = {J_NCA},
  author       = {Sandhu, Simran and Tyagi, Ramavtar and Talaie, Elahe and Srinivasan, Seshasai},
  doi          = {10.1007/s00521-022-06985-0},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9983-9999},
  shortjournal = {Neural Comput. Appl.},
  title        = {Using neurocomputing techniques to determine microstructural properties in a li-ion battery},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conversion of siamese networks to spiking neural networks
for energy-efficient object tracking. <em>NCA</em>, <em>34</em>(12),
9967–9982. (<a
href="https://doi.org/10.1007/s00521-022-06984-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, spiking neural networks (SNNs), the third generation of neural networks, have shown remarkable capabilities of energy-efficient computing, which is a promising alternative for artificial neural networks (ANNs) with high energy consumption. SNNs have reached competitive results compared to ANNs in relatively simple tasks and small datasets such as image classification and MNIST/CIFAR, while few studies on more challenging vision tasks on complex datasets. In this paper, we focus on extending deep SNNs to object tracking, a more advanced vision task with embedded applications and energy-saving requirements. We present a spike-based Siamese network called SiamSNN, which is converted from fully convolutional Siamese networks. Specifically, we propose a spiking correlation layer to evaluate the similarity between two spiking feature maps, and introduce a novel two-status coding scheme to optimize the temporal distribution of output spike trains for further improvements. SiamSNN is the first deep SNN tracker that achieves short latency and low precision degradation on the visual object tracking benchmarks OTB-2013, OTB-2015, VOT-2016, VOT-2018, and GOT-10k. Moreover, SiamSNN achieves notably low energy consumption and real-time on Neuromorphic chip TrueNorth.},
  archive      = {J_NCA},
  author       = {Luo, Yihao and Shen, Haibo and Cao, Xiang and Wang, Tianjiang and Feng, Qi and Tan, Zehan},
  doi          = {10.1007/s00521-022-06984-1},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9967-9982},
  shortjournal = {Neural Comput. Appl.},
  title        = {Conversion of siamese networks to spiking neural networks for energy-efficient object tracking},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The multi-mode operation decision of cleaning robot based on
curriculum learning strategy and feedback network. <em>NCA</em>,
<em>34</em>(12), 9955–9966. (<a
href="https://doi.org/10.1007/s00521-022-06980-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the model and its curriculum learning method of garbage hierarchical classification and corresponding operation mode decision in home environment are proposed from the perspective of cleaning robot. In order to realize the hierarchical learning of garbage attribute concept, this paper designs a learning model with iterative feedback network as the backbone network. In the early stage of iteration, the model focuses on learning the state of garbage, in the middle stage, it focuses on the appearance attributes of garbage, and the specific categories of garbage in the later stage. At the same time, the attention module is introduced to achieve different levels of feature expression learning, which further improves the performance of the model. The evaluation was conducted on the collected garbage data set and the public CIFAR-100 and Stanford Cars data sets, which verified the effectiveness and wide applicability of the proposed method.},
  archive      = {J_NCA},
  author       = {Fu, Panbo and Zhang, Dongbo and Yin, Feng and Tang, Hongzhong},
  doi          = {10.1007/s00521-022-06980-5},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9955-9966},
  shortjournal = {Neural Comput. Appl.},
  title        = {The multi-mode operation decision of cleaning robot based on curriculum learning strategy and feedback network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Electricity generation cost reduction for hydrothermal
systems with the presence of pumped storage hydroelectric plants.
<em>NCA</em>, <em>34</em>(12), 9931–9953. (<a
href="https://doi.org/10.1007/s00521-022-06977-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the applications of novel metaheuristic algorithms including equilibrium optimization (EO), coot optimization, and slime mould optimization together with three Particle swarm optimization variants for optimal power generation cooperation of power systems with conventional hydroelectric power plants, thermal power plants and especially pumped-storage hydroelectric plants (PHPs). Three different power systems are applied to run these algorithms to prove that PHPs have a significant contribution to the generation cost reduction. In the first two systems, there are not inflows to the upper reservoirs of the PHPs and these plants only produce electricity by using pumped water. In the third system, inflows to PHPs are considered. The requirement is that the volume of reservoir at the beginning and the end of a day must be the same. However, the generation cost for the cases with the operation of PHPs is much less than other cases without the PHPs or without the pump mode of PHP. About the generation cost of three systems, PHPs support to reach the saving cost of $1,222.1998, $89,091.16, and $94,449.2 corresponding to 0.45\%, 3\% and 3.4\%, respectively. So, the PHPs should be run in power systems. Among the six applied methods, EO is the best since it can reach less cost than others from higher than 2\% to under 8\%. Hence, it is recommended that EO is a potential method for finding optimal operation parameters of power systems with the PHPs.},
  archive      = {J_NCA},
  author       = {Ha, Phu Trieu and Tran, Dao Trong and Nguyen, Thang Trung},
  doi          = {10.1007/s00521-022-06977-0},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9931-9953},
  shortjournal = {Neural Comput. Appl.},
  title        = {Electricity generation cost reduction for hydrothermal systems with the presence of pumped storage hydroelectric plants},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New inequalities to finite-time synchronization analysis of
delayed fractional-order quaternion-valued neural networks.
<em>NCA</em>, <em>34</em>(12), 9919–9930. (<a
href="https://doi.org/10.1007/s00521-022-06976-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to overcome the complexity of the theoretical analysis caused by using decomposition method to explore the finite-time synchronization behavior of fractional-order quaternion-valued neural networks (FOQVNNs), we aim to deal with this problem directly instead of decomposition. Firstly, two inequalities about quaternion are developed to broaden the current achievements in quaternion field. Secondly, a fractional differential inequality is established by using Laplace transform and applying the definition of Mittag-Leffler function. Then, by employing the presented inequalities and two different quaternion control strategies, some new conditions are derived to guarantee the finite-time synchronization of the delayed FOQVNNs. Finally, two numerical examples are given to illustrate the correctness of the main results.},
  archive      = {J_NCA},
  author       = {Yan, Hongyun and Qiao, Yuanhua and Duan, Lijuan and Miao, Jun},
  doi          = {10.1007/s00521-022-06976-1},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9919-9930},
  shortjournal = {Neural Comput. Appl.},
  title        = {New inequalities to finite-time synchronization analysis of delayed fractional-order quaternion-valued neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interpretable modular knowledge reasoning for machine
reading comprehension. <em>NCA</em>, <em>34</em>(12), 9901–9918. (<a
href="https://doi.org/10.1007/s00521-022-06975-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine reading comprehension (MRC) is a fundamental task of evaluating the natural language understanding ability of model, which requires complicated reasoning about the knowledge involved in the context as well as world knowledge. However, most existing approaches ignore the complicated reasoning process and solve it with a one-step “black box” model and massive data augmentation. Therefore, in this paper, we propose a modular knowledge reasoning approach based on neural network modules that explicitly model each reasoning process step. Five reasoning modules are designed and learned in an end-to-end manner, which leads to a more interpretable model. Experiments using the reasoning over paragraph effects in situations (ROPES) dataset, a challenging dataset that requires reasoning over paragraph effects in a situation, demonstrate the effectiveness and explainability of our proposed approach. Moreover, the transfer of our reasoning modules to the WinoGrande dataset under the zero-shot setting achieved competitive results compared with the data augmented model, proving the generalization capability.},
  archive      = {J_NCA},
  author       = {Ren, Mucheng and Huang, Heyan and Gao, Yang},
  doi          = {10.1007/s00521-022-06975-2},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9901-9918},
  shortjournal = {Neural Comput. Appl.},
  title        = {Interpretable modular knowledge reasoning for machine reading comprehension},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved graph-regularized deep belief network with sparse
features learning for fault diagnosis. <em>NCA</em>, <em>34</em>(12),
9885–9899. (<a
href="https://doi.org/10.1007/s00521-022-06972-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vibration signals are widely used in fault diagnosis of rotating machinery in real-world situations. However, it is very challenging to extract effective fault features from noisy signals and construct an accurate diagnosis model. In this paper, we propose a novel Gaussian–Bernoulli deep belief network (GDBN) model for intelligent fault diagnosis, where improved graph regularization and sparse features learning are embedded in the GDBN smoothly. In particular, the improved graph regularization is added to the hidden layer of original and reconstructed data. Therefore, our model can not only transform the original data into features with improved separability, but also generate discriminant features from vibration signal. An unsupervised pre-training learning process followed by a supervised fine-tuning is implemented in proposed model to contribute the classification capabilities. The effectiveness and superiority of the proposed model have been validated by gearbox and bearing cases studies. The results illustrate that our model can learn effective discriminative features and the extracted features are more separable. Furthermore, the proposed model achieves the better diagnosis accuracy in comparison with that of other models.},
  archive      = {J_NCA},
  author       = {Yang, Jie and Bao, Weimin and Li, Xiaoping and Liu, Yanming},
  doi          = {10.1007/s00521-022-06972-5},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9885-9899},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved graph-regularized deep belief network with sparse features learning for fault diagnosis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Group-based recurrent neural network for human mobility
prediction. <em>NCA</em>, <em>34</em>(12), 9863–9883. (<a
href="https://doi.org/10.1007/s00521-022-06971-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human mobility prediction is of great significance for analyzing the check-in data generated by location-based applications. Compared with classical prediction methods, recently published ones based on neural networks have made significant improvements, but there still exist problems. First, several valuable characteristics in human mobility, such as the geographic relevance, community, and diversity of user movements, are not fully exploited. Second, the sparsity and imbalance of the check-in data also greatly restrict the prediction performance. To alleviate them, this manuscript proposes a new human mobility prediction method called the group-based multi-features move (GMFMove). This method constructs a prediction model based on recurrent neural network and attention mechanism. Three important factors that influence user movements, i.e., the sequence of location, the category of location, and the geographic relevance of human mobility, are taken into consideration in the model to better capture the mobility preference. Furthermore, GMFMove uses a deep-learning-based matrix factorization to integrate prior information including implicit feedbacks and social relationships for grouping users. Then, for each user group, we use a separate multi-features move (MFMove) model to train it and get the subresult. Finally, all of them are integrated in terms of the weights to obtain the final prediction result. We conduct extensive experiments on four real check-in datasets, and the experimental results show that GMFMove method significantly outperforms other methods.},
  archive      = {J_NCA},
  author       = {Ke, Shengren and Xie, Meiyi and Zhu, Hong and Cao, Zhongsheng},
  doi          = {10.1007/s00521-022-06971-6},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9863-9883},
  shortjournal = {Neural Comput. Appl.},
  title        = {Group-based recurrent neural network for human mobility prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantitative cooperation analysis among cross-chain smart
contracts. <em>NCA</em>, <em>34</em>(12), 9847–9862. (<a
href="https://doi.org/10.1007/s00521-022-06970-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cross-chain scenarios, there are different blockchains that need cooperation. The cooperation between different blockchains is completed through smart contracts, which jointly complete cross-chain tasks. When numerous cooperative smart contracts are involved, smart contracts form a complex interactive network, which makes it difficult to evaluate the cooperation. A general model is needed to quantitatively analyze the cross-chain cooperation of associated smart contracts. In this paper, we model the cooperation among smart contracts as conditions and their corresponding actions, the quantitative condition-trigger model. Then, a method of calculating trigger probability by using graph weight is proposed. As the edge weight lacks the information of interaction probability, we introduce the dimension of the edge weight to calculate the interaction probability. The results show that the proposed method can effectively analyze the cross-chain cooperation between smart contracts.},
  archive      = {J_NCA},
  author       = {Su, Hong and Guo, Bing and Lu, Junyu and Suo, Xinhua},
  doi          = {10.1007/s00521-022-06970-7},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9847-9862},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quantitative cooperation analysis among cross-chain smart contracts},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A context aware-based deep neural network approach for
simultaneous speech denoising and dereverberation. <em>NCA</em>,
<em>34</em>(12), 9831–9845. (<a
href="https://doi.org/10.1007/s00521-022-06968-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generally, the recorded speech signal is corrupted by both room reverberation and background noise leading to a reduced speech quality and intelligibility. In order to deal with the distortions caused by the joint effect of noise and reverberation, we propose a context-aware-based deep neural network (DNN) approach for simultaneous speech denoising and dereverberation. The proposed system consists of two stages such as denoising stage and the dereverberation stage. In the denoising stage, the additive noise is suppressed by estimating a phase-sensitive mask using DNN. Then, the noise-free reverberant speech is processed through the dereverberation stage. In the dereverberation stage, a reverberation-time-aware DNN-based model is used to perform dereverberation by adopting two reverberation time-dependent parameters such as frameshift size and acoustic context size to get the benefits of the characteristics of the superposition and frame-wise temporal correlations in different reverberation circumstances. Finally, we integrate both the modules and employ the integrated module for joint training using a multi objective loss function to further optimize both the denoising and dereverberation stages. Experimental results show that the proposed approach has shown significant performance improvements over prevalent benchmark dereverberation algorithms on IEEE corpus, REVERB challenge, and TIMIT corpus datasets under several reverberation circumstances.},
  archive      = {J_NCA},
  author       = {Routray, Sidheswar and Mao, Qirong},
  doi          = {10.1007/s00521-022-06968-1},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9831-9845},
  shortjournal = {Neural Comput. Appl.},
  title        = {A context aware-based deep neural network approach for simultaneous speech denoising and dereverberation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Session-based recommendation with an importance extraction
module. <em>NCA</em>, <em>34</em>(12), 9813–9829. (<a
href="https://doi.org/10.1007/s00521-022-06966-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of session-based recommendation is to make item predictions at the next timestamp based on the anonymous ongoing session. Previous work mainly models user’s preference by exploring the transition pattern between the interacted items in the session. However, they generally fail to pay enough attention to the item importance in terms of the relevance of the items to user’s main purpose. This paper proposes a Session-based Recommendation approach with an Importance Extraction Module, i.e., SR-IEM $$_{{{\text{improved}}}}$$ , which can simultaneously consider user’s long-term interactions and recent behavior in current session. Specifically, we modify the self-attention mechanism to avoid introducing bias for estimating the importance of each item in the session. Then, the item importances are utilized to produce user’s long-term preference, and the sequential signals are incorporated in the long-term interest modeling. Next, the long-term preference and user’s current interest which is conveyed by the last interacted item in the session are combined to obtain user’s final preference representation. Finally, item predictions are generated using the user preference, where a normalization layer is adopted to solve the long-tail problem. Extensive experiments are conducted on three public benchmark datasets, i.e., Yoochoose 1/64, Yoochoose 1/4 and Diginetica. The experimental results show that SR-IEM $$_{{{\text{improved}}}}$$ can outperform the start-of-the-art baselines in terms of Recall and MRR for session-based recommendation. In addition, compared to the state-of-the-art neural methods, SR-IEM $$_{{{\text{improved}}}}$$ can obviously reduce the computational complexity.},
  archive      = {J_NCA},
  author       = {Pan, Zhiqiang and Cai, Fei and Chen, Wanyu and Chen, Honghui},
  doi          = {10.1007/s00521-022-06966-3},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9813-9829},
  shortjournal = {Neural Comput. Appl.},
  title        = {Session-based recommendation with an importance extraction module},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DEIDS: A novel intrusion detection system for industrial
control systems. <em>NCA</em>, <em>34</em>(12), 9793–9811. (<a
href="https://doi.org/10.1007/s00521-022-06965-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the development of industrial production, the hidden danger in industrial control systems (ICSs) has considerably increased, causing challenges in traditional safety defense methods. The combination of machine-learning or deep-learning algorithms and intrusion detection systems (IDSs) has become the mainstream method for solving this problem. However, these methods depend on a massive amount of high-quality attack traffic data, which cannot be obtained easily owing to the independence and unique characteristics of ICSs. In this study, we apply the reconstructed convolutional neural network and a data expansion algorithm named CenterBorderline_SMOTE (CB_SMOTE) to an IDS and propose data expansion intrusion detection system (DEIDS). The DEIDS is an end-to-end detection model that learns representative attack features from raw traffic and classifies them in a unified framework. Moreover, we adopt the classification activation map structure, which can deeply mine the potential characteristics of traffic and enhance the effectiveness of attack features. While enhancing the data quality, we introduce the designed CB_SMOTE algorithm into DEIDS to expand the data and solve the problem of insufficient attack data in the system. Our comprehensive experiments on different open datasets indicate that DEIDS achieves an excellent performance (97 $$\%$$ detection accuracy) and outperforms the state-of-the-art methods. The experimental results also show that our method has high efficiency and high accuracy in processing ICSs datasets.},
  archive      = {J_NCA},
  author       = {Gu, Haoran and Lai, Yingxu and Wang, Yipeng and Liu, Jing and Sun, Motong and Mao, Beifeng},
  doi          = {10.1007/s00521-022-06965-4},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9793-9811},
  shortjournal = {Neural Comput. Appl.},
  title        = {DEIDS: A novel intrusion detection system for industrial control systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The prediction of dynamic energy behavior of a brazilian
disk containing nonpersistent joints subjected to drop hammer test
utilizing heuristic approaches. <em>NCA</em>, <em>34</em>(12),
9777–9792. (<a
href="https://doi.org/10.1007/s00521-022-06964-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crack development initiated from nonpersistent joints in rock mass plays a key role in the instability of rock structures. In particular, the dynamic behavior of nonpersistent discontinuities can result in the coalescence and failure of rock structures. The effect and contribution of such joint parameters on rock structures’ failure under impact loading have not been thoroughly investigated by researchers. In this paper, 68 concrete Brazilian disks, manufactured to include several nonpersistent joints and joint sets, are subjected to impact loading to explore the impact of joint continuity factor, joint spacing, bridge angle, and loading direction on the required dynamic energy for crack initiation (DECI) and coalescence (DECC). Artificial neural network (ANN), adaptive neuro-fuzzy inference system (ANFIS), and its combination with particle swarm optimization (PSO) and genetic algorithm (GA) have been developed to predict the energy indexes. The performance of the models was evaluated using statistical indicators. The results show that intelligent methods can predict both energy indexes and that their outputs are consistent with laboratory results. The R-squared index for the test data of the ANN, ANFIS, and ANFIS-PSO/GA models to predict DECI parameters is 0.97, 0.96, 0.96, and 0.97, respectively, and for DECC is 0.98, 0.96, 0.96, and 0.93, respectively. The ANN have the best performance for the test data based on all statistical indexes. In addition, multiple parametric sensitivity analysis shows that both the joint continuity and joint spacing have the most significant effect while bridge angle and loading direction have the minimal effect on the energy indexes.},
  archive      = {J_NCA},
  author       = {Shakeri, Jamshid and Asadizadeh, Mostafa and Babanouri, Nima},
  doi          = {10.1007/s00521-022-06964-5},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9777-9792},
  shortjournal = {Neural Comput. Appl.},
  title        = {The prediction of dynamic energy behavior of a brazilian disk containing nonpersistent joints subjected to drop hammer test utilizing heuristic approaches},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel self-organizing TS fuzzy neural network for furnace
temperature prediction in MSWI process. <em>NCA</em>, <em>34</em>(12),
9759–9776. (<a
href="https://doi.org/10.1007/s00521-022-06963-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the municipal solid waste incineration (MSWI) process, it is critical to predict furnace temperature, which is closely related to the incinerate state and the steam production, to maintain the high efficiency in the incineration process. In this paper, a novel self-organizing TS fuzzy neural network with an improved gradient descent algorithm (SOTSFNN-IGA) is developed to predict furnace temperature. Firstly, to get a suitable network structure and achieve high-efficiency computing capability, the error criteria and activity intensity are employed to grow and remove the fuzzy rules of SOTSFNN-IGA automatically. Secondly, an improved gradient descent algorithm is employed to adjust the parameters of SOTSFNN-IGA. Thirdly, the convergence analysis of the proposed SOTSFNN-IGA is given through the Lyapunov theory. Subsequently, to understand the influence of each variable on the furnace temperature, a new variable importance measurement method is employed. Finally, the proposed SOTSFNN-IGA is verified based on several benchmark nonlinear systems and a furnace prediction in the MSWI process. Experimental results demonstrate that the developed SOTSFNN-IGA has better advantages in prediction accuracy than other algorithms, which prediction accuracy and NSE coefficient are as high as 99.85\% and 0.9827 respectively in the furnace temperature prediction.},
  archive      = {J_NCA},
  author       = {He, Haijun and Meng, Xi and Tang, Jian and Qiao, Junfei},
  doi          = {10.1007/s00521-022-06963-6},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9759-9776},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel self-organizing TS fuzzy neural network for furnace temperature prediction in MSWI process},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing the detection ability of control charts in profile
monitoring by adding RBF ensemble model. <em>NCA</em>, <em>34</em>(12),
9733–9757. (<a
href="https://doi.org/10.1007/s00521-022-06962-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While numerous contributions and applications have been extended in profile monitoring, little attention has been paid to employing machine learning techniques in development of control charts. In this paper, a novel control chart based on artificial neural network is proposed to improve the performance of monitoring general linear profiles in Phase II. Specifically, an ensemble of radial basis functions (RBF) is added to the predefined base control chart to enhance the detection ability of the control chart for monitoring linear profile parameters based on the average run length (ARL) criterion. The performance of the proposed method is evaluated by adjusting the multivariate exponentially weighted moving average (MEWMA) control chart as a base control chart under simple and multiple linear profiles. The simulation results demonstrate that the proposed approach is very efficient than competing existing methods for monitoring linear profile parameters. Moreover, profile diagnosis actions, referring to the identification of shifted parameters, are provided based on the RBF networks. Finally, we provide an example from thermal management to illustrate the implementation of the proposed monitoring scheme and diagnostic method.},
  archive      = {J_NCA},
  author       = {Yeganeh, Ali and Shadman, Alireza and Abbasi, Saddam Akber},
  doi          = {10.1007/s00521-022-06962-7},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9733-9757},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing the detection ability of control charts in profile monitoring by adding RBF ensemble model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reference-guided face inpainting with reference attention
network. <em>NCA</em>, <em>34</em>(12), 9717–9731. (<a
href="https://doi.org/10.1007/s00521-022-06961-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face inpainting is a significant problem encountered in many image restoration tasks, in which various methods based on deep learning are explored. Existing methods cannot restore enough structure details as the masked input only provides limited information. In this paper, a novel reference-guided face inpainting method is proposed to generate inpainting results more similar to people themselves, which restores the missing pixels by referring to a reference image besides an original masked image. Concretely, another reference image with the same identity as the masked input is utilized as a conditional input to constrain the generated coarse result of the first inpainting stage. Furthermore, a reference attention module is designed to restore more textural details by computing the similarity between the pixels of the coarse result and the reference image. The similarity is further represented by the similarity maps, which are deconvolved to reconstruct the pixels of the missing regions. Extensive experimental results on CelebA datasets and LFW datasets demonstrate that our proposed method can generate an image with more similar features to people themselves and achieves superior performance to the state-of-the-art methods quantitatively and qualitatively.},
  archive      = {J_NCA},
  author       = {Yu, Jiazuo and Li, Kai and Peng, Jinjia},
  doi          = {10.1007/s00521-022-06961-8},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9717-9731},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reference-guided face inpainting with reference attention network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A reinforcement learning-based approach for imputing missing
data. <em>NCA</em>, <em>34</em>(12), 9701–9716. (<a
href="https://doi.org/10.1007/s00521-022-06958-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing data is a major problem in real-world datasets, which hinders the performance of data analytics. Conventional data imputation schemes such as univariate single imputation replace missing values in each column with the same approximated value. These univariate single imputation techniques underestimate the variance of the imputed values. On the other hand, multivariate imputation explores the relationships between different columns of data, to impute the missing values. Reinforcement Learning (RL) is a machine learning paradigm where the agent learns by taking actions and receiving rewards in response, to achieve its goal. In this work, we propose an RL-based approach to impute missing data by learning a policy to impute data through an action-reward-based experience. Our approach imputes missing values in a column by working only on the same column (similar to univariate single imputation) but imputes the missing values in the column with different values thus keeping the variance in the imputed values. We report superior performance of our approach, compared with other imputation techniques, on a number of datasets.},
  archive      = {J_NCA},
  author       = {Awan, Saqib Ejaz and Bennamoun, Mohammed and Sohel, Ferdous and Sanfilippo, Frank and Dwivedi, Girish},
  doi          = {10.1007/s00521-022-06958-3},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9701-9716},
  shortjournal = {Neural Comput. Appl.},
  title        = {A reinforcement learning-based approach for imputing missing data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Super twisting sliding mode network congestion control
based on disturbance observer. <em>NCA</em>, <em>34</em>(12), 9689–9699.
(<a href="https://doi.org/10.1007/s00521-022-06957-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robust super-twisting sliding mode control (SMC) based on a disturbance observer is firstly investigated for transmission control protocol (TCP) network systems with unknown disturbance in this paper. To reject chattering from SMC, a super-twisting algorithm (STA) based on integral SMC is introduced to TCP/AQM systems. Meanwhile, to improve the estimation accuracy of the model, a disturbance observer is designed. By selecting the appropriate sliding surface coefficients, the stability of the closed-loop control system is achieved. At last, simulation comparison results are given to illustrate the feasibility and the superiority of the proposed approach.},
  archive      = {J_NCA},
  author       = {Wang, Kun and Liu, Xiaoping and Jing, Yuanwei},
  doi          = {10.1007/s00521-022-06957-4},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9689-9699},
  shortjournal = {Neural Comput. Appl.},
  title        = {Super twisting sliding mode network congestion control based on disturbance observer},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An integrated approach using growing self-organizing
map-based genetic k-means clustering and tolerance rough set in
occupational risk analysis. <em>NCA</em>, <em>34</em>(12), 9661–9687.
(<a href="https://doi.org/10.1007/s00521-022-06956-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To prevent the occurrences of accidents at workplaces, accident data should be analyzed properly. However, handling such data of higher dimension is often a difficult task for analysis to achieve efficient decision making due to the slow convergence and local minima problem. To address these issues, the present study proposes a new clustering algorithm called growing self-organizing map (GSOM)-based genetic K-means (GSGKM) for classifying accident data into an optimal number of clusters. Tolerance rough set approach (TRSA) is later used on each cluster to extract useful accident patterns, which enables helps in accident analysis and prevention. To validate the effectiveness of our proposed methodology, accident data obtained from an integrated steel plant are used as a case study. Besides, a total of four benchmark datasets collected from the University of California, Irvine (UCI) machine learning repository are also used for comparative study to prove its (i.e., GSGKM) superiority over some other state-of-the-arts. Experimental results reveal that the proposed methodology provides the highest clustering accuracy. A total of four clusters are obtained from the analysis. A set of 16 accident crisp patterns or rules are extracted from clusters using TRSA. Company employees are found to be more exposed to accidents than contractors. Additionally, behavioral issues are identified as the most determinant factor behind the injuries at work. The proposed methodology can be effectively used in decision making for different industries, including construction, manufacturing, and aviation.},
  archive      = {J_NCA},
  author       = {Sarkar, Sobhan and Ejaz, Numan and Maiti, J. and Pramanik, Anima},
  doi          = {10.1007/s00521-022-06956-5},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9661-9687},
  shortjournal = {Neural Comput. Appl.},
  title        = {An integrated approach using growing self-organizing map-based genetic K-means clustering and tolerance rough set in occupational risk analysis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LRTI: Landmark ratios with task importance toward accurate
age estimation using deep neural networks. <em>NCA</em>,
<em>34</em>(12), 9647–9659. (<a
href="https://doi.org/10.1007/s00521-022-06955-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, age estimation systems have become a pressing need in several vital fields such as security services and health systems. Over the past decade, there have been introduced several efforts to build accurate and robust age estimation systems, where deep networks have proved to be the superior leader of machine learning tools. From this point, we propose a system named landmark ratios with task importance (LRTI), which accurately estimates a person’s age using deep neural networks. The proposed system extracts more precise information using the facial landmarks—rather than using only the extracted features inferred by the convolutional neural network —to estimate the age. The proposed system is based on defining the purposeful characteristics that distinguish the different age classes. As a result, LRTI computes the ratio of distances between the facial landmarks to represent the facial stretching through aging. These distance ratios are added to the network to precisely differentiate the age classes. The proposed system takes into account the in-between relation of age labels which enhance the accuracy of the age estimation process. The in-between relation of age labels is addressed by generating an importance vector, which gives a weight for each class label according to the degree of neighborhood to the target label. From the conducted experiments, the LRTI system adequately models the ordering and continuity properties of the aging process; thus, it has outperformed other state-of-the-art approaches when applied onto MORPH II, FGNET, CACD, AFAD, and UTKFace datasets. LRTI achieved the best mean absolute error, reaching 2.58 with MORPH II, 2.51 with FGNET, 5.39 with CACD, 3.44 with AFAD, and 5.14 with UTKFace.},
  archive      = {J_NCA},
  author       = {Badr, Marwa M. and Elbasiony, Reda M. and Sarhan, Amany M.},
  doi          = {10.1007/s00521-022-06955-6},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9647-9659},
  shortjournal = {Neural Comput. Appl.},
  title        = {LRTI: Landmark ratios with task importance toward accurate age estimation using deep neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modelling the edge breakout shear capacity of single anchors
using gene expression programming. <em>NCA</em>, <em>34</em>(12),
9635–9646. (<a
href="https://doi.org/10.1007/s00521-022-06954-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of soft computing techniques is becoming more common in providing solutions to complex engineering problems such as the concrete breakout strength of anchor. Available techniques include semi-empirical equations that are known to over or underpredict and some soft computing techniques that is incapable of generating predictive equations. This study proposes a gene expression programming (GEP)-based mathematical model to predict the concrete edge breakout capacity of single anchors loaded in shear. In doing so, an experimental database compiled by the American Concrete Institute (ACI) Committee 355, containing 366 samples, was used for the model training and testing. The independent variables considered in the model development are the edge distance, anchor diameter, embedment depth and concrete strength. Moreover, the predictive performance of the developed model was compared to that of the existing models proposed in ACI 318 and the Eurocode 2 (EC2) design standards. The assessment showed that the proposed GEP-based model provided a much more uniform and accurate prediction of the actual strength than the models in the existing design standards. The proposed mathematical model is simple and robust and is expected to be very useful for evaluating the concrete breakout shear capacity of single anchors in pre-planning and pre-design phases; that is, towards inclusions in design standards.},
  archive      = {J_NCA},
  author       = {Olalusi, Oladimeji Benedict and Durgapershad, Avishkar and Awoyera, Paul Oluwaseun and Kolawole, John Temitope},
  doi          = {10.1007/s00521-022-06954-7},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9635-9646},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modelling the edge breakout shear capacity of single anchors using gene expression programming},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Encryption technique based on fuzzy neural network hiding
module and effective distortion method. <em>NCA</em>, <em>34</em>(12),
9613–9633. (<a
href="https://doi.org/10.1007/s00521-022-06950-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underrating the evergrowing effectiveness of cryptanalysis tools is likely to be a big mistake. Although available protection techniques are effective and may dissipate our worries about information safety, we should not ignore the formidable advancements in hacking tools. Such advancements are likely to soon challenge our protection techniques. Unfortunately, although this challenge is probable, there is not much advancement in the way the protection tools function. Encryption techniques still use roughly the same computation principles and the same level of dependency on the encryption key. This paper goes beyond these encryption techniques and proffers an encryption technique with a new computation model. This model uses a fuzzy neural network to generate highly complicated hiding codes from the encryption key. The computation model uses also substitution and distortion methods that depend on plaintext and chaotic noises to induce enormous confusion in the ciphertext. This combination along with other confusion boosting actions such as interval scattering and chaotic locking establishes a very effective encryption technique. Experiments on the proof-of-concept prototype showed that the output (ciphertext) of the proposed technique passed rigorous randomness tests.},
  archive      = {J_NCA},
  author       = {Al-Muhammed, Muhammed J. and Al-Daraiseh, Ahmad},
  doi          = {10.1007/s00521-022-06950-x},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9613-9633},
  shortjournal = {Neural Comput. Appl.},
  title        = {Encryption technique based on fuzzy neural network hiding module and effective distortion method},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reading order detection on handwritten documents.
<em>NCA</em>, <em>34</em>(12), 9593–9611. (<a
href="https://doi.org/10.1007/s00521-022-06948-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in Handwritten Text Recognition and Document Layout Analysis have made it possible to convert digital images of manuscripts into electronic text. However, providing this text with the correct structure and context is still an open problem that needs to be solved to actually enable extracting the relevant information conveyed by the text. The most important structure needed for a set of text elements is their reading order. Most of the studies on the reading order problem are rule-based approaches and focus on printed documents. Much less attention has been paid so far to handwritten text documents, where the problem becomes particularly important—and challenging. In this work, we propose a new approach to automatically determine the reading order of text regions and lines in handwritten text documents. The task is approached as a sorting problem where the order-relation operator is automatically learned from examples. We experimentally demonstrate the effectiveness of our method on three different datasets at different hierarchical levels.},
  archive      = {J_NCA},
  author       = {Quirós, Lorenzo and Vidal, Enrique},
  doi          = {10.1007/s00521-022-06948-5},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9593-9611},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reading order detection on handwritten documents},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic lung cancer detection from CT image using improved
deep neural network and ensemble classifier. <em>NCA</em>,
<em>34</em>(12), 9579–9592. (<a
href="https://doi.org/10.1007/s00521-020-04842-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of the computer-aided detection system placed an important role in the clinical analysis for making the decision about the human disease. Among the various disease examination processes, lung cancer needs more attention because it affects both men and women, which leads to increase the mortality rate. Traditional lung cancer prediction techniques failed to manage the accuracy because of low-quality image that affects the segmentation process. So, in this paper new optimized image processing and machine learning technique is introduced to predict the lung cancer. For recognizing lung cancer, non-small cell lung cancer CT scan dataset images are collected. The gathered images are examined by applying the multilevel brightness-preserving approach which effectively examines each pixel, eliminates the noise and also increase the quality of the lung image. From the noise-removed lung CT image, affected region is segmented by using improved deep neural network that segments region in terms of using layers of network and various features are extracted. Then the effective features are selected with the help of hybrid spiral optimization intelligent-generalized rough set approach, and those features are classified using ensemble classifier. The discussed method increases the lung cancer prediction rate which is examined using MATLAB-based results such as logarithmic loss, mean absolute error, precision, recall and F-score.},
  archive      = {J_NCA},
  author       = {Shakeel, P. Mohamed and Burhanuddin, M. A. and Desa, Mohammad Ishak},
  doi          = {10.1007/s00521-020-04842-6},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9579-9592},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic lung cancer detection from CT image using improved deep neural network and ensemble classifier},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of visual and procedural handwriting analysis for
neuropsychological assessment. <em>NCA</em>, <em>34</em>(12), 9561–9578.
(<a href="https://doi.org/10.1007/s00521-022-07185-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To date, Artificial Intelligence systems for handwriting and drawing analysis have primarily targeted domains such as writer identification and sketch recognition. Conversely, the automatic characterization of graphomotor patterns as biomarkers of brain health is a relatively less explored research area. Despite its importance, the work done in this direction is limited and sporadic. This paper aims to provide a survey of related work to provide guidance to novice researchers and highlight relevant study contributions. The literature has been grouped into “visual analysis techniques” and “procedural analysis techniques”. Visual analysis techniques evaluate offline samples of a graphomotor response after completion. On the other hand, procedural analysis techniques focus on the dynamic processes involved in producing a graphomotor reaction. Since the primary goal of both families of strategies is to represent domain knowledge effectively, the paper also outlines the commonly employed handwriting representation and estimation methods presented in the literature and discusses their strengths and weaknesses. It also highlights the limitations of existing processes and the challenges commonly faced when designing such systems. High-level directions for further research conclude the paper.},
  archive      = {J_NCA},
  author       = {Moetesum, Momina and Diaz, Moises and Masroor, Uzma and Siddiqi, Imran and Vessio, Gennaro},
  doi          = {10.1007/s00521-022-07185-6},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9561-9578},
  shortjournal = {Neural Comput. Appl.},
  title        = {A survey of visual and procedural handwriting analysis for neuropsychological assessment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning-based microexpression recognition: A survey.
<em>NCA</em>, <em>34</em>(12), 9537–9560. (<a
href="https://doi.org/10.1007/s00521-022-07157-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent development of microexpression recognition, deep learning (DL) has been widely applied in this field. In this paper, we provide a comprehensive survey of the current DL-based microexpression (ME) recognition methods. In addition, we introduce a novel dataset based on fusing all the existing ME datasets. We also evaluate a baseline DL for the microexpression recognition task. Finally, we make the new dataset and the code publicly available to the community at https://github.com/wenjgong/microExpressionSurvey .},
  archive      = {J_NCA},
  author       = {Gong, Wenjuan and An, Zhihong and Elfiky, Noha M.},
  doi          = {10.1007/s00521-022-07157-w},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9537-9560},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-based microexpression recognition: A survey},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning techniques to classify agricultural crops
through UAV imagery: A review. <em>NCA</em>, <em>34</em>(12), 9511–9536.
(<a href="https://doi.org/10.1007/s00521-022-07104-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the last few years, Unmanned Aerial Vehicles (UAVs) technologies are widely used to improve agriculture productivity while reducing drudgery, inspection time, and crop management cost. Moreover, they are able to cover large areas in a matter of a few minutes. Due to the impressive technological advancement, UAV-based remote sensing technologies are increasingly used to collect valuable data that could be used to achieve many precision agriculture applications, including crop/plant classification. In order to process these data accurately, we need powerful tools and algorithms such as Deep Learning approaches. Recently, Convolutional Neural Network (CNN) has emerged as a powerful tool for image processing tasks achieving remarkable results making it the state-of-the-art technique for vision applications. In the present study, we reviewed the recent CNN-based methods applied to the UAV-based remote sensing image analysis for crop/plant classification to help researchers and farmers to decide what algorithms they should use accordingly to their studied crops and the used hardware. Fusing different UAV-based data and deep learning approaches have emerged as a powerful tool to classify different crop types accurately. The readers of the present review could acquire the most challenging issues facing researchers to classify different crop types from UAV imagery and their potential solutions to improve the performance of deep learning-based algorithms.},
  archive      = {J_NCA},
  author       = {Bouguettaya, Abdelmalek and Zarzour, Hafed and Kechida, Ahmed and Taberkit, Amine Mohammed},
  doi          = {10.1007/s00521-022-07104-9},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9511-9536},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning techniques to classify agricultural crops through UAV imagery: A review},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved method for sink node deployment in wireless
sensor network to big data. <em>NCA</em>, <em>34</em>(12), 9499–9510.
(<a href="https://doi.org/10.1007/s00521-021-06443-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor network (WSNs) technology and Internet technology penetrate and extend each other. It is a good way for physical changes of objects, state recognition and data collection, and becomes an important source of network data in big data. Compared with traditional wireless networks, WSNs have the characteristics of integrating sensing, processing, and transmission, limited hardware resources, limited power supply capacity, no center, self-organization, multi-hop routing, dynamic topology, large number of nodes, and dense distribution. In order to improve the energy utilization rate of a single node to a greater extent, reduce the energy consumption of the entire WSNs, and extend the life cycle of WSNs, high-efficiency networking is essential in the application of WSNs. Networking is one of the foundations to the large-scale WSNs. The network model and node location deployment are important technologies for WSNs networking. Based on the network characteristics of large-scale WSNs and the transmission capacity of big data, a new type of network model suitable is presented which combined the advantages of Star model and Mesh model. More importantly, the deployment environment of sensor nodes is a spatial network. The data collected and transmitted by large-scale WSNs is very large. The deployment of sensor nodes in space can ensure that the big data collected and transmitted are true and effective. This research proposes the space density first (SDF) algorithm, which improves the neighbor density first algorithm with the space node deployment and the density-optimized SDF algorithm. The SDF algorithm saves network energy and extends the life of the network. Experimental results show that large-scale WSNs built with a new networking model and SDF algorithm can collect and transmit big data stably and reliably, which saves network energy and improves the accuracy of big data.},
  archive      = {J_NCA},
  author       = {Chen, Yineng and Zhu, Xinghui and Fang, Kui and Chen, Xiaoxuan and Guo, Ting and Li, Cheng and Ren, Qingshan and Zou, Zhuoyang},
  doi          = {10.1007/s00521-021-06443-3},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9499-9510},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved method for sink node deployment in wireless sensor network to big data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RETRACTED ARTICLE: Research on control strategy and policy
optimal scheduling based on an improved genetic algorithm. <em>NCA</em>,
<em>34</em>(12), 9485–9497. (<a
href="https://doi.org/10.1007/s00521-021-06415-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of artificial intelligence and continuous in-depth integration with big data, cloud computing, robotics, and the Internet, especially the Internet of Things and blockchain, the reconstruction of society has been accelerated. This process not only enables epidemic prevention and control, economic transformation and growth, social governance reform and upgrading, and improvement in people&#39;s well-being but also puts forward many new challenges to social governance. The development of artificial intelligence must require the establishment of ethical standards and systems to be at the same frequency, and the development speed of the two must be coordinated to ensure the healthy development of technology. However, artificial intelligence not only brings convenience to people&#39;s lives but also raises people&#39;s concerns about its ramifications. To understand the influence of AI on governance in the algorithm dimension, a model of the influence of AI governance is built by using a parallel algorithm. It is necessary to learn new knowledge of social governance in the era of artificial intelligence and establish concomitant new ideas of social governance to explore a new way of social governance in the era of artificial intelligence. The research results show that after the introduction of artificial intelligence embedded governance, the governance level is greatly improved, the problem solving rate is increased by more than 50\%, the satisfaction of the masses is increased by 30\%, and the governance cost is reduced by 20\%. However, people do not know much about the risks of artificial intelligence. Only approximately 10\% of the population has a clear understanding of the risks of artificial intelligence. The research results show that artificial intelligence can play an important role in governance, but it is necessary to prevent the risks of artificial intelligence to better promote social development.},
  archive      = {J_NCA},
  author       = {Xia, Jing and Yan, Yongcai and Ji, Lei},
  doi          = {10.1007/s00521-021-06415-7},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9485-9497},
  shortjournal = {Neural Comput. Appl.},
  title        = {RETRACTED ARTICLE: Research on control strategy and policy optimal scheduling based on an improved genetic algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-feature decision fusion algorithm for disease
detection on crop surface based on machine vision. <em>NCA</em>,
<em>34</em>(12), 9471–9484. (<a
href="https://doi.org/10.1007/s00521-021-06388-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the problem of crop disease detection in large-scale planting, a new crop disease detection algorithm based on multi-feature decision fusion is proposed. This paper proposes a multi-feature decision fusion disease discrimination algorithm (PD R-CNN) based on machine vision on crop surfaces. The algorithm is based on the machine vision processing model of R-CNN and integrates a disease discrimination algorithm on the basis of R-CNN. After training on crop image data sets, PD R-CNN can reach the goal of identifying crop surface lesions. This paper uses machine vision image acquisition, image processing and analysis technology to collect and analyze the growth of cucumber seedlings. The research results show that compared with manual judgment, PD R-CNN reduces the workload and can effectively distinguish crop diseases. Through experiments, during the occurrence of pests and diseases, PD R-CNN has a monitoring accuracy of 88.0\% for mosaic disease, 92.0\% for root rot, 88.0\% for powdery mildew, and 86.0\% for aphids, indicating that there are errors in actual monitoring, but the accuracy exceeds 85.0\% can be put into use.},
  archive      = {J_NCA},
  author       = {Hua, Shan and Xu, Minjie and Xu, Zhifu and Ye, Hongbao and Zhou, Chengquan},
  doi          = {10.1007/s00521-021-06388-7},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9471-9484},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-feature decision fusion algorithm for disease detection on crop surface based on machine vision},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on enterprise knowledge service based on semantic
reasoning and data fusion. <em>NCA</em>, <em>34</em>(12), 9455–9470. (<a
href="https://doi.org/10.1007/s00521-021-06382-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, the field of enterprise risk is facing considerable challenges brought by massive multisource heterogeneous information sources. In view of the proliferation of multisource and heterogeneous enterprise risk information, insufficient knowledge fusion capabilities, and the low level of intelligence in risk management, this article explores the application process of enterprise knowledge service models for rapid responses to risk incidents from the perspective of semantic reasoning and data fusion and clarifies the elements of the knowledge service model in the field of risk management. Based on risk data, risk decision making as the standard, risk events as the driving force, and knowledge graph analysis methods as the power, the risk domain knowledge service process is decomposed into three stages: prewarning, in-event response, and postevent summary. These stages are combined with the empirical knowledge of risk event handling to construct a three-level knowledge service model of risk domain knowledge acquisition-organization-application. This model introduces the semantic reasoning and data fusion method to express, organize, and integrate the knowledge needs of different stages of risk events; provide enterprise managers with risk management knowledge service solutions; and provide new growth points for the innovation of interdisciplinary knowledge service theory.},
  archive      = {J_NCA},
  author       = {Yang, Bo and Yang, Meifang},
  doi          = {10.1007/s00521-021-06382-z},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9455-9470},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on enterprise knowledge service based on semantic reasoning and data fusion},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficiency evaluation research of a regional water system
based on a game cross-efficiency model. <em>NCA</em>, <em>34</em>(12),
9441–9454. (<a
href="https://doi.org/10.1007/s00521-021-06381-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the problem of regional water system evaluation, this paper proposes a system efficiency evaluation method based on the game cross-efficiency model and conducts an empirical analysis. First, autopoiesis is introduced as the theoretical basis. The characteristics of the authigenic system are combined with a regional water system, and the connotation and characteristics of the regional water system are defined. Second, based on the competitive relationship between regional water systems, the existing game crossover efficiency model is improved. A crossover efficiency model of other games is proposed to evaluate the efficiency of regional water systems. Then, the Pearl River Delta urban agglomeration is selected as the research object. The effects of four systematic evaluation methods based on the DEA method are compared horizontally to find the optimal system efficiency evaluation method. Finally, the characteristics of the regional water system in the Pearl River Delta are systematically analysed through the evaluation results, and the present situation of the regional water system is fully explained.},
  archive      = {J_NCA},
  author       = {Zhang, Wenyu and Yu, Hongze and Ren, Lu and Dong, Qing and Zhao, Chenxiao},
  doi          = {10.1007/s00521-021-06381-0},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9441-9454},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficiency evaluation research of a regional water system based on a game cross-efficiency model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Digital city landscape planning and design based on spatial
information technology. <em>NCA</em>, <em>34</em>(12), 9429–9440. (<a
href="https://doi.org/10.1007/s00521-021-06377-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of information technology and China’s urban economy, the concept of smart cities has been proposed many times. Planning and designing cityscapes are essential in the process of building smart cities. There are many factors to consider when designing and planning traditional cityscapes, and these factors must be studied in combination with modern developments and characteristics. Information technology can provide massive data support and technical support for these studies. With the support of information technology, cities and modern technology can be closely connected. This paper proposes research on digital cityscape planning and design under spatial information technology using literature methods, field survey methods, comparative survey methods, and other methods. First, we deeply study spatial information technology and theoretical knowledge of digital cityscape planning and design; then, we design a spatial gray-level co-occurrence matrix model, collect urban vegetation data maps via remotely sensed images, and finally analyze the planning and design of digital cityscapes. After landscape planning, the vegetation was rated at 38.94 points, approximately 12 points higher than the rating given before planning. This result shows that after reasonable landscape planning and design, the needs of people for green plants can be met well, and the ecological value of digital urban spatial landscapes can be fully utilized. These results are important for maintaining the diversity of urban biodiversity, regulating the regional climate, and maintaining urban spaces, and the ecological balance of the entire city also plays a vital role.},
  archive      = {J_NCA},
  author       = {Deng, Yi and Xie, Linting and Xing, Chengyue and Cai, Ling},
  doi          = {10.1007/s00521-021-06377-w},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9429-9440},
  shortjournal = {Neural Comput. Appl.},
  title        = {Digital city landscape planning and design based on spatial information technology},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Big data medical behavior analysis based on machine learning
and wireless sensors. <em>NCA</em>, <em>34</em>(12), 9413–9427. (<a
href="https://doi.org/10.1007/s00521-021-06369-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the scientificity and reliability of medical behavior analysis, this paper combines machine learning and wireless sensor technology to construct an intelligent data mining system that can be used for medical behavior analysis and uses association rules to analyze and mine the implicit relationships between structural monitoring parameters. Moreover, this paper establishes strong association rules between different monitoring variables based on historical monitoring data under normal structural conditions to predict whether the structural conditions are normal. In addition, this paper constructs a system function module according to actual needs, obtains the overall system architecture, and implements the system function module in combination with algorithms. Finally, this paper designs experiments to verify the performance of the system constructed in this paper and discusses the experimental results through mathematical graph analysis methods. From the research point of view, it can be observed that the system constructed in this paper has a specific effect.},
  archive      = {J_NCA},
  author       = {Cui, Moyang},
  doi          = {10.1007/s00521-021-06369-w},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9413-9427},
  shortjournal = {Neural Comput. Appl.},
  title        = {Big data medical behavior analysis based on machine learning and wireless sensors},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RETRACTED ARTICLE: Image simulation of urban landscape in
coastal areas based on geographic information system and machine
learning. <em>NCA</em>, <em>34</em>(12), 9397–9411. (<a
href="https://doi.org/10.1007/s00521-021-06335-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studying the changes in the landscape pattern of coastal cities and analyzing their land use conditions are conducive to understanding the internal structure of the city and in-depth analysis of the law of urban development, so as to propose governance measures and improvement methods in the aspects of economy, people&#39;s livelihood, and environment. Based on geographic information system and machine learning technology, this paper analyzes the internal mechanism, temporal and spatial characteristics and change laws of the intensive use of sea areas. The selection of research scale is in the exploratory stage, which is based on the research scale of land intensive use. Moreover, this paper combines landscape ecology to construct a coastal city landscape image simulation system and uses remote sensing technology to analyze the system model. Finally, this paper analyzes the performance of the coastal city landscape image simulation system constructed in this paper through experimental analysis. From the research results, the system constructed in this paper basically meets the needs of coastal city landscape image simulation.},
  archive      = {J_NCA},
  author       = {Zhou, Junling and Wang, Pohsun},
  doi          = {10.1007/s00521-021-06335-6},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9397-9411},
  shortjournal = {Neural Comput. Appl.},
  title        = {RETRACTED ARTICLE: Image simulation of urban landscape in coastal areas based on geographic information system and machine learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic analysis of DIFC systems using noninterference
with declassification. <em>NCA</em>, <em>34</em>(12), 9385–9396. (<a
href="https://doi.org/10.1007/s00521-021-06334-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information flow control (IFC) can effectively resist Trojans and viruses that steal information from systems, and is usually adopted to protect the confidentiality of systems with a high security level. However, covert channel attacks can bypass IFC by exploiting its implementation defects. Thus, it is crucial to verify the system security and identify potential covert channels. Decentralized IFC (DIFC) is a key innovation that provides new flexible mechanisms, including decentralized declassification and taint tracking. However, the flexibility of DIFC systems also brings security risks. At present, there is a lack of a systematic and automatic security analysis approach for complex DIFC systems. In this paper, we propose a formal and automatic method to analyze the security of DIFC systems by using the FDR2 tool. We provide a new definition of noninterference, based on which the security analysis is performed. The analysis results indicate that our approach can both effectively detect covert channels in DIFC systems and accommodate conditional declassification information. The proposed method is more efficient and accurate than existing manual methods of covert channel detection.},
  archive      = {J_NCA},
  author       = {Li, Wenfa and Yang, Zhi and Liu, Jia},
  doi          = {10.1007/s00521-021-06334-7},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9385-9396},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic analysis of DIFC systems using noninterference with declassification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on the improvement effect of machine learning and
neural network algorithms on the prediction of learning achievement.
<em>NCA</em>, <em>34</em>(12), 9369–9383. (<a
href="https://doi.org/10.1007/s00521-021-06333-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the effect of college student performance prediction, based on machine learning and neural network algorithms, this paper improves the traditional data processing algorithms and proposes a similarity calculation method for courses. Moreover, this paper uses cosine similarity to calculate the similarity of courses. Simultaneously, this paper proposes an improved hybrid multi-weight improvement algorithm to improve the cold start problem that cannot be solved by traditional algorithms. In addition, this paper combines the neural network structure to construct a model framework structure, sets the functional modules according to actual needs, and analyzes and predicts students&#39; personal performance through student portraits. Finally, this paper designs experiments to analyze the effectiveness of the model proposed in this paper. From the experimental data, it can be seen that the model proposed in this paper basically meets the expected requirements.},
  archive      = {J_NCA},
  author       = {Su, Yingying and Wang, Shengxu and Li, Yi},
  doi          = {10.1007/s00521-021-06333-8},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9369-9383},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on the improvement effect of machine learning and neural network algorithms on the prediction of learning achievement},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RETRACTED ARTICLE: 5G network-oriented machine learning and
national forest park ecotourism management. <em>NCA</em>,
<em>34</em>(12), 9353–9368. (<a
href="https://doi.org/10.1007/s00521-021-06313-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the efficiency of national forest park ecotourism management, this paper analyzes the national forest park ecotourism management based on 5G network and machine learning and analyzes the prediction algorithm based on time series data used in the process of building the flow prediction network model. Moreover, this paper combines the actual data operation requirements to improve the algorithm, builds the system architecture according to the actual requirements of the national forest park ecotourism management, and performs data processing with the support of machine learning and 5G network. In addition, after constructing the system, this paper verifies the performance of the system and processes the test results through statistical methods. From the experimental analysis, it can be seen that the system constructed in this paper basically meets the needs of ecotourism management in the national forest park.},
  archive      = {J_NCA},
  author       = {Yue, Yin},
  doi          = {10.1007/s00521-021-06313-y},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9353-9368},
  shortjournal = {Neural Comput. Appl.},
  title        = {RETRACTED ARTICLE: 5G network-oriented machine learning and national forest park ecotourism management},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation of rural financial ecological environment based
on machine learning and improved neural network. <em>NCA</em>,
<em>34</em>(12), 9335–9352. (<a
href="https://doi.org/10.1007/s00521-021-06312-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the effect of rural financial ecological environment evaluation, this paper combines machine learning and improved neural network algorithms to construct a rural financial ecological environment evaluation system. First, this paper optimizes the input layer structure and its initial weight random assignment. The input layer structure is processed by factor analysis, and the initial weight random assignment is optimized by particle swarm optimization. Secondly, this paper constructs a rural financial ecological environment evaluation model based on factor analysis method and PSO-SOM to avoid the defects of traditional SOM algorithm used in financial ecological environment evaluation research. Finally, this paper constructs a system framework based on actual needs and designs experiments to verify the performance of the evaluation system constructed in this paper. The research results show that the system constructed in this paper meets the basic needs of rural financial ecological environment evaluation.},
  archive      = {J_NCA},
  author       = {Wei, Wen and Zhang, Qiwen},
  doi          = {10.1007/s00521-021-06312-z},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9335-9352},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluation of rural financial ecological environment based on machine learning and improved neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interactive visual computer vision analysis based on
artificial intelligence technology in intelligent education.
<em>NCA</em>, <em>34</em>(12), 9315–9333. (<a
href="https://doi.org/10.1007/s00521-021-06285-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the effect of intelligent education and teaching, under the guidance of artificial intelligence technology, this article combines interactive visual computer vision analysis algorithms to construct an intelligent education assistance system based on machine vision. In the case of multiple points within the movement point area, the calculation is performed by offsetting from the center of the point area. Visual self-calibration reflects the mapping relationship between the image coordinate system and the camera coordinate system by automatically obtaining the relationship between the vectors by moving to different positions. Aiming at the problem of slow template matching, this paper uses fast normalized correlation, integral image and fast Fourier transform methods to optimize the template recognition speed, and uses surface fitting methods to locate the matching results in sub-pixels. Finally, this article combines experiments to verify the performance of the intelligent education system constructed in this article. The research results show that the algorithm model constructed in this paper has certain practical effects.},
  archive      = {J_NCA},
  author       = {Hu, Yan and Li, QiangQiang and Hsu, Shih-wei},
  doi          = {10.1007/s00521-021-06285-z},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9315-9333},
  shortjournal = {Neural Comput. Appl.},
  title        = {Interactive visual computer vision analysis based on artificial intelligence technology in intelligent education},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring real-time fault detection of high-speed train
traction motor based on machine learning and wavelet analysis.
<em>NCA</em>, <em>34</em>(12), 9301–9314. (<a
href="https://doi.org/10.1007/s00521-021-06284-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implementation of real-time fault detection technology for key components of high-speed train traction electromechanical system is of great significance for improving train motor reliability and reducing guarantee costs. It has become an inevitable trend. Machine learning is a new and powerful means of researching fault detection technology. Based on machine learning, this paper conducts real-time fault detection technology research on the electromechanical actuators of the key components of electromechanical systems. A model of the electromechanical actuator is established, and the mechanism, influence and fault injection method of the three faults of the electromechanical actuator motor shaft jamming, gear broken tooth, excessive ball screw clearance and two faults of internal leakage are analyzed. On this basis, a fault simulation model of the traction motor of a high-speed train was built to obtain simulation fault data. At the same time, based on wavelet packet decomposition and reconstruction, the fault simulation data of electromechanical actuators and hydraulic pumps are analyzed, the wavelet packet energy distribution is calculated, and time-domain statistics are combined to extract energy feature vectors that can reflect component fault characteristics. This paper proposes a fault diagnosis method for electromechanical actuators based on machine learning, designs, and improves the neural network learning algorithm and network parameters, and improves the classification effect of the neural network; proposes a fault diagnosis method based on the GA-SVM algorithm, using real values. The coded genetic algorithm improves the parameter optimization of the support vector machine, and improves the classification speed of the support vector machine. Finally, the effectiveness and superiority of the two fault diagnosis methods designed in this paper are verified on their respective objects.},
  archive      = {J_NCA},
  author       = {Li, Yanshu},
  doi          = {10.1007/s00521-021-06284-0},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9301-9314},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring real-time fault detection of high-speed train traction motor based on machine learning and wavelet analysis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Edge computing clone node recognition system based on
machine learning. <em>NCA</em>, <em>34</em>(12), 9289–9300. (<a
href="https://doi.org/10.1007/s00521-021-06283-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing is an important cornerstone for the construction of 5G networks, but with the development of Internet technology, the computer nodes are extremely vulnerable in attacks, especially clone attacks, causing casualties. The principle of clonal node attack is that the attacker captures the legitimate nodes in the network and obtains all their legitimate information, copies several nodes with the same ID and key information, and puts these clonal nodes in different locations in the network to attack the edge computing devices, resulting in network paralysis. How to quickly and efficiently identify clone nodes and isolate them becomes the key to prevent clone node attacks and improve the security of edge computing. In order to improve the degree of protection of edge computing and identify clonal nodes more quickly and accurately, based on edge computing of machine learning, this paper uses case analysis method, the literature analysis method, and other methods to collect data from the database, and uses parallel algorithm to build a model of clonal node recognition. The results show that the edge computing based on machine learning can greatly improve the efficiency of clonal node recognition, the recognition speed is more than 30\% faster than the traditional edge computing, and the recognition accuracy reaches 0.852, which is about 50\% higher than the traditional recognition. The results show that the edge computing clonal node method based on machine learning can improve the detection success rate of clonal nodes and reduce the energy consumption and transmission overhead of nodes, which is of great significance to the detection of clonal nodes.},
  archive      = {J_NCA},
  author       = {Xiao, Xiang and Zhao, Ming},
  doi          = {10.1007/s00521-021-06283-1},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9289-9300},
  shortjournal = {Neural Comput. Appl.},
  title        = {Edge computing clone node recognition system based on machine learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization of physical education and training system based
on machine learning and internet of things. <em>NCA</em>,
<em>34</em>(12), 9273–9288. (<a
href="https://doi.org/10.1007/s00521-021-06278-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the effect of physical education and training, this paper combines machine learning technology to identify sports training features and action prediction, and combines Internet of Things technology to process physical education and training data, and build a physical education and training system based on machine learning and Internet of Things. In order to solve some shortcomings of the original extreme learning machine, this paper gradually optimizes the hidden layer mapping and parameter optimization to further improve the accuracy of prediction. Moreover, this paper uses the Internet of Things technology to achieve long-term uninterrupted data collection, and after the data have been processed to a certain extent, an extreme learning machine is used to predict the situation of sports training. Finally, this paper designs experiments to verify the performance of the system. The research results show that the physical education and training system constructed in this paper have certain practical effects and can optimize the physical education and training process.},
  archive      = {J_NCA},
  author       = {Wang, Chenhang and Du, Cong},
  doi          = {10.1007/s00521-021-06278-y},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9273-9288},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimization of physical education and training system based on machine learning and internet of things},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diagnosis and classification prediction model of pituitary
tumor based on machine learning. <em>NCA</em>, <em>34</em>(12),
9257–9272. (<a
href="https://doi.org/10.1007/s00521-021-06277-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the diagnosis and classification effect of pituitary tumors, this paper combines the current common machine learning methods and classification prediction methods to improve the traditional machine learning algorithms. Moreover, this paper analyzes the feature algorithm based on the feature extraction requirements of pituitary tumor pictures and compares a variety of commonly used algorithms to select a classification algorithm suitable for the model of this paper through comparison methods. In addition, this paper carries out the calculation of the prediction algorithm and verifies the algorithm according to the actual situation. Finally, based on the neural network algorithm, this paper designs and constructs the algorithm function module and combines the actual needs of pituitary tumors to build the model and verify the performance of the model. The research results show that the model system constructed in this paper meets the expected demand.},
  archive      = {J_NCA},
  author       = {Liu, Anmin and Xiao, Yan and Wu, Min and Tan, Yuzhen and He, Yujie and Deng, Yang and Tang, Liang},
  doi          = {10.1007/s00521-021-06277-z},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9257-9272},
  shortjournal = {Neural Comput. Appl.},
  title        = {Diagnosis and classification prediction model of pituitary tumor based on machine learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Spatial–temporal grid clustering method based on frequent
stay point recognition. <em>NCA</em>, <em>34</em>(12), 9247–9255. (<a
href="https://doi.org/10.1007/s00521-021-06274-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to identify geolocation of defaulter and extract travel information from trajectory data, spatial–temporal grid clustering method are adopted to analysis massive trajectory data. Firstly, the trajectory data are preprocessed, and the spacetime cluster method is applied to detect the travelers’ geolocation information based on the information the travel segments are extracted. Secondly, for the recognition of frequent stay point, we proposed the spatial–temporal grid clustering model with smooth trajectory division algorithm and which improve the efficiency of processing a large amount of trajectory data. Thirdly, we proposed the spatial–temporal grid clustering method based on frequent stay point recognition. The experiment results of stationary trajectory division indicate that the frequent stay point and frequent paths can be effectively excavated under the condition of small information loss. These results demonstrate convincingly the effectiveness of the proposed method.},
  archive      = {J_NCA},
  author       = {Zhang, Bin and Wang, Qiuxia and Li, Jing and Ye, Zhou},
  doi          = {10.1007/s00521-021-06274-2},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9247-9255},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatial–temporal grid clustering method based on frequent stay point recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on AI-based web information processing.
<em>NCA</em>, <em>34</em>(12), 9245–9246. (<a
href="https://doi.org/10.1007/s00521-022-07342-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Huang, Chuanchao and Zhou, Shuren},
  doi          = {10.1007/s00521-022-07342-x},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9245-9246},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on AI-based web information processing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved hybrid classification of brain tumor MRI images
based on conglomeration feature extraction techniques. <em>NCA</em>,
<em>34</em>(11), 9069–9086. (<a
href="https://doi.org/10.1007/s00521-022-06929-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The brain seems to be the most complex organ in the human body and operates as the central part of the nervous system. The classification of brain tumors is the most complicated problem which medical experts face. In our proposed work, the novelty is that we have adopted the hybridization of feature exaction techniques and a conglomerate of classification methods. The hybrid features are extracted from the tumor region using the Gray Level Co-occurrence Matrix technique and shape-based features. There are three different types of brain magnetic resonance imaging datasets used in work. For the segmentation, the Marker-controlled watershed segmentation strategy is implemented in this work. In this work, the hybrid classifier, which includes the Random Forest (RF) classifier, K-Nearest Neighbour classifier, and Decision Tree classifier, is implemented. Dataset 1 (China Hospital data) shows a better overall accuracy of 98.75\%; for dataset 2, accuracy is 98.99\%; and for dataset 3, the achieved accuracy is 98.92\%. The other parameters that prove the overall work&#39;s efficacy include sensitivity, precision, specificity, F1-score, Cohen’s kappa value, Dice coefficient, Jaccard Index, and area under the curve (AUC). The proposed work is also compared with the state-of-the-art methods and observed better one.},
  archive      = {J_NCA},
  author       = {Bansal, Twinkle and Jindal, Neeru},
  doi          = {10.1007/s00521-022-06929-8},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {9069-9086},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved hybrid classification of brain tumor MRI images based on conglomeration feature extraction techniques},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modified firefly algorithm for workflow scheduling in
cloud-edge environment. <em>NCA</em>, <em>34</em>(11), 9043–9068. (<a
href="https://doi.org/10.1007/s00521-022-06925-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing is a novel technology, which is closely related to the concept of Internet of Things. This technology brings computing resources closer to the location where they are consumed by end-users—to the edge of the cloud. In this way, response time is shortened and lower network bandwidth is utilized. Workflow scheduling must be addressed to accomplish these goals. In this paper, we propose an enhanced firefly algorithm adapted for tackling workflow scheduling challenges in a cloud-edge environment. Our proposed approach overcomes observed deficiencies of original firefly metaheuristics by incorporating genetic operators and quasi-reflection-based learning procedure. First, we have validated the proposed improved algorithm on 10 modern standard benchmark instances and compared its performance with original and other improved state-of-the-art metaheuristics. Secondly, we have performed simulations for a workflow scheduling problem with two objectives—cost and makespan. We performed comparative analysis with other state-of-the-art approaches that were tested under the same experimental conditions. Algorithm proposed in this paper exhibits significant enhancements over the original firefly algorithm and other outstanding metaheuristics in terms of convergence speed and results’ quality. Based on the output of conducted simulations, the proposed improved firefly algorithm obtains prominent results and managed to establish improvement in solving workflow scheduling in cloud-edge by reducing makespan and cost compared to other approaches.},
  archive      = {J_NCA},
  author       = {Bacanin, Nebojsa and Zivkovic, Miodrag and Bezdan, Timea and Venkatachalam, K. and Abouhawwash, Mohamed},
  doi          = {10.1007/s00521-022-06925-y},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {9043-9068},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modified firefly algorithm for workflow scheduling in cloud-edge environment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated diagnosis of schistosomiasis by using faster r-CNN
for egg detection in microscopy images prepared by the kato–katz
technique. <em>NCA</em>, <em>34</em>(11), 9025–9042. (<a
href="https://doi.org/10.1007/s00521-022-06924-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the biggest concerns in the area of public health is caused by human intestinal parasites, which are found largely in tropical countries. The diagnosis of these parasitic diseases is done through physiological symptoms and fecal examination. Often, few professionals are available and able to perform this type of examination, which is considered time-consuming, requires trained personnel, prone to errors, and can cause eye strain in the specialist. In this paper, we investigate the use of the faster R-CNN object detection method to identify eggs of Schistosoma mansoni, forming a system to aid decision making in the diagnosis of fecal examination. A real database was built with 66 images prepared by the Kato–Katz method. Online and offline data augmentation techniques were used to obtain a larger number of samples. As a result, the proposed solution reached an average precision value of 0.765 for an IoU (intersection over union) of 0.50. The results and applicability of the system are promising and may be used in public health programs to assist health professionals in the diagnosis and monitoring of schistosomiasis in endemic areas.},
  archive      = {J_NCA},
  author       = {Oliveira, Bruno Alberto Soares and Moreira, João Marcelo Peixoto and Coelho, Paulo Ricardo Silva and Negrão-Corrêa, Deborah Aparecida and Geiger, Stefan Michael and Guimarães, Frederico Gadelha},
  doi          = {10.1007/s00521-022-06924-z},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {9025-9042},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated diagnosis of schistosomiasis by using faster R-CNN for egg detection in microscopy images prepared by the Kato–Katz technique},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Overcoming language priors in VQA via adding visual module.
<em>NCA</em>, <em>34</em>(11), 9015–9023. (<a
href="https://doi.org/10.1007/s00521-022-06923-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Answering (VQA) is a new and popular research direction. Dealing with language prior problems has become a hot topic in VQA in the past two years. With the development of technologies relating to VQA, related scholars have realized that in VQA tasks, the generation of answers relies too much on language priors and considers less with visual content. Some of the previous methods to alleviate language priors only focus on processing the question, while the methods to increase visual acuity only concentrate on finding the correct region. To better overcome the language prior problem of VQA, we propose a method that will improve visual content further to enhance the impact of visual content on answers. Our method consists of three parts: the base model branch, the question-only model branch, and the visual model branch. Many experiments have been carried out on the three datasets VQA-CP v1, VQA-CP v2, and VQA v2, which proves the effectiveness of our method and further improves the accuracy of the different models. Our code is available in GitHub ( https://github.com/shonnon-zxs/AddingVisualModule ).},
  archive      = {J_NCA},
  author       = {Zhao, Jia and Zhang, Xuesong and Wang, Xuefeng and Yang, Ying and Sun, Gang},
  doi          = {10.1007/s00521-022-06923-0},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {9015-9023},
  shortjournal = {Neural Comput. Appl.},
  title        = {Overcoming language priors in VQA via adding visual module},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Large scale salp-based grey wolf optimization for feature
selection and global optimization. <em>NCA</em>, <em>34</em>(11),
8989–9014. (<a
href="https://doi.org/10.1007/s00521-022-06921-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salp swarm algorithm (SSA) is a recently developed meta-heuristic swarm intelligence optimization algorithm based on simulating the chain movement behavior of salps sailing and foraging in the sea. In this paper, a novel hybrid meta-heuristic algorithm called SSA-FGWO is proposed to overcome the shortcomings of the original SSA, including slow convergence speed in dealing with high-dimensional and multimodal landscapes, low precision, and global optimization problems. The essential idea of SSA-FGWO is to improve the salp swarm optimization algorithm (SSA) by utilizing the Grey Wolf Algorithm (GWO) strategy. The hybridization mechanism includes two steps: First, the strong exploitation of SSA is applied to update the leaders&#39; position of the chain population. Second, the strong exploration strategy of GWO is used to update the followers&#39; position to increase the population variance of the proposed optimizer. The proposed algorithm is expected to enhance exploration and exploitation ability significantly by the hybrid design. The effectiveness of SSA-FGWO is investigated through CEC2020, 23 representative benchmark cases, and feature selection problems (18 data sets) are solved. The algorithm has been examined for its computational complexity and convergent behavior. In addition to GWO, SSA and other swarm optimization algorithms are employed to compare with the proposed optimizer. The obtained experimental results show that the exploitation, exploration tendencies, and convergence patterns of SSA-FGWO have significantly improved. The results show that the proposed SSA-FGWO algorithm is a promising one that outperforms the basic SSA, GWO, and other algorithms in terms of efficacy.},
  archive      = {J_NCA},
  author       = {Qaraad, Mohammed and Amjad, Souad and Hussein, Nazar K. and Elhosseini, Mostafa A.},
  doi          = {10.1007/s00521-022-06921-2},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8989-9014},
  shortjournal = {Neural Comput. Appl.},
  title        = {Large scale salp-based grey wolf optimization for feature selection and global optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ovarian cancer detection using optical coherence tomography
and convolutional neural networks. <em>NCA</em>, <em>34</em>(11),
8977–8987. (<a
href="https://doi.org/10.1007/s00521-022-06920-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ovarian cancer has the sixth-largest fatality rate in the United States among all cancers. A non-surgical assay capable of detecting ovarian cancer with acceptable sensitivity and specificity has yet to be developed. However, such a discovery would profoundly impact the pace of the treatment and improvement to patients’ quality of life. Achieving such a solution requires high-quality imaging, image processing, and machine learning to support an acceptably robust automated diagnosis. In this work, we propose an automated framework that learns to identify ovarian cancer in transgenic mice from optical coherence tomography (OCT) recordings. Classification is accomplished using a neural network that perceives spatially ordered sequences of tomograms. We present three neural network-based approaches, namely a VGG-supported feed-forward network, a 3D convolutional neural network, and a convolutional LSTM (Long Short-Term Memory) network. Our experimental results show that our models achieve a favorable performance with no manual tuning or feature crafting, despite the challenging noise inherent in OCT images. Specifically, our best performing model, the convolutional LSTM-based neural network, achieves a mean AUC (± standard error) of 0.81 ± 0.037. To the best of the authors’ knowledge, no application of machine learning to analyze depth-resolved OCT images of whole ovaries has been documented in the literature. A significant broader impact of this research is the potential transferability of the proposed diagnostic system from transgenic mice to human organs, which would enable medical intervention from early detection of an extremely deadly affliction.},
  archive      = {J_NCA},
  author       = {Schwartz, David and Sawyer, Travis W. and Thurston, Noah and Barton, Jennifer and Ditzler, Gregory},
  doi          = {10.1007/s00521-022-06920-3},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8977-8987},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ovarian cancer detection using optical coherence tomography and convolutional neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling of dynamic data-driven approach for the distributed
steel rolling heating furnace temperature field. <em>NCA</em>,
<em>34</em>(11), 8959–8975. (<a
href="https://doi.org/10.1007/s00521-022-06917-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic modeling of the steel rolling heating furnace temperature field (SRHFTF) plays a very important role in the process control of the metallurgical industry. It can control and regulate the temperature of the SRHFTF accurately, save energy consumption and reduce industrial carbon emissions. The SRHFTF is a complex system with nonlinear, strong coupling, and multi-variable, it was difficult to build the mechanism model. Meanwhile, the existing data-driven modeling methodology has a gap which describes the dynamical model structure of SRHFTF. Therefore, this paper studies the neural network dynamic data-driven modeling methodology for the RHFTF. Firstly, the multi-input single-output of the SRHFTF neural network model matrices structure is constructed to improve the model fitting effect. Secondly, an improved neural network back-propagation algorithm is proposed, which has higher accuracy and lower computational cost than static data-driven models. Finally, the effectiveness of the artificial neural network dynamic data-driven model and the INNBP algorithm have been verified by the case of the SRHFTF. The simulation results show that the performance of the dynamic neural network model meets the design requirements.},
  archive      = {J_NCA},
  author       = {Bao, Qingfeng and Zhang, Sen and Guo, Jin and Xu, Zhengguang and Zhang, Zhenquan},
  doi          = {10.1007/s00521-022-06917-y},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8959-8975},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modeling of dynamic data-driven approach for the distributed steel rolling heating furnace temperature field},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybridization of soft-computing algorithms with neural
network for prediction obstructive sleep apnea using biomedical sensor
measurements. <em>NCA</em>, <em>34</em>(11), 8933–8957. (<a
href="https://doi.org/10.1007/s00521-022-06919-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sleep apnea (SA) is a common respiratory disorder, especially among obese people. It is caused by either the relaxation of the upper respiratory tract muscles or the failure of the neural signal to reach the muscles responsible for breathing, both of which interrupt the patient’s sleep–wake cycles. The traditional method for diagnosing this disorder, based on polysomnography, is complicated, vexing, expensive, time-consuming, and requires both sleep centers and specialized staff capable of connecting electrodes to the patient’s body. This paper proposes an SA prediction system based on merging five soft computing algorithms, specifically, combining the multi-verse optimizer (MVO) with an artificial neural network (ANN) to leverage measurements from heart rate, SpO2, and chest movement sensors. The most substantial novelty of this research is the hybridization of MVO and ANN (MVO-ANN), which improves the ANN performance by selecting the best learning rate and number of neurons in hidden ANN layers. This enables highly accurate prediction of sleep apnea events. This work’s experimental results reveal that the MVO-ANN performs better than other algorithms, with mean absolute errors of 0.042, 0.202, and 0.166 for training, testing, and validation of the ANN. In addition, the SA prediction system achieved an accuracy of 98.67\%, a sensitivity of 96.71\%, and a specificity of 99.24\%. These results provide good evidence that the proposed method can reliably predict respiratory events in people suffering from SA.},
  archive      = {J_NCA},
  author       = {Chyad, Mustafa Habeeb and Gharghan, Sadik Kamel and Hamood, Haider Qasim and Altayyar, Ahmed Saleh Hameed and Zubaidi, Salah L. and Ridha, Hussein Mohammed},
  doi          = {10.1007/s00521-022-06919-w},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8933-8957},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybridization of soft-computing algorithms with neural network for prediction obstructive sleep apnea using biomedical sensor measurements},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-task deep learning model based on hierarchical
relations of address elements for semantic address matching.
<em>NCA</em>, <em>34</em>(11), 8919–8931. (<a
href="https://doi.org/10.1007/s00521-022-06914-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Address matching, which aims to match unstructured addresses with standard addresses in an address database, is a key part of geocoding. The core problem of address matching corresponds to text matching in natural language processing. Existing rule-based methods require human-designed templates and thus, have limited applicability. Machine learning and deep learning-based methods ignore the hierarchical relations between address elements, which easily misclassify semantically similar but geographically different locations. We note that the hierarchy of address elements can fill the semantic gap in address matching. Inspired by how humans discriminate addresses, we propose a multi-task learning approach. The approach jointly recognises the address elements and matches the addresses to incorporate the hierarchical relations between the address elements into the neural network. Simultaneously, we introduce a priori information on the hierarchical relationship of address elements through the conditional random field model. Experimental results on the benchmark datasets Shenzhen Address Database and Jiangsu-Hunan Address Dataset demonstrate the effectiveness of our approach. We achieved state-of-the-art F1 scores (i.e. the harmonic mean of precision and recall) of 99.0 and 94.2 on the two datasets, respectively.},
  archive      = {J_NCA},
  author       = {Li, Fangfang and Lu, Yiheng and Mao, Xingliang and Duan, Junwen and Liu, Xiyao},
  doi          = {10.1007/s00521-022-06914-1},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8919-8931},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-task deep learning model based on hierarchical relations of address elements for semantic address matching},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cascade chaotic neural network (CCNN): A new model.
<em>NCA</em>, <em>34</em>(11), 8897–8917. (<a
href="https://doi.org/10.1007/s00521-022-06912-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, studies on chaotic neural networks have been increased to construct a robust and flexible intelligent network resembling the human brain. To increase the chaotic performance and to reduce the time-complexity of conventional chaotic neural networks, this paper presents an innovative chaotic architecture called cascade chaotic neural network (CCNN). Cascade chaotic system is inspired by cascade structures in electronic circuits. Cascade structure is based on a combination of two or more one-dimensional chaotic maps. This combination provides a new chaotic map that has more complicated behavior than its grain maps. The fusion of this structure into the network neurons makes the CCNN more capable of confronting nonlinear problems. In the proposed model, cascade chaotic activation function (CCAF) is introduced and applied. Using the CCAF with inherent chaotic features such as increasing variability, ergodicity, maximum entropy, and free saturation zones can be promising to solve or reduce learning problems in conventional AFs without increasing complexity. The complexity does not increase because no parameter is added to the system in use. The required chaos for neural network is generated by the Li oscillator, and then when using the neural network, parameters are considered as constants. Chaotic behavior of the CCNN is investigated through bifurcation diagram. Also, prediction capability of the proposed model is verified through popular benchmark problems. Simulation and analysis demonstrate that in comparison with outstanding chaotic models, the CCNN provides more accurate and robust results in various conditions.},
  archive      = {J_NCA},
  author       = {Abbasi, Hamid and Yaghoobi, Mahdi and Teshnehlab, Mohammad and Sharifi, Arash},
  doi          = {10.1007/s00521-022-06912-3},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8897-8917},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cascade chaotic neural network (CCNN): A new model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Locally fitting hyperplanes to high-dimensional data.
<em>NCA</em>, <em>34</em>(11), 8885–8896. (<a
href="https://doi.org/10.1007/s00521-022-06909-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problems such as data compression, pattern recognition and artificial intelligence often deal with a large data sample as observations of an unknown object. An effective method is proposed to fit hyperplanes to data points in each hypercubic subregion of the original data sample. Corresponding to a set of affine linear manifolds, the locally fitted hyperplanes optimally approximate the object in the sense of least squares of their perpendicular distances to the sample points. Its effectiveness and versatility are illustrated through approximation of nonlinear manifolds Möbius strip and Swiss roll, handwritten digit recognition, dimensionality reduction in a cosmological application, inter/extrapolation for a social and economic data set, and prediction of recidivism of criminal defendants. Based on two essential concepts of hyperplane fitting and spatial data segmentation, this general method for unsupervised learning is rigorously derived. The proposed method requires no assumptions on the underlying object and its data sample. Also, it has only two parameters, namely the size of segmenting hypercubes and the number of fitted hyperplanes for user to choose. These make the proposed method considerably accessible when applied to solving various problems in real applications.},
  archive      = {J_NCA},
  author       = {Hou, M. and Kambhampati, C.},
  doi          = {10.1007/s00521-022-06909-y},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8885-8896},
  shortjournal = {Neural Comput. Appl.},
  title        = {Locally fitting hyperplanes to high-dimensional data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tangent search algorithm for solving optimization problems.
<em>NCA</em>, <em>34</em>(11), 8853–8884. (<a
href="https://doi.org/10.1007/s00521-022-06908-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a new population-based optimization algorithm called the Tangent Search Algorithm (TSA) to solve optimization problems. The TSA uses a mathematical model based on the tangent function to move a given solution toward a better solution. The tangent flight function has the advantage to balance between the exploitation and the exploration search. Moreover, a novel escape procedure is used to avoid to be trapped in local minima. Besides, an adaptive variable step-size is also integrated in this algorithm to enhance the convergence capacity. The performance of TSA is assessed in three classes of tests: classical tests, CEC benchmarks, and engineering optimization problems. Moreover, several studies and metrics have been used to observe the behavior of the proposed TSA. The experimental results show that TSA algorithm is capable to provide very promising and competitive results on most benchmark functions thanks to better balance between exploration and exploitation of the search space. The main characteristics of this new optimization algorithm is its simplicity and efficiency and it requires only a small number of user-defined parameters.},
  archive      = {J_NCA},
  author       = {Layeb, Abdesslem},
  doi          = {10.1007/s00521-022-06908-z},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8853-8884},
  shortjournal = {Neural Comput. Appl.},
  title        = {Tangent search algorithm for solving optimization problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Boosting arithmetic optimization algorithm by sine cosine
algorithm and levy flight distribution for solving engineering
optimization problems. <em>NCA</em>, <em>34</em>(11), 8823–8852. (<a
href="https://doi.org/10.1007/s00521-022-06906-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several metaheuristic methods have been applied to tackling various global and engineering optimization problems. However, this method still needs more improvement since they require a suitable balance between exploration and exploitation. Therefore, this study presents an enhancement of the arithmetic optimization algorithm (AOA) as a global optimization method. The developed method, named AOASC, depends on using the sine-cosine algorithm’s operators to enhance the exploitation ability of AOA during the searching process. This leads to improving the convergence rate of the developed method toward the optimal solution. Besides, improve the process of avoiding the attraction toward the local point. Besides these behaviors, the quality of the final solution (best one) is improved. To validate the efficiency of the developed method, a set of experiments is conducted, including various optimization problems, such as ten benchmark functions and five engineering optimization problems. Besides, the results of the developed method are compared with other well-known metaheuristic methods. The results showed the high efficiency of the developed method over other methods in terms of performance measures.},
  archive      = {J_NCA},
  author       = {Abualigah, Laith and Ewees, Ahmed A. and Al-qaness, Mohammed A. A. and Elaziz, Mohamed Abd and Yousri, Dalia and Ibrahim, Rehab Ali and Altalhi, Maryam},
  doi          = {10.1007/s00521-022-06906-1},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8823-8852},
  shortjournal = {Neural Comput. Appl.},
  title        = {Boosting arithmetic optimization algorithm by sine cosine algorithm and levy flight distribution for solving engineering optimization problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). DGA botnet detection method based on capsule network and
k-means routing. <em>NCA</em>, <em>34</em>(11), 8803–8821. (<a
href="https://doi.org/10.1007/s00521-022-06904-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the current mainstream DGA domain name detection methods, scalars are almost used to represent numerical features, resulting in the loss of the spatial feature information of domain name characters. This paper proposes a sequence capsule network based on the k-means routing algorithm, LSTM-CapsNet, which only uses DGA domain name text information for detection. The model uses a bidirectional LSTM unit to extract basic features for the capsule network and uses the k-means algorithm to cluster vector features to implement routing functions. In order to verify the proposed LSTM-CapsNet model, data from two different sources are collected to ensure the reliability of the experiment, covering the DGA domain name dataset from the real network defined as Real-Dataset, and the DGA domain name obtained through the domain name generation algorithm is defined as Gen-Dataset. The current DGA domain name detection method of state-of-the-art proposed by researchers is compared and tested on two data sets. The experimental results show that the proposed model has achieved 99.17\% and 97.75\% of the F-score evaluation indicators in the DGA domain name recognition of the two datasets; at the same time, the recognition of the DGA domain name family has been very competitive. Compared with the existing DGA domain name family classification model, the F-score value of the proposed model exceeds 89\% in Gen-Dataset multi-class recognition. This model not only improves the ability of DGA domain name recognition and DGA domain name family recognition but also has an outstanding ability to find real-time aspects in model testing.},
  archive      = {J_NCA},
  author       = {Liu, Xiaoyang and Liu, Jiamiao},
  doi          = {10.1007/s00521-022-06904-3},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8803-8821},
  shortjournal = {Neural Comput. Appl.},
  title        = {DGA botnet detection method based on capsule network and k-means routing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Social ski driver conditional autoregressive-based deep
learning classifier for flight delay prediction. <em>NCA</em>,
<em>34</em>(11), 8777–8802. (<a
href="https://doi.org/10.1007/s00521-022-06898-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of robust flight delay prediction has recently increased in the air transportation industry. This industry seeks alternative methods and technologies for more robust flight delay prediction because of its significance for all stakeholders. The most affected are airlines that suffer from monetary and passenger loyalty losses. Several studies have attempted to analysed and solve flight delay prediction problems using machine learning methods. This research proposes a novel alternative method, namely social ski driver conditional autoregressive-based (SSDCA-based) deep learning. Our proposed method combines the Social Ski Driver algorithm with Conditional Autoregressive Value at Risk by Regression Quantiles. We consider the most relevant instances from the training dataset, which are the delayed flights. We applied data transformation to stabilise the data variance using Yeo-Johnson. We then perform the training and testing of our data using deep recurrent neural network (DRNN) and SSDCA-based algorithms. The SSDCA-based optimisation algorithm helped us choose the right network architecture with better accuracy and less error than the existing literature. The results of our proposed SSDCA-based method and existing benchmark methods were compared. The efficiency and computational time of our proposed method are compared against the existing benchmark methods. The SSDCA-based DRNN provides a more accurate flight delay prediction with 0.9361 and 0.9252 accuracy rates on both dataset-1 and dataset-2, respectively. To show the reliability of our method, we compared it with other meta-heuristic approaches. The result is that the SSDCA-based DRNN outperformed all existing benchmark methods tested in our experiment.},
  archive      = {J_NCA},
  author       = {Bisandu, Desmond Bala and Moulitsas, Irene and Filippone, Salvatore},
  doi          = {10.1007/s00521-022-06898-y},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8777-8802},
  shortjournal = {Neural Comput. Appl.},
  title        = {Social ski driver conditional autoregressive-based deep learning classifier for flight delay prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated ECG multi-class classification system based on
combining deep learning features with HRV and ECG measures.
<em>NCA</em>, <em>34</em>(11), 8755–8775. (<a
href="https://doi.org/10.1007/s00521-022-06889-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrocardiogram (ECG) serves as the gold standard for noninvasive diagnosis of several types of heart disorders. In this study, a novel hybrid approach of deep neural network combined with linear and nonlinear features extracted from ECG and heart rate variability (HRV) is proposed for ECG multi-class classification. The proposed system enhances the ECG diagnosis performance by combining optimized deep learning features with an effective aggregation of ECG features and HRV measures using chaos theory and fragmentation analysis. The constant-Q non-stationary Gabor transform technique is employed to convert the 1-D ECG signal into 2-D image which is sent to a pre-trained convolutional neural network structure, called AlexNet. The pair-wise feature proximity algorithm is employed to select the optimal features from the AlexNet output feature vector to be concatenated with the ECG and HRV measures. The concatenated features are sent to different types of classifiers to distinguish three distinct subjects, namely congestive heart failure, arrhythmia, and normal sinus rhythm (NSR). The results reveal that the linear discriminant analysis classifier has the highest accuracy compared to the other classifiers. The proposed system is investigated with real ECG data taken from well-known databases, and the experimental results show that the proposed diagnosis system outperforms other recent state-of-the-art systems in terms of accuracy 98.75\%, specificity 99.00\%, sensitivity of 98.18\%, and computational time 0.15 s. This demonstrates that the proposed system can be used to assist cardiologists in enhancing the accuracy of ECG diagnosis in real-time clinical setting.},
  archive      = {J_NCA},
  author       = {Eltrass, Ahmed S. and Tayel, Mazhar B. and Ammar, Abeer I.},
  doi          = {10.1007/s00521-022-06889-z},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8755-8775},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated ECG multi-class classification system based on combining deep learning features with HRV and ECG measures},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-attention-based time-variant neural networks for
multi-step time series forecasting. <em>NCA</em>, <em>34</em>(11),
8737–8754. (<a
href="https://doi.org/10.1007/s00521-021-06871-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is ubiquitous in various scientific and industrial domains. Powered by recurrent and convolutional and self-attention mechanism, deep learning exhibits high efficacy in time series forecasting. However, the existing forecasting methods are suffering some limitations. For example, recurrent neural networks are limited by the gradient vanishing problem, convolutional neural networks cost more parameters, and self-attention has a defect in capturing local dependencies. What’s more, they all rely on time invariant or stationary since they leverage parameter sharing by repeating a set of fixed architectures with fixed parameters over time or space. To address the above issues, in this paper we propose a novel time-variant framework named Self-Attention-based Time-Variant Neural Networks (SATVNN), generally capable of capturing dynamic changes of time series on different scales more accurately with its time-variant structure and consisting of self-attention blocks that seek to better capture the dynamic changes of recent data, with the help of Gaussian distribution, Laplace distribution and a novel Cauchy distribution, respectively. SATVNN obviously outperforms the classical time series prediction methods and the state-of-the-art deep learning models on lots of widely used real-world datasets.},
  archive      = {J_NCA},
  author       = {Gao, Changxia and Zhang, Ning and Li, Youru and Bian, Feng and Wan, Huaiyu},
  doi          = {10.1007/s00521-021-06871-1},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8737-8754},
  shortjournal = {Neural Comput. Appl.},
  title        = {Self-attention-based time-variant neural networks for multi-step time series forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph alternate learning for robust graph neural networks in
node classification. <em>NCA</em>, <em>34</em>(11), 8723–8735. (<a
href="https://doi.org/10.1007/s00521-021-06863-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The real-world graphs are full of noises and perturbation. However, recent studies show that the existing graph neural networks (GNNs) are usually sensitive to the quality of the input graph. In this work, we propose a graph alternate learning (GAL) framework to alternately train dual models, i.e., prediction network to learn the graph structure for node classification tasks and graph regularization network to enhance the robustness of GNNs. The adoption of dual models, which learn and teach each other collaboratively at the entire training process, drives the formation of a better graph structure. Furthermore, a node feature selection method is integrated into the GAL network to reduce the influence of node attack. Lastly, in order to evaluate the anti-attack ability of GAL, we devise a smooth input graph adversarial attack, called Smooth-Attack, which can degrade the node classification performance of graph convolutional networks (GCN) and is considered to be a form of over-smoothing. Experiments show that our proposed GAL model can keep superiority on benchmark datasets under edge and node perturbation, and GAL is highly robust against Smooth-Attack.},
  archive      = {J_NCA},
  author       = {Zhang, Baoliang and Guo, Xiaoxin and Tu, Zhenchuan and Zhang, Jia},
  doi          = {10.1007/s00521-021-06863-1},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8723-8735},
  shortjournal = {Neural Comput. Appl.},
  title        = {Graph alternate learning for robust graph neural networks in node classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Short-term data-based spatial parallel autoreservoir
computing on spatiotemporally chaotic system prediction. <em>NCA</em>,
<em>34</em>(11), 8713–8722. (<a
href="https://doi.org/10.1007/s00521-021-06854-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel machine learning method for predicting chaotic spatiotemporal systems by proposing a parallel reservoir-like neural network. In contrast to previous machine learning methods, which require big data and suffer from high computing costs, the main advantage of the method is that it is based on short-term data and only needs to train the weight of the output layer. Theoretically, the ratio of training data length and the prediction data length can reach 2:1. First, the method for transforming an infinite-dimensional system into a finite-dimensional system is introduced. Then, based on this concept and the spatiotemporal information transformation, a network training algorithm of spatial parallel autoreservoir computing structure is proposed. Numerical experiments verified that with short-term data, the proposed method performs better than some widely used data-driven methods.},
  archive      = {J_NCA},
  author       = {Wang, Yin and Liu, Shutang},
  doi          = {10.1007/s00521-021-06854-2},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8713-8722},
  shortjournal = {Neural Comput. Appl.},
  title        = {Short-term data-based spatial parallel autoreservoir computing on spatiotemporally chaotic system prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joining features by global guidance with bi-relevance
trihard loss for person re-identification. <em>NCA</em>,
<em>34</em>(11), 8697–8712. (<a
href="https://doi.org/10.1007/s00521-021-06852-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (ReID) aims to associate the person with the given identity across different cameras, which has wide application in the field of intelligent video. In this work, an efficient method is proposed to improve ReID performance. First, a global-guided feature joint network is designed, which consists of a multiple feature extraction network and a global-guided feature fusion network. The former can align different body regions and extract global feature and local features. The latter utilizes the global feature to guide the adaptive fusion of the local features, which can evaluate the importance of different local features dynamically. Secondly, a Bi-relevance TriHard loss (TriBR) is designed to penalize the loss dynamically. TriBR combines Euclidean distance and angle information, which considers the self-relevance of the intra-class samples and the cross-relevance of the inter-class samples simultaneously. Besides, TriBR can adaptively adjust the distance margin and the angle margin to optimize the network. The proposed TriBR is advantageous to learn more discriminative features. The method achieves 89.2\% mAP (mean Average Precision) with 95.8\% Rank-1 on Market-1501, 79.7\% mAP with 89.3\% Rank-1 on DukeMTMC. The proposed method also performs excellently on the datasets for the occluded person re-identification problem.},
  archive      = {J_NCA},
  author       = {Yu, Zhi and Qin, Wencheng and Huang, Zhiyong and Tahsin, Lamia and Sun, Daming and Zhong, Yuanhong},
  doi          = {10.1007/s00521-021-06852-4},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8697-8712},
  shortjournal = {Neural Comput. Appl.},
  title        = {Joining features by global guidance with bi-relevance trihard loss for person re-identification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid deep learning and genetic algorithms approach
(HMB-DLGAHA) for the early ultrasound diagnoses of breast cancer.
<em>NCA</em>, <em>34</em>(11), 8671–8695. (<a
href="https://doi.org/10.1007/s00521-021-06851-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the most commonly diagnosed cancers in the world that has overtaken lung cancer and is considered a leading cause of molarity. The current study objectives are to (1) design an abstract CNN architecture named “HMB1-BUSI,” (2) suggest a hybrid deep learning and genetic algorithm approach for the learning and optimization named HMB-DLGAHA, (3) apply the transfer learning approach using pre-trained models, (4) study the effects of regularization, optimizers, dropout, and data augmentation through fourteen experiments, and (5) report the state-of-the-art performance metrics compared with other related studies and approaches. The dataset is collected and unified from two different sources (1) “Breast Ultrasound Images Dataset (Dataset BUSI)” and (2) “Breast Ultrasound Image.” The experiments implement the weighted sum (WS) method to judge the overall performance and generalization using loss, accuracy, F1-score, precision, recall, specificity, and area under curve (AUC) metrics with different ratios. MobileNet, MobileNetV2, InceptionResNetV2, DenseNet121, DenseNet169, DenseNet201, RestNet50, ResNet101, ResNet152, RestNet50V2, ResNet101V2, ResNet152V2, Xception, and VGG19 pre-trained CNN models are used in the experiments. Xception reported $$85.17\%$$ as the highest WS metric. Xception, ResNet152V2, and ResNet101V2 reported accuracy and F1-score values above $$90\%$$ . Xception, ResNet152V2, ResNet101V2, and DenseNet169 reported precision values above $$90\%$$ . Xception and ResNet152V2 reported recall values above $$90\%$$ . All models unless ResNet152, ResNet50, and ResNet101 reported specificity values above $$90\%$$ and unless ResNet152, ResNet50, ResNet101, and VGG19 reported AUC values above $$90\%$$ .},
  archive      = {J_NCA},
  author       = {Balaha, Hossam Magdy and Saif, Mohamed and Tamer, Ahmed and Abdelhay, Ehab H.},
  doi          = {10.1007/s00521-021-06851-5},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8671-8695},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid deep learning and genetic algorithms approach (HMB-DLGAHA) for the early ultrasound diagnoses of breast cancer},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Brain stroke lesion segmentation using consistent perception
generative adversarial network. <em>NCA</em>, <em>34</em>(11),
8657–8669. (<a
href="https://doi.org/10.1007/s00521-021-06816-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The state-of-the-art deep learning methods have demonstrated impressive performance in segmentation tasks. However, the success of these methods depends on a large amount of manually labeled masks, which are expensive and time-consuming to be collected. In this work, a novel consistent perception generative adversarial network (CPGAN) is proposed for semi-supervised stroke lesion segmentation. The proposed CPGAN can reduce the reliance on fully labeled samples. Specifically, a similarity connection module (SCM) is designed to capture the information of multi-scale features. The proposed SCM can selectively aggregate the features at each position by a weighted sum. Moreover, a consistent perception strategy is introduced into the proposed model to enhance the effect of brain stroke lesion prediction for the unlabeled data. Furthermore, an assistant network is constructed to encourage the discriminator to learn meaningful feature representations which are often forgotten during training stage. The assistant network and the discriminator are employed to jointly decide whether the segmentation results are real or fake. The CPGAN was evaluated on the Anatomical Tracings of Lesions After Stroke (ATLAS). The experimental results demonstrate that the proposed network achieves superior segmentation performance. In semi-supervised segmentation task, the proposed CPGAN using only two-fifths of labeled samples outperforms some approaches using full labeled samples.},
  archive      = {J_NCA},
  author       = {Wang, Shuqiang and Chen, Zhuo and You, Senrong and Wang, Bingchuan and Shen, Yanyan and Lei, Baiying},
  doi          = {10.1007/s00521-021-06816-8},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8657-8669},
  shortjournal = {Neural Comput. Appl.},
  title        = {Brain stroke lesion segmentation using consistent perception generative adversarial network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Embedding vector generation based on function call graph for
effective malware detection and classification. <em>NCA</em>,
<em>34</em>(11), 8643–8656. (<a
href="https://doi.org/10.1007/s00521-021-06808-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surge of malware poses a huge threat to cyberspace security. The existing malware analysis methods based on machine learning mainly rely on feature engineering. These methods need to extract many handcrafted features from the malware to improve accuracy, which increases the complexity of malware analysis. In order to solve this problem, this paper proposes GEMAL, a new malware analysis method based on function call graph (FCG) and graph embedding network. FCG contains the structure information of the binary file and has been used in various research of malware analysis. Inspired by natural language processing tasks, we treat instructions as words and functions as sentences, so that we can automatically extract semantic features using the natural language processing method. We use an attention mechanism based graph embedding network to combine structural features and semantic features to generate embedding vectors of malware for automatic and efficient malware analysis. We use two datasets to test the efficiency of GEMAL. One is a self-created dataset named WUFCG, which contains 70,188 real-world samples. The other one is the public dataset of the Microsoft Malware Classification Challenge, which contains 10,868 samples. Experimental results show that GEMAL can detect real-world malware with 99.16\% accuracy and classify malware families with the best accuracy of 99.81\%.},
  archive      = {J_NCA},
  author       = {Wu, Xiao-Wang and Wang, Yan and Fang, Yong and Jia, Peng},
  doi          = {10.1007/s00521-021-06808-8},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8643-8656},
  shortjournal = {Neural Comput. Appl.},
  title        = {Embedding vector generation based on function call graph for effective malware detection and classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bayesian finite-element trained machine learning approach
for predicting post-burn contraction. <em>NCA</em>, <em>34</em>(11),
8635–8642. (<a
href="https://doi.org/10.1007/s00521-021-06772-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Burn injuries can decrease the quality of life of a patient tremendously, because of esthetic reasons and because of contractions that result from them. In severe case, skin contraction takes place at such a large extent that joint mobility of a patient is significantly inhibited. In these cases, one refers to a contracture. In order to predict the evolution of post-wounding skin, several mathematical model frameworks have been set up. These frameworks are based on complicated systems of partial differential equations that need finite element-like discretizations for the approximation of the solution. Since these computational frameworks can be expensive in terms of computation time and resources, we study the applicability of neural networks to reproduce the finite element results. Our neural network is able to simulate the evolution of skin in terms of contraction for over one year. The simulations are based on 25 input parameters that are characteristic for the patient and the injury. One of such input parameters is the stiffness of the skin. The neural network results have yielded an average goodness of fit ( $$R^2$$ ) of 0.9928 (± 0.0013). Further, a tremendous speed-up of 19354X was obtained with the neural network. We illustrate the applicability by an online medical App that takes into account the age of the patient and the length of the burn.},
  archive      = {J_NCA},
  author       = {Egberts, Ginger and Schaaphok, Marianne and Vermolen, Fred and Zuijlen, Paul van},
  doi          = {10.1007/s00521-021-06772-3},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8635-8642},
  shortjournal = {Neural Comput. Appl.},
  title        = {A bayesian finite-element trained machine learning approach for predicting post-burn contraction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic differential annealing-based anti-spoofing model for
fingerprint detection using CNN. <em>NCA</em>, <em>34</em>(11),
8617–8633. (<a
href="https://doi.org/10.1007/s00521-021-06758-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data security and privacy play a significant role in human life over the past few years. In the present digital era, advanced technologies utilize wide reliance and ubiquity to assist the counter theft system. Due to the enhanced crime rate, determining the solution becomes a burdensome process to recognize the fingerprint. To overcome such shortcomings, this paper proposes a convolution neural network and dynamic differential annealing (CNN-DDA)-based spoofed fingerprint detection. Here a CNN-DDA approach is proposed to analyze and evaluate the false or forged fingerprint concerning spoof forgery authentication system. The main intention of CNN-DDA architecture employs in investigating a complicated and problematic relationship among various features thus enabling highly detailed features. The proposed CNN-DDA-based spoofed fingerprint detection uses various datasets namely LivDet 2015 and LivDet 2013 for evaluation. Also, the real image set is captured using various fingerprint scanners such as Gelatine, wood glue, ecoflex and modasil. The experimental analysis is conducted for various evaluation measures such as accuracy rate, classification error value rate and processing time. The results revealed that the proposed approach provides high spoofed fingerprint detection with a better accuracy rate, less processing time and classification error.},
  archive      = {J_NCA},
  author       = {Maheswari, B. Uma and Rajakumar, M. P. and Ramya, J.},
  doi          = {10.1007/s00521-021-06758-1},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8617-8633},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic differential annealing-based anti-spoofing model for fingerprint detection using CNN},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of an AI-based FSA for real-time condition
monitoring for industrial machine. <em>NCA</em>, <em>34</em>(11),
8597–8615. (<a
href="https://doi.org/10.1007/s00521-021-06741-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated continuous condition monitoring of industrial electrical machines to identify internal faults has become one of the critical research areas for the past decade. Among various defects, early-stage identification of insulation failure in stator winding is of notable demand as it often occurs and accounts for 37\% of the overall motor failures. Identifying the current signature at its embryonic stage will effectively improve industrial machinery’s downtime and repair costs. Recent advances in computational performance and sensor technology concede advanced systems for achieving these goals. The design of an AI-based fault signature analyzer (FSA) has been developed in this paper. FSA uses real-time stator current data in the time and frequency domain from healthy and faulty induction motors to train the various AI-based machine learning classifiers to identify health conditions using wavelets. Comparing machine learning algorithms such as artificial neural network, random forest, fuzzy logic, neuro-fuzzy logic, K-nearest neighbors is performed, and various performance attributes are quantified. A reliable, automatic fault signature from a motor current is thus analyzed using the fusion of a wavelet-based feature extraction technique and a capable knowledge-based efficient artificial intelligence (AI) approach.},
  archive      = {J_NCA},
  author       = {Verma, Amar Kumar and Raval, Pallav Devang and Rajagopalan, Neha and Khariya, Vaishnavi and Sudha, Radhika},
  doi          = {10.1007/s00521-021-06741-w},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8597-8615},
  shortjournal = {Neural Comput. Appl.},
  title        = {Development of an AI-based FSA for real-time condition monitoring for industrial machine},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymptotic stability of singular delayed reaction-diffusion
neural networks. <em>NCA</em>, <em>34</em>(11), 8587–8595. (<a
href="https://doi.org/10.1007/s00521-021-06740-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The asymptotic stability of delayed reaction-diffusion neural networks with algebraic constraints, that is, singular delayed reaction-diffusion neural networks, is studied in this paper. In terms of Green’s theorem, inequality technique and linear matrix inequalities (LMIs), two less conservative criterion for the asymptotic stability of singular delayed reaction-diffusion neural networks are given by endowing Lyapunov direct method and used to design an appropriate stabilizing feedback controllers. The results address both the effects of the delay and the algebraic constraints. In addition, these conditions have higher computational efficiency and can easily detect and stabilize the actual neural networks. Finally, the numerical simulations verify the validity of the theoretical analysis.},
  archive      = {J_NCA},
  author       = {Wu, Xiang and Liu, Shutang and Wang, Yin and Bi, Zhimin},
  doi          = {10.1007/s00521-021-06740-x},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8587-8595},
  shortjournal = {Neural Comput. Appl.},
  title        = {Asymptotic stability of singular delayed reaction-diffusion neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalized transformer in fault diagnosis of tennessee
eastman process. <em>NCA</em>, <em>34</em>(11), 8575–8585. (<a
href="https://doi.org/10.1007/s00521-021-06711-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis is an important yet challenging task. Because of the powerful feature representation capabilities of deep model, intelligent fault diagnosis on deep learning becomes a research hotspot in the field. Although many deep models as sparse autoencoder, deep belief network is developed for fault diagnosis with encouraging performance, integrating the merits of deep learning into fault diagnosis still has a long way to go. In this paper, we propose a novel method, namely generalized transformer. Compared to previous deep models, generalized transformer excavates relations among inputs and nonlinearity between inputs and outputs by attention mechanism. To deal with structured data, generalized transformer further borrows the idea from graph attention network. By replacing dot product between query and key information in transformer, we introduce a forward network with learned weight vector to compute the similarity. Through limiting the similarity calculations in a neighbor region, prior knowledge can be injected into generalized transformer. On Tennessee Eastman process dataset, our new model can produce high performance, which is better or competitive to state-of-the-art models. Extensive ablation studies validate the effectiveness of the proposed model.},
  archive      = {J_NCA},
  author       = {Zhang, Lei and Song, Zhihuan and Zhang, Qinghua and Peng, Zhiping},
  doi          = {10.1007/s00521-021-06711-2},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8575-8585},
  shortjournal = {Neural Comput. Appl.},
  title        = {Generalized transformer in fault diagnosis of tennessee eastman process},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new PDE learning model for image denoising. <em>NCA</em>,
<em>34</em>(11), 8551–8574. (<a
href="https://doi.org/10.1007/s00521-021-06620-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting appropriate terms to design partial differential equations (PDEs) for specific processing and vision tasks have a prominent role in achieving acceptable results. In this paper, we present an automatic method to obtain a set of suitable terms of PDE for specific processing and vision tasks. Therefore, a new optimization framework has been constructed which is constrained with PDEs in the form of linear combinations of differential terms with time-independent coefficients, and is solved through training data. The optimization problem could be solved by translating it to a least square problem through the assumption of independency of time. By this assumption, it is possible to select any arbitrary term for the PDE and blend different PDEs for processing tasks, including image denoising. Several numerical experiments in image denoising prove the present model robust to the size of data and the kind of its noise.},
  archive      = {J_NCA},
  author       = {Ashouri, F. and Eslahchi, M. R.},
  doi          = {10.1007/s00521-021-06620-4},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8551-8574},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new PDE learning model for image denoising},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). QuasiVSD: Efficient dual-frame smoke detection.
<em>NCA</em>, <em>34</em>(11), 8539–8550. (<a
href="https://doi.org/10.1007/s00521-021-06606-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smoke is a typical symptom of early fire, and the appearance of a large amount of abnormal smoke usually indicates an impending abnormal accident. A smart smoke detection method can substantially reduce damage caused by fires in cities, factories and forests, it is also an important component of intelligent surveillance system. However, existing image-based detection methods often suffer from the lack of dynamic information, and video-based methods are usually computing-expensive because more input images need to be processed. In this work, we propose a novel and efficient Quasi Video Smoke Detector (QuasiVSD) to bridge the gap between image-based and video-based smoke detection. By regarding an unannotated image as reference, QuasiVSD can obtain motion-aware attention from just two frames. Moreover, Weakly Guided Attention Module is designed to further refine the feature representation for smoke regions. Finally, extensive experiments on real-world dataset show that our QuasiVSD achieves clear improvements against the image-based best competitors (CenterNet) by 4.71 with almost same parameters and FLOPs. And the computational complexity of QuasiVSD is just a fraction of that of general video understanding framework. Code will be available at: https://github.com/Caoyichao/VSDT.},
  archive      = {J_NCA},
  author       = {Cao, Yichao and Tang, Qingfei and Xu, Shaosheng and Li, Fan and Lu, Xiaobo},
  doi          = {10.1007/s00521-021-06606-2},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8539-8550},
  shortjournal = {Neural Comput. Appl.},
  title        = {QuasiVSD: Efficient dual-frame smoke detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Ancient poetry generation with an unsupervised method.
<em>NCA</em>, <em>34</em>(11), 8525–8538. (<a
href="https://doi.org/10.1007/s00521-021-06571-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is challenging to use unsupervised machine translation models to generate ancient poems. The current method has solved the problems of Under-translation and Over-translation caused by the huge length difference between the translated sentence pairs. However, the above method lacks guidance in generating intermediate vectors, and the denoising ability of the model is very poor. In this paper, we guide vector space distribution during training to improve the quality of the generated ancient poems and the convergence speed of the model. We also introduce the target language information while adding noise, which effectively avoids the recurrence of the Under-translation problem while improving the model&#39;s denoising ability. Experiment results on the VP dataset show that our model obtains state-of-the-art results with faster convergence speed. In addition to the BLEU scores, we also made a comparative analysis of ancient poetry sentences generated by different models. The analysis results show that the optimization method proposed in this paper is indeed helpful for generating high-quality ancient poems.},
  archive      = {J_NCA},
  author       = {Zhang, Zhanjun and Zhang, Haoyu and Wan, Qian and Jia, Xiangyu and Zhang, Zhe and Liu, Jie},
  doi          = {10.1007/s00521-021-06571-w},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8525-8538},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ancient poetry generation with an unsupervised method},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Road accident risk prediction using generalized regression
neural network optimized with self-organizing map. <em>NCA</em>,
<em>34</em>(11), 8511–8524. (<a
href="https://doi.org/10.1007/s00521-021-06549-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A road accident risk map that is designed to locate high-risk areas is an efficient way to reduce road traffic injuries and fatalities. To produce an accurate road accident risk map, it is required to compute the probability of the accident&#39;s occurrence by considering the various variables that contribute to road accidents. To this end, this research proposed a generalized regression neural network tuned with self-organizing map to estimate the risk of road accidents. This hybrid predictive model estimates the road accident risk by considering 22 different predictor variables (features), including geographic characteristics, temporal conditions, weather conditions, road-related characteristics, vehicle-related characteristics, and driver characteristics calculated based on the authoritative data sources and volunteered geographic information (VGI). The required VGI was collected in this study by developing a third-party application that was run inside telegram messenger. To evaluate the performance and usability of the proposed model for estimation of the accident risk along the road, the developed model was applied to the Tabriz-Marand dual carriageway, Iran. In this sense, 30 different scenarios were designed, and for each scenario, the risk of the accident was predicted at 3008 points along the Tabriz-Marand dual carriageway. A quality assessment of the proposed approach for different scenarios demonstrated that the predicted accident risk had very high accuracy (average accuracy about 90.74\%). According to the results of this research, distance from traffic control cameras, day of the week, driver’s age, weather, elevation, and vehicle type were the most effective factors in high-risk areas of the study area.},
  archive      = {J_NCA},
  author       = {Kaffash Charandabi, Neda and Gholami, Amir and Abdollahzadeh Bina, Ali},
  doi          = {10.1007/s00521-021-06549-8},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8511-8524},
  shortjournal = {Neural Comput. Appl.},
  title        = {Road accident risk prediction using generalized regression neural network optimized with self-organizing map},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on water temperature prediction based on improved
support vector regression. <em>NCA</em>, <em>34</em>(11), 8501–8510. (<a
href="https://doi.org/10.1007/s00521-020-04836-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a model for predicting the water temperature of the reservoir incorporating with solar radiation to analyze and evaluate the water temperature of large high-altitude reservoirs in western China. Through mutual information inspection, the model shows that the dependent variable has a good correlation with water temperature, and it is added to the sample feature training model. Then, the measured water temperature data in the reservoir for many years are used to establish the support vector regression (SVR) model, and genetic algorithm (GA) is introduced to optimize the parameters, so as to construct an improved support vector machine (M-GASVR). At the same time, root-mean-square error, mean absolute error, mean absolute percentage error, and Nash–Sutcliffe efficiency coefficient are used as the criteria for evaluating the performance of SVR model, ANN model, GA-SVR model, and M-GASVR model. In addition, the M-GASVR model is used to simulate the water temperature of the reservoir under different working conditions. The results show that ANN model is the worst among the four models, while GA-SVR model is better than SVR model in terms of metric, and M-GASVR model is the best. For non-stationary sequences, the prediction model M-GASVR can well predict the vertical water temperature and water temperature structure in the reservoir area. This study provides useful insights into the prediction of vertical water temperature at different depths of reservoirs.},
  archive      = {J_NCA},
  author       = {Quan, Quan and Hao, Zou and Xifeng, Huang and Jingchun, Lei},
  doi          = {10.1007/s00521-020-04836-4},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8501-8510},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on water temperature prediction based on improved support vector regression},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weakly-supervised temporal action localization: A survey.
<em>NCA</em>, <em>34</em>(11), 8479–8499. (<a
href="https://doi.org/10.1007/s00521-022-07102-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Action Localization (TAL) is an important task of various computer vision topics such as video understanding, summarization, and analysis. In the real world, the videos are long untrimmed and contain multiple actions, where the temporal boundaries annotations are required in the fully-supervised learning setting for classification and localization tasks. Since the annotation task is costly and time-consuming, the trend is moving toward the weakly-supervised setting, which depends on the video-level labels only without any additional information, and this approach is called weakly-supervised Temporal Action Localization (WTAL). In this survey, we review the concepts, strategies, and techniques related to the WTAL in order to clarify all aspects of the problem and review the state-of-the-art frameworks of WTAL according to their challenges. Furthermore, a comparison of models’ performance and results based on benchmark datasets is presented. Finally, we summarize the future works to allow the researchers to improve the model&#39;s performance.},
  archive      = {J_NCA},
  author       = {Baraka, AbdulRahman and Mohd Noor, Mohd Halim},
  doi          = {10.1007/s00521-022-07102-x},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8479-8499},
  shortjournal = {Neural Comput. Appl.},
  title        = {Weakly-supervised temporal action localization: A survey},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anomaly detection of industrial multi-sensor signals based
on enhanced spatiotemporal features. <em>NCA</em>, <em>34</em>(11),
8465–8477. (<a
href="https://doi.org/10.1007/s00521-022-07101-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the validity of industrial multi-sensor signals, anomaly detection has become a significant part of industrial signal processing. In practical measurement, industrial multi-sensor signals are mostly fluctuant, and the correlation between the front and back signals is uncertain. These increase the difficulty of the abnormal signal detection. For these problems, this paper proposes an anomaly detection method for industrial multi-sensor signals based on enhanced spatiotemporal features. Firstly, a series of signal preprocessing is performed relying on the characteristics of data set, so that the signals will be processed in a stable state. Then, a stack spatial–temporal autoencoder, which relies on the improved deep stack long short-term memory and autoencoder feature extractors, is proposed to extract features and to reconstruct signals. Next, a high-dimensional unsupervised clusterer is proposed to detect the abnormal signals. Finally, two case studies in magnetic flux leakage (MFL) signals and Tennessee Eastman (TE) benchmark are conducted. MFL signals are the actual signals collected from the experimental platform, and TE benchmark is a public data set. State-of-the-art comparison experiments on feature extraction and abnormal signal detection are performed, and the results show that the proposed method is effective.},
  archive      = {J_NCA},
  author       = {Jiang, Lin and Xu, Hang and Liu, Jinhai and Shen, Xiangkai and Lu, Senxiang and Shi, Zhan},
  doi          = {10.1007/s00521-022-07101-y},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8465-8477},
  shortjournal = {Neural Comput. Appl.},
  title        = {Anomaly detection of industrial multi-sensor signals based on enhanced spatiotemporal features},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel tensor factorization for relational learning.
<em>NCA</em>, <em>34</em>(11), 8455–8464. (<a
href="https://doi.org/10.1007/s00521-021-05692-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction is a statistical relational learning problem that has a variety of applications in recommender systems, expert systems, and knowledge bases. Numerous approaches have already been devised to solve the problem. Tensor factorization is one of the ways to solve the link prediction problem. Many tensor factorization techniques have been devised in the last few decades, including Tucker, CANDECOMP/PARAFAC, and DEDICOM. RESCAL is one of the famous tensor factorization technique that can solve large scale problems with relatively less time and space complexity. The time complexity of RESCAL can further be reduced by making it parallel. This variant can also be applied to large scale datasets. This article focuses on devising a parallel version for RESCAL. A decent decrease in execution time has been observed in the execution of parallel RESCAL.},
  archive      = {J_NCA},
  author       = {Al-Obeidat, Feras and Rocha, Álvaro and Khan, Muhammad Shahrose and Maqbool, Fahad and Razzaq, Saad},
  doi          = {10.1007/s00521-021-05692-6},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8455-8464},
  shortjournal = {Neural Comput. Appl.},
  title        = {Parallel tensor factorization for relational learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). (CDRGI)-cancer detection through relevant genes
identification. <em>NCA</em>, <em>34</em>(11), 8447–8454. (<a
href="https://doi.org/10.1007/s00521-021-05739-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is a genetic disease that is categorized among the most lethal and belligerent diseases. An early staging of the disease can reduce the high mortality rate associated with cancer. The advancement in high throughput sequencing technology and the implementation of several Machine Learning algorithms have led to significant progress in Oncogenomics over the past few decades. Oncogenomics uses RNA sequencing and gene expression profiling for the identification of cancer-related genes. The high dimensionality of RNA sequencing data makes it a complex and large-scale optimization problem. CDRGI presents a Discrete Filtering technique based on a Binary Artificial Bee Colony coupling Support Vector Machine and a two-stage cascading classifier to identify relevant genes and detect cancer using RNA seq data. The proposed approach has been tested for seven different cancers, including Breast Cancer, Stomach Cancer (STAD), Colon Cancer (COAD), Liver Cancer, Lung Cancer (LUSC), Kidney Cancer (KIRC), and Skin Cancer. The results revealed that the CDRGI performs better for feature reduction while achieving better classification accuracy for STAD, COAD, LUSC and KIRC cancer types.},
  archive      = {J_NCA},
  author       = {Al-Obeidat, Feras and Rocha, Álvaro and Akram, Maryam and Razzaq, Saad and Maqbool, Fahad},
  doi          = {10.1007/s00521-021-05739-8},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8447-8454},
  shortjournal = {Neural Comput. Appl.},
  title        = {(CDRGI)-cancer detection through relevant genes identification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel emergency situation awareness machine learning
approach to assess flood disaster risk based on chinese weibo.
<em>NCA</em>, <em>34</em>(11), 8431–8446. (<a
href="https://doi.org/10.1007/s00521-020-05487-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media emerged as an important resource of information to improve the emergency situation awareness of flooding disasters. However, the online microblog text stream is unstructured and unbalanced obviously. Given the big, real-time, and noisy flood disaster microblog text flow, a new regional emergency situation awareness model to automatic assess flood disaster risk is proposed. Firstly, according to the established online disaster event-meta frame, a multi-label classification algorithm for the flood microbloggings is constructed based on the historical dataset. This algorithm helps to assign the relevant event-meta tags to each situation microbloggings. Second, a new machine learning method for dynamic assessment of flood risk for online microbloggings is developed. The flood event-metas are considered to be feature vectors, and the four different levels of flood risk are considered to be four classes. Then, the flood risk assessment task is innovatively transformed into a multi-classification task. By the logistic regression ordered multi-classification algorithm, the dynamic quantitative evaluation of event-meta, users and regional risks is realized. Finally, the proposed model is applied in the case of the Yuyao Flood. The results of the case study show that the Yuyao Flood’s online quantitative risk assessment results are consistent with real accumulated precipitation data, which illustrate that the proposed machine learning model could realize the bottom-up automatic disaster information collecting by processing victim user-generated content effectively. Social media is proven to supplement the deficiencies of traditional disaster statistics and provide real-time, scientific information support for the implementation of flood emergency processes.},
  archive      = {J_NCA},
  author       = {Bai, Hua and Yu, Hualong and Yu, Guang and Huang, Xing},
  doi          = {10.1007/s00521-020-05487-1},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8431-8446},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel emergency situation awareness machine learning approach to assess flood disaster risk based on chinese weibo},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recommendation of technological profiles to collaborate in
software projects using document embeddings. <em>NCA</em>,
<em>34</em>(11), 8423–8430. (<a
href="https://doi.org/10.1007/s00521-020-05522-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The information technology sector is continuously growing, and there is a high demand for developers. In the area of software development projects, fixing bugs or solving issues is a task that could be optimized to improve the productivity of developers. Making an adequate allocation for bug fixing will save overall project development time. Moreover, the problem will last for the shortest possible time, minimizing any negative impacts in case the project is already in production. This research work’s objective is to identify the most apt users (where the term “user” refers to any technology professional, for example a software developer, who has registered on any given platform), from a set of different user profiles, for fixing bugs in a software project. The study has been carried out by analyzing large-scale repositories of open-source projects with a large historical volume of bugs, and the extracted knowledge has been successfully applied to new, unrelated projects. Different similarity-based profile raking procedures have been studied, including neural-network-based incidence representation. The obtained results show that the system can be directly applied to different environments and that the selected user profiles are very close to those selected by human experts, which demonstrates the correct functioning of the proposed system.},
  archive      = {J_NCA},
  author       = {Chamoso, Pablo and Hernández, Guillermo and González-Briones, Alfonso and García-Peñalvo, Francisco J.},
  doi          = {10.1007/s00521-020-05522-1},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8423-8430},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recommendation of technological profiles to collaborate in software projects using document embeddings},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiclass classification of nutrients deficiency of apple
using deep neural network. <em>NCA</em>, <em>34</em>(11), 8411–8422. (<a
href="https://doi.org/10.1007/s00521-020-05310-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture industry is the foundation of Indian economy where quality fruit production plays an important role. Apple or pome fruits are always in demand because of rich nutrients in it. Hence, to analyze and recognize the nutrients deficiency in fruits, a deep neural-based model is being proposed. This model automatically classifies and recognizes the type of deficiency present in apple. In this paper, a database has been created for four major types of nutrients deficiency in apples and used for training and validation of the proposed deep convolutional network. The model is tuned with k-fold cross-validation. The hyper-parameters such as epoch are set at 100 and batch size kept at 5. Finally, the model is tested with the testing data and achieved an average accuracy of 98.24\% with k-fold cross-validation set to 15. The model accuracy depends on the hyper-parameters. The process of features optimization reduces the risk of overfitting of the model. Hence, careful selection of hyper-parameters is important for the convergence of cost function to the global minima that results in minimum misclassification.},
  archive      = {J_NCA},
  author       = {Kumar, Yogesh and Dubey, Ashwani Kumar and Arora, Rajeev Ratan and Rocha, Alvaro},
  doi          = {10.1007/s00521-020-05310-x},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8411-8422},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multiclass classification of nutrients deficiency of apple using deep neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Building a knowledge graph by using cross-lingual transfer
method and distributed MinIE algorithm on apache spark. <em>NCA</em>,
<em>34</em>(11), 8393–8409. (<a
href="https://doi.org/10.1007/s00521-020-05495-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The simplest and effective way to store human knowledge through centuries was using text. Along with the advancement of technology nowadays, the volume of text has grown to be larger and larger. To extract useful information from this amount of text becomes an exceptionally complex task. As an effort to solve that problem, in this paper, we present a pipeline to extract core knowledge from large quantity text using distributed computing. The components of our pipeline are systems that were known to yield good results. The outputs of our proposed system are stored in a knowledge graph. A knowledge graph is a graph for storing knowledge in the form of triples (head, relation, tail). Some of the existing knowledge graphs in the world are Google knowledge graph, YAGO, DBLP, or DBpedia. These knowledge graphs have one thing in common—they are in English. The English language is studied by many researchers in the world and it had become a rich-resource language (with many natural language processing tools and data set). Vietnamese, on the other hand, is a low-resource language. Therefore, we use cross-lingual transfer method to build a Vietnamese knowledge graph. Firstly, we collect data in form of text about Vietnam tourism, which was written mostly in Vietnamese, using Google search and Wikipedia. In the next step, we translate them into English with Google Translate and use English Natural Language Processing tools like Stanford Parser, Co-referencing, ClausIE, MinIE to extract useful triples from this text. Lastly, the triples are translated back to Vietnamese to build a Vietnam tourism knowledge graph. Since we are working with massive text, we develop a distributed algorithm to extract triples from sentences of massive text. This is a distributed version of MinIE, which was originally developed for a single machine model. In Apache Spark framework, we divide massive text into many smaller parts and move them to the worker nodes with distributed MinIE function. Spark distributed MinIE will extract the triples of sentences in the local text of this worker node in parallel. Finally, the result of worker nodes will be sent back to the master node for building the knowledge graph. We conduct experiments with the distributed MinIE on spark cluster to prove the outperformance of our proposed algorithm.},
  archive      = {J_NCA},
  author       = {Do, Phuc and Phan, Trung and Le, Hung and Gupta, Brij B.},
  doi          = {10.1007/s00521-020-05495-1},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8393-8409},
  shortjournal = {Neural Comput. Appl.},
  title        = {Building a knowledge graph by using cross-lingual transfer method and distributed MinIE algorithm on apache spark},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bag of feature and support vector machine based early
diagnosis of skin cancer. <em>NCA</em>, <em>34</em>(11), 8385–8392. (<a
href="https://doi.org/10.1007/s00521-020-05212-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer is one of the diseases which lead to death if not detected at an early stage. Computer-aided detection and diagnosis systems are designed for its early diagnosis which may prevent biopsy and use of dermoscopic tools. Numerous researches have considered this problem and achieved good results. In automatic diagnosis of skin cancer through computer-aided system, feature extraction and reduction plays an important role. The purpose of this research is to develop computer-aided detection and diagnosis systems for classifying a lesion into cancer or non-cancer owing to the usage of precise feature extraction technique. This paper proposed the fusion of bag-of-feature method with speeded up robust features for feature extraction and quadratic support vector machine for classification. The proposed method shows the accuracy of 85.7\%, sensitivity of 100\%, specificity of 60\% and training time of 0.8507 s in classifying the lesion. The result and analysis of experiments are done on the PH2 dataset of skin cancer. Our method improves performance accuracy with an increase of 3\% than other state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Arora, Ginni and Dubey, Ashwani Kumar and Jaffery, Zainul Abdin and Rocha, Alvaro},
  doi          = {10.1007/s00521-020-05212-y},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8385-8392},
  shortjournal = {Neural Comput. Appl.},
  title        = {Bag of feature and support vector machine based early diagnosis of skin cancer},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Does semantics aid syntax? An empirical study on named
entity recognition and classification. <em>NCA</em>, <em>34</em>(11),
8373–8384. (<a
href="https://doi.org/10.1007/s00521-021-05949-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many researchers jointly model multiple linguistic tasks (e.g., joint modeling of named entity recognition and named entity classification and joint modeling of syntactic parsing and semantic parsing) with an implicit assumption that these individual tasks can enhance each other via the joint modeling. Before conducting research on jointly modeling multiple tasks, however, such researchers hardly examine whether such assumption is true or not. In this paper, we empirically examine whether named entity classification improves the performance of named entity recognition as an empirical case of examining whether semantics improves the performance of a syntactic task. To this end, we firstly specify the way to determine whether a linguistic task is a syntactic task or a semantic task according to both syntactic theory and semantic theory. After that, we design and conduct extensive experiments on two well-known benchmark datasets using three representative yet diverse state-of-the-art models. Experimental results demonstrate that named entity recognition does not lie at the semantic level and is not a semantic task; instead, it is a syntactic task and that the joint modeling of named entity recognition and classification does not improve the performance of named entity recognition. Experimental results also demonstrate that traditional handcrafted feature models can achieve state-of-the-art performance in comparison with the auto-learned feature model on named entity recognition.},
  archive      = {J_NCA},
  author       = {Zhong, Xiaoshi and Cambria, Erik and Hussain, Amir},
  doi          = {10.1007/s00521-021-05949-0},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8373-8384},
  shortjournal = {Neural Comput. Appl.},
  title        = {Does semantics aid syntax? an empirical study on named entity recognition and classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A machine learning-based approach for the segmentation and
classification of malignant cells in breast cytology images using gray
level co-occurrence matrix (GLCM) and support vector machine (SVM).
<em>NCA</em>, <em>34</em>(11), 8365–8372. (<a
href="https://doi.org/10.1007/s00521-021-05697-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the common disease in female gender population all over the world. The classical methods of segmentation and classification for malignant cells are not only repetitive but also very time-consuming. Therefore, a computer-aided diagnosis is needed for automatic segmentation and classification of malignant cells in breast cytology images. In this article, a machine learning-based approach is proposed for malignant cell segmentation and classification in breast cytology images. In the proposed approach, the segmentation of cells is performed by a level set algorithm which is used to extract statistical information related to the malignant and benign cells. Similarly, the gray level co-occurrence matrix is computed to exploit the texture information, and support vector machine-based classification is used for the classification of malignant and benign cells. It has been observed through experiments that the proposed approach achieved high accuracy (96.3\%) in the classification of malignant and benign cells.},
  archive      = {J_NCA},
  author       = {Khan, Sana Ullah and Islam, Naveed and Jan, Zahoor and Haseeb, Khalid and Shah, Syed Inayat Ali and Hanif, Muhammad},
  doi          = {10.1007/s00521-021-05697-1},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8365-8372},
  shortjournal = {Neural Comput. Appl.},
  title        = {A machine learning-based approach for the segmentation and classification of malignant cells in breast cytology images using gray level co-occurrence matrix (GLCM) and support vector machine (SVM)},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effect of number of neurons and layers in an artificial
neural network for generalized concrete mix design. <em>NCA</em>,
<em>34</em>(11), 8355–8363. (<a
href="https://doi.org/10.1007/s00521-020-05305-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selection of the number of neurons in different layers of an artificial neural network (ANN) is a key decision-making step involved in its successful training. Although the number of neurons in the input layer is decided by the number of input parameters, and similarly, in the output layer the number of neurons is fixed by the output parameters, however, the number of neurons in the hidden layer is not fixed, whereby the overall efficiency of the ANN depends upon the correct modeling of the realistic scenario in the form of a neural network. Concrete can be mixed in a huge variety of methods and compositions to achieve a specific or a combination of specific results. These results have been observed to repeat and follow patterns. Furthermore, for several types of concrete mixes, only actual physical trial data are available with no mix design method; this makes achieving different required results very complex and expensive task. Having an ANN to be able to predict a concrete mix to handle such variations will save a lot of time and money and will prove to be a universal mix design tool. A thorough analysis for deciding the number of neurons for mix design of concrete has been carried out in this research. The results of neural networks for a varying number of neurons and layers have been correlated. The data for a number of concrete mixes were sorted and normalized. Properties of concrete constituents like specific gravity of cement, coarse and fine aggregates, dry density of coarse and fine aggregates, cement type, type of mineral admixture, water-to-cement ratio, type and temperature of curing and hardened properties like compressive strength, modulus of elasticity and tensile strength were taken as input parameters. The contents of constituents of concrete such as water content, cement content, coarse aggregates content, fine aggregates content and content of mineral admixtures are regarded as output parameters. For 17 inputs and 5 outputs, it has been discovered that simple neural network with single or double hidden layers performed better that 3 or more such layers.},
  archive      = {J_NCA},
  author       = {Adil, Mohammad and Ullah, Rahat and Noor, Salma and Gohar, Neelam},
  doi          = {10.1007/s00521-020-05305-8},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8355-8363},
  shortjournal = {Neural Comput. Appl.},
  title        = {Effect of number of neurons and layers in an artificial neural network for generalized concrete mix design},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Impact of data smoothing on semantic segmentation.
<em>NCA</em>, <em>34</em>(11), 8345–8354. (<a
href="https://doi.org/10.1007/s00521-020-05341-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is the process to classify each pixel of an image. The current state-of-the-art semantic segmentation techniques use end-to-end trainable deep models. Generally, the training of these models is controlled by some external hyper-parameters rather to use the variation in data. In this paper, we investigate the impact of data smoothing on the training and generalization of deep semantic segmentation models. A mechanism is proposed to select the best level of smoothing to get better generalization of the deep semantic segmentation models. Furthermore, a smoothing layer is included in the deep semantic segmentation models to automatically adjust the level of smoothing. Extensive experiments are performed to validate the effectiveness of the proposed smoothing strategies.},
  archive      = {J_NCA},
  author       = {Ul Haq, Nuhman and ur Rehman, Zia and Khan, Ahmad and Din, Ahmad and Shah, Sajid and Ullah, Abrar and Qayum, Fawad},
  doi          = {10.1007/s00521-020-05341-4},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8345-8354},
  shortjournal = {Neural Comput. Appl.},
  title        = {Impact of data smoothing on semantic segmentation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving aspect-level sentiment analysis with aspect
extraction. <em>NCA</em>, <em>34</em>(11), 8333–8343. (<a
href="https://doi.org/10.1007/s00521-020-05287-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA), a popular research area in NLP, has two distinct parts—aspect extraction (AE) and labelling the aspects with sentiment polarity (ALSA). Although distinct, these two tasks are highly correlated. The work primarily hypothesizes that transferring knowledge from a pre-trained AE model can benefit the performance of ALSA models. Based on this hypothesis, word embeddings are obtained during AE and, subsequently, feed that to the ALSA model. Empirically, this work shows that the added information significantly improves the performance of three different baseline ALSA models on two distinct domains. This improvement also translates well across domains between AE and ALSA tasks.},
  archive      = {J_NCA},
  author       = {Majumder, Navonil and Bhardwaj, Rishabh and Poria, Soujanya and Gelbukh, Alexander and Hussain, Amir},
  doi          = {10.1007/s00521-020-05287-7},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8333-8343},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving aspect-level sentiment analysis with aspect extraction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gene encoder: A feature selection technique through
unsupervised deep learning-based clustering for large gene expression
data. <em>NCA</em>, <em>34</em>(11), 8309–8331. (<a
href="https://doi.org/10.1007/s00521-020-05101-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is a severe condition of uncontrolled cell division that results in a tumor formation that spreads to other tissues of the body. Therefore, the development of new medication and treatment methods for this is in demand. Classification of microarray data plays a vital role in handling such situations. The relevant gene selection is an important step for the classification of microarray data. This work presents gene encoder, an unsupervised two-stage feature selection technique for the cancer samples’ classification. The first stage aggregates three filter methods, namely principal component analysis, correlation, and spectral-based feature selection techniques. Next, the genetic algorithm is used, which evaluates the chromosome utilizing the autoencoder-based clustering. The resultant feature subset is used for the classification task. Three classifiers, namely support vector machine, k-nearest neighbors, and random forest, are used in this work to avoid the dependency on any one classifier. Six benchmark gene expression datasets are used for the performance evaluation, and a comparison is made with four state-of-the-art related algorithms. Three sets of experiments are carried out to evaluate the proposed method. These experiments are for the evaluation of the selected features based on sample-based clustering, adjusting optimal parameters, and for selecting better performing classifier. The comparison is based on accuracy, recall, false positive rate, precision, F-measure, and entropy. The obtained results suggest better performance of the current proposal.},
  archive      = {J_NCA},
  author       = {Uzma and Al-Obeidat, Feras and Tubaishat, Abdallah and Shah, Babar and Halim, Zahid},
  doi          = {10.1007/s00521-020-05101-4},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8309-8331},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gene encoder: A feature selection technique through unsupervised deep learning-based clustering for large gene expression data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An assortment of evolutionary computation techniques (AECT)
in gaming. <em>NCA</em>, <em>34</em>(11), 8295–8308. (<a
href="https://doi.org/10.1007/s00521-020-05295-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time strategy (RTS) games differ as they persist in varying scenarios and states. These games enable an integrated correspondence of non-player characters (NPCs) to appear as an autodidact in a dynamic environment, thereby resulting in a combined attack of NPCs on human-controlled character (HCC) with maximal damage. This research aims to empower NPCs with intelligent traits. Therefore, we instigate an assortment of ant colony optimization (ACO) with genetic algorithm (GA)-based approach to first-person shooter (FPS) game, i.e., Zombies Redemption (ZR). Eminent NPCs with best-fit genes are elected to spawn NPCs over generations and game levels as yielded by GA. Moreover, NPCs empower ACO to elect an optimal path with diverse incentives and less likelihood of getting shot. The proposed technique ZR is novel as it integrates ACO and GA in FPS games where NPC will use ACO to exploit and optimize its current strategy. GA will be used to share and explore strategy among NPCs. Moreover, it involves an elaboration of the mechanism of evolution through parameter utilization and updation over the generations. ZR is played by 450 players with varying levels having the evolving traits of NPCs and environmental constraints in order to accumulate experimental results. Results revealed improvement in NPCs performance as the game proceeds.},
  archive      = {J_NCA},
  author       = {Khalid, Maham and Al-Obeidat, Feras and Tubaishat, Abdallah and Shah, Babar and Razzaq, Saad and Maqbool, Fahad and Ilyas, Muhammad},
  doi          = {10.1007/s00521-020-05295-7},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8295-8308},
  shortjournal = {Neural Comput. Appl.},
  title        = {An assortment of evolutionary computation techniques (AECT) in gaming},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on advanced deep learning methods for large
scale repositories. <em>NCA</em>, <em>34</em>(11), 8291–8294. (<a
href="https://doi.org/10.1007/s00521-022-07053-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Anwar, Sajid and Rocha, Álvaro},
  doi          = {10.1007/s00521-022-07053-3},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8291-8294},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on advanced deep learning methods for large scale repositories},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Poly-YOLO: Higher speed, more precise detection and instance
segmentation for YOLOv3. <em>NCA</em>, <em>34</em>(10), 8275–8290. (<a
href="https://doi.org/10.1007/s00521-021-05978-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new version of YOLO with better performance and extended with instance segmentation called Poly-YOLO. Poly-YOLO builds on the original ideas of YOLOv3 and removes two of its weaknesses: a large amount of rewritten labels and an inefficient distribution of anchors. Poly-YOLO reduces the issues by aggregating features from a light SE-Darknet-53 backbone with a hypercolumn technique, using stairstep upsampling, and produces a single scale output with high resolution. In comparison with YOLOv3, Poly-YOLO has only 60\% of its trainable parameters but improves the mean average precision by a relative 40\%. We also present Poly-YOLO lite with fewer parameters and a lower output resolution. It has the same precision as YOLOv3, but it is three times smaller and twice as fast, thus suitable for embedded devices. Finally, Poly-YOLO performs instance segmentation by bounding polygons. The network is trained to detect size-independent polygons defined on a polar grid. Vertices of each polygon are being predicted with their confidence, and therefore, Poly-YOLO produces polygons with a varying number of vertices. Source code is available at https://gitlab.com/irafm-ai/poly-yolo .},
  archive      = {J_NCA},
  author       = {Hurtik, Petr and Molek, Vojtech and Hula, Jan and Vajgl, Marek and Vlasanek, Pavel and Nejezchleba, Tomas},
  doi          = {10.1007/s00521-021-05978-9},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {8275-8290},
  shortjournal = {Neural Comput. Appl.},
  title        = {Poly-YOLO: Higher speed, more precise detection and instance segmentation for YOLOv3},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). VGGCOV19-NET: Automatic detection of COVID-19 cases from
x-ray images using modified VGG19 CNN architecture and YOLO algorithm.
<em>NCA</em>, <em>34</em>(10), 8253–8274. (<a
href="https://doi.org/10.1007/s00521-022-06918-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X-ray images are an easily accessible, fast, and inexpensive method of diagnosing COVID-19, widely used in health centers around the world. In places where there is a shortage of specialist doctors and radiologists, there is need for a system that can direct patients to advanced health centers by pre-diagnosing COVID-19 from X-ray images. Also, smart computer-aided systems that automatically detect COVID-19 positive cases will support daily clinical applications. The study aimed to classify COVID-19 via X-ray images in high precision ratios with pre-trained VGG19 deep CNN architecture and the YOLOv3 detection algorithm. For this purpose, VGG19, VGGCOV19-NET models, and the original Cascade models were created by feeding these models with the YOLOv3 algorithm. Cascade models are the original models fed with the lung zone X-ray images detected with the YOLOv3 algorithm. Model performances were evaluated using fivefold cross-validation according to recall, specificity, precision, f1-score, confusion matrix, and ROC analysis performance metrics. While the accuracy of the Cascade VGGCOV19-NET model was 99.84\% for the binary class (COVID vs. no-findings) data set, it was 97.16\% for the three-class (COVID vs. no-findings vs. pneumonia) data set. The Cascade VGGCOV19-NET model has a higher classification performance than VGG19, Cascade VGG19, VGGCOV19-NET and previous studies. Feeding the CNN models with the YOLOv3 detection algorithm decreases the training test time while increasing the classification performance. The results indicate that the proposed Cascade VGGCOV19-NET architecture was highly successful in detecting COVID-19. Therefore, this study contributes to the literature in terms of both YOLO-aided deep architecture and classification success.},
  archive      = {J_NCA},
  author       = {Karacı, Abdulkadir},
  doi          = {10.1007/s00521-022-06918-x},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {8253-8274},
  shortjournal = {Neural Comput. Appl.},
  title        = {VGGCOV19-NET: Automatic detection of COVID-19 cases from X-ray images using modified VGG19 CNN architecture and YOLO algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PAFM: Pose-drive attention fusion mechanism for occluded
person re-identification. <em>NCA</em>, <em>34</em>(10), 8241–8252. (<a
href="https://doi.org/10.1007/s00521-022-06903-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrians are often occluded by various obstacles in public places, which is a big challenge for person re-identification. To alleviate the occlusion problem, we propose a Pose-drive Attention Fusion Mechanism (PAFM) that jointly fuses the discriminative features with pose-driven attention and spatial attention in an end-to-end framework. To simultaneously use global and local features, a multi-task network is constructed to realize multi-granularity feature representation. After anchoring the region of interest to the un-occluded spatial semantic information in the image through the spatial attention mechanism, some key points of the pedestrian’s body are extracted using pose estimation and then fused with the spatial attention map to eliminate the harm of occlusion to the re-identification. Besides, the identification granularity is increased by matching the local features. We test and verify the effectiveness of the PAFM on Occluded-DukeMTMC, Occluded-REID and Partial-REID. The experimental results show that the proposed method has achieved competitive performance to the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Yang, Jing and Zhang, Canlong and Tang, Yanping and Li, Zhixin},
  doi          = {10.1007/s00521-022-06903-4},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {8241-8252},
  shortjournal = {Neural Comput. Appl.},
  title        = {PAFM: Pose-drive attention fusion mechanism for occluded person re-identification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time detection of uncalibrated sensors using neural
networks. <em>NCA</em>, <em>34</em>(10), 8227–8239. (<a
href="https://doi.org/10.1007/s00521-021-06865-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, sensors play a major role in several fields, such as science, industry and everyday technology. Therefore, the information received from the sensors must be reliable. If the sensors present any anomalies, serious problems can arise, such as publishing wrong theories in scientific papers, or causing production delays in industry. One of the most common anomalies are uncalibrations. An uncalibration occurs when the sensor is not adjusted or standardized by calibration according to a ground truth value. In this work, an online machine-learning based uncalibration detector for temperature, humidity and pressure sensors is presented. This development integrates an artificial neural network as the main component which learns from the behavior of the sensors under calibrated conditions. Then, after being trained and deployed, it detects uncalibrations once they take place. The obtained results show that the proposed system is able to detect the 100\% of the presented uncalibration events, although the time response in the detection depends on the resolution of the model for the specific location, i.e., the minimum statistically significant variation in the sensor behavior that the system is able to detect. This architecture can be adapted to different contexts by applying transfer learning, such as adding new sensors or having different environments by re-training the model with minimum amount of data.},
  archive      = {J_NCA},
  author       = {Muñoz-Molina, Luis J. and Cazorla-Piñar, Ignacio and Dominguez-Morales, Juan P. and Lafuente, Luis and Perez-Peña, Fernando},
  doi          = {10.1007/s00521-021-06865-z},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {8227-8239},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time detection of uncalibrated sensors using neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Integrating label propagation with graph convolutional
networks for recommendation. <em>NCA</em>, <em>34</em>(10), 8211–8225.
(<a href="https://doi.org/10.1007/s00521-022-06926-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, graph convolutional networks (GCN) have achieved significant progress in recommender systems, due to its remarkable capability on representation learning and the ability to integrate complex auxiliary information. However, the graph convolution operation is prone to cause over-smoothing due to the use of the graph Laplacian operator, so that the node embeddings become very similar after the multi-layer graph convolution, which leads to a decrease in recommendation performance. The recently proposed model based on simplified GCN can relieve this issue to a certain extent; however, they still only design the model from the viewpoint of GCN. Inspired by the recent developments of label propagation algorithms (LPA), in this paper, we propose a new recommender model that unifies graph convolutional networks and label propagation algorithms. Specifically, we utilize the GCN to build a basic recommendation prediction model, and unify the LPA to provide regularization of training edge weights, which has been proven to effectively alleviate the over-smoothing problem. In addition, we introduce an attention network to capture the attention weight of each user-item pair, which takes into account the fact that users attach different degrees of importance to various relationships of items. Extensive experiments on three real-world datasets demonstrate that the proposed algorithm has a significant improvement over other state-of-the-art recommendation algorithms.},
  archive      = {J_NCA},
  author       = {Zhang, Yihao and Yuan, Meng and Zhao, Chu and Chen, Mian and Liu, Xiaoyang},
  doi          = {10.1007/s00521-022-06926-x},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {8211-8225},
  shortjournal = {Neural Comput. Appl.},
  title        = {Integrating label propagation with graph convolutional networks for recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsteady stagnation-point flow of a hybrid nanofluid over a
spinning disk: Analysis of dual solutions. <em>NCA</em>,
<em>34</em>(10), 8193–8210. (<a
href="https://doi.org/10.1007/s00521-022-06916-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned about the characteristics of the dual solutions of an unsteady stagnation-point flow of a hybrid nanofluid over a rotating disk with the effect of Hall current. The governing equations are non-dimensionalized using the appropriate similarity transformations. The resulting equations are solved numerically by employing the bvp4c method. A comparison between the present solutions with the available solutions is presented which shows an excellent agreement. The solution exists in the upper branch for all values of the hybrid nanofluid $$\phi_{1} ,\,\phi_{2}$$ , the swirl parameter $$\Omega_{A}$$ , and impinging parameter $$\beta_{A}$$ . However, the breakdown is observed in the lower branch solution at some moderate values of $$\beta_{A}$$ . In addition, the radial velocity increases due to hybrid nanofluid, while the azimuthal velocity decreases. However, the temperature increases due to hybrid nanofluid. Moreover, the results also indicate that the swirl parameter augments the velocity in both directions but declines the temperature. Also, it is perceived that the azimuthal velocity and temperature decrease in the upper branch solution as the magnetic parameter increases, while the lower branch solution initially increases and then decreases for the transverse component of velocity but the temperature monotonically increases.},
  archive      = {J_NCA},
  author       = {Khan, Umair and Zaib, A. and Abu Bakar, Sakhinah and Ishak, Anuar},
  doi          = {10.1007/s00521-022-06916-z},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {8193-8210},
  shortjournal = {Neural Comput. Appl.},
  title        = {Unsteady stagnation-point flow of a hybrid nanofluid over a spinning disk: Analysis of dual solutions},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensemble siamese networks for object tracking. <em>NCA</em>,
<em>34</em>(10), 8173–8191. (<a
href="https://doi.org/10.1007/s00521-022-06911-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, considering a balanced accuracy and efficiency, Fully-Convolutional Siamese network (SiamFC) is widely used in the field of visual tracking. Although SiamFC has achieved great success, it is still frustrated in discrimination especially in the discriminative scene. The main reason for the poor discrimination ability of SiamFC is that during the training process, it pays more attention to fitting the whole dataset than learning discrimination ability to similar objects. In terms of this issue, we propose Ensemble Siamese networks (ESiamFC) for tracking by introducing ensemble learning into SiamFC. In detail, firstly, we map the training dataset ILSVRC2015 into embedded space. Secondly, we use balanced k-means to cluster video features. Thirdly, in each cluster, we apply transfer learning into SiamFC to obtain k base trackers with their preferences. Last but not least, to leverage the diversity of base trackers, we propose a Cluster Weight fusion module which can automatically assign fusion weight to base trackers according to the semantic information of the tracking object. Extensive experiments on multiple benchmarks demonstrate that our tracker outperforms SiamFC in precision with a relative increase of 7.1\%, 8.6\%, 6.7\% on Tcolor128, DTB70, LaSOT, respectively.},
  archive      = {J_NCA},
  author       = {Huang, Hanlin and Liu, Guixi and Zhang, Yi and Xiong, Ruke and Zhang, Shaoxuan},
  doi          = {10.1007/s00521-022-06911-4},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {8173-8191},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ensemble siamese networks for object tracking},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust respiratory disease classification using breathing
sounds (RRDCBS) multiple features and models. <em>NCA</em>,
<em>34</em>(10), 8155–8172. (<a
href="https://doi.org/10.1007/s00521-022-06915-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of respiratory diseases using X-ray and CT scan images of lungs is currently practised and used by many medical practitioners for clinical diagnosis. Respiratory disease classification, using breathing and wheezing sounds, remains scarce in the research field and is slowly upcoming. In this work, robust respiratory disease classification using breathing sounds (RRDCBS) is implemented by extracting multiple features from sounds, creating multiple modelling techniques, and experimental identification of diseases using appropriate testing procedures for multi-class and binary classification of respiratory diseases. Decision level fusion of features for Vector quantisation (VQ) modelling technique has provided 100\% accuracy for classifying five respiratory diseases and healthy subjects. Decision level fusion of indices on the features has provided 100\% accuracy for VQ, support vector machine (SVM), and K-nearest neighbour (KNN) modelling techniques to perform binary classification of the respiratory disease against healthy data sound. Deep recurrent and convolutional neural networks are also evaluated for multiple/binary classification of respiratory diseases.},
  archive      = {J_NCA},
  author       = {Revathi, A. and Sasikaladevi, N. and Arunprasanth, D. and Amirtharajan, Rengarajan},
  doi          = {10.1007/s00521-022-06915-0},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {8155-8172},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust respiratory disease classification using breathing sounds (RRDCBS) multiple features and models},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A feature level image fusion for IR and visible image using
mNMRA based segmentation. <em>NCA</em>, <em>34</em>(10), 8137–8154. (<a
href="https://doi.org/10.1007/s00521-022-06900-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image fusion is a method through which an image collection is fused into a composite image by fusing important characteristics from sources. This fused image is more informational, accurate and comprises of all the required information that better enhances human visual perception and machine vision. In this paper a new technique is suggested for the fusion of infrared (IR) and visible (VIS) images. The primary problems for image fusion at feature levels are that artefacts and noise are introduced in the fused picture. The weight map generated by the modified naked mole-rat algorithm (mNMRA) is used to retain important information without using artefacts in a final fused image. The proposed FNMRA fusion method is based on a feature-level fusion after the refinement of weight maps, utilising the WLS approach. This allows the prominent object information from the IR image to be included in the VIS image without any distortion. Experiments on twenty-one image data sets are conducted to verify the fusion performance of the suggested approach. The qualitative and quantitative analysis of fusion results concludes that the suggested technique works well for most image data sets and performs better than some state-of-the-art current methods.},
  archive      = {J_NCA},
  author       = {Singh, Simrandeep and Mittal, Nitin and Singh, Harbinder},
  doi          = {10.1007/s00521-022-06900-7},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {8137-8154},
  shortjournal = {Neural Comput. Appl.},
  title        = {A feature level image fusion for IR and visible image using mNMRA based segmentation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Chaotic quasi-oppositional arithmetic optimization algorithm
for thermo-economic design of a shell and tube condenser running with
different refrigerant mixture pairs. <em>NCA</em>, <em>34</em>(10),
8103–8135. (<a
href="https://doi.org/10.1007/s00521-022-06899-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This theoretical research study proposes a novel Chaotic Quasi-Oppositional Arithmetic Optimization Algorithm (COAOA) for thermo-economic optimization of a shell and tube condenser working with refrigerant mixtures. Arithmetic Optimization Algorithm (AOA) is a recently emerged metaheuristic algorithm considering different mathematical operators to optimize the candidate solutions over a wide range of search domains. The effectiveness the COAOA is assessed by applying it to a set of benchmark optimization problems and comparing the obtained solutions with that of the original AOA and its quasi-oppositional variant. The COAOA has been employed to acquire the minimum value of the total annual cost of the shell and tube condenser by iteratively varying nine decision variables of mass flow rate, shell diameter, the tube inside diameter, tube length, number of tube passes, tube layout, tube pitch ratio, the total number of baffles, and diameter ratio. Three different case studies are solved using different refrigerant pairs used for in-tube flow to show the proposed metaheuristic optimizer’s efficiency and effectivity on real-world mixed-integer optimization problem. Optimal results retrieved for different mixture pairs with varying mass fractions are compared with each other, and parametric configuration yielding the minimum total cost is decided. Finally, a comprehensive sensitivity analysis is performed to investigate the influences of the design variables over the considered problem objective. Overall analysis results indicate that COAOA can be an excellent optimizer to obtain a shell and tube condenser’s optimal configuration within a reasonable computation time.},
  archive      = {J_NCA},
  author       = {Turgut, Mert Sinan and Turgut, Oguz Emrah and Abualigah, Laith},
  doi          = {10.1007/s00521-022-06899-x},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {8103-8135},
  shortjournal = {Neural Comput. Appl.},
  title        = {Chaotic quasi-oppositional arithmetic optimization algorithm for thermo-economic design of a shell and tube condenser running with different refrigerant mixture pairs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new outranking method for multicriteria decision making
with complex pythagorean fuzzy information. <em>NCA</em>,
<em>34</em>(10), 8069–8102. (<a
href="https://doi.org/10.1007/s00521-021-06847-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article contributes to the advancement and evolution of outranking decision-making methodologies, with a novel essay on the ELimination and Choice Translating REality (ELECTRE) family of methods. Its primary target is to unfold the constituents and expound the implementation of the ELECTRE II method for group decision making in complex Pythagorean fuzzy framework. This results in the complex Pythagorean fuzzy ELECTRE II method. By inception, it is intrinsically superior to models using one-dimensional data. It is designed to perform the pairwise comparisons of the alternatives using the core notions of concordance, discordance and indifferent sets, which is then followed by the construction of complex Pythagorean fuzzy concordance and discordance matrices. Further, the strong and weak outranking relations are developed by the comparison of concordance and discordance indices with the concordance and discordance levels. Later, the forward, reverse and average rankings of the alternatives are computed by the dint of strong and weak outranking graphs. This methodology is supported by a case study for the selection of wastewater treatment process, and by a numerical example for the selection of the best cloud solution for a big data project. Its consistency is confirmed by an effectiveness test and comparison analysis with the Pythagorean fuzzy ELECTRE II and complex Pythagorean fuzzy ELECTRE I methods.},
  archive      = {J_NCA},
  author       = {Akram, Muhammad and Zahid, Kiran and Alcantud, José Carlos R.},
  doi          = {10.1007/s00521-021-06847-1},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {8069-8102},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new outranking method for multicriteria decision making with complex pythagorean fuzzy information},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interval-valued fermatean fuzzy sets with multi-criteria
weighted aggregated sum product assessment-based decision analysis
framework. <em>NCA</em>, <em>34</em>(10), 8051–8067. (<a
href="https://doi.org/10.1007/s00521-021-06782-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fermatean fuzzy set, a generalization of the fuzzy set, is a significant way to tackle the complex uncertain information that arises in decision-analysis procedure and thus can be employed on a wider range of applications. Due to the inadequacy in accessible data, it is hard for decision experts to exactly define the belongingness grade (BG) and non-belongingness grade (NG) by crisp values. In such a situation, interval BG and interval NG are good selections. Thus, the aim of the study is to develop the doctrine of interval-valued Fermatean fuzzy sets (IVFFSs) and their fundamental operations. Next, the score and accuracy functions are proposed for interval-valued Fermatean fuzzy numbers (IVFFNs). Two aggregation operators (AOs) are developed for aggregating the IVFFSs information and discussed some axioms. Further, a weighted aggregated sum product assessment method for IVFFSs using developed AOs is introduced to handle the uncertain multi-criteria decision analysis problems. A case study of e-waste recycling partner selection is also considered to elucidate the feasibility and efficacy of the introduced framework. Finally, sensitivity and comparative analyses are given to elucidate the reliability and robustness of the obtained results.},
  archive      = {J_NCA},
  author       = {Rani, Pratibha and Mishra, Arunodaya Raj},
  doi          = {10.1007/s00521-021-06782-1},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {8051-8067},
  shortjournal = {Neural Comput. Appl.},
  title        = {Interval-valued fermatean fuzzy sets with multi-criteria weighted aggregated sum product assessment-based decision analysis framework},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AFA: Adversarial frequency alignment for domain generalized
lung nodule detection. <em>NCA</em>, <em>34</em>(10), 8039–8050. (<a
href="https://doi.org/10.1007/s00521-022-06928-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The different reconstruction parameters of CT imaging lead to domain shifts, which limits the generalization of deep learning models and their applications in computer-aided diagnosis systems. In this paper, we investigate the multi-source domain generalization (DG) problem in the context of lung nodule detection from CT images. We first identify the reconstructed convolution kernel as the key parameter leading to domain shifts. Accordingly, we reorganize the public LUNA16 dataset into a domain generalization benchmark, i.e., LUNA-DG. Then, we propose a novel DG method by adversarial frequency alignment (AFA). Specifically, we devise an adaptive transition module (ATM) to learn a frequency attention map that can align different domain images in a common frequency domain. For this purpose, a fidelity discriminator and a multi-domain discriminator are used to train the ATM alternately and adversarially. In addition, to mitigate the issue of ineffective gradient back-propagation in naive multi-domain adversarial learning, we propose a novel random domain adversarial learning (RDAL) strategy that can back-propagate effective gradient signals and gradually reduce the gap between multiple domains. The ATM can be combined with nodule detection models through differentiable Fast Fourier Transform (FFT) and inverse FFT, allowing end-to-end training. Experimental results on both LUNA-DG and our in-house datasets validate the superiority of AFA over representative DG methods.},
  archive      = {J_NCA},
  author       = {Yin, Baocai and Sun, Mei and Zhang, Jing and Liu, Wenchao and Liu, Cong and Wang, Zengfu},
  doi          = {10.1007/s00521-022-06928-9},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {8039-8050},
  shortjournal = {Neural Comput. Appl.},
  title        = {AFA: Adversarial frequency alignment for domain generalized lung nodule detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view clustering with dual tensors. <em>NCA</em>,
<em>34</em>(10), 8027–8038. (<a
href="https://doi.org/10.1007/s00521-022-06927-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering methods based on tensor have achieved favorable performance thanks to the powerful capacity of capturing the high-order correlation hidden in multi-view data. However, many existing works only pay attention to exploring the inter-view correlation (i.e., the correlation between views for a same sample) and ignore the intra-view correlation (i.e., the correlation between different samples in a view), such that the high-order information cannot be fully utilized. Toward this issue, we propose an innovative multi-view clustering method in this paper, multi-view clustering with dual tensors (MCDT), which simultaneously exploits the intra-view correlation and the inter-view correlation. Specifically, we first learn a set of specific affinity matrices by using subspace learning in each view. Then, we stack these affinity matrices into a tensor and impose the tensor nuclear norm to exploit the intra-view high-order correlation. Meanwhile, we also rotate this tensor to exploit the inter-view high-order correlation, so as to exploit more comprehensive information hidden in multiple views. Extensive experiments on benchmark datasets demonstrate that the proposed MCDT obtains superior performance in comparison with existing state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Mi, Yong and Ren, Zhenwen and Xu, Zhi and Li, Haoran and Sun, Quansen and Chen, Hongxia and Dai, Jian},
  doi          = {10.1007/s00521-022-06927-w},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {8027-8038},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-view clustering with dual tensors},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid deep learning models for multivariate forecasting of
global horizontal irradiation. <em>NCA</em>, <em>34</em>(10), 8005–8026.
(<a href="https://doi.org/10.1007/s00521-022-06907-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing photovoltaic (PV) instalments could affect the stability of the electrical grid as the PV produces weather-dependent electricity. However, prediction of the power output of the PV panels or incoming radiation could help to tackle this problem. It has been concluded within the European Actions “Weather Intelligence for Renewable Energies” framework that more research is needed on short-term energy forecasting using different models, locations and data for a complete overview of all possible scenarios around the world representing all possible meteorological conditions. On the other hand, for the Mediterranean region, there is a need for studies that cover a larger spectrum of forecasting algorithms. This study focuses on forecasting short-term GHI for Kalkanli, Northern Cyprus, while aiming to contribute to ongoing research on developing prediction models by testing different hybrid forecasting algorithms. Three different hybrid models are proposed using convolutional neural network (CNN), long short-term memory (LSTM) and support vector regression (SVR), and the proposed hybrid models are compared with the performance of stand-alone models, i.e. CNN, LSTM and SVR, for the short-term GHI estimation. We present our results with several evaluation metrics and statistical analysis. This is the first time such a study conducted for GHI prediction.},
  archive      = {J_NCA},
  author       = {Vakitbilir, Nuray and Hilal, Adnan and Direkoğlu, Cem},
  doi          = {10.1007/s00521-022-06907-0},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {8005-8026},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid deep learning models for multivariate forecasting of global horizontal irradiation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fake visual content detection using two-stream convolutional
neural networks. <em>NCA</em>, <em>34</em>(10), 7991–8004. (<a
href="https://doi.org/10.1007/s00521-022-06902-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid progress in adversarial learning has enabled the generation of realistic-looking fake visual content. To distinguish between fake and real visual content, several detection techniques have been proposed. The performance of most of these techniques however drops off significantly if the test and the training data are sampled from different distributions. This motivates efforts towards improving the generalization of fake detectors. Since current fake content generation techniques do not accurately model the frequency spectrum of the natural images, we observe that the frequency spectrum of the fake visual data contains discriminative characteristics that can be used to detect fake content. We also observe that the information captured in the frequency spectrum is different from that of the spatial domain. Using these insights, we propose to complement frequency and spatial domain features using a two-stream convolutional neural network architecture called TwoStreamNet. We demonstrate the improved generalization of the proposed two-stream network to several unseen generation architectures, datasets, and techniques. The proposed detector has demonstrated significant performance improvement compared to the current state-of-the-art fake content detectors with the fusing of frequency and spatial domain streams also improving the generalization of the detector.},
  archive      = {J_NCA},
  author       = {Yousaf, Bilal and Usama, Muhammad and Sultani, Waqas and Mahmood, Arif and Qadir, Junaid},
  doi          = {10.1007/s00521-022-06902-5},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7991-8004},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fake visual content detection using two-stream convolutional neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Computational characteristics of feedforward neural
networks for solving a stiff differential equation. <em>NCA</em>,
<em>34</em>(10), 7975–7989. (<a
href="https://doi.org/10.1007/s00521-022-06901-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feedforward neural networks offer a possible approach for solving differential equations. However, the reliability and accuracy of the approximation still represent delicate issues that are not fully resolved in the current literature. Computational approaches are in general highly dependent on a variety of computational parameters as well as on the choice of optimisation methods, a point that has to be seen together with the structure of the cost function. The intention of this paper is to make a step towards resolving these open issues. To this end, we study here the solution of a simple but fundamental stiff ordinary differential equation modelling a damped system. We consider two computational approaches for solving differential equations by neural forms. These are the classic but still actual method of trial solutions defining the cost function, and a recent direct construction of the cost function related to the trial solution method. Let us note that the settings we study can easily be applied more generally, including solution of partial differential equations. By a very detailed computational study, we show that it is possible to identify preferable choices to be made for parameters and methods. We also illuminate some interesting effects that are observable in the neural network simulations. Overall we extend the current literature in the field by showing what can be done in order to obtain useful and accurate results by the neural network approach. By doing this we illustrate the importance of a careful choice of the computational setup.},
  archive      = {J_NCA},
  author       = {Schneidereit, Toni and Breuß, Michael},
  doi          = {10.1007/s00521-022-06901-6},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7975-7989},
  shortjournal = {Neural Comput. Appl.},
  title        = {Computational characteristics of feedforward neural networks for solving a stiff differential equation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Video saliency aware intelligent HD video compression with
the improvement of visual quality and the reduction of coding
complexity. <em>NCA</em>, <em>34</em>(10), 7955–7974. (<a
href="https://doi.org/10.1007/s00521-022-06895-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fast development of video technology and hardware has led to a great amount of video applications in the field of industry, such as the video conference, video surveillance and live video streaming. Most of the applications are facing with the problem of limited network bandwidth while try to keep high video resolution. Perceptual video compression addresses the problem by introducing saliency information to reduce the perceptual redundancy, which retains more information in salient region while compresses the non-salient region as much as possible. In this paper, in order to combine the multi-scale information in video saliency, an advanced video saliency detection model SALDPC is proposed which is built based on deformable pyramid convolution decoder and multi-scale temporal recurrence. In order to better guide video coding through saliency, based on the HEVC video coding standard, a saliency-aware rate-distortion optimization algorithm, SRDO, is proposed using block-based saliency information to change the rate-distortion balance and guide more reasonable bit allocation. Furthermore, a more flexible QP selection method, SAQP, is developed using CU&#39;s saliency information adaptively to change the QP of CU to ensure the high quality of the high saliency areas. The final results are available in the following three configurations: SRDO, SRDO + SQP, and SRDO + SAQP. Experimental results show that our method achieves a very high video quality improvement while significantly reducing the video encoding time. Compared to HEVC, the BD-EWPSNR of the SRDO method improves 0.703 dB, and the BD-Rate based on EWPSNR saves 20.822\%; the BD-EWPSNR of the SRDO + SAQP is improved up to 1.217 dB, and the BD-Rate based on EWPSNR further saves up to 32.41\%. At the same time, in terms of compression time, the proposed method saves up to 29.06\% compared to HEVC. Experimental results show the superiority of the proposed method in comparison to the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Zhu, Shiping and Chang, Qinyao and Li, Qinghai},
  doi          = {10.1007/s00521-022-06895-1},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7955-7974},
  shortjournal = {Neural Comput. Appl.},
  title        = {Video saliency aware intelligent HD video compression with the improvement of visual quality and the reduction of coding complexity},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data portability for activities of daily living and fall
detection in different environments using radar micro-doppler.
<em>NCA</em>, <em>34</em>(10), 7933–7953. (<a
href="https://doi.org/10.1007/s00521-022-06886-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The health status of an older or vulnerable person can be determined by looking into the additive effects of aging as well as any associated diseases. This status can lead the person to a situation of ‘unstable incapacity’ for normal aging and is determined by the decrease in response to the environment and to specific pathologies with apparent decrease of independence in activities of daily living (ADL). In this paper, we use micro-Doppler images obtained using a frequency-modulated continuous wave radar (FMCW) operating at 5.8 GHz with 400 MHz bandwidth as the sensor to perform assessment of this health status. The core idea is to develop a generalized system where the data obtained for ADL can be portable across different environments and groups of subjects, and critical events such as falls in mature individuals can be detected. In this context, we have conducted comprehensive experimental campaigns at nine different locations including four laboratory environments and five elderly care homes. A total of 99 subjects participated in the experiments where 1453 micro-Doppler signatures were recorded for six activities. Different machine learning, deep learning algorithms and transfer learning technique were used to classify the ADL. The support vector machine (SVM), K-nearest neighbor (KNN) and convolutional neural network (CNN) provided adequate classification accuracies for particular scenarios; however, the autoencoder neural network outperformed the mentioned classifiers by providing classification accuracy of ~ 88\%. The proposed system for fall detection in elderly people can be deployed in care centers and is application for any indoor settings with various age group of people. For future work, we would focus on monitoring multiple older adults, concurrently in indoor settings using continuous radar sensor data stream which is limitation of the present system.},
  archive      = {J_NCA},
  author       = {Shah, Syed Aziz and Tahir, Ahsen and Le Kernec, Julien and Zoha, Ahmed and Fioranelli, Francesco},
  doi          = {10.1007/s00521-022-06886-2},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7933-7953},
  shortjournal = {Neural Comput. Appl.},
  title        = {Data portability for activities of daily living and fall detection in different environments using radar micro-doppler},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Selection of suitable distance education platforms based on
human–computer interaction criteria under fuzzy environment.
<em>NCA</em>, <em>34</em>(10), 7919–7931. (<a
href="https://doi.org/10.1007/s00521-022-06935-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid spread of the COVID-19 pandemic has affected not only the health industry but also the education sector. E-learning systems have recently become a compulsory part of all education institutions, including schools, colleges, and universities worldwide because of the COVID-19 pandemic crisis. The objectives of the current study were twofold: (1) to conduct an analytical approach for ranking of distance education platforms based on human–computer interaction criteria and (2) to identify the most appropriate distance learning platform for teaching and learning activities by using multi-criteria decision-making approaches. Selection criteria were grouped into human–computer interaction-related criteria, such as ease of use, possibility of causing mental workload, user-friendly interface design, presentation method, and interactivity. In the selection procedure, a spherical fuzzy extension of Analytical Hierarchy Process was utilized to identify the weights of selection criteria and to rank distance education platforms. The results revealed that the most important criterion was the possibility of causing mental workload while the most preferable e-learning system was identified as “A3”.},
  archive      = {J_NCA},
  author       = {Adem, Aylin and Çakıt, Erman and Dağdeviren, Metin},
  doi          = {10.1007/s00521-022-06935-w},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7919-7931},
  shortjournal = {Neural Comput. Appl.},
  title        = {Selection of suitable distance education platforms based on human–computer interaction criteria under fuzzy environment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of artificial neural network to predict copra
conversion factor. <em>NCA</em>, <em>34</em>(10), 7909–7918. (<a
href="https://doi.org/10.1007/s00521-022-06893-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coconut (Cocos nucifera) is one of the major plantation crops in Sri Lanka. It has paved the way for establishing many industries due to versatility of the crop earning significant income to the country. One of the most important export products of coconut is “Copra” which earns a high export market income to the country (927.7 Rs/Mln in 2019). Literature reports that the copra conversion factor (CCF) is 0.19 kg, where approximately 5 nuts are required to produce 1 kg of copra. This study investigates the stability of this conversion factor and the dependency of it with various nut parameters (number of nuts in a harvest, fresh nut weight, husked nut weight (DW) and split nut weight (SW)) and meteorological parameters (rainfall, maximum and minimum air temperatures) to establish a relationship to estimate CCF of a nut. Results showed that CCF was temporally not stable and positively correlated with DW and SW. The study established a model to predict CCF using multilayer feed-forward neural network approach (MLFFNN). Performance of the model showed R  = 0.83  in training, 0.93 in testing and 0.93 in validation with MSE &lt; 0.0002. Study further revealed that ~ 50\% of the temporal variability of copra outturn was explained by temperature related parameters.},
  archive      = {J_NCA},
  author       = {Waidyarathne, K. P. and Chandrathilake, T. H. and Wickramarachchi, W. S.},
  doi          = {10.1007/s00521-022-06893-3},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7909-7918},
  shortjournal = {Neural Comput. Appl.},
  title        = {Application of artificial neural network to predict copra conversion factor},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance improvement of an AVR system by symbiotic
organism search algorithm-based PID-f controller. <em>NCA</em>,
<em>34</em>(10), 7899–7908. (<a
href="https://doi.org/10.1007/s00521-022-06892-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic voltage regulator (AVR) system is commonly used in power systems to remain terminal voltage of generator at a specified level. The terminal voltage level is controlled by utilizing various controllers in an AVR system. Researchers aim to enhance dynamic performance of the AVR system besides minimize steady state error by employing various controllers in their studies. In most of these studies, evolutionary algorithms are used during controller design process. Evolutionary algorithms are commonly utilized to optimally tune controller parameters according to predefined objective function. In this study, a proportional-integral-derivative (PID) controller with filter (PID-F) is proposed for an AVR system in order to improve its dynamic performance. The proposed PID-F controller has four independent variables which are optimally tuned by utilizing symbiotic organism search (SOS) algorithm. In order to analyze the performance of the designed PID-F controller, step response of the AVR system is obtained and transient response analysis is performed. The obtained transient response characteristics are compared with available current studies proposing optimally tuned PID controllers for the AVR system. In addition, stability of the AVR system with the proposed SOS algorithm-based PID-F controller is analyzed by carrying out pole/zero map analysis and bode diagram analysis. Lastly, robustness of the proposed controller toward parameter uncertainties in the AVR system is examined. The results indicate that the proposed SOS algorithm-based PID-F controller enhances the transient response characteristics, stability and robustness of the AVR system and can be successfully employed in the AVR system.},
  archive      = {J_NCA},
  author       = {Ozgenc, Busra and Ayas, Mustafa Sinasi and Altas, Ismail Hakki},
  doi          = {10.1007/s00521-022-06892-4},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7899-7908},
  shortjournal = {Neural Comput. Appl.},
  title        = {Performance improvement of an AVR system by symbiotic organism search algorithm-based PID-F controller},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward intelligent clothes manufacturing: A systematic
method for static and dynamic task allocation by genetic optimization.
<em>NCA</em>, <em>34</em>(10), 7881–7897. (<a
href="https://doi.org/10.1007/s00521-022-06890-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing of economic globalization and world economic integration, customer demands are becoming increasingly personalization and diversification. How to design a reasonable schedule scheme becomes the key point of industries. Flexible job shop scheduling problem (FJSP) is an extension of the classical job scheduling problem (JSP). It is an important problem in the modern manufacturing system, and constitutes to one of the most difficult combinatorial optimization problems. This paper defines an objective function, which aims at minimizing the makespan, under the conveyor constraints. Moreover, we present a genetic algorithm (GA)-based approach to optimizing the objective. Specifically, we firstly propose a method for solving conveyor-constrained FJSP (CDFJSP) by using a plug-in greedy algorithm and a binary search algorithm. Considering the unexpected events that usually occur in real-life applications, a real-time method with dispatching rules (RDRP) is proposed. Extensive experimental results demonstrate the efficacy of our proposed methods.},
  archive      = {J_NCA},
  author       = {Yan, Han and Du, Xiaomeng and Xu, Lu and Xu, Shichao and Zhang, Yanfeng and Gong, Peng},
  doi          = {10.1007/s00521-022-06890-6},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7881-7897},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward intelligent clothes manufacturing: A systematic method for static and dynamic task allocation by genetic optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A variable weight-based interval type-2 fuzzy rough
comprehensive evaluation method for curtain grouting efficiency
assessment. <em>NCA</em>, <em>34</em>(10), 7851–7879. (<a
href="https://doi.org/10.1007/s00521-021-06864-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curtain grouting efficiency evaluation is vital to ensure the safety and stability of dam foundation constructions. However, the existing grouting efficiency evaluations rarely consider the intrapersonal uncertainty and interpersonal uncertainty involved in the indicator weight determination and cannot objectively reflect the impact of different indicator values on the evaluation results, which may lead to inaccurate results. To address these issues, a variable weight-based interval type-2 fuzzy rough comprehensive evaluation method is proposed. The interval type-2 fuzzy rough AHP is developed to determine the indicator weights under intrapersonal and interpersonal uncertainties, specifically, the individual linguistic judgment is expressed by interval type-2 fuzzy sets (IT2FSs), then the individual judgments are aggregated by rough sets to establish the interval type-2 fuzzy rough number to simultaneously handle individual linguistic vagueness and group preference diversity; furthermore, the multi-attributive border approximation area comparison (MABAC) method extended by variable weight theory is adopted to conduct the grouting efficiency evaluation, and it takes into account the influence of indicator value variations, where the indicator weight can be adjusted according to its actual value to obtain more objective and reliable evaluation results. Finally, the feasibility and superiority of the proposed method are illustrated through a practical case study application and comparisons with several different methods. The proposed model has powerful uncertainty handling capacity and can truly reveal the severity of a problem, ensures more objective and comprehensive evaluation results and is highly practical, which can help grouting engineers judge grouting efficiency more scientifically and effectively.},
  archive      = {J_NCA},
  author       = {Zhu, Yushan and Wang, Xiaoling and Chen, Wenlong and Guo, Hui and Li, Dong},
  doi          = {10.1007/s00521-021-06864-0},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7851-7879},
  shortjournal = {Neural Comput. Appl.},
  title        = {A variable weight-based interval type-2 fuzzy rough comprehensive evaluation method for curtain grouting efficiency assessment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of the undrained shear strength of sensitive
clays using optimized inference intelligence system. <em>NCA</em>,
<em>34</em>(10), 7835–7849. (<a
href="https://doi.org/10.1007/s00521-022-06891-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The undrained shear strength of the sensitive clays is an important parameter for the design of the foundation of the civil engineering structures. In this study, novel hybrid machine learning approaches, namely ANFIS-CA and ANFIS-PSO, are developed to predict the undrained shear strength of the sensitive clays. These approaches are based on adaptive neuro-fuzzy inference system (ANFIS) and two metaheuristic optimizations techniques including cultural algorithm (CA) and particle swarm optimization (PSO). Unlike other empirical methods that relied on accurate determination of the pre-consolidation pressure, the proposed approaches are based on five reliable input parameters: depth, effective vertical stress, natural water content, liquid limit, and plastic limit. For this purpose, data of 216 sensitive clay samples obtained from different parts of Southern Finland were used for validating and training models. Standard statistical measures were used to evaluate performance of the models. The results show that the proposed hybrid ANFIS-PSO model obtained reasonably good accuracy (correlation coefficient: R = 0.715), in comparison with ANFIS-CA model (R = 0.6) in predicting the undrained shear strength of the sensitive clays. Therefore, the ANFIS-PSO model is very promising to predict the undrained shear strength of the sensitive clays with limited input parameters.},
  archive      = {J_NCA},
  author       = {Tran, Quoc Anh and Ho, Lanh Si and Le, Hiep Van and Prakash, Indra and Pham, Binh Thai},
  doi          = {10.1007/s00521-022-06891-5},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7835-7849},
  shortjournal = {Neural Comput. Appl.},
  title        = {Estimation of the undrained shear strength of sensitive clays using optimized inference intelligence system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel ADHD classification method based on resting state
temporal templates (RSTT) using spatiotemporal attention auto-encoder.
<em>NCA</em>, <em>34</em>(10), 7815–7833. (<a
href="https://doi.org/10.1007/s00521-021-06868-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been of great interest in the neuroimaging community to model spatiotemporal brain function and related disorders based on resting state functional magnetic resonance imaging (rfMRI). Although a variety of deep learning models have been proposed for modeling rfMRI, the dominant models are limited in capturing the long-distance dependency (LDD) due to their sequential nature. In this work, we propose a spatiotemporal attention auto-encoder (STAAE) to discover global features that address LDDs in volumetric rfMRI. The unsupervised STAAE framework can spatiotemporally model the rfMRI sequence and decompose the rfMRI into spatial and temporal patterns. The spatial patterns have been extensively explored and are also known as resting state networks (RSNs), yet the temporal patterns are underestimated in last decades. To further explore the application of temporal patterns, we developed a resting state temporal template (RSTT)-based classification framework using the STAAE model and tested it with attention-deficit hyperactivity disorder (ADHD) classification. Five datasets from ADHD-200 were used to evaluate the performance of our method. The results showed that the proposed STAAE outperformed three recent methods in deriving ten well-known RSNs. For ADHD classification, the proposed RSTT-based classification framework outperformed methods in recent studies by achieving a high accuracy of 72.5\%. Besides, we found that the RSTTs derived from NYU dataset still work on the other four datasets, but the accuracy on different test datasets decreased with the increase in the age gap to NYU dataset, which likely supports the idea of that there exist age differences of brain activity among ADHD patients.},
  archive      = {J_NCA},
  author       = {Qiang, Ning and Dong, Qinglin and Liang, Hongtao and Ge, Bao and Zhang, Shu and Zhang, Cheng and Gao, Jie and Sun, Yifei},
  doi          = {10.1007/s00521-021-06868-w},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7815-7833},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel ADHD classification method based on resting state temporal templates (RSTT) using spatiotemporal attention auto-encoder},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new feature extraction technique based on improved owl
search algorithm: A case study in copper electrorefining plant.
<em>NCA</em>, <em>34</em>(10), 7749–7814. (<a
href="https://doi.org/10.1007/s00521-021-06881-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction, feature clustering, feature selection are suitable to enhance learning performance, reduce computational complexity, create better generalizable models, and reduce required storage. Although there are several feature reduction techniques, still it remains one of the research hot spots in the field of data mining and machine learning groups. Owl search algorithm (OSA) is one of the recent metaheuristic optimization algorithms that mimic the hunting mechanism of owls in dark. However, OSA suffers from the same problem faced by many other optimization algorithms and tends to fall in local optima and premature convergence. To overcome these problems, two improvements for OSA algorithm are proposed in this paper. The first improvement uses a fuzzy system which is responsible to tune a control parameter in the updating phase of OSA. The second improvement includes the fuzzy system along with modifying the updating equation of OSA to enhance the exploration activity. In addition, this paper presents a new feature extraction technique for regression problems based on the improved OSA, called Fuzzy Owl Clustering Dimension Reduction (FOCDR). We apply a method that uses three weighting methods (i.e., soft, hard, and mixed) to extract new features based on the generated clusters. The experiment is divided into two parts. In the first part, the performance of the OSA algorithm and two improvement versions are analyzed with ten benchmark functions. The results show that the proposed versions on average can improve the convergence rate by 6.75\% and 14.2\% compared to OSA in solving complex problems. The second part is conducted to show FOCDR’s ability for feature selection problems. The effectiveness of FOCDR has been evaluated using four benchmark datasets and a real-world case study.},
  archive      = {J_NCA},
  author       = {Mansouri, Najme and Khayati, Gholam Reza and Mohammad Hasani Zade, Behnam and Khorasani, Seyed Mohammad Javad and Kafi Hernashki, Roya},
  doi          = {10.1007/s00521-021-06881-z},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7749-7814},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new feature extraction technique based on improved owl search algorithm: A case study in copper electrorefining plant},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Low-light image enhancement network with decomposition and
adaptive information fusion. <em>NCA</em>, <em>34</em>(10), 7733–7748.
(<a href="https://doi.org/10.1007/s00521-021-06836-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-quality clear image can not only bring a good subjective feeling, but also provide good performance guarantee for subsequent computer vision tasks in practical industrial applications. How to improve the low-light image quality and obtain clear image is a challenging task in computer vision. In order to ensure that clear images can be obtained under harsh lighting conditions, we propose a new low-light image enhancement network with decomposition and adaptive information fusion strategy. It firstly decomposes the image by decomposition network, which can obtain a reflection map with more details. Next, a brightness perception network is used to obtain the global and local brightness features of the input image. In addition, we employ an adaptive information fusion module (AIFM) to deal with the redundant information and noise in the multiple features. The experimental results show that the proposed network can not only restore the visually satisfactory image brightness, but also effectively remove the noise and get clear enhancement results. Specifically, the proposed method can achieve 22.20dB PSNR and 0.8380 SSIM gain on LOL dataset, which is the best performance and significantly improved compared with the state-of-the-art methods. We also illustrate the performance by NIQE scores with the proposed method and other comparable algorithms on several other real-world low-light benchmarks datasets including NPE, DICM and LIME, which also indicate that the proposed method has good generalization ability and superiority.},
  archive      = {J_NCA},
  author       = {Zhu, Hegui and Wang, Kai and Zhang, Ziwei and Liu, Yuelin and Jiang, Wuming},
  doi          = {10.1007/s00521-021-06836-4},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7733-7748},
  shortjournal = {Neural Comput. Appl.},
  title        = {Low-light image enhancement network with decomposition and adaptive information fusion},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive grey wolf optimizer. <em>NCA</em>, <em>34</em>(10),
7711–7731. (<a
href="https://doi.org/10.1007/s00521-021-06885-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm-based metaheuristic optimization algorithms have demonstrated outstanding performance on a wide range of optimization problems in both science and industry. Despite their merits, a major limitation of such techniques originates from non-automated parameter tuning and lack of systematic stopping criteria that typically leads to inefficient use of computational resources. In this work, we propose an improved version of grey wolf optimizer (GWO) named adaptive GWO which addresses these issues by adaptive tuning of the exploration/exploitation parameters based on the fitness history of the candidate solutions during the optimization. By controlling the stopping criteria based on the significance of fitness improvement in the optimization, AGWO can automatically converge to a sufficiently good optimum in the shortest time. Moreover, we propose an extended adaptive GWO ( $$\hbox {AGWO}^\varDelta$$ ) that adjusts the convergence parameters based on a three-point fitness history. In a thorough comparative study, we show that AGWO is a more efficient optimization algorithm than GWO by decreasing the number of iterations required for reaching statistically the same solutions as GWO and outperforming a number of existing GWO variants.},
  archive      = {J_NCA},
  author       = {Meidani, Kazem and Hemmasian, AmirPouya and Mirjalili, Seyedali and Barati Farimani, Amir},
  doi          = {10.1007/s00521-021-06885-9},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7711-7731},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive grey wolf optimizer},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning and internet of things for tourist attraction
recommendations in smart cities. <em>NCA</em>, <em>34</em>(10),
7691–7709. (<a
href="https://doi.org/10.1007/s00521-021-06872-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a tourist attraction IoT-enabled deep learning-based recommendation system to enhance tourist experience in a smart city. Travelers will enter details about their travels (traveling alone or with a companion, type of companion such as partner or family with kids, traveling for business or leisure, etc.) as well as user side information (age of the traveler/s, hobbies, etc.) into the smart city app/website. Our proposed deep learning-based recommendation system will process this personal set of input features to recommend the tourist activities/attractions that best fit his/her profile. Furthermore, when the tourists are in the smart city, content-based information (already visited attractions) and context-related information (location, weather, time of day, etc.) are obtained in real time using IoT devices; this information will allow our proposed deep learning-based tourist attraction recommendation system to suggest additional activities and/or attractions in real time. Our proposed multi-label deep learning classifier outperforms other models (decision tree, extra tree, k-nearest neighbor and random forest) and can successfully recommend tourist attractions for the first case [(a) searching for and planning activities before traveling] with the loss, accuracy, precision, recall and F1-score of 0.5\%, 99.7\%, 99.9\%, 99.9\% and 99.8\%, respectively. It can also successfully recommend tourist attractions for the second case [(b) looking for activities within the smart city] with the loss, accuracy, precision, recall and F1-score of 3.7\%, 99.5\%, 99.8\%, 99.7\% and 99.8\%, respectively.},
  archive      = {J_NCA},
  author       = {Cepeda-Pacheco, Juan Carlos and Domingo, Mari Carmen},
  doi          = {10.1007/s00521-021-06872-0},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7691-7709},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning and internet of things for tourist attraction recommendations in smart cities},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-space evolutionary search with dynamic resource
allocation strategy for large-scale optimization. <em>NCA</em>,
<em>34</em>(10), 7673–7689. (<a
href="https://doi.org/10.1007/s00521-021-06844-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-space evolutionary search ( $${\rm MSES}$$ ) is a recently proposed paradigm to optimize across multiple solution spaces for solving a large-scale optimization problem. $${\rm MSES}$$ allocates the computational resource equally on each search space. However, different search spaces are likely to make different contributions to the finding of global optimum of the given problem. Dividing the limited resources equally on each search space in $${\rm MSES}$$ is thus not an efficient strategy. This paper aims to investigate how to utilize the imbalanced efforts to allocate computational resources in multiple search spaces to efficiently improve the performance of $${\rm MSES}$$ . In this paper, we propose a novel multi-space evolutionary search with dynamic resource allocation strategy ( $${\rm MSES-DRA} $$ ) for large-scale optimization. In particular, a detection mechanism is presented to measure the reasonableness of assignment in terms of computation resource of different spaces. Further, according to the interaction between optimal individual and population, the proposed dynamic resource allocation strategy is designed based on the explicit–implicit contributions of spaces. The explicit and implicit contributions are defined by the fitness improvement of best solution and the survival of individuals, respectively. An adaptive technology based on the feedback is conducted to balance the assignment of computational resources for each search space. To evaluate the performance of the proposed method, comprehensive empirical experiments have been conducted on the CEC2013 large-scale benchmark problems.},
  archive      = {J_NCA},
  author       = {Shang, Qingxia and Huang, Yuxiao and Dong, Junwei and Hou, Yaqing and Wang, Yu and Li, Min and Feng, Liang},
  doi          = {10.1007/s00521-021-06844-4},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7673-7689},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-space evolutionary search with dynamic resource allocation strategy for large-scale optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction and optimization of electrical conductivity for
polymer-based composites using design of experiment and artificial
neural networks. <em>NCA</em>, <em>34</em>(10), 7653–7671. (<a
href="https://doi.org/10.1007/s00521-021-06798-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, conductive polymer-based composites in order to have higher electrical conductivity have been constructed using different nanoparticles and numerically considered by different classification techniques. Due to non-conducting feature of polymer-based composites, their other positive advantages (e.g., light weight and stress corrosion) underneath non-conducting defect in which this paper has tried to overcome the faced challenges. For this purpose, carbon black (CB), carbon nanotube (CNT), and expanded graphite (EG) with different weight percentages are added to the epoxy resin as input factors and the electrical conductivity of the samples are measured as response factor. The analysis of input factors is performed and the Taguchi method, artificial neural networks (ANNs) and extreme learning machine (ELM) are designed and used for the prediction of the response factor. The predicted responses using the applied methods are compared with the experimental results. In order to increase the mechanical strength, ten layers of unidirectional carbon fiber are used. The simulation results show that the ANNs and ELM provide good compatible predictions with respect to actual experiment data. Besides, obtained experimental results prove that the highest electrical conductivity has been achieved using 10, 15, and 25 percent using the CNT, EG, and CB, respectively. As a novelty of this paper, the constructed sample composite reaches the acceptable electrical conductivity suggested by United Stated Department of Energy standard considered as material development. In particular, the findings of this research can be used to construct conductive electrodes particularly in oil and gas industries.},
  archive      = {J_NCA},
  author       = {Razavi, Seyed Morteza and Sadollah, Ali and Al-Shamiri, Abobakr Khalil},
  doi          = {10.1007/s00521-021-06798-7},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7653-7671},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction and optimization of electrical conductivity for polymer-based composites using design of experiment and artificial neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A list-based simulated annealing algorithm with crossover
operator for the traveling salesman problem. <em>NCA</em>,
<em>34</em>(10), 7627–7652. (<a
href="https://doi.org/10.1007/s00521-021-06883-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traveling salesman problem (TSP) is one of the most popular combinatorial optimization problems today. It is a problem that is easy to identify but hard to solve. Therefore, it belongs to the class of NP-hard optimization problems, and it is a problem of high time complexity. The TSP can be used to solve various real-world problems. Therefore, researchers use it as a standard test bench for performance evaluation of new algorithms. In this study, a new simulated annealing algorithm with crossover operator was proposed, and it was called LBSA-CO. The LBSA-CO is a population-based metaheuristic method. In this method, a list-based temperature cooling schedule, which can adapt to the topology of the solution space of the problem, was used. The solutions in the population were improved with the inversion, insertion and 2-opt local search operators. The order crossover (OX1) and genetic edge recombination crossover (ER) operators were applied to the improved solutions to accelerate the convergence. In addition, the Taguchi method was used to tune the parameters of the LBSA-CO. The proposed method was tested on 65 well-known TSP instances. The results indicated that this method performs better than the state-of-the-art methods on many instances.},
  archive      = {J_NCA},
  author       = {İlhan, İlhan and Gökmen, Gazi},
  doi          = {10.1007/s00521-021-06883-x},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7627-7652},
  shortjournal = {Neural Comput. Appl.},
  title        = {A list-based simulated annealing algorithm with crossover operator for the traveling salesman problem},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of oil authenticity and adulteration using
deep long short-term memory-based neural network with seagull
optimization algorithm. <em>NCA</em>, <em>34</em>(10), 7611–7625. (<a
href="https://doi.org/10.1007/s00521-021-06829-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important aspects of people&#39;s everyday diet is edible oils. Good quality cooking oil plays a key role in one&#39;s health. Due to the increased demand for oil in both the international and domestic markets, vendors often mix the high-quality oil with low-quality ones causing adulteration which is a serious issue to be solved. Thus, qualified (authentic or pure) edible oils are expensive. Gall bladder cancer is mainly caused when the oil is adulterated with butter yellow, argemone oil, mixing good quality oil with low-quality oils, and wrong ingredients with fraudulent labeling. In the past decades, spectrophotometric methods and machine learning techniques are utilized for adulteration and authenticity identification of sunflower oil, olive oil, corn oil, coconut oil, mustard oil, soybean oils. Nevertheless, the performance of these methods is decreased due to data imbalance, overfitting, higher cost, more execution time, computational complexity, and inaccurate classification. To tackle these issues, we have proposed Deep Long Short-Term Memory (LSTM) neural network with a Seagull Optimization Algorithm (SOA) for the authenticity and adulteration of edible oils classification. In this study, 5 kinds of edible oils such as coconut oil, rice oil, sesame oil, sunflower oil, and Olive oil are used. Each of the oil samples was kept in the refrigerator at 4 °C. During data acquisition, the proton resonance frequency was 19.91 MHz and the magnetic field strength was 0.467 T. The obtained signals are applied for edible oil classification, which is handled using a deep LSTM neural network with SOA. Based on the experimental investigation, the proposed method accomplished superior performances than existing methods including LFNMR-CNN, LFNMR-SVM, DLC, Pre-trained CNN.},
  archive      = {J_NCA},
  author       = {Surya, V. and Senthilselvi, A.},
  doi          = {10.1007/s00521-021-06829-3},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7611-7625},
  shortjournal = {Neural Comput. Appl.},
  title        = {Identification of oil authenticity and adulteration using deep long short-term memory-based neural network with seagull optimization algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GAGIN: Generative adversarial guider imputation network for
missing data. <em>NCA</em>, <em>34</em>(10), 7597–7610. (<a
href="https://doi.org/10.1007/s00521-021-06862-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing data imputation aims to accurately impute the unobserved regions with complete data in the real world. Although many current methods have made remarkable advances, the local homogenous regions, especially in boundary, and the reason of the imputed data are still the two most challenging issues. To address these issues, we propose a novel Generative Adversarial Guider Imputation Network (GAGIN) based on generative adversarial network (GAN) for unsupervised imputation, which is composed of a Global-Impute-Net (GIN), a Local-Impute-Net (LIN) and an Impute Guider Model (IGM). The GIN looks at the entire missing regions to generate and impute data as a whole. Considering the reason of the GIN results, IGM is assigned to capture coherent information between global and local and guide the LIN to look only at a small area centered at the missing focused regions. After processing these three modules, the local imputed results are concatenated to those global imputed results, which impute the rational values and refine the local details from rough to accurate. The comprehensive experiments demonstrate our proposed method is significantly superior to the other three state-of-the-art approaches and seven traditional methods, and we achieve the best RMSE surpass the second-best method on both numeric datasets (17.3\%) and image dataset (24.1\%). Besides, the extensive ablation study validates the superior performance for dealing with missing data imputation.},
  archive      = {J_NCA},
  author       = {Wang, Wei and Chai, Yimeng and Li, Yue},
  doi          = {10.1007/s00521-021-06862-2},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7597-7610},
  shortjournal = {Neural Comput. Appl.},
  title        = {GAGIN: Generative adversarial guider imputation network for missing data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IC-GAR: Item co-occurrence graph augmented session-based
recommendation. <em>NCA</em>, <em>34</em>(10), 7581–7596. (<a
href="https://doi.org/10.1007/s00521-021-06859-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation aims to recommend the next item of an anonymous user session. Previous models consider only the current session and learn both of the user’s global and local preferences. These models fail to consider an important source of information, i.e., the co-occurrence pattern of items in different sessions. The co-occurrence patterns elicit the trajectory of other similar users and can improve the recommendation performance. We propose an Item Co-occurrence Graph Augmented Session-based Recommendation (IC-GAR) model, a novel session-based recommendation model that augments the representations of the current session with session co-occurrence patterns. IC-GAR consists of three modules: Encode Module, Session Co-occurrence Module and Prediction Module. The Encoder Module learns both of the user’s global and local preference from the current session using Gate Recurrent Units (GRU). The Session Co-occurrence Module uses a modified variant of Graph Convolutional Network (GCN) to model higher order interactions between the item transition patterns in the training sessions. By aggregating the GCN representation of items of the current session, session co-occurrence representation is learned. The Prediction Module decomposes global preference, local preference and session co-occurrence to predict the probability scores of candidate items. Extensive experiments on three publicly available datasets are conducted to demonstrate the effectiveness of IC-GAR. 8.5–39.2\% improvement are achieved across datasets in Precision @5, 10 and MRR@5, 10.},
  archive      = {J_NCA},
  author       = {Gwadabe, Tajuddeen Rabiu and Liu, Ying},
  doi          = {10.1007/s00521-021-06859-x},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7581-7596},
  shortjournal = {Neural Comput. Appl.},
  title        = {IC-GAR: Item co-occurrence graph augmented session-based recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new synergy of singular spectrum analysis with a conscious
algorithm to detect faults in industrial robotics. <em>NCA</em>,
<em>34</em>(10), 7565–7580. (<a
href="https://doi.org/10.1007/s00521-021-06848-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investigating vibration signals is an effective technique for assessing system malfunction. However, extraction of weak flaw characteristics of shaking signals with large noise is difficult. Therefore, a new approach using singular spectrum analysis (SSA) integrated with generalized structured shrinkage algorithm (GSSA) is proposed in this study for flaw diagnosis in an industrial robot. First, SSA allows the separation of complicated encoding signals to several interpretable elements involving a trend signal, set of cyclic oscillations, and residual (mixed) signal. Second, the concept of algorithm-conscious sparsity-assisted techniques is presented to improve flaw features, expand the model-conscious sparsity-assisted flaw detection, and enable an easy and scalable algorithm layout. Third, GSSA is built in algorithm-conscious techniques to address drawbacks of $$L_{1}$$ -norm penalty on the basis of flaw characteristic optimization techniques and describe generalized structured shrinkage regulators. GSSA is proposed to extract noise interference, discrete frequency interference, and cyclic impulse of a robot manipulator focused on the signal of rotary encoder. Fourth, a sequence of numerical simulations and four experimental cases are carried out. Finally, comparisons are made with model-conscious strategies, including window-group-lasso and basis pursuit denoising, to prove the GSSA advantages of weak fault enhancement features further.},
  archive      = {J_NCA},
  author       = {Algburi, Riyadh Nazar Ali and Gao, Hongli and Al-Huda, Zaid},
  doi          = {10.1007/s00521-021-06848-0},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7565-7580},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new synergy of singular spectrum analysis with a conscious algorithm to detect faults in industrial robotics},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CFIDNet: Cascaded feature interaction decoder for RGB-d
salient object detection. <em>NCA</em>, <em>34</em>(10), 7547–7563. (<a
href="https://doi.org/10.1007/s00521-021-06845-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with RGB salient object detection (SOD) methods, RGB-D SOD models show better performance in many challenging scenarios by leveraging spatial information embedded in depth maps. However, existing RGB-D SOD models prone to ignore the modality-specific characteristics and fuse multi-modality features by simple element-wise addition or multiplication. Thus, they may induce noise-degraded saliency maps when encountering inaccurate or blurred depth images. Besides, many models adopt the U-shape architecture to integrate multi-level features layer-by-layer. Despite the fact that low-level features can be gradually polished, little attention has been paid to enhance high-level features, which may lead to suboptimal results. In this paper, we propose a novel network named CFIDNet to tackle the above problems. Specifically, we design the feature-enhanced module to excavate informative depth cues from depth images and enhance the RGB features by employing complementary information between RGB and depth modalities. Besides, we propose the feature refinement module to exploit multi-scale complementary information between multi-level features and polish these features by applying residual connections. The cascaded feature interaction decoder (CFID) is then proposed to refine multi-level features iteratively. Equipped with these proposed modules, our CFIDNet is capable of segmenting salient objects accurately. Experimental results on 7 widely used benchmark datasets validate that our CFIDNet achieves highly competitive performance over 15 state-of-the-art models in terms of 8 evaluation metrics. Our source code will be publicly available at https://github.com/clelouch/CFIDNet .},
  archive      = {J_NCA},
  author       = {Chen, Tianyou and Hu, Xiaoguang and Xiao, Jin and Zhang, Guofeng and Wang, Shaojie},
  doi          = {10.1007/s00521-021-06845-3},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7547-7563},
  shortjournal = {Neural Comput. Appl.},
  title        = {CFIDNet: Cascaded feature interaction decoder for RGB-D salient object detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of temperature anomaly in indian ocean based on
autoregressive long short-term memory neural network. <em>NCA</em>,
<em>34</em>(10), 7537–7545. (<a
href="https://doi.org/10.1007/s00521-021-06878-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface temperature is one of the first ocean variables investigated. Ocean temperature is a key indicator of global climate change. The anomalies in ocean temperature have caused significant deterioration of marine systems. Existing works on surface temperature anomaly considered a suite of other remote sensing measurements such as wave height, salinity and models such as support vector machine, self-organizing maps and convolutional neural networks. Neural networks are used for predicting the surface temperature. This paper proposes use of long short-term memory, a recurrent neural network method to the estimate sea surface temperature anomalies based on previous year’s sea surface temperature anomalies. NOAA OI SST V2 dataset with 40 years of data is used in the experimentation. Auto-regression is used during data preprocessing. The basic LSTM method with 3 blocks of size 2 is enhanced to 50 neurons. This proposed LSTM model has been assessed for performance on time series data, yearly wise and for the entire dataset and found that the model has been able to predict the anomalies with a reasonably good precision. The model produced error of 0.036 indicating that the model is feasible for predicting the temperature anomaly and mean absolute error of 0.14 on the testing data.},
  archive      = {J_NCA},
  author       = {Pravallika, M. Sai and Vasavi, S. and Vighneshwar, S. P.},
  doi          = {10.1007/s00521-021-06878-8},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7537-7545},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of temperature anomaly in indian ocean based on autoregressive long short-term memory neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-criteria text mining model for COVID-19 testing
reasons and symptoms and temporal predictive model for COVID-19 test
results in rural communities. <em>NCA</em>, <em>34</em>(10), 7523–7536.
(<a href="https://doi.org/10.1007/s00521-021-06884-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study is conducted to build a multi-criteria text mining model for COVID-19 testing reasons and symptoms. The model is integrated with a temporal predictive classification model for COVID-19 test results in rural underserved areas. A dataset of 6895 testing appointments and 14 features is used in this study. The text mining model classifies the notes related to the testing reasons and reported symptoms into one or more categories using look-up wordlists and a multi-criteria mapping process. The model converts an unstructured feature to a categorical feature that is used in building the temporal predictive classification model for COVID-19 test results and conducting some population analytics. The classification model is a temporal model (ordered and indexed by testing date) that uses machine learning classifiers to predict test results that are either positive or negative. Two types of classifiers and performance measures that include balanced and regular methods are used: (1) balanced random forest and (2) balanced bagged decision tree. The balanced or weighted methods are used to address and account for the biased and imbalanced dataset and to ensure correct detection of patients with COVID-19 (minority class). The model is tested in two stages using validation and testing sets to ensure robustness and reliability. The balanced classifiers outperformed regular classifiers using the balanced performance measures (balanced accuracy and G-score), which means the balanced classifiers are better at detecting patients with positive COVID-19 results. The balanced random forest achieved the best average balanced accuracy (86.1\%) and G-score (86.1\%) using the validation set. The balanced bagged decision tree achieved the best average balanced accuracy (83.0\%) and G-score (82.8\%) using the testing set. Also, it was found that the patient history, age, testing reasons, and time are the key features to classify the testing results.},
  archive      = {J_NCA},
  author       = {Abu Lekham, Laith and Wang, Yong and Hey, Ellen and Khasawneh, Mohammad T.},
  doi          = {10.1007/s00521-021-06884-w},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7523-7536},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-criteria text mining model for COVID-19 testing reasons and symptoms and temporal predictive model for COVID-19 test results in rural communities},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Designing high-performance microstrip quad-band bandpass
filters (for multi-service communication systems): A novel method based
on artificial neural networks. <em>NCA</em>, <em>34</em>(10), 7507–7521.
(<a href="https://doi.org/10.1007/s00521-021-06879-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, high-performance multi-channel microstrip filters are widely demanded by modern multi-service communication systems. Designing these filters with both compact size and low loss is a challenge for the researchers. In this paper and for the first time, we have proposed a novel method based on artificial neural network to design and simulate multichannel microstrip bandpass filters. For this purpose, the frequency, physical dimensions, and substrate parameters, i.e., type and thickness, of the BPF are selected as the inputs and the S-parameters, i.e. S11 and S21, are selected as the outputs of the proposed model. Using an accurate multilayer perceptron neural network trained with back-propagation technique, a high-performance microstrip quad-band bandpass filter (QB-BPF) is designed which has a novel compact structure consisting of meandrous spirals, coupled lines, and patch feeds. The proposed method can be easily used for designing other microstrip devices such as filters, couplers, and diplexers. The designed filter occupies a very small area of 0.0012 λg2, which is the smallest size in comparison with previously published works. It operates at 0.7, 2.2, 3.8, and 5.6 GHz for communication systems. The low insertion loss, high return losses, low group delay, and good frequency selectivity are obtained. To verify the design method and simulation results, the introduced filter is fabricated and measured. The results show an agreement between the simulation and measurement.},
  archive      = {J_NCA},
  author       = {Rezaei, Abbas and Yahya, Salah I. and Noori, Leila and Jamaluddin, Mohd Haizal},
  doi          = {10.1007/s00521-021-06879-7},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7507-7521},
  shortjournal = {Neural Comput. Appl.},
  title        = {Designing high-performance microstrip quad-band bandpass filters (for multi-service communication systems): A novel method based on artificial neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comparison of deep learning models for end-to-end
face-based video retrieval in unconstrained videos. <em>NCA</em>,
<em>34</em>(10), 7489–7506. (<a
href="https://doi.org/10.1007/s00521-021-06875-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face-based video retrieval (FBVR) is the task of retrieving videos that containing the same face shown in the query image. In this article, we present the first end-to-end FBVR pipeline that is able to operate on large datasets of unconstrained, multi-shot, multi-person videos. We adapt an existing audiovisual recognition dataset to the task of FBVR and use it to evaluate our proposed pipeline. We compare a number of deep learning models for shot detection, face detection, and face feature extraction as part of our pipeline on a validation dataset made of more than 4000 videos. We obtain 97.25\% mean average precision on an independent test set, composed of more than 1000 videos. The pipeline is able to extract features from videos at $$\sim $$ 7 times the real-time speed, and it is able to perform a query on thousands of videos in less than 0.5 s.},
  archive      = {J_NCA},
  author       = {Ciaparrone, Gioele and Chiariglione, Leonardo and Tagliaferri, Roberto},
  doi          = {10.1007/s00521-021-06875-x},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7489-7506},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comparison of deep learning models for end-to-end face-based video retrieval in unconstrained videos},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of time series models using sparse
takagi–sugeno fuzzy systems with reduced structure. <em>NCA</em>,
<em>34</em>(10), 7473–7488. (<a
href="https://doi.org/10.1007/s00521-021-06843-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simplifying fuzzy models, including those for predicting time series, is an important issue in terms of their interpretation and implementation. This simplification can involve both the number of inference rules (i.e., structure) and the number of parameters. This paper proposes novel hybrid methods for time series prediction that utilize Takagi–Sugeno fuzzy systems with reduced structure. The fuzzy sets are obtained using a global optimization algorithm (particle swarm optimization, simulated annealing, genetic algorithm, or pattern search). The polynomials are determined by elastic net regression, which is a sparse regression. The simplification is based on reducing the number of polynomial parameters in the then-part by using sparse regression and removing unnecessary rules by using labels. A new quality criterion is proposed to express a compromise between the model accuracy and its simplification. The experimental results show that the proposed methods can improve a fuzzy model while simplifying its structure.},
  archive      = {J_NCA},
  author       = {Wiktorowicz, Krzysztof and Krzeszowski, Tomasz},
  doi          = {10.1007/s00521-021-06843-5},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7473-7488},
  shortjournal = {Neural Comput. Appl.},
  title        = {Identification of time series models using sparse Takagi–Sugeno fuzzy systems with reduced structure},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved seagull optimization algorithm using lévy flight
and mutation operator for feature selection. <em>NCA</em>,
<em>34</em>(10), 7437–7472. (<a
href="https://doi.org/10.1007/s00521-021-06751-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seagull optimization algorithm (SOA) is a recent bio-inspired technique utilized to improve the constrained large-scale problems in low computational cost and quick convergence speed. However, the globally optimized search space for the SOA is linear, which means that the SOA’s global search capability could not be fully utilized. Thus, we propose an improved SOA algorithm (ISOA) using Lévy flight and mutation operators. The ISOA obtains some Lévy flight features, which improves the original SOA by performing large jumps, making the search escape from the local optima and begin at a different search space region. The mutation operator, which improves the exploration–exploitation trade-off, allows the catch of the optimal solution quickly and accurately. In order to examine the performance of the proposed ISOA approach, three experiments were conducted. The first one evaluates the ISOA in solving the global optimization problem. The second one is a comparative study based on twenty benchmark datasets to evaluate the general capability of ISOA in feature selection, compared to ten recent and well-established algorithms constructed using the other meta-heuristics methods. Furthermore, the third experiment is conducted using a real dataset with various face poses to investigate the efficiency of the ISOA in pose-variation recognition. Compared to the other meta-heuristics methods, the results show that the proposed model is more accurate and efficient in global optimization, feature selection purposes, and pose variation recognition. Furthermore, the ISOA approach outperforms the other methods proposed in the state-of-the-art literature.},
  archive      = {J_NCA},
  author       = {Ewees, Ahmed A. and Mostafa, Reham R. and Ghoniem, Rania M. and Gaheen, Marwa A.},
  doi          = {10.1007/s00521-021-06751-8},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7437-7472},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved seagull optimization algorithm using lévy flight and mutation operator for feature selection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary-based neuro-fuzzy modelling of combustion
enthalpy of municipal solid waste. <em>NCA</em>, <em>34</em>(10),
7419–7436. (<a
href="https://doi.org/10.1007/s00521-021-06870-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The viability of thermal waste-to-energy (WTE) plants and its optimal performance have informed intelligent predictive modelling of its significant variables critical to optimal energy recovery and plant operational planning using machine learning approach. However, the optimality of hyper-parameters is significant to accurate modelling of combustion enthalpy of waste in neuro-fuzzy models. In this study, the significant effect of hyper-parameters tuning of different clustering techniques, vis-à-vis fuzzy c-means (FCM), subtractive clustering (SC) and grid partitioning (GP), on the performance of the ANFIS model in its standalone and hybridized form was investigated. The ANFIS model was optimized with two evolutionary algorithms, namely particle swarm optimization (PSO) and genetic algorithm (GA), for predicting the lower heating value (LHV) of waste using the city of Johannesburg as a case study. The optimal model for LHV prediction was selected based on minimum error criteria after testing the models’ performance using relevant statistical metrics like root mean square error (RMSE), mean absolute percentage error (MAPE), mean absolute deviation (MAD), relative mean bias error (rMBE) and coefficient of variation (RCoV). The result revealed a better performance of the hybridized ANFIS model than the standalone ANFIS model. Also, a significant variation in all models’ performance at different clustering technique was noted. However, all GP-clustered models gave the most accurate prediction than others. The most accurate model was obtained using a GP-clustered PSO-ANFIS model with triangular input membership function (tri-MF) giving RMSE, MAD, MAPE, rMBE and RCoV values of 0.139, 0.064, 2.536, 0.071 and 0.181, respectively. This study established the significance of municipality-based LHV prediction model to enhance the efficiency of thermal WTE plants and the robustness of evolutionary-based neuro-fuzzy model for heating value prediction.},
  archive      = {J_NCA},
  author       = {Adeleke, Oluwatobi and Akinlabi, Stephen and Jen, Tien-Chien and Adedeji, Paul A. and Dunmade, Israel},
  doi          = {10.1007/s00521-021-06870-2},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7419-7436},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evolutionary-based neuro-fuzzy modelling of combustion enthalpy of municipal solid waste},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A finite-time projection neural network to solve the joint
optimal dispatching problem of CHP and wind power. <em>NCA</em>,
<em>34</em>(10), 7405–7417. (<a
href="https://doi.org/10.1007/s00521-021-06867-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper constructs an optimal scheduling model for combined heat and power generation units with heat storage and wind power generation considering carbon transaction costs and optimizes the output of each unit to reduce wind curtailment rate, carbon emissions, and total operating costs. In the case of considering transmission loss, the optimal scheduling model subject to actual operation constraints is expressed as a non-convex optimization problem. Based on a sufficient condition, the equivalent problem transformed from the original optimization problem is expressed as a convex problem, and a finite-time reduced-dimensional projection neural network with time-varying parameters is proposed to solve the problem. The proposed neural network can reach convergence in a limited time. The Lyapunov function is used to prove the convergence of the algorithm. Finally, the effectiveness of the designed neural network is verified by numerical simulation. Compared with reduced-dimensional projection neural network and finite-time fixed-parameter reduced-dimensional projection neural network, our neural network has a faster convergence speed.},
  archive      = {J_NCA},
  author       = {Wei, Boyu and He, Xing},
  doi          = {10.1007/s00521-021-06867-x},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7405-7417},
  shortjournal = {Neural Comput. Appl.},
  title        = {A finite-time projection neural network to solve the joint optimal dispatching problem of CHP and wind power},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-local feature relation network for few-shot learning.
<em>NCA</em>, <em>34</em>(10), 7393–7403. (<a
href="https://doi.org/10.1007/s00521-021-06840-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, few-shot learning has received considerable attention from researchers. Compared to deep learning, which requires abundant data for training, few-shot learning only requires a few labeled samples. Therefore, few-shot learning has been extensively used in scenarios in which a large number of samples cannot be obtained. However, effectively extracting features from a limited number of samples are the most important problem in few-shot learning. To solve this limitation, a multi-local feature relation network (MLFRNet) is proposed to improve the accuracy of few-shot image classification. First, we obtain the local sub-images of each image by random cropping, which is used to obtain local features. Second, we propose support-query local feature attention by exploring local feature relationships between the support and query sets. Using the local feature attention, the importance of local features of each class prototype can be calculated to classify query data. Moreover, we explore local feature relationship between the support set and the support set, and we propose support-support local feature similarity. Using local feature similarity, we can adaptively determine the margin loss of the local features, which then improves the network accuracy. Experiments on two benchmark datasets show that the proposed MLFRNet achieves state-of-the-art performance. In particular, for the miniImageNet dataset, the proposed method achieves 66.79\% (1-shot) and 83.16\% (5-shot) accuracy.},
  archive      = {J_NCA},
  author       = {Ren, Li and Duan, Guiduo and Huang, Tianxi and Kang, Zhao},
  doi          = {10.1007/s00521-021-06840-8},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7393-7403},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-local feature relation network for few-shot learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A configurable deep learning framework for medical image
analysis. <em>NCA</em>, <em>34</em>(10), 7375–7392. (<a
href="https://doi.org/10.1007/s00521-021-06873-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence-based Medical Image Analysis (AI-MIA) has achieved significant advantages in accuracy and efficiency in various biomedical applications. However, most existing deep learning (DL) models have a fixed network structure and aim at single MIA tasks, making it difficult to meet the diverse and complex MIA requirements. To improve the universality of the AI-MIA DL models, we propose a configurable DL framework, which consists of a MIA task element library and a DL model component library. We establish a MIA task element library to accurately define various potential MIA tasks for numerous diseases. In addition, we collect DL computation modules that can be used in different steps of MIA and built a DL model component library. Given a specific MIA demand of different diseases, the framework can build a personalized DL model by defining MIA tasks and configuring DL model components. Moreover, by comparing with the existing machine learning (ML)/DL models, the structure of the DL model for each configuration can be further adjusted to improve its performance. To demonstrate the effectiveness of the proposed framework, two personalized DL models are designed for upper abdominal organ detection and colon cancer cell classification, achieving high accuracy and high performance. Experimental results on actual medical image datasets show that the configurable DL framework can define specific MIA requirements for different diseases and flexibly configure DL model components to build suitable personalized DL models. Compared with the state-of-the-art methods, the significant advantage of our framework is that it can generate personalized DL models with a flexible structure and can continuously fine-tune the model structure to improve model performance.},
  archive      = {J_NCA},
  author       = {Chen, Jianguo and Yang, Nan and Zhou, Mimi and Zhang, Zhaolei and Yang, Xulei},
  doi          = {10.1007/s00521-021-06873-z},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7375-7392},
  shortjournal = {Neural Comput. Appl.},
  title        = {A configurable deep learning framework for medical image analysis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of deep learning methods for multiple sclerosis
identification using brain MRI images. <em>NCA</em>, <em>34</em>(10),
7349–7373. (<a
href="https://doi.org/10.1007/s00521-022-07099-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple sclerosis (MS) is one of the most common inflammatory neurological diseases in young adults. There are three types of MS: (1) In relapsing remitting MS (RRMS), people have temporarily periods of relapses (attacks) for days or weeks, and then symptoms seem to disappear (remitting stage). (2) In secondary progressive MS (SPMS), symptoms worsen more steadily over time. Attacks (relapses) may occur time to time but the disease can progress in non-attack periods. It is estimated that half of the RRMS patients progress to SPMS in 10 years. (3) Primary progressive MS (PPMS) is characterized by slowly worsening symptoms from the beginning, with no relapses or remissions. For PPMS patients, disability progresses slowly. Researchers have found out that in the first year, MS causes more damage than following 5–10 years. Therefore, early diagnosis is vital. In this context, deep learning models started to be popular for assisting identification/diagnosis/classification of MS patients using magnetic resonance imaging (MRI). This paper provides an in-depth review of deep learning approaches for identification and classification of MS using brain MRI images. We discuss recent trends of deep learning methods for MS identification under three categories: CNN models, hybrid models (CNN with a classifier) and deep transfer learning models. Existing deep learning algorithms are analyzed and compared according to their architecture, image modality, pre-processing, feature extraction, classifier, dataset, categories and accuracy. This survey paper would provide a valuable source for researchers who are interested in state-of-the-art deep learning methods for MS identification using MRI images.},
  archive      = {J_NCA},
  author       = {Sah, Melike and Direkoglu, Cem},
  doi          = {10.1007/s00521-022-07099-3},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7349-7373},
  shortjournal = {Neural Comput. Appl.},
  title        = {A survey of deep learning methods for multiple sclerosis identification using brain MRI images},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective optimization of electric vehicle routing
problem with battery swap and mixed time windows. <em>NCA</em>,
<em>34</em>(10), 7325–7348. (<a
href="https://doi.org/10.1007/s00521-022-06967-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing interest in green logistics, the electric vehicles have been widely used as an important distribution means. In this paper, the electric vehicle routing problem with battery swap consideration and mixed time windows constraints (EVRP-BS-MTW) is proposed. The problem aims to minimize the total distribution costs and maximize the average utilization of batteries simultaneously, meeting both the environmental and economic interests. To solve this problem, a multi-objective whale optimization algorithm enhanced by particle filter and Levy flights (MWOA-PFLF) is developed. The introduction of particle filter makes it possible to predict the near optimal solutions at each iteration, meanwhile, the combination of Levy flights contributes to escape from local optimum and accelerate convergence. Experimental results have verified the efficiency of the neighborhood search strategies. The results also indicate that the proposed MWOA-PFLF outperforms the comparison algorithms both in solution quality and convergence rate.},
  archive      = {J_NCA},
  author       = {Zhou, Binghai and Zhao, Zhe},
  doi          = {10.1007/s00521-022-06967-2},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7325-7348},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective optimization of electric vehicle routing problem with battery swap and mixed time windows},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mango leaf disease identification and classification using a
CNN architecture optimized by crossover-based levy flight distribution
algorithm. <em>NCA</em>, <em>34</em>(9), 7311–7324. (<a
href="https://doi.org/10.1007/s00521-021-06726-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mango leaf diseases have a negative impact on mango quality and yield. It is difficult to make an accurate diagnosis of mango leaf disease diagnosis with the naked eye. A lot of computer-aided and machine learning techniques have recently been used by researchers for the classification of mango leaf diseases. However, it has been reported that these approaches have some limitations to their performance which can be attributed to problems due to higher feature dimensionality, overfitting, computational complexity, and lack of feature qualities. To overcome these issues, we proposed a novel framework for mango leaves disease classification. The images were taken from Andhra Pradesh, the largest mango cultivating land in India. The proposed framework is categorized into four stages: data preparation stage, feature selection stage, learning and classification stage, and the performance evaluation stage. We selected 380 images from the categories of healthy and diseased (Mango Anthracnose, Bacterial black spot, and Sooty mold). Different data augmentation techniques are applied to prevent overfitting and improve generalization. Next, a convolutional neural network with crossover-based levy flight distribution is applied for better feature selection. Further, the pre-trained MobileNetV2 model is used for the learning stage and leaves diseases classification is done via support vector machine at the final stage of the MobileNetV2 model. The experimental results demonstrate superior classification performances over other state-of-art methods.},
  archive      = {J_NCA},
  author       = {Prabu, M. and Chelliah, Balika J.},
  doi          = {10.1007/s00521-021-06726-9},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7311-7324},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mango leaf disease identification and classification using a CNN architecture optimized by crossover-based levy flight distribution algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MSL-MNN: Image deraining based on multi-scale lightweight
memristive neural network. <em>NCA</em>, <em>34</em>(9), 7299–7309. (<a
href="https://doi.org/10.1007/s00521-021-06835-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images and videos captured in rainy conditions show visual degradation, resulting in poor performance for outdoor computer vision systems. Traditional deraining methods fail to work in moderate and torrential rain removal, while the data-driven learning-based methods are hindered by removing rain streaks in an efficient manner, and lack consideration applied to edge devices with limited resources. So, this paper proposes a software-hardware co-designed image deraining system named MSL-MNN based on the multi-scale lightweight memristive neural network, which combines deep learning and the nanoscale device memristor. Specifically, a novel feature extraction block ReFiSE based on the lightweight residual mode and squeeze-and-excitation operation is designed. Benefiting from this, MSL-MNN is endowed with a lightweight network framework. Then, the multi-scale skip connection design is introduced to encourage the decoder to use low-level semantic information. Besides, a hardware implementation scheme of MSL-MNN is presented by leveraging the memristor crossbar array, which organically combines the deep learning algorithm with the neuro-inspired computing chip to speed the real-time processing of image data. Finally, a series of experimental results prove the effectiveness and superiority of MSL-MNN in rain removal and the recovery of image details. This study is expected to provide an end-to-end algorithm design and hardware acceleration solution for intelligent image processing besides image deraining.},
  archive      = {J_NCA},
  author       = {Zhang, Lin and Zhou, Yue and Hu, Xiaofang and Sun, Fan and Duan, Shukai},
  doi          = {10.1007/s00521-021-06835-5},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7299-7309},
  shortjournal = {Neural Comput. Appl.},
  title        = {MSL-MNN: Image deraining based on multi-scale lightweight memristive neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). U-net skip-connection architectures for the automated
counting of microplastics. <em>NCA</em>, <em>34</em>(9), 7283–7297. (<a
href="https://doi.org/10.1007/s00521-021-06876-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water pollution is a widespread problem, with lakes, rivers, and oceans contaminated by an increasing amount of microplastics and other pollutants. Microplastic counting from microscope images is a laborious, time-consuming, and error-prone task. The ability of researchers to automate the detection and counting of microplastics would accelerate research and monitoring activities. This paper applies machine learning techniques to automatically segment and count microplastics in a given image, in challenging cluttered conditions. A U-Net neural network was trained to segment microplastics and image post-processing techniques were then applied to count the number of microplastics as well as highlight their position in an image. Different forms of skip connections from the U-Net encoder layers to decoder layers were tested to assess the impact of skip connections on the performance of the U-Net architecture. Our work shows that U-Net can achieve human-level performance in enumerating microplastics in cluttered images and that the standard skip-connection architecture is not necessarily optimal.},
  archive      = {J_NCA},
  author       = {Lee, Ka Shing and Chen, Hui Ling and Ng, Yong Sin and Maul, Tomas and Gibbins, Chris and Ting, Kang-Nee and Amer, Mohammed and Camara, Mateus},
  doi          = {10.1007/s00521-021-06876-w},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7283-7297},
  shortjournal = {Neural Comput. Appl.},
  title        = {U-net skip-connection architectures for the automated counting of microplastics},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive image annotation: Refining labels according to
contents and relations. <em>NCA</em>, <em>34</em>(9), 7271–7282. (<a
href="https://doi.org/10.1007/s00521-021-06866-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image annotation has been an active research in computer vision. Most of the prior research works focus on annotating images with fixed number of labels, while it is unreasonable to annotate all images with the same number of labels and do not take into consideration their contents. In this paper, we present an extensive survey on the recent works about image annotation with label-to-image semantic relevance and propose a general framework for image adaptive annotation. Compared to previous works on image annotation methods, the proposed framework is novel in the following aspects: (1) It predicts label numbers of each image according to its visual features, which is more reasonable and practical for real-world image annotation. (2) It models label-to-image relevance with similar images and related labels, which can generate abundant candidate labels. (3) It can progressively refine the image label sets, which ensures the selected label set to be truly representative and with few redundancies. Experimental results on two benchmark multi-label image annotation datasets demonstrate that the proposed model outperforms the prior state-of-the-art approaches.},
  archive      = {J_NCA},
  author       = {Xiao, Fen and Chen, Yuyu and Zhang, Yiming and Gong, Xue and Gao, Xieping},
  doi          = {10.1007/s00521-021-06866-y},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7271-7282},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive image annotation: Refining labels according to contents and relations},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning approach for insulator instance segmentation
and defect detection. <em>NCA</em>, <em>34</em>(9), 7253–7269. (<a
href="https://doi.org/10.1007/s00521-021-06792-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research regarding the problem of defective insulator recognition on power distribution networks retains an open interest, due to the significant role insulators play to maintain quality service delivery. Most existing methods detect insulators by rectangular bounding box but do not perform segmentation down to instance pixel-level. In this paper, we propose an automated end-to-end framework enabled by attention mechanism to enhance recognition of defective insulators. Using natural industry dataset of images acquired by unmanned aerial vehicle, pixel-level recognition is formulated into two computer vision tasks; object detection and instance segmentation. We increase the capabilities of our chosen model by leveraging a light-weight but effective three-branch attention structure integrated into the backbone network as an add-on module. Specifically, we exploit cross-dimensional interactions to build an efficient computation of attention weights across channels of the backbone network to achieve gains in detection performance for defective insulators up to about + 2.0 points compared to our base model, at negligible overhead cost. Our proposed model reaches comparable levels with a more recent state of the art instance mask prediction model.},
  archive      = {J_NCA},
  author       = {Antwi-Bekoe, Eldad and Liu, Guisong and Ainam, Jean-Paul and Sun, Guolin and Xie, Xiurui},
  doi          = {10.1007/s00521-021-06792-z},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7253-7269},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning approach for insulator instance segmentation and defect detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). An adaptive multi-sensor visual attention model.
<em>NCA</em>, <em>34</em>(9), 7241–7252. (<a
href="https://doi.org/10.1007/s00521-021-06857-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emerging recurrent visual attention models mostly utilize a sensor to continuously capture features from the input, which requires a suited design for the sensor. Researchers usually need a number of attempts to determine optimal structures for the sensor and corresponding modules. In this work, an adaptive multi-sensor visual attention model (AM-MA) is proposed to enhance the recurrent visual attention model. The proposed model uses several sensors to observe the original input recurrently, while the number of sensors can be added adaptively. Each sensor generates a hidden state and is followed by a location network to provide the deployment scheme. We design a self-evaluation mechanism for AM-MA, by which it can decide whether to add new sensors during training. Besides, the proposed AM-MA leverages a fine-tune mechanism to avoid a lengthy training process. AM-MA is a parameter-insensitive model. That is, there is no need for researchers to pre-train the model for finding the optimal structure in the case of unknown complexity. Experimental results show that the proposed AM-MA not only outperforms the renowned sensor-based attention model on image classification tasks, but also achieves satisfactory results when given an inappropriate structure.},
  archive      = {J_NCA},
  author       = {Chen, Wenbai and Li, Jingchen and Shi, Haobin and Hwang, Kao-Shing},
  doi          = {10.1007/s00521-021-06857-z},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7241-7252},
  shortjournal = {Neural Comput. Appl.},
  title        = {An adaptive multi-sensor visual attention model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed localization for IoT with multi-agent
reinforcement learning. <em>NCA</em>, <em>34</em>(9), 7227–7240. (<a
href="https://doi.org/10.1007/s00521-021-06855-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localization has become one of the important techniques for Internet of Things (IoT). However, most existing localization methods need a central controller and operate on an off-line manner, which cannot satisfy the requirements of real-time IoT applications. In order to address this issue, a novel distributed localization scheme based on multi-agent reinforcement learning (MARL) is proposed. The localization problem is first reformulated as a stochastic game for maximizing the sum of the negative localization error. Each non-anchor node is then modeled as an intelligent agent, where its action space corresponds to possible locations. After that, we invoke a MARL framework on the basis of conventional Q-learning framework to learn the optimal policy, and to maximize the long-term expected reward. The novel strategy is also proposed to reduce the localization error. Extensive simulations demonstrate that the proposed localization method is superior to game theoretic-based distributed localization algorithm and virtual force-based distributed localization algorithm in terms of both localization accuracy and convergence speed, and is suitable for on-line localization scenarios.},
  archive      = {J_NCA},
  author       = {Jia, Jie and Yu, Ruoying and Du, Zhenjun and Chen, Jian and Wang, Qinghu and Wang, Xingwei},
  doi          = {10.1007/s00521-021-06855-1},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7227-7240},
  shortjournal = {Neural Comput. Appl.},
  title        = {Distributed localization for IoT with multi-agent reinforcement learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generative adversarial network with hybrid attention and
compromised normalization for multi-scene image conversion.
<em>NCA</em>, <em>34</em>(9), 7209–7225. (<a
href="https://doi.org/10.1007/s00521-021-06841-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to generate high-quality realistic images, this paper proposes an image conversion algorithm based on hybrid attention generation adversarial network. This network is composed of the generator and discriminator, both of which are jointly trained through the loss function. The generator is constructed by using a three-stage structure of down-sampling, residual and up-sampling blocks where the residual block uses a hybrid attention mechanism. The compromised instance and layer normalization is also proposed by weighting the output of the fully connected layer.  The multi-scale PatchGAN is introduced as the discriminator. The proposed network can produce more realistic images using a new loss function, which comprises four iterms: generation adversarial loss, $$L_1$$ regularization loss, VGG loss and feature matching loss. The experimental results demonstrated that the proposed method can produce more realistic and detailed images than the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Xiao, Jinsheng and Zhang, Shuhao and Yao, Yuntao and Wang, Zhongyuan and Zhang, Yongqin and Wang, Yuan-Fang},
  doi          = {10.1007/s00521-021-06841-7},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7209-7225},
  shortjournal = {Neural Comput. Appl.},
  title        = {Generative adversarial network with hybrid attention and compromised normalization for multi-scene image conversion},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient tumor volume measurement and segmentation approach
for CT image based on twin support vector machines. <em>NCA</em>,
<em>34</em>(9), 7199–7207. (<a
href="https://doi.org/10.1007/s00521-021-06769-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suspicious volumetric tumor (SVT) segmentation of a CT-image (CT $$_{i}$$ ) and analysing changes in the volume of tumor is a significantly challenging task for the identification of lung cancer. In this regard, we design a two-step suspicious volumetric tumor segmentation (SVTS) approach based on an adaptive multiple resolution contour (AMRC) models for effective SVT segmentation. First, the high-intensity-pixels edge centroid of SVT (HECS) method is designed to identify the SVT location in CT $$_{i}$$ , and these outcomes are subsequently conceding threshold values to fix the level set method (LSM). Second, HECS outcomes are recognised using particle swarm optimisation (PSO) which is harmonised twin support vector machines (TSVM) to achieve segmentation accuracy. An open-source tumor cancer imaging archive (TCIA) dataset, 529 abnormal tissues (ATs) of the lung from the lung image database consortium (LIDC), are conceded to assess the performance of the SVT segmentation approach. The average segmentation accuracy of NLTC, TCIA, and LIDC datasets are 73.19\%, 76.21\% and 75.89\%, respectively, compared with standard benchmark approaches. Subsequently, our framework efficiently classified the normal and abnormal CT $$_{i}$$ based on the SVT segmentation accuracy rate.},
  archive      = {J_NCA},
  author       = {Sathish, K. and Narayana, Y. V. and Mekala, M. S. and Rizwan, Patan and Kallam, Suresh},
  doi          = {10.1007/s00521-021-06769-y},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7199-7207},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient tumor volume measurement and segmentation approach for CT image based on twin support vector machines},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid cooperative differential evolution assisted by
CMA-ES with local search mechanism. <em>NCA</em>, <em>34</em>(9),
7173–7197. (<a
href="https://doi.org/10.1007/s00521-021-06849-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a hybrid cooperative differential evolution with the perturbation of the Covariance Matrix Adaptation Evolutionary Strategy (CMA-ES) with the local search of Limited-Memory Broyden–Fletcher–Goldfarb–Shanno (LBFGS) mechanism, named jSO_CMA-ES_LBFGS, is proposed to solve the complex continuous problems. In the proposed algorithm, jSO, as a variant of Differential Evolution (DE), is used as a global search operator to explore the entire solution space. When the population falls into stagnation, a relatively reliable initial solution for the local search operator is generated by the CMA-ES, which is activated to perturb the optimal candidates in the solution space. The LBFGS utilized as the local search strategy is embedded in CMA-ES to obtain the potential local optimal solutions. A cooperative co-evolutionary dynamic system is formed by jSO and CMA-ES with a local search operator. The proposed jSO_CMA-ES_LBFGS is tested on the CEC2017 benchmark test suite and compared with eleven state-of-the-art algorithms. Further, two practical engineering problems are investigated utilizing the proposed method. The experimental results reveal the effectiveness and efficiency of the jSO_CMA-ES_LBFGS.},
  archive      = {J_NCA},
  author       = {Zhao, Fuqing and Bao, Haizhu and Wang, Ling and He, Xuan and Jonrinaldi},
  doi          = {10.1007/s00521-021-06849-z},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7173-7197},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid cooperative differential evolution assisted by CMA-ES with local search mechanism},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time kinematic analysis of beam pumping unit: A deep
learning approach. <em>NCA</em>, <em>34</em>(9), 7157–7171. (<a
href="https://doi.org/10.1007/s00521-021-06783-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A kinematics analysis model for the beam pumping unit (BPU) based on deep learning is proposed in this study. It takes the real-time BPU video stream as the input, and outputs the sequence of kinematic parameters. The model is composed of two parts. The first is the motion detection model based on modified Yolov4, which can output the components classes and positions of the targeted BPU in the input video. Experimental results on the test dataset reveal that the average precision of the modified model is superior to original Yolov4 and other methods. The second part is the BPU kinematics analysis model based on motion detection, which can analyze and output the kinematics parameters of BPU in real time according to the input motion detection results. Finally, we deployed this model on mobile inspection robot and run in oilfield. The experiment results show that the approach proposed in this study can help achieve accurate kinematics analysis on targeted BPU in real time. In general, this research provides a novel approach for BPU kinematics analysis, which is a very important part of the intelligent oilfield construction.},
  archive      = {J_NCA},
  author       = {Sun, Junjiao and Huang, Zhiqing and Zhu, Yue and Zhang, Yanxin},
  doi          = {10.1007/s00521-021-06783-0},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7157-7171},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time kinematic analysis of beam pumping unit: A deep learning approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Collocation polynomial neural forms and domain
fragmentation for solving initial value problems. <em>NCA</em>,
<em>34</em>(9), 7141–7156. (<a
href="https://doi.org/10.1007/s00521-021-06860-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several neural network approaches for solving differential equations employ trial solutions with a feedforward neural network. There are different means to incorporate the trial solution in the construction, for instance, one may include them directly in the cost function. Used within the corresponding neural network, the trial solutions define the so-called neural form. Such neural forms represent general, flexible tools by which one may solve various differential equations. In this article, we consider time-dependent initial value problems, which require to set up the neural form framework adequately. The neural forms presented up to now in the literature for such a setting can be considered as first-order polynomials. In this work, we propose to extend the polynomial order of the neural forms. The novel collocation-type construction includes several feedforward neural networks, one for each order. Additionally, we propose the fragmentation of the computational domain into subdomains. The neural forms are solved on each subdomain, whereas the interfacing grid points overlap in order to provide initial values over the whole fragmentation. We illustrate in experiments that the combination of collocation neural forms of higher order and the domain fragmentation allows to solve initial value problems over large domains with high accuracy and reliability.},
  archive      = {J_NCA},
  author       = {Schneidereit, Toni and Breuß, Michael},
  doi          = {10.1007/s00521-021-06860-4},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7141-7156},
  shortjournal = {Neural Comput. Appl.},
  title        = {Collocation polynomial neural forms and domain fragmentation for solving initial value problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic portfolio rebalancing through reinforcement
learning. <em>NCA</em>, <em>34</em>(9), 7125–7139. (<a
href="https://doi.org/10.1007/s00521-021-06853-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio managements in financial markets involve risk management strategies and opportunistic responses to individual trading behaviours. Optimal portfolios constructed aim to have a minimal risk with highest accompanying investment returns, regardless of market conditions. This paper focuses on providing an alternative view in maximising portfolio returns using Reinforcement Learning (RL) by considering dynamic risks appropriate to market conditions through dynamic portfolio rebalancing. The proposed algorithm is able to improve portfolio management by introducing the dynamic rebalancing of portfolios with vigorous risk through an RL agent. This is done while accounting for market conditions, asset diversifications, risk and returns in the global financial market. Studies have been performed in this paper to explore four types of methods with variations in fully portfolio rebalancing and gradual portfolio rebalancing, which combine with and without the use of the Long Short-Term Memory (LSTM) model to predict stock prices for adjusting the technical indicator centring. Performances of the four methods have been evaluated and compared using three constructed financial portfolios, including one portfolio with global market index assets with different risk levels, and two portfolios with uncorrelated stock assets from different sectors and risk levels. Observed from the experiment results, the proposed RL agent for gradual portfolio rebalancing with the LSTM model on price prediction outperforms the other three methods, as well as returns of individual assets in these three portfolios. The improvements of the returns using the RL agent for gradual rebalancing with prediction model are achieved at about 27.9–93.4\% over those of the full rebalancing without prediction model. It has demonstrated the ability to dynamically adjust portfolio compositions according to the market trends, risks and returns of the global indices and stock assets.},
  archive      = {J_NCA},
  author       = {Lim, Qing Yang Eddy and Cao, Qi and Quek, Chai},
  doi          = {10.1007/s00521-021-06853-3},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7125-7139},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic portfolio rebalancing through reinforcement learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PConv: Simple yet effective convolutional layer for
generative adversarial network. <em>NCA</em>, <em>34</em>(9), 7113–7124.
(<a href="https://doi.org/10.1007/s00521-021-06846-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel convolutional layer, called perturbed convolution (PConv), which performs not only a convolution operation but also a dropout one. The PConv focuses on achieving two goals simultaneously: improving the generative adversarial network (GAN) performance and alleviating the memorization problem in which the discriminator memorizes all images from a given dataset as training progresses. In PConv, perturbed features are generated by randomly disturbing an input tensor before performing the convolution operation. This approach is simple but surprisingly effective. First, to produce a similar output even with the perturbed tensor, each layer in the discriminator should learn robust features having a small local Lipschitz value. Second, since the input tensor is randomly perturbed during the training procedure like the dropout in neural networks, the memorization problem could be alleviated. To show the generalization ability of the proposed method, we conducted extensive experiments with various loss functions and datasets including CIFAR-10, CelebA, CelebA-HQ, LSUN, and tiny-ImageNet. The quantitative evaluations demonstrate that PConv effectively boosts the performance of GAN and conditional GAN in terms of Frechet inception distance (FID).},
  archive      = {J_NCA},
  author       = {Park, Seung and Yeo, Yoon-Jae and Shin, Yong-Goo},
  doi          = {10.1007/s00521-021-06846-2},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7113-7124},
  shortjournal = {Neural Comput. Appl.},
  title        = {PConv: Simple yet effective convolutional layer for generative adversarial network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fractional-order momentum optimization approach of deep
neural networks. <em>NCA</em>, <em>34</em>(9), 7091–7111. (<a
href="https://doi.org/10.1007/s00521-021-06765-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of universal and high-efficiency optimization algorithms is a very important research direction of neural networks. Stochastic Gradient Decent Momentum(SGDM) is one of the most successful optimization algorithms, and easily fall into local extremes minimum. Inspired by the prominent success of Fractional-order Calculus in automatic control, we proposed a method based on Fractional-Order named Fractional-Order Momentum(FracM). As a natural extension of integral calculus, fractional order calculus inherits almost all the characteristics of integral calculus, and have some memorization and nonlocality. FracM performs fractional-order difference of momentum and gradient in SGDM algorithm. FracM can partially solve the problem of traps in the local minimum point and accelerated the train process. The proposed FracM optimization method can compare with the most advanced SGDM and Adam and other advanced optimization algorithm in terms of classification accuracy. The experiments show that FracM outperforms other optimizers on CIFAR10/100 and textual datasets IMDB with transformer-based models.},
  archive      = {J_NCA},
  author       = {Yu, ZhongLiang and Sun, Guanghui and Lv, Jianfeng},
  doi          = {10.1007/s00521-021-06765-2},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7091-7111},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fractional-order momentum optimization approach of deep neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incremental deep learning for reflectivity data recognition
in stomatology. <em>NCA</em>, <em>34</em>(9), 7081–7089. (<a
href="https://doi.org/10.1007/s00521-021-06842-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recognition of stomatological disorders and the classification of dental caries are important areas of biomedicine that can hugely benefit from machine learning tools for the construction of relevant mathematical models. This paper explores the possibility of using reflectivity data to distinguish between healthy tissues and caries by deep learning and multilayer convolutional neural networks. The experimental data set includes more than 700 observations recorded in the stomatology laboratory. For rigor, the results obtained from the deep learning systems are compared with those evaluated for selected sets of features estimated for each observation and classified by a decision tree, support vector machine (SVM), k-nearest neighbor, Bayesian methods, and two-layer neural networks. The classification accuracy obtained for the deep learning systems was 98.1\% and 94.4\% for data in the signal and spectral domains, respectively, in comparison with an accuracy of 97.2\% and 87.2\% evaluated by the SVM method. The proposed method conclusively demonstrates how the artificial intelligence and deep learning methodology can contribute to improved diagnosis of dental problem in stomatology.},
  archive      = {J_NCA},
  author       = {Procházka, Aleš and Charvát, Jindřich and Vyšata, Oldřich and Mandic, Danilo},
  doi          = {10.1007/s00521-021-06842-6},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7081-7089},
  shortjournal = {Neural Comput. Appl.},
  title        = {Incremental deep learning for reflectivity data recognition in stomatology},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid intelligence modeling for estimating shear strength
of FRP reinforced concrete members. <em>NCA</em>, <em>34</em>(9),
7069–7079. (<a
href="https://doi.org/10.1007/s00521-021-06791-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The corrosion problem in the conventional steel reinforcement in concrete structures has diverted the researchers to explore alternative materials. As a substitute to replace the traditional steel bars in reinforced concrete structures, innovative reinforcement such as fiber reinforced polymer (FRP) rebars has been suggested. Consequently, different codes and guidelines have been proposed for forecasting the shear strength of FRP reinforced members using traditional empirical methods and neural networks. The current paper concentrates on the development of a hybrid intelligence model, namely an artificial neural network articulated with a Bayesian optimization algorithm (ANN-BOA) for estimating the shear strength of these types of members without stirrups. Totally, 216 specimens, collected from the literature, were used in this analysis. The input parameters of the model were beam depth, the ratio of shear span and depth, effective reinforcement ratio, and concrete strength. The ANN hyperparameters (viz. neuron numbers in the hidden layer, learning rate) have been tuned automatically to get the best predictions. The estimated shear strengths are compared with the recent design provisions of Japan (JSCE), UK (BISE), Italy (CNR-DT 203), Canada (CHBDC, CSA S806), and the USA (ACI 440.1R). The results were also compared with a similar ANN model. It was observed that the predicted results using the proposed method are better than those of the other methods in terms of some statistical as well as performance measuring parameters with a maximum Pearson correlation coefficient (R) value of 0.97. These values are higher than the other investigated methods.},
  archive      = {J_NCA},
  author       = {Alam, Md. Shah and Sultana, N. and Hossain, S. M. Zakir and Islam, Mohammad S.},
  doi          = {10.1007/s00521-021-06791-0},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7069-7079},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid intelligence modeling for estimating shear strength of FRP reinforced concrete members},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Swarm-based optimally selected histogram computation system
for image enhancement. <em>NCA</em>, <em>34</em>(9), 7053–7067. (<a
href="https://doi.org/10.1007/s00521-021-06858-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, two newly proposed evolutionary computational algorithms (ECAs) are joined with Otsu thresholding method to achieve brightness preserving image contrast enhancement. The selected ECAs are the whale optimization algorithm (WOA) and the crow search algorithm (CSA) which embrace more contrast and minimum entropy alteration corresponding to the original image. The proposed algorithm employs histogram equalization method, based on an improved cumulative distribution to calculate a mapping function. Therefore, a 3-stage procedure has been assumed to change the original histogram. The primary step of the proposed method is to sub-divide the image histogram by using the Otsu thresholding technique. Further, both of histograms are weighted and thresholded in order to control the level of enhancement. The constraint parameters are attained by WOA and CSA algorithms for modification. After constraining the histograms, mean shift modification is executed to slight altering the position of mean shifting from input to output image. The results reflect that proposed technique accomplishes balanced contrast enhancement and better color preservation in comparison with surviving techniques. Through the proposed technique, the enhanced images achieve low contrast boosting, a good trade-off between detail improvement, and brightness conservation with naturalness of the input image.},
  archive      = {J_NCA},
  author       = {Bhandari, Ashish Kumar and Singh, Neha and Singh, Anurag},
  doi          = {10.1007/s00521-021-06858-y},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7053-7067},
  shortjournal = {Neural Comput. Appl.},
  title        = {Swarm-based optimally selected histogram computation system for image enhancement},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TSK fuzzy echo state neural network: A hybrid structure for
black-box nonlinear systems identification. <em>NCA</em>,
<em>34</em>(9), 7033–7051. (<a
href="https://doi.org/10.1007/s00521-021-06838-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the black-box nonlinear system identification approaches have become effective methods to model complex systems. By the idea of combining the merits of reservoir computing (RC) of the Echo state network (ESN) and fuzzy inference system, a TSK fuzzy ESN for the black-box identification is proposed in this paper. The proposed network is constructed on the basis of the framework of ESN containing multiple sub-reservoirs in which each sub-reservoir is contributed with a TSK fuzzy rule. Through this hybrid structure, first, a modified structure of ESN with less complexity is provided to give an effective black-box identification method for uncertain nonlinear systems. Second, the fuzzy clustering of the training data of an application is used to define the number of sub-reservoirs; then, the singular value decomposition (SVD) is applied to randomly initialize the weight matrix of each sub-reservoir. Third, according to the characteristic of ESN, only the output weights of the sub-reservoirs are learned by the recursive least squares (RLS) algorithm without adjusting the other parameters of the network including the centers and widths of the fuzzy basis function of the TSK fuzzy inference system. Moreover, the convergence of the parameter learning based on RLS is investigated. To demonstrate the performance of the proposed TSK fuzzy ESN in the identification of nonlinear systems, three numerical simulations are given. The simulation results also involve a comparison with other structures of ESN and fuzzy neural networks to confirm the effectiveness of the proposed TSK fuzzy ESN.},
  archive      = {J_NCA},
  author       = {Mahmoud, Tarek A. and Elshenawy, Lamiaa M.},
  doi          = {10.1007/s00521-021-06838-2},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7033-7051},
  shortjournal = {Neural Comput. Appl.},
  title        = {TSK fuzzy echo state neural network: A hybrid structure for black-box nonlinear systems identification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial neural network-based optimization of operating
parameters for minimum quantity lubrication-assisted burnishing process
in terms of surface characteristics. <em>NCA</em>, <em>34</em>(9),
7005–7031. (<a
href="https://doi.org/10.1007/s00521-021-06834-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Roller burnishing is an alternative approach to enhance surface properties under plastic deformation and most investigations focused on optimizing process parameters. However, the impacts of operating parameters of the minimum quantity lubrication (MQL) system on the surface properties have not been considered. The roller burnishing process is widely applied to fabricate high-pressure bushings and crankshafts with superior quality, while the MQL system is extensively employed to facilitate different machining operations for saving lubricant usage, decreasing negative impacts on the environment, and protecting worker’s health. The purpose of this investigation is to select the optimal  MQL system factors, including the nozzle diameter (D), impingement angle (I), flow rate (Q), and air pressure (P) for decreasing the maximum profile peak height of the roughness (MAR) and improving Vickers hardness (VH) for the roller burnishing process. The optimal artificial neural network (ANN) model was proposed to render the relations between the optimizing inputs and burnishing responses. An efficiently evolutionary technique entitled multi-objective glowworm swarm optimization (MOGSO) was utilized to produce a set of feasible solutions. The VIKOR method was employed to determine the best optimal solution. The results revealed that the 4–10–2 architecture of the developed ANN models efficiently described the burnishing performances and precisely predicted the response values. The optimal outcomes of the D, I, Q, and P were 1.5 mm, 45 deg., 130 ml/h, and 0.6 MPa, while the improvements in the MAR and VH were 17.0\% and 14.0\%, respectively, as compared to the common values used. The proposed approach comprising the ANN, MOGSO, and VIKOR could be considered as a powerful technique to deal with the complicated optimizing issue for the roller burnishing operation. The obtained finding could be expected as a significant contribution to enhancement in the machining quality for the roller burnishing process under the MQL condition.},
  archive      = {J_NCA},
  author       = {Nguyen, Trung-Thanh and Nguyen, Truong-An and Trinh, Quang-Hung and Le, Xuan-Ba and Pham, Long-Hai and Le, Xuan-Hung},
  doi          = {10.1007/s00521-021-06834-6},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7005-7031},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial neural network-based optimization of operating parameters for minimum quantity lubrication-assisted burnishing process in terms of surface characteristics},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep neural network-based collaborative filtering using a
matrix factorization with a twofold regularization. <em>NCA</em>,
<em>34</em>(9), 6991–7003. (<a
href="https://doi.org/10.1007/s00521-021-06831-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the ever-growing contents (movies, clothes, books, etc.) accessible and buyable via the Internet have led to the information overload issue and therefore the item targeting problem. Indeed, the huge mass of contents complexifies the identification of items fitting users’ expectations. As powerful filtering tools, recommender systems efficiently alleviate the item targeting issue. Collaborative filtering-based methods are among the most influential algorithms adopted in recommender systems. Among collaborative filtering-based methods, model-based approaches are widely used in recent powerful recommendation methods. Due to its efficiency, the matrix factorization technique is spreadly employed in model-based approaches. However, those methods badly deal with issues such as data sparseness and cold-start problems that severely affect the recommendation quality. To overcome these limitations shown by state-of-the-art methods, we propose in this paper a recommender approach that couples the effectiveness of an enhanced matrix factorization technique to the power of a deep neural network model. In the first step, the user’s latent factors and item latent factors are extracted from a doubly-regularized matrix factorization process. Thereafter, those latent factors are used to feed a deep learning structure in a forward-propagation process, and a normalized cross-entropy method is used to increase the precision of the deep neural network through a backpropagation process. The end prediction is made by combining results from the matrix factorization step and the deep neural structure. Extensive experiments are conducted on real-world datasets and show that our proposal outperforms other methods in terms of prediction accuracy and recommendation quality.},
  archive      = {J_NCA},
  author       = {Noulapeu Ngaffo, Armielle and Choukair, Zièd},
  doi          = {10.1007/s00521-021-06831-9},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6991-7003},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep neural network-based collaborative filtering using a matrix factorization with a twofold regularization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of urban functional zones through deep
learning. <em>NCA</em>, <em>34</em>(9), 6973–6990. (<a
href="https://doi.org/10.1007/s00521-021-06822-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, artificial neural networks (ANN) are models widely used in many areas; one of these is the classification of urban areas. This work aims to discuss a new framework for the delimitation of functional zones for the city of Naples through deep learning algorithms. More in detail, firstly, a segmentation approach is used to generate the urban zones from the satellite RGB image of interest; then, starting from an extrapolated OSM data, we develop a new labelled dataset used for the training of a convolutional neural network model. Finally, the urban zones are classified with a majority vote procedure. The innovative aspect of this methodology is the use of data provided for different purposes (that is, labelled OSM data) to compensate for the lack of data provided by experts in the field. For the experimentation, we compare two segmentation algorithms (FNEA and selective search) and three CNN models (AlexNet, ResNet-50 and a regularized version of AlexNet), providing good performances in the functional zone classification.},
  archive      = {J_NCA},
  author       = {Izzo, Stefano and Prezioso, Edoardo and Giampaolo, Fabio and Mele, Valeria and Di Somma, Vittorio and Mei, Gang},
  doi          = {10.1007/s00521-021-06822-w},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6973-6990},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of urban functional zones through deep learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A cost-sensitive active learning algorithm: Toward
imbalanced time series forecasting. <em>NCA</em>, <em>34</em>(9),
6953–6972. (<a
href="https://doi.org/10.1007/s00521-021-06837-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many outstanding techniques for Time series forecasting (TSF) have been proposed. These techniques depend on necessary and sufficient data samples, which is the key to train a good predictor. Thus, an Active learning (AL) algorithmic framework based on Support vector regression (SVR) is designed for TSF, with the goal to choose the most valuable samples and reduce the complexity of the training set. To evaluate the quality of samples comprehensively, multiple essential criteria, such as informativeness, representativeness and diversity, are considered in a two clustering-based consecutive stages procedure. In addition, considering the imbalance of time series data, a range of values might be seriously under-represented but extremely important to the user. Thus, it is unreasonable to assign the same prediction cost to each sample. To address this imbalance problem, a multiple criteria cost-sensitive active learning algorithm in the virtue of weight SVR architecture, abbreviated as MAW-SVR, ad hoc for imbalanced TSF, is proposed. By introducing the cost-sensitive scheme, each sample is endowed with a penalty weight, which can be dynamically updated in the AL procedure. The experimental comparisons between MAW-SVR and the other six AL algorithms on a total of thirty time series datasets verify the effectiveness of the proposed algorithm.},
  archive      = {J_NCA},
  author       = {Zhang, Jing and Dai, Qun},
  doi          = {10.1007/s00521-021-06837-3},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6953-6972},
  shortjournal = {Neural Comput. Appl.},
  title        = {A cost-sensitive active learning algorithm: Toward imbalanced time series forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A generic and lightweight security mechanism for detecting
malicious behavior in the uncertain internet of things using fuzzy
logic- and fog-based approach. <em>NCA</em>, <em>34</em>(9), 6927–6952.
(<a href="https://doi.org/10.1007/s00521-021-06823-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the massive surge of interest in the Internet of Things (IoT), this work focuses on the kinetics of its security. By automating everything, starting from baby monitors to life-saving medical devices, IoT brought convenience to people’s lives and rapidly became a trillion-dollar industry. However, the future of IoT will be decided on how its security and privacy concerns are dealt with. It is a fact that at present, the security of IoT is lacking in coherent and logical perspectives. For example, the researchers do not adequately accommodate the uncertainty and insider attacks while developing the IoT security procedures, even though most security concerns related to IoT arise from an insider and uncertain habitat. This paper provides a critical analysis of the most recent and relevant state-of-art methods of IoT security and identifies the parameters that are crucial for any security posture in IoT. Considering all the intricate details of IoT environments, this work proposes a Generic and Lightweight Security mechanism for detecting malicious behavior in the uncertain IoT using a Fuzzy Logic- and Fog-based approach (GLSF2IoT). It is developed on the principle of “zero trust,” i.e., trust nothing and treat everything as hostile. While Fuzzy Logic has been used to remove uncertainties, the Fog-IoT architecture makes GLSF2IoT inherently better than the cloud-IoT. Once the malicious activity is detected, GLSF2IoT automatically limits the network access against the IoT device that initiated this activity, preventing it from targeting other devices. We evaluated GLSF2IoT for blackhole, selective forward, collusion and DDoS attacks, i.e., attacks which can invalidate any IoT architecture. Besides yielding better accuracy results than the existing benchmarks, we found that GLSF2IoT puts extremely low pressure on the constrained nodes, is scalable, supports heterogeneity, and uncertainty of the IoT environments.},
  archive      = {J_NCA},
  author       = {Zahra, Syed Rameem and Chishti, Mohammad Ahsan},
  doi          = {10.1007/s00521-021-06823-9},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6927-6952},
  shortjournal = {Neural Comput. Appl.},
  title        = {A generic and lightweight security mechanism for detecting malicious behavior in the uncertain internet of things using fuzzy logic- and fog-based approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Mathematical formulation and two-phase optimisation
methodology for the constrained double-row layout problem. <em>NCA</em>,
<em>34</em>(9), 6907–6926. (<a
href="https://doi.org/10.1007/s00521-021-06817-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The double-row layout problem (DRLP) was previously investigated as an unconstrained optimisation problem without enforcing any limits on the arrangement of the machines. However, in reality, a DRLP is required to respect certain facility constraints imposed on the arrangement of its machines. To address these limits in the scientific literature, we originally proposed a constrained DRLP (cDRLP). A mixed-integer linear programming model with three types of constraints: positioning, ordering, and relation, is constructed for the cDRLP. We decompose the cDRLP into two subproblems: a combinatorial optimisation problem and a continuous optimization problem. To further deal with larger instances, a two-phase methodology is designed to solve the cDRLP. In our algorithm, the differential evolution with a novel discrete framework is applied to seek local and global feasible solutions. Finally, a series of benchmark instances obtained from the literature are added to meet the constraint requirements of our developed cDRLP, and these 40 test instances with different sizes (n = 9 ~ 42) are employed to assess the performance of our proposed methodology. The results of computational experiments tested clearly demonstrate that our proposed two-phase optimisation methodology is effective for handling the problem considered and also help in producing good quality solutions.},
  archive      = {J_NCA},
  author       = {Liu, Silu and Zhang, Zeqiang and Guan, Chao and Liu, Junqi and Gong, Juhua and Dewil, Reginald},
  doi          = {10.1007/s00521-021-06817-7},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6907-6926},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mathematical formulation and two-phase optimisation methodology for the constrained double-row layout problem},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inverse design of self-oscillatory gels through deep
learning. <em>NCA</em>, <em>34</em>(9), 6879–6905. (<a
href="https://doi.org/10.1007/s00521-021-06788-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a deep learning architecture for inverse design of a self-oscillating sheet propelled by an embedded chemical reaction. The dynamics of our problems are nonlinear and exhibit chaotic behavior, a challenging setting for existing deep-learning-based inverse design approaches. The aim is to explore data-driven design of soft robots using a novel locomotion mechanism. We train the architecture using a forward model of the locomotion mechanism developed recently by Alben et al. (J Comput Phys 399:108952, 2019). The architecture is shown to successfully map a snapshot of target motions of the gel into geometric and reaction parameters. The final architecture consists of a multi-layer perceptron (MLP) classifier for discrete parameters, followed by a stacked MLP regressor (SMLPR) for continuous parameters. Our inverse design setting is unique in that it considers both discrete and continuous outputs, requiring an architecture capable of classification and regression. We are able to recover parameters within 2.87\% accuracy. We also compare the simulated motion of the sheets at the recovered parameters. Because the motion has a chaotic quality, our demonstration is able to show quantitative agreement for a small time horizon and qualitative agreement over longer time horizons. We also demonstrate agreement of Lyapunov exponents up to 6.78\% accuracy for suitable motions.},
  archive      = {J_NCA},
  author       = {Aksoy, Doruk and Alben, Silas and Deegan, Robert D. and Gorodetsky, Alex A.},
  doi          = {10.1007/s00521-021-06788-9},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6879-6905},
  shortjournal = {Neural Comput. Appl.},
  title        = {Inverse design of self-oscillatory gels through deep learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). InstaIndoor and multi-modal deep learning for indoor scene
recognition. <em>NCA</em>, <em>34</em>(9), 6861–6877. (<a
href="https://doi.org/10.1007/s00521-021-06781-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indoor scene recognition is a growing field with great potential for behaviour understanding, robot localization, and elderly monitoring, among others. In this study, we approach the task of scene recognition from a novel standpoint, using multi-modal learning and video data gathered from social media. The accessibility and variety of social media videos can provide realistic data for modern scene recognition techniques and applications. We propose a model based on fusion of transcribed speech to text and visual features, which is used for classification on a novel dataset of social media videos of indoor scenes named InstaIndoor. Our model achieves up to 70\% accuracy and 0.7 F1-Score. Furthermore, we highlight the potential of our approach by benchmarking on a YouTube-8M subset of indoor scenes as well, where it achieves 74\% accuracy and 0.74 F1-Score. We hope the contributions of this work pave the way to novel research in the challenging field of indoor scene recognition.},
  archive      = {J_NCA},
  author       = {Glavan, Andreea and Talavera, Estefanía},
  doi          = {10.1007/s00521-021-06781-2},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6861-6877},
  shortjournal = {Neural Comput. Appl.},
  title        = {InstaIndoor and multi-modal deep learning for indoor scene recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incremental learning paradigm with privileged information
for random vector functional-link networks: IRVFL+. <em>NCA</em>,
<em>34</em>(9), 6847–6859. (<a
href="https://doi.org/10.1007/s00521-021-06793-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning using privileged information (LUPI) paradigm, which pioneered teacher–student interaction mechanism, makes the learning models use additional information in the training stage. This paper is the first to propose an incremental learning algorithm with LUPI paradigm for random vector functional-link (RVFL) networks, named IRVFL+ . This novel algorithm can leverage privileged information into incremental RVFL (IRVFL) networks in the training stage, which provides a new constructive method to train IRVFL networks. In order to solve two scenarios that require fast speed of modeling but low-accuracy requirements and high accuracy but slow speed of modeling requirements, two algorithmic implementations of IRVFL+ , respectively, based on local update and global update strategies are presented for data classification and regression problems in this paper. Specifically, the first algorithm, named IRVFL-I+ , calculates the output weights of the newly added hidden nodes, while the input and output parameters of all the existing hidden nodes are fixed. In contrast to IRVFL-I+ , the second one named IRVFL-II + can update all the parameters of all the existing hidden nodes and newly added hidden nodes. Moreover, the convergences of two implementations have been studied in this paper. Finally, experimental results indicate that IRVFL+ indeed performs favorably.},
  archive      = {J_NCA},
  author       = {Dai, Wei and Ao, Yanshuang and Zhou, Linna and Zhou, Ping and Wang, Xuesong},
  doi          = {10.1007/s00521-021-06793-y},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6847-6859},
  shortjournal = {Neural Comput. Appl.},
  title        = {Incremental learning paradigm with privileged information for random vector functional-link networks: IRVFL+},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-markovian switching-based strategy for solving the
stochastic point location problem. <em>NCA</em>, <em>34</em>(9),
6825–6846. (<a
href="https://doi.org/10.1007/s00521-022-06894-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic Point Location problem considering that a learning entity (i.e. mechanisms, algorithm, etc) attempts to locate a certain point by interaction with a stochastic environment is encountered widely in Machine Learning. A conventional technique is to sample the search space into discrete points and perform a random walk. Nevertheless, the random walk is confined to the neighboring point. In this paper, an extended version of the random walk-based triple level algorithm is introduced to overcome the aforementioned defect. Specifically, the proposed algorithm exploits the multi-Markovian switching to generalize the random walk concerning adjacent nodes to intermittent nodes. Hence, the whole approach could be regarded as the Markov chain, and its transform matrix could be constructed, followed by a rigorous mathematical pf procedure of the convergence. The experimental results demonstrate the effectiveness and efficiency of the proposed algorithm, showing its abilities of stronger stability, a higher precision, and a faster speed in comparison with the counterparts available in open literatures.},
  archive      = {J_NCA},
  author       = {Guo, Ying and Li, Shenghong},
  doi          = {10.1007/s00521-022-06894-2},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6825-6846},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-markovian switching-based strategy for solving the stochastic point location problem},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel reduced parameter s-model of estimator learning
automata in the switching non-stationary environment. <em>NCA</em>,
<em>34</em>(9), 6811–6824. (<a
href="https://doi.org/10.1007/s00521-021-06777-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning automata (LA), a powerful tool for reinforcement learning in the field of machine learning, could explore its optimal state by continuously interacting with an external environment. Generally, the traditional LA algorithms, especially estimator LA algorithms, can be ultimately abstracted out as P- or Q-models, which are simply located in the stationary environments. A more comprehensive consideration would be S-model operating in the non-stationary environment. For this specific LA, presently the most popular achievement belongs to stochastic estimator LA (SELA). However, synchronously handing four parameters involved in SELA is an intractable job, as these parameters may vary dramatically in values under different environments, making it essential to develop a strategy for parameter tuning. In this paper, we first propose a scheme to determine the parameter searching scope and subsequently present a series of parameter searching methods, including a four-dimensional method and a two-dimensional method, making SELA applicable for any environment with switching non-stationary characteristics. Furthermore, to decrease the tuning cost, a reduced parameter SELA supported by the new two-dimensional parameter searching method emerges. And to break the traditional limit that the environmental reward probability must be symmetrically distributed, the S-model is constructed from a new perspective, thus forming a novel reduced parameter S-model of SELA (rpS-SELA). A detailed mathematical proof theoretically reveals the absolute expediency of rpS-SELA. In addition, it is demonstrated by experimental simulations that rpS-SELA outperforms others with a reduced tuning cost, a minor time consumption, a higher accuracy rate, and above all, a stronger tracking ability to the environmental switches.},
  archive      = {J_NCA},
  author       = {Guo, Ying and Di, Chong and Li, Shenghong},
  doi          = {10.1007/s00521-021-06777-y},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6811-6824},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel reduced parameter s-model of estimator learning automata in the switching non-stationary environment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual search difficulty prediction with image ROI
information. <em>NCA</em>, <em>34</em>(9), 6799–6809. (<a
href="https://doi.org/10.1007/s00521-021-06413-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target recognition difficulty quantification and prediction using the search time for the human visual system to target an object is a challenging task, which can effectively guide the training of machine learning models such as target recognition and target location. Our work focuses on how to use region-of-interest (ROI) information to improve the accuracy of the visual search difficulty prediction model. First, the influence of ROI information on visual search difficulty is explored in this paper. Then, based on the learning using privileged information paradigm, we build a support vector regression model using privileged information (SVR +), which uses the deep features of ROIs in the training stage. Next, a coordinate descent algorithm is developed to solve the dual optimization problem in SVR + training. Comprehensive experiments validate the improvement in the accuracy of the proposed model in predicting the difficulty of visual search and the efficiency of our coordinate descent algorithm in model training.},
  archive      = {J_NCA},
  author       = {Xiao, Bo and Liu, Xuelian and Wang, Chunyang},
  doi          = {10.1007/s00521-021-06413-9},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6799-6809},
  shortjournal = {Neural Comput. Appl.},
  title        = {Visual search difficulty prediction with image ROI information},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Indoor positioning algorithm based on improved convolutional
neural network. <em>NCA</em>, <em>34</em>(9), 6787–6798. (<a
href="https://doi.org/10.1007/s00521-021-06112-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional navigation systems rely mainly on satellite navigation, but internal positioning and navigation cannot be achieved. This is mainly due to the inability to penetrate the wall due to the complex internal environment and the signal reaching the ground. Therefore, this paper proposes the research of indoor positioning algorithm based on improved convolutional neural network. The main method of this paper is based on the monocular vision indoor positioning based on the improved convolutional neural network. This method is an intelligent solution to the problems of traditional methods such as high cost, poor anti-interference ability, weak robustness, and poor compatibility. Positioning aids. The traditional computer vision camera pose estimation method is affected by the complex background in the image. When extracting feature corners, it is very affected by non-interest corners, so this paper adds an improved convolutional neural network algorithm to add in complex indoor scenes. With the region limitation, camera pose estimation in the region of interest is better to achieve low-cost, high accuracy and more stability. The improved model in this paper was tested on a test set of indoor datasets with markers, and the recognition accuracy reached 98.1\%. In addition, this paper improves the PnP solution method, compares and analyzes the traditional RPnP, EPnP, and CEPPnP algorithms, and seeks the optimal camera pose estimation algorithm to locate the world coordinates of the current shooting position. The experimental results show that this paper proposes the positioning algorithm has high stability.},
  archive      = {J_NCA},
  author       = {Zhou, Taoyun and Ku, Junhua and Lian, Baowang and Zhang, Yi},
  doi          = {10.1007/s00521-021-06112-5},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6787-6798},
  shortjournal = {Neural Comput. Appl.},
  title        = {Indoor positioning algorithm based on improved convolutional neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation of factors affecting dance training effects based
on reinforcement learning. <em>NCA</em>, <em>34</em>(9), 6773–6785. (<a
href="https://doi.org/10.1007/s00521-021-06032-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional dance training process lacks a certain degree of scientificity due to the lack of precise motion capture and analysis system, which directly affects the final training effect. In view of the robust limitations of the type 1 fuzzy reinforcement learning flexible structure control system to the uncertainty of noise interference, based on the reinforcement learning algorithm, this paper proposes a flexible structure controller based on the type 2 fuzzy reinforcement learning algorithm. Moreover, this paper uses fuzzy sets with equidistant fuzzy centers to divide large-scale state or continuous state space into two types of fuzzy divisions, divide the action space uniformly, and build fuzzy rules based on the basic ideas of type 1 fuzzy reinforcement learning. In addition, this paper constructs an evaluation system for factors affecting dance training effects based on reinforcement learning and designs experiments to verify the performance of the system. The research results show that the system constructed in this paper meets the theoretical needs and can be applied to dance training practice later.},
  archive      = {J_NCA},
  author       = {Xin, Liu},
  doi          = {10.1007/s00521-021-06032-4},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6773-6785},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluation of factors affecting dance training effects based on reinforcement learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of CT coronary flow reserve fraction based on
deep learning in coronary artery diagnosis of coronary heart disease
complicated with diabetes mellitus. <em>NCA</em>, <em>34</em>(9),
6763–6772. (<a
href="https://doi.org/10.1007/s00521-021-06070-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronary heart disease is a heart disease caused by coronary atherosclerosis, which seriously endangers human life and health. More and more studies have shown that diabetes is one of the main pathogenic factors of coronary heart disease and has an important relationship with coronary heart disease. At present, the mainstream treatment of coronary heart disease complicated with diabetes mellitus is the use of coronary angiography, which is the gold standard of treatment at present. However, it still has a certain risk, and most of the postoperative complications, the improvement method is to use FFR evaluation standard. At present, there are few special researches on this aspect. Therefore, this paper proposes the application research of FFR based on deep learning in the diagnosis of coronary heart disease complicated with diabetes mellitus. Through the core theoretical research on coronary heart disease complicated with diabetes mellitus and FFR, this paper analyzes that the existing coronary angiography is still in the development stage, which has a positive effect on the treatment of coronary heart disease and diabetes mellitus. On this basis, combined with FFR can play a better therapeutic effect. The second part is the establishment method of the related comparative experiment. This experiment adopts real coronary heart disease complicated with diabetes cases, through the way of random grouping, each group of 41 people, one group was FFRCT group, the other was FFRQCA group, and in order to ensure the experimental effect, a unified evaluation index is established. In the third part, the comparative analysis of the experimental methods of angina pectoris was carried out. Through the analysis of experimental data, it is shown that the safety, postoperative complications control and comprehensive treatment effect of this method are significantly improved compared with the traditional methods.},
  archive      = {J_NCA},
  author       = {Wang, Zhaoping and Yin, Hongji and Jing, Wei and Sun, Hui and Ru, Ming and Zhang, Suhua and Wang, Yingcui},
  doi          = {10.1007/s00521-021-06070-y},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6763-6772},
  shortjournal = {Neural Comput. Appl.},
  title        = {Application of CT coronary flow reserve fraction based on deep learning in coronary artery diagnosis of coronary heart disease complicated with diabetes mellitus},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid recommendation algorithm of cross-border e-commerce
items based on artificial intelligence and multiview collaborative
fusion. <em>NCA</em>, <em>34</em>(9), 6753–6762. (<a
href="https://doi.org/10.1007/s00521-021-06249-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce platforms apply recommendation technology to a wide variety of commercial websites to help users quickly find the product they need from a large number of products. At present, recommendation systems have been widely used in large-scale e-commerce websites, and most e-commerce shopping websites attract customers through the image information of goods. In this paper, the research status of content-based image retrieval algorithms is analysed, and how to use image content information to recommend goods is studied. A hierarchical commodity classification and retrieval system are designed. A class decision layer is used to determine the category of commodity images and then precisely retrieve the corresponding category of commodity image features. The corresponding relationship between different commodity visual features is used to recommend commodities, and a matching recommendation algorithm for commodities is proposed. Experiments show that the proposed image content-based recommendation method can coordinate with features, and its recommendation results have high accuracy in practical applications.},
  archive      = {J_NCA},
  author       = {Li, Bing and Li, Jiahua and Ou, Xijun},
  doi          = {10.1007/s00521-021-06249-3},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6753-6762},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid recommendation algorithm of cross-border e-commerce items based on artificial intelligence and multiview collaborative fusion},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Control method of robot detour obstacle based on EEG.
<em>NCA</em>, <em>34</em>(9), 6745–6752. (<a
href="https://doi.org/10.1007/s00521-021-06155-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of science and technology and the progress of the times, robots have slowly entered people&#39;s lives and work. However, how to control robots to bypass obstacles has become the focus of current research. Different from other related researches, the main research purpose of this paper is to use electroencephalogram (EEG) to control robots and achieve obstacles. In this paper, sample entropy is used to extract features of EEG, and then integrated learning is used to classify the extracted features. In the research process, this paper analyses the changes in the accuracy of the subjects before and after training, respectively, analyses the results of the two kinds of sports recognition, and then analyses the distribution of brain regions for motor control. Through the experiment on 12 subjects, the results show that through training, the four sports can achieve the highest recognition result of 85.4\%. The experimental results show that, for the specific analysis of the distribution of brain regions, it can be seen that there are obvious differences in the characteristics of the left and right brains that control the movement of the robot, but there are differences in the control of the movement of the robot.},
  archive      = {J_NCA},
  author       = {Wang, Qingjun and Mu, Zhendong and Jin, Ling},
  doi          = {10.1007/s00521-021-06155-8},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6745-6752},
  shortjournal = {Neural Comput. Appl.},
  title        = {Control method of robot detour obstacle based on EEG},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-invasive quantitative diagnosis of liver fibrosis with
an artificial neural network. <em>NCA</em>, <em>34</em>(9), 6733–6744.
(<a href="https://doi.org/10.1007/s00521-021-06257-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hepatic fibrosis is the body’s response to chronic liver disorders caused by various causes. Ultrasonic examination using an intelligent algorithm is increasingly important for the diagnosis of hepatic fibrosis. The purpose of this study was to analyse the preliminary application of artificial neural networks (ANNs) combined with ultrasonic quantitative diagnosis of hepatic fibrosis. In this study, 93 patients with hepatic fibrosis in our hospital were enrolled. The ultrasound image data of patients with chronic liver disease and the normal control group were collected, and 10 ultrasound examination indexes were quantified. The liver fibrosis grade of patients with chronic liver disease was confirmed by ultrasound-guided liver biopsy. After statistical analysis of all the ultrasonic data, the meaningful indexes were selected as the input layer, and the pathological grading results of liver fibrosis were selected as the output layer. The results showed that grades 2 and 4 hepatic fibrosis were diagnosed by ANN. The sensitivity, specificity and accuracy of the artificial neural network model were 95.4\%, 96.2\% and 95.8\%, respectively. The preliminary artificial neural network model of ultrasound diagnosis of early liver cirrhosis has high sensitivity and specificity. In this study, the accuracy and specificity of ultrasound diagnosis of hepatic fibrosis were greatly improved. It is concluded that this is very helpful for the treatment of the disease.},
  archive      = {J_NCA},
  author       = {Song, Jiaguang and Zhang, Yuezhong and Cheng, Jinling and Wang, Shi and Liu, Zhi and Sun, Dianmin},
  doi          = {10.1007/s00521-021-06257-3},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6733-6744},
  shortjournal = {Neural Comput. Appl.},
  title        = {Non-invasive quantitative diagnosis of liver fibrosis with an artificial neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). The artistic design of user interaction experience for
mobile systems based on context-awareness and machine learning.
<em>NCA</em>, <em>34</em>(9), 6721–6731. (<a
href="https://doi.org/10.1007/s00521-021-06160-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the art design of user interaction experience in mobile systems through the methods of contextual perception and machine learning. The theoretical foundations for the design of intangible cultural heritage interactive display resources include digital display theory, intangible cultural heritage education theory, embodied cognition theory, and gamification design theory. Based on the modelling and analysis of the theoretical foundations, the design principles are derived, including the heritage education principle, the somatic interaction design principle, and the content design principle. In this paper, we use ontologies to construct user knowledge models, fuse multi-situational similarity metrics, screen out candidate neighbour sets through preliminary screening, then combine the user&#39;s activity to construct time-based weight tensor scores, use tensor decomposition to obtain recommendation evaluation values, and finally use the recommendation evaluation values to make artistic recommendations. The experimental results show that the algorithm can still obtain a good recommendation implementation in the case of extremely sparse data. The analysis of the fit between augmented reality and folk art appreciation class, as well as the reference to relevant application cases, make design and practice of augmented reality application in folk art appreciation class, try to solve the common problems in folk art appreciation class, analyse the feedback effect and make a summary and outlook.},
  archive      = {J_NCA},
  author       = {Liu, Lina},
  doi          = {10.1007/s00521-021-06160-x},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6721-6731},
  shortjournal = {Neural Comput. Appl.},
  title        = {The artistic design of user interaction experience for mobile systems based on context-awareness and machine learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RETRACTED ARTICLE: Decision response of subway evacuation
signs based on brain component features. <em>NCA</em>, <em>34</em>(9),
6705–6719. (<a
href="https://doi.org/10.1007/s00521-021-06150-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to safety issues when passengers get on and off the subway and spend a lot of time on the subway, this makes subway station signs very important. Moreover, in case of fire and other dangerous situations and emergency evacuation, the guiding signs must be able to guide passengers to leave the station and dangerous areas efficiently and orderly, so as to protect the personal and property safety of passengers. The purpose of this study was to analyze the decision response of subway evacuation signs using the characteristics of the brain components. In this study, subway model is constructed. When you perform simulation using software, you need to fine tune the parameters to get the best simulation effect. A questionnaire survey was made on the components of the subway sign. The results show that the number of people who think that the standard font of the blackboard logo is the most representative of the emergency exit, accounting for 78.2\% of the total number of people, taking the image as the first choice accounted for 52.9\% of the total number of people, and the green sulfur powder logo as the first choice accounted for 69.8\% of the total number. This study makes an important contribution to the research of subway traffic safety problems.},
  archive      = {J_NCA},
  author       = {Huang, Yixin and Cao, Dongmei},
  doi          = {10.1007/s00521-021-06150-z},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6705-6719},
  shortjournal = {Neural Comput. Appl.},
  title        = {RETRACTED ARTICLE: Decision response of subway evacuation signs based on brain component features},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monitoring and visualization application of smart city
energy economic management based on IoT sensors. <em>NCA</em>,
<em>34</em>(9), 6695–6704. (<a
href="https://doi.org/10.1007/s00521-021-06108-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban economic development is not linear, but it always exhibits certain volatility. If the economic fluctuation exceeds a certain range, it may damage the urban economic development. In order to solve the economic damage caused by the excessive fluctuation of the urban economy in the development process, this article is based on the current situation of China&#39;s macroeconomic monitoring and early warning and data warehouse-related technologies, analyzed, explained the role of IoT sensors in the macroeconomic early warning system, reviewed the development process of economic monitoring and early warning, sorted out and compared several common economic monitoring methods, and proposed the application of IoT sensors to urban economic monitoring, the idea of early warning, and the construction of an urban economic data monitoring and early warning model. The urban economic data monitoring and early warning model is based on IoT sensors and has carried out research on data transmission, monitoring, forecasting, processing and display. After simulating the model, the results of the simulation experiment show that the accuracy rate of the economic volatility prediction of the model reaches 80\%, which has certain practical value.},
  archive      = {J_NCA},
  author       = {Li, Qianyuan and Jiang, Zhiyong and Yuan, Feng},
  doi          = {10.1007/s00521-021-06108-1},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6695-6704},
  shortjournal = {Neural Comput. Appl.},
  title        = {Monitoring and visualization application of smart city energy economic management based on IoT sensors},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Crawling robot manipulator tracking based on gaussian
mixture model of machine vision. <em>NCA</em>, <em>34</em>(9),
6683–6693. (<a
href="https://doi.org/10.1007/s00521-021-06063-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the grasping process of the robot, the pose of robot should adapt to the change of the object&#39;s pose. In order to avoid the cumbersome calibration and difficulty of inversion in the existing vision-based robotic arm-grasping methods, a robotic arm grasping and tracking method based on Gaussian mixture of machine vision model (MGV) are proposed. This method uses Gaussian mixture model of machine vision to build the mapping relationship between the observed variables of the object and the robot joint variables. In the learning phase, the Gaussian mixture model of machine vision is used to directly construct the mapping from the pose of the target object to the joint angle of the manipulator. In the grasping stage, the pose of the target object is acquired through the camera, and the generation probability of the pose under each Gaussian component is calculated, respectively, and the Gaussian process regression corresponding to the Gaussian component with the largest posterior probability is selected to calculate the corresponding manipulator joint angle. The experimental results show that using Gaussian mixture machine vision model can make the robot manipulator grasp and track better than using single Gaussian process model.},
  archive      = {J_NCA},
  author       = {Lou, Jingjing},
  doi          = {10.1007/s00521-021-06063-x},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6683-6693},
  shortjournal = {Neural Comput. Appl.},
  title        = {Crawling robot manipulator tracking based on gaussian mixture model of machine vision},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on early warning of agricultural credit and
guarantee risk based on deep learning. <em>NCA</em>, <em>34</em>(9),
6673–6682. (<a
href="https://doi.org/10.1007/s00521-021-06114-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the impact of agricultural industry differentiation, traditional financial risk model cannot forewarn the guarantee risk of agricultural credit with effectively. This paper proposes an early warning algorithm of agricultural credit and guarantee risk that can effectively overcome the interference of external factors. Using deep learning network, the risk algorithm of agricultural credit and guarantee was built and it could change the deep belief network into supervised learning. To train for an optimal model, two new hidden layers are added to extract image feature vectors, as well as a Softmax classifier. The model is trained and evaluated by the usage of the risk data set of L province from 2017 to 2019, reinforcing the pre-training network and data to deal with the issue of overfitting in training. The results show that the accuracy of the model reaches 92.56\%, when the training sample proportion is 90\%, with all the 13 factors in the test set taken as input. It shows that the training of the model worked well and that it can effectively predict the risk of agricultural credit and guarantee.},
  archive      = {J_NCA},
  author       = {Zhang, Chao and Wang, Zhenyu and Lv, Jie},
  doi          = {10.1007/s00521-021-06114-3},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6673-6682},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on early warning of agricultural credit and guarantee risk based on deep learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Image recognition algorithm based on artificial
intelligence. <em>NCA</em>, <em>34</em>(9), 6661–6672. (<a
href="https://doi.org/10.1007/s00521-021-06058-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks also encountered some problems in the development of image recognition. The most prominent problem is that it is costly and time-consuming to collect data sets and train models. Limited data sets will cause the trained models to overfit. This paper proposes two methods to reduce overfitting based on the residual neural network architecture. The first type of method proposes a method of cross-combining waivers, reducing the size of the convolution kernel, and reducing the number of convolution kernels. The fitting method uses cross-combination to make the accuracy of Kaggle cat and dog data on the validation data set reach 95.37\% and 90.31\% on 30 types of engineering practice verification data set. The second method is based on the finetune residual neural network. A method of recurrent finetune residual neural network is proposed to improve the accuracy of the model. The accuracy of the finetune residual neural network on the Kaggle cat and dog validation dataset is 99.37\%, and the accuracy of the dataset is verified in 30 types of engineering practice. The accuracy is 99.30\%. The residual neural network method achieves 99.68\% accuracy in the Kaggle cat and dog validation dataset and 99.61\% in the validation dataset for 30 types of engineering practice.},
  archive      = {J_NCA},
  author       = {Chen, Hong and Geng, Liwei and Zhao, Hongdong and Zhao, Cuijie and Liu, Aiyong},
  doi          = {10.1007/s00521-021-06058-8},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6661-6672},
  shortjournal = {Neural Comput. Appl.},
  title        = {Image recognition algorithm based on artificial intelligence},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anesthesia depth evaluation algorithm based on permutation
and combination entropy. <em>NCA</em>, <em>34</em>(9), 6647–6660. (<a
href="https://doi.org/10.1007/s00521-021-06030-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of anesthesia is of great value to the risk of surgery and the recovery of postoperative patients. The evaluation of depth of anesthesia through EEG signals is an effective method to improve the quality of anesthesia. The difficulty of anesthesia depth evaluation lies in the lack of a relatively stable algorithm. In this study, the permutation and entropy algorithm are used as the system algorithm. Meanwhile, this study combines with the anesthesia depth assessment needs and actual conditions to improve the algorithm and realize the anesthesia depth detection function by extracting the feature parameters of different fields of EEG signals. In addition, this study analyzes multiple channels of EEG signals through adaptive neural networks to obtain quantified anesthesia depth values and compares this value with IoC monitors. Through experimental research, we can see that the method proposed in this paper has a certain practical effect.},
  archive      = {J_NCA},
  author       = {Zhang, Wenwen and Yu, Hong and Duan, Zongsheng and Yu, Tingting and Li, Xinbai},
  doi          = {10.1007/s00521-021-06030-6},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6647-6660},
  shortjournal = {Neural Comput. Appl.},
  title        = {Anesthesia depth evaluation algorithm based on permutation and combination entropy},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GVnet: Gaussian model with voxel-based 3D detection network
for autonomous driving. <em>NCA</em>, <em>34</em>(9), 6637–6645. (<a
href="https://doi.org/10.1007/s00521-021-06061-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposed a two-stage Voxel-based 3D Object detector which named GVnet. Voxel-based method mainly relies on sampling and Grouping point in voxel and the feature map generated by subsequent 3D CNN to control the quality of detection. Moreover, traditional voxel feature encoder (VFE) methods cannot adjust the quality of feature map through reasonable sampling. Therefore, the method we propose is an improvement to the existing VFE. The specific operations are: First calculate the corresponding Gaussian distribution of the original point cloud data, and then sampling any number of points by controlling the confidence value to improve the performance of voxel encoder and further improve the quality of the feature map output by the 3D CNN. In addition, a voxel ROI pooling method is proposed in stage two. In ROI Pooling, the receptive field in the original space and the corresponding raw point are obtained through the mapping relationship between feature and ROI, then change the raw point to adjust the receptive field to improve the performance of classification and regression. Finally, the experimental results on the KITTI, nuScenes and Waymo dataset show that the performance of GVnet under most of the evaluation indexes is better than the current detection methods, at the cost of only a small amount of inference time.},
  archive      = {J_NCA},
  author       = {Qin, Peilin and Zhang, Chuanwei and Dang, Meng},
  doi          = {10.1007/s00521-021-06061-z},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6637-6645},
  shortjournal = {Neural Comput. Appl.},
  title        = {GVnet: Gaussian model with voxel-based 3D detection network for autonomous driving},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Binary tree pricing method of farmland management right
mortgage based on machine learning and complex network algorithm.
<em>NCA</em>, <em>34</em>(9), 6625–6636. (<a
href="https://doi.org/10.1007/s00521-021-06071-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the mortgage loan of farmland contractual management right is in the pilot and exploration stage. In this overall environment, how to formulate an appropriate pricing model according to the particularity of farmland property right and the actual situation is the theoretical support to be solved. On the basis of theoretical analysis, model construction and analysis of existing problems, this paper establishes a binary tree pricing method of farmland management right mortgage based on machine learning and complex network algorithm. This paper analyzes the basic theory of rural land management right mortgage pricing and constructs the pricing model. Based on the Markov decision process model of dynamic pricing problem, this paper proposes the solution algorithm and proposes the dynamic pricing solution for this paper from two aspects of value function and strategy gradient reinforcement learning algorithm. This paper analyzes the basic principle of A3C algorithm and expounds the algorithm design and neural network architecture for the specific dynamic pricing problem in this paper. The dynamic pricing method of rural land mortgage based on deep reinforcement learning designed in this paper can well predict the real price of rural land management right mortgage pricing and effectively optimize the mortgage loan environment of rural contracted land management right, which is the innovation of financial system in the current new rural construction.},
  archive      = {J_NCA},
  author       = {Fu, Zhaogang and Hu, Shanshan},
  doi          = {10.1007/s00521-021-06071-x},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6625-6636},
  shortjournal = {Neural Comput. Appl.},
  title        = {Binary tree pricing method of farmland management right mortgage based on machine learning and complex network algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Sudden passenger flow characteristics and congestion
control based on intelligent urban rail transit network. <em>NCA</em>,
<em>34</em>(9), 6615–6624. (<a
href="https://doi.org/10.1007/s00521-021-06062-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of smart city is of strategic significance to the realization of modern society in China, and rail transit network is an important part of urban development. Currently, China&#39;s urban rail transport is at the bottleneck stage, and many medium-sized cities are facing a sudden heavy passenger congestion situation. Based on the next-generation innovation of the knowledge society, smart cities will maximize the use of new generation information technology in all fields of the city, and realize advanced urban informatization that realizes deep integration of informatization, industrialization, and informatization and helps to reduce urbanization and &quot;disease in big cities.&quot; Improve the quality of urbanization, realize refined and dynamic management, and enhance the effectiveness of urban management and improve the quality of life of citizens. In order to ensure the safety of passengers, passenger flow control and optimization and upgrading of rail transit network become urgent. However, there are few researches in this field in China, so this paper will focus on the characteristics of sudden passenger flow and congestion control based on smart city rail transit network. First, in this paper, we systematically explained the relationship between smart cities and smart transportation and analyzed the need for sudden passenger flow control in urban railway transportation according to its characteristics. According to a study on the characteristics of sudden passenger flow, this paper believes that passenger flow comes primarily from large-scale activities, commuters, and individual emergencies, but is still predictable and controllable. For this reason, this paper studies the control scheme of sudden passenger flow congestion, which fully combines the characteristics of sudden passenger flow, and according to the characteristics of the treatment. This scheme is safe and reliable and has the advantage of controlling congestion from the source. In order to further test the actual effect of the passenger flow control scheme, the simulation experiment is carried out in the end of this paper. According to experimental data analysis, the passenger flow control method of this paper can effectively improve the existing rail transport congestion control in the case of sudden large-scale passenger flow, and the effect is remarkable, and most of them. Suitable for urban rail transport networks.},
  archive      = {J_NCA},
  author       = {Wang, Yulei and Li, Meng and Zhou, Jian and Zheng, Hongyu},
  doi          = {10.1007/s00521-021-06062-y},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6615-6624},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sudden passenger flow characteristics and congestion control based on intelligent urban rail transit network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Video analysis of intelligent teaching based on machine
learning and virtual reality technology. <em>NCA</em>, <em>34</em>(9),
6603–6614. (<a
href="https://doi.org/10.1007/s00521-021-06072-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study and analyse the teaching video of oil painting art through machine learning combined with virtual reality computing. Since the current oil painting, image acquisition method cannot meet the user&#39;s demand for multi-dimensional image description, and at the same time the retrieval method is too simple to perform high flexibility retrieval, we try to adopt the deep learning-based object extraction fusion method. Also, objects with poor performance quality are not suitable for further interception and cutting. We first pre-process the images in the image library to filter out the relatively high-quality images and then filter out the objects whose saliency and clarity do not reach the queue value by judging the saliency and clarity values of the images. Next, a series of aesthetic criteria, such as visual balance, visual triangulation, and centrosymmetric diagonal composition criteria, used to further filter the objects with relatively poor quality and low ratings. Then, we expand the areas with high saliency, match the contours of the segmented image elements with the contours of the user-drawn image to return an optimal matching value, and finally improve the quality and naturalness of the image by learning the deeper features of the image based on the style migration. The experimental framework based on TensorFlow is a new application of deep learning in the field of image synthesis, which has a very good improvement in the implementation efficiency compared with the traditional method. Using virtual reality technology to carry out teaching practice and analyse the effect of teaching practice, students can immerse themselves in art appreciation teaching activities, accept multiculturalism, learn through experience, and improve aesthetic quality.},
  archive      = {J_NCA},
  author       = {Mao, Wenli},
  doi          = {10.1007/s00521-021-06072-w},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6603-6614},
  shortjournal = {Neural Comput. Appl.},
  title        = {Video analysis of intelligent teaching based on machine learning and virtual reality technology},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transport infrastructure connectivity and conflict
resolution: A machine learning analysis. <em>NCA</em>, <em>34</em>(9),
6585–6601. (<a
href="https://doi.org/10.1007/s00521-021-06015-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transport infrastructure connectivity (TIC) has strong endogeneity issues, making it difficult to directly assess its impact on local conflict resolution. This study presents new evidence of the effects of TIC on conflict resolution by conducting a natural experiment and applying machine learning methods to overcome the endogeneity issue. Based on global conflict data from 2010 to 2017, the empirical results show the following: (1) TIC can significantly improve countries’ global ranking for conflict resolution; in particular, the marginal benefit of developed countries is greater than that of developing countries. (2) The mechanism behind this effect is the promotion of trade facilitation, a more balanced employment ratio across genders, and improved income levels through TIC, which further enhances the conflict governance capacity of countries. In light of the findings, policy-makers should consider the opportunity to combine TIC with greater security for the realization of economic and social benefits, taking into account the significant opportunities for developing countries and the importance of balance across genders and income levels.},
  archive      = {J_NCA},
  author       = {Luo, Ji and Wang, Guijun and Li, Guangqin and Pesce, Greta},
  doi          = {10.1007/s00521-021-06015-5},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6585-6601},
  shortjournal = {Neural Comput. Appl.},
  title        = {Transport infrastructure connectivity and conflict resolution: A machine learning analysis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on neural computing challenges and
applications for industry 4.0. <em>NCA</em>, <em>34</em>(9), 6583–6584.
(<a href="https://doi.org/10.1007/s00521-022-07074-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Liang, Haibo and Liu, Weidong},
  doi          = {10.1007/s00521-022-07074-y},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6583-6584},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on neural computing challenges and applications for industry 4.0},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Combining functional near-infrared
spectroscopy and EEG measurements for the diagnosis of attention-deficit
hyperactivity disorder. <em>NCA</em>, <em>34</em>(8), 6581. (<a
href="https://doi.org/10.1007/s00521-022-07056-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Güven, Ayşegül and Altınkaynak, Miray and Dolu, Nazan and İzzetoğlu, Meltem and Pektaş, Ferhat and Özmen, Sevgi and Demirci, Esra and Batbat, Turgay},
  doi          = {10.1007/s00521-022-07056-0},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6581},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Combining functional near-infrared spectroscopy and EEG measurements for the diagnosis of attention-deficit hyperactivity disorder},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Correction to: A hybrid deep neural network approach to
estimate reference evapotranspiration using limited climate data.
<em>NCA</em>, <em>34</em>(8), 6579. (<a
href="https://doi.org/10.1007/s00521-021-06832-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Sharma, Gitika and Singh, Ashima and Jain, Sushma},
  doi          = {10.1007/s00521-021-06832-8},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6579},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: A hybrid deep neural network approach to estimate reference evapotranspiration using limited climate data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Correction to: A deep learning-assisted mathematical model
for decongestion time prediction at railroad grade crossings.
<em>NCA</em>, <em>34</em>(8), 6577. (<a
href="https://doi.org/10.1007/s00521-021-06767-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Jiang, Zhuocheng and Guo, Feng and Qian, Yu and Wang, Yi and Pan, W. David},
  doi          = {10.1007/s00521-021-06767-0},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6577},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: A deep learning-assisted mathematical model for decongestion time prediction at railroad grade crossings},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Use of GMDH-type neural network to model the
mechanical behavior of a cement-treated sand. <em>NCA</em>,
<em>34</em>(8), 6575. (<a
href="https://doi.org/10.1007/s00521-021-06562-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {MolaAbasi, Hossein and Khajeh, Aghileh and Jamshidi Chenari, Reza},
  doi          = {10.1007/s00521-021-06562-x},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6575},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Use of GMDH-type neural network to model the mechanical behavior of a cement-treated sand},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Playing to distraction: Towards a robust
training of CNN classifiers through visual explanation techniques.
<em>NCA</em>, <em>34</em>(8), 6571–6574. (<a
href="https://doi.org/10.1007/s00521-021-06407-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Morales, David and Talavera, Estefania and Remeseiro, Beatriz},
  doi          = {10.1007/s00521-021-06407-7},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6571-6574},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: playing to distraction: towards a robust training of CNN classifiers through visual explanation techniques},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Correction to: Classification of thermal image of clinical
burn based on incremental reinforcement learning. <em>NCA</em>,
<em>34</em>(8), 6569. (<a
href="https://doi.org/10.1007/s00521-021-06052-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A correction to this paper has been published: https://doi.org/10.1007/s00521-021-06052-0},
  archive      = {J_NCA},
  author       = {Wu, Xianjun and Huang, Wendong and Wu, Xiaoli and Wu, Shenghang and Huang, Jinbo},
  doi          = {10.1007/s00521-021-06052-0},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6569},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Classification of thermal image of clinical burn based on incremental reinforcement learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). MEDAS: An open-source platform as a service to help break
the walls between medicine and informatics. <em>NCA</em>,
<em>34</em>(8), 6547–6567. (<a
href="https://doi.org/10.1007/s00521-021-06750-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past decade, deep learning (DL) has achieved unprecedented success in numerous fields, such as computer vision and healthcare. Particularly, DL is experiencing an increasing development in advanced medical image analysis applications in terms of segmentation, classification, detection, and other tasks. On the one hand, tremendous needs that leverage DL’s power for medical image analysis arise from the research community of a medical, clinical, and informatics background to share their knowledge, skills, and experience jointly. On the other hand, barriers between disciplines are on the road for them, often hampering a full and efficient collaboration. To this end, we propose our novel open-source platform, i.e., MEDAS–the MEDical open-source platform As Service. To the best of our knowledge, MEDAS is the first open-source platform providing collaborative and interactive services for researchers from a medical background using DL-related toolkits easily and for scientists or engineers from informatics modeling faster. Based on tools and utilities from the idea of RINV (Rapid Implementation aNd Verification), our proposed platform implements tools in pre-processing, post-processing, augmentation, visualization, and other phases needed in medical image analysis. Five tasks, concerning lung, liver, brain, chest, and pathology, are validated and demonstrated to be efficiently realizable by using MEDAS. MEDAS is available at http://medas.bnc.org.cn/ .},
  archive      = {J_NCA},
  author       = {Zhang, Liang and Li, Johann and Li, Ping and Lu, Xiaoyuan and Gong, Maoguo and Shen, Peiyi and Zhu, Guangming and Shah, Syed Afaq and Bennamoun, Mohammed and Qian, Kun and Schuller, Björn W.},
  doi          = {10.1007/s00521-021-06750-9},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6547-6567},
  shortjournal = {Neural Comput. Appl.},
  title        = {MEDAS: An open-source platform as a service to help break the walls between medicine and informatics},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of the compressive strength of concrete using
various predictive modeling techniques. <em>NCA</em>, <em>34</em>(8),
6535–6545. (<a
href="https://doi.org/10.1007/s00521-021-06820-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concrete is one of the most essential construction materials used in construction industry. For assessment of concrete strength and quality, compressive strength is the most frequently utilized parameter. This paper establishes the application of Gaussian process, M5P model, random forest and random tree techniques for appropriate proportioning of the concrete mixes. The models proposed were based on six input parameters, namely cement, sand, coarse aggregate, water, curing period and fineness modulus, while the compressive strength was an output parameter. Five most popular statistical parameters such as Pearson correlation coefficient, mean absolute error, root mean square error, Scattering Index and Nash–Sutcliffe model efficiency were used for the assessment of the developed models. On comparison, it was found that better results were achieved with Radial bases kernel function based Gaussian process regression model as compared to other applied models. The suggested models are expected to save cost of materials, cost of labor work, time and contribute to greater accuracy. The concrete designed is anticipated to have more durability and therefore be more economical.},
  archive      = {J_NCA},
  author       = {Gupta, Sakshi and Sihag, Parveen},
  doi          = {10.1007/s00521-021-06820-y},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6535-6545},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of the compressive strength of concrete using various predictive modeling techniques},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Chaos synchronization using adaptive quantum neural networks
and its application in secure communication and cryptography.
<em>NCA</em>, <em>34</em>(8), 6521–6533. (<a
href="https://doi.org/10.1007/s00521-021-06768-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an adaptive controller for chaos synchronization using quantum neural networks (QNN). The main purpose is to design a communication system for transmission of information securely. In many applications of chaotic systems, the exact model of system is not available and may involve uncertainties such as external disturbance and parametric uncertainties originating from environmental conditions. To estimate the uncertainties in the receiver and improve the accuracy of synchronization and recovering the message signal for secure communication applications, a QNN is used. The parameters of the proposed system should be estimated by applying the adaptive rules obtained by Lyapunov theorem. Taylor series expansion has been utilized to obtain a linear relation between the output of quantum neural network and its adaptive parameters. Simulation results show that the synchronization procedure for state variables of the master and slave systems is performed well with negligible synchronization error. Also, its application is investigated in secure communication and cryptography.},
  archive      = {J_NCA},
  author       = {Aliabadi, Fatemeh and Majidi, Mohammad-Hassan and Khorashadizadeh, Saeed},
  doi          = {10.1007/s00521-021-06768-z},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6521-6533},
  shortjournal = {Neural Comput. Appl.},
  title        = {Chaos synchronization using adaptive quantum neural networks and its application in secure communication and cryptography},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparing the performance of hebbian against backpropagation
learning using convolutional neural networks. <em>NCA</em>,
<em>34</em>(8), 6503–6519. (<a
href="https://doi.org/10.1007/s00521-021-06701-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate Hebbian learning strategies applied to Convolutional Neural Network (CNN) training. We consider two unsupervised learning approaches, Hebbian Winner-Takes-All (HWTA), and Hebbian Principal Component Analysis (HPCA). The Hebbian learning rules are used to train the layers of a CNN in order to extract features that are then used for classification, without requiring backpropagation (backprop). Experimental comparisons are made with state-of-the-art unsupervised (but backprop-based) Variational Auto-Encoder (VAE) training. For completeness,we consider two supervised Hebbian learning variants (Supervised Hebbian Classifiers—SHC, and Contrastive Hebbian Learning—CHL), for training the final classification layer, which are compared to Stochastic Gradient Descent training. We also investigate hybrid learning methodologies, where some network layers are trained following the Hebbian approach, and others are trained by backprop. We tested our approaches on MNIST, CIFAR10, and CIFAR100 datasets. Our results suggest that Hebbian learning is generally suitable for training early feature extraction layers, or to retrain higher network layers in fewer training epochs than backprop. Moreover, our experiments show that Hebbian learning outperforms VAE training, with HPCA performing generally better than HWTA.},
  archive      = {J_NCA},
  author       = {Lagani, Gabriele and Falchi, Fabrizio and Gennaro, Claudio and Amato, Giuseppe},
  doi          = {10.1007/s00521-021-06701-4},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6503-6519},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparing the performance of hebbian against backpropagation learning using convolutional neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). M-GCN: Brain-inspired memory graph convolutional network for
multi-label image recognition. <em>NCA</em>, <em>34</em>(8), 6489–6502.
(<a href="https://doi.org/10.1007/s00521-021-06803-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional single-label classification methods can not be effectively applied in multi-label classification due to the semantic correlation. Conventional methods using the attention mechanism or prior knowledge, lacks deep semantic correlations, resulting in degradation for detection performance. Considering the hippocampal circuit and memory mechanism of human brain, a brain-inspired Memory Graph Convolutional Network (M-GCN) is proposed. M-GCN presents crucial short-term and long-term memory modules to interact attention and prior knowledge, learning complex semantic enhancement, and suppression. We evaluate the effectiveness of our method on public benchmarks (Microsoft COCO and PASCAL VOC). Extensive experiments demonstrate that M-GCN outperforms general state-of-the-art methods and shows the advantages in semantic correlation and complexity comparing with traditional memory models.},
  archive      = {J_NCA},
  author       = {Yao, Xiao and Xu, Feiyang and Gu, Min and Wang, Peipei},
  doi          = {10.1007/s00521-021-06803-z},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6489-6502},
  shortjournal = {Neural Comput. Appl.},
  title        = {M-GCN: Brain-inspired memory graph convolutional network for multi-label image recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward an action-granularity-oriented modularization
strategy for complex mechanical products using a hybrid GGA-CGA method.
<em>NCA</em>, <em>34</em>(8), 6453–6487. (<a
href="https://doi.org/10.1007/s00521-021-06796-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modular technology is a mainstream industrial trend, especially in manufacturing transformation and upgrading. Modularization is fundamental in modular technology and plays an important role in modular production processes, such as modular design, manufacturing, and assembly. Previous modularization studies have neglected large-scale and complex mechanical products. Furthermore, the traditional modularization method generates coarse-grained modular results with complex structures and specific functions; these modules are difficult to standardize and apply in modular production processes for cross-family products. Therefore, this study proposes an action-granularity-oriented modularization strategy to obtain finer-granularity modules and emphasizes the simplicity, fundamentality, and typicality of these modules to increase their generality. This strategy clusters components into different modules at the action level by first analyzing the association strengths among the components based on the concept of key action components and a modularity-driven factor system. Then, with the help of the design structure matrix (DSM) theory and the evidence theory, the association information is synthesized to construct a synthetic association DSM. Additionally, a new modularization method combining the grouping genetic algorithm (GGA) and constrained genetic algorithm (CGA), called the hybrid GGA-CGA method, is developed to search for the optimal modular schemes among all possible solutions based on the synthetic association DSM. Finally, a modularization case for a typical complex mechanical product (a winding engine) is used to demonstrate the feasibility and effectiveness of the proposed hybrid method in addressing modularization.},
  archive      = {J_NCA},
  author       = {Xiao, Liming and Huang, Guangquan and Zhang, Genbao},
  doi          = {10.1007/s00521-021-06796-9},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6453-6487},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward an action-granularity-oriented modularization strategy for complex mechanical products using a hybrid GGA-CGA method},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient binary chimp optimization algorithm for feature
selection in biomedical data classification. <em>NCA</em>,
<em>34</em>(8), 6427–6451. (<a
href="https://doi.org/10.1007/s00521-021-06775-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate classification of high-dimensional biomedical data highly depends on the efficient recognition of the data&#39;s main features which can be used to assist diagnose related diseases. However, due to the existence of a large number of irrelevant or redundant features in biomedical data, classification approaches struggle to correctly identify patterns in data without a feature selection algorithm. Feature selection approaches seek to eliminate irrelevant and redundant features to maintain or enhance classification accuracy. In this paper, a new wrapper feature selection method is proposed based on the chimp optimization algorithm (ChOA) for biomedical data classification. The ChOA is a newly proposed metaheuristic algorithm whose capability for solving feature selection problems has not been investigated yet. Two binary variants of the ChoA are introduced for the feature selection problem. In the first approach, two transfer functions (S-shaped and V-shaped) are used to convert the continuous version of ChoA to binary. In addition to the transfer function, the crossover operator is utilized in the second approach to improve the ChOA&#39;s exploratory behavior. To validate the efficiency of the proposed approaches, five publicly available high-dimensional biomedical datasets, and a few datasets from different domains such as life, text, and image are employed. The proposed approaches were then compared with six well-known wrapper-based feature selection methods, including multi-objective genetic algorithm (GA), particle swarm optimization (PSO), Bat algorithm (BA), ant colony optimization (ACO), firefly algorithm (FA), and flower pollination (FP) algorithm, as well as two standard filter-based feature selection methods using three different classifiers. The experimental results demonstrate that the proposed approaches can effectively remove the least significant features and improve classification accuracy. The suggested wrapper feature selection techniques also outperform the GA, PSO, BA, ACO, FA, FP, and other existing methods in the terms of the number of selected genes, and classification accuracy in most cases.},
  archive      = {J_NCA},
  author       = {Pashaei, Elnaz and Pashaei, Elham},
  doi          = {10.1007/s00521-021-06775-0},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6427-6451},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient binary chimp optimization algorithm for feature selection in biomedical data classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DCRS: A deep contrast reciprocal recommender system to
simultaneously capture user interest and attractiveness for online
dating. <em>NCA</em>, <em>34</em>(8), 6413–6425. (<a
href="https://doi.org/10.1007/s00521-021-06749-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the reciprocal recommendation, especially for online dating applications, has attracted increasing research attention. Different from the conventional recommendation problems, the reciprocal recommendation aims to simultaneously best match users’ mutual interests to make the recommendations. However, the most existing RRS algorithms seldom model users’ interest and attractiveness simultaneously under the high-dimensional feature space. Furthermore, the sparsity of reciprocal relations seriously deteriorates the recommendation performance. Thus, we propose a novel Deep Contrast Reciprocal Recommender System (DCRS) to address the aforementioned research issues. Particularly, we resolve the sparsity issue by introducing the reciprocal neighbors to increase the number of possible reciprocal relations. Then, a novel deep contrast neural network is then proposed to model the mutual interest by contrasting between the reciprocal and non-reciprocal relations. As a result, it was able to better identify the reciprocal relations for the latter recommendation. Extensive experiments have been evaluated on two real-world datasets, and the promising results demonstrate that the proposed DCRS is superior to both baseline and the state-of-the-art approaches.},
  archive      = {J_NCA},
  author       = {Luo, Linhao and Zhang, Xiaofeng and Chen, Xiaoyun and Liu, Kai and Peng, Dan and Yang, Xiaofei},
  doi          = {10.1007/s00521-021-06749-2},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6413-6425},
  shortjournal = {Neural Comput. Appl.},
  title        = {DCRS: A deep contrast reciprocal recommender system to simultaneously capture user interest and attractiveness for online dating},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint extraction of entities and relations using multi-label
tagging and relational alignment. <em>NCA</em>, <em>34</em>(8),
6397–6412. (<a
href="https://doi.org/10.1007/s00521-021-06685-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction aims to identify semantic relations between entities in text. In recent years, this task has been extended to the joint extraction of entities and relations, which requires the simultaneous identification of entities and their relations from sentences. However, existing methods, limited by the existing tagging scheme, fail to identify more complex entities, which in turn limits the performance of the joint extraction task. This article presents a joint extraction model for entities and relations called MLRA-LSTM-CRF that uses multi-label tagging and relational alignment to transform this task into a multi-label tag recognition problem. The proposed model first tags the entities and their relations according to the multi-label tagging scheme and then uses a joint entity and relation extraction module with a multi-layer attention mechanism to extract the triplets in the sentence. Finally, the relational alignment module is used to align the predicted relation classification results. Experimental results on the New York Times and Wiki-KBP datasets indicate that MLRA-LSTM-CRF is significantly better than that of several state-of-the-art models and baseline.},
  archive      = {J_NCA},
  author       = {Hang, Tingting and Feng, Jun and Yan, Le and Wang, Yunfeng and Lu, Jiamin},
  doi          = {10.1007/s00521-021-06685-1},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6397-6412},
  shortjournal = {Neural Comput. Appl.},
  title        = {Joint extraction of entities and relations using multi-label tagging and relational alignment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Kimesurface representation and tensor linear modeling of
longitudinal data. <em>NCA</em>, <em>34</em>(8), 6377–6396. (<a
href="https://doi.org/10.1007/s00521-021-06789-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many modern techniques for analyzing time-varying longitudinal data rely on parametric models to interrogate the time-courses of univariate or multivariate processes. Typical analytic objectives include utilizing retrospective observations to model current trends, predict prospective trajectories, derive categorical traits, or characterize various relations. Among the many mathematical, statistical, and computational strategies for analyzing longitudinal data, tensor-based linear modeling offers a unique algebraic approach that encodes different characterizations of the observed measurements in terms of state indices. This paper introduces a new method of representing, modeling, and analyzing repeated-measurement longitudinal data using a generalization of event order from the positive reals to the complex plane. Using complex time (kime), we transform classical time-varying signals as 2D manifolds called kimesurfaces. This kime characterization extends the classical protocols for analyzing time-series data and offers unique opportunities to design novel inference, prediction, classification, and regression techniques based on the corresponding kimesurface manifolds. We define complex time and illustrate alternative time-series to kimesurface transformations. Using the Laplace transform and its inverse, we demonstrate the bijective mapping between time-series and kimesurfaces. A proposed general tensor regression based linear model is validated using functional Magnetic Resonance Imaging data. This kimesurface representation method can be used with a wide range of machine learning algorithms, artificial intelligence tools, analytical approaches, and inferential techniques to interrogate multivariate, complex-domain, and complex-range longitudinal processes.},
  archive      = {J_NCA},
  author       = {Zhang, Rongqian and Zhang, Yupeng and Liu, Yuyao and Guo, Yunjie and Shen, Yueyang and Deng, Daxuan and Qiu, Yongkai Joshua and Dinov, Ivo D.},
  doi          = {10.1007/s00521-021-06789-8},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6377-6396},
  shortjournal = {Neural Comput. Appl.},
  title        = {Kimesurface representation and tensor linear modeling of longitudinal data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A background-aware correlation filter with adaptive
saliency-aware regularization for visual tracking. <em>NCA</em>,
<em>34</em>(8), 6359–6376. (<a
href="https://doi.org/10.1007/s00521-021-06771-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the discriminative correlation filters (DCF)-based methods have performed excellent precision and speed in object tracking. Due to the continuous change and expansion of the search region, the problem of insufficient training samples is solved by the periodicity hypothesis, which inevitably introduces boundary effects that can lead to severe failures in the detection stage. In this paper, we firstly add a background penalty factor into the correlation filter and propose a novel spatial regularization term by using the saliency detection method. Based on the above two points, a background-aware correlation filter model with saliency-aware regularization is established. Secondly, in order to solve the model better and faster, we introduce an energy function for the solution of the spatial weight and apply the alternating direction method of multipliers (ADMM) method and deduce the closed-form solution of each subproblem of the objective function efficiently. Thirdly, we propose an adaptive updating mechanism based on the variation of target appearance and the reliability of tracking results, which can update the model online by adjusting the spatial weight distribution for precisely tracking in the spatio-temporal domain. Finally, we apply two BAASR models to estimate the position and the scale of the target, respectively. One model adopts hand-crafted features at multiple scales to select the optimal scale, while the other model predicts the optimal position by fusing hand-crafted features with deep features extracted from the trained network models. Extensive experiments are carried out on the following five datasets, OTB-2013, OTB-2015, UAV123, UAV20L, and TC128. Experimental results demonstrate that our tracker has superior robustness and performance.},
  archive      = {J_NCA},
  author       = {Zhang, Jianming and Yuan, Tingyu and He, Yaoqi and Wang, Jin},
  doi          = {10.1007/s00521-021-06771-4},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6359-6376},
  shortjournal = {Neural Comput. Appl.},
  title        = {A background-aware correlation filter with adaptive saliency-aware regularization for visual tracking},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stark spectral line broadening modeling by machine learning
algorithms. <em>NCA</em>, <em>34</em>(8), 6349–6358. (<a
href="https://doi.org/10.1007/s00521-021-06763-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various types of electric fields contained in the laboratory and astrophysical plasma cause a Stark broadening of spectral lines in plasma. Therefore, a large number of spectroscopic diagnostics of laboratory and astrophysical plasma are based on experimental and theoretical studies of Stark broadening of spectral lines in plasma. The topic of the present investigation is the Stark broadening caused by free electrons in plasma and its dependence on certain atomic parameters using a new method based on the machine learning (ML) approach. Analysis of empirical data on atomic parameters was done by ML algorithms with more success that it was previously done by classical methods of data analysis. The correlation parameter obtained by artificial intelligence (AI) is slightly better than the one obtained by classical methods, but the scope of application is much wider. AI conclusions are applicable to any physical system while conclusions made by classical analysis are applicable only to a small portion of these systems. ML algorithms successfully identified quantum nature by analyzing atomic parameters. The biggest issue of classical analysis, which is infinite spectral line broadening for high ionization stages, was resolved by AI with a saturation tendency.},
  archive      = {J_NCA},
  author       = {Tapalaga, Irinel and Traparić, Ivan and Trklja Boca, Nora and Purić, Jagoš and Dojčinović, Ivan P.},
  doi          = {10.1007/s00521-021-06763-4},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6349-6358},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stark spectral line broadening modeling by machine learning algorithms},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving question answering over incomplete knowledge
graphs with relation prediction. <em>NCA</em>, <em>34</em>(8),
6331–6348. (<a
href="https://doi.org/10.1007/s00521-021-06736-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale knowledge graphs (KGs) play a critical role in question answering over KGs (KGs-QA). Despite of large scale, KGs suffer from incompleteness, which has fueled a lot of research on relation prediction. Since existing researches of relation prediction process each triple independently, the hidden relations which are inherently present can not be captured. Complementarily, to simultaneously capture both entity features and relation features in a given entity’s neighborhood, an entity importance estimation network of attention-based graph embedding is proposed, which consists of the attention-based graph embedding module and the entity importance estimation module. Firstly, the new embedding of an entity from its n-hop neighbor is learned by an attention-based graph embedding module. Then, the learned new embedding is integrated into the entity importance estimation module to find entities of high importance in n-hop neighbors of the central entity. Finally, multi-hop relations are encapsulated and an auxiliary edge of n-hop neighbors is introduced, which realizes the relation prediction task. To the best our knowledge, we are the first to realize KGs-QA while realizing relation prediction, which alleviates the phenomenon of missing relations and the low-precision problem of KGs-QA. On the SQ datasets, the proposed method obtains a high F1 score (49.3\%) in 10\% missing relation, compared to QASE and MCCNNs with F1 scores of 44.2\% and 46.3\%, respectively.},
  archive      = {J_NCA},
  author       = {Zhao, Fen and Li, Yinguo and Hou, Jie and Bai, Ling},
  doi          = {10.1007/s00521-021-06736-7},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6331-6348},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving question answering over incomplete knowledge graphs with relation prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective learner performance-based behavior algorithm
with five multi-objective real-world engineering problems. <em>NCA</em>,
<em>34</em>(8), 6307–6329. (<a
href="https://doi.org/10.1007/s00521-021-06811-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a new multi-objective optimization algorithm called multi-objective learner performance-based behavior algorithm is proposed. The proposed algorithm is based on the process of moving graduated students from high school to college. The proposed technique produces a set of non-dominated solutions. To test the ability and efficacy of the proposed multi-objective algorithm, it is applied to a group of benchmarks and five real-world engineering optimization problems. Several widely used metrics are employed in the quantitative statistical comparisons. The proposed algorithm is compared with three multi-objective algorithms: Multi-Objective Water Cycle Algorithm (MOWCA), Non-dominated Sorting Genetic Algorithm (NSGA-II), and Multi-Objective Dragonfly Algorithm (MODA). The produced results for the benchmarks and engineering problems show that in general the accuracy and diversity of the proposed algorithm are better compared to the MOWCA and MODA. However, the NSGA-II outperformed the proposed work in some of the cases and showed better accuracy and diversity. Nevertheless, in problems, such as coil compression spring design problem, the quality of solutions produced by the proposed algorithm outperformed all the participated algorithms. Moreover, in regard to the processing time, the proposed work provided better results compared with all the participated algorithms.},
  archive      = {J_NCA},
  author       = {Rahman, Chnoor M. and Rashid, Tarik A. and Ahmed, Aram Mahmood and Mirjalili, Seyedali},
  doi          = {10.1007/s00521-021-06811-z},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6307-6329},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective learner performance-based behavior algorithm with five multi-objective real-world engineering problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A twin-decoder structure for incompressible laminar flow
reconstruction with uncertainty estimation around 2D obstacles.
<em>NCA</em>, <em>34</em>(8), 6289–6305. (<a
href="https://doi.org/10.1007/s00521-021-06784-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few years, deep learning methods have proved to be of great interest for the computational fluid dynamics community, especially when used as surrogate models, either for flow reconstruction, turbulence modeling, or for the prediction of aerodynamic coefficients. Overall exceptional levels of accuracy have been obtained but the robustness and reliability of the proposed approaches remain to be explored, particularly outside the confidence region defined by the training dataset. In this contribution, we present an autoencoder architecture with twin decoder for incompressible laminar flow reconstruction with uncertainty estimation around 2D obstacles. The proposed architecture is trained over a dataset composed of numerically-computed laminar flows around 12,000 random shapes, and naturally enforces a quasi-linear relation between a geometric reconstruction branch and the flow prediction decoder. Based on this feature, two uncertainty estimation processes are proposed, allowing either a binary decision (accept or reject prediction), or proposing a confidence interval along with the flow quantities prediction (u, v, p). Results over dataset samples as well as unseen shapes show a strong positive correlation of this reconstruction score to the mean-squared error of the flow prediction. Such approaches offer the possibility to warn the user of trained models when provided input shows too large deviation from the training data, making the produced surrogate model conservative for fast and reliable flow prediction.},
  archive      = {J_NCA},
  author       = {Chen, J. and Viquerat, J. and Heymes, F. and Hachem, E.},
  doi          = {10.1007/s00521-021-06784-z},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6289-6305},
  shortjournal = {Neural Comput. Appl.},
  title        = {A twin-decoder structure for incompressible laminar flow reconstruction with uncertainty estimation around 2D obstacles},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid metaheuristic approach using random forest and
particle swarm optimization to study and evaluate backbreak in open-pit
blasting. <em>NCA</em>, <em>34</em>(8), 6273–6288. (<a
href="https://doi.org/10.1007/s00521-021-06776-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backbreak is a rock fracture problem that exceeds the limits of the last row of holes in an explosion operation. Excessive backbreak increases operational costs and also poses a threat to mine safety. In this regard, a new hybrid intelligence approach based on random forest (RF) and particle swarm optimization (PSO) is proposed for predicting backbreak with high accuracy to reduce the unsolicited phenomenon induced by backbreak in open-pit blasting. A data set of 234 samples with six input parameters including special drilling (SD), spacing (S), burden (B), hole length (L), stemming (T) and powder factor (PF) and one output parameter backbreak (BB) is set up in this study. Seven input combinations (one with six parameters, six with five parameters) are built to generate the optimal prediction model. The PSO algorithm is integrated with the RF algorithm to find the optimal hyper-parameters of each model and the fitness function, which is the mean absolute error (MAE) of ten cross-validations. The performance capacities of the optimal models are assessed using MAE, root-mean-square error (RMSE), Pearson correlation coefficient (R2) and mean absolute percentage error (MAPE). Findings demonstrated that the PSO–RF model combining L–S–B–T–PF with MAE of 0.0132 and 0.0568, RMSE of 0.0811 and 0.1686, R2 of 0.9990 and 0.9961 and MAPE of 0.0027 and 0.0116 in training and testing phases, respectively, has optimal prediction performance. The optimal PSO–RF models were compared with the classical artificial neural network, RF, genetic programming, support vector machine and convolutional neural network models and show that the PSO–RF model has superiority in predicting backbreak. The Gini index of each input variable has also been calculated in the RF model, which was 31.2 (L), 23.1 (S), 27.4 (B), 36.6 (T), 23.4 (PF) and 16.9 (SD), respectively.},
  archive      = {J_NCA},
  author       = {Dai, Yong and Khandelwal, Manoj and Qiu, Yingui and Zhou, Jian and Monjezi, M. and Yang, Peixi},
  doi          = {10.1007/s00521-021-06776-z},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6273-6288},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid metaheuristic approach using random forest and particle swarm optimization to study and evaluate backbreak in open-pit blasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Short-term forecasting of the italian load demand during the
easter week. <em>NCA</em>, <em>34</em>(8), 6257–6271. (<a
href="https://doi.org/10.1007/s00521-021-06797-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In electrical load forecasting the prediction of the demand during holidays is a challenging task because of the drift of the demand profile with respect to normal working days. Among holidays, the Easter Week is peculiar because it is a moving holiday: though the weekdays are always the same, it may fall anywhere between March and April. The main contribution of this work is to develop a short-term day-ahead predictor for the load demand during the Easter Week using the Italian data as benchmark. The proposed strategy uses a Gaussian Process (GP) estimator to track the difference between the target Easter Week and an average Easter Week load profile. Differently from usual GP approaches that employ ‘canonical’ kernels, we propose and validate the use of a tailored kernel based on the nonstationary autocovariance of the time series, whose estimation is made possible by the availability of historical load series starting from 1990. On the Italian data the novel approach outperforms both GP methods based on canonical kernels and the forecasts provided by the Italian Transmission System Operator (TSO) Terna. The scarce correlation between the prediction residuals of the novel technique and those of the Terna forecaster motivated the use of aggregation strategies that yielded a further improvement. Indeed, all the main error indexes exhibit a decrease in several tens percent over Terna. The proposed approach is of general validity if, thanks to the availability of historical datasets, the kernel can be tailored to the statistical properties of the time series.},
  archive      = {J_NCA},
  author       = {Incremona, Alessandro and De Nicolao, Giuseppe},
  doi          = {10.1007/s00521-021-06797-8},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6257-6271},
  shortjournal = {Neural Comput. Appl.},
  title        = {Short-term forecasting of the italian load demand during the easter week},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Accelerated duality-aware correlation filters for visual
tracking. <em>NCA</em>, <em>34</em>(8), 6241–6256. (<a
href="https://doi.org/10.1007/s00521-021-06794-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correlation filters (CF) based tracking methods have attracted considerable attentions for their competitive performance. However, the inherent issues of boundary effect and filter degradation, as well as the scale variation, degrade the tracking accuracy. In addition, the frame-by-frame updating strategy limits the tracking speed, especially in those deep features-based CF trackers. To address these issues, we propose a novel tracker, namely Accelerated Duality-aware Correlation Filters (ADCF), in this paper. In the proposed tracker, dual correlation filters, i.e., translation filter and scale filter, are designed for target localization and scale estimation, respectively. A spatio-temporal regularization term is employed to suppress the boundary effect and filter degradation. Moreover, a model updating strategy named Sparse learning-based Average Peak-to-Correlation Energy (S-APCE) is proposed to accelerate the tracking speed. Finally, an Alternating Direction Method of Multipliers (ADMM) formulation is developed to optimize the ADCF efficiently. Extensive experimental results over six tracking benchmarks prove that the proposed tracker outperforms the state-of-the-art (SOTA) trackers in tracking accuracy and speed.},
  archive      = {J_NCA},
  author       = {Xu, Libin and Gao, Mingliang and Liu, Zheng and Li, Qilei and Jeon, Gwanggil},
  doi          = {10.1007/s00521-021-06794-x},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6241-6256},
  shortjournal = {Neural Comput. Appl.},
  title        = {Accelerated duality-aware correlation filters for visual tracking},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A real-time adaptive network intrusion detection for
streaming data: A hybrid approach. <em>NCA</em>, <em>34</em>(8),
6227–6240. (<a
href="https://doi.org/10.1007/s00521-021-06786-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aimed at improving the performance of classifiers when trained to identify signatures of unknown attacks. Furthermore, this paper addresses the following objectives: (1) To establish and examine most commonly used classifiers in the implementation of IDSs (KNN and Bayes); (2) To evaluate the performance of the individual classifiers independently; and (3) To model a hybrid classifier based on the strengths of the two classifiers. This study adopted a quantitative methodology of collecting and interpreting data. The study had used the NSL-KDD and the original KDD 1999 datasets. This paper evaluated the devised mechanisms over virtualised networked environments and traffic workloads. SVM was used for detecting cycle numbers whereas coefficients and signal shifts were used for completing period detection. Also, this paper has presented rare data for detecting anomalies. Anticipated events that have not occurred and unanticipated events can be detected at various sampling frequencies based on a hybrid approach since no one has proposed a hybrid approach for detecting anomalies. This paper has ranked features from a network traffic database based on a combination of feature selection wrappers and filers and determined that 16 features showed a strong contribution to the anomaly detection task.},
  archive      = {J_NCA},
  author       = {Saeed, Mozamel M.},
  doi          = {10.1007/s00521-021-06786-x},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6227-6240},
  shortjournal = {Neural Comput. Appl.},
  title        = {A real-time adaptive network intrusion detection for streaming data: A hybrid approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive consensus tracking control of strict-feedback
nonlinear multi-agent systems with unknown dynamic leader. <em>NCA</em>,
<em>34</em>(8), 6215–6226. (<a
href="https://doi.org/10.1007/s00521-021-06801-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An adaptive leader-following consensus tracking control approach is considered for strict-feedback nonlinear multi-agent systems, which contain unknown parameters and dynamic leader with both input and output. An adaptive tracking controller and adaptive consensus controllers are designed for nonlinear leader agent and follower agents by backstepping control technique, respectively. Compared to the control methods in the existing literature, only a few adaptive laws need to be constructed by tuning function approach, and the number of design parameters is greatly reduced also. Furthermore, through the Lyapunov stability principle, the tracking error and consensus errors asymptotically converge to zero, and other signals in nonlinear multi-agent systems are bounded. A simulation example shows the effectiveness and feasibility of the proposed control method at the end of this paper.},
  archive      = {J_NCA},
  author       = {Cui, Yang and Liu, Xiaoping},
  doi          = {10.1007/s00521-021-06801-1},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6215-6226},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive consensus tracking control of strict-feedback nonlinear multi-agent systems with unknown dynamic leader},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). “What-where” sparse distributed invariant representations of
visual patterns. <em>NCA</em>, <em>34</em>(8), 6207–6214. (<a
href="https://doi.org/10.1007/s00521-021-06759-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although modern deep learning approaches have achieved astounding results in most visual pattern recognition tasks, they do it using large datasets of labeled data. Besides the fact that, in many applications, such labels are costly to obtain, the need for them is not observed in a biologically intelligent machine like the human brain. “What-Where” sets were proposed as a way to represent visual patterns in a manipulatable manner, where two-dimensional geometric transformations can be exploited to increase invariance, and thus reduce the need for large amounts of training data. However, the cornerstone of classification using these sets is a similarity measure that implicates a time-consuming computation due to the unstructured nature of sets. In this work, we propose a grid-based coding strategy to represent the sets as sparse binary vectors. By doing so, we achieve three main advantages: first, leveraging pointer-coding of active bits, we reduce the time complexity of the similarity computation from quadratic to linear in the number of elements of the smaller set being compared; second, we use the theoretical framework of sparse representations to justify the classification robustness exhibited in the original work; third, we bring the model under the widely accepted biological constraint that populations of neurons in the brain code sparse representations.},
  archive      = {J_NCA},
  author       = {Sa-Couto, Luis and Wichert, Andreas},
  doi          = {10.1007/s00521-021-06759-0},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6207-6214},
  shortjournal = {Neural Comput. Appl.},
  title        = {“What-where” sparse distributed invariant representations of visual patterns},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel early warning strategy for right-turning blind zone
based on vulnerable road users detection. <em>NCA</em>, <em>34</em>(8),
6187–6206. (<a
href="https://doi.org/10.1007/s00521-021-06800-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blind zone detection of vehicles, as an essential function of Advanced Driver Assistance System, can effectively reduce the occurrence of traffic accidents and has attracted unprecedented attention. This paper develops an active collision avoidance method for right-turning blind zone, based on vulnerable road users (VRUs) detection. The proposed strategy consists of three main steps. First of all, an improved YOLOv4-tiny algorithm based on deep learning, combining two optimization strategies, is proposed to detect VRUs in right-turning blind zone more accurately and robustly. Secondly, a distance measurement method via monocular camera is used for ranging the distance between the host vehicle and the detected VRUs. Finally, a simple and effective vehicle active speed control algorithm is presented, based on distance and vehicle speed information, to provide early warning to the driver. This method was tested in a large driving dataset and in various actual driving situations. Experimental results show that, compared with the lightweight state-of-the-art methods, the improved YOLOv4-tiny has the best detection accuracy for VRUs and can stabilize at a detection speed of 50FPS on 1920*1080 resolution video, and that the measured distance error remains within 4\%. A simulation test also proves that the proposed active speed control algorithm can effectively deliver early warning to drivers and avoid traffic accidents.},
  archive      = {J_NCA},
  author       = {Han, Lei and Zheng, Peng and Li, Haobo and Chen, Jiangfan and Hua, Zexi and Zhang, Zutao},
  doi          = {10.1007/s00521-021-06800-2},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6187-6206},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel early warning strategy for right-turning blind zone based on vulnerable road users detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven wind turbine wake modeling via probabilistic
machine learning. <em>NCA</em>, <em>34</em>(8), 6171–6186. (<a
href="https://doi.org/10.1007/s00521-021-06799-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind farm design primarily depends on the variability of the wind turbine wake flows to the atmospheric wind conditions and the interaction between wakes. Physics-based models that capture the wake flow field with high-fidelity are computationally very expensive to perform layout optimization of wind farms, and, thus, data-driven reduced-order models can represent an efficient alternative for simulating wind farms. In this work, we use real-world light detection and ranging (LiDAR) measurements of wind-turbine wakes to construct predictive surrogate models using machine learning. Specifically, we first demonstrate the use of deep autoencoders to find a low-dimensional latent space that gives a computationally tractable approximation of the wake LiDAR measurements. Then, we learn the mapping between the parameter space and the (latent space) wake flow fields using a deep neural network. Additionally, we also demonstrate the use of a probabilistic machine learning technique, namely, Gaussian process modeling, to learn the parameter-space-latent-space mapping in addition to the epistemic and aleatoric uncertainty in the data. Finally, to cope with training large datasets, we demonstrate the use of variational Gaussian process models that provide a tractable alternative to the conventional Gaussian process models for large datasets. Furthermore, we introduce the use of active learning to adaptively build and improve a conventional Gaussian process model predictive capability. Overall, we find that our approach provides accurate approximations of the wind-turbine wake flow field that can be queried at an orders-of-magnitude cheaper cost than those generated with high-fidelity physics-based simulations.},
  archive      = {J_NCA},
  author       = {Ashwin Renganathan, S. and Maulik, Romit and Letizia, Stefano and Iungo, Giacomo Valerio},
  doi          = {10.1007/s00521-021-06799-6},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6171-6186},
  shortjournal = {Neural Comput. Appl.},
  title        = {Data-driven wind turbine wake modeling via probabilistic machine learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Event-triggered leader-following synchronization of delayed
dynamical networks with intermittent coupling. <em>NCA</em>,
<em>34</em>(8), 6163–6170. (<a
href="https://doi.org/10.1007/s00521-021-06805-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates the synchronization problem of dynamical networks with delayed nodal dynamics under a leader-following framework, where the topological structure is directed, and the inter-couplings are allowed to be intermittent. By tailoring certain simple triggering condition, an event-triggered control protocol is designed to reduce the redundant execution of the control, and some sufficient conditions in terms of the time average of the control gain over one single period are established for reaching synchronization despite the intermittency of the inter-coupling. Moreover, the largest admissible delay is estimated. Interestingly, our theoretical result is applicable to situations with typical coupling strength functions for delayed nodal dynamics, such as the piece-wise linear function and quadratic function. Some numerical examples are finally given to demonstrate the validity of the theoretical result.},
  archive      = {J_NCA},
  author       = {Sun, Mei and Lyu, Deguang and Jia, Qiang},
  doi          = {10.1007/s00521-021-06805-x},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6163-6170},
  shortjournal = {Neural Comput. Appl.},
  title        = {Event-triggered leader-following synchronization of delayed dynamical networks with intermittent coupling},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-scale strip pooling feature aggregation network for
cloud and cloud shadow segmentation. <em>NCA</em>, <em>34</em>(8),
6149–6162. (<a
href="https://doi.org/10.1007/s00521-021-06802-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud and cloud shadow detection is a crucial issue in remote sensing image processing. The backgrounds of clouds and cloud shadows are mostly complex in actual remote sensing images. Traditional methods are easily affected by ground object interference, noise interference and other factors, and problems such as missing detection and false detection are prone to occur in the process of cloud detection. In addition, due to insufficient edge information extraction capabilities, traditional methods have very rough segmentation results for cloud and cloud shadow boundaries. In order to improve the accuracy of cloud and cloud shadow detection, a Multi-scale Strip Pooling Feature Aggregation Network is proposed. This method uses the residual network as the backbone to extract different levels of semantic information. And, in order to improve the multi-scale information extraction ability of the network, an Improved Pyramid Pooling module is introduced to mine deep multi-scale semantic information. Then, the Mutual Fusion module is used to guide the fusion of different levels of information. Finally, in view of the problem of rough segmentation boundaries in traditional methods, the Strip Boundary Refinement module is used to repair the boundary information of clouds and cloud shadows. The experimental results conducted on the datasets collected by Landsat-8, Sentinel-2 and a public dataset HRC_WHU show that this method is superior to the existing methods.},
  archive      = {J_NCA},
  author       = {Lu, Chen and Xia, Min and Lin, Haifeng},
  doi          = {10.1007/s00521-021-06802-0},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6149-6162},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-scale strip pooling feature aggregation network for cloud and cloud shadow segmentation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved equilibrium optimizer for optimal placement of
photovoltaic systems in radial distribution power networks.
<em>NCA</em>, <em>34</em>(8), 6119–6148. (<a
href="https://doi.org/10.1007/s00521-021-06779-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an improved equilibrium optimizer (IEO) for selecting the most suitable location and the most effective size of photovoltaic systems (PVSs) in radial distribution power networks (RDPNs). The objective of the study is to reduce the total active power loss on all distribution lines of RDPNs while constraints regarding node voltage limits, branch current limits and active and reactive power balance must be satisfied exactly. IEO is first developed in the paper by modifying the newly generated solution mechanism of the conventional equilibrium optimizer (EO). In addition to the proposed IEO method and EO, two previously published methods including modified equilibrium optimizer (MEO) and adaptive equilibrium optimizer (AEO) are also implemented for three study cases with one, two and three PVSs placed in the IEEE 33-node and 85-node RDPNs. Compared to the base systems, the proposed IEO can reach the loss reduction with 65.5\% for the IEEE 33-node RDPN and 52.96\% for the IEEE 85-node RDPN. Total loss, loss reduction and computation speed comparisons indicate that the proposed IEO outperforms EO, MEO, AEO and other previously published methods shown in the literature for approximately all study cases. As a result, it concludes that the proposed IEO is a favorable optimization algorithm applied to the problem of PVSs placement in RDPNs.},
  archive      = {J_NCA},
  author       = {Nguyen, Thang Trung and Nguyen, Thuan Thanh and Duong, Minh Quan},
  doi          = {10.1007/s00521-021-06779-w},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6119-6148},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved equilibrium optimizer for optimal placement of photovoltaic systems in radial distribution power networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view multi-label-based online method with threefold
correlations and dynamic updating multi-region. <em>NCA</em>,
<em>34</em>(8), 6097–6117. (<a
href="https://doi.org/10.1007/s00521-021-06766-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised real-time generation multi-view multi-label data sets are widely encountered in practical applications. A key issue is how to process the data whose information including labels or features may be lost due to some unforeknowable factors. In our work, we develop a multi-view multi-label-based online method with threefold correlations and dynamic updating multi-region (M2CR) to solve this issue. First, we adopt three kinds of correlations between features and labels to recover the missing information. Second, we process new arriving instances with dynamic updating multi-region. Experiments on classical multi-view multi-label data sets validate the effectiveness of M2CR in terms of classification, time performance, convergence, etc.},
  archive      = {J_NCA},
  author       = {Zhu, Changming and Guo, Shuaiping and Cao, Dujuan and Zhou, YiTing and Miao, Duoqian and Pedrycz, Witold},
  doi          = {10.1007/s00521-021-06766-1},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6097-6117},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-view multi-label-based online method with threefold correlations and dynamic updating multi-region},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RIECNN: Real-time image enhanced CNN for traffic sign
recognition. <em>NCA</em>, <em>34</em>(8), 6085–6096. (<a
href="https://doi.org/10.1007/s00521-021-06762-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic sign recognition plays a crucial role in the development of autonomous cars to reduce the accident rate and promote road safety. It has been a necessity to address traffic signs that are affected significantly by the environment as well as poor real-time performance for deep-learning state-of-the-art algorithms. In this paper, we introduce Real-Time Image Enhanced CNN (RIECNN) for Traffic Sign Recognition. RIECNN is a real-time, novel approach that tackles multiple, diverse traffic sign datasets, and out-performs the state-of-the-art architectures in terms of recognition rate and execution time. Experiments are conducted using the German Traffic Sign Benchmark (GTSRB), the Belgium Traffic Sign Classification (BTSC), and the Croatian Traffic Sign (rMASTIF) benchmark. Experimental results show that our approach has achieved the highest recognition rate for all Benchmarks, achieving a recognition accuracy of 99.75\% for GTSRB, 99.25\% for BTSC and 99.55\% for rMASTIF. In terms of latency and meeting the real-time constraint, the pre-processing time and inference time together do not exceed 1.3 ms per image. Not only have our proposed approach achieved remarkably high accuracy with real-time performance, but it also demonstrated robustness against traffic sign recognition challenges such as brightness and contrast variations in the environment.},
  archive      = {J_NCA},
  author       = {Abdel-Salam, Reem and Mostafa, Rana and Abdel-Gawad, Ahmed H.},
  doi          = {10.1007/s00521-021-06762-5},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6085-6096},
  shortjournal = {Neural Comput. Appl.},
  title        = {RIECNN: Real-time image enhanced CNN for traffic sign recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Open set task augmentation facilitates generalization of
deep neural networks trained on small data sets. <em>NCA</em>,
<em>34</em>(8), 6067–6083. (<a
href="https://doi.org/10.1007/s00521-021-06753-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many application scenarios for image recognition require learning of deep networks from small sample sizes in the order of a few hundred samples per class. Then, avoiding overfitting is critical. Common techniques to address overfitting are transfer learning, reduction of model complexity and artificial enrichment of the available data by, e.g., data augmentation. A key idea proposed in this paper is to incorporate additional samples into the training that do not belong to the classes of the target task. This can be accomplished by formulating the original classification task as an open set classification task. While the original closed set classification task is not altered at inference time, the recast as open set classification task enables the inclusion of additional data during training. Hence, the original closed set classification task is augmented with an open set task during training. We therefore call the proposed approach open set task augmentation. In order to integrate additional task-unrelated samples into the training, we employ the entropic open set loss originally proposed for open set classification tasks and also show that similar results can be obtained with a modified sum of squared errors loss function. Learning with the proposed approach benefits from the integration of additional “unknown” samples, which are often available, e.g., from open data sets, and can then be easily integrated into the learning process. We show that this open set task augmentation can improve model performance even when these additional samples are rather few or far from the domain of the target task. The proposed approach is demonstrated on two exemplary scenarios based on subsets of the ImageNet and Food-101 data sets as well as with several network architectures and two loss functions. We further shed light on the impact of the entropic open set loss on the internal representations formed by the networks. Open set task augmentation is particularly valuable when no additional data from the target classes are available—a scenario often faced in practice.},
  archive      = {J_NCA},
  author       = {Zai El Amri, Wadhah and Reinhart, Felix and Schenck, Wolfram},
  doi          = {10.1007/s00521-021-06753-6},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6067-6083},
  shortjournal = {Neural Comput. Appl.},
  title        = {Open set task augmentation facilitates generalization of deep neural networks trained on small data sets},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An advanced form-finding of tensegrity structures aided with
noise-tolerant zeroing neural network. <em>NCA</em>, <em>34</em>(8),
6053–6066. (<a
href="https://doi.org/10.1007/s00521-021-06745-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A high-efficiency form-finding algorithm is crucially important for finding a stabilized tensegrity structure. In this paper, a modified Broyden-Fletcher-Goldfarb-Shanno noise-tolerant zeroing neural network (MBFGS-NTZNN) form-finding approach is developed and investigated for the form-finding problems of tensegrity systems. A modified BFGS algorithm (MBFGS) is employed to solve the irreversibility of the Hessian matrix, which could avoid the non-positive definite circumstance of the stiffness matrix. Additionally, the approach could be utilized to make a reduction in algorithm calculation complexity. Moreover, to find a group of suitable nodal coordinates, a zeroing neural network (ZNN) based NTZNN is considered to suppress the noise, which may include rounding errors and external disturbance during the form-finding process. Besides, the 0-stable and global convergence under the pollution of noise are verified. Eventually, numerical simulations and an application example are conducted to ascertain the superiority and availability of the MBFGS-NTZNN algorithm in the fields of form-finding.},
  archive      = {J_NCA},
  author       = {Sun, Zhongbo and Zhao, Liming and Liu, Keping and Jin, Long and Yu, Junzhi and Li, Chunxu},
  doi          = {10.1007/s00521-021-06745-6},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6053-6066},
  shortjournal = {Neural Comput. Appl.},
  title        = {An advanced form-finding of tensegrity structures aided with noise-tolerant zeroing neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pose-invariant face recognition with multitask cascade
networks. <em>NCA</em>, <em>34</em>(8), 6039–6052. (<a
href="https://doi.org/10.1007/s00521-021-06690-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a face recognition method is proposed for face under pose variations using a multitask convolutional neural network (CNN). Furthermore, a pose estimation method followed by a face identification module is combined in a cascaded structure and used separately. In the presence of various facial expressions as well as low illuminations, datasets that include separated face poses can enhance the robustness of face recognition. The proposed method relies on a pose estimation module using a convolutional neural network model and trained on three categories of face image capture such as the left side, frontal, and right side. Second, three CNN models are used for face identification according to the estimated pose. The Left-CNN model, Front-CNN model, and Right-CNN model are used to identify the face for the left, frontal, and right pose of the face, respectively. Because face images may contain some useless information (e.g., background content), we propose a skin-based face segmentation method using structure–texture decomposition and the color-invariant descriptor. Experimental evaluation has been conducted using the proposed cascade-based face recognition system that consists of the aforementioned steps (i.e., pose estimation, face segmentation, and face identification) and is assessed on four different datasets and its superiority has been shown over related state-of-the-art techniques. Results reveal the contribution of the separate representation, skin segmentation, and pose estimation in the recognition robustness.},
  archive      = {J_NCA},
  author       = {Elharrouss, Omar and Almaadeed, Noor and Al-Maadeed, Somaya and Khelifi, Fouad},
  doi          = {10.1007/s00521-021-06690-4},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6039-6052},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pose-invariant face recognition with multitask cascade networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neighbourhood component analysis and deep feature-based
diagnosis model for middle ear otoscope images. <em>NCA</em>,
<em>34</em>(8), 6027–6038. (<a
href="https://doi.org/10.1007/s00521-021-06810-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Otitis media (OM), known as inflammation of the middle ear, is a condition especially seen in children. To carry out a definitive diagnosis of the discomfort that manifests itself with various symptoms such as pain in the ear, fever, and discharge, the eardrum in the middle ear should be examined by a specialist. In this study, a convolution neural network was used for feature extraction from middle ear otoscope images to diagnose different types of OM. These features were extracted using AlexNet, VGG-16, GoogLeNet, ResNet-50 models. The deep features extracted from these models were combined into a new deep feature vector. This feature vector consisting of 4000 deep features was examined, and the most relevant 222 deep features were selected from this large feature set by using the neighbourhood component analysis. In this case, the number of features was decreased and a more effective feature set was obtained. In the next stage of this experimental study, this new feature set was applied as the input to the support vector machine. As a result of the experimental study, an accuracy rate of 79.02\% was achieved. The results point out that the use of deep features in detecting OM provides efficient results, and the proposed approach is beneficial in reducing the number of deep features as well as achieving better classification results.},
  archive      = {J_NCA},
  author       = {Başaran, Erdal and Cömert, Zafer and Çelik, Yüksel},
  doi          = {10.1007/s00521-021-06810-0},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6027-6038},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neighbourhood component analysis and deep feature-based diagnosis model for middle ear otoscope images},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). YOLO-SLAM: A semantic SLAM system towards dynamic
environment with geometric constraint. <em>NCA</em>, <em>34</em>(8),
6011–6026. (<a
href="https://doi.org/10.1007/s00521-021-06764-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous localization and mapping (SLAM), as one of the core prerequisite technologies for intelligent mobile robots, has attracted much attention in recent years. However, the traditional SLAM systems rely on the static environment assumption, which becomes unstable for the dynamic environment and further limits the real-world practical applications. To deal with the problem, this paper presents a dynamic-environment-robust visual SLAM system named YOLO-SLAM. In YOLO-SLAM, a lightweight object detection network named Darknet19-YOLOv3 is designed, which adopts a low-latency backbone to accelerate and generate essential semantic information for the SLAM system. Then, a new geometric constraint method is proposed to filter dynamic features in the detecting areas, where dynamic features can be distinguished by utilizing the depth difference with Random Sample Consensus (RANSAC). YOLO-SLAM composes the object detection approach and the geometric constraint method in a tightly coupled manner, which is able to effectively reduce the impact of dynamic objects. Experiments are conducted on the challenging dynamic sequences of TUM dataset and Bonn dataset to evaluate the performance of YOLO-SLAM. The results demonstrate that the RMSE index of absolute trajectory error can be significantly reduced to 98.13\% compared with ORB-SLAM2 and 51.28\% compared with DS-SLAM, indicating that YOLO-SLAM is able to effectively improve stability and accuracy in the highly dynamic environment.},
  archive      = {J_NCA},
  author       = {Wu, Wenxin and Guo, Liang and Gao, Hongli and You, Zhichao and Liu, Yuekai and Chen, Zhiqiang},
  doi          = {10.1007/s00521-021-06764-3},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6011-6026},
  shortjournal = {Neural Comput. Appl.},
  title        = {YOLO-SLAM: A semantic SLAM system towards dynamic environment with geometric constraint},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Utilizing deep learning models in CSI-based human activity
recognition. <em>NCA</em>, <em>34</em>(8), 5993–6010. (<a
href="https://doi.org/10.1007/s00521-021-06787-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, channel state information (CSI) in WiFi 802.11n has been increasingly used to collect data pertaining to human activity. Such raw data are then used to enhance human activity recognition. Activities such as lying down, falling, walking, running, sitting down, and standing up can now be detected with the use of information collected through CSI. Human activity recognition has a multitude of applications, such as home monitoring of patients. Four deep learning models are presented in this paper, namely: a convolution neural network (CNN) with a Gated Recurrent Unit (GRU); a CNN with a GRU and attention; a CNN with a GRU and a second CNN, and a CNN with Long Short-Term Memory (LSTM) and a second CNN. Those models were trained to perform Human Activity Recognition (HAR) using CSI amplitude data collected by a CSI tool. Experiments conducted to test the efficacy of these models showed superior results compared with other recent approaches. This enhanced performance of our models may be attributable the ability of our models to make full use of available data and to extract all data features, including high dimensionality and time sequence. The highest average recognition accuracy reached by the proposed models was achieved by the CNN-GRU, and the CNN-GRU with attention models, standing at 99.31\% and 99.16\%, respectively. In addition, the performance of the models was evaluated for unseen CSI data by training our models using a random split-of-dataset method (70\% training and 30\% testing). Our models achieved impressive results with accuracies reaching 100\% for nearly all activities. For the lying down activity, accuracy obtained from the CNN-GRU model stood at 99.46\%; slightly higher than the 99.05\% achieved by the CNN-GRU with attention model. This confirmed the robustness of our models against environmental changes.},
  archive      = {J_NCA},
  author       = {Shalaby, Eman and ElShennawy, Nada and Sarhan, Amany},
  doi          = {10.1007/s00521-021-06787-w},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5993-6010},
  shortjournal = {Neural Comput. Appl.},
  title        = {Utilizing deep learning models in CSI-based human activity recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NeuroVision: Perceived image regeneration using cProGAN.
<em>NCA</em>, <em>34</em>(8), 5979–5991. (<a
href="https://doi.org/10.1007/s00521-021-06774-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the reaction of the human brain to visual stimuli is active research for the past few years due to its wide application in Brain-Computer Interaction. Brain signals generated through this has high information content about the perceived scenes and therefore can be used to regenerate the perceived images. But the regeneration of high-quality perceived images using brain signals is a big challenge. With advancements in Generative Adversarial Networks (GANs) in Deep Learning, seen images can now be regenerated in high-quality using visual cues from brain signals. Electroencephalography (EEG) is a cost-effective way to record brain signals. This paper proposes an EEG classifier followed by conditional Progressive Growing of GANs to regenerate perceived images using EEG. After training and testing on publicly available dataset, EEG Classifier was able to achieve 98.8\% test accuracy, and cProGAN achieved an inception score (IS) of 5.15 surpassing the previous best 5.07 IS.},
  archive      = {J_NCA},
  author       = {Khare, Sanchita and Choubey, Rajiv Nayan and Amar, Loveleen and Udutalapalli, Venkanna},
  doi          = {10.1007/s00521-021-06774-1},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5979-5991},
  shortjournal = {Neural Comput. Appl.},
  title        = {NeuroVision: Perceived image regeneration using cProGAN},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual and language semantic hybrid enhancement and
complementary for video description. <em>NCA</em>, <em>34</em>(8),
5959–5977. (<a
href="https://doi.org/10.1007/s00521-021-06733-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a fundamental task of computer vision to describe and express the visual content of a video in natural language, which not only highly summarizes the video, but also presents the visual information in description sentence with reasonable pattern, correct grammars and decent words. The task has wide potential application in early education, visual aids, automatic interpretation and human–machine environment development. Nowadays, there are a variety of effective models for video description with the help of deep learning. However, the visual or language semantics is frequently mined alone, and the visual and language information cannot be complemented each other, resulting in that the accuracy and semantics of the generated sentence are difficult to be further improved. Facing the challenge, a framework for video description with visual and language semantic hybrid enhancing and complementary is proposed in this work. In detail, the language and visual semantics enhancing branches are integrated with the multimodal feature-based module firstly. Then a multi-objective jointly training strategy is employed for model optimization. Finally, the output probabilities from the three branches are fused with the weighted average for word prediction at each time step. Additionally, the language and visual semantics enhancing-based deep fusion modules are combined together with the same jointly training and sequential probabilities fusion for further performance improving. The experimental results on MSVD and MSR-VTT2016 datasets demonstrate the effectiveness of the proposed models, with the performance of proposed models outperforming the baseline model Deep-Glove (which is denoted as E-LSC for simplification and comparison) greatly and achieving competitive performance compared to the state-of-the-art methods. In particular, the BLEU4 and CIDEr reach 52.4 and 81.5, respectively, on MSVD with the proposed $$\hbox {HE-VLSC}^\#$$ model.},
  archive      = {J_NCA},
  author       = {Tang, Pengjie and Tan, Yunlan and Luo, Wenlang},
  doi          = {10.1007/s00521-021-06733-w},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5959-5977},
  shortjournal = {Neural Comput. Appl.},
  title        = {Visual and language semantic hybrid enhancement and complementary for video description},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic detection of outliers and the number of clusters
in k-means clustering via chebyshev-type inequalities. <em>NCA</em>,
<em>34</em>(8), 5939–5958. (<a
href="https://doi.org/10.1007/s00521-021-06689-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address two key challenges of k-means clustering. In the first part of the paper, we show that: when a dataset is partitioned with an appropriate number of clusters (k), not more than 1/9 of D will exceed twice its standard deviation (2 s.d.), and not more than 4/9 of D will exceed its standard deviation (1 s.d.) (σ), where D is a vector comprising the distance of each point to its cluster centroid. Our bounds assume unimodal symmetrical clusters (a generalization of k-means’ Gaussian assumption). In the second part of the paper, we show that a non-outlier will not be further from its cluster centroid than 14.826 times the median of absolute deviations from the median of D. Interestingly, D is already available from the k-means process. The first insight leads to an enhanced k-means algorithm (named Automatic k-means) which  efficiently estimates k. Unlike popular techniques, ours eliminates the need to supply a search range for k. Meanwhile, since practical datasets may deviate from the ideal distribution, the 1 and 2 s.d. tests may yield different k estimates. Both estimates constitute effective lower and upper bounds. Thus, our algorithm also provides a general way to speed up and automate existing techniques, via automatically determined narrow search range. We demonstrate this by presenting enhanced versions of the popular silhouette and gap statistics techniques (Auto-Silhouette and Auto-Gap). We apply the second theoretical insight to incorporate automatic outlier detection into k-means. Our outlier-aware algorithm (named k-means#) is identical to the standard k-means in the absence of outliers. In the presence of outliers, it is identical to a known outlier-aware algorithm, named k-means-−, except for the crucial difference that k-means−− relies on the user to supply the number of outliers, while our algorithm is automated. Our technique solves a puzzle described by the authors of k-means−− regarding the difficulty of complete automation, which was considered an open problem.},
  archive      = {J_NCA},
  author       = {Olukanmi, Peter and Nelwamondo, Fulufhelo and Marwala, Tshilidzi and Twala, Bhekisipho},
  doi          = {10.1007/s00521-021-06689-x},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5939-5958},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic detection of outliers and the number of clusters in k-means clustering via chebyshev-type inequalities},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quick extreme learning machine for large-scale
classification. <em>NCA</em>, <em>34</em>(8), 5923–5938. (<a
href="https://doi.org/10.1007/s00521-021-06727-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extreme learning machine (ELM) is a method to train single-layer feed-forward neural networks that became popular because it uses a fast closed-form expression for training that minimizes the training error with good generalization ability to new data. The ELM requires the tuning of the hidden layer size and the calculation of the pseudo-inverse of the hidden layer activation matrix for the whole training set. With large-scale classification problems, the computational overload caused by tuning becomes not affordable, and the activation matrix is extremely large, so the pseudo-inversion is very slow and eventually the matrix will not fit in memory. The quick extreme learning machine (QELM), proposed in the current paper, is able to manage large classification datasets because it: (1) avoids the tuning by using a bounded estimation of the hidden layer size from the data population; and (2) replaces the training patterns in the activation matrix by a reduced set of prototypes in order to avoid the storage and pseudo-inversion of large matrices. While ELM or even the linear SVM cannot be applied to large datasets, QELM can be executed on datasets up to 31 million data, 30,000 inputs and 131 classes, spending reasonable times (less than 1 h) in general purpose computers without special software nor hardware requirements and achieving performances similar to ELM.},
  archive      = {J_NCA},
  author       = {Albtoush, Audi and Fernández-Delgado, Manuel and Cernadas, Eva and Barro, Senén},
  doi          = {10.1007/s00521-021-06727-8},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5923-5938},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quick extreme learning machine for large-scale classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AM-ConvGRU: A spatio-temporal model for typhoon path
prediction. <em>NCA</em>, <em>34</em>(8), 5905–5921. (<a
href="https://doi.org/10.1007/s00521-021-06724-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typhoons are one of the most destructive types of disasters. Several statistical models have been designed to predict their paths to reduce damage, casualties, and economic loss. To further increase prediction accuracy, two key challenges are (1) to extract better nonlinear 3D features of typhoons, which is hard due to their complex high-dimensional properties, and (2) to combine suitable 2D and 3D features in a proper way to improve predictions. To address these challenges, this paper presents a novel spatio-temporal deep learning model named Attention-based Multi ConvGRU (AM-ConvGRU). To automatically select high response isobaric planes of typhoons when considering their whole 3D structures, AM-ConvGRU leverages the Residual Channel Attention Block (RCAB). Furthermore, it integrates a novel model named Multi-ConvGRU to extract large-scale nonlinear spatial features of typhoons. Moreover, the approach relies on a Wide &amp; Deep framework to fuse the traditional Generalized Linear Model (GLM) with the proposed AM-ConvGRU model. To evaluate the designed approach, extensive experiments have been conducted using real-world typhoons data from the Western North Pacific (WNP) basin obtained from both the China Meteorological Administration (CMA) dataset and the EAR-Interim dataset maintained by the European Centre for Medium-Range Weather Forecasts (ECMWF). Results show that the proposed method outperforms state-of-the-art deep learning typhoon prediction methods. The source code is available on GitHub with the following link: https://github.com/xuguangning1218/Typhoon_Path .},
  archive      = {J_NCA},
  author       = {Xu, Guangning and Xian, Di and Fournier-Viger, Philippe and Li, Xutao and Ye, Yunming and Hu, Xiuqing},
  doi          = {10.1007/s00521-021-06724-x},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5905-5921},
  shortjournal = {Neural Comput. Appl.},
  title        = {AM-ConvGRU: A spatio-temporal model for typhoon path prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adversarial model for electromechanical actuator fault
diagnosis under nonideal data conditions. <em>NCA</em>, <em>34</em>(8),
5883–5904. (<a
href="https://doi.org/10.1007/s00521-021-06732-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electromechanical actuators (EMAs) are safety-critical components that work under various conditions and loads. Realizing robust and precise fault diagnosis for an EMA increases the overall availability/safety of the whole system. However, the monitoring data of an EMA are collected under different working conditions and consist of numerous unlabeled samples and few unbalanced labeled samples; this severely limits the applications of intelligent data-driven diagnosis approaches. Therefore, this paper provides an extended convolutional adversarial autoencoder (ECAAE) as an adversarial model to achieve end-to-end fault diagnosis for EMAs based only on vibration signals. This approach combines the feature extraction ability of convolutional neural networks (CNNs) with the semisupervised learning and data generation capabilities of adversarial autoencoders (AAEs) by activating different submodels during different training phases and is thus able to utilize both unlabeled and unbalanced labeled samples. With the help of a hyperparameter-free signal conversion method and an imbalance-compensation loss function, the adversarial training process of the model results in a feature extractor that is robust to varying working conditions as well as a sample generator capable of generating samples belonging to a given class. Consequently, after fine-tuning on samples rebalanced by the generator, the classifier of the ECAAE is able to perform robust and precise fault diagnosis even under various working conditions, unbalanced samples and few-shot situations. The proposed method is validated under 12 multicondition data scenarios and achieves a diagnostic accuracy above 90\%, even in cases worse than 5-way 5-shot scenarios, thereby revealing its superiority over 3 state-of-the-art models.},
  archive      = {J_NCA},
  author       = {Wang, Chao and Tao, Laifa and Ding, Yu and Lu, Chen and Ma, Jian},
  doi          = {10.1007/s00521-021-06732-x},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5883-5904},
  shortjournal = {Neural Comput. Appl.},
  title        = {An adversarial model for electromechanical actuator fault diagnosis under nonideal data conditions},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new hybrid deep learning-based phishing detection system
using MCS-DNN classifier. <em>NCA</em>, <em>34</em>(8), 5867–5882. (<a
href="https://doi.org/10.1007/s00521-021-06717-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phishing is an attack that deceit online users by means of masquerading as a genuine website to pilfer their classified or personal information. This is one among the recognized cybercrime. Disparate phishing website detection systems were recently developed for the purpose of detecting the phishing websites. However, they fail to attain the desired output and are suffered from countless drawbacks like lower accuracy and higher training time. For trouncing such drawbacks, this paper proposes an effectual Hybrid Deep Learning (HDL)-centric Phishing Detection System (PDS) using the MCS-DNN classifier. At first, pre-processing is done on the input dataset for ameliorating its quality. Subsequently, clustering and feature selection (FS) are performed to lessen the processing time and elevate the accuracy using CoK-means and CM-WOA, respectively. The features which are chosen during FS are fed into the MCS-DNN classifier, which classifies the legitimate websites and phishing websites. Lastly, the K-fold cross-validations (KCV) are employed for effectively predicting the proposed system’s accurateness. The outcomes highlight the robustness and predictive ability of the proposed PDS to distinguish the phishing as well as legitimate sites.},
  archive      = {J_NCA},
  author       = {Anitha, J. and Kalaiarasu, M.},
  doi          = {10.1007/s00521-021-06717-w},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5867-5882},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new hybrid deep learning-based phishing detection system using MCS-DNN classifier},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning model for behavioural credit scoring in
banks. <em>NCA</em>, <em>34</em>(8), 5839–5866. (<a
href="https://doi.org/10.1007/s00521-021-06695-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main aim of this paper is to help bank management in scoring credit card clients using machine learning by modelling and predicting the consumer behaviour concerning three aspects: the probability of single and consecutive missed payments for credit card customers, the purchasing behaviour of customers, and grouping customers based on a mathematical expectation of loss. Two models are developed: the first provides the probability of a missed payment during the next month for each customer, which is described as Missed payment prediction Long Short Term Memory model (MP-LSTM), whilst the second estimates the total monthly amount of purchases, which is defined as Purchase Estimation Prediction Long Short Term Memory model (PE-LSTM). Based on both models, a customer behavioural grouping is provided, which can be helpful for the bank’s decision-making. Both models are trained on real credit card transactional datasets. Customer behavioural scores are analysed using classical performance evaluation measures. Calibration analysis of MP-LSTM scores showed that they could be considered as probabilities of missed payments. Obtained purchase estimations were analysed using mean square error and absolute error. The MP-LSTM model was compared to four traditional well-known machine learning algorithms. Experimental results show that, compared with conventional methods based on feature extraction, the consumer credit scoring method based on the MP-LSTM neural network has significantly improved consumer credit scoring.},
  archive      = {J_NCA},
  author       = {Ala’raj, Maher and Abbod, Maysam F. and Majdalawieh, Munir and Jum’a, Luay},
  doi          = {10.1007/s00521-021-06695-z},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5839-5866},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning model for behavioural credit scoring in banks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Review on r&amp;d task integrated management of intelligent
manufacturing equipment. <em>NCA</em>, <em>34</em>(8), 5813–5837. (<a
href="https://doi.org/10.1007/s00521-022-07023-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of various types of industrial big data technologies, in the context of industrial big data and systems science, intelligent optimization algorithms and other technologies have been widely used in the field of intelligent manufacturing. In recent years, it has not only become an important engine for the transformation and upgrading of smart manufacturing industry, but also brought new opportunities and challenges to the development task integrated management of intelligent manufacturing equipment. This paper reviews the research on task integrated management of intelligent manufacturing equipment development from the following four aspects: task analysis and management of intelligent manufacturing equipment in big data environment, task decomposition and resource allocation, task network analysis and evaluation, and task integration analysis and verification evaluation progress. Prospects for further research are pointed out, including the customized research into high-end equipment developed for the individual needs of users, data-driven optimal allocation of resources research, multi-layer interaction of complex network modeling, intelligent systems integration, and verification evaluation.},
  archive      = {J_NCA},
  author       = {Ren, Teng and Luo, Tianyu and Li, Shuxuan and Xing, Lining and Xiang, Shang},
  doi          = {10.1007/s00521-022-07023-9},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5813-5837},
  shortjournal = {Neural Comput. Appl.},
  title        = {Review on R&amp;D task integrated management of intelligent manufacturing equipment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Literature review: Efficient deep neural networks techniques
for medical image analysis. <em>NCA</em>, <em>34</em>(8), 5791–5812. (<a
href="https://doi.org/10.1007/s00521-022-06960-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant evolution in deep learning took place in 2010, when software developers started using graphical processing units for general-purpose applications. From that date, the deep neural network (DNN) started progressive steps across different applications ranging from natural language processing to hyperspectral image processing. The convolutional neural network (CNN) mostly triggers the interest, as it is considered one of the most powerful ways to learn useful representations of images and other structured data. The revolution of DNNs in medical imaging (MI) came in 2012, when Li launched ImageNet, a free database of more than 14 million labeled medical images. This state-of-the-art work presents a comprehensive study for the recent DNNs research directions applied in MI analysis. Clinical and pathological analysis through a selected patch of most cited researches is introduced. It will be shown how DNNs are able to tackle medical problems: classification, detection, localization, segmentation, and automatic diagnosis. Datasets comprises a range of imaging technologies: X-Ray, MRI, CT, Ultrasound, PET, Fluorescene Angiography, and even photographic images. This work surveys different patterns of DNNs and focuses somehow on the CNN, which offers an outstanding percentage of solutions compared to other DNNs structures. CNN emphasizes image features and has well-known architectures. On the other hand, limitations beyond DNNs training and execution time will be explained. Problems related to data augmentation and image annotation will be analyzed among a multiple of high standard publications. Finally, a comparative study of existing software frameworks supporting DNNs and future research directions in the area will be presented. From all presented works it could be deduced that the use of DNNs in healthcare is still in its early stages, there are strong initiatives in academia and industry to pursue healthcare projects based on DNNs.},
  archive      = {J_NCA},
  author       = {Abdou, Mohamed A.},
  doi          = {10.1007/s00521-022-06960-9},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5791-5812},
  shortjournal = {Neural Comput. Appl.},
  title        = {Literature review: Efficient deep neural networks techniques for medical image analysis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design of backpropagated neurocomputing paradigm for stuxnet
virus dynamics in control infrastructure. <em>NCA</em>, <em>34</em>(7),
5771–5790. (<a
href="https://doi.org/10.1007/s00521-021-06721-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present study, a novel application of backpropagated neurocomputing heuristics (BNCH) is presented for epidemic virus model that portrays the Stuxnet virus propagation in regimes of supervisory control and data acquisition (SCADA) networks using multi-layer structure of neural networks (NNs) optimized with competency of efficient backpropagation with Levenberg–Marquardt (LM) method. Stuxnet virus spread through removable storage media that used to transfer of data and virus to device connected to SCADA networks with ability to exploit the whole system. The reference dataset of mathematical model of Stuxnet virus dynamics is generated by the competency of Adams method and used arbitrary for training, testing and validation of BNCH through NNs learning with LM scheme. Comparative study of BNCH with reference results shows the matching of 4–7 decimal places of accuracy and the further validated through mean squared error-based figure of merit, histograms, and regression measures.},
  archive      = {J_NCA},
  author       = {Raja, Muhammad Asif Zahoor and Naz, Hira and Shoaib, Muhammad and Mehmood, Ammara},
  doi          = {10.1007/s00521-021-06721-0},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5771-5790},
  shortjournal = {Neural Comput. Appl.},
  title        = {Design of backpropagated neurocomputing paradigm for stuxnet virus dynamics in control infrastructure},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Response map evaluation for RGBT tracking. <em>NCA</em>,
<em>34</em>(7), 5757–5769. (<a
href="https://doi.org/10.1007/s00521-021-06704-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, RGB and thermal sensors are widely used. There is complementary information from these two types of sensors. A fundamental task which arises in this domain is RGBT tracking. It is a challenging problem to leverage RGB and thermal data. In this paper, we propose an adaptive fusion algorithm based on response map evaluation for RGBT tracking. Specifically, a hierarchical convolutional neural network is employed to extract deep features in RGB and thermal images, respectively. The target is tracked in correlation filter framework with each layer independently in RGB and thermal images. To evaluate response map of tracking status in various conditions, the average sidelobe peak response (ASPR) is proposed. Gaussian regression process is employed to provide adaptive fusion weights based on ASPR. Experimental results on two RGBT tracking datasets demonstrate the success of our method.},
  archive      = {J_NCA},
  author       = {Wang, Yong and Wei, Xian and Tang, Xuan and Wu, Jingjing and Fang, Jiangxiong},
  doi          = {10.1007/s00521-021-06704-1},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5757-5769},
  shortjournal = {Neural Comput. Appl.},
  title        = {Response map evaluation for RGBT tracking},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Protection of image ROI using chaos-based encryption and
DCNN-based object detection. <em>NCA</em>, <em>34</em>(7), 5743–5756.
(<a href="https://doi.org/10.1007/s00521-021-06725-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images always contain sensitive information, e.g., a clear face on a photo, which needs to be protected. The simple way is to encrypt the whole image for hiding “everything” securely, but it brings huge amounts of unnecessary encryption operations. Considering the most sensitive regions of an image, this paper focuses on protecting the important regions, thus reducing the redundant encryption operations. This paper employs the latest DCNN-based object detection model (YOLOv4) for choosing regions (i.e., multiple objects) and chaos-based encryption for fast encryption. We analyze object detection algorithm from a security perspective and modify YOLOv4 to guarantee that all areas of the detected objects are contained in the output regions of interest (ROI). Later, we propose a multi-object-oriented encryption algorithm to protect all the detected ROI at one go. We also encrypt the ROI coordinates and embed them into the whole image, relieving the burden of distributing ROI coordinates separately. Experimental results and security analyses show that all the detected objects are well protected.},
  archive      = {J_NCA},
  author       = {Song, Wei and Fu, Chong and Zheng, Yu and Cao, Lin and Tie, Ming and Sham, Chiu-Wing},
  doi          = {10.1007/s00521-021-06725-w},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5743-5756},
  shortjournal = {Neural Comput. Appl.},
  title        = {Protection of image ROI using chaos-based encryption and DCNN-based object detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel transfer learning for recognition of overlapping
nano object. <em>NCA</em>, <em>34</em>(7), 5729–5741. (<a
href="https://doi.org/10.1007/s00521-021-06731-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the science and technology of nanostructure have rapidly been developed in many fields, it is still hard to obtain sufficient samples of nano objects due to high cost, thus, impeding the development of deep learning approaches to the material fields. Here, we develop a novel approach to recognize nano objects in Atomic Force Microscope (AFM) images. First, a noise reduction method based on the Laplacian of the Gaussian(LoG) is represented to denoise the AFM images. Then, two improved methods based on the watershed algorithm are proposed to segment the overlapping objects. Finally, a CNN recognition model based on transfer learning which is pre-trained on a large scale of shapes of handwritten numbers and letters is built to recognize the nano objects in AFM images. These methods can resolve effectively the small sample problem of AFM image processing.},
  archive      = {J_NCA},
  author       = {Han, Yuexing and Liu, Yuhong and Wang, Bing and Chen, Qiaochuan and Song, Leilei and Tong, Lin and Lai, Chuanbin and Konagaya, Akihiko},
  doi          = {10.1007/s00521-021-06731-y},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5729-5741},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel transfer learning for recognition of overlapping nano object},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tackling the muon identification in water cherenkov
detectors problem for the future southern wide-field gamma-ray
observatory by means of machine learning. <em>NCA</em>, <em>34</em>(7),
5715–5728. (<a
href="https://doi.org/10.1007/s00521-021-06730-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents several approaches to deal with the problem of identifying muons in a water Cherenkov detector with a reduced water volume and 4 PMTs. Different perspectives of information representation are used, and new features are engineered using the specific domain knowledge. As results show, these new features, in combination with the convolutional layers, are able to achieve a good performance avoiding overfitting and being able to generalise properly for the test set. The results also prove that the combination of state-of-the-art machine learning analysis techniques and water Cherenkov detectors with low water depth can be used to efficiently identify muons, which may lead to huge investment savings due to the reduction of the amount of water needed at high altitudes. This achievement can be used in further research to be able to discriminate between gamma and hadron-induced showers using muons as discriminant.},
  archive      = {J_NCA},
  author       = {González, B. S. and Conceição, R. and Pimenta, M. and Tomé, B. and Guillén, A.},
  doi          = {10.1007/s00521-021-06730-z},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5715-5728},
  shortjournal = {Neural Comput. Appl.},
  title        = {Tackling the muon identification in water cherenkov detectors problem for the future southern wide-field gamma-ray observatory by means of machine learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep localization of subcellular protein structures from
fluorescence microscopy images. <em>NCA</em>, <em>34</em>(7), 5701–5714.
(<a href="https://doi.org/10.1007/s00521-021-06715-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate localization of proteins from fluorescence microscopy images is challenging due to the inter-class similarities and intra-class disparities introducing grave concerns in addressing multi-class classification problems. Conventional machine learning-based image prediction pipelines rely heavily on pre-processing such as normalization and segmentation followed by handcrafted feature extraction to identify useful, informative, and application-specific features. Here, we demonstrate that deep learning-based pipelines can effectively classify protein images from different datasets. We propose an end-to-end Protein Localization Convolutional Neural Network (PLCNN) that classifies protein images more accurately and reliably. PLCNN processes raw imagery without involving any pre-processing steps and produces outputs without any customization or parameter adjustment for a particular dataset. Experimental analysis is performed on five benchmark datasets. PLCNN consistently outperformed the existing state-of-the-art approaches from traditional machine learning and deep architectures. This study highlights the importance of deep learning for the analysis of fluorescence microscopy protein imagery. The proposed deep pipeline can better guide drug designing procedures in the pharmaceutical industry and open new avenues for researchers in computational biology and bioinformatics.},
  archive      = {J_NCA},
  author       = {Tahir, Muhammad and Anwar, Saeed and Mian, Ajmal and Muzaffar, Abdul Wahab},
  doi          = {10.1007/s00521-021-06715-y},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5701-5714},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep localization of subcellular protein structures from fluorescence microscopy images},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneous information network embedding for user
behavior analysis on social media. <em>NCA</em>, <em>34</em>(7),
5683–5699. (<a
href="https://doi.org/10.1007/s00521-021-06706-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User behavior prediction with low-dimensional vectors generated by user network embedding models has been verified to be efficient and reliable in real applications. However, existing graph representation learning methods mainly focus on homogeneous and static graphs and cannot well represent the real-world social networks that are heterogeneous and keep evolving. To address this challenge, we propose a dynamic heterogeneous user behavior analysis network (DHBN) model, which applies graph network embedding to fuse multi-networks information by considering their heterogeneity and evolutionary patterns over dynamic networks. In particular, by separately performing user social relationship embedding, node attribute embedding and user behavior embedding, the proposed scheme learns the highly nonlinear representations of network nodes; and then we explore recurrent neural networks based on attention mechanism to capture the networks&#39; dynamic evolution. Our proposed method has been examined on two real-world datasets, and five state-of-the-art schemes are compared to the proposed scheme for link prediction quality and node recommendation. Especially, for dynamic user behavior link prediction task on Weibo-UBA dataset, DHBN model achieves AUROC of 77.3\% and AUPOC of 71.2\%. In terms of AUROC, DHBN is at least 5\% better than other models, the other experimental results also demonstrate that the DHBN model has significant advantages over other comparison models. This work can provide guidance on the future user behavior prediction studies.},
  archive      = {J_NCA},
  author       = {Zhao, Xiaofang and Jin, Zhigang and Liu, Yuhong and Hu, Yi},
  doi          = {10.1007/s00521-021-06706-z},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5683-5699},
  shortjournal = {Neural Comput. Appl.},
  title        = {Heterogeneous information network embedding for user behavior analysis on social media},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Holistic versus segmentation-based recognition of
handwritten devanagari conjunct characters: A CNN-based experimental
study. <em>NCA</em>, <em>34</em>(7), 5665–5681. (<a
href="https://doi.org/10.1007/s00521-021-06672-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Character recognition of the script is the most vital step of Optical Character Recognition and the recognition accuracy directly affects the optical character recognition performance. Recognition of the script is fully achieved when all the components of the script are recognized completely. The conjunct character of the Devanagari script is one such component whose recognition is a challenging task. Researchers are adopting either segmentation-based or segmentation-free (holistic) recognition of these conjunct characters using structural features. This work provides an experimental study to compare between the holistic- and segmentation-based recognition of handwritten Devanagari conjunct characters. We propose a polygonal approximation-based novel segmentation approach that uses structural properties to decompose the conjunct characters of the Devanagari script to its constituent characters. This technique segments the conjunct character from the point where two basic shapes are joined to form the conjunct character and thus, segmentation accuracy is enhanced. Convolutional neural network and convolution neural network-based transfer learning are used for the recognition purpose. Convolutional neural network-Recurrent neural network hybrid architecture is also adopted to simplify the holistic approach and reduce the classification complexity. A comparative study is delineated between the methods on the basis of experiments conducted. The proposed method is observed to provide better results in terms of segmentation and recognition of conjunct characters in comparison to previously reported works.},
  archive      = {J_NCA},
  author       = {Gupta, Deepika and Bag, Soumen},
  doi          = {10.1007/s00521-021-06672-6},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5665-5681},
  shortjournal = {Neural Comput. Appl.},
  title        = {Holistic versus segmentation-based recognition of handwritten devanagari conjunct characters: A CNN-based experimental study},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tactical UAV path optimization under radar threat using deep
reinforcement learning. <em>NCA</em>, <em>34</em>(7), 5649–5664. (<a
href="https://doi.org/10.1007/s00521-021-06702-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of the research efforts that aim to solve UAV path optimization problems in a Reinforcement Learning (RL) setting focus on closed spaces or urban areas as the operating environment. The problem of Tactical UAV (TUAV) path planning under hostile radar tracking threat has some peculiarities that distinguish it from other typical UAV path optimization problems. Particularly, 1–spatial regions delineated by threat probabilities may be legitimately penetrable under certain conditions that do not impair the survivability of the UAV and 2–A TUAV is detectable by a radar via its Radar Cross Section (RCS) which is a function of multiple parameters such as the radar operating frequency, the shape of the UAV and more importantly the engagement geometry between the radar and the UAV. The latter suggests that any maneuver performed by the UAV may change multiple angles that specify the engagement geometry. The work presented in this paper proposes a RL based solution to this complex problem in a novel way by 1–Implementing a Markov Decision Process (MDP) compliant RL environment with comprehensive probabilistic radar behavior models incorporated into it and 2–Integrating a core RL algorithm (namely DQN with Prioritized Experience Replay (DQN-PER) with a specific variant of transfer learning (namely learning from demonstrations (LfD)) in a single framework, demonstrating the utility of combining a core RL algorithm and a machine learning scheme toward boosting the performance of a learning agent, and more importantly to alleviate the sparse reward problem.},
  archive      = {J_NCA},
  author       = {Alpdemir, M. Nedim},
  doi          = {10.1007/s00521-021-06702-3},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5649-5664},
  shortjournal = {Neural Comput. Appl.},
  title        = {Tactical UAV path optimization under radar threat using deep reinforcement learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving embedding learning by virtual attribute decoupling
for text-based person search. <em>NCA</em>, <em>34</em>(7), 5625–5647.
(<a href="https://doi.org/10.1007/s00521-021-06734-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the problem of text-based person search, which aims to find the target person based on a query textual description. Previous methods commonly focus on learning shared image-text embeddings, but largely ignore the effect of pedestrian attributes. Attributes are fine-grained information, which provide mid-level semantics and have been demonstrated to be effective in traditional image-based person search. However, in text-based person search, it is hard to incorporate attribute information to learn discriminative image-text embeddings, because (1) the description of attributes could be various at different texts and (2) it is hard to decouple attributes-related information without the help of attribute annotations. In this paper, we propose an improving embedding learning by virtual attribute decoupling (iVAD) model for learning modality-invariant image-text embeddings. To the best of our knowledge, this is the first work which performs unsupervised attribute decoupling in text-based person search task. In the iVAD, we first propose a novel virtual attribute decoupling (VAD) module which uses an encoder-decoder embedding learning structure to decompose attribute information from image and text. In this module, we regard the pedestrian attributes as a hidden vector and obtain attribute-related embeddings. In addition, different from previous works which separates attribute learning from image-text embedding learning, we propose a hierarchical feature embedding framework. We incorporate the attribute-related embeddings into learned image-text embeddings by an attribute-enhanced feature embedding (AEFE) module. The proposed AEFE module can utilize attribute information to improve discriminability of learned features. Extensive evaluations demonstrate the superiority of our method over a wide variety of state-of-the-art methods on the CUHK-PEDES dataset. The experimental results on Caltech-UCSD Birds (CUB), Oxford-102 Flowers (Flowers) and Flickr30K verify the effectiveness of the proposed approach. A further visualization shows that the proposed iVAD model can effectively discover the co-occurring pedestrian attributes in corresponded image-text pairs.},
  archive      = {J_NCA},
  author       = {Wang, Chengji and Luo, Zhiming and Lin, Yaojin and Li, Shaozi},
  doi          = {10.1007/s00521-021-06734-9},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5625-5647},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving embedding learning by virtual attribute decoupling for text-based person search},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An extended MAIRCA method using intuitionistic fuzzy sets
for coronavirus vaccine selection in the age of COVID-19. <em>NCA</em>,
<em>34</em>(7), 5603–5623. (<a
href="https://doi.org/10.1007/s00521-021-06728-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {All over the world, the COVID-19 outbreak seriously affects life, whereas numerous people have infected and passed away. To control the spread of it and to protect people, appreciable vaccine development efforts continue with increasing momentum. Given that this pandemic will be in our lives for a long time, it is obvious that a reliable and useful framework is needed to choose among coronavirus vaccines. To this end, this paper proposes a new intuitionistic fuzzy extension of MAIRCA framework, named intuitionistic fuzzy MAIRCA (IF-MAIRCA) to assess coronavirus vaccines according to some evaluation criteria. Based on the group decision-making, the IF-MAIRCA framework both extracts the criteria weights and discovers the prioritization of the alternatives under uncertainty. In this work, as a case study, five coronavirus vaccines approved by the world&#39;s leading authorities are evaluated according to various criteria. The findings demonstrate that the most significant criteria considered in coronavirus vaccine selection are “duration of protection,” “effectiveness of the vaccine,” “success against the mutations,” and “logistics,” respectively, whereas the best coronavirus vaccine is AZD1222. Apart from this, the proposed model&#39;s robustness is verified with a three-phase sensitivity analysis.},
  archive      = {J_NCA},
  author       = {Ecer, Fatih},
  doi          = {10.1007/s00521-021-06728-7},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5603-5623},
  shortjournal = {Neural Comput. Appl.},
  title        = {An extended MAIRCA method using intuitionistic fuzzy sets for coronavirus vaccine selection in the age of COVID-19},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical attention network for attributed community
detection of joint representation. <em>NCA</em>, <em>34</em>(7),
5587–5601. (<a
href="https://doi.org/10.1007/s00521-021-06723-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attributed community detection is a challenging task as it requires joint modelling of graph structure and node attributes. Recent progress on graph neural network (GNN) has proved that it is effective in combining structural and content information, and several GNN-based methods have achieved promising clustering performance on real-world attributed network. Most of the existing community detection methods adopt non-clustering-oriented representation learning methods, which is incapable of capturing interaction between embedding and clustering, thus resulting in suboptimal outcome. In this paper, we propose a novel Hierarchical Attention Network (HiAN) solution for attributed community detection, and unique hierarchical attention network may significantly change the community detection paradigm. In order to fuse rich interpretable interactive information, the hierarchical attentive aggregator in HiAN is designed to learn node representation at both attribute-and structure-spaces. More importantly, the self-training process is jointly learned and optimized with embedding representation in a unified community detection framework, to mutually benefit both components. The experimental results demonstrate that HiAN outperforms several state-of-the-art baselines on four real-world datasets.},
  archive      = {J_NCA},
  author       = {Zhao, Qiqi and Ma, Huifang and Guo, Lijun and Li, Zhixin},
  doi          = {10.1007/s00521-021-06723-y},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5587-5601},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hierarchical attention network for attributed community detection of joint representation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Electrical consumption forecasting: A framework for high
frequency data. <em>NCA</em>, <em>34</em>(7), 5577–5586. (<a
href="https://doi.org/10.1007/s00521-021-06735-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowing the demand for electrical consumption beforehand is important for efficient energy programming policies that can help with climate change, life cycle-costs, and optimal primary resource extraction. In this paper, we propose a framework to improve forecasting performance of high frequency electrical consumption data. We use different models for each day of the week, and then compose them to obtain the total forecast. We apply both machine learning (Long-Short Term Memory network) and econometric models (AutoRegressive Integrated Moving Average and Holtz-Winters) that consider time dependence in the data comparing model performance. We find that a classical ARIMA model outperforms other models; however, in applying the proposed framework, LSTM manages to outperform all other models. The results are statistically significant as indicated by the Model Confidence Set test constructed for Mean Absolute Percentage Error and Mean Square Error.},
  archive      = {J_NCA},
  author       = {Michell, Kevin and Kristjanpoller, Werner and Minutolo, Marcel C.},
  doi          = {10.1007/s00521-021-06735-8},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5577-5586},
  shortjournal = {Neural Comput. Appl.},
  title        = {Electrical consumption forecasting: A framework for high frequency data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). End-to-end quantum-inspired method for vehicle
classification based on video stream. <em>NCA</em>, <em>34</em>(7),
5561–5576. (<a
href="https://doi.org/10.1007/s00521-021-06718-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent Transportation Systems (ITS) are the most widely used systems for road traffic management. The vehicle type classification (VTC) is a crucial ITS task due to its capability to gather valuable traffic information. However, designing a performant VTC method is challenging due to the considerable intra-class variation of vehicles. This paper presents a new quantum decision-based method for VTC applied to video streaming. This method allows for earlier decision-making by considering a few stream’s images. Our method is threefold. First, the video stream is acquired and preprocessed following a specific pipeline. Second, we aim to detect and track vehicles. Therefore, we apply a deep learning-based model to detect vehicles, and then a vehicle tracking algorithm is used to track each detected vehicle. Third, we seek to classify the tracked vehicle according to six defined classes. Furthermore, we transform the tracked vehicles according to a pipeline, consisting of the histogram of oriented gradients (HOG), and principal component analysis (PCA) methods. Then, we estimate the vehicles’ probabilities of belonging to each class by training multilayer perceptron (MLP) classifier with the resulting features. To assign a class to a vehicle, we apply a quantum-inspired probability integrator that handles each frame’s information flow. The unique characteristics of the work we propose, compared to the existing ones, are expressed in the decision-making process, since the former requires a sequence of frames of different sizes, compared to the image-based-decision made by the other methods. Our method outperformed the baseline methods with an accuracy up to 96\%.},
  archive      = {J_NCA},
  author       = {Derrouz, Hatim and Cabri, Alberto and Ait Abdelali, Hamd and Oulad Haj Thami, Rachid and Bourzeix, François and Rovetta, Stefano and Masulli, Francesco},
  doi          = {10.1007/s00521-021-06718-9},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5561-5576},
  shortjournal = {Neural Comput. Appl.},
  title        = {End-to-end quantum-inspired method for vehicle classification based on video stream},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Large-scale cellular traffic prediction based on graph
convolutional networks with transfer learning. <em>NCA</em>,
<em>34</em>(7), 5549–5559. (<a
href="https://doi.org/10.1007/s00521-021-06708-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent cellular traffic prediction is very important for mobile operators to achieve resource scheduling and allocation. In reality, people often need to predict very large scale of cellular traffic involving thousands of cells. This paper proposes a transfer learning strategy based on graph convolution neural network to achieve the task of large-scale traffic prediction. In this paper, we design a novel spatial-temporal graph convolutional network based on attention mechanism (STA-GCN). In order to achieve large-scale traffic prediction, this paper proposes a regional transfer learning strategy based on STA-GCN to improve knowledge reuse. The effectiveness of STA-GCN is validated through two real-world traffic datasets. The results show that STA-GCN outperforms the state-of-art baselines, and the transfer learning strategy can effectively reduce the number of epochs while training.},
  archive      = {J_NCA},
  author       = {Zhou, Xu and Zhang, Yong and Li, Zhao and Wang, Xing and Zhao, Juan and Zhang, Zhao},
  doi          = {10.1007/s00521-021-06708-x},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5549-5559},
  shortjournal = {Neural Comput. Appl.},
  title        = {Large-scale cellular traffic prediction based on graph convolutional networks with transfer learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finger knuckle biometric feature selection based on the
FIS_DE optimization algorithm. <em>NCA</em>, <em>34</em>(7), 5535–5547.
(<a href="https://doi.org/10.1007/s00521-021-06705-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the hand-based biometric system has received significant attention in identifying a person. In the hand-based biometric, the finger knuckle print plays a vital role in recognizing a person. The main purpose of this research is to propose an effective feature optimization technique for identifying the best feature vectors for finger knuckle print-based authentication. This work presents a novel feature selection algorithm, fitness index selection with differential evolution (FIS_DE), based on K-nearest neighbor (KNN). Initially, the feature extraction is performed using the conventional methods like principal component analysis, linear discriminant analysis, and independent component analysis. Then, evolutionary algorithm is used for feature selection with best vectors. The population-based metaheuristic algorithm DE proposed is used to optimize the KNN classifier. FIS_DE_KNN is compared with Euclidean and neural network classifiers to show the improved efficiency of the proposed work. In this research, experimental results of the proposed FIS_DE-KNN improve the classification accuracy with an optimized number of features.},
  archive      = {J_NCA},
  author       = {Jayapriya, P. and Umamaheswari, K.},
  doi          = {10.1007/s00521-021-06705-0},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5535-5547},
  shortjournal = {Neural Comput. Appl.},
  title        = {Finger knuckle biometric feature selection based on the FIS_DE optimization algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An automatic plant leaf disease identification using
DenseNet-121 architecture with a mutation-based henry gas solubility
optimization algorithm. <em>NCA</em>, <em>34</em>(7), 5513–5534. (<a
href="https://doi.org/10.1007/s00521-021-06714-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Farmers are struggling to provide the fast-growing population with sufficient agricultural products, while plant diseases result in devastating food loss. The billions of dollars spent by agriculturists in disease management often result in poor disease control without any technical support. Advances in computer vision techniques help to detect plant pathogens at an earlier level with an adaptive algorithm designed through deep learning and machine learning techniques. In this paper, we present an efficient Mutation-based Henry Gas Solubility Optimization (MHGSO) algorithm to optimize the hyperparameters of the DenseNet-121 architecture. The hyperparameter optimization is mainly done to reduce the computational complexity and the error rate of the Convolutional Neural Network (CNN). This step helps the MHGSO optimized DenseNet-121 architecture to achieve a higher classification accuracy for classifying different plant images from the PlantVillage dataset. The experimental results achieved showed that the proposed model is capable of classifying 14 leaf classes present in the PlantVillage dataset with higher classification accuracy (98.7\%) and stability. When tested with a field dataset with complicated backgrounds, the proposed MHGSO optimized DenseNet-121 architecture achieves accuracy, precision, and recall scores of 98.81\%, 98.60\%, and 98.75\%, respectively.},
  archive      = {J_NCA},
  author       = {Nandhini, S. and Ashokkumar, K.},
  doi          = {10.1007/s00521-021-06714-z},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5513-5534},
  shortjournal = {Neural Comput. Appl.},
  title        = {An automatic plant leaf disease identification using DenseNet-121 architecture with a mutation-based henry gas solubility optimization algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficacy prediction based on attribute and multi-source data
collaborative for auxiliary medical system in developing countries.
<em>NCA</em>, <em>34</em>(7), 5497–5512. (<a
href="https://doi.org/10.1007/s00521-021-06713-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-small cell lung cancer is one of the acute diseases threatening human life. In many developing countries, there are medical problems such as large populations, underdeveloped technologies, and lack of resources. It is difficult for the &quot;fragmented&quot; approach to medical treatment to provide patients with complete life cycle treatment services. Research on the medical system of personalized adjuvant therapy can improve medical resources and the survival rate of patients in developing countries. This paper establishes a predictive framework for adjuvant therapy&#39;s medication based on the collaborative filtering of a patient and drug attributes and multi-source data. The framework is divided into the feature extraction module of patients and drugs about the treatment stage and the efficacy evaluation prediction module. We have proposed a quantitative method for efficacy evaluation. The proposed method can assist doctors in providing patients with personalized treatment plans based on efficacy evaluation analysis and prediction. By comparing and analyzing with other methods, the framework can effectively learn from expert experience and provide doctors with auxiliary treatment analysis and medication evaluation. The prediction accuracy of the model can reach 0.86.},
  archive      = {J_NCA},
  author       = {Yu, Genghua and Wu, Jia},
  doi          = {10.1007/s00521-021-06713-0},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5497-5512},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficacy prediction based on attribute and multi-source data collaborative for auxiliary medical system in developing countries},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-phase multi-expert knowledge approach by using fuzzy
clustering and rule-based system for technology evaluation of unmanned
aerial vehicles. <em>NCA</em>, <em>34</em>(7), 5479–5495. (<a
href="https://doi.org/10.1007/s00521-021-06694-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) are utilized in many different areas for different aims such as the benefit of humanity, safety control, traffic control, crop monitoring, scientific research, and commercial applications. Moreover, the UAVs are also successfully utilized for military operations, such as surveillance of an area and counter-terrorism actions. Evaluating them through the technological perspective is quite significant and should be considered from multiple perspectives. In this context, it will be more beneficial to construct a methodology for an efficient evaluation process. The fuzzy set theory (FST) can also be integrated into this methodology to improve its sensitiveness and flexibility. In this paper, a novel methodology integrating fuzzy $$c$$ -means (FCM) clustering and fuzzy inference system (FIS) has been suggested for the technical evaluation of UAVs. While the FCM clustering algorithm has been utilized to determine the clusters, rules have been created for the FIS through expert assessments, and alternative UAV technologies have been prioritized. For the evaluation procedure, the hierarchical structure of the technology evaluation features has been determined by fusing expert knowledge, literature review, and related ISO standards. Through the FCM clustering algorithm, alternative vehicles have been clustered based on the sub-features of each main feature. Then, FIS has been conducted by using experts’ knowledge from the fields of military technologies in UAVs and armed UAVs to obtain the technology indices of the eight UAVs locally produced and used in Turkey. The results demonstrate that the proposed methodology can be successfully applied by the managers or research and development (R&amp;D) engineers for evaluation of the UAV technologies to consider cardinal and linguistic data. Additionally, a comparative analysis based on self-organizing map (SOM) and fuzzy $$k$$ -means algorithms has also been applied for the proposed method, and their performances have been compared.},
  archive      = {J_NCA},
  author       = {Çolak, Murat and Kaya, İhsan and Karaşan, Ali and Erdoğan, Melike},
  doi          = {10.1007/s00521-021-06694-0},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5479-5495},
  shortjournal = {Neural Comput. Appl.},
  title        = {Two-phase multi-expert knowledge approach by using fuzzy clustering and rule-based system for technology evaluation of unmanned aerial vehicles},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation of lubricant condition and engine health based on
soft computing methods. <em>NCA</em>, <em>34</em>(7), 5465–5477. (<a
href="https://doi.org/10.1007/s00521-021-06688-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating the condition of the lubricant plays an influential role in the maintenance engineering of mechanical systems. This study has several objectives and finally offers a method based on the neural network. That method uses more limited indicators to determine the condition of the lubricant and the engine&#39;s health. That will reduce testing costs and encourage equipment and machine owners to perform lubricant analyses. The 681 results of the engine lubricant spectral analysis had used. The statistical analysis results showed; out of twelve indexes, only seven indexes, including iron, chromium, lead, copper, aluminum, nickel, and TDPQ, could have been influential in determining the three conditions of normal, caution, and critical wear. Soft computing methods, including KNN and RBF-ANN, were used to diagnose engine health conditions in three classes of normal, caution, and critical based on seven indexes of engine lubricant in three sizes of the training data set includes 40, 60, and 80\%. The results showed that the engine health diagnosis accuracy by KNN of the training set sizes of 80, 60, and 40\% was equal to 99.71, 98.38, and 97.36\%, while detection accuracy of the RBF-ANN for all three training set sizes was approximately 99.85\%. Also, the sensitivity analysis results showed soft computing methods could have the high ability to diagnose engine health.},
  archive      = {J_NCA},
  author       = {Pourramezan, Mohammad-Reza and Rohani, Abbas and Keramat Siavash, Nemat and Zarein, Mohammad},
  doi          = {10.1007/s00521-021-06688-y},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5465-5477},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluation of lubricant condition and engine health based on soft computing methods},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stubborn state estimation for complex-valued neural networks
with mixed time delays: The discrete time case. <em>NCA</em>,
<em>34</em>(7), 5449–5464. (<a
href="https://doi.org/10.1007/s00521-021-06707-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the state estimation problem is investigated for a class of discrete-time complex-valued neural networks (CVNNs) with mixed time delays. We consider a scenario that the measurement output may contain the unexpected outliers. In order to attenuate the impact of measurement outliers on the state estimation performance, a stubborn state estimator is designed for discrete-time CVNNs. For the purpose of analysis and synthesis, the CVNNs under consideration are firstly transformed to an augmented system which includes the dynamics of the real and imaginary parts of original CVNNs. Then, by resorting to the Lyapunov functional approach, a sufficient condition is given to ensure that the estimation error system is asymptotically stable. Subsequently, the desired state estimator gain is determined by solving a set of matrix inequalities. Finally, two simulation examples are provided to demonstrate the effectiveness of the proposed stubborn state estimation scheme.},
  archive      = {J_NCA},
  author       = {Liu, Yufei and Shen, Bo and Sun, Jie},
  doi          = {10.1007/s00521-021-06707-y},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5449-5464},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stubborn state estimation for complex-valued neural networks with mixed time delays: The discrete time case},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LightweightDeRain: Learning a lightweight multi-scale
high-order feedback network for single image de-raining. <em>NCA</em>,
<em>34</em>(7), 5431–5448. (<a
href="https://doi.org/10.1007/s00521-021-06700-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep convolutional neural networks have gained significant performance in single image de-raining. However, this progress is contributing to their complicated model design. These complicated models generally contain a huge number of parameters, resulting in high memory footprints and low efficiency. To handle this issue, we propose a novel Lightweight Multi-scale High-order Feedback Network (LMHFNet) for single image de-raining. First, we regard the de-raining problem as a multi-stage task and combine a high-order feedback mechanism with global residual learning to assist the network training. This combination brings obvious performance improvement and avoids increasing additional parameters. Then, we design a novel Lightweight Multi-scale (LM) block as the core component of our network by utilizing the depthwise separable convolution. Next, we propose a novel Lightweight Multi-scale ConvLSTM (LM-ConvLSTM) module to integrate the deep features generated by the feedback mechanism. Last, we discuss the influence of different factors (i.e., loss function and network input/output) to tap the maximum potential of our lightweight network. Our LMHFNet could achieve competitive performance compared with the latest state-of-the-art methods (i.e., RCDNet and DRDNet), and bring a 28- or 46- times compression at the same time. The extensive experiments demonstrate the effectiveness and efficiency of our model in both quantitative assessments and visual quality.},
  archive      = {J_NCA},
  author       = {Chen, Zheng and Bi, Xiaojun and Zhang, Yu and Yue, Jianyu and Wang, Haibo},
  doi          = {10.1007/s00521-021-06700-5},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5431-5448},
  shortjournal = {Neural Comput. Appl.},
  title        = {LightweightDeRain: Learning a lightweight multi-scale high-order feedback network for single image de-raining},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reinforcement learning-based control of improved hybrid
current modulated dual active bridge AC/DC converter. <em>NCA</em>,
<em>34</em>(7), 5417–5430. (<a
href="https://doi.org/10.1007/s00521-021-06698-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The DC bus voltage of AC/DC converters is conventionally regulated by proportional plus integral (PI)-based controllers. However, such controllers can’t provide good performance over the entire operating region and their performance is also affected by the change of parameters of passive components depending on temperature during the converters’ operation. On the other hand, reinforcement learning (RL), which is one of the machine learning methods, can become immune to parameter changes as it maintains training during the converter operation. In this paper, an RL-based control algorithm is proposed for an AC/DC dual active bridge (DAB) converter which operates with improved hybrid current modulation (iHCM). In the proposed method, the model-free Q-learning algorithm of RL is used to train an agent to regulate the DC bus voltage. The proposed algorithm is verified for various load and disturbance conditions by MATLAB/Simulink simulations, and it is compared with a PI controller which is tuned with Internal Model Control (IMC) method. According to the simulation results, besides the online learning advantage, the proposed method creates a small settling time and overshoot at the start-up for light load conditions, unlike the PI controller. On the other hand, during the change of dynamic load and AC grid voltage, it creates smaller voltage oscillations in the output DC voltage and regulates it faster. Furthermore, since the proposed method keeps the duty cycle value constant in each grid period, it produces lower total harmonic distortion (THD) than the PI controller.},
  archive      = {J_NCA},
  author       = {Zengin, Sinan},
  doi          = {10.1007/s00521-021-06698-w},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5417-5430},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reinforcement learning-based control of improved hybrid current modulated dual active bridge AC/DC converter},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep semantic hashing with dual attention for cross-modal
retrieval. <em>NCA</em>, <em>34</em>(7), 5397–5416. (<a
href="https://doi.org/10.1007/s00521-021-06696-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of multimodal data, cross-modal retrieval has drawn increasing research interests. Hashing-based methods have made great advancements in cross-modal retrieval due to the benefits of low storage cost and fast query speed. However, there still exists a crucial challenge to improve the accuracy of cross-modal retrieval due to the heterogeneity gap between modalities. To further tackle this problem, in this paper, we propose a new two-staged cross-modal retrieval method, called Deep Semantic Hashing with Dual Attention (DSHDA). In the first stage of DSHDA, a Semantic Label Network (SeLabNet) is designed to extract label semantic features and hash codes by training the multi-label annotations, which can make the learning of different modalities in a common semantic space and bridge the modality gap effectively. In the second stage of DSHDA, we propose a deep neural network to simultaneously integrate feature and hash code learning for each modality into the same framework, the training of the framework is guided by the label semantic features and hash codes generated from SeLabNet to maximize the cross-modal semantic relevance. Moreover, dual attention mechanisms are used in our neural networks: (1) Lo-attention is used to extract the local key information of each modality and improve the quality of modality features. (2) Co-attention is used to strengthen the relationship between different modalities to produce more consistent and accurate hash codes. Extensive experiments on two real datasets with image-text modalities demonstrate the superiority of the proposed method in cross-modal retrieval tasks.},
  archive      = {J_NCA},
  author       = {Wu, Jiagao and Weng, Weiwei and Fu, Junxia and Liu, Linfeng and Hu, Bin},
  doi          = {10.1007/s00521-021-06696-y},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5397-5416},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep semantic hashing with dual attention for cross-modal retrieval},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gland segmentation in colorectal cancer histopathological
images using u-net inspired convolutional network. <em>NCA</em>,
<em>34</em>(7), 5383–5395. (<a
href="https://doi.org/10.1007/s00521-021-06687-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate gland segmentation from digitized H&amp;E (hematoxylin and eosin) histology images with a wide range of histologic grades of cancer is quite challenging. The methodologies proposed in recent researches have performed well in segmenting glands from benign subjects but have not given satisfactory results when segmenting glands from malignant cases. The methodology proposed in this paper is based on the symmetric encoder-decoder network which works remarkably well in detecting and segmenting glands in the case of malignant subjects and overall. The proposed pipelines harness the power of multilevel CNN architecture to capture contextual information and concatenation of features from skip connections with upsampled feature maps to improve the localization accuracy thereby improving the precise segmentation accuracy. The raw predicted map is further refined using morphological operators as a post-processing tool. The method is trained and evaluated on the Warwick-QU dataset. The final segmentation results have been compared with the performance of top-performing teams of gland challenge (GlaS) MICCI 2015 along with the recent researches. The final predicted segmentation maps have achieved the F1 score of 0.81 for gland detection, object dice score of 0.82 for segmentation, and Hausdorff distance of 84.18 for gland shape similarity which is akin to or higher than the existing models for the malignant subject. The model has done affably well on the overall dataset too.},
  archive      = {J_NCA},
  author       = {Rastogi, Priyanka and Khanna, Kavita and Singh, Vijendra},
  doi          = {10.1007/s00521-021-06687-z},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5383-5395},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gland segmentation in colorectal cancer histopathological images using U-net inspired convolutional network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Highway accident number estimation in turkey with jaya
algorithm. <em>NCA</em>, <em>34</em>(7), 5367–5381. (<a
href="https://doi.org/10.1007/s00521-022-06952-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the transportation sector in Turkey, approximately 90\% of cargo and passenger transportation is carried out on highways. In recent years, increasing population and welfare levels have brought along an increase in demand for and intensity of highway use. Accidents experienced along with the increased intensity in the use of highways result in fatalities and loss of property. In order to minimize such losses on the highways and determine plans and programs for the future by benefiting from historical data, it is necessary to conduct accurate, consistent, effective, and reliable accident estimations. In the study, highway accident number estimation (HANE) in Turkey was made by using the meta-heuristic Jaya optimization algorithm. For HANE, Jaya linear (Jaya-L) and Jaya Quadratic (Jaya-Q) models were proposed. Indicators such as the number of accidents that occurred between 2002 and 2018, population, gross domestic product (GDP), total divided road length (TDRL), and the number of vehicles were taken for HANE. Indicators were analyzed for four different conditions. HANE was made by using Population–GDP–TDRL–Number of Vehicle indicators together. A total of 75\% of the total 17-year data between 2002 and 2018 were used for training purposes, and 25\% of the data were used for testing. The results of the proposed Jaya-L and Jaya-Q models were analyzed by comparing them with the Andreassen estimation model (AEM) and multiple linear regression (MLR) methods. Following the successful training and testing results, low, expected, and high scenarios were proposed, and the number of accidents between 2019 and 2030 was estimated.},
  archive      = {J_NCA},
  author       = {Tefek, Mehmet Fatih and Arslan, Muhammed},
  doi          = {10.1007/s00521-022-06952-9},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5367-5381},
  shortjournal = {Neural Comput. Appl.},
  title        = {Highway accident number estimation in turkey with jaya algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). COVID-19 diagnosis on CT images with bayes
optimization-based deep neural networks and machine learning algorithms.
<em>NCA</em>, <em>34</em>(7), 5349–5365. (<a
href="https://doi.org/10.1007/s00521-022-07052-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early diagnosis of COVID-19, the new coronavirus disease, is considered important for the treatment and control of this disease. The diagnosis of COVID-19 is based on two basic approaches of laboratory and chest radiography, and there has been a significant increase in studies performed in recent months by using chest computed tomography (CT) scans and artificial intelligence techniques. Classification of patient CT scans results in a serious loss of radiology professionals&#39; valuable time. Considering the rapid increase in COVID-19 infections, in order to automate the analysis of CT scans and minimize this loss of time, in this paper a new method is proposed using BO (BO)-based MobilNetv2, ResNet-50 models, SVM and kNN machine learning algorithms. In this method, an accuracy of 99.37\% was achieved with an average precision of 99.38\%, 99.36\% recall and 99.37\% F-score on datasets containing COVID and non-COVID classes. When we examine the performance results of the proposed method, it is predicted that it can be used as a decision support mechanism with high classification success for the diagnosis of COVID-19 with CT scans.},
  archive      = {J_NCA},
  author       = {Canayaz, Murat and Şehribanoğlu, Sanem and Özdağ, Recep and Demir, Murat},
  doi          = {10.1007/s00521-022-07052-4},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5349-5365},
  shortjournal = {Neural Comput. Appl.},
  title        = {COVID-19 diagnosis on CT images with bayes optimization-based deep neural networks and machine learning algorithms},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pooling in convolutional neural networks for medical image
analysis: A survey and an empirical study. <em>NCA</em>, <em>34</em>(7),
5321–5347. (<a
href="https://doi.org/10.1007/s00521-022-06953-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNN) are widely used in computer vision and medical image analysis as the state-of-the-art technique. In CNN, pooling layers are included mainly for downsampling the feature maps by aggregating features from local regions. Pooling can help CNN to learn invariant features and reduce computational complexity. Although the max and the average pooling are the widely used ones, various other pooling techniques are also proposed for different purposes, which include techniques to reduce overfitting, to capture higher-order information such as correlation between features, to capture spatial or structural information, etc. As not all of these pooling techniques are well-explored for medical image analysis, this paper provides a comprehensive review of various pooling techniques proposed in the literature of computer vision and medical image analysis. In addition, an extensive set of experiments are conducted to compare a selected set of pooling techniques on two different medical image classification problems, namely HEp-2 cells and diabetic retinopathy image classification. Experiments suggest that the most appropriate pooling mechanism for a particular classification task is related to the scale of the class-specific features with respect to the image size. As this is the first work focusing on pooling techniques for the application of medical image analysis, we believe that this review and the comparative study will provide a guideline to the choice of pooling mechanisms for various medical image analysis tasks. In addition, by carefully choosing the pooling operations with the standard ResNet architecture, we show new state-of-the-art results on both HEp-2 cells and diabetic retinopathy image datasets.},
  archive      = {J_NCA},
  author       = {Nirthika, Rajendran and Manivannan, Siyamalan and Ramanan, Amirthalingam and Wang, Ruixuan},
  doi          = {10.1007/s00521-022-06953-8},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5321-5347},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pooling in convolutional neural networks for medical image analysis: A survey and an empirical study},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nodes placement in wireless mesh networks using optimization
approaches: A survey. <em>NCA</em>, <em>34</em>(7), 5283–5319. (<a
href="https://doi.org/10.1007/s00521-022-06941-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless mesh networks (WMNs) have grown substantially and instigated numerous deployments during the previous decade thanks to their simple implementation, easy network maintenance, and reliable service coverage. Despite these proprieties, the nodes placement of such networks presents many challenges for network operators. In this paper, we present a survey of optimization approaches implemented to address the WMNs nodes placement problem. These approaches are classified into four main categories: exact approaches, heuristic approaches, meta-heuristic approaches, and hybrid approaches. For each category, a critical analysis is drawn according to targeted objectives, considered constraints, type of positioned nodes (Mesh Router and Mesh Gateway), location (discrete or continuous), and environment (static or dynamic). In the end, several new key search areas for WMNs nodes placement are suggested.},
  archive      = {J_NCA},
  author       = {Taleb, Sylia Mekhmoukh and Meraihi, Yassine and Gabis, Asma Benmessaoud and Mirjalili, Seyedali and Ramdane-Cherif, Amar},
  doi          = {10.1007/s00521-022-06941-y},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5283-5319},
  shortjournal = {Neural Comput. Appl.},
  title        = {Nodes placement in wireless mesh networks using optimization approaches: A survey},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Extreme learning machine-based field-oriented feedback
linearization speed control of permanent magnetic synchronous motors.
<em>NCA</em>, <em>34</em>(7), 5267–5282. (<a
href="https://doi.org/10.1007/s00521-021-06722-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An extreme learning machine (ELM)-based field-oriented feedback linearization speed control (ELMFOFLC) is proposed to enhance the robustness and tracking performance of a permanent magnetic synchronous motor (PMSM) system. First, the field-oriented control (FOC) is adopted to control the electromagnetic torque and the stator magnetic flux of PMSM independently with a detailed discussion on effects especially brought by the model parameter uncertainties on a FOC-based PMSM model. Then, three field-oriented feedback linearization controllers (FOFLCs) are designed to control the electromagnetic torque loop, the stator magnetic flux loop and the outer speed loop, respectively, and cancel nonlinearities in these three loops. Furthermore, a specific ELM is proposed based on the analysis of the characteristics and the uncertainties of PMSM with FOFLC. The stability is proved using the Lyapunov method. Finally, comprehensive simulations and experiments demonstrate that the proposed control is robust to various uncertainties with a superior speed tracking performance.},
  archive      = {J_NCA},
  author       = {Zheng, Yusai and Cao, Zhenwei and Wang, Song and Man, Zhihong and Chuei, Raymond},
  doi          = {10.1007/s00521-021-06722-z},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5267-5282},
  shortjournal = {Neural Comput. Appl.},
  title        = {Extreme learning machine-based field-oriented feedback linearization speed control of permanent magnetic synchronous motors},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Control of an AUV with completely unknown dynamics and
multi-asymmetric input constraints via off-policy reinforcement
learning. <em>NCA</em>, <em>34</em>(7), 5255–5265. (<a
href="https://doi.org/10.1007/s00521-021-06476-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a novel model-free optimal controller for nonlinear autonomous underwater vehicles (AUVs). It is considered that the AUV considered as the case study is subject to multi-asymmetric constrained inputs. To achieve the optimal controller, a performance index function with exponential discounted value term and input hyperbolic function is developed. Since it is assumed that the AUV dynamics are completely unknown, a model-free integral reinforcement learning (RL) strategy is established. The suggested approach uses the sampled data pairs of input and states. To implement the model-free Integral RL optimal controller, a neural network structure is suggested to estimate the performance index function and control policy. Finally, a numerical simulation and comparative results are given to verify the effectiveness of the proposal.},
  archive      = {J_NCA},
  author       = {Mohammadi, Mehdi and Arefi, Mohammad Mehdi and Vafamand, Navid and Kaynak, Okyay},
  doi          = {10.1007/s00521-021-06476-8},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5255-5265},
  shortjournal = {Neural Comput. Appl.},
  title        = {Control of an AUV with completely unknown dynamics and multi-asymmetric input constraints via off-policy reinforcement learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive full order sliding mode control for electronic
throttle valve system with fixed time convergence using extreme learning
machine. <em>NCA</em>, <em>34</em>(7), 5241–5253. (<a
href="https://doi.org/10.1007/s00521-021-06365-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel extreme learning machine (ELM)-based fixed time adaptive trajectory control for electronic throttle valve system with uncertain dynamics and external disturbances. The developed control strategy consists of a recursive full order terminal sliding mode structure based on the bilimit homogeneous property and a lumped uncertainty changing rate upper bound estimator via an adaptive ELM algorithm such that not only the fixed time convergence for both sliding variable and error states can be guaranteed, but also the chattering phenomenon can be suppressed effectively. The stability of the closed-loop system is proved rigorously based on Lyapunov theory. The simulation results are given to verify the superior tracking performance of the proposed control strategy.},
  archive      = {J_NCA},
  author       = {Hu, Youhao and Wang, Hai and Yazdani, Amirmehdi and Man, Zhihong},
  doi          = {10.1007/s00521-021-06365-0},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5241-5253},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive full order sliding mode control for electronic throttle valve system with fixed time convergence using extreme learning machine},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Control-oriented modeling and optimization for the
temperature and airflow management in an air-cooled data-center.
<em>NCA</em>, <em>34</em>(7), 5225–5240. (<a
href="https://doi.org/10.1007/s00521-021-06385-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a method for minimizing the power consumption of a data-center cooling system by optimizing the airflow pattern and the supplied cold air temperature simultaneously. To discover the potential benefits of reorganizing the rack flow rates, a gray-box fast-temperature evaluation model is proposed for the first time, which reflects the thermal relationship among the components of the data center and has low computational complexity. Next, a model-based constrained nonlinear optimization problem is formulated with the aim of minimizing the power consumption of both cooling fans and air conditioners. Meanwhile, the safety thermal guidelines are considered as the main constraints. At last, the optimal settings of rack airflow rates and supplied cold air temperature are obtained by solving the optimization problems. The simulation results show that the proposed method can yield an effective thermal management tool and reduce significant cooling power for air-cooled data centers.},
  archive      = {J_NCA},
  author       = {Fang, Qiu and Zhou, Jiakang and Wang, Shi and Wang, Yaonan},
  doi          = {10.1007/s00521-021-06385-w},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5225-5240},
  shortjournal = {Neural Comput. Appl.},
  title        = {Control-oriented modeling and optimization for the temperature and airflow management in an air-cooled data-center},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evasion guidance for air-breathing hypersonic vehicles
against unknown pursuer dynamics. <em>NCA</em>, <em>34</em>(7),
5213–5224. (<a
href="https://doi.org/10.1007/s00521-021-06250-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of hypersonic vehicles has motivated the related research dramatically while the evasion of the hypersonic vehicles becomes one of the challenging issues. Different from the work based on the premise that the pursuers’ information is fully known, in this paper the evasion guidance for air-breathing hypersonic vehicles (AHVs) against unknown pursuer dynamics is studied. The gradient descent is employed for parameter estimation of the unknown dynamics of the pursuer. The energy-optimized evasion guidance algorithm is further developed by taking the acceleration constraint and energy optimization into consideration. Under the proposed algorithm, the system can deal with the unknown pursuer dynamics effectively and provide more practical guidance for the evasion process. The simulation results show that the proposed method can enable the AHV to achieve successful evasion.},
  archive      = {J_NCA},
  author       = {Yan, Tian and Cai, Yuanli and Xu, Bin},
  doi          = {10.1007/s00521-021-06250-w},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5213-5224},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evasion guidance for air-breathing hypersonic vehicles against unknown pursuer dynamics},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Precise pose and assembly detection of generic tubular
joints based on partial scan data. <em>NCA</em>, <em>34</em>(7),
5201–5211. (<a
href="https://doi.org/10.1007/s00521-021-06246-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent and accurate determination of the position and orientation, or pose, of a workpiece which is manually placed is essential for automating fabrication tasks such as welding. In this paper, a novel algorithm based on minimizing the area of a boundary enclosing partial scan data points is proposed for detecting both the pose and assembly of tubular joints with the aid of reference ideal models. The proposed algorithm can also be applied to tubular joints with non-cylindrical cross sections. The fit-up information obtained can be used to determine whether realignment is required or combined with the pose information to re-plan paths for subsequent tasks. The focus of existing state-of-the-art is on objects with features, and the localization of featureless objects such as generic tubular joints using partial and sparse scan data remains a challenge. The proposed algorithm is applied to an actual robotic welding system to locate a tubular workpiece. Experiment results using the scan data as ground truth show that root mean square error is less than 1\% of the pipe diameters, considering both brace and chord components with diameters greater than 200 mm.},
  archive      = {J_NCA},
  author       = {Tan, Yan Zhi and Pang, Chee Khiang and Al Mamun, Abdullah and Wong, Fook Seng and Chew, Chee Meng},
  doi          = {10.1007/s00521-021-06246-6},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5201-5211},
  shortjournal = {Neural Comput. Appl.},
  title        = {Precise pose and assembly detection of generic tubular joints based on partial scan data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparative study of metaheuristic algorithms for optimal
sizing of standalone microgrids in a remote area community.
<em>NCA</em>, <em>34</em>(7), 5181–5199. (<a
href="https://doi.org/10.1007/s00521-021-06165-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper evaluates the performance and suitability of four different metaheuristic algorithms for optimal sizing of standalone microgrids in remote area. The studied metaheuristic algorithms are particle swarm optimization, differential evolution, water cycle algorithm and grey wolf optimization. These algorithms are applied to optimize the capacity of diesel generator, fuel tank, solar photovoltaic, wind turbine, and battery energy storage in four different AC-coupled standalone microgrids for a remote area community in South Australia. The objective function is selected as the net present value of electricity over a 20-year lifetime. The optimisation study is conducted based on the real data of annual load consumption, ambient temperature, solar insolation, and wind speed of the site. Capital, replacement, and maintenance costs of components in Australian market are incorporated for the economic analysis. An operating power reserve is maintained based on the static and dynamic reserve concepts. Uncertainty analysis based on 10-year real data of renewable energies and load consumption is conducted. Sensitivity analysis is provided for variations of the battery price and capacity. The performance of the applied algorithms is evaluated by comparing the economic and operational results, as well as the computational time and optimization convergence. It is found that differential evolution algorithm is unreliable for optimal sizing problem of the studied standalone microgrids..},
  archive      = {J_NCA},
  author       = {Fathi, Mohammad and Khezri, Rahmat and Yazdani, Amirmehdi and Mahmoudi, Amin},
  doi          = {10.1007/s00521-021-06165-6},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5181-5199},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparative study of metaheuristic algorithms for optimal sizing of standalone microgrids in a remote area community},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A nonrepetitive fault estimation design via iterative
learning scheme for nonlinear systems with iteration-dependent
references. <em>NCA</em>, <em>34</em>(7), 5169–5179. (<a
href="https://doi.org/10.1007/s00521-021-06176-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the fault estimation problem for a class of nonlinear nonrepetitive systems subject to iteration-dependent references. Firstly, based on the high-order internal model strategy, iterative learning fault estimation scheme is proposed to track the fault signals that varies with iteration index increasing. Then, the convergence of the presented method is achieved by the norm-based approach. Further, the proposed method is also extended to the uncertain systems with varying parameter matrices, discrete-time systems with Lipschitz perturbation and time-variant coefficients. Finally, the effectiveness of the proposed iterative learning fault estimation scheme is verified by numerical simulation studies.},
  archive      = {J_NCA},
  author       = {Li, Feng and Kenan, Du and Shuiqing, Xu and Ke, Zhang and Yi, Chai},
  doi          = {10.1007/s00521-021-06176-3},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5169-5179},
  shortjournal = {Neural Comput. Appl.},
  title        = {A nonrepetitive fault estimation design via iterative learning scheme for nonlinear systems with iteration-dependent references},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved neural network tracking control strategy for
linear motor-driven inverted pendulum on a cart and experimental study.
<em>NCA</em>, <em>34</em>(7), 5161–5168. (<a
href="https://doi.org/10.1007/s00521-021-05986-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much recently, based on the discrete-time nonlinear output regulation (NOR) theory, a neural network (NN) method combined with feedforward friction compensation was proposed to tackle the tracking problem of the linear motor-driven inverted pendulum on a cart (IPC) system, where the NN was used to approximate the solution of the discrete regulator equations (DREs) for the IPC system whose dimension is equal to the sum of the dimensions of the system state and the control input. However, it is quite tedious to calculate the approximate solution and the feedforward friction compensation requires a complicated off-line friction identification procedure. This paper proposes an improved NN method combined with adaptive friction compensation for this tracking problem. In particular, the NN is used to approximate a feedforward function instead of the solution of the DREs. Since the dimension of the feedforward function is the same as that of the control input, the computational efficiency is improved. Moreover, the adaptive friction compensator is easy to implement since it does not need to establish detailed friction model. Experimental results demonstrate that our control strategy can lead to much more satisfactory tracking performance compared with the existing NN control strategy.},
  archive      = {J_NCA},
  author       = {Ping, Zhaowu and Zhou, Mengya and Liu, Chenxi and Huang, Yunzhi and Yu, Ming and Lu, Jun-Guo},
  doi          = {10.1007/s00521-021-05986-9},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5161-5168},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved neural network tracking control strategy for linear motor-driven inverted pendulum on a cart and experimental study},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Remaining useful life predictions for turbofan engine
degradation based on concurrent semi-supervised model. <em>NCA</em>,
<em>34</em>(7), 5151–5160. (<a
href="https://doi.org/10.1007/s00521-021-06089-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a crucial and expensive component of the aircraft, it is important to effectively predict its remaining useful life (RUL) so as to reduce maintenance costs and improve maintenance strategies. In this paper, a novel concurrent semi-supervised model is proposed to estimate the RUL of the aero-engine. This semi-supervised model can provide satisfying prediction results with only a small amount of labeled data. And the concurrent structure is designed to improve the stability and accuracy of the prediction. The proposed method is verified on the popular C-MAPSS dataset and is compared with a variety of state-of-the-art approaches. The experimental results demonstrate that the proposed method is effective in the task of remaining useful life prediction.},
  archive      = {J_NCA},
  author       = {Wang, Tiancheng and Guo, Di and Sun, Xi-Ming},
  doi          = {10.1007/s00521-021-06089-1},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5151-5160},
  shortjournal = {Neural Comput. Appl.},
  title        = {Remaining useful life predictions for turbofan engine degradation based on concurrent semi-supervised model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Path-tracking control for autonomous vehicles using
double-hidden-layer output feedback neural network fast nonsingular
terminal sliding mode. <em>NCA</em>, <em>34</em>(7), 5135–5150. (<a
href="https://doi.org/10.1007/s00521-021-06101-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a double-hidden-layer output feedback neural network fast nonsingular terminal sliding mode control strategy is developed for path-tracking tasks of autonomous vehicles. First, a vehicle kinematic-and-dynamic model is established to describe the vehicle’s fundamental lateral dynamics in path-tracking behavior. Afterwards, detailed design procedure of the proposed controller is shown, where the control system’s stability is verified in the Lyapunov sense. Finally, MATLAB-Carsim co-simulations are executed for the aim of testing the control performance. Simulation results illustrate that the designed control algorithm possesses remarkable superiority reflected in higher tracking precision, faster convergence rate and firmer robustness in comparison with a conventional sliding mode controller and a nonsingular terminal sliding mode controller.},
  archive      = {J_NCA},
  author       = {Sun, Zhe and Zou, Jiayang and He, Defeng and Zhu, Wei},
  doi          = {10.1007/s00521-021-06101-8},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5135-5150},
  shortjournal = {Neural Comput. Appl.},
  title        = {Path-tracking control for autonomous vehicles using double-hidden-layer output feedback neural network fast nonsingular terminal sliding mode},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive NN-based finite-time trajectory tracking control of
wheeled robotic systems. <em>NCA</em>, <em>34</em>(7), 5119–5133. (<a
href="https://doi.org/10.1007/s00521-021-06021-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The trajectory tracking and finite-time control problems of wheeled robotic systems with nonlinear dynamics and uncertainties are investigated in this paper. An adaptive neural network (NN)-based control technique is developed to deal with the nonlinearities and uncertainties. Then, finite-time dynamic control and kinematic control schemes are constructed on the basis of the adaptive estimations to remedy the negative influence of uncertainties and nonlinearities. Specific forward and azimuthal angular velocities are developed by using NN-based kinematic control schemes to obtain the finite-time tracking of the desired position trajectory for the wheeled robotic system. Furthermore, the asymptotic tracking of the specific forward and azimuthal angular velocities is further achieved based on the finite-time dynamic control schemes with uncertainties and nonlinear dynamics. The efficacy of the developed finite-time tracking control approach is substantiated by a robotic system.},
  archive      = {J_NCA},
  author       = {Jin, Xiaozheng and Zhao, Zhiye and Wu, Xiaoming and Chi, Jing and Deng, Chao},
  doi          = {10.1007/s00521-021-06021-7},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5119-5133},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive NN-based finite-time trajectory tracking control of wheeled robotic systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural network-based robust finite-time attitude
stabilization for rigid spacecraft under angular velocity constraint.
<em>NCA</em>, <em>34</em>(7), 5107–5117. (<a
href="https://doi.org/10.1007/s00521-021-06056-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of attitude stabilization control of spacecraft under angular velocity constraint is investigated. A state-constrained finite-time attitude control scheme is designed by making full use of the model feature of the quaternion. Based on the homogeneous domination approach, the finite-time stability of the closed-loop system is proved. It proves that the angular velocity can be constrained within the limited range at any time. For the attitude loop dynamics subsystem with external disturbances, based on a radial basis function neural network, an integral terminal sliding mode controller is proposed. Finally, the validity and advantages of the proposed control scheme are demonstrated in the simulation section compared with the other two control methods.},
  archive      = {J_NCA},
  author       = {Yu, Bo and Du, Haibo and Ding, Lijian and Wu, Di and Li, Hua},
  doi          = {10.1007/s00521-021-06056-w},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5107-5117},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural network-based robust finite-time attitude stabilization for rigid spacecraft under angular velocity constraint},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finite-time lag synchronization for uncertain complex
networks involving impulsive disturbances. <em>NCA</em>, <em>34</em>(7),
5097–5106. (<a
href="https://doi.org/10.1007/s00521-021-05987-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the finite-time lag synchronization (FTLS) of uncertain complex networks involving impulsive disturbance effects. By designing two different controllers, some Lyapunov-based conditions are established in terms of linear matrix inequalities to ensure the FTLS of impulsive systems, where the upper bound of the synchronizing times can be estimated via constructing Lyapunov functions. It is interesting to discover that the synchronizing time depends not only on the initial value but also on the impulse sequences, which implies that different impulses will lead to different synchronization times. Finally, a numerical example is given to illustrate the feasibility and effectiveness of the proposed FTLS criterion.},
  archive      = {J_NCA},
  author       = {Yang, Xueyan and Li, Xiaodi and Duan, Peiyong},
  doi          = {10.1007/s00521-021-05987-8},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5097-5106},
  shortjournal = {Neural Comput. Appl.},
  title        = {Finite-time lag synchronization for uncertain complex networks involving impulsive disturbances},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fault diagnosis and prognosis of steer-by-wire system based
on finite state machine and extreme learning machine. <em>NCA</em>,
<em>34</em>(7), 5081–5095. (<a
href="https://doi.org/10.1007/s00521-021-06028-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an integrated condition monitoring method combining model-based fault diagnosis and data-driven prognosis is proposed for steer-by-wire (SBW) system. First, the SBW system is modeled by bond graph (BG) technique and a two-degree-of-freedom (2-DOF) state-space model of the vehicle is built. Based on the 2-DOF model, the estimated self-aligning torque is used for the control of feedback motor. The fault detection is carried out by evaluating the analytical redundancy relations derived from the BG model. Since the fault isolation performance is essential to subsequent fault estimation process, a new fault isolation method based on finite state machine is developed to improve the isolation ability by combining the dependent and independent analytical redundancy relations, where the number of potential faults could be decreased. In order to refine the possible fault set to determine the true fault, a cuckoo search (CS)–particle filter is developed for fault estimation. Based on the estimated true fault, prognosis can be implemented which is important to achieve failure prevention and prolong system lifespan. To this end, an optimized extreme learning machine (OELM) is proposed where the input weights and hidden layer biases are optimized by CS. Based on data representing fault values obtained from the fault identification, the OELM model is trained for remaining useful life prediction of failing component. Finally, the proposed methodologies are validated by simulations.},
  archive      = {J_NCA},
  author       = {Lan, Dun and Yu, Ming and Huang, Yunzhi and Ping, Zhaowu and Zhang, Jie},
  doi          = {10.1007/s00521-021-06028-0},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5081-5095},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fault diagnosis and prognosis of steer-by-wire system based on finite state machine and extreme learning machine},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep neural network-based hierarchical learning method for
dispatch control of multi-regional power grid. <em>NCA</em>,
<em>34</em>(7), 5063–5079. (<a
href="https://doi.org/10.1007/s00521-021-06008-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-regional power grid with interconnected tie-lines has become an increasingly important structure for current power systems, and can efficiently reallocate power resources on a large scale. The power dispatch of a multi-regional power grid involving multiple resources plays a key role in maintaining system balance and improving operating profit. Current optimisation methods for this dispatch problem need to execute a complete optimisation calculation at each dispatch moment, and lack online decision and optimisation abilities. Therefore, we introduce a deep neural network-based hierarchical learning optimisation method to establish an online approach to focused coordination dispatch problems. The method can realise system optimisation based solely on historical operating data. First, the focused coordination dispatch problem is formulated mathematically. Then, we establish a hierarchical structure suitable for online learning methods. Under this designed structure, we establish a learning optimisation model for each agent, and introduce a deep reinforcement learning algorithm for solving the optimisation problems online. Simulation results based on the IEEE 300-bus system are presented to validate the efficiency and availability of the proposed hierarchical method.},
  archive      = {J_NCA},
  author       = {Tang, Hao and Lv, Kai and Bak-Jensen, Birgitte and Pillai, Jayakrishnan Radhakrishna and Wang, Zhengfeng},
  doi          = {10.1007/s00521-021-06008-4},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5063-5079},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep neural network-based hierarchical learning method for dispatch control of multi-regional power grid},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reinforcement learning-based nonlinear tracking control
system design via LDI approach with application to trolley system.
<em>NCA</em>, <em>34</em>(7), 5055–5062. (<a
href="https://doi.org/10.1007/s00521-021-05909-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel scheme for the tracking problem of nonlinear systems is proposed. First, as a new technology of neural network in control field, linear differential inclusion is used to approximate the nonlinear term for the entire system. Based on the equivalent linear system, tracking reference signal is given and a new augmented system is built. According to the mentioned value function, two reinforcement learning algorithms are proposed to design the optimal control law. Notice that the online algorithm does not involve the system dynamics and tracking dynamics. In the simulation section, the model of trolley system is given to prove the effectiveness and accuracy of the scheme proposed in this paper.},
  archive      = {J_NCA},
  author       = {Tu, Yidong and Fang, Haiyang and Yin, Yanyan and He, Shuping},
  doi          = {10.1007/s00521-021-05909-8},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5055-5062},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reinforcement learning-based nonlinear tracking control system design via LDI approach with application to trolley system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploiting a fleet of UAVs for monitoring and data
acquisition of a distributed sensor network. <em>NCA</em>,
<em>34</em>(7), 5041–5054. (<a
href="https://doi.org/10.1007/s00521-021-05906-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes an efficient data collection strategy exploiting a team of unmanned aerial vehicles (UAVs) to monitor and collect the data of a large distributed sensor network usually used for environmental monitoring, meteorology, agriculture, and renewable energy applications. The study develops a collaborative mission planning system that enables a team of UAVs to conduct and complete the mission of sensors’ data collection collaboratively while considering existing constrains of the UAV payload and battery capacity. The proposed mission planner system employs the differential evolution optimization algorithm enabling UAVs to maximize the number of visited sensor nodes given the priority of the sensors and avoiding redundant collection of sensors’ data. The proposed mission planner is evaluated through extensive simulation and comparative analysis. The simulation results confirm the effectiveness and fidelity of the proposed mission planner to be used for the distributed sensor network monitoring and data collection.},
  archive      = {J_NCA},
  author       = {MahmoudZadeh, Somaiyeh and Yazdani, Amirmehdi and Elmi, Atabak and Abbasi, Amin and Ghanooni, Pooria},
  doi          = {10.1007/s00521-021-05906-x},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5041-5054},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploiting a fleet of UAVs for monitoring and data acquisition of a distributed sensor network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust adaptive backstepping INTSM control for robotic
manipulators based on ELM. <em>NCA</em>, <em>34</em>(7), 5029–5039. (<a
href="https://doi.org/10.1007/s00521-021-05824-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a novel control algorithm to deal with trajectory tracking control problems of robotic manipulators based on adaptive backstepping integral nonsingular terminal sliding mode control (BINTSMC). The proposed approach is developed based on an integration between the integral nonsingular terminal sliding mode control (INTSMC) and stability analysis procedure of backstepping control technique. In addition, the extreme learning machine (ELM) learning algorithm is introduced to approximate lumped uncertain component of the dynamics model. The approximated lumped uncertain terms are transmitted to rebuild the dynamics and provide a compensation feedback for control systems. Moreover, the robust term is utilized to counteract the approximation residual error, wherein the nonconstant ELM approximation error is analyzed. The superior performance of the BINTSMC is validated by comparing conventional NTSMC in the simulations.},
  archive      = {J_NCA},
  author       = {Gao, Miao-Miao and Jin, Xiao-Zheng and Ding, Li-Jian},
  doi          = {10.1007/s00521-021-05824-y},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5029-5039},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust adaptive backstepping INTSM control for robotic manipulators based on ELM},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced myoelectric control against arm position change
with weighted recursive gaussian process. <em>NCA</em>, <em>34</em>(7),
5015–5028. (<a
href="https://doi.org/10.1007/s00521-021-05743-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, there has been huge advancement in biomechatronic systems by the integration of pattern recognition and regression algorithms. In many myoelectric control studies, high accuracy in estimating a subject’s wrist movement was reported by measuring electromyography (EMG) signal from subjects’ forearms. However, many algorithms suffer from limited robustness against undesired disturbance in the real-world environment. In particular, arm position change is an inevitable disturbance that results in severe degradation of performance. In this study, the weighted recursive Gaussian process (WRGP) is proposed to overcome this effect. In the algorithm, the noise variance is weighted by covariate shift adaptation, which is able to handle the uncertainties. WRGP is compared with the commonly used linear regression (LR) and multilayer perceptron (MLP). LR, MLP, and WRGP are trained with the EMG dataset acquired at an arm position and tested with the different EMG dataset acquired at another arm position. Also, WRGP with uniform weights and WRGP with the weights estimated from the covariate shift adaptation are compared. The results show that WRGP with uniform weights is more robust than LR and MLP regardless of the arm position (0.16 and 0.16 higher average $$R^2$$ index, respectively). The performance of WRGP with the weights estimated from the covariate shift adaptation is significantly higher ( $$p&lt;0.05$$ ) than the performance of LR and MLP (0.30 and 0.33 higher average $$R^2$$ index, respectively).},
  archive      = {J_NCA},
  author       = {Jung, Myong Chol and Chai, Rifai and Zheng, Jinchuan and Nguyen, Hung},
  doi          = {10.1007/s00521-021-05743-y},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5015-5028},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced myoelectric control against arm position change with weighted recursive gaussian process},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on computational intelligence-based modeling,
control and estimation in modern mechatronic systems. <em>NCA</em>,
<em>34</em>(7), 5011–5013. (<a
href="https://doi.org/10.1007/s00521-021-06818-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Wang, Hai and Zheng, Jinchuan and Lu, Yuqian and Ding, Shihong and Chaoui, Hicham},
  doi          = {10.1007/s00521-021-06818-6},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5011-5013},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on computational intelligence-based modeling, control and estimation in modern mechatronic systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time super-resolution mapping of locally anisotropic
grain orientations for ultrasonic non-destructive evaluation of
crystalline material. <em>NCA</em>, <em>34</em>(6), 4993–5010. (<a
href="https://doi.org/10.1007/s00521-021-06670-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the spatially varying microstructures of heterogeneous and locally anisotropic media non-destructively is necessary for the accurate detection of flaws and reliable monitoring of manufacturing processes. Conventional algorithms used for solving this inverse problem come with significant computational cost, particularly in the case of high-dimensional, nonlinear tomographic problems, and are thus not suitable for near-real-time applications. In this paper, for the first time, we propose a framework which uses deep neural networks (DNNs) with full aperture, pitch-catch and pulse-echo transducer configurations, to reconstruct material maps of crystallographic orientation. We also present the first application of generative adversarial networks (GANs) to achieve super-resolution of ultrasonic tomographic images, providing a factor-four increase in image resolution and up to a 50\% increase in structural similarity. The importance of including appropriate prior knowledge in the GAN training data set to increase inversion accuracy is demonstrated: known information about the material’s structure should be represented in the training data. We show that after a computationally expensive training process, the DNNs and GANs can be used in less than 1 second (0.9 s on a standard desktop computer) to provide a high-resolution map of the material’s grain orientations, addressing the challenge of significant computational cost faced by conventional tomography algorithms.},
  archive      = {J_NCA},
  author       = {Singh, Jonathan and Tant, Katherine and Curtis, Andrew and Mulholland, Anthony},
  doi          = {10.1007/s00521-021-06670-8},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4993-5010},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time super-resolution mapping of locally anisotropic grain orientations for ultrasonic non-destructive evaluation of crystalline material},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design of innovative CAPTCHA for hindi language.
<em>NCA</em>, <em>34</em>(6), 4957–4992. (<a
href="https://doi.org/10.1007/s00521-021-06686-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing a CAPTCHA possessing the property of a sweet spot is always a challenge. Text-based CAPTCHAs are popular among websites. The history of text-based schemes shows that these schemes are broken with a very high success rate. Most of these broken schemes are designed using English language-based letters. It motivated the researchers to design non-English-based CAPTCHA schemes. The author has also successfully broken some Hindi language-based CAPTCHA schemes. After breaking the existing 20 typical CAPTCHA designs in the Hindi language, the authors have observed some serious limitations in a text-based scheme. In this article, the authors have used important guidelines that are proposed in the previous work by the authors. The authors implemented these guidelines to design a secure and usable CAPTCHA in the Hindi language. In this article, we have developed a new CAPTCHA based on the Hindi language and tested the proposed design from a security and usability point of view. The proposed novel CAPTCHA scheme first time uses a combination of printed and handwritten Hindi characters. The proposed scheme is 100\% secure from computer attacks and also 90\% usable.},
  archive      = {J_NCA},
  author       = {Kumar, Mohinder and Jindal, M. K. and Kumar, Munish},
  doi          = {10.1007/s00521-021-06686-0},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4957-4992},
  shortjournal = {Neural Comput. Appl.},
  title        = {Design of innovative CAPTCHA for hindi language},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new extension of FDOSM based on pythagorean fuzzy
environment for evaluating and benchmarking sign language recognition
systems. <em>NCA</em>, <em>34</em>(6), 4937–4955. (<a
href="https://doi.org/10.1007/s00521-021-06683-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many studies have recently developed real-time sign language recognition system (SLRS)-based DataGlove wearable electronic devices for deaf and dumb to assort hand gestures as having an identical meaning in spoken language. An evaluation and benchmarking of these systems are important towards understanding the most suitable for fulfilling all essential requirements. This process falls under the multi-criteria decision-making (MCDM) problem because of different issues, namely, multi-evaluation criteria, criteria importance and data variation. Therefore, the MCDM solution is necessary to solve complex problems. The latest MCDM method called the fuzzy decision by the opinion score method (FDOSM) and its extension are considered the most powerful and suitable methods. However, these methods still suffer from vagueness issues. According to the advantage of Pythagorean fuzzy numbers in solving such issues, this study extended FDOSM into Pythagorean fuzzy set based on the Interactive hybrid arithmetic mean (IHAM) operator (called PFDOSM-IHAM) to evaluate and benchmark effectively the real-time SLRS. The methodology is presented on the basis of the two phases. Firstly, a decision matrix is proposed on the basis of ‘performance evaluation criteria’ and ‘SLRS set’. Secondly, the development of the PFDOSM-IHAM method is provided considering the following two stages: data transformation and processing. The following results are presented. (1) Variations are observed in the individual benchmarking results of real-time SLRS depending on each decision maker. (2) The group benchmarking results indicate that the 29th real-time SLRS was the best, whereas the worst real-time SLRS was attributed to SLRS (6th). (3) In evaluation, the statistical test indicates that the benchmarked systems from PFDOSM-IHAM are undergoing a systematic ranking. (4) Comparative analysis confirmed the efficacy of the proposed PFDOSM-IHAM against of the other well-known MCDM methods running on Pythagorean fuzzy numbers.},
  archive      = {J_NCA},
  author       = {Al-Samarraay, Mohammed S. and Salih, Mahmood M. and Ahmed, Mohamed A. and Zaidan, A. A. and Albahri, O. S. and Pamucar, Dragan and AlSattar, H. A. and Alamoodi, A. H. and Zaidan, B. B. and Dawood, Kareem and Albahri, A. S.},
  doi          = {10.1007/s00521-021-06683-3},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4937-4955},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new extension of FDOSM based on pythagorean fuzzy environment for evaluating and benchmarking sign language recognition systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance enhancement and ANN prediction of r600a vapour
compression refrigeration system using CuO/Sio2 hybrid nanolubricants:
An energy conservation approach. <em>NCA</em>, <em>34</em>(6),
4923–4935. (<a
href="https://doi.org/10.1007/s00521-021-06681-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study improvement in performance of vapour compression refrigeration using R600a as refrigerant is enhanced by using CuO/Sio2 hybrid nanolubricants. The experiment was performed with four various nanolubricants concentration of 0.2, 0.4, 0.6 and 0.8 g/L and refrigerant mass charges of 60, 70 and 80 g. Three significant variables like coefficient of performance, cooling effect and compressor work was determined. Artificial neural network (ANN) techniques are applied to predict the R600a refrigerator performance dispersed with hybrid nanolubricants by training the input parameters like nanolubricants concentrations, refrigerant mass flow rate, evaporator and condenser temperatures. MATLAB tool box is used to predict the experimental data’s. In the network, the back propagation algorithm was utilized. The ANN predicted outputs in comparison to experimental output of refrigeration effect, compressor and COP were significantly enhanced. The ANN predicted coefficient of performance is enhanced from 2.4 to 3.8 with 36\% increase in COP, refrigeration effect from 112 to 253 W with 55\% increase in refrigeration effect and reduction in compressor work from 147 to 108 W with 27\% reduction in power utilized by the compressor in comparison with the system without dispersion of nanolubricant. The ANN model predicted output is accepted with the experimental and the values of mean square error and percentage error are also provided. The predicted data are useful and significant for substituting CuO/Sio2 hybrid nanolubricants with vapour compression refrigeration without addition of nanoparticles and this trained output provide the optimization of CuO/Sio2 hybrid nanolubricants in household refrigerator.},
  archive      = {J_NCA},
  author       = {Senthilkumar, A. and Anderson, A. and Alagarsamy, Saravanan},
  doi          = {10.1007/s00521-021-06681-5},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4923-4935},
  shortjournal = {Neural Comput. Appl.},
  title        = {Performance enhancement and ANN prediction of r600a vapour compression refrigeration system using CuO/Sio2 hybrid nanolubricants: An energy conservation approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Borrowing wisdom from world: Modeling rich external
knowledge for chinese named entity recognition. <em>NCA</em>,
<em>34</em>(6), 4905–4922. (<a
href="https://doi.org/10.1007/s00521-021-06680-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chinese named entity recognition (CNER) is one of the fundamental tasks in natural language processing (NLP), supporting a wide range of downstream NLP tasks for Chinese texts. The recent best-performing CNER works have extensively shown that by using external knowledge, such as lexicons and syntactic dependency features, considerable task improvements can be secured. Nevertheless, we note that current works still fail to sufficiently integrate rich external knowledge to boost the CNER performances further. In this work, we propose to enhance the CNER by incorporating heterogeneous knowledge from the linguistic, syntactic and semantic perspectives. For linguistic source, we consider (1) part-of-speech (POS) tags and (2) multi-granularity lexicons, including characters, words and subwords. For syntactic source, we adopt label-wise character-level syntactic dependency structures. For semantic source, we employ (1) BERT contextualized representations and (2) rich sememe representations from HowNet. We build heterogeneous graphs based on the multi-granularity lexicons and encode them with graph attention neural network (GAT). We also propose an innovative label-aware graph convolutional network (LGCN) for modeling the syntactic dependency arcs and labels simultaneously. Further, we present a sememe composition attention module for better injecting the sememe representations. Our system achieves new state-of-the-art CNER performances over current best baselines on four benchmark datasets. Further in-depth analysis has been conducted to reveal the contribution of each used resource, as well as the strengths of our proposed methods for the task improvements.},
  archive      = {J_NCA},
  author       = {Nie, Yu and Zhang, Yilai and Peng, Yongkang and Yang, Lisha},
  doi          = {10.1007/s00521-021-06680-6},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4905-4922},
  shortjournal = {Neural Comput. Appl.},
  title        = {Borrowing wisdom from world: Modeling rich external knowledge for chinese named entity recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heuristic-based automatic pruning of deep neural networks.
<em>NCA</em>, <em>34</em>(6), 4889–4903. (<a
href="https://doi.org/10.1007/s00521-021-06679-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of a deep neural network (deep NN) is dependent upon a significant number of weight parameters that need to be trained which is a computational bottleneck. The growing trend of deeper architectures poses a restriction on the training and inference scheme on resource-constrained devices. Pruning is an important method for removing the deep NN’s unimportant parameters and making their deployment easier on resource-constrained devices for practical applications. In this paper, we proposed a heuristics-based novel filter pruning method to automatically identify and prune the unimportant filters and make the inference process faster on devices with limited resource availability. The selection of the unimportant filters is made by a novel pruning estimator ( $$\gamma$$ ). The proposed method is tested on various convolutional architectures AlexNet, VGG16, ResNet34, and datasets CIFAR10, CIFAR100, and ImageNet. The experimental results on a large-scale ImageNet dataset show that the FLOPs of the VGG16 can be reduced up to 77.47\%, achieving $$\approx ~5x$$ inference speedup. The FLOPs of a more popular ResNet34 model are reduced by 41.94\% while retaining competitive performance compared to other state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Choudhary, Tejalal and Mishra, Vipul and Goswami, Anurag and Sarangapani, Jagannathan},
  doi          = {10.1007/s00521-021-06679-z},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4889-4903},
  shortjournal = {Neural Comput. Appl.},
  title        = {Heuristic-based automatic pruning of deep neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of accurate automated language identification
model using polymer pattern and tent maximum absolute pooling
techniques. <em>NCA</em>, <em>34</em>(6), 4875–4888. (<a
href="https://doi.org/10.1007/s00521-021-06678-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various language identification tools and methods have been used in the real world. These applications can detect language using text or images. However, there is no speech-based language automated identification tool available. Therefore, many studies have been presented to overcome this problem. This work presents an automated high accurate language identification model and developed a new corpus for language identification. The developed language identification model uses two novel methods: (i) polymer pattern (PP) and (ii) tent maximum absolute pooling (TMAP). These methods help to extract both low- and high-frequency features. In order to choose the most informative features, a threshold-based iterative feature selector is presented. The proposed PP- and TMAP-based model has attained an accuracy of 97.87\% and 99.70\% using our newly developed and VoxForge datasets, respectively, with kNN classifier with tenfold cross-validation.},
  archive      = {J_NCA},
  author       = {Tuncer, Turker and Dogan, Sengul and Akbal, Erhan and Cicekli, Abdullah and Rajendra Acharya, U.},
  doi          = {10.1007/s00521-021-06678-0},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4875-4888},
  shortjournal = {Neural Comput. Appl.},
  title        = {Development of accurate automated language identification model using polymer pattern and tent maximum absolute pooling techniques},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy k-plane clustering method with local spatial
information for segmentation of human brain MRI image. <em>NCA</em>,
<em>34</em>(6), 4855–4874. (<a
href="https://doi.org/10.1007/s00521-021-06677-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human brain MRI images are complex, and matters present in the brain exhibit non-spherical shape. There exits uncertainty in the overlapping structure of brain tissue, i.e. a lack of distinctness in the class definition. Soft clustering methods can efficiently handle the uncertainty, and plane-based clustering methods are found to be more efficient for non-spherical shape data. Fuzzy k-plane clustering (FkPC) method is a soft plane-based clustering algorithms that can handle the uncertainty in medical images, but its performance degraded in the presence of noise. In this research work, we incorporated local spatial information in the FkPC clustering method to handle the noise present in the image. This spatial regularization term included in the proposed FkPC_S method refines the membership value of noisy pixel with the help of immediate neighbour pixels information. To show the effectiveness of the proposed FkPC_S method, extensive experiments are performed on one synthetic image and two publicly available human brain MRI datasets. The performance of the proposed method is compared with 10 related methods in terms of average segmentation accuracy and dice score. The experiments result shows that the proposed FkPC_S method is superior in comparison with 10 related methods in the presence of noise. Statistically significance difference and superior performance of the proposed method in comparison with other methods are also found using Friedman test.},
  archive      = {J_NCA},
  author       = {Kumar, Puneet and Kumar, Dhirendra and Agrawal, Ramesh Kumar},
  doi          = {10.1007/s00521-021-06677-1},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4855-4874},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fuzzy k-plane clustering method with local spatial information for segmentation of human brain MRI image},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exocytotic vesicle fusion classification for early disease
diagnosis using a mobile GPU microsystem. <em>NCA</em>, <em>34</em>(6),
4843–4854. (<a
href="https://doi.org/10.1007/s00521-021-06676-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses monitoring vesicle fusions occurring during the exocytosis process, which is the main way of intercellular communication. Certain vesicle behaviors may also indicate certain precancerous conditions in cells. For this purpose we designed a system able to detect two main types of exocytosis: a full fusion and a kiss-and-run fusion, based on data from multiple amperometric sensors at once. It uses many instances of small perceptron neural networks in a massively parallel manner and runs on Jetson TX2 platform, which uses a GPU for parallel processing. Based on performed benchmarking, approximately 140,000 sensors can be processed in real time within the sensor sampling period equal to 10 ms and an accuracy of 99 $$\%$$ . The work includes an analysis of the system performance with varying neural network sizes, input data sizes, and sampling periods of fusion signals.},
  archive      = {J_NCA},
  author       = {Szczęsny, Szymon and Pietrzak, Paweł},
  doi          = {10.1007/s00521-021-06676-2},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4843-4854},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exocytotic vesicle fusion classification for early disease diagnosis using a mobile GPU microsystem},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Long short term memory based functional characterization
model for unknown protein sequences using ensemble of shallow and deep
features. <em>NCA</em>, <em>34</em>(6), 4831–4841. (<a
href="https://doi.org/10.1007/s00521-021-06674-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous protein sequences are evolving with advances in high-throughput technologies and genomic projects. Functional characterization of the variable length unknown protein sequence (VLUPS) provides valuable insights into the disease diagnosis and drug design. In this paper, subcellular localization-based deep learning framework has been proposed for the functional characterization of VLUPS using ensemble of shallow and deep features. Pseudo-amino acid composition and pseudo-position specific scoring matrix features of protein sequences are established as shallow feature. Deep feature and Prot_Seq of the raw protein sequences are extracted through one-hot encoding and convolutional neural network. Next, shallow and deep features are embedded as hybrid feature vector while preserving the sequence-order-information and protein residue properties. To handle the skewed and variable length protein sequence data, ensemble deep learning model has been formed using feature subset ensemble and long short-term memory. The proposed model is trained and tested using subsets of shallow, deep, and hybrid features of Gram-positive (G+) and Gram-negative (G-) datasets with 5-fold cross-validation. Accuracy attained by the model is 96.77\% with known G+ dataset and 98.32\% using G- dataset. Achieved accuracy for VLUPS is 79.29\% with the G+ dataset and 76.84\% for G- dataset.},
  archive      = {J_NCA},
  author       = {Agrawal, Saurabh and Sisodia, Dilip Singh and Nagwani, Naresh Kumar},
  doi          = {10.1007/s00521-021-06674-4},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4831-4841},
  shortjournal = {Neural Comput. Appl.},
  title        = {Long short term memory based functional characterization model for unknown protein sequences using ensemble of shallow and deep features},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning for short-term origin–destination passenger
flow prediction under partial observability in urban railway systems.
<em>NCA</em>, <em>34</em>(6), 4813–4830. (<a
href="https://doi.org/10.1007/s00521-021-06669-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term origin–destination (OD) flow prediction is vital for operations planning, control, and management in urban railway systems. While the entry and exit passenger demand prediction problem has been studied in various studies, the OD passenger flow prediction problem receives much less attention. One key challenge for short-term OD flow prediction is the partial observability of the OD flow information due to trips having not been completed at a certain time interval. This paper develops a novel deep learning architecture for the OD flow prediction in urban railway systems and examines various mechanisms for data representation and for dealing with partial information. The deep learning framework consists of three main components, including multiple LSTM networks with an attention mechanism capturing short/long-term temporal dependencies, a temporally shifted graph matrix for spatiotemporal correlations, and a reconstruction mechanism for partial OD flow observations. The model is validated using smart card data from Hong Kong’s Mass Transit Railway (MTR) system and compared with state-of-the-art prediction models. Experiments are designed to examine the characteristics of the proposed approach and its various components. The results show the superior performance (accuracy and robustness) of the proposed model and also the importance of partial observations of OD flow information in improving prediction performance. In terms of data representation, predicting the deviation of OD flows performs consistently better than predicting OD flows directly.},
  archive      = {J_NCA},
  author       = {Jiang, Wenhua and Ma, Zhenliang and Koutsopoulos, Haris N.},
  doi          = {10.1007/s00521-021-06669-1},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4813-4830},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning for short-term origin–destination passenger flow prediction under partial observability in urban railway systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel deep learning approach for intelligent fault
diagnosis applications based on time-frequency images. <em>NCA</em>,
<em>34</em>(6), 4803–4812. (<a
href="https://doi.org/10.1007/s00521-021-06668-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) techniques have been gaining ground for intelligent equipment/process fault diagnosis applications. However, employing DL methods for such applications comes with its technical challenges. The DL methods are utilized to extract features from raw data automatically, which leads up to its own complications in data preprocessing and/or feature engineering phases. Moreover, another difficulty arises when DL methods are employed utilizing single type of sensor data as the performance of a fault diagnosis application is hindered. To address these issues, we propose utilization of a deep residual network-based multi-sensory data fusion method. The method is established on time-frequency images obtained by short-time Fourier transform to diagnose machine faults. The experimental results demonstrate that the proposed model combining different types of measured signals can diagnose bearing conditions on machines more effectively compared to a single type of measured signal in terms of diagnostic accuracy.},
  archive      = {J_NCA},
  author       = {Gültekin, Özgür and Çinar, Eyüp and Özkan, Kemal and Yazıcı, Ahmet},
  doi          = {10.1007/s00521-021-06668-2},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4803-4812},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel deep learning approach for intelligent fault diagnosis applications based on time-frequency images},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep neural network-based relation extraction: An overview.
<em>NCA</em>, <em>34</em>(6), 4781–4801. (<a
href="https://doi.org/10.1007/s00521-021-06667-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge is a formal way of understanding the world, providing human-level cognition and intelligence for the next-generation artificial intelligence (AI). An effective way to automatically acquire this important knowledge, called Relation Extraction (RE), plays a vital role in Natural Language Processing (NLP). To date, there are amount of studies for RE in previous works, among which these technologies based on deep neural networks (DNNs) have become the mainstream direction of this research. In particular, the supervised and distant supervision methods based on DNNs are the most popular and reliable solutions for RE, whose various evolutions on structure and settings have affected this task. Understanding the model structure and related settings will give the researchers a deep insight into RE. However, little research has been done on them. Hence, this paper starts from these two points and carries out analysis around the mainstream research routes, supervised and distant supervision. Meanwhile, we classify all related works according to the evolution of model structure to facilitate the analysis. Finally, we discuss some challenges of RE and give out our conclusion.},
  archive      = {J_NCA},
  author       = {Wang, Hailin and Qin, Ke and Zakari, Rufai Yusuf and Lu, Guoming and Yin, Jin},
  doi          = {10.1007/s00521-021-06667-3},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4781-4801},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep neural network-based relation extraction: An overview},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leak detection and localization in water distribution
networks by combining expert knowledge and data-driven models.
<em>NCA</em>, <em>34</em>(6), 4759–4779. (<a
href="https://doi.org/10.1007/s00521-021-06666-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leaks represent one of the most relevant faults in water distribution networks (WDN), resulting in severe losses. Despite the growing research interest in critical infrastructure monitoring, most of the solutions present in the literature cannot completely address the specific challenges characterizing WDNs, such as the low spatial resolution of measurements (flow and/or pressure recordings) and the scarcity of annotated data. We present a novel integrated solution that addresses these challenges and successfully detects and localizes leaks in WDNs. In particular, we detect leaks by a sequential monitoring algorithm that analyzes the inlet flow, and then we validate each detection by an ad hoc statistical test. We address leak localization as a classification problem, which we can simplify by a customized clustering scheme that gathers locations of the WDN where, due to the low number of sensors, it is not possible to accurately locate leaks. A relevant advantage of the proposed solution is that it exposes interpretable tuning parameters and can integrate knowledge from domain experts to cope with scarcity of annotated data. Experiments, performed on a real dataset of the Barcelona WDN with both real and simulated leaks, show that the proposed solution can improve the leak detection and localization performance with respect to methods proposed in the literature.},
  archive      = {J_NCA},
  author       = {Soldevila, Adrià and Boracchi, Giacomo and Roveri, Manuel and Tornil-Sin, Sebastian and Puig, Vicenç},
  doi          = {10.1007/s00521-021-06666-4},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4759-4779},
  shortjournal = {Neural Comput. Appl.},
  title        = {Leak detection and localization in water distribution networks by combining expert knowledge and data-driven models},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DB-NMS: Improving non-maximum suppression with density-based
clustering. <em>NCA</em>, <em>34</em>(6), 4747–4757. (<a
href="https://doi.org/10.1007/s00521-021-06628-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-maximum suppression (NMS) is a post-processing step in most object detection pipelines. It is a greedy algorithm based on the Intersection over Union (IoU) of the bounding boxes to reduce false positives by removing excessive repeated bounding boxes, yet the geometric distributions of bounding boxes are not fully utilized. It is found that the distributions of bounding boxes’ center points correspond to the distributions of objects. Local areas with clustered distributions of center points exist objects. Local areas with sparse distributions of center points are considered as the false positives or noises of the detector. In this work, a density-based NMS (DB-NMS) is proposed, which is based on the density distributions of the bounding boxes’ center points to evaluate the importance of difference anchors. The proposed DB-NMS is able to obtain better results than the original NMS on the MS-COCO 2017 dataset. Because DB-NMS does not change the network structure, it can be easily integrated into the object detection pipelines to achieve better performances. Object detection pipelines such as Faster R-CNN and RetinaNet can be integrated with the proposed DB-NMS with little degradation on the computational efficiency.},
  archive      = {J_NCA},
  author       = {Rui, Li and Tang, Xue-song and Hao, Kuangrong},
  doi          = {10.1007/s00521-021-06628-w},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4747-4757},
  shortjournal = {Neural Comput. Appl.},
  title        = {DB-NMS: Improving non-maximum suppression with density-based clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attentive fine-grained recognition for cross-domain few-shot
classification. <em>NCA</em>, <em>34</em>(6), 4733–4746. (<a
href="https://doi.org/10.1007/s00521-021-06627-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain few-shot classification aims to recognize images in the new categories and domains that only contain few but unacquainted images. Considering the problems of fine-grained recognition in cross-domain few-shot classification including marginal overall-discrepancy in feature distribution and obvious fine-grained difference in dataset, this paper proposes a simple and effective attentive fine-grained recognition (AFGR) model. Specifically, the residual attention module is stacked into the feature encoder based on the residual network, which can linearly enhance different semantic feature information to help the metric function better locate the fine-grained feature information of the image. In addition, a bilinear metric function structure is proposed to learn and fuse different fine-grained image features, respectively, since the weights of bilinear measurement functions are not shared. Eventually, the final classification result is obtained by merging the recognition of bilinear metric function through posterior probability multiplication. In this paper, ablation experiments and comparative experiments are carried out with the typical few-shot dataset mini-ImageNet as the training domain and the CUB, Cars, Places and Plantae datasets as the test domain. The experimental results demonstrate that the proposed AFGR method is effective, with the highest increase in recognition accuracy 13.82\% and 7.95\% compared with the latest results under the experimental settings of 5-way1-shot and 5-way5-shot, respectively, which also proves the problems of fine-grained recognition in cross-domain small sample classification.},
  archive      = {J_NCA},
  author       = {Sa, Liangbing and Yu, Chongchong and Ma, Xianqin and Zhao, Xia and Xie, Tao},
  doi          = {10.1007/s00521-021-06627-x},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4733-4746},
  shortjournal = {Neural Comput. Appl.},
  title        = {Attentive fine-grained recognition for cross-domain few-shot classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A deep learning-assisted mathematical model for
decongestion time prediction at railroad grade crossings. <em>NCA</em>,
<em>34</em>(6), 4715–4732. (<a
href="https://doi.org/10.1007/s00521-021-06625-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a deep learning-assisted framework to estimate the decongestion time at the grade crossing, and its key novelty lies in a differential approach to address the challenge associated with data deficiency of congestion events in grade crossings. A hypothesis of the traffic behavior during the congestion event caused by passing trains is proposed. A deep neural network-based vehicle crowd counting algorithm is developed to estimate the number of vehicles at the normal traffic condition. A running average-based motion detection algorithm is designed to estimate the time of the train passing through the grade crossing. A regression model is then constructed to relate the quantitative information with the decongestion time. In the experiments, 30 congestion events are video-recorded during a period of 200 h with different camera angles at a selected grade crossing, and then studied by the proposed method to learn the congestion pattern and predict the decongestion time, which to the best of our knowledge has not been attempted before. Analysis of the experimental results shows that the vehicle number at the normal traffic flow and the train passing time have significant influences on the traffic decongestion time. The relationship is captured by a quantitative model for rapid prediction. Our study also points out the direction for further improvement of the present development to meet the need for real-world applications.},
  archive      = {J_NCA},
  author       = {Jiang, Zhuocheng and Guo, Feng and Qian, Yu and Wang, Yi and Pan, W. David},
  doi          = {10.1007/s00521-021-06625-z},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4715-4732},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning-assisted mathematical model for decongestion time prediction at railroad grade crossings},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fractional-order optimal control model for the equipment
management optimization problem with preventive maintenance.
<em>NCA</em>, <em>34</em>(6), 4693–4714. (<a
href="https://doi.org/10.1007/s00521-021-06624-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current quality status of most machinery and equipment is based on its accumulated historical status, but the influence of the past quality status on the current status of equipment is often overlooked in optimization management. This paper uses a Caputo-type fractional derivative to characterize this property. By refining the nature and characteristics of the equipment maintenance effect function and considering the memory characteristics of equipment quality, the existing model is improved, and a fractional-order optimal control model for equipment maintenance and replacement is constructed. Theoretical analyses verify the effectiveness of the fractional-order equipment maintenance management model. Furthermore, the results of numerical experiments also reflect this difference between integer-order and fractional-order equipment maintenance management models. The result shows that with an increase of the order $$\alpha$$ , the optimal target value of the equipment maintenance management problem will also increase with the weakening of the memory effect.},
  archive      = {J_NCA},
  author       = {Gong, Yanping and Zha, Mingjiang and Lv, Zhanmei},
  doi          = {10.1007/s00521-021-06624-0},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4693-4714},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fractional-order optimal control model for the equipment management optimization problem with preventive maintenance},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Population synthesis for urban resident modeling using deep
generative models. <em>NCA</em>, <em>34</em>(6), 4677–4692. (<a
href="https://doi.org/10.1007/s00521-021-06622-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The impact of new real estate developments is strongly associated with its target population distribution, that is, the characteristics that define a population such as composition of household, income, and socio-demographics, conditioned on characteristics of the development itself, such as dwelling typology, price, location, and floor level. This paper presents a machine learning-based method to model the population distribution of upcoming developments of new buildings within larger neighborhood/condo settings. We use a real data set from Ecopark Township, a real estate development project in Hanoi, Vietnam and study two machine learning algorithms from the deep generative models literature to create a population of synthetic agents: conditional variational auto-encoder (CVAE) and conditional generative adversarial networks (CGAN). A large experimental study was performed, showing that the CVAE outperforms both the empirical distribution, a non-trivial baseline model, and the CGAN in estimating the population distribution of new real estate development projects.},
  archive      = {J_NCA},
  author       = {Johnsen, Martin and Brandt, Oliver and Garrido, Sergio and Pereira, Francisco},
  doi          = {10.1007/s00521-021-06622-2},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4677-4692},
  shortjournal = {Neural Comput. Appl.},
  title        = {Population synthesis for urban resident modeling using deep generative models},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep long short-term memory based model for agricultural
price forecasting. <em>NCA</em>, <em>34</em>(6), 4661–4676. (<a
href="https://doi.org/10.1007/s00521-021-06621-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agricultural price forecasting is one of the research hotspots in time series forecasting due to its unique characteristics. In this paper, we developed a deep long short-term memory (DLSTM) based model for the accurate forecasting of a nonstationary and nonlinear agricultural prices series. DLSTM model is a type of deep neural network which is advantageous in capturing the nonlinear and volatile patterns by utilizing both the recurrent architecture and deep learning methodologies together. The study further compares the price forecasting ability of the developed DLSTM model with conventional time-delay neural network (TDNN) and ARIMA models using international monthly price series of maize and palm oil. The empirical results demonstrate the superiority of the developed DLSTM model over other models in terms of various forecasting evaluation criteria like root mean square error, mean absolute percentage error and mean absolute deviation. The DLSTM model also showed dominance over other models in predicting the directional change of those monthly price series. Moreover, the accuracy of the forecasts obtained by all the models is also evaluated using the Diebold–Mariano test and the Friedman test whose results validate that the DLSTM based model has a clear advantage over the other two models.},
  archive      = {J_NCA},
  author       = {Jaiswal, Ronit and Jha, Girish K. and Kumar, Rajeev Ranjan and Choudhary, Kapil},
  doi          = {10.1007/s00521-021-06621-3},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4661-4676},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep long short-term memory based model for agricultural price forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved extreme learning machine with AutoEncoder and
particle swarm optimization for short-term wind power prediction.
<em>NCA</em>, <em>34</em>(6), 4643–4659. (<a
href="https://doi.org/10.1007/s00521-021-06619-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind energy is a green source of electricity that is growing faster than other renewable energies. However, dependent mainly on wind speed, this source is characterized by the randomness and fluctuation that makes challenging optimal management. In order to remedy this inconvenience, it is essential to predict meteorological data or power produced by generators. In this paper, we present a wind power forecasting approach based on regularized extreme learning machine algorithm (R-ELM), particle swarm optimization method (PSO), and AutoEncoder network (AE) so-called AutoEncoder-optimal regularized extreme learning machine (AE-ORELM). Firstly, we train the AE model by the ELM algorithm. Then, the output weights resulting are used as the input weights of the R-ELM model. Furthermore, the PSO method is used to optimally select hyperparameters of the whole model, namely the regularization parameter and the number of hidden nodes in the hidden layer. The simulation results show that the proposed AE-ORELM can achieve better testing accuracy with a faster training time compared to related models.},
  archive      = {J_NCA},
  author       = {El Bourakadi, Dounia and Yahyaouy, Ali and Boumhidi, Jaouad},
  doi          = {10.1007/s00521-021-06619-x},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4643-4659},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved extreme learning machine with AutoEncoder and particle swarm optimization for short-term wind power prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation of machine learning methods for rock mass
classification. <em>NCA</em>, <em>34</em>(6), 4633–4642. (<a
href="https://doi.org/10.1007/s00521-021-06618-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solutions in geotechnics have been optimizing with the aid of machine learning methods. The aim of this paper is to apply different machine learning algorithms in order to achieve rock mass classification. It is demonstrated that RMR classification system can be obtained using only variables which are closely related to rock mass quality, instead of all RMR variables, without missing significant accuracy. The different machine learning algorithms used are the naïve Bayes, random forest, artificial neural networks and support vector machines. The variables to calculate RMR, selected by factor analysis, are: rock strength, rock weathering, spacing, persistence and aperture of discontinuities and presence of water. The machine learning models were trained and tested thirty times, with random subsampling, using two-thirds of the total database for training sample. The models presented average accuracy greater than 0.81, which was calculated from the confusion matrix, using the proportion of true positives and true negatives in the test sample. Significant values of efficiency, precision and reproducibility rates were achieved. The study shows the application of machine learning algorithms allows obtaining the RMR classes, even with a small number of variables. In addition, the results of the evaluation metrics of the developed algorithms show that the methodology can be applied to new database, working as a valuable way to achieve rock mass classification.},
  archive      = {J_NCA},
  author       = {Santos, Allan Erlikhman Medeiros and Lana, Milene Sabino and Pereira, Tiago Martins},
  doi          = {10.1007/s00521-021-06618-y},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4633-4642},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluation of machine learning methods for rock mass classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph neural network for hamiltonian-based material property
prediction. <em>NCA</em>, <em>34</em>(6), 4625–4632. (<a
href="https://doi.org/10.1007/s00521-021-06616-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Development of next-generation electronic devices calls for the discovery of quantum materials hosting novel electronic, magnetic, and topological properties. Traditional electronic structure methods require expensive computation time and memory consumption, thus a fast and accurate prediction model is desired with increasing importance. Representing the interactions among atomic orbitals in material, a Hamiltonian matrix provides all the essential elements that control the structure–property correlations in inorganic compounds. Learning of Hamiltonian by machine learning therefore offers an approach to accelerate the discovery and design of quantum materials. With this motivation, we present and compare several different graph convolution networks that are able to predict the band gap for inorganic materials. The models are developed to incorporate two different features: the information of each orbital itself and the interaction between each other. The information of each orbital includes the name, relative coordinates with respect to the center of super cell and the atom number. The interaction between orbitals is represented by the Hamiltonian matrix. The results show that our model can get a promising prediction accuracy with cross-validation.},
  archive      = {J_NCA},
  author       = {Bai, Hexin and Chu, Peng and Tsai, Jeng-Yuan and Wilson, Nathan and Qian, Xiaofeng and Yan, Qimin and Ling, Haibin},
  doi          = {10.1007/s00521-021-06616-0},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4625-4632},
  shortjournal = {Neural Comput. Appl.},
  title        = {Graph neural network for hamiltonian-based material property prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning inspired intelligent embedded system for
haptic rendering of facial emotions to the blind. <em>NCA</em>,
<em>34</em>(6), 4595–4623. (<a
href="https://doi.org/10.1007/s00521-021-06613-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our day-to-day social interactions, non-verbal cues such as facial emotions play a vital role. These cues assist people in understanding and inferring the hidden emotional state of the individuals. However, blind and visually impaired persons (VIPs) sadly lack access to such cues, which results in impaired interpersonal communication. To alleviate the issue, in this research, we present a proof-of-concept (POC) implementation of a deep learning-inspired vision-based low-cost intelligent embedded system for the haptic rendering of facial emotions to the VIPs. To this end, a novel lightweight shallow convolutional neural network (CNN) has been designed, optimized, and implemented on a resource-constrained embedded platform for the real-time analysis of facial emotions in static images. We evaluated the model on five benchmark FER datasets, namely CK+, RaFD, SFEW, FER2013, and RAF. Also, for real-time performance, the trained CNN is optimized using TensorRT SDK and deployed on the Nvidia Jetson TX2 embedded platform. Comparative analysis results with state-of-the-art FER techniques confirm the efficacy of the designed CNN that achieves competitive recognition accuracy and runs in real-time at a frame processing speed of 40 fps on the Jetson TX2 embedded device. Finally, the embedded FER platform is integrated with a low-cost and user-friendly haptic device to render emotions to the VIPs in the form of vibration cues. A working demo of the developed FER system is available at https://youtu.be/c73Ledn27dQ .},
  archive      = {J_NCA},
  author       = {Saurav, Sumeet and Saini, Anil Kumar and Saini, Ravi and Singh, Sanjay},
  doi          = {10.1007/s00521-021-06613-3},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4595-4623},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning inspired intelligent embedded system for haptic rendering of facial emotions to the blind},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive intelligent diagnostic system to predict early
stage of parkinson’s disease using two-stage dimension reduction with
genetically optimized lightgbm algorithm. <em>NCA</em>, <em>34</em>(6),
4567–4593. (<a
href="https://doi.org/10.1007/s00521-021-06612-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson&#39;s disease is one of the most prevalent neurodegenerative sicknesses distinguished by motor function impairment. Parkinson&#39;s disease (PD) diagnosis is a complicated job that demands the evaluation of numerous non-motor and motor signs. Throughout the analysis of vocal or speech abnormalities are notable indications that doctors should think. Early diagnosis of PD is essential for preliminary treatment and assisting the doctor to heal and evade the PD&#39;s spread in other brain cells and save several lives. So, this study introduces an adaptive expert diagnostic system to predict PD accurately. This suggested system proposes a hybrid methodology: two-stage mutual information and autoencoder-based dimensionality reduction approach with genetically optimized LightGBM (MI-AE-GOLGBM) algorithm, to improve the proposed system&#39;s performance and predict the best outcomes. The proposed MI-AE-GOLGBM approach comprises four methodologies: mutual information, autoencoder, genetic algorithm, and LightGBM algorithm, in which mutual information and autoencoder are implemented to form a two-stage dimensionality reduction approach for selecting the informative features from the input dataset and hence producing a reduced dataset with the most significant newly generated features, and genetic algorithm is employed to intelligently optimize the hyperparameters of LightGBM algorithm in which LightGBM algorithm utilizes such newly generated features and the best-optimized hyperparameters provided by the two-stage mutual information and autoencoder-based dimension reduction methods and the genetic algorithm, respectively, to which to classify the PD sufferers and healthy controls and enhance the precision value and reliability of the proposed system. Four different real-world publicly available Parkinson&#39;s disease datasets are employed in this proposed research to assess and verify the proposed methodology&#39;s performance. This proposed research utilizes different machine learning (ML) algorithms to compare our proposed approach&#39;s performance. The outcomes reveal that the proposed methodology can produce the best predictions based on voice data relating to the PD compared to the different ML algorithms.},
  archive      = {J_NCA},
  author       = {Dhar, Joy},
  doi          = {10.1007/s00521-021-06612-4},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4567-4593},
  shortjournal = {Neural Comput. Appl.},
  title        = {An adaptive intelligent diagnostic system to predict early stage of parkinson&#39;s disease using two-stage dimension reduction with genetically optimized lightgbm algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved fuzzy logic control-based MPPT method to enhance
the performance of PEM fuel cell system. <em>NCA</em>, <em>34</em>(6),
4555–4566. (<a
href="https://doi.org/10.1007/s00521-021-06611-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, wide installations of photovoltaic (PV) systems have been achieved in the electrical power systems. However, fluctuated output power of the PV generation and/or fluctuated load demands represent critical factors for the operation of PV systems. Thence, energy storage systems (ESSs) are highly needed for improving the supply reliability of PV generation systems. Among existing ESSs, the proton exchange membrane fuel cell (PEMFC) systems represent long-lifetime, efficient, and cost-effective solutions for PV systems. However, nonlinear behaviour exists in the output of PEMFC systems, which depends on the operating cell temperature, and the membrane water contents. The output of PEMFC has a unique operating maximum power point (MPP) for each operating combination of membrane water content and temperature, which requires MPP tracking (MPPT) control loop. Therefore, this paper presents a fuzzy logic control (FLC) MPPT method for enhancing the operation of PEMFC systems. The traditional MPPT methods in the literature employ three sensors, including voltage, water content, and temperature. The proposed controller employs only the PEMFC output current and voltage electrical signals. Compared to the classical fixed step size perturb and observe (P and O) and hill climbing MPPT methods, the proposed method represents variable step size MPPT method. In addition, compared to the widely employed incremental conductance (INC) and incremental resistance (INR) MPPT methods, the proposed method benefits the wide operating and adaptive step size MPPT operation due to using the FLC approach. The proposed method is simple and can be implemented using low cost microcontrollers. The design procedures, operating principle, and performance verification of the proposed method are presented in this paper.},
  archive      = {J_NCA},
  author       = {Aly, Mokhtar and Rezk, Hegazy},
  doi          = {10.1007/s00521-021-06611-5},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4555-4566},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved fuzzy logic control-based MPPT method to enhance the performance of PEM fuel cell system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Histogram-based fast and robust image clustering using
stochastic fractal search and morphological reconstruction.
<em>NCA</em>, <em>34</em>(6), 4531–4554. (<a
href="https://doi.org/10.1007/s00521-021-06610-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partitional clustering-based image segmentation is one of the most significant approaches. K-means is the conventional clustering techniques even though very sensitive to noise and easy convergences to local optima depending on the initial cluster centers. In addition, the computational time of K-means algorithm is also very high due to the repetitive distance calculation between pixels and cluster centers. In order to solve these problems, this paper presents a Histogram-based Fast and Robust Crisp Image Clustering (HFRCIC) technique. Local spatial information is often introduced to an objective function to improve the noise robustness of the clustering technique. At first, the local spatial information has been introduced into HFRCIC by incorporating morphological reconstruction which assures noise-immunity as well as image detail-preservation. Then clustering has been executed depending on gray levels in the place of pixels of the image. As result, the execution time is low as the number of gray levels is usually much smaller than the number of pixels in the image. Due to the random initialization of centers, HFRCIC easily stuck into local optima as HFRCIC is greedy in nature and an efficient local optimizer. Therefore, Nature-Inspired Optimization Algorithms (NIOA) are successfully employed to overcome the problem within reasonable computational time. Here, Stochastic Fractal Search (SFS) has been employed to find the optimal cluster centers. The experimental study has been performed over synthetic images, real-world images and white the gray level conversion of RGB imaged for white blood cell (WBC) segmentation. Visual and numerical results indicate the superiority of the proposed HFRCIC with SFS(HFRCIC-SFS) over state-of-the-art image segmentation algorithms and NIOA-based crisp image clustering techniques.},
  archive      = {J_NCA},
  author       = {Das, Arunita and Dhal, Krishna Gopal and Ray, Swarnajit and Gálvez, Jorge},
  doi          = {10.1007/s00521-021-06610-6},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4531-4554},
  shortjournal = {Neural Comput. Appl.},
  title        = {Histogram-based fast and robust image clustering using stochastic fractal search and morphological reconstruction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-domain learning using optimized pseudo labels: Toward
adaptive car detection in different weather conditions and urban cities.
<em>NCA</em>, <em>34</em>(6), 4519–4529. (<a
href="https://doi.org/10.1007/s00521-021-06609-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks based object detection usually assumes that training and test data have the same distribution, which, however, does not always hold in real-world applications. In autonomous vehicles, the driving scene (target domain) consists of unconstrained road environments which cannot all possibly be observed in training data (source domain) and this will lead to a sharp drop in the accuracy of the detector. In this paper, we propose a domain adaptation framework based on pseudo-labels to solve the domain shift. First, the pseudo-labels of the target domain images are generated by the baseline detector (BD) and optimized by our data optimization module to correct the errors. Then, the hard samples in a single image are labeled based on the optimization results of pseudo-labels. The adaptive sampling module is approached to sample target domain data according to the number of hard samples per image to select more effective data. Finally, a modified knowledge distillation loss is applied in the retraining module, and we investigate two ways of assigning soft-labels to the training examples from the target domain to retrain the detector. We evaluate the average precision of our approach in various source/target domain pairs and demonstrate that the framework improves over 10\% average precision of BD on multiple domain adaptation scenarios on the Cityscapes, KITTI, and Apollo datasets.},
  archive      = {J_NCA},
  author       = {Wang, Ke and Zhang, Lianhua and Xia, Qin and Pu, Liang and Chen, Junlan},
  doi          = {10.1007/s00521-021-06609-z},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4519-4529},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cross-domain learning using optimized pseudo labels: Toward adaptive car detection in different weather conditions and urban cities},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New criteria on the finite-time stability of
fractional-order BAM neural networks with time delay. <em>NCA</em>,
<em>34</em>(6), 4501–4517. (<a
href="https://doi.org/10.1007/s00521-021-06605-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the finite-time stability of a class of fractional-order bidirectional associative memory neural networks(FBAMNNs) with time delay is concerned. Based on the monotonicity of function, a new inequality is proved. For $$0&lt; \alpha &lt; 1$$ and $$1&lt; \alpha &lt; 2$$ , based on the properties of the fractional derivative, the method of step and the fractional Gronwall inequality or the generalized Gronwall inequality, some new criteria on the finite-time stability of FBAMNNs are derived. Finally, three numerical examples are provided to show the effectiveness and superiority of the criteria obtained in this paper.},
  archive      = {J_NCA},
  author       = {Li, Xuemei and Liu, Xinge and Zhang, Shuailei},
  doi          = {10.1007/s00521-021-06605-3},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4501-4517},
  shortjournal = {Neural Comput. Appl.},
  title        = {New criteria on the finite-time stability of fractional-order BAM neural networks with time delay},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stabilization of stochastic delayed networks with markovian
switching via intermittent control: An averaging technique.
<em>NCA</em>, <em>34</em>(6), 4487–4499. (<a
href="https://doi.org/10.1007/s00521-021-06603-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the stabilization of stochastic delayed networks with Markovian switching via aperiodically intermittent control (AIC). The concepts of average control ratio and average control period are proposed to characterize the distributions of control and rest intervals of AIC. It should be noted that the averaging technique used here is more general and less restrictive than the quasi-periodicity condition and minimum control ratio condition used in previous works. Then two kinds of stabilization criteria are obtained: (1) the upper bound of time delay should be less than the average control width; (2) the upper bound of time delay has no relationship with the average control width. Finally, the results are applied to studying the stabilization of coupled stochastic neural networks with Markovian switching via AIC. Numerical simulations are provided to show the effectiveness of obtained results.},
  archive      = {J_NCA},
  author       = {Guo, Ying and Feng, Jiqiang},
  doi          = {10.1007/s00521-021-06603-5},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4487-4499},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stabilization of stochastic delayed networks with markovian switching via intermittent control: An averaging technique},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A dataset and benchmark for malaria life-cycle
classification in thin blood smear images. <em>NCA</em>, <em>34</em>(6),
4473–4485. (<a
href="https://doi.org/10.1007/s00521-021-06602-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malaria microscopy, microscopic examination of stained blood slides to detect parasite Plasmodium, is considered to be a gold standard for detecting life-threatening disease malaria. Detecting the plasmodium parasite requires a skilled examiner and may take up to 10 to 15 minutes to completely go through the whole slide. Due to a lack of skilled medical professionals in the underdeveloped or resource-deficient regions, many cases go misdiagnosed, which results in unavoidable medical complications. We propose to complement the medical professionals by creating a deep learning-based method to automatically detect (localize) the plasmodium parasites in the photograph of stained film. To handle the unbalanced nature of the dataset, we adopt a two-stage approach. Where the first stage is trained to classify cells into just healthy or infected. The second stage is trained to classify each detected cell further into the malaria life-cycle stage. To facilitate the research in machine learning-based malaria microscopy, we introduce a new large-scale microscopic image malaria dataset. Thirty-eight thousand cells are tagged from the 345 microscopic images of different Giemsa-stained slides of blood samples. Extensive experimentation is performed using different Convolutional Neural Networks on this dataset. Our experiments and analysis reveal that the two-stage approach works better than the one-stage approach for malaria detection. To ensure the usability of our approach, we have also developed a mobile app that will be used by local hospitals for investigation and educational purposes. The dataset, its annotations, and implementation codes will be released upon publication of the paper.},
  archive      = {J_NCA},
  author       = {Arshad, Qazi Ammar and Ali, Mohsen and Hassan, Saeed-ul and Chen, Chen and Imran, Ayisha and Rasul, Ghulam and Sultani, Waqas},
  doi          = {10.1007/s00521-021-06602-6},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4473-4485},
  shortjournal = {Neural Comput. Appl.},
  title        = {A dataset and benchmark for malaria life-cycle classification in thin blood smear images},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust image features for classification and zero-shot tasks
by merging visual and semantic attributes. <em>NCA</em>, <em>34</em>(6),
4459–4471. (<a
href="https://doi.org/10.1007/s00521-021-06601-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate visual-semantic representations by combining visual features and semantic attributes to form a compact subspace containing the most relevant properties of each domain. This subspace can better represent image features for recognition tasks and even allow to better interpret results in the light of the nature of semantic attributes, offering a path for explainable learning. Experiments were performed in four benchmark datasets and compared against state-of-the-art algorithms. The method shows to be robust for up to 20\% degradation of semantic attributes and offering possibilities for future work on the deployment of an automatic gathering of semantic data to improve representations for image classification. Additionally, empirical evidence suggests the high-level concepts adds linearity to the feature space, allowing for example PCA and SVM to perform well in the combined visual and semantic features. Also, the representations allow for zero-shot learning which demonstrates the viability of merging semantic and visual data at both training and test time for learning aspects that transcend class boundaries that allow the classification of unseen data.},
  archive      = {J_NCA},
  author       = {de Resende, Damares Crystina Oliveira and Ponti, Moacir Antonelli},
  doi          = {10.1007/s00521-021-06601-7},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4459-4471},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust image features for classification and zero-shot tasks by merging visual and semantic attributes},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Co-embedding: A semi-supervised multi-view representation
learning approach. <em>NCA</em>, <em>34</em>(6), 4437–4457. (<a
href="https://doi.org/10.1007/s00521-021-06599-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning an expressive representation from multi-view data is a crucial step in various real-world applications. In this paper, we propose a semi-supervised multi-view representation learning approach named Co-Embedding. Unlike conventional multi-view representation learning methods use joint to concatenate different views, which ignores information exchange between views and limits the methods’ ability to utilize complementarity of multi-view data, Co-Embedding fulfills mutual help between views by coordinating and exchanging information between views. Specifically, we first build a weighted deep metric learning based multi-view representation learning framework in Co-Embedding. This framework models multi-view information through coordinate alignment, which is customized to exploit the complementary information from well-learned representations to help with modeling the under-learned representations. Then, by exploiting consensus property and neighborhood information, we design a multi-view label propagation algorithm that labels unlabeled data for Co-Embedding. Experimental results on seven benchmark multi-view datasets demonstrate the effectiveness of Co-Embedding.},
  archive      = {J_NCA},
  author       = {Jia, Xiaodong and Jing, Xiao-Yuan and Zhu, Xiaoke and Cai, Ziyun and Hu, Chang-Hui},
  doi          = {10.1007/s00521-021-06599-y},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4437-4457},
  shortjournal = {Neural Comput. Appl.},
  title        = {Co-embedding: A semi-supervised multi-view representation learning approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature learning via multi-action forms supervising force
for face recognition. <em>NCA</em>, <em>34</em>(6), 4425–4436. (<a
href="https://doi.org/10.1007/s00521-021-06598-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, face recognition (FR) has made great achievements with the development of deep convolutional neural networks (CNNs). To obtain highly discriminative features, the existing approaches train CNNs equipped with well-designed loss function to constrain their distributions in various feature spaces. (e.g., Euclidean or angular space). However, the prior methods still suffer from two issues: (1) The angular loss functions cannot produce radial binding force to push features away from the origin; (2) the Euclidean ones lack tangential restraints to separate features from different classes. To address the aforementioned issues, we design a simple and efficient loss function, named Origin loss, which integrates multi-action forms supervising forces from Euclidean and angular spaces and additionally produces a radial repulsive force to supplement it. A series of extensive experiments are conducted to demonstrate the effects on feature learning and prove the notable improvement on popular facial benchmarks, in which the proposed loss consistently outperforms than the state-of-the-art (SOTA) methods.},
  archive      = {J_NCA},
  author       = {Sun, Zhengzheng and Tian, Lianfang and Du, Qiliang and Bhutto, Jameel A. and Wang, Zhaolin},
  doi          = {10.1007/s00521-021-06598-z},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4425-4436},
  shortjournal = {Neural Comput. Appl.},
  title        = {Feature learning via multi-action forms supervising force for face recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mining periodic patterns from spatio-temporal trajectories
using FGO-based artificial neural network optimization model.
<em>NCA</em>, <em>34</em>(6), 4413–4424. (<a
href="https://doi.org/10.1007/s00521-021-06596-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Periodic patterns are occurrences that occur regularly over a long period of time at a specific location. In recent years, mining periodic patterns have become a popular area of research. There are several difficulties to map and find the periodical motion pattern of moving objects. Recently, the most challenging task is hidden periodic pattern detection from a historical object movement. To tackle these challenges, we have proposed artificial neural network (ANN) for periodic pattern mining. The proposed methodology involves three major sections namely data pre-processing, clustering, and periodic pattern mining. The two stages involved in data pre-processing are the dataset produced from the obtained matrix and the matrix form that expresses the given sub-sequence. Next, the data clustering for further process is carried out by using teaching–learning-based optimization (TLBO) algorithm. Finally, periodic pattern mining is effectively performed using artificial neural network (ANN)-based football game-based optimization (ANN-FGO) with nine constraints namely item, value, cyclic pattern, aggregate, length, sequence, similarity, duration, and gap constraints, respectively. However, the proposed model outperformed other existing methods in terms of performance.},
  archive      = {J_NCA},
  author       = {Upadhyay, Pragati and Pandey, M. K. and Kohli, Narendra},
  doi          = {10.1007/s00521-021-06596-1},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4413-4424},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mining periodic patterns from spatio-temporal trajectories using FGO-based artificial neural network optimization model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A MAS approach for vehicle routing problem. <em>NCA</em>,
<em>34</em>(6), 4387–4411. (<a
href="https://doi.org/10.1007/s00521-021-06587-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Vehicle Routing Problem (VRP) is a class of well-known combinatorial optimization problems. The great interest in the VRP is due to its practical importance, as well as the difficulty in solving it. The Capacitated Vehicle Routing Problem (CVRP) is the most common variant of the VRP. Most of the approaches that have been developed to solve this problem tend to solve the problem in a centralized way. There has been very little research done into solving this problem in a distributed manner. In this paper, we propose an innovative approach for solving CVRP in a distributed manner based on multi-agent systems and using the game theory, which consists of three types of intelligent agents: customer agent, vehicle agent, and depot agent and includes the two phases: cluster construction and clusters optimization. The cluster construction phase consists of playing a Game Theoretic Clustering Algorithm by customer agents to divide the customers into several clusters, each consisting of a cluster head and several member customers. Then, we present a Game Theoretic Clusters Optimization Algorithm for the cluster optimization phase, which is played by vehicle agents to minimize the cost of each vehicle’s route to optimize the quality of the solution. The performance of the proposed approach is evaluated on 48 instances from 10 standard benchmark sets and compared with some state-of-the-art methods in terms of execution time and quality of solutions. Our experiments illustrated that the proposed method can compete or even outperform much more complex algorithms.},
  archive      = {J_NCA},
  author       = {Alipour, Mir Mohammad and Emami, Hojjat and Abdolhosseinzadeh, Mohsen},
  doi          = {10.1007/s00521-021-06587-2},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4387-4411},
  shortjournal = {Neural Comput. Appl.},
  title        = {A MAS approach for vehicle routing problem},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved medical image synthesis approach based on marine
predators algorithm and maximum gabor energy. <em>NCA</em>,
<em>34</em>(6), 4367–4385. (<a
href="https://doi.org/10.1007/s00521-021-06577-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal medical image fusion has been attracting the attention of researchers in recent years because it supports doctors in enhancing clinical diagnosis. Improving the quality of fused images and keeping important information from the input images remain a significant challenge for the current algorithms. Therefore, an effective approach for medical image fusion is introduced in this paper to address the challenges posed above. Initially, the three-scale image decomposition method using the weighted mean curvature filter and two-scale image decomposition is introduced to decompose the input images into high- and low-frequency coefficients. Subsequently, an efficient fusion rule for high-frequency components using maximum Gabor energy is proposed. This rule allows the preservation of important information in the composite image. Ultimately, the low-frequency components are synthesized using the optimal parameters from the Marine predators algorithm. This fusion rule is designed to ensure a good quality output image. A total of 120 pairs of medical images are tested in our experiments. Five latest medical image fusion methods and six image quality metrics are used for comparing and evaluating the effectiveness of the proposed algorithm. Based on the analysis of the experimental results, the proposed algorithm has obtained better performance than the current latest algorithms.},
  archive      = {J_NCA},
  author       = {Dinh, Phu-Hung},
  doi          = {10.1007/s00521-021-06577-4},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4367-4385},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved medical image synthesis approach based on marine predators algorithm and maximum gabor energy},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sparse one-dimensional convolutional neural network-based
feature learning for fault detection and diagnosis in multivariable
manufacturing processes. <em>NCA</em>, <em>34</em>(6), 4343–4366. (<a
href="https://doi.org/10.1007/s00521-021-06575-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Those fault detection and diagnosis (FDD) models can identify various faulty signals in industrial processes by extracting features from process data with high nonlinearity and correlations. However, the diagnostic performance of those models mainly depends primarily on the validity of the features extracted from the process data. In this paper, a novel deep neural network (DNN) model, sparse one-dimensional convolutional neural network (S1-DCNN), is proposed to learn features from process signals and improve the performance of FDD in industrial processes. S1-DCNN not only extracts discriminative features from complex process signals, but selects effective features based on a sparsity regularization in the convolution layers. Thus, an S1-DCNN-based representation learning method is developed for FDD in industrial processes. Tennessee Eastman process and fed-batch fermentation penicillin process are employed to validate effectiveness of S1-DCNN for FDD. The experimental results illustrate that S1-DCNN extracted and selected effective representative features for process FDD.},
  archive      = {J_NCA},
  author       = {Yu, Jianbo and Zhang, Chengyi and Wang, Shijin},
  doi          = {10.1007/s00521-021-06575-6},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4343-4366},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sparse one-dimensional convolutional neural network-based feature learning for fault detection and diagnosis in multivariable manufacturing processes},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GOWSeqStream: An integrated sequential embedding and
graph-of-words for short text stream clustering. <em>NCA</em>,
<em>34</em>(6), 4321–4341. (<a
href="https://doi.org/10.1007/s00521-021-06563-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the proposed non-parametric Bayesian based techniques which aim to model short-length textual documents through the multinomial distribution on the bag-of-words (BOW), aka mixture model-based approach. Although existing model can effectively deal with the topic/concept drift and textual sparsity problems, they are unable to exploit the semantic sequential representation of text as well as the co-occurrence relationships between words. To meet these challenges, we propose a novel approach called as GOWSeqStream. Our proposed model is a joint integration of graph-of-words (GOW) and deep sequential encoding within the Dirichlet Process Mixture Model (DPMM) framework to improve the performance of text clustering task. Extensive experiments in benchmark real-world datasets demonstrate the effectiveness of our proposed GOWSeqStream model in comparing with recent state-of-the-art baselines. Experimental outputs in terms of NMI standard metric demonstrate the outperformances of proposed GOWSeqStream model over the recent well-known text stream clustering baselines, such as MStream, NPMM and OSDM.},
  archive      = {J_NCA},
  author       = {Vo, Tham},
  doi          = {10.1007/s00521-021-06563-w},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4321-4341},
  shortjournal = {Neural Comput. Appl.},
  title        = {GOWSeqStream: An integrated sequential embedding and graph-of-words for short text stream clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 2D fully chaotic map for image encryption constructed
through a quadruple-objective optimization via artificial bee colony
algorithm. <em>NCA</em>, <em>34</em>(6), 4295–4319. (<a
href="https://doi.org/10.1007/s00521-021-06552-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a novel 2D fully chaotic map (FULLMAP) derived through a multi-objective optimization strategy with artificial bee colony (ABC) algorithm is introduced for image encryption procedures (IMEPs). First, a model for FULLMAP with eighth decision variables was empirically constituted, and then, the variables were optimally determined using ABC for minimizing a quadruple-objective function composed of Lyapunov exponent (LE), entropy, 0–1 test and correlation coefficient. FULLMAP manifests superior performance in diverse measurements such as bifurcation, 3D phase space, LE, 0–1 test, permutation entropy (PE) and sample entropy (SE). The encryption performance of FULLMAP through an IMEP was verified with respect to various cryptanalyses compared with many reported studies, as well. The main advantage of FULLMAP rather than the optimization-based IMEP studies reported elsewhere is that it need not any optimization in the encryption procedures, and hence, it is faster than the reported procedures. On the other hand, those studies use ciphertext images through IMEPs in every cycle of the optimization. For this reason, they might have long processing time. As a result, the proposed IMEP with FULLMAP demonstrates better cryptanalyses for the most of the compared results.},
  archive      = {J_NCA},
  author       = {Toktas, Abdurrahim and Erkan, Uğur},
  doi          = {10.1007/s00521-021-06552-z},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4295-4319},
  shortjournal = {Neural Comput. Appl.},
  title        = {2D fully chaotic map for image encryption constructed through a quadruple-objective optimization via artificial bee colony algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Time-varying formation control with general linear
multi-agent systems by distributed event-triggered mechanisms under
fixed and switching topologies. <em>NCA</em>, <em>34</em>(6), 4277–4294.
(<a href="https://doi.org/10.1007/s00521-021-06539-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the time-varying formation control (TVFC) problem of multi-agent systems (MASs) with general linear dynamics under fixed topology by utilizing event-triggered mechanisms. In order to achieve the TVFC problem, two kinds of distributed event-triggered formation control schemes are proposed. Moreover, the Zeno behavior is excluded under these event-triggered mechanisms. Since these control protocols are constructed on the basis of the sampling information of the event time instants instead of the real-time information of each agent, each agent does not require to communicate continuously with its neighbors, thus effectively reducing the bandwidth requirement of communication and greatly reducing the use of energy in MASs. It deserves to be mentioned that the second control protocol introduces time-varying coupling weights, does not require to utilize any global information of the system networks, and is more suitable for systems with large-scale network. Moreover, the proposed event-triggered formation control protocols are suitable for arbitrarily switching topologies, and its related results are extended to the case of switching topologies. Finally, several examples are introduced to achieve the TVFC problem by utilizing the adaptive event-triggered control protocol, and Zeno behavior is not observed during the process of simulation.},
  archive      = {J_NCA},
  author       = {Zhang, Juan and Zhang, Huaguang and Gao, Zhiyun and Sun, Shaoxin},
  doi          = {10.1007/s00521-021-06539-w},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4277-4294},
  shortjournal = {Neural Comput. Appl.},
  title        = {Time-varying formation control with general linear multi-agent systems by distributed event-triggered mechanisms under fixed and switching topologies},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Observer-based adaptive control and faults estimation for
t-s fuzzy singular fractional order systems. <em>NCA</em>,
<em>34</em>(6), 4265–4275. (<a
href="https://doi.org/10.1007/s00521-021-06527-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper handles the issue of adaptive control and faults estimation of a class of T-S singular fractional order systems(SFOSs) with $$H_{\infty }$$ performance, where the fractional order belongs to (0, 1). Firstly, a novel observer for SFOSs is proposed, which estimate unmeasurable or partially measurable state and faults, simultaneously. Secondly, regarding to the information obtained by the above observer and the designed adaptive parameters, an adaptive controller is proposed to estimate actuator faults of the SFOSs. Further, it is indispensable to ensure the admissibility of the proposed fuzzy SFOSs with $$H_{\infty }$$ performance, novel sufficient conditions are obtained by linear matrix inequalities (LMIs), Finally, to illustrate the method proposed above is available, simulation examples are presented.},
  archive      = {J_NCA},
  author       = {Yan, Yuqing and Zhang, Huaguang and Ming, Zhongyang and Wang, Yingchun},
  doi          = {10.1007/s00521-021-06527-0},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4265-4275},
  shortjournal = {Neural Comput. Appl.},
  title        = {Observer-based adaptive control and faults estimation for T-S fuzzy singular fractional order systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An optimization model for a manufacturing-inventory system
with rework process based on failure severity under multiple
constraints. <em>NCA</em>, <em>34</em>(6), 4221–4264. (<a
href="https://doi.org/10.1007/s00521-021-06513-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work investigates a manufacturing-inventory system with a single machine and multiple products, featuring returns on sales and backorders. In the proposed model, some imperfect items, including scrapped and defective items, are produced by the manufacturer. Such items can be classified, based on the severity of the failure, into several categories; as a result, the rework process is carried out at different rates. Moreover, the implementation of the quality control policy requires monitoring and checking the items during the production and reworking processes via an inspection process. The present study is aimed to calculate and obtain the optimal values of the cycle length and backorders quantity for every product in order to achieve the minimum total cost of system considering machine capacity, service level, warehouse space, and budget constraints. To solve the presented model, given as a Nonlinear Programming (NLP) problem, the GAMS software as well as four commonly used algorithms, which are categorized among the meta-heuristic algorithms, is used. These algorithms include the GA (Genetic Algorithm), IWO (Invasive Weed Optimization), GWO (Grey Wolf Optimizer) and HHO (Harris Hawks Optimization) algorithms. Along with these algorithms, the Response Surface Methodology (RSM) is applied to calibrate the parameters of the proposed algorithms. Finally, several numeric problems are solved, the results of which are then compared with each other. Moreover, an analytical hierarchy process (AHP) technique for order performance by similarity to ideal solution (TOPSIS), which is a hybrid method of decision making with multiple attributes, is used for ranking the algorithms.},
  archive      = {J_NCA},
  author       = {Taleizadeh, Ata Allah and Askari, Reza and Konstantaras, Ioannis},
  doi          = {10.1007/s00521-021-06513-6},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4221-4264},
  shortjournal = {Neural Comput. Appl.},
  title        = {An optimization model for a manufacturing-inventory system with rework process based on failure severity under multiple constraints},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine-learning-based top-view safety monitoring of ground
workforce on complex industrial sites. <em>NCA</em>, <em>34</em>(6),
4207–4220. (<a
href="https://doi.org/10.1007/s00521-021-06489-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Telescopic cranes are powerful lifting facilities employed in construction, transportation, manufacturing and other industries. Since the ground workforce cannot be aware of their surrounding environment during the current crane operations in busy and complex sites, accidents and even fatalities are not avoidable. Hence, deploying an automatic and accurate top-view human detection solution would make significant improvements to the health and safety of the workforce on such industrial operational sites. The proposed method (CraneNet) is a new machine learning empowered solution to increase the visibility of a crane operator in complex industrial operational environments while addressing the challenges of human detection from top-view on a resource-constrained small-form PC to meet the space constraint in the operator’s cabin. CraneNet consists of 4 modified ResBlock-D modules to fulfill the real-time requirements. To increase the accuracy of small humans at high altitudes which is crucial for this use-case, a PAN (Path Aggregation Network) was designed and added to the architecture. This enhances the structure of CraneNet by adding a bottom-up path to spread the low-level information. Furthermore, three output layers were employed in CraneNet to further improve the accuracy of small objects. Spatial Pyramid Pooling (SPP) was integrated at the end of the backbone stage which increases the receptive field of the backbone, thereby increasing the accuracy. The CraneNet has achieved 92.59\% of accuracy at 19 FPS on a portable device. The proposed machine learning model has been trained with the Standford Drone Dataset and Visdrone 2019 to further show the efficacy of the smart crane approach. Consequently, the proposed system is able to detect people in complex industrial operational areas from a distance up to 50 meters between the camera and the person. This system is also applicable to the detection of any other objects from an overhead camera.},
  archive      = {J_NCA},
  author       = {Golcarenarenji, Gelayol and Martinez-Alpiste, Ignacio and Wang, Qi and Alcaraz-Calero, Jose Maria},
  doi          = {10.1007/s00521-021-06489-3},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4207-4220},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine-learning-based top-view safety monitoring of ground workforce on complex industrial sites},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FMNSICS: Fractional meyer neuro-swarm intelligent computing
solver for nonlinear fractional lane–emden systems. <em>NCA</em>,
<em>34</em>(6), 4193–4206. (<a
href="https://doi.org/10.1007/s00521-021-06452-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fractional neuro-evolution-based intelligent computing has substantial potential to solve fractional order systems represented with Lane–Emden equation arising in astrophysics including Newtonian self-gravitating, spherically symmetric and polytropic fluid. The present study aimed to present a neuro-swarm-based intelligent computing solver for the solution of nonlinear fractional Lane–Emden system (NFLES) using by exploitation of fractional Meyer wavelet artificial neural networks (FMW-ANNs) and global optimization mechanism of particle swarm optimization (PSO) combined with rapid local search of sequential quadratic programming (SQP), i.e., FMW-ANN-PSO-SQP. The motivation for the design of FMW-ANN-PSO-SQP intelligent computing comes with an objective of presenting an accurate, reliable, and viable framworks to deal with stiff nonlinear singular models represented with NFLES involving both fractional and integer derivative terms. The designed algorithm is tested for six different variants of NFLESs. The obtained numerical outcomes obtained by the proposed FMW-ANN-PSO-SQP are compared with the exact results to authenticate the correctness, efficacy, and viability, and these aspects are further endorsed statistical observations.},
  archive      = {J_NCA},
  author       = {Sabir, Zulqurnain and Raja, Muhammad Asif Zahoor and Umar, Muhammad and Shoaib, Muhammad and Baleanu, Dumitru},
  doi          = {10.1007/s00521-021-06452-2},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4193-4206},
  shortjournal = {Neural Comput. Appl.},
  title        = {FMNSICS: Fractional meyer neuro-swarm intelligent computing solver for nonlinear fractional Lane–Emden systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel hybrid approach of ABC with SCA for the parameter
optimization of SVR in blind image quality assessment. <em>NCA</em>,
<em>34</em>(6), 4165–4191. (<a
href="https://doi.org/10.1007/s00521-021-06435-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images may be distorted to different degrees in the process of acquisition, transmission, and reconstruction, which is not conducive to the perception and recognition of the human eye. Therefore, it is necessary to reasonably quantify the image quality through image quality assessment. This enables people to correctly understand the image content. In practical applications, blind image quality assessment (BIQA) has attracted widespread attention in the field of image processing because it can evaluate the image itself without any prior knowledge. Support vector regression (SVR) is widely adopted in the field of BIQA, which is one important step in many BIQA methods based on a two-step framework that contains feature extraction and SVR. However, the parameters of SVR greatly affect its predictive performance and generalization ability. Therefore, grid search (GS) is usually utilized to select the appropriate parameters of SVR in the field of BIQA. However, GS may cause the omission of potential solutions when searching the best parameters of SVR, degenerating the performance of SVR. To search the promising parameters of SVR, a novel meta-heuristic algorithm named hybrid artificial bee colony and sine cosine algorithm (ABC-SCA) is proposed. Besides, a feasible scheme for SVR parameter selection is given to further improve the prediction accuracy of the BIQA algorithm. The proposed SVR parameter selection algorithm is compared with GS and several other meta-heuristic algorithms on the three image databases (LIVE, TID2013, and CSIQ) with three BIQA schemes. The experimental results show that the proposed ABC-SCA can effectively obtain the optimal parameters of SVR in the field of BIQA.},
  archive      = {J_NCA},
  author       = {Li, Chunquan and He, Yonghua and Xiao, Dian and Luo, Zu and Fan, Jinghui and Liu, Peter X.},
  doi          = {10.1007/s00521-021-06435-3},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4165-4191},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel hybrid approach of ABC with SCA for the parameter optimization of SVR in blind image quality assessment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving stylized caption compatibility with image content
by integrating region context. <em>NCA</em>, <em>34</em>(6), 4151–4163.
(<a href="https://doi.org/10.1007/s00521-021-06422-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depicting an image in a specific style (e.g., positive, negative, humor, and romantic) is drawing emerging attention. In consideration of the inadequacy of diversity in the stylistic dataset, a larger factual corpus is typically introduced to enhance the correlation between generated caption and image content. Due to the emphasis on emotional expression, the model may neglect the semantic representation, which reduces the consistency of the stylized caption with image object and content. Therefore, based on adversarial training mechanism , we proposed an image captioning system CA-GAN to address this issue. Conditioned on image features and semantic vectors, a refining gate is implemented to obtain the most informative context from sentences. A two-separated LSTM architecture is designed to learn semantic knowledge at a comprehensive level. During adversarial training, the parameters of generator and discriminator are updated with stylistic corpus, interactively. Benefited from these components, the generated caption is capable of integrating sentiment-bearing properties with appropriate factual information, and with a strong correlation to the image. Evaluation results show the outstanding performance of our approach. The linguistic analysis demonstrates that our model improves the consistency, as well as the attractiveness, of the stylized caption with the object and content of image, respectively.},
  archive      = {J_NCA},
  author       = {Feng, Junlong and Zhao, Jianping},
  doi          = {10.1007/s00521-021-06422-8},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4151-4163},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving stylized caption compatibility with image content by integrating region context},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient multilayer RBF neural network and its
application to regression problems. <em>NCA</em>, <em>34</em>(6),
4133–4150. (<a
href="https://doi.org/10.1007/s00521-021-06373-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By combining multilayer perceptrons (MLPs) and radial basis function neural networks (RBF-NNs), an efficient multilayer RBF network is proposed in this work for regression problems. As an extension to the existing multilayer RBF network (RBF-MLP-I), the new multilayer RBF network (RBF-MLP-II) first nonlinearly transforms the multi-dimensional input data by adopting a set of multivariate basis functions. Then, linear weighted sums of these basis functions, i.e., the RBF approximations, are computed in the first hidden layer and used as the features of this layer. Subsequently, in the following hidden layers, each feature of the preceding hidden layer is fed into a univariate RBF characterized by the trainable scalar center and width, and then, RBF approximations are also applied to these basis functions. Finally, the features of the last hidden layer are linearly transformed to approximate the target output data. RBF-MLP-II reduces the number of parameters in basis functions and thus the network complexity of RBF-MLP-I. Verified by four regression problems, it is demonstrated that the proposed RBF-MLP-II exhibits the best approximation accuracy and fastest training convergence compared to conventional MLPs, RBF-NNs, and RBF-MLP-I.},
  archive      = {J_NCA},
  author       = {Jiang, Qinghua and Zhu, Lailai and Shu, Chang and Sekar, Vinothkumar},
  doi          = {10.1007/s00521-021-06373-0},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4133-4150},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient multilayer RBF neural network and its application to regression problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A differentially private indoor localization scheme with
fusion of WiFi and bluetooth fingerprints in edge computing.
<em>NCA</em>, <em>34</em>(6), 4111–4132. (<a
href="https://doi.org/10.1007/s00521-021-06815-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an enabling technology for edge computing scenarios, indoor localization has a broad prospect in a variety of location-based applications, such as tracking, navigating, and monitoring in indoor environments. In order to improve the location accuracy, numerous machine learning (ML)-based indoor localization schemes with fingerprint fusion have been proposed recently, which take advantage of the fusion of signal gathered from multiple wireless technologies (e.g., WiFi and BLE) and require a site survey to construct the fingerprint database. However, most solutions are based on cloud framework and thus pose a serious privacy leakage because users’ sensitive information (e.g., locations) is computed from the fingerprint database by the untrusted localization service provider. Furthermore, the site survey is time-consuming and labor-intensive. In this paper, we propose a differentially private fingerprint fusion semi-supervised extreme learning machine for indoor localization in the edge computing, called Adp-FSELM. The Adp-FSELM firstly employs a multi-level edge network-based privacy-preserving system framework to meet the requirements of ML-based fingerprint indoor localization for lightweight, low latency, and real-time response. Then, the Adp-FSELM extends the $$\varepsilon$$ -differential privacy to the fingerprint fusion semi-supervised extreme learning machine for indoor localization in edge computing through a three-phase private process consisting of private labeled sample obfuscation, differentially private feature fusion, and differentially private model training. Theoretical and comprehensive experimental results in real indoor environments demonstrate that the Adp-FSELM provides a high $$\varepsilon$$ -differential privacy guarantee for users’ location privacy while reducing human calibration effort and effectively resists Bayesian inference attacks. Compared with the existing semi-supervised learning-based localization methods, the mean absolute error of location accuracy of the Adp-FSELM is restricted to 2.22\% at most, and the additional time consumption can be almost ignored. Thus, our mechanism can balance the trade-off among location privacy, location accuracy, and time consumption.},
  archive      = {J_NCA},
  author       = {Zhang, Xuejun and He, Fucun and Chen, Qian and Jiang, Xinlong and Bao, Junda and Ren, Tongwei and Du, Xiaogang},
  doi          = {10.1007/s00521-021-06815-9},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4111-4132},
  shortjournal = {Neural Comput. Appl.},
  title        = {A differentially private indoor localization scheme with fusion of WiFi and bluetooth fingerprints in edge computing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Meta-heuristic optimization algorithms for solving
real-world mechanical engineering design problems: A comprehensive
survey, applications, comparative analysis, and results. <em>NCA</em>,
<em>34</em>(6), 4081–4110. (<a
href="https://doi.org/10.1007/s00521-021-06747-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world engineering design problems are widespread in various research disciplines in both industry and industry. Many optimization algorithms have been employed to address these kinds of problems. However, the algorithm’s performance substantially reduces with the increase in the scale and difficulty of problems. Various versions of the optimization methods have been proposed to address the engineering design problems in the literature efficiently. In this paper, a comprehensive review of the meta-heuristic optimization methods that have been used to solve engineering design problems is proposed. We use six main keywords in collecting the data (meta-heuristic, optimization, algorithm, engineering, design, and problems). It is worth mentioning that there is no survey or comparative analysis paper on this topic available in the literature to the best of our knowledge. The state-of-the-art methods are presented in detail over several categories, including basic, modified, and hybrid methods. Moreover, we present the results of the state-of-the-art methods in this domain to figure out which version of optimization methods performs better in solving the problems studied. Finally, we provide remarkable future research directions for the potential methods. This work covers the main important topics in the engineering and artificial intelligence domain. It presents a large number of published works in the literature related to the meta-heuristic optimization methods in solving various engineering design problems. Future researches can depend on this review to explore the literature on meta-heuristic optimization methods and engineering design problems.},
  archive      = {J_NCA},
  author       = {Abualigah, Laith and Elaziz, Mohamed Abd and Khasawneh, Ahmad M. and Alshinwan, Mohammad and Ibrahim, Rehab Ali and Al-qaness, Mohammed A. A. and Mirjalili, Seyedali and Sumari, Putra and Gandomi, Amir H.},
  doi          = {10.1007/s00521-021-06747-4},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4081-4110},
  shortjournal = {Neural Comput. Appl.},
  title        = {Meta-heuristic optimization algorithms for solving real-world mechanical engineering design problems: A comprehensive survey, applications, comparative analysis, and results},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A real-time approach to recognition of turkish sign language
by using convolutional neural networks. <em>NCA</em>, <em>34</em>(5),
4069–4079. (<a
href="https://doi.org/10.1007/s00521-021-06664-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign language is a form of visual communication used by people with hearing problems to express themselves. The main purpose of this study is to make life easier for these people. In this study, a data set was created using 3200 RGB images for 32 classes (32 static words) taken from three different people. Data augmentation methods were applied to the data sets, and the number of images increased from 3200 to 19,200, 600 per class. A 10-layer convolutional neural network model was created for the classification of the signs, and VGG166, Inception, and ResNet deep network architectures, which are deep learning methods, were applied by using the transfer learning method. Also, the signs are classified using the support vector machines and k-nearest neighbor methods, which are the traditional machine learning methods, by using features obtained from the last layer of the convolutional neural network. The most successful method was determined by comparing the obtained results according to time and performance ratios. In addition to these analyses, an interface was developed. By using the interface, the static words belonging to Turkish sign language (TSL) are translated into real-time written language. With the real-time system designed, its success in recognizing the static words of TSL signs and printing its prediction on the computer screen was evaluated.},
  archive      = {J_NCA},
  author       = {Güney, Selda and Erkuş, Mehmet},
  doi          = {10.1007/s00521-021-06664-6},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4069-4079},
  shortjournal = {Neural Comput. Appl.},
  title        = {A real-time approach to recognition of turkish sign language by using convolutional neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Global synchronization of multi-weighted complex dynamical
networks with multiple time-varying delays via PI/PD control.
<em>NCA</em>, <em>34</em>(5), 4047–4068. (<a
href="https://doi.org/10.1007/s00521-021-06663-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the multiple weighted complex dynamical networks (MWCDNs) with multiple time-varying delays (MTDs) is introduced. The main purpose of this paper is to study the global synchronization of MWCDNs with MTDs by designing novel PI/PD controllers which is related to the number of subsystems in networks. Firstly, in order to study the global synchronization problem of MWCDNs with MTDs based on the novel PI controller, a new type of Lyapunov-Krasovskii function is established in this paper which contains the integral term of PI controller. Secondly, by using Jensen’s inequality and Newton-Leibniz formulas, sufficient conditions for the global synchronization of MWCDNs with MTDs based on PI/PD controllers are obtained in the form of linear matrix inequalities. Finally, two numerical examples are used to illustrate the advantages and validity of the theoretical results we obtained.},
  archive      = {J_NCA},
  author       = {Yuan, Wenying and Shi, Shengli and Ma, Yuechao},
  doi          = {10.1007/s00521-021-06663-7},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4047-4068},
  shortjournal = {Neural Comput. Appl.},
  title        = {Global synchronization of multi-weighted complex dynamical networks with multiple time-varying delays via PI/PD control},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pattern recognition techniques for classifying aeroballistic
flying vehicle paths. <em>NCA</em>, <em>34</em>(5), 4033–4045. (<a
href="https://doi.org/10.1007/s00521-021-06662-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Here is a task of classifying aeroballistic vehicle path in atmospheric phase. It has been suggested the task to be solved by means of pattern recognition technique involving tutor-assisted training with a variety of classification samples, i.e., flying vehicle paths in atmospheric phase targeted at different ground objects. The pattern recognition technique has been developed, which involves minimum distance to a class standard and artificial neural network such as multilayer perceptron for the task solution. The novelty of the developed technique includes generation of gliding aircraft path through simulation of spline approximation of sectional polyline defined with a set of fixed points which include origin and end of the path as well as disturbing points. The path recognition system quality is to be assessed through probability measures. The path recognition quality assessment during study of various recognition techniques involved calculations of probability measures for different values of class numbers, path types (with changing number and steepness of maneuvers), and time interval assigned for decision-making. There is a set of programs involving mathematical modeling of aircraft paths in atmospheric phase, recognition procedures based on minimum distance to class standard method and artificial neural network such as multilayer perceptron as well as recognition quality check program through statistical assessment of correct recognition probabilities. The developed set of programs is a basis for study of various aircraft path recognition techniques with different initial data. There are computer modeling results and calculations of aircraft path classification error probabilities using the mentioned techniques in case of various path class number and limitations of decision-making time.},
  archive      = {J_NCA},
  author       = {Vladimir, Goncharenko and Yury, Mikhaylov and Natalya, Kartushina},
  doi          = {10.1007/s00521-021-06662-8},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4033-4045},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pattern recognition techniques for classifying aeroballistic flying vehicle paths},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A hybrid deep neural network approach to estimate reference
evapotranspiration using limited climate data. <em>NCA</em>,
<em>34</em>(5), 4013–4032. (<a
href="https://doi.org/10.1007/s00521-021-06661-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reference evapotranspiration (ET0) plays an undeniably important role in irrigation management. Thus, accurate estimation of ET0 is necessary to avoid over or under irrigation to increase agricultural productivity and manage water resources effectively. Due to the limited availability of climate datasets in developing countries, the estimation of ET0 remains the biggest challenge. This study presents two-hybrid deep neural network models for the estimation of reference evapotranspiration: Convolution—Long Short Term Memory (Conv-LSTM), which performs the convolution operation in LSTM cells and Convolution Neural Network—LSTM (CNN-LSTM) that uses the convolution layer for feature extraction of input data and then extracted features are fed to LSTM layers. The study also focuses on climate data scarcity conditions, and thus, different input combinations of climate parameters have been used to investigate the minimum required parameters to model the ET0 process. The climate dataset of two stations of India: Ludhiana and Amritsar, is adopted to develop proposed models. It includes daily maximum temperature (Tmax), minimum temperature (Tmin), wind speed measured at the height of 2 m (U2), solar radiation (Rs), relative humidity (Rh), vapor pressure (Vp), and sunshine hours (Ssh) data from the period 2003 to 2015 of Ludhiana station and 2000 to 2016 of Amritsar station. Several performance measures are used to assess the precision of the model and to perform sensitivity analysis. Temperature and radiation are observed as the prime data inputs required to estimate ET0 values. The proposed hybrid models are then compared with existing temperature and radiation-based empirical models such as Hargreaves, Makkink, and Ritchie. The comparison reveals that CNN-LSTM and Conv-LSTM outperform these existing models. Also, Conv-LSTM performs best among all for the estimation of ET0.},
  archive      = {J_NCA},
  author       = {Sharma, Gitika and Singh, Ashima and Jain, Sushma},
  doi          = {10.1007/s00521-021-06661-9},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4013-4032},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid deep neural network approach to estimate reference evapotranspiration using limited climate data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel aspect-based sentiment classifier using whale
optimized adaptive neural network. <em>NCA</em>, <em>34</em>(5),
4003–4012. (<a
href="https://doi.org/10.1007/s00521-021-06660-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of e-commerce applications, nowadays the aspect-based sentiment analysis has become vital and every consumer started focusing on various aspects of the product before making the purchase decision through online portals like Amazon, Walmart, Alibaba, Flipkart, etc. Hence, the enhancement of sentiment classification considering every aspect of product and services is in the limelight. In this proposed research, aspect-based sentiment classification model has been developed employing sentiment whale optimized adaptive neural network (SWOANN) for classifying the sentiment of key aspects of products and services. The proposed work uses the key features such as the positive opinion score, negative opinion score and the term frequency-inverse document frequency (TF-IDF) for representing each aspect of products and services, which further improves the overall effectiveness of the classifier. Moreover, the computational speed and accuracy of sentiment classification of the product and services have been improved by the optimal selection of weights of the neurons of proposed model. The promising results are obtained by analysing the mobile phone review dataset when compared with other existing sentiment classification approaches such as support vector machine (SVM) and artificial neural network (ANN). The proposed model can be compatible with any sentiment classification problem of products and services.},
  archive      = {J_NCA},
  author       = {Balaganesh, N. and Muneeswaran, K.},
  doi          = {10.1007/s00521-021-06660-w},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4003-4012},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel aspect-based sentiment classifier using whale optimized adaptive neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Just-in-time software defect prediction using deep temporal
convolutional networks. <em>NCA</em>, <em>34</em>(5), 3981–4001. (<a
href="https://doi.org/10.1007/s00521-021-06659-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software maintenance and evolution can introduce defects in software systems. For this reason, there is a great interest to identify defect prediction and estimation techniques. Recent research proposes just-in-time techniques to predict defective changes just at the commit level allowing the developers to fix the defect when it is introduced. However, the performance of existing just-in-time defect prediction models still requires to be improved. This paper proposes a new approach based on a large feature set containing product and process software metrics extracted from commits of software projects along with their evolution. The approach also introduces a deep temporal convolutional networks variant based on hierarchical attention layers to perform the fault prediction. The proposed approach is evaluated on a large dataset, composed of data gathered from six Java open-source systems. The obtained results show the effectiveness of the proposed approach in timely predicting defect proneness of code components.},
  archive      = {J_NCA},
  author       = {Ardimento, Pasquale and Aversano, Lerina and Bernardi, Mario Luca and Cimitile, Marta and Iammarino, Martina},
  doi          = {10.1007/s00521-021-06659-3},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3981-4001},
  shortjournal = {Neural Comput. Appl.},
  title        = {Just-in-time software defect prediction using deep temporal convolutional networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast reinforcement learning algorithms for joint adaptive
source coding and transmission control in IoT devices with renewable
energy storage. <em>NCA</em>, <em>34</em>(5), 3959–3979. (<a
href="https://doi.org/10.1007/s00521-021-06656-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy harvesting and source coding are two key techniques that can be exploited to mitigate the device battery limitation in Internet of things (IoT). However, these mitigating techniques come with the expense of adding to the complexity of control and optimization in the digital communication chain. In this paper, to strike a balance between the opposing goals of energy-efficient communication, high-fidelity reconstruction at the IoT gateway, low packet drop ratio, and timeliness of data, we address the delay-constrained joint lossy compression and transmission control problem for an IoT device with rechargeable energy storage. Given the stochastic dynamics emanated from the random nature of the energy harvesting process as well as the fading channel, we formulate a stochastic optimization problem using the formalism of constrained Markov decision process (CMDP) and utilize the standard Lagrangian technique to recast the problem in the unconstrained form. To compute the optimal control policy, we propose a two-timescale stochastic approximation algorithm consisting of some reinforcement learning (RL) algorithms for estimating the CMDP’s value function and stochastic gradient descent for estimating the Lagrange multiplier. Specifically, we propose three RL procedures: one based on standard Q-learning, and two accelerated learning procedures, namely post-decision state (PDS) and virtual experience (VE) learning. These algorithms exploit the known system dynamics and batch updates to overcome the slowness caused by the asynchronous updating pattern in Q-learning. Simulation results demonstrate that the proposed PDS and VE learning algorithms speed up the convergence to the optimal control policy by one and two orders of magnitude, respectively.},
  archive      = {J_NCA},
  author       = {Namjoonia, Farnoosh and Sheikhi, Marzieh and Hakami, Vesal},
  doi          = {10.1007/s00521-021-06656-6},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3959-3979},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fast reinforcement learning algorithms for joint adaptive source coding and transmission control in IoT devices with renewable energy storage},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning-based monarch butterfly optimization algorithm for
solving numerical optimization problems. <em>NCA</em>, <em>34</em>(5),
3939–3957. (<a
href="https://doi.org/10.1007/s00521-021-06654-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many optimization algorithms have been used to solve complex real-world problems, motivating many scientists to improve various optimization algorithms. The monarch butterfly optimization algorithm MBO has been proven to have good performance and is an effective tool for solving many problems. However, the migration and updating operators mainly learn from the global best and are often trapped in local optima as well as premature convergence in many optimization problems. This work introduces an adaptive learning strategy and elitism strategy namely ALMBO to enhance the exploration capacity of the algorithm and ensure that the fittest individuals are retained in the next generation. The experimental results on fourteen benchmark functions show that compared with the two representative MBO algorithm and other methods, ALMBO performs much better than the others on mean values, best values, standard deviation and convergence speed.},
  archive      = {J_NCA},
  author       = {Ghetas, Mohamed},
  doi          = {10.1007/s00521-021-06654-8},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3939-3957},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning-based monarch butterfly optimization algorithm for solving numerical optimization problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New ranking model with evidence theory under probabilistic
hesitant fuzzy context and unknown weights. <em>NCA</em>,
<em>34</em>(5), 3923–3937. (<a
href="https://doi.org/10.1007/s00521-021-06653-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel ranking model under probabilistic hesitant fuzzy set (PHFS) by extending the idea of evidence theory (ET). PHFS is a strong variant of hesitant fuzzy set that associates occurrence probabilities to multiple membership grades. This offers flexibility to experts during preference elicitation and aids proper handling of uncertainty. Evidence theory is also a powerful concept for managing uncertainty/hesitation. By integrating Bayesian approximation with ET, a flexible ranking model is developed that complements ET. Due to the partial availability of evidences for decision-making under uncertainty, an approximation strategy is combined. Previous studies on PHFS have not handled hesitation of experts better and to alleviate the issue, a new regret-rejoice approach is put forward that calculates weights of criteria by handling hesitation efficiently. Ranking values from each expert are obtained that are further fused by the Maclaurin operator to get the final ranking order. These approaches are integrated into a framework and its usefulness is exemplified using renewable energy technology selection for Tamil Nadu. Finally, comparative analysis with other approaches reveals the strengths and weaknesses of the proposed work.},
  archive      = {J_NCA},
  author       = {Krishankumaar, R. and Mishra, Arunodaya Raj and Gou, Xunjie and Ravichandran, K. S.},
  doi          = {10.1007/s00521-021-06653-9},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3923-3937},
  shortjournal = {Neural Comput. Appl.},
  title        = {New ranking model with evidence theory under probabilistic hesitant fuzzy context and unknown weights},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fast accurate fine-grain object detection model based on
YOLOv4 deep neural network. <em>NCA</em>, <em>34</em>(5), 3895–3921. (<a
href="https://doi.org/10.1007/s00521-021-06651-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early identification and prevention of various plant diseases is a key feature of precision agriculture technology. This paper presents a high-performance real-time fine-grain object detection framework that addresses several obstacles in plant disease detection that hinders the performance of traditional methods, such as dense distribution, irregular morphology, multi-scale object classes, textural similarity. The proposed model is built on an improved version of the You Only Look Once (YOLOv4) algorithm. The modified network architecture maximizes both detection accuracy and speed by including the DenseNet in the backbone to optimize feature transfer and reuse; two new residual blocks in backbone and neck enhance feature extraction and reduce computing cost; the Spatial Pyramid Pooling (SPP) enhances receptive field, and a modified Path Aggregation Network (PANet) preserves fine-grain localized information and improves feature fusion. Additionally, use of the Hard-Swish function as the primary activation improved the model’s accuracy due to better nonlinear feature extraction. The proposed model is tested in detecting four different diseases in tomato plants under various challenging environments. The model outperforms the existing state-of-the-art detection models in detection accuracy and speed. At a detection rate of 70.19 FPS, the proposed model obtained a precision value of 90.33\%, F1-score of 93.64\%, and a mean average precision (mAP) value of 96.29\%. Current work provides an effective and efficient method for detecting different plant diseases in complex scenarios that can be extended to different fruit and crop detection, generic disease detection, and various automated agricultural detection processes.},
  archive      = {J_NCA},
  author       = {Roy, Arunabha M. and Bose, Rikhi and Bhaduri, Jayabrata},
  doi          = {10.1007/s00521-021-06651-x},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3895-3921},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fast accurate fine-grain object detection model based on YOLOv4 deep neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification and prediction of phubbing behavior: A
data-driven approach. <em>NCA</em>, <em>34</em>(5), 3885–3894. (<a
href="https://doi.org/10.1007/s00521-021-06649-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on Phubbing has received a lot of attention in recent years from the research community. However, the studies conducted are mainly based on linear statistics, which is a very conservative method for data analysis. To overcome this limitation, we adopted a data mining and machine learning-based approach to identify the patterns related to Phubbing behavior. We developed several models on online survey data that we collected for our analysis purposes. The results highlighted that addiction measures fail to predict Phubbing fully. Indeed, Phubbing appeared to be linked in a nonlinear way to both Information and Communication Technology (ICT) measures that do not imply a dysfunctional use of technology and social anxiety. Moreover, the machine learning approach appeared more suitable than traditional linear statistics methods to predict Phubbing, as highlighted by a much higher explained variance. Phubbing is not solely attributable to addiction dynamics. Phubbing is indicated by a series of predictors that cannot be reduced to addiction (e.g., age, social anxiety, ICT services owned). Modeling procedures able to account for nonlinearity are also required to accurately assessing users’ Phubbing levels. The patterns produced by our modeling procedure may help scholars in accounting for phubbing definition, detection, and prediction more accurately.},
  archive      = {J_NCA},
  author       = {Rahman, Md Anisur and Duradoni, Mirko and Guazzini, Andrea},
  doi          = {10.1007/s00521-021-06649-5},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3885-3894},
  shortjournal = {Neural Comput. Appl.},
  title        = {Identification and prediction of phubbing behavior: A data-driven approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using combined clustering algorithms and association rules
for better management of the amount of water delivered to the irrigation
network of abyek plain, iran. <em>NCA</em>, <em>34</em>(5), 3875–3883.
(<a href="https://doi.org/10.1007/s00521-021-06648-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aimed to perform more appropriate management of the water delivered to the irrigation network. For this purpose, a combination of K-Means and Apriori algorithms was conducted to evaluate the impact of various factors on the management of water delivered to the irrigation network. Initially, the amount of water entering the irrigation network and its various influential factors were clustered by the K-Means algorithm. Then, the output information of the K-Means algorithm was selected as the input information of the Apriori algorithm. Accordingly, six optimal clusters were formed by the K-Means algorithm whereby 18 association rules related to six clusters were extracted by the Apriori algorithm. In addition, the amount of water requirements of crops played the greatest impact on the decision of managers for the amount of water delivered to the irrigation network. In some cases, although the amount of precipitation satisfies the water requirements of crops, it does not affect reduction of the amount of water delivered to the irrigation network. Further, air temperature and air humidity percentage had not been considered in the managers’ decision related to the amount of water delivered to this network. Since the problem of water deficit and lack of precipitation existed in the Abyek plain, it is suggested that the positive effects of environmental factors on the amount of water delivered to the irrigation network be considered to prevent water wastage.},
  archive      = {J_NCA},
  author       = {Mirhashemi, Seyed Hassan and Mirzaei, Farhad},
  doi          = {10.1007/s00521-021-06648-6},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3875-3883},
  shortjournal = {Neural Comput. Appl.},
  title        = {Using combined clustering algorithms and association rules for better management of the amount of water delivered to the irrigation network of abyek plain, iran},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LMSVCR: Novel effective method of semi-supervised
multi-classification. <em>NCA</em>, <em>34</em>(5), 3857–3873. (<a
href="https://doi.org/10.1007/s00521-021-06647-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The previously known works studying the learning performance of multi-classification algorithm are usually based on supervised samples, but large amount of data generated in real-life is usually unlabeled. This paper introduces a novel Laplacian multi-classification support vector classification and regression (LMSVCR) algorithm for the case of semi-supervised learning. We first establish the fast learning rate of LMSVCR algorithm with semi-supervised multi-classification samples, and prove that LMSVCR algorithm with semi-supervised multi-classification samples is consistent. We show the numerical investigation on the learning performance of LMSVCR algorithm. The experimental studies indicate that the proposed LMSVCR algorithm has better learning performance in terms of prediction accuracy, sampling and training total time than other semi-supervised multi-classification algorithms.},
  archive      = {J_NCA},
  author       = {Dong, Zijie and Qin, Yimo and Zou, Bin and Xu, Jie and Tang, Yuan Yan},
  doi          = {10.1007/s00521-021-06647-7},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3857-3873},
  shortjournal = {Neural Comput. Appl.},
  title        = {LMSVCR: Novel effective method of semi-supervised multi-classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic network embedding via multiple sequence learning.
<em>NCA</em>, <em>34</em>(5), 3843–3855. (<a
href="https://doi.org/10.1007/s00521-021-06646-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capturing dynamic changes of networks can greatly improve the representation ability of nodes, which leads to dynamic network embedding becoming a hot research topic nowadays. However, current work focus on the correlation information and the position information of nodes, while the valuable timestamp information of edges is ignored. The timestamp information of edges presents the revolution of dynamic networks, which is extremely important for the dynamic node influence evaluation. To solve the problems of the existing works, we propose a novel dynamic network embedding method with multiple sequences learnings (DEMS). DEMS uses node sequence learning and edge sequence learning simultaneously to preserve more information of node dynamics in the network embedding. Specifically, node sequence learning preserves the node position information, and edge sequence learning preserves the edge timestamp information. Self-Attention mechanism is used in both sequence learnings to preserve the correlation information. Experiments on seven real-world dynamic networks verify the superiority of DEMS to the state-of-the-art methods in temporal link prediction tasks.},
  archive      = {J_NCA},
  author       = {Yuan, Weiwei and Shi, Chenyang and Guan, Donghai},
  doi          = {10.1007/s00521-021-06646-8},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3843-3855},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic network embedding via multiple sequence learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial neural network models to predict the response of
55NiTi shape memory alloy under stress and thermal cycles. <em>NCA</em>,
<em>34</em>(5), 3829–3842. (<a
href="https://doi.org/10.1007/s00521-021-06643-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work focused on the development and application of artificial neural network (ANN) models to predict the cyclic behavior of a commercially available, binary Ni49.9 Ti50.1 (at.\%) shape memory alloy, also known as 55NiTi (55 wt\% Ni). This 55NiTi material is well known in the aerospace industry for design of actuators (which operate under several thermomechanical cycles). Using only the predominant factors that influence the cyclic behavior of the alloy as input variables, simple yet practical models are generated that are able to predict the material responses under several stress magnitudes and hundreds of cycles. A comparison between the predicted temperature–strain responses and available experimental data demonstrated a high level of accuracy of the developed ANN models. It was found that the cyclic response of the 55NiTi alloy was more sensitive to the stress magnitude (in comparison with the effect of the other input parameters considered in the study).},
  archive      = {J_NCA},
  author       = {Owusu-Danquah, J. S. and Bseiso, Abdallah and Allena, Srinivas},
  doi          = {10.1007/s00521-021-06643-x},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3829-3842},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial neural network models to predict the response of 55NiTi shape memory alloy under stress and thermal cycles},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hachimoji DNA-based reversible blind color images hiding
using julia set and SVD. <em>NCA</em>, <em>34</em>(5), 3811–3827. (<a
href="https://doi.org/10.1007/s00521-021-06642-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel reversible blind dual-color image watermarking algorithm is proposed by using singular value decomposition (SVD), Hachimoji Deoxyribonucleic Acid (HDNA) biogenetic encryption, coupled map lattice-based Tent–Sine system (TSS-CML) and mathematical Julia set. For watermark embedding, the watermark image is firstly encrypted using 8-bases HDNA sequences, TSS-CML and Julia set image. Then the encrypted HDNA watermark is obtained. Next, decompose the host image into equal non-overlapping blocks and utilize SVD on the randomly selected blocks. Further, embed the HDNA watermark through modifying the relation between the elements in the first column of the matrix U or V. The watermarked image can be eventually attained by carrying out the inverse SVD on all selected blocks. Also a reliable extraction algorithm is designed to recover the watermark from the possibly attacked watermarked images without resorting to the original image. Experimental and analysis results demonstrate that the proposed watermarking scheme has not only an excellent imperceptibility but a strong robustness against the common image processing attacks, geometric attacks and some composite attacks. In addition, the running time taken for hiding and exacting is about 1 s, which is suitable for real-time network transmission and application. In conclusion, the proposed method outperforms the related dual images watermarking algorithms in terms of time performance, extraction effect and robustness.},
  archive      = {J_NCA},
  author       = {Wang, Kunshu and Wu, Xiangjun and Liu, Mengqi and Gao, Hang and Gao, Tiegang},
  doi          = {10.1007/s00521-021-06642-y},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3811-3827},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hachimoji DNA-based reversible blind color images hiding using julia set and SVD},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Temporal attention augmented transformer hawkes process.
<em>NCA</em>, <em>34</em>(5), 3795–3809. (<a
href="https://doi.org/10.1007/s00521-021-06641-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, mining the knowledge from asynchronous sequences by Hawkes process is a subject worthy of continued attention, and Hawkes processes based on the neural network have gradually become the most hotly researched fields, especially based on the recurrence neural network (RNN). However, these models still contain some inherent shortcomings of RNN, such as vanishing and exploding gradient and long-term dependency problems. Meanwhile, transformer-based on self-attention has achieved great success in sequential modeling like text processing and speech recognition. Although the Transformer Hawkes process (THP) has gained huge performance improvement, THPs do not effectively utilize the temporal information in the asynchronous events, for these asynchronous sequences, the event occurrence instants are as important as the types of events, while conventional THPs simply convert temporal information into position encoding and add them as the input of transformer. With this in mind, we come up with a new kind of Transformer-based Hawkes process model, temporal attention augmented transformer Hawkes Process (TAA-THP), we modify the traditional dot-product attention structure and introduce the temporal encoding into attention structure. We conduct numerous experiments on a wide range of synthetic and real-life datasets to validate the performance of our proposed TAA-THP model, a significant improvement compared with existing baseline models on the different measurements is achieved, including log-likelihood on the test dataset, and prediction accuracies of event types and occurrence times. In addition, through the ablation studies, we vividly demonstrate the merit of introducing additional temporal attention by comparing the performance of the model with and without temporal attention.},
  archive      = {J_NCA},
  author       = {Zhang, Lu-ning and Liu, Jian-wei and Song, Zhi-yan and Zuo, Xin},
  doi          = {10.1007/s00521-021-06641-z},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3795-3809},
  shortjournal = {Neural Comput. Appl.},
  title        = {Temporal attention augmented transformer hawkes process},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Radiative and magnetohydrodynamic micropolar hybrid
nanofluid flow over a shrinking sheet with joule heating and viscous
dissipation effects. <em>NCA</em>, <em>34</em>(5), 3783–3794. (<a
href="https://doi.org/10.1007/s00521-021-06640-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines the radiative and magnetohydrodynamic micropolar fluid flow over a stretching/shrinking sheet consisting of Al2O3 and Cu nanoparticles. Besides, the effects of the Joule heating and viscous dissipation are taken into consideration. The similarity variables are employed to convert the governing equations into similarity equations. Then, the bvp4c in MATLAB is utilized to obtain the numerical results. The accuracy of the current formulation and method has been done by comparing the present results with those previously published data. Findings discovered that two solutions are obtained for the limited range of $$S$$ and $$K$$ , and these solutions are terminated at $$S = S_{c}$$ and $$K = K_{c}$$ . The influence of $${\text{Ec}}$$ and $$R$$ is to reduce the local Nusselt number of $${\text{Re}}_{x}^{ - 1/2} {\text{Nu}}_{x}$$ . Meanwhile, the values of $${\text{Re}}_{x}^{ - 1/2} {\text{Nu}}_{x}$$ increase with the increase in $$\varphi_{{{\text{hnf}}}}$$ when larger values of $$R$$ are considered. The rise of $$M$$ contributes to the increment in the values of $${\text{Re}}_{x}^{1/2} C_{f}$$ , $${\text{Re}}_{x} M_{w}$$ , and $${\text{Re}}_{x}^{ - 1/2} {\text{Nu}}_{x}$$ , but the effect of $$K$$ lowers the values of these physical quantities. Lastly, it was discovered that the first solution is physically reliable and in a stable mode.},
  archive      = {J_NCA},
  author       = {Waini, Iskandar and Ishak, Anuar and Pop, Ioan},
  doi          = {10.1007/s00521-021-06640-0},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3783-3794},
  shortjournal = {Neural Comput. Appl.},
  title        = {Radiative and magnetohydrodynamic micropolar hybrid nanofluid flow over a shrinking sheet with joule heating and viscous dissipation effects},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). End-to-end variational graph clustering with local
structural preservation. <em>NCA</em>, <em>34</em>(5), 3767–3782. (<a
href="https://doi.org/10.1007/s00521-021-06639-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph clustering, a basic problem in machine learning and artificial intelligence, facilitates a variety of real-world applications. How to perform a task of graph clustering, with a relatively high-quality optimization decision and an effective yet efficient way to use graph information, to obtain a more excellent assignment for discrete points is not an ordinary challenge that troubles scholars. Often, many preeminent works on graph clustering neglect an essential element that the defined clustering loss may destroy the feature space. This is also a vital factor that leads to unrepresentative nonsense features that generate poor partitioning decisions. Here, we propose an end-to-end variational graph clustering (EVGC) algorithm focusing on preserving the original information of the graph. Specifically, the KL loss with an auxiliary distribution serves as a specific guide to manipulate the embedding space, and consequently disperse data points. A graph auto-encoder plays a propulsive role in maximumly retaining the local structure of the generative distribution of the graph. And each node is represented as a Gaussian distribution in dealing with separating the true embedding position and uncertainty from the graph. Experimental results reveal the importance of preserving local structure, and our EVGC system outperforms state-of-the-art approaches.},
  archive      = {J_NCA},
  author       = {Guo, Lin and Dai, Qun},
  doi          = {10.1007/s00521-021-06639-7},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3767-3782},
  shortjournal = {Neural Comput. Appl.},
  title        = {End-to-end variational graph clustering with local structural preservation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning deep convolutional descriptor aggregation for
efficient visual tracking. <em>NCA</em>, <em>34</em>(5), 3745–3765. (<a
href="https://doi.org/10.1007/s00521-021-06638-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual trackers have achieved a high-level performance from deep features, but many limitations remain. Online trackers suffer from low speed while using deep features for parameter updating, and deep trackers trained offline demonstrate data hunger. To meet these challenges, our work aims to mine the target representation capability of a pre-trained model and presents deep convolutional descriptor aggregation (DCDA) for visual tracking. Based on spatial and semantic priors, we propose an edge-aware selection (EAS) and a central-aware selection (CAS) method to aggregate the accuracy-aware and robustness-aware features. To make full use of the scene context, our method is derived from one-shot learning by designing a dedicated regression process that is capable of predicting discriminative model in a few iterations. By exploiting robustness feature aggregation, the accuracy feature aggregation, and the discriminative regression, our DCDA with Siamese tracking architecture not only enhances the target prediction capacity, but also achieves a low-cost reuse of the pre-trained model. Comprehensive experiments on OTB-100, VOT2016, VOT2017, VOT2020, NFS30, and NFS240 show that our DCDA tracker achieves state-of-the-art performance with a high running speed of 65 FPS. The source code and all the experimental results of this work will be made public at https://github.com/Gitlyz007/DCDA_Tracker .},
  archive      = {J_NCA},
  author       = {Ke, Xiao and Li, Yuezhou and Guo, Wenzhong and Huang, Yanyan},
  doi          = {10.1007/s00521-021-06638-8},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3745-3765},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning deep convolutional descriptor aggregation for efficient visual tracking},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance assessment of the two metaheuristic techniques
and their hybrid for power system stability enhancement with PV-STATCOM.
<em>NCA</em>, <em>34</em>(5), 3723–3744. (<a
href="https://doi.org/10.1007/s00521-021-06637-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper demonstrates a comprehensive performance assessment of the two metaheuristic swarm-based optimization algorithms namely PSO (Particle swarm optimization), BFOA (Bacterial foraging optimization algorithm), and the hybrid PSO-BFOA optimizer for the alleviation and control of the power oscillations in a two-area four generator system integrated with a large-scale PV-farm. After sunset, the PV-plant operates as VSC (Voltage Source Converter)-STATCOM (Static synchronous compensator) using its overall inverting capabilities for the power system stability improvement. While in the daytime during the faults, the PV-farm immediately stops the active power production and behaves as PV-STATCOM until the normal operating conditions are resumed. The modified version of Kundur’s two-area system comprising of a large-scale PV-farm is simulated with MATLAB software. An innovative control strategy employing the two PI controllers distinctly controls the DC-AC currents of the PV-STATCOM. The series compensation is set to an optimal value of 85\% and subjected to a 3-φ fault. Zero mechanical dampings, along with extra disturbances of 20\% variation in reference voltage and electromagnetic torque are introduced to flaunt the worst damping scenarios. The simulation outcomes and time-domain analysis for various test conditions: without a controller, with PSO-based PV-STATCOM, with BFOA-based PV-STATCOM, and with the Hybrid PSO-BFOA-based PV-STATCOM, reveal that all the system modes are stabilized with PSO application. The stability of modes is progressively improved with BFO control, eventually, the modes are optimally stabilized by deploying the hybrid PSO-BFO algorithm.},
  archive      = {J_NCA},
  author       = {Kumar, Rajeev and Diwania, Sourav and Khetrapal, Pavan and Singh, Sheetal},
  doi          = {10.1007/s00521-021-06637-9},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3723-3744},
  shortjournal = {Neural Comput. Appl.},
  title        = {Performance assessment of the two metaheuristic techniques and their hybrid for power system stability enhancement with PV-STATCOM},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modified monarch butterfly optimization with distribution
functions and its application for 3 DOF hover flight system.
<em>NCA</em>, <em>34</em>(5), 3697–3722. (<a
href="https://doi.org/10.1007/s00521-021-06635-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, Modified Monarch Butterfly Optimization Algorithm (M2BO) is proposed by modeling stochastic processes in Monarch Butterfly Optimization (MBO) algorithm with different random distribution functions. The proposed M2BO algorithm has been firstly tested with benchmark functions and the results have been compared with the literature and classical MBO algorithm. In order to analyze the performance of the proposed M2BO algorithm for the real engineering problem, the feedback gain matrix (K matrix) for the control of the 3 Degree of Freedom (3 DOF) Hover system has been optimized. The results have been compared with classical MBO, DSO (Discrete Stochastic Optimization), and SMDO (Stochastic Multi-parameter Divergence Optimization) optimization algorithms. The obtained results have been compared on 3 DOF Hover simulation models and real-time 3 DOF Hover experimental sets. The performance of the proposed M2BO algorithm in benchmark and real engineering problem tests has been shown theoretically and experimentally. Thus, it has been shown that the performance of algorithms can be increased without changing the basic philosophy of algorithms by modeling stochastic processes in algorithms with random distributions other than a uniform distribution. In addition to these, it has been determined that distribution function-based contributions can be applied to many of these algorithms.},
  archive      = {J_NCA},
  author       = {Ates, Abdullah and Akpamukcu, Mehmet},
  doi          = {10.1007/s00521-021-06635-x},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3697-3722},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modified monarch butterfly optimization with distribution functions and its application for 3 DOF hover flight system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient orthogonal opposition-based learning slime
mould algorithm for maximum power point tracking. <em>NCA</em>,
<em>34</em>(5), 3671–3695. (<a
href="https://doi.org/10.1007/s00521-021-06634-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The slime mould algorithm (SMA) is a recent physics-based optimization approach. The main inspiration of the SMA is motivated by the natural oscillating state of the slime mould organisms. In order to boost the performance, several problems must be resolved properly on the original SMA itself. One of these problems is the dilemma of the improper balancing between the exploration and exploitation phases which might deviate the algorithm to be trapped in the local optima. This work introduces a new version of the SMA called mSMA-based on the hybridization of the original SMA with a modified version of the opposition-based learning (mOBL) and the Orthogonal learning (OL) strategies. To assess the performance of the proposed mSMA, it has been evaluated over ten CEC’2020 test suites and three engineering design problems. As the output performance of the thermoelectric generator (TEG) is mainly based on the applied temperatures on the hot and cold sides of the TEG together with the load value. Consequently, in case of either varying the applied temperature or the load, to force the TEG to operate as close as possible to the maximum power point (MPP), a robust maximum power point tracking (MPPT) strategy is highly required. Therefore, an optimized fractional-order (FO) MPPTS is proposed to increase the delivered energy from the TEG. The suggested strategy is based on the FO control approach. The optimal parameters of the optimized fractional MPPTS were identified by the new mSMA. To demonstrate the superiority of mSMA, the results are compared to other well-known algorithms such as the ABC, GSA, PSO, HHO, TSA, GBO, HBO, and the original SMA. The main purpose of the proposed optimal fractional MPPTS is to increase the dynamic response and to remove the oscillations that occurred at the steady-state response. Therefore, the performance of the proposed strategy is compared to two common methods; the incremental resistance and the perturb &amp; observe. The obtained results proved the superiority of the optimized fractional MPPTS in comparison to the other traditional MPPT methods in both the dynamic and steady-state responses.},
  archive      = {J_NCA},
  author       = {Houssein, Essam H. and Helmy, Bahaa El-din and Rezk, Hegazy and Nassef, Ahmed M.},
  doi          = {10.1007/s00521-021-06634-y},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3671-3695},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient orthogonal opposition-based learning slime mould algorithm for maximum power point tracking},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalization techniques of neural networks for fluid flow
estimation. <em>NCA</em>, <em>34</em>(5), 3647–3669. (<a
href="https://doi.org/10.1007/s00521-021-06633-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We demonstrate several techniques to encourage practical uses of neural networks for fluid flow estimation. In the present paper, three perspectives which are remaining challenges for applications of machine learning to fluid dynamics are considered: 1. interpretability of machine-learned results, 2. bulking out of training data, and 3. generalizability of neural networks. For the interpretability, we first demonstrate two methods to observe the internal procedure of neural networks, i.e., visualization of hidden layers and application of gradient-weighted class activation mapping (Grad-CAM), applied to canonical fluid flow estimation problems—(1) drag coefficient estimation of a cylinder wake and (2) velocity estimation from particle images. It is exemplified that both approaches can successfully tell us evidences of the great capability of machine learning-based estimations. We then utilize some techniques to bulk out training data for super-resolution analysis and temporal prediction for cylinder wake and NOAA sea surface temperature data to demonstrate that sufficient training of neural networks with limited amount of training data can be achieved for fluid flow problems. The generalizability of machine learning model is also discussed by accounting for the perspectives of inter/extrapolation of training data, considering super-resolution of wakes behind two parallel cylinders. We find that various flow patterns generated by complex interaction between two cylinders can be reconstructed well, even for the test configurations regarding the distance factor. The present paper can be a significant step toward practical uses of neural networks for both laminar and turbulent flow problems.},
  archive      = {J_NCA},
  author       = {Morimoto, Masaki and Fukami, Kai and Zhang, Kai and Fukagata, Koji},
  doi          = {10.1007/s00521-021-06633-z},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3647-3669},
  shortjournal = {Neural Comput. Appl.},
  title        = {Generalization techniques of neural networks for fluid flow estimation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust affect analysis using committee of deep convolutional
neural networks. <em>NCA</em>, <em>34</em>(5), 3633–3645. (<a
href="https://doi.org/10.1007/s00521-021-06632-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human emotion has attracted researcher’s attention as it finds potential applications in identifying consumer’s mood and interest towards their product, assessments of learner emotional states, manufacturing smart cars, automotive industry and detecting mental states of the person in health care applications. In this paper, a well-designed committee network that focuses on the applicability of deep features for human emotion recognition from facial expressions is proposed. This architecture has the advantage of multi-level feature extraction using multiple filters that improve the performance of the network. The designed variant of inception–residual structure helps in the flow of input data through multiple paths, thus explicitly captures emotion variation from multi-path sibling layers and concatenated for recognition. The proposed algorithm is experimented with eNTERFACE, SAVEE and AFEW databases and the accuracy of 94.76\%, 98.67\% and 66.84\%, respectively, is obtained.},
  archive      = {J_NCA},
  author       = {Russel, Newlin Shebiah and Selvaraj, Arivazhagan},
  doi          = {10.1007/s00521-021-06632-0},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3633-3645},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust affect analysis using committee of deep convolutional neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sepsis prediction in intensive care unit based on genetic
feature optimization and stacked deep ensemble learning. <em>NCA</em>,
<em>34</em>(5), 3603–3632. (<a
href="https://doi.org/10.1007/s00521-021-06631-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sepsis is a life-threatening disease that is associated with organ dysfunction. It occurs due to the body’s dysregulated response to infection. It is difficult to identify sepsis in its early stages, this delay in identification has a dramatic effect on mortality rate. Developing prognostic tools for sepsis prediction has been the focus of various studies over previous decades. However, most of these studies relied on tracking a limited number of features, as such, these approaches may not predict sepsis sufficiently accurately in many cases. Therefore, in this study, we concentrate on building a more accurate and medically relevant predictive model for identifying sepsis. First, both NSGA-II (a multi-objective genetic algorithm optimization approach) and artificial neural networks are used concurrently to extract the optimal feature subset from patient data. In the next stage, a deep learning model is built based on the selected optimal feature set. The proposed model has two layers. The first is a deep learning classification model used to predict sepsis. This is a stacking ensemble of neural network models that predicts which patients will develop sepsis. For patients who were predicted to have sepsis, data from their first six hours after admission to the ICU are retrieved, this data is then used for further model optimization. Optimization based on this small, recent timeframe leads to an increase in the effectiveness of our classification model compared to other models from previous works. In the second layer of our model, a multitask regression deep learning model is used to identify the onset time of sepsis and the blood pressure at that time in patients that were predicted to have sepsis by the first layer. Our study was performed using the medical information from the intensive care MIMIC III real-world dataset. The proposed classification model achieved 0.913, 0.921, 0.832, 0.906 for accuracy, specificity, sensitivity, and AUC, respectively. In addition, the multitask regression model obtained an RMSE of 10.26 and 9.22 for predicting the onset time of sepsis and the blood pressure at that time, respectively. There are no other studies in the literature that can accurately predict the status of sepsis in terms of its onset time and predict medically verifiable quantities like blood pressure to build confidence in the onset time prediction. The proposed model is medically intuitive and achieves superior performance when compared to all other current state-of-the-art approaches.},
  archive      = {J_NCA},
  author       = {El-Rashidy, Nora and Abuhmed, Tamer and Alarabi, Louai and El-Bakry, Hazem M. and Abdelrazek, Samir and Ali, Farman and El-Sappagh, Shaker},
  doi          = {10.1007/s00521-021-06631-1},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3603-3632},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sepsis prediction in intensive care unit based on genetic feature optimization and stacked deep ensemble learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving finger vein discriminant representation using
dynamic margin softmax loss. <em>NCA</em>, <em>34</em>(5), 3589–3601.
(<a href="https://doi.org/10.1007/s00521-021-06630-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing demand for secure biometric identification systems, finger vein recognition has received widespread attention. Recent studies have made progress in the verification of finger veins, but the extraction of the discriminative features of finger veins from images remains challenging. Although the traditional method of extracting features by combining softmax function and cross-entropy loss function can achieve separation between classes, it lacks discriminability. In addition, the method of setting a fixed margin yields good results, but it may cause some features to overlap. We argue that when some features are separated well from other features, the margin set needs to be reduced. Therefore, a dynamic margin softmax loss (dynamic softmax) is proposed in this study to obtain discriminative image features. Features and weight vectors are normalized, and the loss function dynamics are subsequently adjusted to achieve different cosine intervals for different classes. The main idea of this method is to maximize the distance between inter-class and minimize the distance between intra-class. This method can keep features separated without increasing the complexity of optimizing the neural network model. It is simpler and more effective than other loss functions. Experiments prove the effectiveness of the proposed method for finger vein recognition.},
  archive      = {J_NCA},
  author       = {Li, Huachuan and Lyu, Yi and Duan, Guiduo and Chen, Ci},
  doi          = {10.1007/s00521-021-06630-2},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3589-3601},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving finger vein discriminant representation using dynamic margin softmax loss},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LAANet: Lightweight attention-guided asymmetric network for
real-time semantic segmentation. <em>NCA</em>, <em>34</em>(5),
3573–3587. (<a
href="https://doi.org/10.1007/s00521-022-06932-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing demand for real-world scenarios such as robot navigation and autonomous driving, how to achieve a good trade-off between segmentation accuracy, inference speed and model size has become a core issue for real-time semantic segmentation applications. In this paper, we propose a lightweight attention-guided asymmetric network (LAANet), which adopts an asymmetric encoder–decoder architecture. In the encoder, we propose an efficient asymmetric bottleneck (EAB) module to jointly extract local and context information. In the decoder, we propose an attention-guided dilated pyramid pooling (ADPP) module and an attention-guided feature fusion upsampling (AFFU) module, which are used to aggregate multi-scale context information and fuse features from different layers, respectively. LAANet has only 0.67M parameters, while achieving the accuracy of 73.6\% and 67.9 $$\%$$ mean Intersection over Union (mIoU) at 95.8 and 112.5 Frames Per Second (FPS) on the Cityscapes and CamVid datasets, respectively. The experimental results show that LAANet achieves an optimal trade-off between segmentation accuracy, inference speed, and model size.},
  archive      = {J_NCA},
  author       = {Zhang, Xiuling and Du, Bingce and Wu, Ziyun and Wan, Tingbo},
  doi          = {10.1007/s00521-022-06932-z},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3573-3587},
  shortjournal = {Neural Comput. Appl.},
  title        = {LAANet: Lightweight attention-guided asymmetric network for real-time semantic segmentation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive review on GANs for time-series signals.
<em>NCA</em>, <em>34</em>(5), 3551–3571. (<a
href="https://doi.org/10.1007/s00521-022-06888-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the last decade, deep learning (DL) techniques have demonstrated the capabilities in various applications with a large number of labeled samples. Unfortunately, it is normally difficult to obtain such large amounts of samples in practice. As one of the most promising research directions of data generation in DL, generative adversarial network (GAN) can process not only images but also time-series signals. Unfortunately, it is easy to lose the time-dependence information from the latter due to characteristics of GAN, which increases the challenge of signal generation. Besides, the existing evaluation methods cannot evaluate the performance of GAN comprehensively. Therefore, this paper summarizes the current work of time-series signals generation based on GAN and the existing evaluation methods of GAN. As compared to existing GAN-related review work, this paper claims four unique points: (1) we specify the difficulties of GAN for time-series generation, particularly for the biological signal generation with potential solutions; (2) we analyze drawbacks of existing evaluation methods, and propose feasible solutions; (3) some suggestions are provided for the further research of robust time-series signal generation, especially for biological signal generation; (4) we provide a preliminary experiment to demonstrate the effectiveness of GANs for time-series signals generation, particularly, electroencephalogram (EEG).},
  archive      = {J_NCA},
  author       = {Zhang, Da and Ma, Ming and Xia, Likun},
  doi          = {10.1007/s00521-022-06888-0},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3551-3571},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comprehensive review on GANs for time-series signals},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecast of flood disaster emergency material demand based
on IACO-BP algorithm. <em>NCA</em>, <em>34</em>(5), 3537–3549. (<a
href="https://doi.org/10.1007/s00521-021-05883-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The frequent occurrence of various sudden natural disasters in the world has caused heavy losses to human beings. It is very important to forecast the demand of emergency materials in order to protect people&#39;s safety and property. The purpose of this study is to use IACO-BP algorithm to forecast the demand of emergency supplies in the case of flood disaster. In this study, the flood disaster situation in recent years published by the Ministry of Water Resources of China is selected as the experimental data set. The data are sorted and analyzed by a variety of theoretical comprehensive operation, qualitative and quantitative research method, analytic hierarchy process and system dynamics method. The improved ant colony optimization algorithm is used to model the emergency material demand, and the population, flood level, flood level of the disaster area are analyzed. As the network input, the material situation outputs the material demand, so as to forecast. The results show that the iteration times of IACO-BP algorithm are 11 and the running time is 3S. The fluctuation of IACO-BP algorithm is the least and the most stable among the three algorithms. The material satisfaction degree predicted by IACO-BP algorithm is improved by 15\% from the original 80.9\%. It is concluded that this algorithm is very accurate and efficient in the prediction of emergency material demand, which can better assist the disaster situation. This study contributes to the prediction of emergency material demand for emergency disaster.},
  archive      = {J_NCA},
  author       = {Chen, Fujiang and Chen, Junying and Liu, Jingang},
  doi          = {10.1007/s00521-021-05883-1},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3537-3549},
  shortjournal = {Neural Comput. Appl.},
  title        = {Forecast of flood disaster emergency material demand based on IACO-BP algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural network combining x-ray and ultrasound in breast
examination. <em>NCA</em>, <em>34</em>(5), 3523–3535. (<a
href="https://doi.org/10.1007/s00521-021-05882-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the acceleration of people’s life rhythm, the incidence of breast cancer is gradually increasing. This study mainly explores the application of neural network combined with X-ray and ultrasound in breast examination. The process discussed in this research is mainly based on AdaBoost integrated neural network. According to the basic principles of artificial neural networks, first use training samples to train the neural network, then form an integrated neural network based on the AdaBoost algorithm, and then use the test samples to perform prediction tests on the network, and perform calculations in the integrated neural network to predict the classification the results are compared with the actual results in the test set, and the total number of misclassifications is analyzed to determine whether the prediction effect of the integrated neural network is good or bad. In the process of training the neural network, the analysis of the obtained case data needs to be numerically processed and then normalized to map the data to the [− 1,1] interval. The segmentation goal is to segment each tissue in the breast ultrasound image, which are skin layer, fat layer, gland layer, tumor, muscle layer, and background layer. The mean squared error is used as the network performance evaluation function. The research results are measured by the error rate. The lower the error rate, the better the classification prediction effect and the better the performance of the individual neural network. The diagnostic coincidence rate combined with X-ray and ultrasound was 88.33\% (265/300). Compared with pure ultrasound or mammography, the difference was significant (P &lt; 0.05). The recall rate of neural network combined with X-ray and ultrasound reached 91.4\%. The results show that the neural network combined with X-ray and ultrasound has extremely high application value in breast examination.},
  archive      = {J_NCA},
  author       = {Song, Jiaguang and Zhang, Yuezhong and Wang, Shi and Liu, Zhi and Sun, Dianmin},
  doi          = {10.1007/s00521-021-05882-2},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3523-3535},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural network combining X-ray and ultrasound in breast examination},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection and recognition of stationary vehicles and seat
belts in intelligent internet of things traffic management system.
<em>NCA</em>, <em>34</em>(5), 3513–3522. (<a
href="https://doi.org/10.1007/s00521-021-05870-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increase in the size of the city and the increase in population mobility have greatly increased the number of vehicles on the road, and at the same time brought considerable challenges to the traffic management department. In recent years, more and more experts and scholars have devoted themselves to applying sensors, network communication and dynamic adaptive technologies to road traffic management systems. At present, people have not completely overcome all kinds of complex problems in traffic supervision. The complexity of traffic information and the defects of identification algorithms have brought great challenges to intelligent traffic management. This article has launched a research on the intelligent Internet of Things traffic management system, with the detection and recognition of stationary vehicles and seat belts as the key analysis targets. When monitoring stationary vehicles, this paper replaces the background difference algorithm commonly used in dynamic vehicle detection with a new recognition algorithm. From the experimental results, the average detection accuracy of the new algorithm is 96.77\% higher than the previous 87.56\%. When studying the driver&#39;s seat belt detection, this paper combines the YOLOv3 target detection algorithm and the lightweight network structure, and proposes a driver-oriented positioning algorithm. With the increase in the number of lightweight templates, the accuracy of the positioning algorithm has increased from 80.57 to 99.98\%. But on the other hand, the detection speed has also changed from 78 to 69 frames/s.},
  archive      = {J_NCA},
  author       = {Wang, Zhenyan and Ma, Yongjie},
  doi          = {10.1007/s00521-021-05870-6},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3513-3522},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection and recognition of stationary vehicles and seat belts in intelligent internet of things traffic management system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Price prediction of pu’er tea based on ARIMA and BP models.
<em>NCA</em>, <em>34</em>(5), 3495–3511. (<a
href="https://doi.org/10.1007/s00521-021-05827-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pu’er tea is a Yunnan geographical indication product, and its brand value ranks first in China. At present, qualitative and quantitative methods with low prediction accuracy are used to predict price. In this paper, based on the current situation and industry characteristics, a differential autoregressive integrated moving average model (ARIMA) is used to predict the short-term price. From the perspective of macro and micro, back-propagation neural network model (BP) was established to predict the long-term price based on the weight ranking of 16 factors affecting the price by technique for order preference by similarity to ideal solution method (TOPSIS). The future price is predicted and analyzed, and then based on the empirical results, suggestions are put forward for the industry in terms of reducing production capacity, increasing consumer demand and combining with the publicity and promotion of Internet.},
  archive      = {J_NCA},
  author       = {Dou, Zhi-wu and Ji, Ming-xin and Wang, Man and Shao, Ya-nan},
  doi          = {10.1007/s00521-021-05827-9},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3495-3511},
  shortjournal = {Neural Comput. Appl.},
  title        = {Price prediction of pu’er tea based on ARIMA and BP models},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast overlap removal for location-related representation
elements. <em>NCA</em>, <em>34</em>(5), 3483–3494. (<a
href="https://doi.org/10.1007/s00521-021-05825-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to resolve the issues with overlapping elements in location-related applications, an element adjustment method is proposed. This adjustment method can be implemented using a non-iterative algorithm which can significantly improve the processing efficiency of overlap removal. The method first sorts out all the elements according to the distance from the preset Starting Point. Repulsive offset adjustment is used for circular elements. It can be validated through theoretical derivation. Finally, the influencing factors of algorithm parameters are analyzed. Suggestions are given to further optimization of the algorithm. Experimental results show that it can effectively remove overlapping. The relative positional relationship among elements can be preserved to the greatest extent. User’s verifications and expert’s evaluation show that it can also achieve high recognition rate between the geographic region and its representation element.},
  archive      = {J_NCA},
  author       = {Chen, Hongqian and Li, Hui},
  doi          = {10.1007/s00521-021-05825-x},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3483-3494},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fast overlap removal for location-related representation elements},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A joint model for entity and relation extraction based on
BERT. <em>NCA</em>, <em>34</em>(5), 3471–3481. (<a
href="https://doi.org/10.1007/s00521-021-05815-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, as the knowledge graph has attained significant achievements in many specific fields, which has become one of the core driving forces for the development of the internet and artificial intelligence. However, there is no mature knowledge graph in the field of agriculture, so it is a great significance study on the construction technology of agricultural knowledge graph. Named entity recognition and relation extraction are key steps in the construction of knowledge graph. In this paper, based on the joint extraction model LSTM-LSTM-Bias brought in BERT pre-training language model to proposed a agricultural entity relationship joint extraction model BERT-BILSTM-LSTM which is applied to the standard data set NYT and self-built agricultural data set AgriRelation. Experimental results showed that the model can effectively extracted the relationship between agricultural entities and entities.},
  archive      = {J_NCA},
  author       = {Qiao, Bo and Zou, Zhuoyang and Huang, Yu and Fang, Kui and Zhu, Xinghui and Chen, Yiming},
  doi          = {10.1007/s00521-021-05815-z},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3471-3481},
  shortjournal = {Neural Comput. Appl.},
  title        = {A joint model for entity and relation extraction based on BERT},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Classification of thermal image of clinical burn based on
incremental reinforcement learning. <em>NCA</em>, <em>34</em>(5),
3457–3470. (<a
href="https://doi.org/10.1007/s00521-021-05772-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the judgment of the burn depth is mainly based on the experience of doctors, so the accuracy of judgment is low, which will affect the follow-up treatment and nursing. In order to improve the diagnostic effect of clinical burns, based on incremental reinforcement learning algorithms, this paper constructs a classification model of clinical burn thermal images based on machine learning algorithms. Moreover, this paper proposes an adaptive network algorithm and uses the structure of the network to implement a reinforcement learning algorithm. In this algorithm, in order to reduce the computational complexity under the premise of ensuring sample utilization, the parameters are updated in the form of increments. In addition, this paper uses the value function approximator to linearly approximate the value function and TD error. Finally, this paper constructs the basic structure of the model based on the functional requirements and constructs experiments to verify the performance of the model. The research results show that the algorithm has good convergence and the image classification effect is very obvious, so it has certain practical significance.},
  archive      = {J_NCA},
  author       = {Wu, Xianjun and Huang, Wendong and Wu, Xiaoli and Wu, Shenghang and Huang, Jinbo},
  doi          = {10.1007/s00521-021-05772-7},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3457-3470},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of thermal image of clinical burn based on incremental reinforcement learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Flood disaster risk assessment based on random forest
algorithm. <em>NCA</em>, <em>34</em>(5), 3443–3455. (<a
href="https://doi.org/10.1007/s00521-021-05757-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the frequent occurrence of natural disasters, timely warning of flood disasters has become an issue of concern. This research mainly discusses flood disaster risk assessment based on random forest algorithm. This study uses the special functions of GIS to collect, manage, and analyze data to propose a method of flood disaster risk assessment based on GIS. This method is based on the characteristics of natural disaster-causing factors in the study area, selects an appropriate grid size, and finally realizes the function of visual expression of regional disaster risk. First, use ArcGIS10.1 to analyze and integrate each hazard factor into the flood disaster report index model. Second, the random forest algorithm is used as the weight of each parameter of the flood disaster index model. Finally, use ArcGIS spatial analysis tool map algebra function to model, carry out flood risk assessment in different periods, and use spatial analysis function to extract the median value to point function to extract the flood inundation depth of the study area in a specific scenario. In the experimental part, this research uses layer overlay to determine the number and types of affected areas. Using the natural break point method of ArcGIS 10.1 platform, the study area is divided according to the magnitude of the flood disaster risk value. At the same time, there are a total of 85 samples that have experienced flood disasters, of which only six have been misjudged as no flood disasters. Generally speaking, the model prediction accuracy is high. The research results show that the combination of random forest algorithm and GIS technology is convenient for analyzing the spatial pattern and internal laws of flood risk, and has good applicability.},
  archive      = {J_NCA},
  author       = {Zhu, Zijiang and Zhang, Yu},
  doi          = {10.1007/s00521-021-05757-6},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3443-3455},
  shortjournal = {Neural Comput. Appl.},
  title        = {Flood disaster risk assessment based on random forest algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Early warning and real-time control of construction safety
risk of underground engineering based on building information modeling
and internet of things. <em>NCA</em>, <em>34</em>(5), 3433–3442. (<a
href="https://doi.org/10.1007/s00521-021-05755-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this study is to establish a safety risk warning system for the construction of underground engineering and to solve the problems existing in current construction of underground engineering, such as large investment, long construction period, complex construction environment, and many unforeseen risk factors. In this research, building information modeling (BIM) technology and Internet of things technology are used to analyze the construction of safety risk warning system for underground engineering. Firstly, the concept and application of BIM technology and safety risk warning of underground engineering construction are introduced. Then, aiming at the existing safety problems of underground construction, the construction principle of underground construction safety indicator system, the establishment steps of indicator system and safety risk indicator system are introduced in detail, and a set of early warning and control system of safety risk of underground construction based on BIM technology and Internet of things technology is established. At last, the working mode and real-time monitoring of underground engineering early warning based on BIM technology and Internet of things are expounded. The results show that the underground engineering prediction system based on BIM technology and the Internet of things adopts the working mode that combines the circular safety risk warning wheel mode and the three-dimensional safety risk warning mode. Moreover, the real-time dynamic monitoring of the security risk warning system can be achieved through the periodic recording and testing of process indicators by the BIM management platform. It is hoped that this study can provide a good management platform for underground construction safety and reduce the occurrence of safety accidents in underground construction.},
  archive      = {J_NCA},
  author       = {Liang, Yu and Liu, Qixin},
  doi          = {10.1007/s00521-021-05755-8},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3433-3442},
  shortjournal = {Neural Comput. Appl.},
  title        = {Early warning and real-time control of construction safety risk of underground engineering based on building information modeling and internet of things},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-domain recommendation based on latent factor
alignment. <em>NCA</em>, <em>34</em>(5), 3421–3432. (<a
href="https://doi.org/10.1007/s00521-021-05737-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, various cross-domain recommendation (CDR) models are proposed to overcome the sparsity problem, which leverage relatively abundant rating data from the auxiliary domain to improve recommendation performance of target domain. Though matrix factorization-based collaborative filtering algorithms gain dominance in single-domain recommendation systems, they cannot be used directly in cross-domain cases as the obtained latent factors of the target and auxiliary domains may not be aligned, which will lead to inaccurate knowledge transfer from the auxiliary domain to the target one. A CDR model named CDCFLFA is presented in this paper to solve this problem. In CDCFLFA, firstly latent factors between the two domains are aligned based on pattern matching. Then, user preferences of the auxiliary domain are transferred to update the original user latent vectors of target domain. Finally, a linear least square problem is solved to compute the item latent vectors of target domain and thus unknown ratings are obtained according to the updated user and item latent vectors. CDCFLFA does not require the same user or item sets between the two domains. Extensive experiments are conducted, and the results show that CDCFLFA achieves smaller MAE and RMSE values and larger precision and recall than the previous single- and cross-domain recommendation methods. Hence, CDCFLFA can be regarded as an effective cross-domain extension of single-domain matrix factorization algorithm.},
  archive      = {J_NCA},
  author       = {Yu, Xu and Hu, Qiang and Li, Hui and Du, Junwei and Gao, Jia and Sun, Lijun},
  doi          = {10.1007/s00521-021-05737-w},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3421-3432},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cross-domain recommendation based on latent factor alignment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-system fusion based on deep neural network and cloud
edge computing and its application in intelligent manufacturing.
<em>NCA</em>, <em>34</em>(5), 3411–3420. (<a
href="https://doi.org/10.1007/s00521-021-05735-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural network is an important computer operating system in China. It has made great breakthroughs in target recognition, image classification and other fields. It plays a key role in multi-system integration and intelligent manufacturing industry, such as training and testing. The purpose of this paper is to study the multi-system fusion of deep neural network and its application in intelligent manufacturing industry. By setting up experiments, the multi-system fusion of neural network is carried out, combining with big data and artificial intelligence to verify the efficient operation of neural network in multi-system fusion. Using the methods of mathematical analysis and big data fitting, the collected data are classified, the experimental data are collected and then analyzed. In this paper, the reliability of this method is verified by research; the application of multi-system fusion based on deep neural network in intelligent manufacturing industry can effectively integrate all systems, improve the comprehensive working efficiency of each system by about 20\% and improve the multi-system fusion of deep neural network and its application in intelligent manufacturing industry by about 15\%. Thus, as the terminal of the system, the deep neural network plays the leading role of multiple systems. It can effectively integrate the various systems and improve the comprehensive work efficiency of each system, which has guiding significance for the development of industry.},
  archive      = {J_NCA},
  author       = {Fan, Linyuan and Zhang, Liang},
  doi          = {10.1007/s00521-021-05735-y},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3411-3420},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-system fusion based on deep neural network and cloud edge computing and its application in intelligent manufacturing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Condition monitoring and life prediction of the turning tool
based on extreme learning machine and transfer learning. <em>NCA</em>,
<em>34</em>(5), 3399–3410. (<a
href="https://doi.org/10.1007/s00521-021-05716-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When the turning tool has worn and failed but the failure is not found, if it continues to be used for processing, it will break, and cause the workpiece to be scrapped, and even damage the machine tool. In order to avoid the loss caused by turning tool wear, the remaining useful life (RUL) prediction of turning tool wear has become a hot research topic in recent years. For RUL prediction in turning tools, the traditional machine is difficult to acquire sufficient degradation data and inconsistent data distribution among different turning tools in engineering, and they cannot provide better prediction accuracy to some extent. To solve the above problems, this paper proposes a multi-granularity feature extraction (MGFE) method based on the gray-level co-occurrence matrix (GLCM) and random forest (RF). Moreover, a health indicator (HI) of turning tools in the source domain was obtained. The common representative features in HI sequence of target domain was transferred to source domain and builds the condition monitoring and life prediction system of turning tools based on extreme learning machine and transfer learning. Finally, extreme vector machine (ELM) is used to construct the RUL prediction model. The research results show that the model constructed in this paper is effective in RUL prediction and can significantly improve the prediction accuracy of remaining useful life.},
  archive      = {J_NCA},
  author       = {Gao, Zhan and Hu, Qiguo and Xu, Xiangyang},
  doi          = {10.1007/s00521-021-05716-1},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3399-3410},
  shortjournal = {Neural Comput. Appl.},
  title        = {Condition monitoring and life prediction of the turning tool based on extreme learning machine and transfer learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of jujube defects in small data sets based on
transfer learning. <em>NCA</em>, <em>34</em>(5), 3385–3398. (<a
href="https://doi.org/10.1007/s00521-021-05715-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although convolutional neural networks have achieved success in the field of image classification, there are still challenges in the field of agricultural product quality sorting such as machine vision-based jujube defects detection. The performance of jujube defect detection mainly depends on the feature extraction and the classifier used. Due to the diversity of the jujube materials and the variability of the testing environment, the traditional method of manually extracting the features often fails to meet the requirements of practical application. In this paper, a jujube sorting model in small data sets based on convolutional neural network and transfer learning is proposed to meet the actual demand of jujube defects detection. Firstly, the original images collected from the actual jujube sorting production line were pre-processed, and the data were augmented to establish a data set of five categories of jujube defects. The original CNN model is then improved by embedding the SE module and using the triplet loss function and the center loss function to replace the softmax loss function. Finally, the depth pre-training model on the ImageNet image data set was used to conduct training on the jujube defects data set, so that the parameters of the pre-training model could fit the parameter distribution of the jujube defects image, and the parameter distribution was transferred to the jujube defects data set to complete the transfer of the model and realize the detection and classification of the jujube defects. The classification results are visualized by heatmap through the analysis of classification accuracy and confusion matrix compared with the comparison models. The experimental results show that the SE-ResNet50-CL model optimizes the fine-grained classification problem of jujube defect recognition, and the test accuracy reaches 94.15\%. The model has good stability and high recognition accuracy in complex environments.},
  archive      = {J_NCA},
  author       = {Ju, Jianping and Zheng, Hong and Xu, Xiaohang and Guo, Zhongyuan and Zheng, Zhaohui and Lin, Mingyu},
  doi          = {10.1007/s00521-021-05715-2},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3385-3398},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of jujube defects in small data sets based on transfer learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Study on the intelligent identification method of formation
lithology by element and gamma spectrum. <em>NCA</em>, <em>34</em>(5),
3375–3383. (<a
href="https://doi.org/10.1007/s00521-021-05714-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid and accurate identification of the formation lithology encountered during the drilling of oil and gas fields is an important step to control the trajectory of the drilling tool borehole and improve the optimal reservoir encounter rate. At present, the main way to distinguish the lithology of the formation encountered by drilling is to use artificial detection elements, which does not form a set of intelligent formation identification system. In view of the above problems, this paper proposes a method to identify the lithology of drilled formation by using element and gamma spectrum measurement and establishes a reasoning model of intelligent identification of formation lithology by using improved fuzzy clustering algorithm-SVM (IFCM-SVM) method. Field application shows that the accuracy of IFCM-SVM intelligent formation identification method proposed in this paper can reach 90.9\%, and verifies the feasibility of using element and gamma spectrum measurement to realize the intelligent identification of formation lithology in drilling.},
  archive      = {J_NCA},
  author       = {Zhang, He and Chen, Qiuhong and Ni, Pengbo and Liang, Haibo and Mao, Min and Zou, Jialing},
  doi          = {10.1007/s00521-021-05714-3},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3375-3383},
  shortjournal = {Neural Comput. Appl.},
  title        = {Study on the intelligent identification method of formation lithology by element and gamma spectrum},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The improved genetic and BP hybrid algorithm and neural
network economic early warning system. <em>NCA</em>, <em>34</em>(5),
3365–3374. (<a
href="https://doi.org/10.1007/s00521-021-05712-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Economic early warning is the recognition and judgment of the state of economic operation, and its research results directly affect the rational formulation of macro-control policies. However, the traditional early warning methods are mainly based on expert experience or simple statistical model, which are difficult to reflect the nature of highly nonlinear economic system and can not meet the objective requirements of macroeconomic early warning. Based on the above background, the purpose of this study is to design an economic early warning system based on improved genetic and BP hybrid algorithm and neural network. Based on the overview of macroeconomic early warning at home and abroad, this study expounds the design of early warning index system, early warning model, establishment of early warning system and other issues in the macroeconomic early warning theoretical system; deeply analyses the theoretical methods of BP neural network and adaptive mutation genetic algorithm, and discusses the feasibility of realizing macroeconomic early warning by BP neural network and adaptive mutation genetic algorithm, The improved genetic and BP hybrid algorithm and neural network economic early warning model are established. Finally, the experimental results show that the correlation coefficient between the composite index and the comprehensive early warning is 0.89, and the delay number is 0, which shows that the early warning index obtained by the early warning system can accurately reflect the actual economic fluctuations. The results show that the improved genetic and BP hybrid algorithm and neural network economic early warning system are effective, feasible and have good accuracy.},
  archive      = {J_NCA},
  author       = {Yin, Xinzhe and Li, Jinghua and Huang, Shoujun},
  doi          = {10.1007/s00521-021-05712-5},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3365-3374},
  shortjournal = {Neural Comput. Appl.},
  title        = {The improved genetic and BP hybrid algorithm and neural network economic early warning system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interactivity of english online learning based on neural
network. <em>NCA</em>, <em>34</em>(5), 3349–3364. (<a
href="https://doi.org/10.1007/s00521-021-05701-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operation of the mobile interactive autonomous learning system injects advanced management technology and scientific and reasonable management system for the effective management and arrangement of the school&#39;s teaching, enables students to conduct autonomous learning in their spare time, makes full use of students&#39; fragmented time, and improves students&#39; learning enthusiasm and efficiency. Based on the neural network algorithm, this paper constructs an English network learning interactive evaluation model, studies the influence of the flattening layer in the convolutional neural network structure on the structural complexity, and then proposes spatial pyramid weighted average pooling to optimize the traditional flattened layer. Moreover, this paper evaluates RSPP from three aspects: space complexity, training time-consuming, and accuracy. In addition, this paper designs two types of integrated convolutional neural networks, namely Bagging integration and snapshot integration. Finally, this paper evaluates the performance of the model through experiments and counts the experimental results. The research results show that the model constructed in this paper has a certain effect.},
  archive      = {J_NCA},
  author       = {Hong, Xiyao},
  doi          = {10.1007/s00521-021-05701-8},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3349-3364},
  shortjournal = {Neural Comput. Appl.},
  title        = {Interactivity of english online learning based on neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Aerobics posture recognition based on neural network and
sensors. <em>NCA</em>, <em>34</em>(5), 3337–3348. (<a
href="https://doi.org/10.1007/s00521-020-05632-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional aerobics gesture recognition has shortcomings such as low scalability, limitations in application scenarios, limitations in labor costs, and human–computer interaction. In order to improve the efficiency of aerobics posture recognition, based on neural network, this paper constructs aerobics posture recognition model combined with sensor network. Moreover, aiming at the unsatisfactory performance of the natural feature-based visual 3D registration method for scenes with sparse texture features and complex dynamic scenes, a deep neural network based on CNN + LSTM is proposed to establish the relative motion relationship between camera positions in continuous video sequences. In addition, this paper uses the transfer learning method to apply the network training parameters for the classification task to the video sequence posture recognition in this paper. Finally, considering the temporal correlation between video sequences, this paper uses the LSTM structure to store long-term image memory information. The experimental results show that the performance of the model constructed in this paper is good.},
  archive      = {J_NCA},
  author       = {Liu, Qinqin},
  doi          = {10.1007/s00521-020-05632-w},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3337-3348},
  shortjournal = {Neural Comput. Appl.},
  title        = {Aerobics posture recognition based on neural network and sensors},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Considering optimization of english grammar error correction
based on neural network. <em>NCA</em>, <em>34</em>(5), 3323–3335. (<a
href="https://doi.org/10.1007/s00521-020-05591-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {English expression, language characteristics and usage norms are quite special, which is quite different from Chinese. This has special requirements for auxiliary teaching tools that use computer technology for English text processing. Based on neural network algorithm, this paper combines the actual needs of English grammar error correction to construct an English grammar error correction model based on neural network. In data processing, after feature selection, logistic regression model is used to analyze the influence of different features on article error correction. The article error correction incorporating word vector features mainly explores how to effectively express the features in English grammar error correction. In addition, this paper proposes two methods to optimize the feature representation in article error correction. One is to directly use the word vector corresponding to the word as a feature, replacing the original One-hot encoding, and the other uses a clustering method to compress the article features. Finally, this paper designs experiments to study the performance of the model constructed in this paper. The results obtained show that the model constructed in this paper has a certain effect.},
  archive      = {J_NCA},
  author       = {Hu, Liang and Tang, Yanling and Wu, Xinli and Zeng, Jincheng},
  doi          = {10.1007/s00521-020-05591-2},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3323-3335},
  shortjournal = {Neural Comput. Appl.},
  title        = {Considering optimization of english grammar error correction based on neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Routing optimization strategy of IoT awareness layer based
on improved cat swarm algorithm. <em>NCA</em>, <em>34</em>(5),
3311–3322. (<a
href="https://doi.org/10.1007/s00521-020-05590-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Internet of Things technology, wireless sensor networks have been widely used in many places. This study mainly discusses the routing optimization strategy of the IoT perceptive layer based on the improved cat swarm algorithm. This study simulates a perceptive network with 100 nodes deployed randomly. As SDWSN for Internet of Things applications, in order to simulate the data transmission requirements of IoT communication and ensure the fairness of experimental comparison, this study uses the pseudo-random mechanism to generate the source address and destination address of data packets. A special SDN controller node is added to the network. The SDN controller node broadcasts information to each sensing node, and the common sensing node sends node information to the SDN controller. The SDN controller can survive the global time graph of the entire network according to the information of the common node. In order to avoid the problem of high energy consumption of cluster heads caused by long-distance data transmission, the cat algorithm protocol adopts multi-hop communication between cluster heads and BS and uses network overhead index to quantify link overhead as the basis for cluster heads to select the next hop node. When the inter-cluster multi-hop route is successfully established, the wireless sensor node begins to collect data and send it to BS node. Six monitoring nodes, two coordinators and one workstation were selected as the test objects. The data volume sent by each node was 2000, and the accuracy rate of test transmission information at different rates and transmission distances was determined. The group network coverage rate of cat swarm algorithm is always above 95\%, and the average energy loss of nodes is the highest and less than 36\%. The results show that the aggregate of energy consumption of cluster heads and the variance of energy consumption are the lowest in the improved cat cluster algorithm, which ensures the reliable transmission of node data.},
  archive      = {J_NCA},
  author       = {Xiao, Xiang and Zhao, Ming},
  doi          = {10.1007/s00521-020-05590-3},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3311-3322},
  shortjournal = {Neural Comput. Appl.},
  title        = {Routing optimization strategy of IoT awareness layer based on improved cat swarm algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Neural network in sports cluster analysis. <em>NCA</em>,
<em>34</em>(5), 3301–3309. (<a
href="https://doi.org/10.1007/s00521-020-05585-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of rapid development of the Internet, various types of data in daily life are becoming more and more important, as are people&#39;s sports data. How to collect and store these massive exercise data and how to extract the user&#39;s exercise habits from these data are of great significance for improving people&#39;s exercise enthusiasm. This article mainly studies the application of the network in the cluster analysis of sports. This paper proposes a combination of a neural network-based sports data analysis model and a density peak clustering algorithm for unsupervised dimensionality reduction of high-dimensional data. We design both the encoder and the decoder with a three-layer fully connected neural network structure. The encoder extracts the characteristics of the sample data, and then, the decoder approximates the original input sample. The encoder is used to reduce the dimensionality of the high-dimensional data to the middle dimension, combined with the density peak clustering algorithm to further reduce the dimensionality, and then analyze the low-dimensional data. And set the corresponding learning rate for different data sets, the three data sets are iterated 40 times. The prediction accuracy rates of the algorithm in the three data sets are 94.1\%, 90.3\%, and 89.6\% respectively; compared with the traditional PCA dimensionality reduction method, the method in this paper can extract data features more effectively, improve the dispersion between clusters, and have a better clustering effect. Finally, a numerical example is given to illustrate the effectiveness of the proposed algorithm.},
  archive      = {J_NCA},
  author       = {Zhang, Yanhua and Hou, Xuehua and Xu, Shan},
  doi          = {10.1007/s00521-020-05585-0},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3301-3309},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural network in sports cluster analysis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on multi-modal information learning and
analytics on big data. <em>NCA</em>, <em>34</em>(5), 3299–3300. (<a
href="https://doi.org/10.1007/s00521-021-06363-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ma, Xiaomeng and Sun, Yan},
  doi          = {10.1007/s00521-021-06363-2},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3299-3300},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on multi-modal information learning and analytics on big data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tuning of LQR-PID controller to control parallel
manipulator. <em>NCA</em>, <em>34</em>(4), 3283–3297. (<a
href="https://doi.org/10.1007/s00521-021-06608-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents mathematical modeling and optimal path control of a 3-DOF Maryland manipulator. Three dissimilar and consecutive paths are taken under observation, and control action is performed by linear quadratic regulator (LQR)-based proportional–integral–derivative (PID) controller. To achieve optimal path tracking control, tuning of PID gain parameters is necessary and it is done by optimal selection of weighting matrices of LQR. The evolutionary optimization algorithms like GA and PSO are used in the past for the optimal selection of LQR parameters for tuning of PID gain parameter, but both the methods fail to achieve accurate trajectory tracking control because the simulation results show higher values of fitness function (J), sum square error, integral square error, and integral absolute error between the desired and the actual trajectory for all joint angles, as discussed in the result analysis section. The gray wolf optimizer (GWO) algorithm is then proposed; this method provides optimal values of gain parameters. The simulation results show that the values of all types of error and fitness function for all joint angles are quite lesser than GA and PSO. Hence, the proposed GWO proves better among all and it provides high accuracy in trajectory tracking control with better performance indices. To demonstrate the proposed algorithm, the mathematical simulations are performed as well as the conduction of experimental work.},
  archive      = {J_NCA},
  author       = {Choubey, Chandan and Ohri, Jyoti},
  doi          = {10.1007/s00521-021-06608-0},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3283-3297},
  shortjournal = {Neural Comput. Appl.},
  title        = {Tuning of LQR-PID controller to control parallel manipulator},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A precise neuro-fuzzy model enhanced by artificial bee
colony techniques for assessment of rock brittleness index.
<em>NCA</em>, <em>34</em>(4), 3263–3281. (<a
href="https://doi.org/10.1007/s00521-021-06600-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When planning rock-based projects, the brittleness index (BI) may play a significant role in the success of various projects, such as tunnel boring machines and road headers. Lack of accurate BI prediction of the rock sample may result in numerous disastrous incidents associated with rock mechanics. Adaptive neuro-fuzzy inference system (ANFIS) is a model for predicting the rock’s BI. However, the performance of this model mainly depends on its parameter values and tuning these values requires knowledge and time. This study improves the performance of ANFIS modeling using an Artificial Bee Colony (ABC) optimization algorithm to automatically optimize the parameters of ANFIS, called ANFIS_ABC. Three versions of ANFIS_ABC algorithms were proposed to predict the BI of rock, in which the ABC algorithm was applied in different model development stages. The performance of the proposed predictive models was evaluated using the rock samples collected from a tunneling project in Malaysia comprising 113 samples. The Schmidt hammer rebound number (Rn) (ranging from 20 to 61), P-wave velocity (Vp) (ranging from 2870 to 7702 m/s), and Point load index (IS50) (ranging from 0.89 to 7.1 MPa) were used as input parameters. According to the results obtained by the various performance indices, the proposed model (i.e., ANFIS_ABC_PC) was able to receive the highest accuracy level in predicting rock BI among all constructed models. The developed model may be applied with caution to relevant areas of rock mechanics.},
  archive      = {J_NCA},
  author       = {Parsajoo, Maryam and Armaghani, Danial Jahed and Asteris, Panagiotis G.},
  doi          = {10.1007/s00521-021-06600-8},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3263-3281},
  shortjournal = {Neural Comput. Appl.},
  title        = {A precise neuro-fuzzy model enhanced by artificial bee colony techniques for assessment of rock brittleness index},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Endogenous growth factors and their empirical verification
in the colombian business context by applying fuzzy measurement
techniques. <em>NCA</em>, <em>34</em>(4), 3249–3261. (<a
href="https://doi.org/10.1007/s00521-021-06492-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper centers on the role and economic effect of the factors that affect the endogenous growth of organizations. To this end, it analyzes the case of Colombian companies, whose economy has been characterized in Latin America by maintaining a traditional economic policy and sectors that seek to maximize the opportunities offered by international markets. This study seeks to identify and analyze the factors that influence the endogenous economic growth of organizations and that allow them to be sustainable over time. For this purpose, adaptation algorithms based on fuzzy logics and supervised and unsupervised learning methods were used, generating an adaptation strategy that allows classifying and knowing the endogenous growth of companies in the Colombian context and identifying the most relevant aspects to take into account. Finally, it was found that most Colombian companies focus their business policies on strengthening human capital, followed by innovation, financial resources and, to a lesser extent, strategic alliances.},
  archive      = {J_NCA},
  author       = {Gómez-Caicedo, Melva Inés and Gaitán-Angulo, Mercedes and Quintero, Anderson and Danna-Buitrago, Jenny Paola},
  doi          = {10.1007/s00521-021-06492-8},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3249-3261},
  shortjournal = {Neural Comput. Appl.},
  title        = {Endogenous growth factors and their empirical verification in the colombian business context by applying fuzzy measurement techniques},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BINGO: Brain-inspired learning memory. <em>NCA</em>,
<em>34</em>(4), 3223–3247. (<a
href="https://doi.org/10.1007/s00521-021-06484-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Storage and retrieval of data in a computer memory play a major role in system performance. Traditionally, computer memory organization is ‘static’—i.e. it does not change based on the application-specific characteristics in memory access behaviour during system operation. Specifically, in the case of a content-operated memory (COM), the association of a data block with a search pattern (or cues) and the granularity (details) of a stored data do not evolve. Such a static nature of computer memory, we observe, not only limits the amount of data we can store in a given physical storage, but it also misses the opportunity for performance improvement in various applications. On the contrary, human memory is characterized by seemingly infinite plasticity in storing and retrieving data—as well as dynamically creating/updating the associations between data and corresponding cues. In this paper, we introduce BINGO, a brain-inspired learning memory paradigm that organizes the memory as a flexible neural memory network. In BINGO, the network structure, strength of associations, and granularity of the data adjust continuously during system operation, providing unprecedented plasticity and performance benefits. We present the associated storage/retrieval/retention algorithms in BINGO, which integrate a formalized learning process. Using an operational model, we demonstrate that BINGO achieves an order of magnitude improvement in memory access times and effective storage capacity using the CIFAR-10 dataset and the wildlife surveillance dataset when compared to traditional content-operated memory.},
  archive      = {J_NCA},
  author       = {Chakraborty, Prabuddha and Bhunia, Swarup},
  doi          = {10.1007/s00521-021-06484-8},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3223-3247},
  shortjournal = {Neural Comput. Appl.},
  title        = {BINGO: Brain-inspired learning memory},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decoding neurobiological spike trains using recurrent neural
networks: A case study with electrophysiological auditory cortex
recordings. <em>NCA</em>, <em>34</em>(4), 3213–3221. (<a
href="https://doi.org/10.1007/s00521-021-06589-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in multielectrode methods and spike-sorting algorithms enable the in vivo recording of the activities of many neurons at a high temporal resolution. These datasets offer new opportunities in the investigation of the biological neural code, including the direct testing of specific coding hypotheses, but they also reveal the limitations of present decoder algorithms. Classical methods rely on a manual feature extraction step, resulting in a feature vector, like the firing rates of an ensemble of neurons. In this paper, we present a recurrent neural-network-based decoder and evaluate its performance on experimental and artificial datasets. The experimental datasets were obtained by recording the auditory cortical responses of rats exposed to sound stimuli, while the artificial datasets represent preset encoding schemes. The task of the decoder was to classify the action potential timeseries according to the corresponding sound stimuli. It is illustrated that, depending on the coding scheme, the performance of the recurrent-network-based decoder can exceed the performance of the classical methods. We also show how randomized copies of the training datasets can be used to reveal the role of candidate spike-train features. We conclude that artificial neural network decoders can be a useful alternative to classical population vector-based techniques in studies of the biological neural code.},
  archive      = {J_NCA},
  author       = {Szabó, Péter and Barthó, Péter},
  doi          = {10.1007/s00521-021-06589-0},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3213-3221},
  shortjournal = {Neural Comput. Appl.},
  title        = {Decoding neurobiological spike trains using recurrent neural networks: A case study with electrophysiological auditory cortex recordings},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view dual attention network for 3D object recognition.
<em>NCA</em>, <em>34</em>(4), 3201–3212. (<a
href="https://doi.org/10.1007/s00521-021-06588-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing view-based 3D object classification and recognition methods ignore the inherent hierarchical correlation and distinguishability of views, making it difficult to further improve the classification accuracy. In order to solve this problem, this paper proposes an end-to-end multi-view dual attention network framework for high-precision recognition of 3D objects. On one hand, we obtain three feature layers of query, key, and value through the convolution layer. The spatial attention matrix is generated by the key-value pairs of query and key, and each feature in the value of the original feature space branch is assigned different importance, which clearly captures the prominent detail features in the view, generates the view space shape descriptor, and focuses on the detail part of the view with the feature of category discrimination. On the other hand, a channel attention vector is obtained by compressing the channel information in different views, and the attention weight of each view feature is scaled to find the correlation between the target views and focus on the view with important features in all views. Integrating the two feature descriptors together to generate global shape descriptors of the 3D model, which has a stronger response to the distinguishing features of the object model and can be used for high-precision 3D object recognition. The proposed method achieves an overall accuracy of 96.6\% and an average accuracy of 95.5\% on the open-source ModelNet40 dataset, compiled by Princeton University when using Resnet50 as the basic CNN model. Compared with the existing deep learning methods, the experimental results demonstrate that the proposed method achieves state-of-the-art performance in the 3D object classification accuracy.},
  archive      = {J_NCA},
  author       = {Wang, Wenju and Cai, Yu and Wang, Tao},
  doi          = {10.1007/s00521-021-06588-1},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3201-3212},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-view dual attention network for 3D object recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient equilibrium optimizer with support vector
regression for stock market prediction. <em>NCA</em>, <em>34</em>(4),
3165–3200. (<a
href="https://doi.org/10.1007/s00521-021-06580-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybridized method that relies on using the support vector regression (SVR) method with equilibrium optimizer (EO) is proposed to foresee the closing prices of Egyptian Exchange (EGX). Three indices are modeled and employed: EGX 30, EGX 30 capped, and EGX 50 EWI. The efficiency of using the technical indicators and statistical measures in the forecasting process is evaluated. The proposed EO-SVR-based forecasting model is adopted and evaluated using mean absolute percentage error, average, standard deviation, best fit, worst fit, and CPU time. Also, it is compared with recently developed metaheuristic optimization algorithms published in the literature such as whale optimization algorithm, salp swarm algorithm, Harris Hawks optimization, gray wolf optimizer, Henry gas solubility optimization, Barnacles mating optimizer, Manta ray foraging optimization, and slime mold algorithm. The proposed EO-SVR model got better results than other the counterparts, and EO-SVR is considered the optimal model according to its superior outcomes. Moreover, there is no need to use technical indicators and statistical measures as their effect is not noticeable.},
  archive      = {J_NCA},
  author       = {Houssein, Essam H. and Dirar, Mahmoud and Abualigah, Laith and Mohamed, Waleed M.},
  doi          = {10.1007/s00521-021-06580-9},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3165-3200},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient equilibrium optimizer with support vector regression for stock market prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical deep network with uncertainty-aware
semi-supervised learning for vessel segmentation. <em>NCA</em>,
<em>34</em>(4), 3151–3164. (<a
href="https://doi.org/10.1007/s00521-021-06578-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of organ vessels is essential for computer-aided diagnosis and surgical planning. But it is not an easy task since the fine-detailed connected regions of organ vessel bring a lot of ambiguity in vessel segmentation and sub-type recognition, especially for the low-contrast capillary regions. Furthermore, recent two-staged approaches would accumulate and even amplify these inaccuracies from the first-stage whole vessel segmentation into the second-stage sub-type vessel pixel-wise classification. Moreover, the scarcity of manual annotation in organ vessels poses another challenge. In this paper, to address the above issues, we propose a hierarchical deep network where an attention mechanism localizes the low-contrast capillary regions guided by the whole vessels, and enhance the spatial activation in those areas for the sub-type vessels. In addition, we propose an uncertainty-aware semi-supervised training framework to alleviate the annotation-hungry limitation of deep models. The proposed method achieves the state-of-the-art performance in the benchmarks of both retinal artery/vein segmentation in fundus images and liver portal/hepatic vessel segmentation in CT images. Our implementation is publicly available at https://github.com/XGGNet/Vessel-Seg .},
  archive      = {J_NCA},
  author       = {Li, Chenxin and Ma, Wenao and Sun, Liyan and Ding, Xinghao and Huang, Yue and Wang, Guisheng and Yu, Yizhou},
  doi          = {10.1007/s00521-021-06578-3},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3151-3164},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hierarchical deep network with uncertainty-aware semi-supervised learning for vessel segmentation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel approach based on combining deep learning models
with statistical methods for COVID-19 time series forecasting.
<em>NCA</em>, <em>34</em>(4), 3135–3149. (<a
href="https://doi.org/10.1007/s00521-021-06548-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has disrupted the economy and businesses and impacted all facets of people’s lives. It is critical to forecast the number of infected cases to make accurate decisions on the necessary measures to control the outbreak. While deep learning models have proved to be effective in this context, time series augmentation can improve their performance. In this paper, we use time series augmentation techniques to create new time series that take into account the characteristics of the original series, which we then use to generate enough samples to fit deep learning models properly. The proposed method is applied in the context of COVID-19 time series forecasting using three deep learning techniques, (1) the long short-term memory, (2) gated recurrent units, and (3) convolutional neural network. In terms of symmetric mean absolute percentage error and root mean square error measures, the proposed method significantly improves the performance of long short-term memory and convolutional neural networks. Also, the improvement is average for the gated recurrent units. Finally, we present a summary of the top augmentation model as well as a visual representation of the actual and forecasted data for each country.},
  archive      = {J_NCA},
  author       = {Abbasimehr, Hossein and Paki, Reza and Bahrini, Aram},
  doi          = {10.1007/s00521-021-06548-9},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3135-3149},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel approach based on combining deep learning models with statistical methods for COVID-19 time series forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). SSIT: A sample selection-based incremental model training
method for image recognition. <em>NCA</em>, <em>34</em>(4), 3117–3134.
(<a href="https://doi.org/10.1007/s00521-021-06515-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the big data environment, the expansion of image data sets makes the image recognition process need to adapt to sample characteristics and data distribution changes. In this case, image recognition research focuses on finding the balance point of incremental learning in the stability-plasticity dilemma under limited computing and storage resources. The existing incremental learning methods have disadvantages in generalization performance, iteration rounds, convergence speed, and data category imbalance, so it is essential to study the incremental learning methods for image recognition training. In this study, a sample selection-based incremental model training method is proposed for image recognition. The training process is improved by optimizing the training samples needed for each iteration. A generalization error-based category determination method is proposed to avoid the imbalance of training samples. A sample selection method based on dynamic weight is proposed to avoid the problem of increasing recognition gain. At last, experiments show that this method can enhance the generalization ability of the model. At the same time, it can meet the goal of balancing the recognition effect, reducing the number of iterations, and accelerating convergence.},
  archive      = {J_NCA},
  author       = {Zhang, Yichuan and Liu, Yadi and Yang, Guangming and Song, Jie},
  doi          = {10.1007/s00521-021-06515-4},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3117-3134},
  shortjournal = {Neural Comput. Appl.},
  title        = {SSIT: A sample selection-based incremental model training method for image recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Poisoning attacks against knowledge graph-based
recommendation systems using deep reinforcement learning. <em>NCA</em>,
<em>34</em>(4), 3097–3115. (<a
href="https://doi.org/10.1007/s00521-021-06573-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, studies have revealed that introducing knowledge graphs (KGs) into recommendation systems as auxiliary information can improve recommendation accuracy. However, KGs are usually based on third-party data that may be manipulated by malicious individuals. In this study, we developed a poisoning attack strategy applied on a KG-based recommendation system to analyze the influence of fake links. The aim of an attacker is to recommend specific products to improve their visibility. Most related studies have focused on adversarial attacks on graph data; KG-based recommendation systems have rarely been discussed. We propose an attack model corresponding to recommendations. In the model, the current recommended status and a specified item are analyzed to estimate the effects of different attack decisions (addition or deletion of facts), thereby generating the optimal attack combination. Finally, the KG is contaminated by the attack combination so that the trained recommendation model recommends a specific item to as many people as possible. We formulated the process into a deep reinforcement learning method. Conducting experiments on the movie and the fund data sets enabled us to systematically analyze our poisoning attack strategy. The experimental results proved that the proposed strategy can effectively improve an item’s ranking in a recommendation list.},
  archive      = {J_NCA},
  author       = {Wu, Zih-Wun and Chen, Chiao-Ting and Huang, Szu-Hao},
  doi          = {10.1007/s00521-021-06573-8},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3097-3115},
  shortjournal = {Neural Comput. Appl.},
  title        = {Poisoning attacks against knowledge graph-based recommendation systems using deep reinforcement learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Video surveillance image enhancement via a convolutional
neural network and stacked denoising autoencoder. <em>NCA</em>,
<em>34</em>(4), 3079–3095. (<a
href="https://doi.org/10.1007/s00521-021-06551-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an extensive-scale surveillance system, the quality of the surveillance camera installed varies. This variation of surveillance camera produces different image quality in terms of resolution, illumination, and noise. The quality of the captured image depends on the surveillance camera hardware, placement and orientation, and the surrounding light. A pixelated, low illumination and noisy image produced by a low-quality surveillance camera causes critical issues for video surveillance face recognition systems. To address these issues, a deep learning image enhancement (DLIE) model is proposed. By utilizing a deep learning architecture such as a convolutional neural network (CNN) and a denoising autoencoder, the image quality can be enhanced. The DLIE model is able to improve image resolution and illumination and reduce noise in an image. There are two deep learning blocks (DLB) in the DLIE model, which are DLB1 and DLB2. Both DLBs are arranged in parallel so that all the stated problems can be addressed simultaneously. DLB1 is proposed to address the occurrence of pixelated images by reconstructing a low-resolution image into a high-resolution image using a CNN. DLB2 used the capability of a denoising autoencoder to reconstruct the corrupted image into a clean image by enhancing the dark and noisy images. The output of each DLB is fused using image fusion to obtain the optimum image quality. The image is evaluated using the peak to signal noise ratio (PSNR) and structural similarity index (SSIM). The enhanced image from the DLIE model exhibits superior quality compared to the original image ranging from 13.3625 to 22.7728 for PSNR and 0.6207 to 0.8155 for SSIM.},
  archive      = {J_NCA},
  author       = {Che Aminudin, Muhamad Faris and Suandi, Shahrel Azmin},
  doi          = {10.1007/s00521-021-06551-0},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3079-3095},
  shortjournal = {Neural Comput. Appl.},
  title        = {Video surveillance image enhancement via a convolutional neural network and stacked denoising autoencoder},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing reasoning through reduction of vagueness using
fuzzy OWL-2 for representation of breast cancer ontologies.
<em>NCA</em>, <em>34</em>(4), 3053–3078. (<a
href="https://doi.org/10.1007/s00521-021-06517-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need to address the challenge of vagueness across several domains of applicability of ontology is gaining research attention. The presence of vagueness in knowledge represented with description logic impairs automating reasoning and inference making. The importance of reducing this vagueness in the formalization of medical knowledge representation is rising, considering the vulnerability of this domain to the expression of vague concepts or terms. This vagueness may be addressed from the perspective of ontology modeling language application such as ontology web language (OWL). Although several attempts have been made to tackle this problem in other disease prognoses such as diabetes and cardiovascular diseases, a similar effort is missing for breast cancer. Minimizing vagueness in breast cancer ontology is necessary to enhance automated reasoning and handle knowledge representation problems. This study proposes a framework for reducing vagueness in breast cancer ontology. The approach obtained breast cancer crisp ontology and applied fuzzy ontology elements based on the Fuzzy OWL2 model to formulate breast cancer fuzzy ontology. This was achieved by extending the elements of OWL2 (a more expressive version of OWL) with annotation properties to fuzzify the breast cancer crisp ontology. Results obtained showed a significant reduction of vagueness in the domain, yielding 0.38 for vagueness spread and 1.0 for vagueness explicitness. In addition, ontology metrics such as completeness, consistency, correctness and accuracy were also evaluated, and we obtained impressive performance. The implication of this result is the reduction of vagueness in breast cancer ontology, which provides increased computational reasoning support to applications using the ontology.},
  archive      = {J_NCA},
  author       = {Oyelade, Olaide N. and Ezugwu, Absalom E. and Adewuyi, Sunday A.},
  doi          = {10.1007/s00521-021-06517-2},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3053-3078},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing reasoning through reduction of vagueness using fuzzy OWL-2 for representation of breast cancer ontologies},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid models for suspended sediment prediction: Optimized
random forest and multi-layer perceptron through genetic algorithm and
stochastic gradient descent methods. <em>NCA</em>, <em>34</em>(4),
3033–3051. (<a
href="https://doi.org/10.1007/s00521-021-06550-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the nonlinear and non-stationary nature of the suspended sediment transport in rivers, suspended sediment concentration (SSC) modeling is a challenging task in environmental engineering. Investigation of SSC is of paramount importance in river morphology and hydraulic structures operation. To this end, for SSC modeling, first random forest (RF) and multi-layer perceptron (MLP) standalone models were developed, and then, they were optimized with genetic algorithm (GA) and stochastic gradient descent (SGD) to develop GA-MLP, GA-RF, SGD-MLP, and SGD-RF hybrid models. Variety of input scenarios are implemented for SSC prediction to find the best input combination. The streamflow and SSC data collected from two stations of Minnesota and San Joaquin rivers, respectively, located at South Dakota and California are utilized in the current study. Accuracies of the developed models are examined by means of three performance criteria of correlation coefficient (CC), scattered index (SI), and Willmott’s index of agreement (WI). A significant promotion in accuracy of hybrid models has been seen in contrast to their standalone counterparts. As can be deduced from the results, GA-MLP-5 and GA-RF-5 models with CC of 0.950 and 0.944, SI of 0.290 and 0.308, and WI of 0.974 and 0.971, respectively, were found as best models for prediction of SSC at Minnesota river. The developed SGD-MLP-5 and SGD-RF-5 models with CC of 0.900 and 0.901, SI of 0.339 and 0.339, and WI of 0.945 and 0.946, respectively, gave accurate results at San Joaquin river. Through the application of SGD algorithm, the adaptive learning rate, epochs, rho, L1 and L2 were activated and presumed as 0.004, 10, 1, 0.000009 and 0, respectively. The ExpRectifier was considered as san activation operation due to its better efficiency in comparison with its alternatives for predicting SSC in SGD-MLP model. According to the results, the fifth scenario that incorporates SSCt–1, SSCt–2, Qt, Qt–1, and Qt–2 were found superior for SSC modeling in the studied rivers. The recommended hybrid algorithms based on GA and SGD optimization algorithms are proposed as practical tools for solving complex environmental problems.},
  archive      = {J_NCA},
  author       = {Samadianfard, Saeed and Kargar, Katayoun and Shadkani, Sadra and Hashemi, Sajjad and Abbaspour, Akram and Safari, Mir Jafar Sadegh},
  doi          = {10.1007/s00521-021-06550-1},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3033-3051},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid models for suspended sediment prediction: Optimized random forest and multi-layer perceptron through genetic algorithm and stochastic gradient descent methods},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fuzzy WASD neuronet with application in breast cancer
prediction. <em>NCA</em>, <em>34</em>(4), 3019–3031. (<a
href="https://doi.org/10.1007/s00521-021-06572-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is one of the world’s leading causes of human mortality, and the most prevalent type is breast cancer. However, when diagnosed early, breast cancer may be treated. In this paper, a 5-layer feed-forward neuronet model, trained by a novel fuzzy WASD (weights-and-structure-determination) algorithm, called FUZWASD, is introduced and employed to predict whether the breast cancer is benign or malignant. In general, WASD-trained neuronets are known to overcome the limitations of traditional back-propagation neuronets, including slow training speed and local minimum; however, multi-input WASD-trained neuronets with no dimension explosion weakness are few. In this work, a novel FUZWASD algorithm for training neuronets is modeled by embedding a fuzzy logic controller (FLC) in a WASD algorithm, and a multi-input FUZWASD neuronet (MI-FUZWASDN) model for classification problems with no dimension explosion weakness is proposed. The FUZWASD algorithm uses a FLC to map the input data into a specific interval that enhances the accuracy of the weights-direct-determination (WDD) method. In this way, the FUZWASD algorithm detects the optimal weights and structure of the MI-FUZWASDN using a power softplus activation function and while handling the model fitting and validation. Applications on two diagnostic breast cancer datasets validate and demonstrate the MI-FUZWASDN model’s exceptional learning and predicting performance. In addition, for the intrigued user, we have created a MATLAB kit, which is freely accessible via GitHub, to promote and support the results of this work.},
  archive      = {J_NCA},
  author       = {Simos, Theodore E. and Katsikis, Vasilios N. and Mourtas, Spyridon D.},
  doi          = {10.1007/s00521-021-06572-9},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3019-3031},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fuzzy WASD neuronet with application in breast cancer prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An investigation on m-polar fuzzy tolerance graph and its
application. <em>NCA</em>, <em>34</em>(4), 3007–3017. (<a
href="https://doi.org/10.1007/s00521-021-06529-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tolerance graph is a well-defined topic for a crisp graph theory. But, tolerance in a fuzzy graph is defined recently and many properties have been investigated. But, in a fuzzy graph, only one tolerance is considered for every vertex. But, in an m-polar fuzzy graph (mPFG), each vertex and edge has a m number of membership values. So, defining tolerance for mPFG is not easy and needs some new ideas. By considering m tolerances for every component out of m components of membership values of a vertex or edge, we defined m-polar fuzzy tolerance graph (mPFTG). Here, m-polar fuzzy convex set (mPFCS) as well as strongly mPFCS are also studied. Some different types of mPFTGs like m-polar fuzzy min-tolerance graph, m-polar fuzzy max-tolerance graph, m-polar fuzzy sum-tolerance graph are also introduced. Some related terms like bounded mPFTG, m-polar fuzzy interval containment graph, m-polar fuzzy unit tolerance graph (mPF unit TG) are also defined. Here, m-polar fuzzy intersection graph along with tolerance core as well as tolerance support length are also discussed. Some interesting properties on m-polar fuzzy min-tolerance graph, m-polar fuzzy max-tolerance graph, m-polar fuzzy sum-tolerance graph are also investigated. Lastly, a real-life application based on an assigned work done by a private company has been discussed to show its practicability in mPFTG.},
  archive      = {J_NCA},
  author       = {Mahapatra, Tanmoy and Pal, Madhumangal},
  doi          = {10.1007/s00521-021-06529-y},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3007-3017},
  shortjournal = {Neural Comput. Appl.},
  title        = {An investigation on m-polar fuzzy tolerance graph and its application},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel ensemble learning approach for hourly global solar
radiation forecasting. <em>NCA</em>, <em>34</em>(4), 2983–3005. (<a
href="https://doi.org/10.1007/s00521-021-06421-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise solar radiation forecasting can provide great benefits and solutions for smart grid distribution and electricity management. However, its non-stationary behavior and randomness render its estimation very difficult. In this respect, a new hybrid learning approach is proposed for multi-hour global solar radiation forecasting, relying on Convolutional Neural Network (CNN), Nonparametric Gaussian Process Regression (GPR), Least Support Vector Machine (LS-SVM), and Extreme Learning Machine (ELM) as essence predictors. Then compressive sensing technique is applied to perform a hybridization scheme of the model’s output. Hourly global solar radiation data from two sites in Algeria with different climate conditions are used to evaluate the full potential of the integrated model, with stationarity checks with an advanced clear sky model (MecClear model). Different comparative simulations show the superiority of the proposed pipeline in forecasting hourly global solar radiation data for multi-hour ahead compared to the stand-alone model. Experimental results show that the proposed hybridization methodology can effectively improve the prediction accuracy and outperforms benchmarking models during all the forecasting horizons.},
  archive      = {J_NCA},
  author       = {Guermoui, Mawloud and Benkaciali, Said and Gairaa, Kacem and Bouchouicha, Kada and Boulmaiz, Tayeb and Boland, John W.},
  doi          = {10.1007/s00521-021-06421-9},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2983-3005},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel ensemble learning approach for hourly global solar radiation forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-level shared-weight encoding for abstractive sentence
summarization. <em>NCA</em>, <em>34</em>(4), 2965–2981. (<a
href="https://doi.org/10.1007/s00521-021-06566-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Features in a text are hierarchically structured and may not be optimally learned using one-step encoding. Scrutinizing the literature several times facilitates a better understanding of content and helps frame faithful context representations. The proposed model encapsulates the idea of re-examining a piece of text multiple times to grasp the underlying theme and aspects of English grammar before formulating a summary. We suggest a multi-level shared-weight encoder (MSE) that exclusively focuses on the sentence summarization task. MSE exercises a weight-sharing mechanism for proficiently regulating the multi-level encoding process. Weight-sharing helps recognize patterns left undiscovered by single level encoding strategy. We perform experiments with six encoding levels with weight sharing on the renowned short sentence summarization Gigaword and DUC2004 Task1 datasets. The experiments show that MSE generates a more readable(fluent) summary (Rouge-L score) as compared to multiple benchmark models while preserving similar levels of informativeness (Rouge-1 and Rouge-2 scores). Moreover, human evaluation of the generated abstracts also corroborates these assertions of enhanced readability.},
  archive      = {J_NCA},
  author       = {Lal, Daisy Monika and Singh, Krishna Pratap and Tiwary, Uma Shanker},
  doi          = {10.1007/s00521-021-06566-7},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2965-2981},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-level shared-weight encoding for abstractive sentence summarization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dual attention granularity network for vehicle
re-identification. <em>NCA</em>, <em>34</em>(4), 2953–2964. (<a
href="https://doi.org/10.1007/s00521-021-06559-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle re-identification (Re-ID) aims to search for a vehicle of interest in a large video corpus captured by different surveillance cameras. The identification process considers both coarse-grained similarity (e.g., vehicle Model/color) and fine-grained similarity (e.g., windshield stickers/decorations) among vehicles. Coarse-grained and fine-grained similarity comparisons usually attend to very different visual regions, which implies that two different attention modules are required to handle different granularity comparisons. In this paper, we propose a dual attention granularity network (DAG-Net) for Vehicle Re-ID. The DAG-Net consists of three main components: (1) A convolutional neural network with a dual-branch structure is proposed as the backbone feature extractor for coarse-grained recognition (i.e., vehicle Model) and fine-grained recognition (i.e., vehicle ID); (2) the self-attention model is added to each branch, which enables the DAG-Net to detect different regions of interest (ROIs) at both coarse-level and fine-level with the assistance of the part-positioning block; (3) finally, we obtain refined regional features of the ROIs from the sub-networks ROIs. As a result, the proposed DAG-Net is able to selectively attend to the most discriminative regions for coarse/fine-grained recognition. We evaluate our method on two Vehicle Re-ID datasets: VeRi-776 and VehicleID. Experiments show that the proposed method can bring substantial performance improvement and achieve state-of-the-art accuracy. In addition, we focus on the different effects of regional features and global features. We conduct experiments to verify it in the PKU dataset and discuss the effectiveness.},
  archive      = {J_NCA},
  author       = {Zhang, Jianhua and Chen, Jingbo and Cao, Jiewei and Liu, Ruyu and Bian, Linjie and Chen, Shengyong},
  doi          = {10.1007/s00521-021-06559-6},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2953-2964},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dual attention granularity network for vehicle re-identification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning approach to obtain collaborative filtering
neighborhoods. <em>NCA</em>, <em>34</em>(4), 2939–2951. (<a
href="https://doi.org/10.1007/s00521-021-06493-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of recommender systems based on collaborative filtering (CF), obtaining accurate neighborhoods of the items of the datasets is relevant. Beyond particular individual recommendations, knowing these neighbors is fundamental for adding differentiating factors to recommendations, such as explainability, detecting shilling attacks, visualizing item relations, clustering, and providing reliabilities. This paper proposes a deep learning architecture to efficiently and accurately obtain CF neighborhoods. The proposed design makes use of a classification neural network to encode the dataset patterns of the items, followed by a generative process that obtains the neighborhood of each item by means of an iterative gradient localization algorithm. Experiments have been conducted using five popular open datasets and five representative baselines. The results show that the proposed method improves the quality of the neighborhoods compared to the K-Nearest Neighbors (KNN) algorithm for the five selected similarity measure baselines. The efficiency of the proposed method is also shown by comparing its computational requirements with that of KNN.},
  archive      = {J_NCA},
  author       = {Bobadilla, Jesús and González-Prieto, Ángel and Ortega, Fernando and Lara-Cabrera, Raúl},
  doi          = {10.1007/s00521-021-06493-7},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2939-2951},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning approach to obtain collaborative filtering neighborhoods},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Macaque neuron instance segmentation only with point
annotations based on multiscale fully convolutional regression neural
network. <em>NCA</em>, <em>34</em>(4), 2925–2938. (<a
href="https://doi.org/10.1007/s00521-021-06574-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of biomedicine, instance segmentation / individualization is important in analyzing the number, the morphology and the distribution of neurons for the whole slide images. Traditionally, biologists apply the stereology technique to manually count the number of neurons in the regions of interest and estimate the number in anatomical regions or the entire brain. This is very tedious and time-consuming. In this paper, we propose a multiscale fully convolutional regression neural network combined with a competitive region growing technique to individualize size-varying and touching neurons in the major anatomical regions of the macaque brain. Given that neuron instance or contour annotations are infeasible to obtain in certain regions, such as the dentate gyrus where thousands of touching neurons are present, we ask an expert to perform point annotations in the center location of neurons (noted as neuron centroids) for training. Thanks to the multiscale resolution achieved by parallel multiple receptive fields and different network depths, our proposed network succeeds in detecting the centroids of size-varying and touching neurons. Competitive region growing is then applied on these centroids to achieve neuron instance segmentation. Experiments on the macaque brain data suggest that our proposed method outperform the state-of-the-art methods in terms of neuron instance segmentation performance. To our knowledge, this is the first deep learning research work to individualize size-varying and touching neurons only using point annotations in major anatomical regions of the macaque brain.},
  archive      = {J_NCA},
  author       = {You, Zhenzhen and Jiang, Ming and Shi, Zhenghao and Shi, Cheng and Du, Shuangli and Liang, Jimin and Hérard, Anne-Sophie and Jan, Caroline and Souedet, Nicolas and Delzescaux, Thierry},
  doi          = {10.1007/s00521-021-06574-7},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2925-2938},
  shortjournal = {Neural Comput. Appl.},
  title        = {Macaque neuron instance segmentation only with point annotations based on multiscale fully convolutional regression neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel global polynomial stability criteria of impulsive
complex-valued neural networks with multi-proportional delays.
<em>NCA</em>, <em>34</em>(4), 2913–2924. (<a
href="https://doi.org/10.1007/s00521-021-06555-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The impulsive complex-valued neural networks (CVNNs) with multi-proportional delays (MPDs) are considered. By setting up a suitable Lyapunov–Krasovskii functional (L-KF) and utilizing the matrix inequality skills, several delay-dependent criteria for examining the global polynomial stability (GPS) of the CVNNs are built via linear matrix inequalities (LMIs), which can be verified numerically using the valid YALMIP toolbox in MATLAB. An example with simulations is presented to highlight the potency and the efficiency of the raised criteria.},
  archive      = {J_NCA},
  author       = {Zhang, Yongkang and Zhou, Liqun},
  doi          = {10.1007/s00521-021-06555-w},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2913-2924},
  shortjournal = {Neural Comput. Appl.},
  title        = {Novel global polynomial stability criteria of impulsive complex-valued neural networks with multi-proportional delays},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved rao algorithm for frequency stability
enhancement of nonlinear power system interconnected by AC/DC links with
high renewables penetration. <em>NCA</em>, <em>34</em>(4), 2883–2911.
(<a href="https://doi.org/10.1007/s00521-021-06545-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an improved optimization algorithm is proposed to overcome the original Rao algorithm limitations (i.e., different characteristics in exploration and exploitation) and enhance the performance of the original Rao algorithm. In the improved algorithm, the self-adaptive multi-population and Levy flight methods are utilized in the original Rao algorithm. The improved algorithm is called I_Rao_3. The improved algorithm’s efficiency is confirmed by comparing it to the original Rao algorithm utilizing various standard benchmark test functions. Moreover, the proposed I_Rao_3 algorithm is utilized to improve the frequency response in a hybrid renewable power grid by fine-tuning the proportional-integral-derivative (PID) controller parameters. The targeted system used for this study is a hybrid power grid, which encompasses conventional generating stations (i.e., thermal power plants), renewable power stations (i.e., PV and wind power stations) for the analysis of the load frequency control (LFC) issue. Unlike other previously published works, this study considers the impact of DC links in parallel to AC links to interconnect the two-hybrid renewable power system area. In addition, the nonlinearities effects (i.e., generation rate constraint and a governor dead band) are applied to each area in order to achieve a more realistic study. The superiority of the proposed PID controller-based I_Rao_3 algorithm is endorsed by comparing its performance with many other optimization algorithms.},
  archive      = {J_NCA},
  author       = {Khamies, Mohamed and Magdy, Gaber and Selim, Ali and Kamel, Salah},
  doi          = {10.1007/s00521-021-06545-y},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2883-2911},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved rao algorithm for frequency stability enhancement of nonlinear power system interconnected by AC/DC links with high renewables penetration},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization of vector convolutional deep neural network
using binary real cumulative incarnation for detection of distributed
denial of service attacks. <em>NCA</em>, <em>34</em>(4), 2869–2882. (<a
href="https://doi.org/10.1007/s00521-021-06565-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s technological world, distributed denial of service (DDoS) attacks threaten Internet users by flooding huge network traffic to make critical Internet services unavailable to genuine users. Therefore, design of DDoS attack detection system is on urge to mitigate these attacks for protecting the critical services. Nowadays, deep learning techniques are extensively used to detect these attacks. The existing deep feature learning approaches face the lacuna of designing an appropriate deep neural network structure for detection of DDoS attacks which leads to poor performance in terms of accuracy and false alarm. In this article, a tuned vector convolutional deep neural network (TVCDNN) is proposed by optimizing the structure and parameters of the deep neural network using binary and real cumulative incarnation (CuI), respectively. The CuI is a genetic-based optimization technique which optimizes the tuning process by providing values generated from best-fit parents. The TVCDNN is tested with publicly available benchmark network traffic datasets and compared with existing classifiers and optimization techniques. It is evident that the proposed optimization approach yields promising results compared to the existing optimization techniques. Further, the proposed approach achieves significant improvement in performance over the state-of-the-art attack detection systems.},
  archive      = {J_NCA},
  author       = {Amma, N. G. Bhuvaneswari and Selvakumar, S.},
  doi          = {10.1007/s00521-021-06565-8},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2869-2882},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimization of vector convolutional deep neural network using binary real cumulative incarnation for detection of distributed denial of service attacks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A human-centred deep learning approach facilitating design
pedagogues to frame creative questions. <em>NCA</em>, <em>34</em>(4),
2841–2868. (<a
href="https://doi.org/10.1007/s00521-021-06511-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creative questions are a major component of examination in design education for testing creative aptitude. During this process of framing creative questions, examiners remain ever-inquisitive to know whether questions framed by them really capture features of creative questions. Our objective is to explore whether technology can support examiners in situations like these. This paper investigates features of creative questions through mixed-method research techniques. A model is proposed based on DL algorithms that can find out inherent creativity factors in questions and identify whether a question is creative. This process of identifying creative questions triggers decision-making of examiners by which they update their questions based on the outcome of the DL-based system. This model is implemented using bidirectional encoder representations using transformers (BERT), and long short-term memory (LSTM) method for identifying creativity in questions, and their performance is compared. Results highlight that BERT overrules LSTM mechanism, showing 99.99\% and 81.006\% accuracy, respectively. Inter-rater reliability between the model and examiner’s opinion shows higher agreement (α = 0.96) in categorizing creative questions, and comparison among baselines builds trust in the model. A significant contribution of this research is to capture creative features in a question and categorize whether a question is creative in design education. This model highlights human–machine collaboration and promotes examiners&#39; decision-making process to frame effective questions. It attempts to reduce uncertainty of examiners and assists in quick decisions to include creativity features in their questions by providing feedback on whether a question is creative.},
  archive      = {J_NCA},
  author       = {Chaudhuri, Nandita Bhanja and Dhar, Debayan and Yammiyavar, Pradeep G.},
  doi          = {10.1007/s00521-021-06511-8},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2841-2868},
  shortjournal = {Neural Comput. Appl.},
  title        = {A human-centred deep learning approach facilitating design pedagogues to frame creative questions},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Firefighting robot with deep learning and machine vision.
<em>NCA</em>, <em>34</em>(4), 2831–2839. (<a
href="https://doi.org/10.1007/s00521-021-06537-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While extinguishing the fire, firefighters find it difficult to reach certain areas due to narrow spaces or debris blocking the way. In urban cities and industrial areas, there is a constant need to have firefighters ready in case of emergencies. This can lead to a shortage of manpower. Thus, the firefighting robot can act as assisting support for firefighters and will also lower down the risk of their life. Even though many firefighter robots have been developed currently to overcome this problem, these robots are expensive and difficult to maintain. We propose an intelligent robot that uses deep learning to not only detect and classify fire but also extinguish the detected fire based on its class. The proposed firefighter robot is cheaper, autonomous, and easier to maintain. We have used a combination of AlexNet to detect fire and ImageNet for detecting the type of fire. We achieved a classification accuracy of fire detection up to 98.25\%, and the classification accuracy of fire-type classification was around 92\%. The firefighter robot can be deployed in places that are hard to reach for the firefighters and thereby reduce the burden on firefighters.},
  archive      = {J_NCA},
  author       = {Dhiman, Amit and Shah, Neel and Adhikari, Pranali and Kumbhar, Sayali and Dhanjal, Inderjit Singh and Mehendale, Ninad},
  doi          = {10.1007/s00521-021-06537-y},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2831-2839},
  shortjournal = {Neural Comput. Appl.},
  title        = {Firefighting robot with deep learning and machine vision},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Triple-layer attention mechanism-based network embedding
approach for anchor link identification across social networks.
<em>NCA</em>, <em>34</em>(4), 2811–2829. (<a
href="https://doi.org/10.1007/s00521-021-06556-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anchor link identification is a task that determines which pair of accounts in different social networks belongs to the same user. As a foundation of many applications, such as information dissemination across networks, anchor link identification has attracted much attention in recent years. Several methods learned a latent common space to preserve the structural proximity of accounts, such that the contributions of diverse neighbors are ignored due to the unweighted edges. In sparse networks, the overlapping of neighbors is rare and structural similarities are small, resulting in performance degradation of these methods. In this paper, we propose a triple-layer attention mechanism-based network embedding (TANE) method which utilizes the network structure to identify anchor links. TANE has two learning modules: the attention learning module which learns contribution weights of intranetwork and internetwork neighbors in anchor link identification under the supervision of observed anchor links, and the embedding learning module which tries to learn a latent common space by preserving weighted structural proximity of neighbors and second-order neighbors (i.e., neighbors of neighbors). By exploiting second-order neighbors, more structural information is introduced into embedding processing, which reduces sparsity. The weights and embeddings are transferred between modules and learned uniformly by Adam algorithm. Extensive experimental results of two real-world datasets show that TANE can improve the top-k hit ratio of anchor link identification compared with several state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Li, Yao and Cui, Huiyuan and Liu, Huilin and Li, Xiaoou},
  doi          = {10.1007/s00521-021-06556-9},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2811-2829},
  shortjournal = {Neural Comput. Appl.},
  title        = {Triple-layer attention mechanism-based network embedding approach for anchor link identification across social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DF classification algorithm for constructing a small sample
size of data-oriented DF regression model. <em>NCA</em>, <em>34</em>(4),
2785–2810. (<a
href="https://doi.org/10.1007/s00521-021-06809-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deep forest (DF) model is built using a multilayer ensemble of forest units through decision tree aggregation. DF presents characteristics of an easy-to-understand structure, is suitable for small sample data, and has become an important research direction in the field of deep learning. These attributes are particularly suitable for the modeling of difficult-to-measure parameters in actual industrial process. However, existing methods have mainly focused on the problem of DF classification (DFC) and cannot be directly applied to regression modeling. To overcome these issues, a survey on the DFC algorithm is presented in terms of constructing a small sample data-oriented DF regression (DFR) model for industrial processes. Hence, a survey on the DFC algorithm is presented to construct a small sample size of the data-oriented DF regression (DFR) model for industrial processes. First, principle and properties of DFC are introduced in detail to demonstrate the non-neural network deep learning model. Second, methods of DFC are discussed in terms of feature engineering, representation learning, learner selection, weighting strategy, and hierarchical structure. Furthermore, related studies on decision tree algorithm are reviewed and future investigations on DFR and its relationship with deep learning are discussed and analyzed in detail. Finally, conclusions and the future direction of this study for industrial process modeling are presented. Developing a DFR algorithm with characteristics of dynamic adaptive and interpretation abilities and lightweight structure on the basis of actual industrial domain knowledge will be the focus of our follow-up investigation. Moreover, the existing research results of DFC and deep learning can provide guidance for the future investigations on the DFR model.},
  archive      = {J_NCA},
  author       = {Xia, Heng and Tang, Jian and Qiao, Junfei and Zhang, Jian and Yu, Wen},
  doi          = {10.1007/s00521-021-06809-7},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2785-2810},
  shortjournal = {Neural Comput. Appl.},
  title        = {DF classification algorithm for constructing a small sample size of data-oriented DF regression model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent progress in leveraging deep learning methods for
question answering. <em>NCA</em>, <em>34</em>(4), 2765–2783. (<a
href="https://doi.org/10.1007/s00521-021-06748-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question answering, serving as one of important tasks in natural language processing, enables machines to understand questions in natural language and answer the questions concisely. From web search to expert systems, question answering systems are widely applied to various domains in assisting information seeking. Deep learning methods have boosted various tasks of question answering and have demonstrated dramatic effects in performance improvement for essential steps of question answering. Thus, leveraging deep learning methods for question answering has drawn much attention from both academia and industry in recent years. This paper provides a systematic review of the recent development of deep learning methods for question answering. The survey covers the scope including methods, datasets, and applications. The methods are discussed in terms of network structure characteristics, methodology innovations, and their effectiveness. The survey is expected to be a contribution to the summarization of recent research progress and future directions of deep learning methods for question answering.},
  archive      = {J_NCA},
  author       = {Hao, Tianyong and Li, Xinxin and He, Yulan and Wang, Fu Lee and Qu, Yingying},
  doi          = {10.1007/s00521-021-06748-3},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2765-2783},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recent progress in leveraging deep learning methods for question answering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Material analysis and big data monitoring of sports training
equipment based on machine learning algorithm. <em>NCA</em>,
<em>34</em>(4), 2749–2763. (<a
href="https://doi.org/10.1007/s00521-021-05852-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different machine learning algorithms predict the application effect of perovskite materials in sports training equipment. The sensitivity to material data is different on different ranges of data sets. Therefore, the algorithm needs to be selected according to specific material data samples. This study compares the prediction performance of neural network prediction algorithm (NN), genetic algorithm, and support vector machine-based machine learning algorithm (SVM) and uses statistical analysis to perform data analysis and draw corresponding curves. Moreover, this study uses a single perovskite material to verify the algorithm performance. In addition, based on the real data, the three machine learning algorithms of this study are applied to the related performance prediction, and the comparative analysis method is used to analyze the prediction performance of the machine learning algorithm. Through data analysis and chart analysis, we can see that machine learning algorithms have a certain effect in the application prediction of perovskite materials in sports training equipment. Among the three machine learning algorithms selected in this study, the performance of the machine learning algorithm based on support vector machine in all aspects is more excellent.},
  archive      = {J_NCA},
  author       = {Zhang, Lei and Li, Ning},
  doi          = {10.1007/s00521-021-05852-8},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2749-2763},
  shortjournal = {Neural Comput. Appl.},
  title        = {Material analysis and big data monitoring of sports training equipment based on machine learning algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Traditional chinese medicine entity relation extraction
based on CNN with segment attention. <em>NCA</em>, <em>34</em>(4),
2739–2748. (<a
href="https://doi.org/10.1007/s00521-021-05897-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting medical entity relations from Traditional Chinese Medicine (TCM) related article is crucial to connect domain knowledge between TCM with modern medicine. Herb accounts for the majority of Traditional Chinese Medicine, so our work mainly focuses on herb. The problem would be effectively solved by extracting herb-related entity relations from PubMed literature. In order to realize the entity relation mining, we propose a novel deep-learning model with improved layers without manual feature engineering. We design a new segment attention mechanism based on Convolutional Neural Network, which enables extracting local semantic features through word embedding. Then we classify the relations by connecting different embedding features. We first test this method on the Chemical-Induced Disease task and the experiment show better result comparing to other state-of-the-art deep learning methods. Further, we apply this method to a herbal-related data set (Herbal-Disease and Herbal Chemistry, HD-HC) constructed from PubMed to explore entity relation classification. The experiment shows superior results than other baseline methods.},
  archive      = {J_NCA},
  author       = {Bai, Tian and Guan, Haotian and Wang, Shang and Wang, Ye and Huang, Lan},
  doi          = {10.1007/s00521-021-05897-9},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2739-2748},
  shortjournal = {Neural Comput. Appl.},
  title        = {Traditional chinese medicine entity relation extraction based on CNN with segment attention},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weighted naïve bayes text classification algorithm based on
improved distance correlation coefficient. <em>NCA</em>, <em>34</em>(4),
2729–2738. (<a
href="https://doi.org/10.1007/s00521-021-05989-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an innovative method to improve the attribute weighting approaches for naïve Bayes text classifiers using the improved distance correlation coefficient. The resulted model is called improved distance correlation coefficient attribute weighted multinomial naïve Bayes, denoted by IDCWMNB. Unlike the traditional correlation statistical measurements that consider the cumulative distribution function of random vectors, the improved distance correlation coefficient tests the joint correlation of random vectors by describing the distance between the joint characteristic function and the product of the marginal characteristic functions. Specifically, a measurement of inverse document frequency that considers the distribution information of document concentrating and scattering has been proposed. Then, the measurement and the distance correlation coefficient between attributes and categories have been combined to measure the importance of attributes to categories, to allocate different weights to different terms. Meanwhile, the learned attribute weights are incorporated into the posterior probability estimates of the multinomial naïve Bayes model, which is known as deep attribute weighting. This measurement is more effective than the traditional statistical measurements in the presence of nonlinear relationship between two random vectors. Experimental results taking benchmark and real-world data indicate that the new attribute weighting method can achieve an effective balance between classification accuracy and execution time.},
  archive      = {J_NCA},
  author       = {Ruan, Shufen and Chen, Baozhou and Song, Kunfang and Li, Hongwei},
  doi          = {10.1007/s00521-021-05989-6},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2729-2738},
  shortjournal = {Neural Comput. Appl.},
  title        = {Weighted naïve bayes text classification algorithm based on improved distance correlation coefficient},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Innovative research on the visual performance of image
two-dimensional animation film based on deep neural network.
<em>NCA</em>, <em>34</em>(4), 2719–2728. (<a
href="https://doi.org/10.1007/s00521-021-06140-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural network (DNN) has gone through more than forty years from the simulation stage to the embryonic stage, to the conception and the initial formation of the theory, until further simple applications. Firstly, deep convolution neural network is used to extract features, and then the extracted features are coded by Gaussian aggregation. Finally, the encoded features are input into the full connection layer to classify the image. The experiment in this paper focuses on the two-dimensional facial expression animation technology under DNN. This experiment mainly introduces the two important steps of image conversion, spatial mapping and resampling technology, as well as the detailed definition of the MPEG-4 standard. By using the feature points obtained in the experiment as the feature points set in the face definition parameters, in the deformation algorithm based on Delaunay triangulation, the inverse mapping technology and the quadratic linear interpolation technology are combined with the face and combined with facial animation. The parameter step can realize the conversion of facial expressions, and the generated facial expressions are more natural and delicate.The experimental data show that the facial animation parameters (FAP) as a complete set of basic facial movements can recognize the most subtle facial expressions under DNN. Change, different FAP combinations can form different facial expressions. The experimental results show that the 76 facial feature points located in the experiment have been tested for grid generation. When the segmentation threshold is larger, the merge method is closer to the sub-point insertion method; otherwise, it is closer to the divide and conquer method. When the threshold is 20, the algorithm belongs to the divide and conquer method; when the threshold is 80, the algorithm belongs to the point insertion method. Through research, this article finds that the innovation of DNN on the visual performance of animated films can provide more help for the production of sophisticated animation works, and can continuously improve the visual performance and cultural connotation of animated films.},
  archive      = {J_NCA},
  author       = {Xu, Ping and Zhu, Yufang and Cai, Shaoshuo},
  doi          = {10.1007/s00521-021-06140-1},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2719-2728},
  shortjournal = {Neural Comput. Appl.},
  title        = {Innovative research on the visual performance of image two-dimensional animation film based on deep neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design and implementation of video processing controller for
pipeline robot based on embedded machine vision. <em>NCA</em>,
<em>34</em>(4), 2707–2718. (<a
href="https://doi.org/10.1007/s00521-021-06022-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of pipeline transportation, there are more and more hidden safety risks behind the rapid development of pipeline transportation. However, the current pipeline inspection methods are incomplete, and the inspection technology fails to meet the requirements. This has led to pipelines with potential safety hazards being missed during the inspection process. In order to perform effective video detection on the pipeline, this paper is based on the pipeline robot on the embedded platform to complete the control operation of the embedded machine vision system on the video processing in the pipeline. The experiments show that the system has better recognition and positioning effect, less error, and the system occupancy and real-time performance can meet the design requirements. This paper proposes an improved LwIP-based congestion prevention method for video processing in embedded machine vision systems. When the RTT value is higher than the RTO value, it will cause false retransmission of data, which will affect the data transmission efficiency. The experimental results show that the improved congestion control method can more effectively deal with the problem of packet loss, effectively reduce the false retransmission of data, and improve the data throughput. Through comparison, it is found that under the same object change interference, the video processing controller based on embedded machine vision can more effectively suppress the video control error in the pipeline than the traditional video processing controller, and it will not affect the stability of the system.},
  archive      = {J_NCA},
  author       = {Song, Zenglu and Yao, Jin and Hao, Huadong},
  doi          = {10.1007/s00521-021-06022-6},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2707-2718},
  shortjournal = {Neural Comput. Appl.},
  title        = {Design and implementation of video processing controller for pipeline robot based on embedded machine vision},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recognition and extraction of high-resolution satellite
remote sensing image buildings based on deep learning. <em>NCA</em>,
<em>34</em>(4), 2691–2706. (<a
href="https://doi.org/10.1007/s00521-021-06027-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting and recognizing buildings from high-resolution remote sensing images faces many problems due to the complexity of the buildings on the surface. The purpose is to improve the recognition and extraction capabilities of remote sensing satellite images. The Gao Fen-2 (GF-2) high-resolution remote sensing satellite is taken as the research object. The deep convolutional neural network (CNN) serves as the core of image feature extraction, and PCA (principal component analysis) is adopted to reduce the dimensionality of the data. A correction neural network model, that is, boundary regulated network (BR-Net) is proposed. The features of remote sensing images are extracted through convolution, pooling, and classification. Different data collection models are utilized for comparative analysis to verify the performance of the proposed model. Results demonstrate that when using CNN to recognize remote sensing images, the recognition accuracy is much higher than that of traditional image recognition models, which can reach 95.3\%. Compared with the newly researched models, the performance is improved by 15\%, and the recognition speed is increased by 20\%. When extracting buildings with higher accuracy, the proposed model can also ensure clear boundaries, thereby obtaining a complete building image. Therefore, using deep learning technology to identify and extract buildings from high-resolution satellite remote sensing images is of great significance for advancing the deep learning applications in image recognition.},
  archive      = {J_NCA},
  author       = {Zeng, Yifu and Guo, Yi and Li, Jiayi},
  doi          = {10.1007/s00521-021-06027-1},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2691-2706},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recognition and extraction of high-resolution satellite remote sensing image buildings based on deep learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint access point fuzzy rough set reduction and multisource
information fusion for indoor wi-fi positioning. <em>NCA</em>,
<em>34</em>(4), 2677–2689. (<a
href="https://doi.org/10.1007/s00521-021-05934-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing maturity and popularity of wireless network techniques, indoor Wi-Fi positioning will inevitably become a significant application in indoor location-based services. In this circumstance, there is normally no control over the number of access points (APs) and the diversity of the Wi-Fi signal distribution, which may significantly deteriorate the positioning effectiveness as well as the system efficiency. To address this issue, we first adopt the fuzzy information entropy-based fuzzy rough set to conduct redundant APs reduction. Second, we calculate the Wasserstein distance between the signal distribution at the target position and the one at each Reference Point (RP) by the Wasserstein distance method. Third, the multisource information fusion method based on the Dempster–Shafer evidence theory is exerted to construct the matching RPs set. Finally, the abundant experiments and results in a realistic indoor Wi-Fi environment testify that the proposed method is able to preserve satisfactory localization performance as well as reduce the computation overhead of localization.},
  archive      = {J_NCA},
  author       = {Nie, Wei and Liu, Zhu and Zhou, Mu and Yang, Xiaolong and He, Wei},
  doi          = {10.1007/s00521-021-05934-7},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2677-2689},
  shortjournal = {Neural Comput. Appl.},
  title        = {Joint access point fuzzy rough set reduction and multisource information fusion for indoor wi-fi positioning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction model of the impact of innovation and
entrepreneurship on china’s digital economy based on neural network
integration systems. <em>NCA</em>, <em>34</em>(4), 2661–2675. (<a
href="https://doi.org/10.1007/s00521-021-05899-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Innovation and entrepreneurship as the core development mode is the only way to continue my country&#39;s economic development. Therefore, research on the synergistic impact of innovation on China&#39;s economic development is of great significance. With the continuous development of sharing economy, Internet finance, and other fields, the digital economy is reshaping the entire social ecology and becoming an important part of the national economy. Aiming at China’s digital economy, this article takes the Shanghai Composite Index and three listed stocks in the stock market as examples, collects the closing data of the Shanghai Composite Index and the stock market prices of three listed companies as sample data, uses the BP neural network prediction model and the optimized particle swarm optimization-neural networks (PSO-BP) neural network model predicts the future trends of the Shanghai Composite Index and the three stocks, respectively. Compared with other models, PSO-BP requires fewer parameters and draws more accurate conclusions. It is a model that is very suitable for digital economic forecasting. The experimental results show that the prediction effect of the PSO-BP neural network is higher than that of the BP neural network prediction model obtained by the two prediction models in the prediction process of the Shanghai Composite Index; the error rate of the BP neural network prediction model in the three listed stocks 6.37\%, 3.01\%, 9.85\%; PSO-BP neural network prediction model predicts the future trend of the three listed stocks with error rates of 3.21\%, 0.37\%, and 0.89\%. After comparing and analyzing the results of the forecast error value, it is concluded that the PSO-BP neural network forecast model has a more accurate forecast of stock prices and smaller errors, and the forecast of future trends is also consistent with actual trends.},
  archive      = {J_NCA},
  author       = {Jiang, Yanfeng},
  doi          = {10.1007/s00521-021-05899-7},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2661-2675},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction model of the impact of innovation and entrepreneurship on china&#39;s digital economy based on neural network integration systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of rockburst hazard based on particle swarm
algorithm and neural network. <em>NCA</em>, <em>34</em>(4), 2649–2659.
(<a href="https://doi.org/10.1007/s00521-021-06057-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rockburst is a typical dynamic phenomenon of mine destruction. With the expansion of mining scale and mining depth, its harm is becoming more and more serious. This has become an important problem to be solved urgently in the mining industry. This paper aims to study the prediction and prediction of rockburst risk based on particle swarm algorithm and neural network. This paper proposes a shock risk assessment method based on BP neural network. It uses existing shock pressure data to establish a regression model through BP network, and uses PSO algorithm to optimize connection weights to evaluate the slow convergence of BP network and easy to fall into local optimality. The shortcomings of and the degree of convergence was evaluated. In addition, this paper proposes a rockburst risk prediction method. In order to improve the accuracy of rockburst prediction, regional prevention and control measures and certain risk mitigation methods can also be quickly adopted. It not only identifies the mechanical properties of coal and rock mass in the laboratory, but also judges the possibility of rockbursts during mining. The experimental results in this paper show that 10 main factors that affect rockbursts are selected, 20 standard mechanical data sets are used, and a PSO-BP-based mine explosion risk assessment model is established, and the model is compared with the standard BP model Make a comparison. The results show that compared with the standard BP model, the evaluation accuracy of the PSO-BP model is increased by 15\%. Finally, an example of mine risk assessment verifies the accuracy and overall applicability of the method.},
  archive      = {J_NCA},
  author       = {Zhang, Meichang},
  doi          = {10.1007/s00521-021-06057-9},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2649-2659},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of rockburst hazard based on particle swarm algorithm and neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of processing technology based on skyline query
in computer network. <em>NCA</em>, <em>34</em>(4), 2637–2647. (<a
href="https://doi.org/10.1007/s00521-021-05931-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of network data communication technology, the complexity of the network environment makes the data in the data stream have uncertain characteristics, and a large number of data streams are generated in many fields. Therefore, it is necessary to find an efficient and accurate processing method to process a large amount of data in a computer network. This paper takes the skyline probability calculation and the actual efficiency of the unknown object index structure in the skyline query processing technology on the uncertain data stream as the research object. Based on the skyline query technology, we study an efficient skyline query processing method on the unknown network traffic based on the model SUMG. The method includes two algorithms: dynamic modeling algorithm DMG and skyline query algorithm GST. The DMG algorithm samples the data in the sliding window of the uncertain data stream and establishes a model to convert the data stream into the parameter stream in the uncertain object probability density function, the GST algorithm establishes the R-tree index structure, which is in order to reduce the amount of calculation, it uses the parameter flow of the model. In both methods, the set of local skyline results is first obtained at the distributed node, and the skyline query is performed again on the union of the local skyline results to obtain the global skyline result set. The experimental results show that compared with the skyline query method BNL for unknown network traffic without an index structure, the SUMG method can not only effectively model the link-type unknown object to assist the skyline query, but also effectively prune the uncertain data object and improve the skyline. The distributed skyline query method can cope with the skyline query task on the distributed data stream.},
  archive      = {J_NCA},
  author       = {Zeng, Yifu and Yang, Zhibang and Zhang, Wei and Li, Chuang},
  doi          = {10.1007/s00521-021-05931-w},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2637-2647},
  shortjournal = {Neural Comput. Appl.},
  title        = {Application of processing technology based on skyline query in computer network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on computer vision enhancement in intelligent robot
based on machine learning and deep learning. <em>NCA</em>,
<em>34</em>(4), 2623–2635. (<a
href="https://doi.org/10.1007/s00521-021-05898-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stable operation of intelligent robots requires the effective support of machine vision technology. In order to improve the effect of robot machine vision recognition, based on deep learning, this paper, under the guidance of machine learning ideas, proposes a target detection framework that combines target recognition and target tracking based on the efficiency advantages of the KCF visual tracking algorithm. Moreover, this paper designs a vision system based on a high-resolution color camera and TOF depth camera. In addition, by modeling the coordinate conversion relationship of the same object in the camera coordinate system of two cameras, the projection relationship of the depth map collected by the TOF camera to the pixel coordinate system of the high-resolution color camera is determined. In addition, this paper designs experiments to verify the performance of the model. The research results show that the method proposed in this paper has a certain effect.},
  archive      = {J_NCA},
  author       = {Ding, Yuhan and Hua, Lisha and Li, Shunlei},
  doi          = {10.1007/s00521-021-05898-8},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2623-2635},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on computer vision enhancement in intelligent robot based on machine learning and deep learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on nonlinear forecast and influencing factors of
foreign trade export based on support vector neural network.
<em>NCA</em>, <em>34</em>(4), 2611–2622. (<a
href="https://doi.org/10.1007/s00521-021-05900-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a kind of time series, the export volume of foreign trade has the characteristics of randomness, complexity, strong nonlinearity and noise, so it is difficult to describe it by using the traditional time series model algorithm. Support vector neural network (SVNN) has many unique advantages in solving small sample, nonlinear and high-dimensional pattern recognition problems. This paper uses the method of support vector neural network to predict and analyze China&#39;s foreign trade export and uses principal component analysis and regression analysis to analyze the contribution rate of different influencing factors to foreign trade export. The results show that:(1) the contribution rate of domestic economic factors to China&#39;s foreign trade export is the largest, reaching 59.65\%, which also reflects the necessity and correctness of China&#39;s insistence on supply-side reform. (2) The nonlinear prediction results of the support vector neural network have a good fitting with the actual value of China&#39;s foreign trade export, and the prediction error of the support vector neural network is controlled within 10\%, showing a good prediction effect; (3) neural network method has good modeling and generalization ability for nonstationary small sample import and export time series data and can achieve high prediction accuracy and decision judgment accuracy, especially for the prediction of its development trend, and the model has a high degree of fitting.},
  archive      = {J_NCA},
  author       = {Han, Zhao’an and Zhu, Zijiang and Zhao, Shajunyi and Dai, Weihuang},
  doi          = {10.1007/s00521-021-05900-3},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2611-2622},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on nonlinear forecast and influencing factors of foreign trade export based on support vector neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using machine learning method on calculation of boundary
layer height. <em>NCA</em>, <em>34</em>(4), 2597–2609. (<a
href="https://doi.org/10.1007/s00521-021-05865-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional observation methods of the boundary layer are susceptible to external factors. In particular, detection data are relatively scarce in special areas such as plateaus and oceans. However, occultation observation data have the unique advantage of global coverage, and the boundary layer information of the occultation profile is rich. Based on the machine learning algorithm, this paper combines GPS occultation technology to improve the algorithm and constructs the boundary layer height simulation model based on the actual situation and analyzes its functional structure one by one. Moreover, in order to verify the validity of the simulation model, a simulation analysis is performed in combination with actual data. In addition, the performance of the model is verified from multiple aspects, and the results of the research are calculated by mathematical statistics, and the corresponding statistical diagram is drawn. Through experimental analysis, it can be known that the model constructed in this paper can effectively simulate the boundary height and has certain practical effects.},
  archive      = {J_NCA},
  author       = {Jiang, Rongsheng and Zhao, Kaihui},
  doi          = {10.1007/s00521-021-05865-3},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2597-2609},
  shortjournal = {Neural Comput. Appl.},
  title        = {Using machine learning method on calculation of boundary layer height},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring online intelligent teaching method with machine
learning and SVM algorithm. <em>NCA</em>, <em>34</em>(4), 2583–2596. (<a
href="https://doi.org/10.1007/s00521-021-05846-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the effect of modern music teaching, this paper builds an intelligent music teaching system based on machine learning and SVM algorithm, innovates the music teaching process, and gradually expands from the simplest three-layer structure BPNN to a multi-layer structure. Moreover, this paper proposes a method of dividing the error by the proportion of each link&#39;s contribution to the error, and the idea that the error of the hidden layer node is the sum of the errors on each link during the forward propagation process. In addition, this paper combines the actual needs of music teaching to construct an intelligent music teaching system. Finally, this paper conducts training tests on music teaching data and sets up the experimental group and the control group to evaluate the system teaching effect based on actual needs. The research results show that the performance of the intelligent music teaching system constructed in this paper is good.},
  archive      = {J_NCA},
  author       = {Shuo, Wang and Ming, Mu},
  doi          = {10.1007/s00521-021-05846-6},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2583-2596},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring online intelligent teaching method with machine learning and SVM algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on enterprise risk knowledge graph based on
multi-source data fusion. <em>NCA</em>, <em>34</em>(4), 2569–2582. (<a
href="https://doi.org/10.1007/s00521-021-05985-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction of risk knowledge graphs aims at the effective organization and utilization of enterprise knowledge resources in big data environments. To address the problem of static mapping in existing enterprise knowledge graphs, this paper introduces the time dimension to describe the evolutionary characteristics of enterprise risk events, such as dynamics, suddenness and timeliness. Through information extraction, knowledge fusion, ontology construction and dynamic knowledge reasoning about risk knowledge, a bottom-up enterprise dynamic risk knowledge graph is systematically constructed. In the knowledge fusion link, aiming at the imbalanced classification problem for the entity samples of a data set, this paper proposes the ResNet dynamic knowledge reasoning method to improve the loss balance function of the Multi-Net model. The experiments show that the new model can effectively improve the accuracy of entity and relationship prediction. Finally, the knowledge graph is applied to an intelligent question-answering system.},
  archive      = {J_NCA},
  author       = {Yang, Bo and Liao, Yi-ming},
  doi          = {10.1007/s00521-021-05985-w},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2569-2582},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on enterprise risk knowledge graph based on multi-source data fusion},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An approach for discovery and scheduling replaceable service
on edge environment. <em>NCA</em>, <em>34</em>(4), 2555–2568. (<a
href="https://doi.org/10.1007/s00521-021-05862-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an edge computing environment, in order to provide highly accessible services and computing resources to nearby users, edge servers are usually deployed on base stations and other types of equipment. However, due to the limited storage space of edge servers, it is very difficult to manage services with a failure. Therefore, the rapid restoration of services in the edge computing environment will become an important means to ensure the resilience of the system. Among them, service replacement with similarities within the edge server is one of the effective technologies to ensure system resilience. In this paper, we regard the discovery and scheduling problem of replaceable services replacement as the discovery and scheduling component, and develop an approach based on replaceable service form the app vendor’s perspective for solving the none replaceable services environment. We have evaluated our approach in a real experimental environment. The results show that in the case of large mirroring, the DAS approach can effectively reduce the recovery time required by the system due to failure.},
  archive      = {J_NCA},
  author       = {Wu, Zihao and Yan, Zeming and Huang, Dongyi and Kuang, Jiayi},
  doi          = {10.1007/s00521-021-05862-6},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2555-2568},
  shortjournal = {Neural Comput. Appl.},
  title        = {An approach for discovery and scheduling replaceable service on edge environment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on the effectiveness of english online learning
based on neural network. <em>NCA</em>, <em>34</em>(4), 2543–2554. (<a
href="https://doi.org/10.1007/s00521-021-05855-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to overcome the shortcomings of the current English network learning system, based on the neural network algorithm, this paper constructs an intelligent English network learning system based on the improved algorithm. Moreover, by analyzing the coupling between recurrent neural networks by contrast methods, this paper infers the coupling between recurrent neural networks. Moreover, this paper studies the continuous attractors of the autoencoder neural network and studies the continuous attractors of different types of autoencoder models. On this basis, this paper expands the existing model, adds the module of the interaction between the external input and the visible layer and studies the conditions required for the continuous attractor of the autoencoder model. In addition, on the basis of actual needs, this paper constructs the basic structure of the model and integrates it into the improved algorithm proposed in this paper to realize English online intelligent learning. Finally, this paper designs experiments to analyze the practical effects of this model and analyzes the experimental results through mathematical statistics. The research results show that the English network learning system constructed in this paper is effective.},
  archive      = {J_NCA},
  author       = {Peng, Nianfan},
  doi          = {10.1007/s00521-021-05855-5},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2543-2554},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on the effectiveness of english online learning based on neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization analysis of football match prediction model
based on neural network. <em>NCA</em>, <em>34</em>(4), 2525–2541. (<a
href="https://doi.org/10.1007/s00521-021-05930-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to build a football match prediction model and use scientific methods to solve the prediction problem has become a key point in the application of artificial intelligence in the sports industry. In this paper, we choose a BP neural network model that is powerful in processing nonlinear data to perform research. According to the demand, this paper constructs a gray fuzzy prediction model based on neural network, a gray extreme learning machine prediction model, and a gray fuzzy extreme learning machine prediction combination model based on neural network. Moreover, this paper tests the neural network model by comparing actual results with predicted results. In addition, by predicting and analyzing the football league data, this article tests the three models in terms of match result prediction accuracy, data processing speed, data transmission accuracy, match analysis scores, etc., and uses statistical analysis methods to process data, and uses intuitive statistical graphs to obtain the processing results. The research results show that the gray fuzzy extreme learning machine prediction combination model based on neural network constructed in this paper can retain the advantages of a single model and effectively improve the prediction accuracy of the model and the performance of the system.},
  archive      = {J_NCA},
  author       = {Guan, Shuo and Wang, Xiaochen},
  doi          = {10.1007/s00521-021-05930-x},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2525-2541},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimization analysis of football match prediction model based on neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Loss prediction of mountain flood disaster in villages and
towns based on rough set RBF neural network. <em>NCA</em>,
<em>34</em>(4), 2513–2524. (<a
href="https://doi.org/10.1007/s00521-021-05902-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flood disasters cause serious economic losses to our country every year, which affects the rapid development and construction of our country’s economy to a certain extent. Our country’s mountain floods mostly occur in mountainous hills and other rural areas with relatively backward economic development. Disaster relief and reconstruction ability in these places are relatively weak. To provide an important basis for making decisions on flood prevention and mitigation, we must first be able to scientifically, accurately and efficiently assess the losses caused by flood disasters. Aiming at the problems of low assessment accuracy, heavy workload and cumbersome operation in the disaster assessment work of Dangtian in the disaster-affected area, this paper starts from the analysis of the disaster mechanism and attribute characteristics of mountain floods and proposes an RBF neural network integration based on rough set flood damage loss assessment model of, and the flood loss assessment model based on neural network integration was applied in the flood loss prediction work of Village A, making the flood loss rate suitable for the use of the flood loss assessment model. The forecast results are compared and analyzed with the actual statistically published flood loss value, which verifies the feasibility of the forecast model and provides a new method for flood loss assessment. The prediction results of mountain flood disaster loss in villages and towns show that the research based on the improved RBF neural network earthquake damage loss prediction can quickly and accurately obtain more reliable evaluation results in terms of direct economic loss and casualty assessment, which improves rescue efficiency and reduces the affected population. It has significant practicality in disaster reduction and rescue operations, industrial layout planning, and economic benefit evaluation.},
  archive      = {J_NCA},
  author       = {Zhang, Yu and Hao, Yonghe},
  doi          = {10.1007/s00521-021-05902-1},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2513-2524},
  shortjournal = {Neural Comput. Appl.},
  title        = {Loss prediction of mountain flood disaster in villages and towns based on rough set RBF neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A model-based collaborate filtering algorithm based on
stacked AutoEncoder. <em>NCA</em>, <em>34</em>(4), 2503–2511. (<a
href="https://doi.org/10.1007/s00521-021-05933-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, recommender systems are widely used on various platforms in real world to provide personalized recommendations. However, sparsity is a tough problem in a Collaborate Filtering (CF) recommender system as it always leads to the over-fitting problem. This paper proposes a Model-based Collaborate Filtering Algorithm Based on Stacked AutoEncoder (MCFSAE) to overcome the sparsity problem. In the MCFSAE model, we first convert the rating matrix into a high-dimensional classification dataset with a size equal to the number of ratings. As the number of ratings is usually large scale, the classification performance can be guaranteed. Since the obtained classification dataset is high dimensional, we then utilize Stacked AutoEncoder, which is a good nonlinear feature reduction model, to obtain a high-level low-dimensional feature presentation. Finally, a softmax classification model is used to predict the unknown ratings based on the high-level features. Extensive experiments on EachMovie and MovieLens datasets are conducted to compare the proposed MCFSAE model with other SOTA CF models. Experimental results show that MCFSAE performs better than other CF models, especially when the rating matrix is sparse.},
  archive      = {J_NCA},
  author       = {Yu, Miao and Quan, Tianqi and Peng, Qinglong and Yu, Xu and Liu, Lei},
  doi          = {10.1007/s00521-021-05933-8},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2503-2511},
  shortjournal = {Neural Comput. Appl.},
  title        = {A model-based collaborate filtering algorithm based on stacked AutoEncoder},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on cognitive-inspired computing and
applications. <em>NCA</em>, <em>34</em>(4), 2501–2502. (<a
href="https://doi.org/10.1007/s00521-021-06509-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ye, Jun and Pang, Sulin},
  doi          = {10.1007/s00521-021-06509-2},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2501-2502},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on cognitive-inspired computing and applications},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Noise-estimation-based anisotropic diffusion
approach for retinal blood vessel segmentation. <em>NCA</em>,
<em>34</em>(3), 2499. (<a
href="https://doi.org/10.1007/s00521-021-06819-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Abdallah, Mariem Ben and Azar, Ahmad Taher and Guedri, Hichem and Malek, Jihene and Belmabrouk, Hafedh},
  doi          = {10.1007/s00521-021-06819-5},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2499},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Noise-estimation-based anisotropic diffusion approach for retinal blood vessel segmentation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Multi-objective hybrid genetic algorithm for
task scheduling problem in cloud computing. <em>NCA</em>,
<em>34</em>(3), 2497. (<a
href="https://doi.org/10.1007/s00521-021-06790-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Pirozmand, Poria and Hosseinabadi, Ali Asghar Rahmani and Farrokhzad, Maedeh and Sadeghilalimi, Mehdi and Mirkamali, Seyedsaeid and Slowik, Adam},
  doi          = {10.1007/s00521-021-06790-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2497},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Multi-objective hybrid genetic algorithm for task scheduling problem in cloud computing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Co-active neuro-fuzzy inference system model
as single imputation approach for non-monotone pattern of missing data.
<em>NCA</em>, <em>34</em>(3), 2495–2496. (<a
href="https://doi.org/10.1007/s00521-021-06623-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is an addendum to Ref. Neural Computing and Applications (2021) 33:8981–9004 that adds information to clarify certain aspects of the models used adding information and some citations. In this paper an approach based on Co-active Neuro-Fuzzy Inference System named CANFIS-ART is proposed to automate data imputation procedure. This model is compared to other state-of-the-art imputation techniques such as its baseline model Artificial Neural Network and statistical methods, using a total of eighteen databases exposed to a perturbation procedure based on the random generation of non-monotone missing values pattern. A comparison of databases imputed by these models using a set of three classifiers were conducted.},
  archive      = {J_NCA},
  author       = {Silva-Ramirez, Esther-Lydia and Cabrera-Sánchez, Juan-Francisco},
  doi          = {10.1007/s00521-021-06623-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2495-2496},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Co-active neuro-fuzzy inference system model as single imputation approach for non-monotone pattern of missing data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic and intelligent content visualization system based
on deep learning and genetic algorithm. <em>NCA</em>, <em>34</em>(3),
2473–2493. (<a
href="https://doi.org/10.1007/s00521-022-06887-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing demand in distance education, e-learning, web-based learning, and other digital sectors (e.g., entertainment) has led to excessive amounts of e-content. Learning objects (LOs) are among the most important components of electronic content (e-content) and are preserved in learning object repositories (LORs). LORs produce different types of electronic content. In producing e-content, several visualization techniques are employed to attract users and ensure a better understanding of the provided information. Many of these visualization systems match images with corresponding text using methods such as semantic web, ontologies, natural language processing, statistical techniques, neural networks, and deep neural networks. Unlike these methods, in this study, an automatic and intelligent content visualization system is developed using deep learning and popular artificial intelligence techniques. The proposed system includes subsystems that segment images to panoptic image instances and use these image instances to generate new images using a genetic algorithm, an evolution-based technique that is one of the best-known artificial intelligence methods. This large-scale proposed system was used to test different amounts of LOs for various science fields. The results show that the developed system can be efficiently used to create visually enhanced content for digital use.},
  archive      = {J_NCA},
  author       = {İnce, Murat},
  doi          = {10.1007/s00521-022-06887-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2473-2493},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic and intelligent content visualization system based on deep learning and genetic algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A modified firefly algorithm applying on multi-objective
radial-based function for blasting. <em>NCA</em>, <em>34</em>(3),
2455–2471. (<a
href="https://doi.org/10.1007/s00521-021-06544-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modifying the metaheuristics as a striking alternative of basic algorithms is outstanding and efficient scientific approach in optimization of engineering problems to improve robustness and convergence rate. Firefly algorithm (FA) is one of the new metaheuristics inspired by the flashing behavior of fireflies, where the performance of each randomly generated solution on objective function is evaluated by the brightness. In the current paper, a modified firefly algorithm (MFA) was introduced using expectation value and generalized weighted average of a random brightness and then evaluated with different benchmark functions. Since brightness varies with movements of fireflies, the parameter settings can adaptively be tuned for different problems. The capability of the MFA then in hybridizing with a developed automated multi-objective radial-based function network (MORBF) was examined. In blasting engineering, multi-objective models covering the peak particle velocity (PPV) and the vibration frequency (Fvib) due to providing more insight on safety criteria significantly are essential and great of interested. The hybrid MORBF-MFA then was applied on 78 blasting data comprising stemming, burden, spacing, total charge, distance, and charge per delay to provide more accurate predictive model. Detailed executed analyses through different metrics showed 1.01\% and 2.43\% improvement in hybrid MORBF-MFA corresponding to PPV and Fvib over MORBF-FA. The observed results approved that the introduced MFA as a reliable and feasible tool with accurate enough response can effectively be applied to multi-objective problems. Implemented sensitivity analyses scored the distance and burden as the most and least influences factors on predicted outputs.},
  archive      = {J_NCA},
  author       = {Abbaszadeh Shahri, Abbas and Khorsand Zak, Mohammad and Abbaszadeh Shahri, Hossein},
  doi          = {10.1007/s00521-021-06544-z},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2455-2471},
  shortjournal = {Neural Comput. Appl.},
  title        = {A modified firefly algorithm applying on multi-objective radial-based function for blasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). KRR-CNN: Kernels redundancy reduction in convolutional
neural networks. <em>NCA</em>, <em>34</em>(3), 2443–2454. (<a
href="https://doi.org/10.1007/s00521-021-06540-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are a promising tool for solving real-world problems. However, successful CNNs often require a large number of parameters, which leads to a significant amount of memory and a higher computational cost. This may produce some undesirable phenomena, notably the overfitting. Indeed, in CNNs, many kernels are usually redundant and can be eliminated from the network while preserving the performance. In this work, we propose a new optimization model for kernels redundancy reduction in CNN named KRR-CNN. It consists of minimization and optimization phases. In the first one, a dataset is used to train a specific CNN generating a learned CNN with optimal parameters. These later are combined with a decision optimization model to reduce kernels that have not contributed to the first task. The optimization phase is carried out by the evolutionary genetic algorithm. Efficiency of KRR-CNN has been demonstrated by several experiments. In fact, the suggested model allows reducing the kernels redundancy and improving the classification performance comparable to the state-of-the-art CNNs.},
  archive      = {J_NCA},
  author       = {Hssayni, El houssaine and Joudar, Nour-Eddine and Ettaouil, Mohamed},
  doi          = {10.1007/s00521-021-06540-3},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2443-2454},
  shortjournal = {Neural Comput. Appl.},
  title        = {KRR-CNN: Kernels redundancy reduction in convolutional neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Drought modelling by standard precipitation index (SPI) in a
semi-arid climate using deep learning method: Long short-term memory.
<em>NCA</em>, <em>34</em>(3), 2425–2442. (<a
href="https://doi.org/10.1007/s00521-021-06505-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drought modelling is an important issue because it is required for curbing or mitigating its effects, alerting the people to the its consequences, and water resources planning. This study investigates the capability of a deep learning method, long short-term memory (LSTM), in forecasting drought calculated from monthly rainfall data obtained from four stations of Iran. The outcomes of LSTM compared with extra-trees (ET), vector autoregressive approach (VAR) and multivariate adaptive regression spline (MARS) methods in forecasting four drought indices, SPI-3, SPI-6, SPI-9 and SPI-12, taking into account numerical criteria, root-mean-square errors (RMSE), Nash–Sutcliffe efficiency and correlation coefficient together with the visual methods, time variation graphs, scatter plots and Taylor diagrams. The overall results showed that the LSTM method performed superior to the ET, VAR and MARS in forecasting drought based on SPI-3, SPI-6, SPI-9 and SPI-12. The RMSE of ET, VAR and MARS was improved by about 17.1\%, 12.8\% and 9.6\% for SPI-3, by 10.5\%, 6.2\% and 5\% for SPI-6, by 7.3\%, 4.1\% and 6.2\% for SPI-9 and by 22.2\%, 27\% and 10.6\% for SPI-12 using LSTM. The MARS method was ranked as the second best, while the ET provided the worst results in forecasting drought based on SPI.},
  archive      = {J_NCA},
  author       = {Docheshmeh Gorgij, Alireza and Alizamir, Meysam and Kisi, Ozgur and Elshafie, Ahmed},
  doi          = {10.1007/s00521-021-06505-6},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2425-2442},
  shortjournal = {Neural Comput. Appl.},
  title        = {Drought modelling by standard precipitation index (SPI) in a semi-arid climate using deep learning method: Long short-term memory},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). (2+1)d-SLR: An efficient network for video sign language
recognition. <em>NCA</em>, <em>34</em>(3), 2413–2423. (<a
href="https://doi.org/10.1007/s00521-021-06467-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most existing sign language recognition methods have made significant progress. However, there are still problems in the field of sign language recognition: Traditional SLR technology relies on external devices such as data gloves, position tracker, and has achieved limited success. Moreover, the current state-of-the-art vision-based technologies cannot be applied in practice due to the difficulty in balancing accuracy and speed, because most of them pay the cost of running time for better sign language classification accuracy. In this paper, we propose a (2+1)D-SLR network based on (2+1)D convolution, which is different from other methods in that the proposed network can achieve higher accuracy with a faster speed. Because (2+1)D-SLR can learn spatio-temporal features from the raw sign RGB frames. In addition, the existing Chinese sign language dataset is difficult to guarantee the personality differences between different sign language speakers and the presentation differences of the same presenter. Therefore, we propose a large-scale Chinese sign language video dataset called NCSL to solve this problem, including 300 different sign language vocabulary which demonstrated by 30 volunteers, 10 times each. We also validated our method on NCSL and another large-scale sign language dataset, i.e., LSA64, Achieved 96.4\% and 98.7\% accuracy, respectively, demonstrating that our method can not only achieve competitive accuracy but be much faster than current well-known sign language recognition methods.},
  archive      = {J_NCA},
  author       = {Wang, Fei and Du, Yuxuan and Wang, Guorui and Zeng, Zhen and Zhao, Lihong},
  doi          = {10.1007/s00521-021-06467-9},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2413-2423},
  shortjournal = {Neural Comput. Appl.},
  title        = {(2+1)D-SLR: An efficient network for video sign language recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy-based modeling of thermohydraulic aspect of solar air
heater roughened with inclined broken roughness. <em>NCA</em>,
<em>34</em>(3), 2393–2412. (<a
href="https://doi.org/10.1007/s00521-021-06547-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, inclined broken roughness is experimentally investigated to enhance the thermohydraulic performance of solar air heaters. Current article focuses on a fuzzy-based structure as a substitution method for predicting the thermohydraulic performance. A separated fuzzy inference system for each smooth and roughened plate along with an integrated one designed for both plates was selected as the strategy of modeling. In addition, utilizing temperature and velocity features with their generality in all solar air heaters were suggested as a cutting-edge solution to dominate complexity restrictions of geometrical roughness parameters. Throughout the experiments, triangular membership functions obtained better agreement with experimental data than Gaussian functions except for the friction factor of the roughened plate in the separated method. Sugeno structure demonstrated better forecasting ability than Mamdani. Additionally, Nusselt number showed better applicability in being predicted more easily by the considered fuzzy structures rather than the friction factor. Moreover, the system constructed based on the Gaussian membership function showed higher accuracy in forecasting the roughened plate parameters. The least mean square error of the separated method for the Nusselt number and the friction factor of the smooth plate were 2.5477 × 10−04 and 8.1115 × 10−04, respectively. Furthermore, these values were equal to 2.0218 × 10−04 and 7.5150 × 10−04, for the Nusselt number and friction factor of the roughened plate, respectively. Having considered the thermohydraulic performance, the least mean square error of the separated method was equal to 8.6255 × 10-04. The obtained results approved that the fuzzy method is a significantly efficient method for anticipating the parameters of solar air heaters.},
  archive      = {J_NCA},
  author       = {Rahmati Aidinlou, H. and Nikbakht, Ali M.},
  doi          = {10.1007/s00521-021-06547-w},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2393-2412},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fuzzy-based modeling of thermohydraulic aspect of solar air heater roughened with inclined broken roughness},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fault location in distribution networks based on SVM and
impedance-based method using online databank generation. <em>NCA</em>,
<em>34</em>(3), 2375–2391. (<a
href="https://doi.org/10.1007/s00521-021-06541-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault location methods help to reduce outage time and improve reliability indices and therefore are important in practice. However, the performance of traditional fault location methods which are mainly developed for transmission grid is challenged by the specification and complexities of the distribution grid. Furthermore, the errors in measurement devices compromise the accuracy of the fault localization. This paper addresses these issues through an integrated methodology. In the proposed methodology, current transformer (CT) and potential transformer (PT) errors are first applied to current and voltage data recorded at the starting point of the feeder. Then, the impedance-based fault location method (IBFLM) is used to locate possible fault locations using the recorded voltage and current. Then, at the section of possible points, some locations are selected, the same fault is simulated, and an online databank is generated. After this, using a combination of the wavelet transform, Fourier transform and minimum redundancy maximum relevance (mRMR) algorithm, some features are selected and they can be separated using support vector machine (SVM) classifier. They are utilized to select one point as the final fault location among possible locations. A real feeder is considered as the sample distribution network to assess the performance of the proposed method. Instrument errors are modeled using the Gaussian stochastic process which is added to recorded signals at the starting point of the feeder. The accuracy of the proposed method is investigated under different fault locations, fault resistances, and fault inception angles. Simulation results confirm that the proposed method is highly accurate. The proposed method is tested in a distribution network in a power system simulator in the power system laboratory of Persian Gulf University. The experimental results confirm that the accuracy and precision of the proposed method are high. The method is also compared with other state-of-the-art methods, and the results show a clear improvement.},
  archive      = {J_NCA},
  author       = {Keshavarz, Ahmad and Dashti, Rahman and Deljoo, Maryam and Shaker, Hamid Reza},
  doi          = {10.1007/s00521-021-06541-2},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2375-2391},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fault location in distribution networks based on SVM and impedance-based method using online databank generation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NucNormZSL: Nuclear norm-based domain adaptation in
zero-shot learning. <em>NCA</em>, <em>34</em>(3), 2353–2374. (<a
href="https://doi.org/10.1007/s00521-021-06461-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability of human beings to recognize novel concepts has attracted significant attention in the research community. Zero-shot learning, also known as zero-data learning, seeks to build models that can recognize novel class instances even without “seeing” them during their training; some description of novel classes is, however, required. In this work, we pose zero-shot learning as a dictionary learning problem to learn the projection functions from feature to semantic space as dictionaries in the source and target domains. To get a robust projection mapping in the source domain, we introduce nuclear norm to achieve low-rank solutions. Further, this low-ranked dictionary is used as a regularizer in the target domain so that the knowledge contained in the source dictionary is utilized in the target domain. In our experiments, source domain contains the seen class images, their ground truths and attribute representations while corresponding data for unseen class are contained in the target domain. We also use label propagation as an alternative to the nearest neighbor search in the semantic space for class-label assignment. Our proposed model, NucNormZSL, achieves state-of-the-art results for the Large Attribute (LAD) dataset and remains fairly competitive with existing approaches on Animals with Attributes-2 (AWA2), Caltech-UCSD Birds (CUB) and SUN datasets in the conventional setting and generalized setting.},
  archive      = {J_NCA},
  author       = {Singh, Upendra Pratap and Singh, Krishna Pratap and Thakur, Manoj},
  doi          = {10.1007/s00521-021-06461-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2353-2374},
  shortjournal = {Neural Comput. Appl.},
  title        = {NucNormZSL: Nuclear norm-based domain adaptation in zero-shot learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Emotionally charged text classification with deep learning
and sentiment semantic. <em>NCA</em>, <em>34</em>(3), 2341–2351. (<a
href="https://doi.org/10.1007/s00521-021-06542-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification is one of the widely used phenomena in different natural language processing tasks. State-of-the-art text classifiers use the vector space model for extracting features. Recent progress in deep models, recurrent neural networks those preserve the positional relationship among words achieve a higher accuracy. To push text classification accuracy even higher, multi-dimensional document representation, such as vector sequences or matrices combined with document sentiment, should be explored. In this paper, we show that documents can be represented as a sequence of vectors carrying semantic meaning and classified using a recurrent neural network that recognizes long-range relationships. We show that in this representation, additional sentiment vectors can be easily attached as a fully connected layer to the word vectors to further improve classification accuracy. On the UCI sentiment labelled dataset, using the sequence of vectors alone achieved an accuracy of 85.6\%, which is better than 80.7\% from ridge regression classifier—the best among the classical technique we tested. Additional sentiment information further increases accuracy to 86.3\%. On our suicide notes dataset, the best classical technique—the Naíve Bayes Bernoulli classifier, achieves accuracy of 71.3\%, while our classifier, incorporating semantic and sentiment information, exceeds that at 75\% accuracy.},
  archive      = {J_NCA},
  author       = {Huan, Jeow Li and Sekh, Arif Ahmed and Quek, Chai and Prasad, Dilip K.},
  doi          = {10.1007/s00521-021-06542-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2341-2351},
  shortjournal = {Neural Comput. Appl.},
  title        = {Emotionally charged text classification with deep learning and sentiment semantic},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-fragile sliding mode control for <span
class="math display"><em>H</em><sub>∞</sub></span> /passive
synchronization of master-slave markovian jump complex dynamical
networks with time-varying delays. <em>NCA</em>, <em>34</em>(3),
2323–2340. (<a
href="https://doi.org/10.1007/s00521-021-06445-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the master-slave Markovian jump complex dynamical networks (CDNs) with multiple time-varying delays by designing a non-fragile sliding mode control mechanism to achieve $${H_\infty }$$ /passive synchronization. First, by introducing a non-fragile sliding surface, master-slave CDNs can achieve $${H_\infty }$$ /passive synchronization, and the state trajectory of CDNs can arrive the sliding surface based on a suitable controller. By applying an appropriate Lyapunov–Krasovskii functional (LKF) that combines triple and four integral terms, using the reciprocal convex combination method and utilizing a few novel integral inequalities, the criterion of $${H_\infty }$$ /passive synchronization is established for master-slave CDNs. Besides, the prospective criterion of $${H_\infty }$$ /passive synchronization can be transformed into the form of linear matrix inequalities. Moreover, reasonability of theoretical results is proved via numerical simulations.},
  archive      = {J_NCA},
  author       = {He, Qiushi and Ma, Yuechao},
  doi          = {10.1007/s00521-021-06445-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2323-2340},
  shortjournal = {Neural Comput. Appl.},
  title        = {Non-fragile sliding mode control for $${H_\infty }$$ /passive synchronization of master-slave markovian jump complex dynamical networks with time-varying delays},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GSTA: Gated spatial–temporal attention approach for travel
time prediction. <em>NCA</em>, <em>34</em>(3), 2307–2322. (<a
href="https://doi.org/10.1007/s00521-021-06560-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate travel time prediction between two locations is one of the most substantial services in transport. In travel time prediction, origin–destination (OD) method is more challenging since it has no intermediate trajectory points. This paper puts forward a deep learning-based model, called Gated Spatial–Temporal Attention (GSTA), to optimize the OD travel time prediction. While many trip features are available, their relations and particular contributions to the output are usually unknown. To give our model the flexibility to select the most relevant features, we develop a feature selection module with an integration unit and a gating mechanism to pass or suppress the trip feature based on its contribution. To capture spatial–temporal dependencies and correlations in the short and long term, we propose a new pair-wise attention mechanism with spatial inference and temporal reasoning. In addition, we adapt and integrate multi-head attention to improve model performance in case of sophisticated dependencies in long term. Extensive experiments on two large taxi datasets in New York City, USA, and Chengdu, China demonstrate the superiority of our model in comparison with other models.},
  archive      = {J_NCA},
  author       = {Khaled, Alkilane and Elsir, Alfateh M. Tag and Shen, Yanming},
  doi          = {10.1007/s00521-021-06560-z},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2307-2322},
  shortjournal = {Neural Comput. Appl.},
  title        = {GSTA: Gated spatial–temporal attention approach for travel time prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A gray code model for the encoding of grid cells in the
entorhinal cortex. <em>NCA</em>, <em>34</em>(3), 2287–2306. (<a
href="https://doi.org/10.1007/s00521-021-06482-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the brains of humans and mammals, the formation of episodic memories results from the association between objects, space and time. Both the hippocampus and the entorhinal cortex have shown to play an essential role in the formation of these memories. The hippocampus may be considered as an indexer of the pattern of neocortical activity produced by an episode, while the entorhinal cortex is characterized as performing time and space integration, conveying that information to the hippocampus, in the form of grid cells. Although these grid cells are biological based, non-biological grid cells are used in discrete global grid systems that currently support the indexing of assets across the globe, allowing a more adequate partitioning of the Earth into logical structures that take into account the heterogeneity of the scales of the associated geospatial data. The reasons that led to the definition of these grid systems at macro-levels may have led to the formation of similar structures inside our brains. In this paper, we investigate a representation that unifies these views, creating new types of Gray encodings for both one- and two-dimensional spaces. We start by defining a multilayer ternary encoder based on an equilateral triangular coordinate system. After defining a space filling method for this two-dimensional architecture, two Gray codes for one-dimensional signals are defined, for both circular/periodic and non-circular representations of signals. An algorithm is defined to build the two-dimensional Gray encoding of grid cells, which is then successfully applied in a navigation system of a robot, generating patterns of grid cells similar with the ones observed in neuroscience.},
  archive      = {J_NCA},
  author       = {Monteiro, Jânio and Pedro, André and Silva, António João},
  doi          = {10.1007/s00521-021-06482-w},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2287-2306},
  shortjournal = {Neural Comput. Appl.},
  title        = {A gray code model for the encoding of grid cells in the entorhinal cortex},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AFP-SRC: Identification of antifreeze proteins using sparse
representation classifier. <em>NCA</em>, <em>34</em>(3), 2275–2285. (<a
href="https://doi.org/10.1007/s00521-021-06558-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Species living in the extreme cold environment fight against the harsh conditions using antifreeze proteins (AFPs), which manipulate the freezing mechanism of water in more than one way. This amazing nature of AFPs turns out to be extremely useful in several industrial and medical applications. The lack of similarity in their structure and sequence makes their prediction an arduous task, and identifying them experimentally in the wet laboratory is time-consuming and expensive. In this research, we propose a computational framework for the prediction of AFPs, which is essentially based on a sample-specific classification method using sparse reconstruction. A linear model and an over-complete dictionary matrix (ODM) of known AFPs are used to predict a sparse class-label vector that provides a sample-association score. Delta rule is applied for the reconstruction of two pseudo-samples using lower and upper parts of the sample-association vector and based on the minimum recovery score, class labels are assigned. We compare our approach with contemporary methods on a standard dataset. The proposed method outperforms the contemporary methods in terms of balanced accuracy and Youden’s index. The MATLAB implementation of the proposed method is available at the author’s GitHub page ( https://github.com/Shujaat123/AFP-SRC ).},
  archive      = {J_NCA},
  author       = {Usman, Muhammad and Khan, Shujaat and Park, Seongyong and Wahab, Abdul},
  doi          = {10.1007/s00521-021-06558-7},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2275-2285},
  shortjournal = {Neural Comput. Appl.},
  title        = {AFP-SRC: Identification of antifreeze proteins using sparse representation classifier},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybridizing multi-objective, clustering and particle swarm
optimization for multimodal optimization. <em>NCA</em>, <em>34</em>(3),
2247–2274. (<a
href="https://doi.org/10.1007/s00521-021-06355-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal optimization problems (MMOPs) are a kind of common optimization problem aiming to find multiple high-accurate optimal solutions. In this paper, a multimodal optimization algorithm named MO-C-PSO is proposed. In the proposed method, we combine the exploration ability in the whole search space of multi-objective technique with the special clustering ability of mean-shift clustering method. In this way, each potential optimal individual is induced to form its own unique sub-population. Then, particle swarm optimization (PSO) guides the local search in each sub-population by applying the proposed switching evolutionary process (SEP) strategy, which can refine the solution accuracy. To evaluate the performance, the proposed method is compared with other state-of-the-art methods on CEC’2013 benchmark set, the classic high-dimensional problems, and a real-world application. The experimental results have validated that MO-C-PSO can provide competitive performance.},
  archive      = {J_NCA},
  author       = {Zheng, Tianzi and Liu, Jianchang and Liu, Yuanchao and Tan, Shubin},
  doi          = {10.1007/s00521-021-06355-2},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2247-2274},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybridizing multi-objective, clustering and particle swarm optimization for multimodal optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A real-time and high-precision method for small
traffic-signs recognition. <em>NCA</em>, <em>34</em>(3), 2233–2245. (<a
href="https://doi.org/10.1007/s00521-021-06526-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a fundamental element of the traffic system, traffic signs reduce the risk of accidents by providing essential information about the road condition to drivers, pedestrians, etc. With the rapid progress of computer vision and artificial intelligence, traffic-signs recognition systems have been applied for the advanced driver assistance system and auto driving system, to help drivers and self-driving vehicles capture the important road information precisely. However, in real applications, small traffic-signs recognition is still challenging. In this article, we propose an efficient method for small-size traffic-signs recognition, named traffic-signs recognition small-aware, with the inspiration of the state-of-the-art object detection framework YOLOv4 and YOLOv5. In general, there are four contributions in our work: (1) for the Backbone of the model, we introduce high-level features to construct a better detector head; (2) for the Neck of the model, receptive field block-cross is utilized for capturing the contextual information of feature map; (3) for the Head of the model, we refine the detector head grid to achieve more accurate detection of small traffic signs; (4) for the input, we propose a data augmentation method named Random Erasing-Attention, which can increase difficult samples and enhance the robustness of the model. Real experiments on the challenging dataset TT100K demonstrate that our method can achieve significant performance improvement compared with the state of the art. Moreover, it is a real-time method and shows huge potential applications in advanced driver assistance system and auto driving system.},
  archive      = {J_NCA},
  author       = {Chen, Junzhou and Jia, Kunkun and Chen, Wenquan and Lv, Zhihan and Zhang, Ronghui},
  doi          = {10.1007/s00521-021-06526-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2233-2245},
  shortjournal = {Neural Comput. Appl.},
  title        = {A real-time and high-precision method for small traffic-signs recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AURORA: An autonomous agent-oriented hybrid trading service.
<em>NCA</em>, <em>34</em>(3), 2217–2232. (<a
href="https://doi.org/10.1007/s00521-021-06508-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock markets play an essential role in the economy and offer companies opportunities to grow, and insightful investors to make profits. Many tools and techniques have been proposed and applied to analyze the overall market behavior to seize such opportunities. However, understanding the stock exchange’s intrinsic rules and taking opportunities are not trivial tasks. With that in mind, this work proposes AURORA: a new hybrid service to trade equities in the stock market, using an autonomous agent-based approach. The goal is to offer a reliable service based on technical and fundamental analysis with precision and stability in the decision-making process. For this, AURORA’s intelligence is modeled using a rational agent capable of perceiving the market and acting upon its perception autonomously. When compared with other solutions in the literature, the proposed service shows that it can predict the gain or loss of value at the price of a stock with an accuracy higher than 82.86\% in the worst case and 89.23\% in the best case. Furthermore, the proposed service can achieve a profitability of 11.74\%, overcoming fixed-income investments, and portfolios built with the Markowitz Mean-Variance model.},
  archive      = {J_NCA},
  author       = {Nobre, Renato A. and Nascimento, Khalil C. do and Vargas, Patricia A. and Valejo, Alan Demétrius Baria and Pessin, Gustavo and Villas, Leandro A. and Filho, Geraldo P. Rocha},
  doi          = {10.1007/s00521-021-06508-3},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2217-2232},
  shortjournal = {Neural Comput. Appl.},
  title        = {AURORA: An autonomous agent-oriented hybrid trading service},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A topic-based multi-channel attention model under hybrid
mode for image caption. <em>NCA</em>, <em>34</em>(3), 2207–2216. (<a
href="https://doi.org/10.1007/s00521-021-06557-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically generating captions of an image is not closely related to every spatial area of the visual information, but always related to the topic of the image expression. Aiming at the decoupling problem of visual spatial feature attention and semantic decoder, a topic-based multi-channel attention model (TMA) under hybrid mode for image caption is proposed. First, natural language processing (NLP) technology is used to preprocess the caption references, including filtering stop words, analyzing word frequency and constructing a semantic network graph with node labels. Then, combined with the image features extracted by the convolutional neural network (CNN), a semantic perception network is designed to achieve cross-domain prediction from image to topic. Next, a topic-based multi-channel attention fusion mechanism is proposed to realize image-text attention fusion representation under the joint action of the global spatial features of the image, the local semantic features of the graph nodes and the hidden layer features of the long short-term memory (LSTM) decoder. Finally, multi-task loss function is used to train the TMA. Experimental results show that the proposed model has better evaluation performance with topic-focused attention than state-of-the-art (SOTA) methods.},
  archive      = {J_NCA},
  author       = {Qian, Kui and Tian, Lei},
  doi          = {10.1007/s00521-021-06557-8},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2207-2216},
  shortjournal = {Neural Comput. Appl.},
  title        = {A topic-based multi-channel attention model under hybrid mode for image caption},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fog-based traffic light management strategy (TLMS) based
on fuzzy inference engine. <em>NCA</em>, <em>34</em>(3), 2187–2205. (<a
href="https://doi.org/10.1007/s00521-021-06525-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban mobility is one of the critical challenges in modern cities that should be tackled carefully. The exponential growth of cars number badly impacts the transportation system (TS) on which most cities are living on. Traffic control is one of the most critical issues in TS, which depends on a set of cooperative traffic lights. Smart Traffic lights, which can receive and analyze traffic data, can solve traffic problems by efficiently predict the accurate waiting time for each traffic lane at the intersections. This can improve the traffic flow and accordingly promotes the transportation system performance. This paper introduces a Fog-Based Traffic Light Management Strategy (TLMS) based on Fuzzy Inference Engine. TLMS can accurately calculate the optimal waiting time for each traffic lane at the intersections to decrease the average waiting time for the stopped vehicles. TLMS applies Vehicle to infrastructure protocol (V2I) that allows vehicles to interact directly with the infrastructure of the road such as GPS sensors and the traffic light signals. At each traffic intersection, the number of waiting vehicles, their locations relative to TLMS, and their sizes are detected and sent to TLMS in real time. Then, based on fuzzy inference, TLMS can calculate the optimal waiting time for each lane, which optimizes the traffic flow at the intersection by minimizing the waiting time for the vehicles. The performance of the proposed TLMS has been compared and tested against recently proposed techniques via simulation. The results of the experiment showed that TLMS outperforms recent technologies as it minimizes the average waiting time of vehicles around the intersections and accordingly maximizes the performance of the traffic system.},
  archive      = {J_NCA},
  author       = {Gamel, Samah A. and Saleh, Ahmed I. and Ali, Hesham A.},
  doi          = {10.1007/s00521-021-06525-2},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2187-2205},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fog-based traffic light management strategy (TLMS) based on fuzzy inference engine},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A variable memory state feedback and its application to
robust control of uncertain singular time-delay systems. <em>NCA</em>,
<em>34</em>(3), 2177–2186. (<a
href="https://doi.org/10.1007/s00521-021-06524-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is focused on the robust control of uncertain singular time-delay systems. The systems are firstly decomposed to differential-algebraic equations. The state decomposition is applied to customize a special augmented Lyapunov–Krasovskii functional and a variable memory state feedback (which includes the general state feedback and memory state feedback as special cases). Then, a robust admissibility condition and a robust admissibilization condition are derived, by which less conservatism and better control effect can be obtained with less computation. Finally, the above statements are demonstrated by some numerical examples.},
  archive      = {J_NCA},
  author       = {Zhi, Ya-Li},
  doi          = {10.1007/s00521-021-06524-3},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2177-2186},
  shortjournal = {Neural Comput. Appl.},
  title        = {A variable memory state feedback and its application to robust control of uncertain singular time-delay systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CN-waterfall: A deep convolutional neural network for
multimodal physiological affect detection. <em>NCA</em>, <em>34</em>(3),
2157–2176. (<a
href="https://doi.org/10.1007/s00521-021-06516-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affective computing solutions, in the literature, mainly rely on machine learning methods designed to accurately detect human affective states. Nevertheless, many of the proposed methods are based on handcrafted features, requiring sufficient expert knowledge in the realm of signal processing. With the advent of deep learning methods, attention has turned toward reduced feature engineering and more end-to-end machine learning. However, most of the proposed models rely on late fusion in a multimodal context. Meanwhile, addressing interrelations between modalities for intermediate-level data representation has been largely neglected. In this paper, we propose a novel deep convolutional neural network, called CN-Waterfall, consisting of two modules: Base and General. While the Base module focuses on the low-level representation of data from each single modality, the General module provides further information, indicating relations between modalities in the intermediate- and high-level data representations. The latter module has been designed based on theoretically grounded concepts in the Explainable AI (XAI) domain, consisting of four different fusions. These fusions are mainly tailored to correlation- and non-correlation-based modalities. To validate our model, we conduct an exhaustive experiment on WESAD and MAHNOB-HCI, two publicly and academically available datasets in the context of multimodal affective computing. We demonstrate that our proposed model significantly improves the performance of physiological-based multimodal affect detection.},
  archive      = {J_NCA},
  author       = {Fouladgar, Nazanin and Alirezaie, Marjan and Främling, Kary},
  doi          = {10.1007/s00521-021-06516-3},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2157-2176},
  shortjournal = {Neural Comput. Appl.},
  title        = {CN-waterfall: A deep convolutional neural network for multimodal physiological affect detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Long-term analysis of HIV infection therapy with cubature
kalman filtering-based predictive control. <em>NCA</em>, <em>34</em>(3),
2133–2155. (<a
href="https://doi.org/10.1007/s00521-021-06410-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical model-based analysis and control of human immunodeficiency virus (HIV) infection have recently provided important advantages in medicine. In this paper, firstly the literature on mathematical models and applied control methods will be surveyed to evaluate the HIV models and therapy. Secondly, a cubature Kalman filter-based nonlinear model predictive control is proposed for the multi-input multi-output control of HIV infection for decreasing the cost of sensory devices and increasing the efficiency of therapy. By doing so both unmeasurable states and personalized parameters of the HIV infection are jointly estimated in a control process to generate suitable drug dosages. In the literature, the applied drug dosages are in continuous or on/off levels. For a practical application of continuous drug dosage-level, it has been discretized into 10 levels of full dosage level. Therefore, the applied drug dosages are in piecewise-continuous levels instead of continuous values or on/off levels. The proposed observer–controller configuration has been applied to the strong and moderate therapy levels of long-term non-progressive as well as fast-progressive patients with personalized parameters, where the application results are discussed for 1-, 5-, 10- and 20-year periods. The computational results show that satisfactory performances are obtained for future applications in terms of the root-mean-squared error of the estimation and control, and in terms of the integral sum of the control input.},
  archive      = {J_NCA},
  author       = {Cetin, Meriç and Beyhan, Selami},
  doi          = {10.1007/s00521-021-06410-y},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2133-2155},
  shortjournal = {Neural Comput. Appl.},
  title        = {Long-term analysis of HIV infection therapy with cubature kalman filtering-based predictive control},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Further improved global exponential stability result for
neural networks with time-varying delay. <em>NCA</em>, <em>34</em>(3),
2115–2132. (<a
href="https://doi.org/10.1007/s00521-021-06380-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of exponential stability for neural networks with time-varying delay. An improved delay-dependent reciprocally convex inequality is proved. Combined the suitable augmented Lyapunov–Krasovskii functional with the generalized free-weighting-matrix integral inequality, the auxiliary function-based integral inequality and the novel delay-dependent reciprocally convex matrix inequality, a less conservative exponential stability criterion is established. Finally, some numerical examples are provided to illustrate the effectiveness and benefits of our proposed approach.},
  archive      = {J_NCA},
  author       = {Chen, Qiao and Liu, Xinge and Li, Xuemei},
  doi          = {10.1007/s00521-021-06380-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2115-2132},
  shortjournal = {Neural Comput. Appl.},
  title        = {Further improved global exponential stability result for neural networks with time-varying delay},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multivariate regression and genetic programming for
prediction of backbreak in open-pit blasting. <em>NCA</em>,
<em>34</em>(3), 2103–2114. (<a
href="https://doi.org/10.1007/s00521-021-06553-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In bench blasting, backbreak is the unwanted result that causes instability to the highwall and can lead to safety hazards. Hence, it is utmost necessary to minimize the generation of backbreak to improve mine’s safety. It has always been difficult to predict the backbreak because of various parameters involved, i.e. blast design, explosive properties, rock mass, etc. In this study, multivariate regression analysis (MVRA) and genetic programming (GP) techniques were performed on 70 blast data sets of previously published papers. Both the models have been developed and tested with the same mine data set. For validation of the models, a total of 14 trial blasts have been conducted in Indian coal mines with different geological strata and other parameters. The values of R2, RMSE, MAPE and prediction level at 25\% and 90\% were computed for GP and MVRA techniques. Also, the GP model is compared with the other state-of-the-art techniques. It has been found that the level of prediction for validation data set at 25\% using GP is 78.57\% and for MVRA is 21.42\%. The mean magnitude of relative error (MMRE) value for GP and MVRA is 0.18 and 0.42, respectively. The results show that the GP is a more efficient tool for prediction of backbreak in comparison with MVRA. On performing sensitivity analysis, it has been found that stemming length and powder factor are the most influencing parameters to backbreak.},
  archive      = {J_NCA},
  author       = {Sharma, Mukul and Agrawal, Hemant and Choudhary, B. S.},
  doi          = {10.1007/s00521-021-06553-y},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2103-2114},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multivariate regression and genetic programming for prediction of backbreak in open-pit blasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incremental learning model based on an improved CKS-PFNN for
aluminium electrolysis manufacturing. <em>NCA</em>, <em>34</em>(3),
2083–2102. (<a
href="https://doi.org/10.1007/s00521-021-06530-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Filtering neural networks (FNNs) are popular computing frameworks for process system modeling. However, they are vulnerable to non-Gaussian noise and consequently may suffer from low filtering accuracy. To overcome the problem, in this paper, a novel model construction algorithm by combining the improved clustering kernel function smoothing technique and the particle filter neural network (ICKS-PFNN) is proposed. Specifically, ICKS-PFNN firstly presents a construction framework for particle filter neural network (PFNN), which utilizes the dynamic approximation of particles to adjust the NN’s weights and thresholds in real time. Then, the proposed model uses kernel fuzzy C-means algorithm to uncover clusters in the particles of PFNN. A novel proportional distribution sampling strategy is adopted to maintain the diversity in particle clusters, through merging the inferior and superior particles to generate new particles based on the set proportional factors, rather than directly eliminating particles. At last, the estimation of the PFNN model is achieved by utilizing a kernel function smoothing method to update the particles in each cluster. The proposed model has been tested on the real-world system for aluminium electrolysis manufacturing and compared with several closely related frameworks. The experimental results show ICKS-PFNN obtains a superb performance when compared with other baselines. ICKS-PFNN is able to tackle noise and improve the prediction accuracy when dealing with non-Gaussian systems. Successfully applying the proposed framework in aluminium electrolysis manufacturing broadens the practical impact of FNN systems.},
  archive      = {J_NCA},
  author       = {Ding, Wei and Yao, Lizhong and Li, Yanyan and Long, Wei and Yi, Jun},
  doi          = {10.1007/s00521-021-06530-5},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2083-2102},
  shortjournal = {Neural Comput. Appl.},
  title        = {Incremental learning model based on an improved CKS-PFNN for aluminium electrolysis manufacturing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of hyperspectral imagery using spectrally
partitioned HyperUnet. <em>NCA</em>, <em>34</em>(3), 2073–2082. (<a
href="https://doi.org/10.1007/s00521-021-06532-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is one of the forefront research areas in hyperspectral image processing. The large intra-class and small inter-class variance in the pixel values of objects of interest still poses challenges in classification task. The huge dimension and a minimal number of labeled information further add challenges in the case of hyperspectral image classification. Therefore, in the present research, a novel architecture is conceived which is inspired by the U-net architecture along with spectral partitioning. The proposed architecture (HyperUnet) mainly addresses the broader issue of classification of hyperspectral images by classifying each pixel. The performance of the proposed model is evaluated on two benchmark datasets and compared with existing U-net-based models. The overall classification accuracy obtained in experiments is more than 93\% which is better than the other compared methods in the same field.},
  archive      = {J_NCA},
  author       = {Paul, Arati and Bhoumik, Sanghamita},
  doi          = {10.1007/s00521-021-06532-3},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2073-2082},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of hyperspectral imagery using spectrally partitioned HyperUnet},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain and writer adaptation of offline arabic handwriting
recognition using deep neural networks. <em>NCA</em>, <em>34</em>(3),
2055–2071. (<a
href="https://doi.org/10.1007/s00521-021-06520-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arabic Handwritten Text Recognition (AHTR) based on deep learning approaches remains a challenging problem due to the inevitable domain shift like the variability among writers’ styles and the scarcity of labelled data. To alleviate such problems, we investigate in this paper different domain adaptation strategies of AHTR system. The main idea is to exploit the knowledge of a handwriting source domain and to transfer this knowledge to another domain where only few labelled data are available. Different writer-dependent and writer-independent domain adaptation strategies are explored using a convolutional neural networks (CNN) and Bidirectional Long Short Term Memory (BSTM) - connectionist temporal classification (CTC) architecture. To discuss the interest of the proposed techniques on the target domain, we have conducted extensive experiments using three Arabic handwritten text datasets, mainly, the MADCAT, the AHTID/MW and the IFN/ENIT. Concurrently, the Arabic handwritten text dataset KHATT was used as the source domain. The obtained results prove the effectiveness of the proposed strategies specially when considering the writer’s information during the supervised adaptation process.},
  archive      = {J_NCA},
  author       = {Jemni, Sana Khamekhem and Ammar, Sourour and Kessentini, Yousri},
  doi          = {10.1007/s00521-021-06520-7},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2055-2071},
  shortjournal = {Neural Comput. Appl.},
  title        = {Domain and writer adaptation of offline arabic handwriting recognition using deep neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance assessment of meta-heuristics for composite
layup optimisation. <em>NCA</em>, <em>34</em>(3), 2031–2054. (<a
href="https://doi.org/10.1007/s00521-021-06519-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the performance of several meta-heuristic algorithms, including Particle Swarm Optimisation (PSO), different variants of Differential Evolution (DE), Biogeography-Based Optimisation (BBO), Cultural Algorithm (CA), Optics-Inspired Optimisation (OIO), and League Championship Algorithm (LCA), for optimum layup of laminated composite plates. The study provides detailed Pseudo codes for different algorithms. The buckling capacity maximisation of a 64-layer laminated composite plate under various load scenarios has been considered as the benchmark problem, in which the design variables are the stacking sequences of layers. A Deep Statistical Comparison (DSC) method is employed to rank the performance of different algorithms. The DSC uses a nonparametric two-sample Kolmogorov-Smirnov test to conduct the performance comparisons between the algorithms. The overall performance rankings obtained from the DSC suggest that the LCA, OIO, and PSO algorithms perform remarkably better in comparison to other algorithms. The comparisons provide some interesting conclusions on the performance of different algorithms.},
  archive      = {J_NCA},
  author       = {Jalili, Shahin and Khani, Reza and Maheri, Alireza and Hosseinzadeh, Yousef},
  doi          = {10.1007/s00521-021-06519-0},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2031-2054},
  shortjournal = {Neural Comput. Appl.},
  title        = {Performance assessment of meta-heuristics for composite layup optimisation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-adaptive mobile web service discovery approach based on
modified negative selection algorithm. <em>NCA</em>, <em>34</em>(3),
2007–2029. (<a
href="https://doi.org/10.1007/s00521-021-06486-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a self-adaptive mobile web service (MWS) discovery approach based on the modified negative selection algorithm (M-NSA) to improve the effectiveness and accuracy of MWS discovery in dynamic mobile environment. The main contributions of this work are the service relevance learning model and a MWS matchmaking algorithm that it is capable of changing as soon as the discovery demonstrates the feasibility of attaining improved effectiveness or accuracy. This is achieved by transforming the two stages of modified negative selection algorithm (M-NSA) into service relevance and self-adaptive matchmaking, respectively. The proposed approach is evaluated in terms of both binary and graded relevance. After an experiment with the largest MWS dataset, the proposed approach records better results in comparison with the state-of-the-art approaches. This is owing to the self/nonself discrimination mechanism, in addition to the decent parameter analysis, and the use of more comprehensive information that covers the entire discovery space.},
  archive      = {J_NCA},
  author       = {Garba, Salisu and Mohamad, Radziah and Saadon, Nor Azizah},
  doi          = {10.1007/s00521-021-06486-6},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2007-2029},
  shortjournal = {Neural Comput. Appl.},
  title        = {Self-adaptive mobile web service discovery approach based on modified negative selection algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GUASOM: An adaptive visualization tool for unsupervised
clustering in spectrophotometric astronomical surveys. <em>NCA</em>,
<em>34</em>(3), 1993–2006. (<a
href="https://doi.org/10.1007/s00521-021-06510-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an adaptive visualization tool for unsupervised classification of astronomical objects in a Big Data context such as the one found in the increasingly popular large spectrophotometric sky surveys. This tool is based on an artificial intelligence technique, Kohonen’s self-organizing maps, and our goal is to facilitate the analysis work of the experts by means of oriented domain visualizations, which is impossible to achieve by using a generic tool. We designed a client-server that handles the data treatment and computational tasks to give responses as quickly as possible, and we used JavaScript Object Notation to pack the data between server and client. We optimized, parallelized, and evenly distributed the necessary calculations in a cluster of machines. By applying our clustering tool to several databases, we demonstrated the main advantages of an unsupervised approach: the classification is not based on pre-established models, thus allowing the “natural classes” present in the sample to be discovered, and it is suited to isolate atypical cases, with the important potential for discovery that this entails. Gaia Utility for the Analysis of self-organizing maps is an analysis tool that has been developed in the context of the Data Processing and Analysis Consortium, which processes and analyzes the observations made by ESA’s Gaia satellite (European Space Agency) and prepares the mission archive that is presented to the international community in sequential periodic publications. Our tool is useful not only in the context of the Gaia mission, but also allows segmenting the information present in any other massive spectroscopic or spectrophotometric database.},
  archive      = {J_NCA},
  author       = {Álvarez, M. A. and Dafonte, C. and Manteiga, M. and Garabato, D. and Santoveña, R.},
  doi          = {10.1007/s00521-021-06510-9},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1993-2006},
  shortjournal = {Neural Comput. Appl.},
  title        = {GUASOM: An adaptive visualization tool for unsupervised clustering in spectrophotometric astronomical surveys},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fault classification method using dynamic centered
one-dimensional local angular binary pattern for a PMSM and drive
system. <em>NCA</em>, <em>34</em>(3), 1981–1992. (<a
href="https://doi.org/10.1007/s00521-021-06534-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, fault classification of the electric motors has become a hot-topic research area. Therefore, many machine learning method has been presented to create an intelligent fault detection system for electric motor. In this work, a novel classification method is presented for five different fault conditions of a motor and its drive system by using dynamic centered one-dimensional local angular binary pattern (DC-1D-LABP). It is proposed a novel multi-leveled feature extraction network, and one-dimensional discrete wavelet transform (1D-DWT) is used in order to create levels. Features are extracted from each level by using the proposed DC-1D-LABP. Neighborhood component analysis (NCA) and ReliefF-based 2-layered feature selector (NCARF) are used to select most discriminative features, and four conventional classifiers are selected for testing. A novel fault dataset is acquired, and this dataset is used for tests. Four cases were defined according to input current signal. The achieved best classification accuracy rates are 0.9692, 0.9571, 0.9650 and 1 for Case 1, Case 2, Case 3 and Case 4, respectively. These results indicate that the proposed DC-1D-LABP-based method is very effective for fault classification. Consequently, it is proposed a highly accurate and cognitive method for a fault classification in this study.},
  archive      = {J_NCA},
  author       = {Boztas, Gullu and Tuncer, Turker},
  doi          = {10.1007/s00521-021-06534-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1981-1992},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fault classification method using dynamic centered one-dimensional local angular binary pattern for a PMSM and drive system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modified job shop scheduling via taguchi method and genetic
algorithm. <em>NCA</em>, <em>34</em>(3), 1963–1980. (<a
href="https://doi.org/10.1007/s00521-021-06504-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To be in the competitive industrial world, industries required high quality, speed in completing the required work, and commitment to the delivery dates. One of the most important issues in the field of production management is the job shop scheduling problem (JSSP). In this paper, the researchers tried to solve JSSP of factory by presenting a method to improve the factory&#39;s production. Job shop scheduling (JSS) is a suitable method for solving these types of problems, which aims to improve the production flow through minimizing the whole operation time of the products. Moreover, considering the factory that depends on workers as same as machine, human factor should be considered while scheduling by using the workers&#39; weightage, in order to improve the workers&#39; working time flexibility in terms of their waiting time among their tasks by proposed model of JSS. In addition, the researchers proposed a new combination of weightage values by using Taguchi method, regarding to improve the workers&#39; working time and using genetic algorithm (GA) to solve the proposed model of JSS. One of the factories which is located in Jordan, and it is considered as one of the important factories; nevertheless, it can cover the local demands hardly, and hence, it deserves to be as a study case for this research. The findings of the studies decreased the whole operation time of the products by saving 75 min for each production line and 90 min by using GA, and the proposed model improved the  flexibility  of the workers&#39; working time in terms of their waiting times among their tasks.},
  archive      = {J_NCA},
  author       = {Saidat, Suhaila and Junoh, Ahmad Kadri and Wan Muhamad, Wan Zuki Azman and Yahya, Zainab},
  doi          = {10.1007/s00521-021-06504-7},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1963-1980},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modified job shop scheduling via taguchi method and genetic algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling path information for knowledge graph completion.
<em>NCA</em>, <em>34</em>(3), 1951–1961. (<a
href="https://doi.org/10.1007/s00521-021-06460-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) store real-world information in the form of graphs consisting of relationships between entities and have been widely used in the Semantic Web community since it is readable by machines. However, most KGs are known to be very incomplete. The issues of structure sparseness and noise paths in large-scale KGs create a substantial barrier to representation learning. In this paper, we propose an Attribute-embodied neural Relation Path Prediction (ARPP) model to predict missing relations between entities in a KG. The ARPP framework leverages both structural information and textual information from the KG to enrich the representation learning and aid in learning more valuable information from noise paths for relation prediction. To handle the overlooked equal path weight distribution issue which hinders the performance of KG completion, our method evaluates the information propagation for the path by mining neighboring nodes. In order to verify the benefits of incorporating structural information and textual information and the effectiveness of path weight re-distribution, we conduct experiments from various aspects to evaluate the quantitative results for link prediction and entity prediction task, the accuracy change caused by the ablation studies, the effectiveness of the entity attribute and entity/sequence attention, the applicability of the proposed method on Knowledge Graph Completion task, and case study. Results demonstrate that the ARPP model significantly outperforms the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Shen, Ying and Li, Dagang and Nan, Du},
  doi          = {10.1007/s00521-021-06460-2},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1951-1961},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modeling path information for knowledge graph completion},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Causal discovery from multi-domain data using the
independence of modularities. <em>NCA</em>, <em>34</em>(3), 1939–1949.
(<a href="https://doi.org/10.1007/s00521-021-06507-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding a causal relationship that can be generalized in different scenarios is a fundamental problem in science. However, in real-world scenarios, it commonly encounters a distribution shift, of which the underlying generating process changes across the domains. Such a distribution shift brings the challenge to the causal discovery from observational data, as most of the current models assume a fixed causal mechanism in heterogeneous data. As a consequence, the causal direction fails to be identified. Fortunately, in a general causal system, the distributions in the causal direction (but not the anti-causal direction) change independently across the domains, which inspires a way for causal discovery in the multi-domain data by measuring the independent change. By investigating the modularity of the causal mechanism in the multi-domain discretization data, we establish theoretical results on the identification of the causal direction under a mild technical condition. One step further, by utilizing the discretization technique, we propose a general framework for causal direction identification in the multi-domain data without assuming the specific causal mechanism and data types. We verify the effectiveness of our proposed methods in synthetic data and successfully identified the causal direction in two real-world datasets.},
  archive      = {J_NCA},
  author       = {Qiao, Jie and Bai, Yiming and Cai, Ruichu and Hao, Zhifeng},
  doi          = {10.1007/s00521-021-06507-4},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1939-1949},
  shortjournal = {Neural Comput. Appl.},
  title        = {Causal discovery from multi-domain data using the independence of modularities},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A classification and quantification approach to generate
features in soundscape ecology using neural networks. <em>NCA</em>,
<em>34</em>(3), 1923–1937. (<a
href="https://doi.org/10.1007/s00521-021-06501-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In soundscape ecology analysis, the use of acoustic features is well established and offers important baselines to ecological analyses. However, in many cases, the problem is difficult due to high-class overlap in terms of time-frequency characteristics, as well as the presence of noise. Deep neural networks have become state-of-the-art for feature learning in many multi-class applications, but they often present issues such as over-fitting or achieve unbalanced performances for different classes, which can hamper the deployment of such models in realistic scenarios. In the context of counting the number of classes in observations, the quantification task is attracting attention and was shown to be effective in other applications. This paper investigates the use of quantification combined with classification loss in order to train a convolutional neural network to classify species of birds and anurans. Results indicate quantification has advantages over both acoustic features alone and the use of regular classification networks, in particular in terms of generalization and class recall making it a suitable choice for segregation tasks related to soundscape ecology. Moreover, we show that a more compact network can outperform a deeper one for fine-grained scenarios of birds and anurans species.},
  archive      = {J_NCA},
  author       = {Dias, Fábio Felix and Ponti, Moacir Antonelli and Minghim, Rosane},
  doi          = {10.1007/s00521-021-06501-w},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1923-1937},
  shortjournal = {Neural Comput. Appl.},
  title        = {A classification and quantification approach to generate features in soundscape ecology using neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CWI: A multimodal deep learning approach for named entity
recognition from social media using character, word and image features.
<em>NCA</em>, <em>34</em>(3), 1905–1922. (<a
href="https://doi.org/10.1007/s00521-021-06488-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) from social media posts is a challenging task. User-generated content that forms the nature of social media is noisy and contains grammatical and linguistic errors. This noisy content makes tasks such as NER much harder. We propose two novel deep learning approaches utilizing multimodal deep learning and transformers. Both of our approaches use image features from short social media posts to provide better results on the NER task. On the first approach, we extract image features using InceptionV3 and use fusion to combine textual and image features. This approach presents more reliable name entity recognition when the images related to the entities are provided by the user. On the second approach, we use image features combined with text and feed it into a BERT-like transformer. The experimental results using precision, recall, and F1 score metrics show the superiority of our work compared to other state-of-the-art NER solutions.},
  archive      = {J_NCA},
  author       = {Asgari-Chenaghlu, Meysam and Feizi-Derakhshi, M. Reza and Farzinvash, Leili and Balafar, M. A. and Motamed, Cina},
  doi          = {10.1007/s00521-021-06488-4},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1905-1922},
  shortjournal = {Neural Comput. Appl.},
  title        = {CWI: A multimodal deep learning approach for named entity recognition from social media using character, word and image features},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The novel VIKOR methods for generalized pythagorean fuzzy
soft sets and its application to children of early childhood in COVID-19
quarantine. <em>NCA</em>, <em>34</em>(3), 1877–1903. (<a
href="https://doi.org/10.1007/s00521-021-06427-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the new VIKOR methods are established using the generalized Pythagorean fuzzy soft sets (GPFSSs). For GPFSSs, the distance measures such as Hamming, Euclidean, and generalized are given. Further, the basic characteristics of these distance measures are examined. Fuzzy and soft sets are strong instruments for uncertainty. This strongness has been demonstrated by the GPFSS combining Pythagorean fuzzy sets and soft sets and applied to imprecise and ambiguous information. In this context, new remoteness index-based methods have been proposed, which are dissimilar from available VIKOR methods. The displaced and fixed ideals positive and negative Pythagorean fuzzy values (PFV) were defined. Thus, based on this definition, displaced positive ideal remoteness indices, negative ideal remoteness indices, and fixed positive ideal, negative ideal remoteness indices were discussed. Two different weights are used here: weights based on OF preference information and precise weights calculated with the expectation score function. The VIKOR method given here provides a different way from canonical VIKOR methods: rank candidate alternatives and determining a compromise solution based on different preference structures. The processes principles of the newly defined GPFSSs VIKOR methods are given by four algorithms. An example of these algorithms is given with the behavioral development and cognitive development of the children of Early Childhood children in the COVID-19 quarantine.},
  archive      = {J_NCA},
  author       = {Kirişci, Murat and Demir, İbrahim and Şimşek, Necip and Topaç, Nihat and Bardak, Musa},
  doi          = {10.1007/s00521-021-06427-3},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1877-1903},
  shortjournal = {Neural Comput. Appl.},
  title        = {The novel VIKOR methods for generalized pythagorean fuzzy soft sets and its application to children of early childhood in COVID-19 quarantine},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive review of deep neuro-fuzzy system
architectures and their optimization methods. <em>NCA</em>,
<em>34</em>(3), 1837–1875. (<a
href="https://doi.org/10.1007/s00521-021-06807-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neuro-fuzzy systems (DNFSs) have been successfully applied to real-world problems using the efficient learning process of deep neural networks (DNNs) and reasoning aptitude from fuzzy inference systems (FIS). This study provides a comprehensive review of DNFS dividing it into two essential parts. The first part aims to provide a thorough understanding of DNFS and its architectural representation, whereas the second part reviews DNFS optimization methods. This study aims to assist researchers in understanding the various ways DNFS models are developed by hybridizing DNN and FIS, as well as gradient (derivative)-based methods and metaheuristics (derivative-free) optimization, as discussed in the literature. This study revealed that the proposed DNFS architectures performed 11.6\% better than non-fuzzy models, with an overall accuracy of 81.4\%. The investigation based on optimization methods revealed that DNFS with metaheuristics optimization methods has shown an overall accuracy of 93.56\%, which is 21.10\% higher than the DNFS models using gradient-based methods. Additionally, this study showed that DNFS networks presented in the literature have integrated DNN with typical FIS, although more satisfactory results can be obtained using a new generation of FIS termed fractional FIS (FFIS) and Mamdani complex FIS (M-CFIS). Besides, dynamic neural networks are suggested in the replacement of static DNNs to facilitate dynamic learning. Some studies have also demonstrated the optimization of DNFS using classical gradient-based approaches that can affect network performance when solving highly nonlinear problems. This study suggests implementing optimization methods with new and improvised metaheuristics to improve the training and performance of the models.},
  archive      = {J_NCA},
  author       = {Talpur, Noureen and Abdulkadir, Said Jadid and Alhussian, Hitham and Hasan, ·Mohd Hilmi and Aziz, Norshakirah and Bamhdi, Alwi},
  doi          = {10.1007/s00521-021-06807-9},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1837-1875},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comprehensive review of deep neuro-fuzzy system architectures and their optimization methods},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep convolutional neural networks for computer-aided breast
cancer diagnostic: A survey. <em>NCA</em>, <em>34</em>(3), 1815–1836.
(<a href="https://doi.org/10.1007/s00521-021-06804-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in deep learning networks, especially deep convolutional neural networks (DCNNs), are causing remarkable breakthroughs in radiology and imaging sciences. These advances have influenced the development of computer-aided diagnosis (CAD). This study presents applications of DCNNs for computer-aided breast cancer diagnosis. We discuss the recent breakthrough, achievements, and notable advances in CAD for breast cancer. Various key and novel insights and challenges on the use of DCNNs for mammogram analysis have been presented in the paper. The latest deep learning toolkits and libraries that are available and insights for using them have been elaborated. We also point out the possible limitations in the use of DCNNs for breast cancer detection. Finally, give some ideas of future research which can address the existing limitations.},
  archive      = {J_NCA},
  author       = {Oza, Parita and Sharma, Paawan and Patel, Samir and Kumar, Pankaj},
  doi          = {10.1007/s00521-021-06804-y},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1815-1836},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep convolutional neural networks for computer-aided breast cancer diagnostic: A survey},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Value targets in off-policy AlphaZero: A new greedy backup.
<em>NCA</em>, <em>34</em>(3), 1801–1814. (<a
href="https://doi.org/10.1007/s00521-021-05928-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents and evaluates a family of AlphaZero value targets, subsuming previous variants and introducing AlphaZero with greedy backups (A0GB). Current state-of-the-art algorithms for playing board games use sample-based planning, such as Monte Carlo Tree Search (MCTS), combined with deep neural networks (NN) to approximate the value function. These algorithms, of which AlphaZero is a prominent example, are computationally extremely expensive to train, due to their reliance on many neural network evaluations. This limits their practical performance. We improve the training process of AlphaZero by using more effective training targets for the neural network. We introduce a three-dimensional space to describe a family of training targets, covering the original AlphaZero training target as well as the soft-Z and A0C variants from the literature. We demonstrate that A0GB, using a specific new value target from this family, is able to find the optimal policy in a small tabular domain, whereas the original AlphaZero target fails to do so. In addition, we show that soft-Z, A0C and A0GB achieve better performance and faster training than the original AlphaZero target on two benchmark board games (Connect-Four and Breakthrough). Finally, we juxtapose tabular learning with neural network-based value function approximation in Tic-Tac-Toe, and compare the effects of learning targets therein.},
  archive      = {J_NCA},
  author       = {Willemsen, Daniel and Baier, Hendrik and Kaisers, Michael},
  doi          = {10.1007/s00521-021-05928-5},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1801-1814},
  shortjournal = {Neural Comput. Appl.},
  title        = {Value targets in off-policy AlphaZero: A new greedy backup},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The impact of environmental stochasticity on value-based
multiobjective reinforcement learning. <em>NCA</em>, <em>34</em>(3),
1783–1799. (<a
href="https://doi.org/10.1007/s00521-021-05859-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common approach to address multiobjective problems using reinforcement learning methods is to extend model-free, value-based algorithms such as Q-learning to use a vector of Q-values in combination with an appropriate action selection mechanism that is often based on scalarisation. Most prior empirical evaluation of these approaches has focused on deterministic environments. This study examines the impact on stochasticity in rewards and state transitions on the behaviour of multi-objective Q-learning. It shows that the nature of the optimal solution depends on these environmental characteristics, and also on whether we desire to maximise the Expected Scalarised Return (ESR) or the Scalarised Expected Return (SER). We also identify a novel aim which may arise in some applications of maximising SER subject to satisfying constraints on the variation in return and show that this may require different solutions than ESR or conventional SER. The analysis of the interaction between environmental stochasticity and multi-objective Q-learning is supported by empirical evaluations on several simple multiobjective Markov Decision Processes with varying characteristics. This includes a demonstration of a novel approach to learning deterministic SER-optimal policies for environments with stochastic rewards. In addition, we report a previously unidentified issue with model-free, value-based approaches to multiobjective reinforcement learning in the context of environments with stochastic state transitions. Having highlighted the limitations of value-based model-free MORL methods, we discuss several alternative methods that may be more suitable for maximising SER in MOMDPs with stochastic transitions.},
  archive      = {J_NCA},
  author       = {Vamplew, Peter and Foale, Cameron and Dazeley, Richard},
  doi          = {10.1007/s00521-021-05859-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1783-1799},
  shortjournal = {Neural Comput. Appl.},
  title        = {The impact of environmental stochasticity on value-based multiobjective reinforcement learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Opponent learning awareness and modelling in multi-objective
normal form games. <em>NCA</em>, <em>34</em>(3), 1759–1781. (<a
href="https://doi.org/10.1007/s00521-021-06184-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world multi-agent interactions consider multiple distinct criteria, i.e. the payoffs are multi-objective in nature. However, the same multi-objective payoff vector may lead to different utilities for each participant. Therefore, it is essential for an agent to learn about the behaviour of other agents in the system. In this work, we present the first study of the effects of such opponent modelling on multi-objective multi-agent interactions with nonlinear utilities. Specifically, we consider two-player multi-objective normal form games with nonlinear utility functions under the scalarised expected returns optimisation criterion. We contribute novel actor-critic and policy gradient formulations to allow reinforcement learning of mixed strategies in this setting, along with extensions that incorporate opponent policy reconstruction and learning with opponent learning awareness (i.e. learning while considering the impact of one’s policy when anticipating the opponent’s learning step). Empirical results in five different MONFGs demonstrate that opponent learning awareness and modelling can drastically alter the learning dynamics in this setting. When equilibria are present, opponent modelling can confer significant benefits on agents that implement it. When there are no Nash equilibria, opponent learning awareness and modelling allows agents to still converge to meaningful solutions that approximate equilibria.},
  archive      = {J_NCA},
  author       = {Rădulescu, Roxana and Verstraeten, Timothy and Zhang, Yijie and Mannion, Patrick and Roijers, Diederik M. and Nowé, Ann},
  doi          = {10.1007/s00521-021-06184-3},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1759-1781},
  shortjournal = {Neural Comput. Appl.},
  title        = {Opponent learning awareness and modelling in multi-objective normal form games},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scalable multi-product inventory control with lead time
constraints using reinforcement learning. <em>NCA</em>, <em>34</em>(3),
1735–1757. (<a
href="https://doi.org/10.1007/s00521-021-06129-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining optimum inventory replenishment decisions are critical for retail businesses with uncertain demand. The problem becomes particularly challenging when multiple products with different lead times and cross-product constraints are considered. This paper addresses the aforementioned challenges in multi-product, multi-period inventory management using deep reinforcement learning (deep RL). The proposed approach improves upon existing methods for inventory control on three fronts: (1) concurrent inventory management of a large number (hundreds) of products under realistic constraints, (2) minimal retraining requirements on the RL agent under system changes through the definition of an individual product meta-model, (3) efficient handling of multi-period constraints that stem from different lead times of different products. We approach the inventory problem as a special class of dynamical system control, and explain why the generic problem cannot be satisfactorily solved using classical optimisation techniques. Subsequently, we formulate the problem in a general framework that can be used for parallelised decision-making using off-the-shelf RL algorithms. We also benchmark the formulation against the theoretical optimum achieved by linear programming under the assumptions that the demands are deterministic and known apriori. Experiments on scales between 100 and 220 products show that the proposed RL-based approaches perform better than the baseline heuristics, and quite close to the theoretical optimum. Furthermore, they are also able to transfer learning without retraining to inventory control problems involving different number of products.},
  archive      = {J_NCA},
  author       = {Meisheri, Hardik and Sultana, Nazneen N. and Baranwal, Mayank and Baniwal, Vinita and Nath, Somjit and Verma, Satyam and Ravindran, Balaraman and Khadilkar, Harshad},
  doi          = {10.1007/s00521-021-06129-w},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1735-1757},
  shortjournal = {Neural Comput. Appl.},
  title        = {Scalable multi-product inventory control with lead time constraints using reinforcement learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discrete-to-deep reinforcement learning methods.
<em>NCA</em>, <em>34</em>(3), 1713–1733. (<a
href="https://doi.org/10.1007/s00521-021-06270-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks are effective function approximators, but hard to train in the reinforcement learning (RL) context mainly because samples are correlated. In complex problems, a neural RL approach is often able to learn a better solution than tabular RL, but generally takes longer. This paper proposes two methods, Discrete-to-Deep Supervised Policy Learning (D2D-SPL) and Discrete-to-Deep Supervised Q-value Learning (D2D-SQL), whose objective is to acquire the generalisability of a neural network at a cost nearer to that of a tabular method. Both methods combine RL and supervised learning (SL) and are based on the idea that a fast-learning tabular method can generate off-policy data to accelerate learning in neural RL. D2D-SPL uses the data to train a classifier which is then used as a controller for the RL problem. D2D-SQL uses the data to initialise a neural network which is then allowed to continue learning using another RL method. We demonstrate the viability of our algorithms with Cartpole, Lunar Lander and an aircraft manoeuvring problem, three continuous-space environments with low-dimensional state variables. Both methods learn at least 38\% faster than baseline methods and yield policies that outperform them.},
  archive      = {J_NCA},
  author       = {Kurniawan, Budi and Vamplew, Peter and Papasimeon, Michael and Dazeley, Richard and Foale, Cameron},
  doi          = {10.1007/s00521-021-06270-6},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1713-1733},
  shortjournal = {Neural Comput. Appl.},
  title        = {Discrete-to-deep reinforcement learning methods},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lucid dreaming for experience replay: Refreshing past states
with the current policy. <em>NCA</em>, <em>34</em>(3), 1687–1712. (<a
href="https://doi.org/10.1007/s00521-021-06104-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experience replay (ER) improves the data efficiency of off-policy reinforcement learning (RL) algorithms by allowing an agent to store and reuse its past experiences in a replay buffer. While many techniques have been proposed to enhance ER by biasing how experiences are sampled from the buffer, thus far they have not considered strategies for refreshing experiences inside the buffer. In this work, we introduce L uc i d D reaming for E xperience R eplay (LiDER), a conceptually new framework that allows replay experiences to be refreshed by leveraging the agent’s current policy. LiDER consists of three steps: First, LiDER moves an agent back to a past state. Second, from that state, LiDER then lets the agent execute a sequence of actions by following its current policy—as if the agent were “dreaming” about the past and can try out different behaviors to encounter new experiences in the dream. Third, LiDER stores and reuses the new experience if it turned out better than what the agent previously experienced, i.e., to refresh its memories. LiDER is designed to be easily incorporated into off-policy, multi-worker RL algorithms that use ER; we present in this work a case study of applying LiDER to an actor–critic-based algorithm. Results show LiDER consistently improves performance over the baseline in six Atari 2600 games. Our open-source implementation of LiDER and the data used to generate all plots in this work are available at https://github.com/duyunshu/lucid-dreaming-for-exp-replay .},
  archive      = {J_NCA},
  author       = {Du, Yunshu and Warnell, Garrett and Gebremedhin, Assefaw and Stone, Peter and Taylor, Matthew E.},
  doi          = {10.1007/s00521-021-06104-5},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1687-1712},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lucid dreaming for experience replay: Refreshing past states with the current policy},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Policy invariant explicit shaping: An efficient alternative
to reward shaping. <em>NCA</em>, <em>34</em>(3), 1673–1686. (<a
href="https://doi.org/10.1007/s00521-021-06259-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) is a powerful learning paradigm in which agents can learn to maximize sparse and delayed reward signals. Although RL has had many impressive successes in complex domains, learning can take hours, days, or even years of training data. A major challenge of contemporary RL research is to discover how to learn with less data. Previous work has shown that domain information can be successfully used to shape the reward; by adding additional reward information, the agent can learn with much less data. Furthermore, if the reward is constructed from a potential function, the optimal policy is guaranteed to be unaltered. While such potential-based reward shaping (PBRS) holds promise, it is limited by the need for a well-defined potential function. Ideally, we would like to be able to take arbitrary advice from a human or other agent and improve performance without affecting the optimal policy. The recently introduced dynamic potential-based advice (DPBA) was proposed to tackle this challenge by predicting the potential function values as part of the learning process. However, this article demonstrates theoretically and empirically that, while DPBA can facilitate learning with good advice, it does in fact alter the optimal policy. We further show that when adding the correction term to “fix” DPBA it no longer shows effective shaping with good advice. We then present a simple method called policy invariant explicit shaping (PIES) and show theoretically and empirically that PIES can use arbitrary advice, speed-up learning, and leave the optimal policy unchanged.},
  archive      = {J_NCA},
  author       = {Behboudian, Paniz and Satsangi, Yash and Taylor, Matthew E. and Harutyunyan, Anna and Bowling, Michael},
  doi          = {10.1007/s00521-021-06259-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1673-1686},
  shortjournal = {Neural Comput. Appl.},
  title        = {Policy invariant explicit shaping: An efficient alternative to reward shaping},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamical systems as a level of cognitive analysis of
multi-agent learning. <em>NCA</em>, <em>34</em>(3), 1653–1671. (<a
href="https://doi.org/10.1007/s00521-021-06117-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A dynamical systems perspective on multi-agent learning, based on the link between evolutionary game theory and reinforcement learning, provides an improved, qualitative understanding of the emerging collective learning dynamics. However, confusion exists with respect to how this dynamical systems account of multi-agent learning should be interpreted. In this article, I propose to embed the dynamical systems description of multi-agent learning into different abstraction levels of cognitive analysis. The purpose of this work is to make the connections between these levels explicit in order to gain improved insight into multi-agent learning. I demonstrate the usefulness of this framework with the general and widespread class of temporal-difference reinforcement learning. I find that its deterministic dynamical systems description follows a minimum free-energy principle and unifies a boundedly rational account of game theory with decision-making under uncertainty. I then propose an on-line sample-batch temporal-difference algorithm which is characterized by the combination of applying a memory-batch and separated state-action value estimation. I find that this algorithm serves as a micro-foundation of the deterministic learning equations by showing that its learning trajectories approach the ones of the deterministic learning equations under large batch sizes. Ultimately, this framework of embedding a dynamical systems description into different abstraction levels gives guidance on how to unleash the full potential of the dynamical systems approach to multi-agent learning.},
  archive      = {J_NCA},
  author       = {Barfuss, Wolfram},
  doi          = {10.1007/s00521-021-06117-0},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1653-1671},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamical systems as a level of cognitive analysis of multi-agent learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on adaptive and learning agents 2020.
<em>NCA</em>, <em>34</em>(3), 1649–1651. (<a
href="https://doi.org/10.1007/s00521-021-06593-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {da Silva, Felipe Leno and MacAlpine, Patrick and Rădulescu, Roxana and Santos, Fernando P. and Mannion, Patrick},
  doi          = {10.1007/s00521-021-06593-4},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {1649-1651},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on adaptive and learning agents 2020},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A convolutional recursive deep architecture for
unconstrained urdu handwriting recognition. <em>NCA</em>,
<em>34</em>(2), 1635–1648. (<a
href="https://doi.org/10.1007/s00521-021-06498-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An offline handwriting recognition system for Urdu, a language with a user base of 200 Million and written in Nastaleeq script, has been a challenge for the research community. The key problems include recognition of complex ligature shapes and lack of publicly available datasets. This paper addresses both these problems by (i) proposing an end-to-end handwriting recognition system based on a new CNN-RNN architecture with n-gram language modeling, and (ii) presenting a new unconstrained dataset called NUST-UHWR. We compiled the first unconstrained Urdu handwritten data from around 1000 people from diverse background, age and gender population. The text in this dataset is selected carefully from seven different fields to ensure the presence of commonly used words in different domains. The model architecture is capable of incorporating fine-grained features necessary for handwritten text recognition of complex ligature languages. Our method addresses the limitations of existing architectures and provides state-of-the-art performance on Urdu handwritten text. We achieve a minimum character error rate of 5.28\% on Urdu handwriting recognition (UHWR) and establish a state-of-the-art. The paper further demonstrates the generalization ability of the proposed model by training on English language and bilingual (Urdu and English) handwritten data.},
  archive      = {J_NCA},
  author       = {ul Sehr Zia, Noor and Naeem, Muhammad Ferjad and Raza, Syed Muhammad Kumail and Khan, Muhammad Mubasher and Ul-Hasan, Adnan and Shafait, Faisal},
  doi          = {10.1007/s00521-021-06498-2},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1635-1648},
  shortjournal = {Neural Comput. Appl.},
  title        = {A convolutional recursive deep architecture for unconstrained urdu handwriting recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Multi-features guidance network for partial-to-partial
point cloud registration. <em>NCA</em>, <em>34</em>(2), 1623–1634. (<a
href="https://doi.org/10.1007/s00521-021-06464-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent extraction of hybrid features improves point cloud registration performance by emphasizing more integrated information. However, hybrid features ignore the large dimensional differences, big semantic gaps, and mutual interference between the shape features and spatial coordinates. This paper proposes a novel Multi-Features Guidance Network (MFGNet) for partial-to-partial point cloud registration to overcome the intrinsic flaws of hybrid features, which leverages the shape features and the spatial coordinates to account for correspondences searching independently. The proposed network mainly includes four parts: keypoints’ feature extraction, correspondences search, correspondences credibility computation, and singular value decomposition (SVD), among which correspondences search and correspondences credibility computation are the cores of the network. Specifically, the correspondences search module utilizes the shape features and the spatial coordinates to guide correspondences matching independently and fusing the matching results to obtain the final matching matrix. Moreover, based on the conflicted relationship between the two matching matrices, the correspondences credibility computation module scores each correspondence pair’s reliability, which can reduce the impact of mismatched or non-matched points significantly. Empirical experiments on the ModelNet40 dataset validate the effectiveness of the proposed MFGNet, which achieves 0.19 $$^\circ$$ , 0.24 $$^\circ$$ and 1.3 $$^\circ$$ mean absolute errors for rotation matrix and 0.0010, 0.0011, and 0.0068 mean absolute errors for translation vectors, respectively, under the settings of unseen point clouds, unseen categories, and Gaussian noise.},
  archive      = {J_NCA},
  author       = {Wang, Hongyuan and Liu, Xiang and Kang, Wen and Yan, Zhiqiang and Wang, Bingwen and Ning, Qianhao},
  doi          = {10.1007/s00521-021-06464-y},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1623-1634},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-features guidance network for partial-to-partial point cloud registration},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A weighted ensemble classifier based on WOA for
classification of diabetes. <em>NCA</em>, <em>34</em>(2), 1613–1621. (<a
href="https://doi.org/10.1007/s00521-021-06481-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the threat and increasing trend to diabetes, different approaches to diagnose it have been proposed, so that classification is one of the main techniques. In this article ultimate aim is designing a novel system to diagnose diabetes. To this end, we use an ensemble classifier to apply support vector machine (SVM), k-nearest neighbor (KNN), and whale optimization algorithm (WOA). WOA is responsible for generating weights for each classifier to improve the accuracy of the diabetes classification. For our empirical study, we gathered a dataset of diabetes from medical centers in Iran. The implementation results showed that the designed ensemble classifier achieved the accuracy rate of 83\%, which means it improved the accuracy of the best preceding classifier about 5\%. Moreover, the designed ensemble classifier based on WOA improved the accuracy about 1\% in comparison with PSO that is preceding the WOA in terms of accuracy level.},
  archive      = {J_NCA},
  author       = {Khademi, Fatemeh and Rabbani, Mohsen and Motameni, Homayun and Akbari, Ebrahim},
  doi          = {10.1007/s00521-021-06481-x},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1613-1621},
  shortjournal = {Neural Comput. Appl.},
  title        = {A weighted ensemble classifier based on WOA for classification of diabetes},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NER2QUES: Combining named entity recognition and sequence to
sequence to automatically generating vietnamese questions. <em>NCA</em>,
<em>34</em>(2), 1593–1612. (<a
href="https://doi.org/10.1007/s00521-021-06477-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) is an important task in natural language processing. NER is usually used to classify documents, extract information, and translate languages. However, few studies have used NER types to automatically generate questions. In this paper, we proposed a method named NER2QUES to solve the above problem for a low-resource language such as Vietnamese. NER2QUES was the combining pre-trained language model and sequence-to-sequence model. Specifically, we used BERT to detect NERs in a sentence and then applied a sequence-to-sequence model to automatically generate questions that corresponded to NER’s types. We compared the accuracy of the proposed method to PhoBERT and spaCy on the NER task. Also, we used F1, BLEU, ROUGE, and METEOR to measure the effectiveness of this approach with the rules-based method, T5, and BERT on question generation tasks. The experiment results show that the accuracy of our method is more improved than previous methods’ accuracy of 94\% on SQuAD, 89\% on XQuAD, and 95\% on MLQA. This indicates that using NER to automatically generate questions may enrich question answering systems.},
  archive      = {J_NCA},
  author       = {Phan, Truong H. V. and Do, Phuc},
  doi          = {10.1007/s00521-021-06477-7},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1593-1612},
  shortjournal = {Neural Comput. Appl.},
  title        = {NER2QUES: Combining named entity recognition and sequence to sequence to automatically generating vietnamese questions},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive kernel selection network with attention constraint
for surgical instrument classification. <em>NCA</em>, <em>34</em>(2),
1577–1591. (<a
href="https://doi.org/10.1007/s00521-021-06368-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision (CV) technologies are assisting the health care industry in many respects, i.e., disease diagnosis. However, as a pivotal procedure before and after surgery, the inventory work of surgical instruments has not been researched with the CV-powered technologies. To reduce the risk and hazard of surgical tools’ loss, we propose a study of systematic surgical instrument classification and introduce a novel attention-based deep neural network called SKA-ResNet which is mainly composed of: (a) A feature extractor with selective kernel attention module to automatically adjust the receptive fields of neurons and enhance the learnt expression and (b) A multi-scale regularizer with KL-divergence as the constraint to exploit the relationships between feature maps. Our method is easily trained end-to-end in only one stage with few additional calculation burdens. Moreover, to facilitate our study, we create a new surgical instrument dataset called SID19 (with 19 kinds of surgical tools consisting of 3800 images) for the first time. Experimental results show the superiority of SKA-ResNet for the classification of surgical tools on SID19 when compared with state-of-the-art models. The classification accuracy of our method reaches up to 97.703\%, which is well supportive for the inventory and recognition study of surgical tools. Also, our method can achieve state-of-the-art performance on four challenging fine-grained visual classification datasets.},
  archive      = {J_NCA},
  author       = {Hou, Yaqing and Zhang, Wenkai and Liu, Qian and Ge, Hongwei and Meng, Jun and Zhang, Qiang and Wei, Xiaopeng},
  doi          = {10.1007/s00521-021-06368-x},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1577-1591},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive kernel selection network with attention constraint for surgical instrument classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A parallel NAW-DBLSTM algorithm on spark for traffic flow
forecasting. <em>NCA</em>, <em>34</em>(2), 1557–1575. (<a
href="https://doi.org/10.1007/s00521-021-06409-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow forecasting (TFF) is critical for constructing intelligent transportation systems and offering real-time traffic applications, and especially accurate flow forecasting based on traffic big data can drive reliable strategies for traffic management and control. To consider the weight of the influence of the spatial correlation among the road segments and capture the nonlinear characteristics of traffic flow, this paper presents a parallel Normal Distribution and Attention Mechanism Weighted Deep Bidirectional Long Short-Term Memory (NAW-DBLSTM) algorithm on Spark. Specifically, we employ the resilient distributed data set (RDD) to preprocess large-scale mobile trajectory data (e.g., taxi GPS trajectory data), and then Kalman Filter (KF) is utilized to smooth the taxi trajectory big data. Next, the parallel NAW-DBLSTM algorithm is put forward on a Spark distributed computing platform to enhance the accuracy and scalability of TFF, combined with the attention mechanism and the normal distribution, and then the time window is used for TFF. Finally, the traffic flow is forecasted successfully on Spark by our NAW-DBLSTM algorithm with the real-world GPS trajectories of taxicabs. The experimental results demonstrate that, compared with LSTM, BiLSTM, DBLSTM, DNN, SVR, KNN, SAEs, BP, CNN, GRU, and ANNs, NAW-DBLSTM can produce better performance with the MAPE value that is 85.1\%, 80.1\%, 85.8\%, 73.1\%, 78.2\%, 77.9\%, 78.8\%, 84.6\%, 96.4\%, 86.2\%, and 73.2\% lower than that of comparable algorithms, respectively. Particularly, the MAPE value of NAW-DBLSTM is 28.3\%, 20.1\%, 71.1\%, and 79.1\% lower than that of LSTM weighted with the normal distribution and the attention mechanism (NAW-LSTM), BiLSTM weighted with the normal distribution and the attention mechanism (NAW-BiLSTM), DBLSTM weighted with the normal distribution (NW-DBLSTM), and NAW-DBLSTM weighted without the time window (NT-NAW-DBLSTM), respectively.},
  archive      = {J_NCA},
  author       = {Xia, Dawen and Yang, Nan and Jiang, Shunying and Hu, Yang and Li, Yantao and Li, Huaqing and Wang, Lin},
  doi          = {10.1007/s00521-021-06409-5},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1557-1575},
  shortjournal = {Neural Comput. Appl.},
  title        = {A parallel NAW-DBLSTM algorithm on spark for traffic flow forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Failure assessment of defected pipe under strike-slip fault
with data-driven models accounting for the model uncertainty.
<em>NCA</em>, <em>34</em>(2), 1541–1555. (<a
href="https://doi.org/10.1007/s00521-021-06497-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Buried pipeline is threatened from the soil displacement due to earthquake and other causes, which leads to the formation of unexpected external forces such as bending moment. The problem can be worse with the appearance of defects, resulting in the reduction in pipe capacity. The paper focuses on the overall problem of defected pipe crossing the strike-slip fault. A full-scaled FE model can be very complicated with the large-scale and micro-scale levels corresponding to the strike-slip fault and defect on pipe problems, respectively. To ease this difficulty, the macro and micro problems are solved separately with two types of FE models and their corresponding databases. To be specific, one FE model is used for predicting external moment due to strike-slip fault and the other is for predicting the moment capacity of defected pipe. Data-driven models are consequently developed with artificial neural network (ANN) for each database generated from these types of models: ANN1 evaluating moment capacity of defected pipe (R2 is 0.9943 on test set) and ANN2 predicting both moment and axial force appeared in pipe due to strike-slip fault (R-squares are 0.9883 and 0.9929 on test set, respectively). Consequently, the stress–strength analysis for the overall problem is solved. Accounting for the unavoidable uncertainty of the models, the paper proposed an approach which assumes that the actual distribution of residual of a model is equivalent to this of the test set. The distributions of residuals on test set of these ANNs are tested to be normally distributed and generated by the conventional Monte Carlo simulation. To the end, the deterministic problem leads to the failure probability. The proposed framework has been investigated, and the final results on this selective parametric study are reasonable.},
  archive      = {J_NCA},
  author       = {Phan, Hieu Chi and Bui, Nang Duc},
  doi          = {10.1007/s00521-021-06497-3},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1541-1555},
  shortjournal = {Neural Comput. Appl.},
  title        = {Failure assessment of defected pipe under strike-slip fault with data-driven models accounting for the model uncertainty},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An unbiased monte carlo method to solve linear volterra
equations of the second kind. <em>NCA</em>, <em>34</em>(2), 1527–1540.
(<a href="https://doi.org/10.1007/s00521-021-06417-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In previous works (Dimov and Maire in Adv Comput Math 45(3):1499–1519, 2019; Dimov et al. in Appl Math Model 39(15):4494–4510, https://doi.org/10.1016/j.apm.2014.12.018 , 2015), we have developed two Monte Carlo algorithms to solve linear systems and Fredholm integral equations of the second kind. These algorithms rely on the computation of a score along a discrete or continuous homogeneous Markov chain until absorption. Here, we propose two approaches to extend the Fredholm algorithm to Volterra equations. The first one is based on a change in variable at each step of the Markov chain. The second one uses the indicator function to transform the Volterra equation into an appropriate form. The resulting Markov chains are inhomogeneous with an increasing absorption rate. The convergence is ensured as soon as the Volterra kernel is bounded. Numerical examples are given on basic reference problems and on high dimensional test cases up to 100 dimensions.},
  archive      = {J_NCA},
  author       = {Dimov, Ivan and Maire, Sylvain and Todorov, Venelin},
  doi          = {10.1007/s00521-021-06417-5},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1527-1540},
  shortjournal = {Neural Comput. Appl.},
  title        = {An unbiased monte carlo method to solve linear volterra equations of the second kind},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A simple and efficient rainfall–runoff model based on
supervised brain emotional learning. <em>NCA</em>, <em>34</em>(2),
1509–1526. (<a
href="https://doi.org/10.1007/s00521-021-06475-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve a robust data-driven flood forecasting model, features such as fast learning, appropriate training using insufficient data and reliable prediction of flood flows are of essential importance. These models also have notable vulnerabilities such as decreased accuracy in forecasting peak discharges, challenging simulation of rainy events, performance deterioration in confronting with inadequate training data and weakness due to reduced number of training epochs. In this paper, the supervised brain emotional learning (SBEL) neural network has been used in daily rainfall–runoff modeling of the Dez Dam watershed in the southwest of Iran, as its first application in the field of hydrology. SBEL is a supervised neurocomputing model inspired by the limbic system in the mammalian brain. To create the right responses, the SBEL models the processing of emotional stimuli and the inhibitory mechanism of incorrect responses to stimuli in the emotional brain. The performance of SBEL was compared to the well-known multilayer perceptron (MLP) with 15–8–1 architecture, through different perspectives. The SBEL outperforms MLP in peak flow prediction, limiting the training epochs, reducing the training samples and predictions of rainy events, while improving the mean relative error by 21\%, 59.4\%, 74.5\% and 14.4\%, respectively. By placing reduced training data in dry, normal and wet periods, it has been observed that SBEL has more generalization ability in all flow regimes. Overall, the use of this type of emotional intelligence-based model can be of particular interest in developing reliable early flood forecasting and warning systems.},
  archive      = {J_NCA},
  author       = {Parvinizadeh, Sara and Zakermoshfegh, Mohammad and Shakiba, Maryam},
  doi          = {10.1007/s00521-021-06475-9},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1509-1526},
  shortjournal = {Neural Comput. Appl.},
  title        = {A simple and efficient rainfall–runoff model based on supervised brain emotional learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contextual anomaly detection on time series: A case study of
metro ridership analysis. <em>NCA</em>, <em>34</em>(2), 1483–1507. (<a
href="https://doi.org/10.1007/s00521-021-06455-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increase in the amount of data collected in the transport domain can greatly benefit mobility studies and create high value-added mobility information for passengers, data analysts, and transport operators. This work concerns the detection of the impact of disturbances on a transport network. It aims, from smart card data analysis, to finely quantify the impacts of known disturbances on the transportation network usage and to reveal unexplained statistical anomalies that may be related to unknown disturbances. The mobility data studied take the form of a multivariate time series evolving in a dynamic environment with additional contextual attributes. The research mainly focuses on contextual anomaly detection using machine learning models. Our main goal is to build a robust anomaly score to highlight statistical anomalies (contextual extremums), considering the variability within the time series induced by the dynamic context. The robust anomaly score is built from normalized forecasting residuals. The normalization of the residuals is carried out using the estimated contextual variance. Indeed, there are complex dynamics on both the mean and the variance in the ridership time series induced by the flexible transportation schedule, the variability in transport demand, and contextual factors such as the station location and the calendar information. Therefore, they should be considered by the anomaly detection approach to obtain a reliable anomaly score. We investigate several prediction models (including an LSTM encoder–decoder of the recurrent neural network deep learning family) and several variance estimators obtained through dedicated models or extracted from prediction models. The proposed approaches are evaluated on synthetic data and real data from the smart card riderships of the Quebec Metro network. It includes a basis of events and disturbances that have impacted the transport network. The experiments show the relevance of variance normalization on prediction residuals to build a robust anomaly score under a dynamic context.},
  archive      = {J_NCA},
  author       = {Pasini, Kevin and Khouadjia, Mostepha and Samé, Allou and Trépanier, Martin and Oukhellou, Latifa},
  doi          = {10.1007/s00521-021-06455-z},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1483-1507},
  shortjournal = {Neural Comput. Appl.},
  title        = {Contextual anomaly detection on time series: A case study of metro ridership analysis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A dual-stream fused neural network for fall detection in
multi-camera and <span class="math display">360<sup>∘</sup></span>
videos. <em>NCA</em>, <em>34</em>(2), 1455–1482. (<a
href="https://doi.org/10.1007/s00521-021-06495-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Globally, human falls are the second leading cause of deaths induced due to unintentional injuries. These fatalities, in most cases, arise due to a lack of timely medication. Therefore, over the years, there has been an immense demand for systems that can quickly send fall-related information to the caretakers so that the medical relief team can reach on time. The traditional schemes for fall detection using wearable sensors such as accelerometers, gyroscopes, etc., are highly intrusive and generate high false positives in real-world conditions. Consequently, the current research directions in this domain have been toward harnessing the availability of low-cost vision sensors and the power of deep learning. To this end, in this work, we present a dual-stream fused neural network (DSFNN) for fall detection in multi-camera and $$360^{\circ }$$ video streams. The DSFNN model learns to extract spatial-temporal information using two neural networks, trained independently on the RGB video sequences of fall and non-fall activities and their corresponding single dynamic images. Once trained, the model fuses the prediction scores of the two neural networks using a weighted fusion scheme to obtain the final decision. We assessed the performance of the proposed DSFNN on two multi-camera fall datasets, namely UP-Fall and URFD, and on a new in-house $$360^{\circ }$$ video dataset of fall and non-fall activities. The evaluation results in terms of different performance metrics demonstrated the superiority of the proposed fall detection scheme. The framework achieved superior performance and outperformed the previous state-of-the-art fall detection methods. For further research and analysis in the fall detection domain, we will make the source code and the in-house fall dataset available to the research community on request.},
  archive      = {J_NCA},
  author       = {Saurav, Sumeet and Saini, Ravi and Singh, Sanjay},
  doi          = {10.1007/s00521-021-06495-5},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1455-1482},
  shortjournal = {Neural Comput. Appl.},
  title        = {A dual-stream fused neural network for fall detection in multi-camera and $$360^{\circ }$$ videos},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parkinson’s disease diagnosis using convolutional neural
networks and figure-copying tasks. <em>NCA</em>, <em>34</em>(2),
1433–1453. (<a
href="https://doi.org/10.1007/s00521-021-06469-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is a progressive neurodegenerative disorder that causes abnormal movements and an array of other symptoms. An accurate PD diagnosis can be a challenging task as the signs and symptoms, particularly at an early stage, can be similar to other medical conditions or the physiological changes of normal ageing. This work aims to contribute to the PD diagnosis process by using a convolutional neural network, a type of deep neural network architecture, to differentiate between healthy controls and PD patients. Our approach focuses on discovering deviations in patient’s movements with the use of drawing tasks. In addition, this work explores which of two drawing tasks, wire cube or spiral pentagon, are more effective in the discrimination process. With $$93.5\%$$ accuracy, our convolutional classifier, trained with images of the pentagon drawing task and augmentation techniques, can be used as an objective method to discriminate PD from healthy controls. Our compact model has the potential to be developed into an offline real-time automated single-task diagnostic tool, which can be easily deployed within a clinical setting.},
  archive      = {J_NCA},
  author       = {Alissa, Mohamad and Lones, Michael A. and Cosgrove, Jeremy and Alty, Jane E. and Jamieson, Stuart and Smith, Stephen L. and Vallejo, Marta},
  doi          = {10.1007/s00521-021-06469-7},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1433-1453},
  shortjournal = {Neural Comput. Appl.},
  title        = {Parkinson’s disease diagnosis using convolutional neural networks and figure-copying tasks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection of invisible cracks in ceramic materials using by
pre-trained deep convolutional neural network. <em>NCA</em>,
<em>34</em>(2), 1423–1432. (<a
href="https://doi.org/10.1007/s00521-021-06652-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ceramic materials are an indispensable part of our lives. Today, ceramic materials are mainly used in construction and kitchenware production. The fact that some deformations cannot be seen with the naked eye in the ceramic industry leads to a loss of time in the detection of deformations in the products. Delays that may occur in the elimination of deformations and in the planning of the production process cause the products with deformation to be excessive, which adversely affects the quality. In this study, a deep learning model based on acoustic noise data and transfer learning techniques was designed to detect cracks in ceramic plates. In order to create a data set, noise curves were obtained by applying the same magnitude impact to the ceramic experiment plates by impact pendulum. For experimental application, ceramic plates with three invisible cracks and one undamaged ceramic plate were used. The deep learning model was trained and tested for crack detection in ceramic plates by the data set obtained from the noise graphs. As a result, 99.50\% accuracy was achieved with the deep learning model based on acoustic noise.},
  archive      = {J_NCA},
  author       = {Nogay, Hidir Selcuk and Akinci, Tahir Cetin and Yilmaz, Musa},
  doi          = {10.1007/s00521-021-06652-w},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1423-1432},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection of invisible cracks in ceramic materials using by pre-trained deep convolutional neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deeper multi-column dilated convolutional network for
congested crowd understanding. <em>NCA</em>, <em>34</em>(2), 1407–1422.
(<a href="https://doi.org/10.1007/s00521-021-06458-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In highly congested crowd scenes, it is hard to generate high-quality density maps because the crowd and background are highly mixed such that it is difficult to distinguish them. To alleviate the issue, this paper presents a deeper multi-column dilated convolutional network (DMDCNet) method, which is capable of extracting sufficient semantic features for crowd understanding in highly congested crowd scenes. In DMDCNet, there are two modules: feature extractor and density map estimator. Feature extractor is a VGG-16-based convolutional neural network (CNN), which is able to extract low-level features contained in crowd images. Density map estimator is designed as a multi-column structure of dilated convolutional neural networks (DCNNs) to further extract the deeper information and capture multi-scale contextual information, which could generate high-quality density maps from the input images. Furthermore, multi-column DCNNs in DMDCNet can effectively alleviate the “gridding” problem caused by the dilated convolution framework. Extensive experiments on several commonly used benchmark datasets are conducted to demonstrate the proposed DMDCNet, which shows that DMDCNet is comparable with the recent state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Yan, Leilei and Zhang, Li and Zheng, Xiaohan and Li, Fanzhang},
  doi          = {10.1007/s00521-021-06458-w},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1407-1422},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deeper multi-column dilated convolutional network for congested crowd understanding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved sine cosine algorithm with simulated annealing and
singer chaotic map for hadith classification. <em>NCA</em>,
<em>34</em>(2), 1385–1406. (<a
href="https://doi.org/10.1007/s00521-021-06448-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) represents an important task in classification. Hadith represents an example in which we can apply FS on it. Hadiths are the second major source of Islam after the Quran. Thousands of Hadiths are available in Islam, and these Hadiths are grouped into a number of classes. In the literature, there are many studies conducted for Hadiths classification. Sine Cosine Algorithm (SCA) is a new metaheuristic optimization algorithm. SCA algorithm is mainly based on exploring the search space using sine and cosine mathematical formulas to find the optimal solution. However, SCA, like other Optimization Algorithm (OA), suffers from the problem of local optima and solution diversity. In this paper, to overcome SCA problems and use it for the FS problem, two major improvements were introduced to the standard SCA algorithm. The first improvement includes the use of singer chaotic map within SCA to improve solutions diversity. The second improvement includes the use of the Simulated Annealing (SA) algorithm as a local search operator within SCA to improve its exploitation. In addition, the Gini Index (GI) is used to filter the resulted selected features to reduce the number of features to be explored by SCA. Furthermore, three new Hadith datasets were created. To evaluate the proposed Improved SCA (ISCA), the new three Hadiths datasets were used in our experiments. Furthermore, to confirm the generality of ISCA, we also applied it on 14 benchmark datasets from the UCI repository. The ISCA results were compared with the original SCA and the state-of-the-art algorithms such as Particle Swarm Optimization (PSO), Genetic Algorithm (GA), Grasshopper Optimization Algorithm (GOA), and the most recent optimization algorithm, Harris Hawks Optimizer (HHO). The obtained results confirm the clear outperformance of ISCA in comparison with other optimization algorithms and Hadith classification baseline works. From the obtained results, it is inferred that ISCA can simultaneously improve the classification accuracy while it selects the most informative features.},
  archive      = {J_NCA},
  author       = {Tubishat, Mohammad and Ja’afar, Salinah and Idris, Norisma and Al-Betar, Mohammed Azmi and Alswaitti, Mohammed and Jarrah, Hazim and Ismail, Maizatul Akmar and Omar, Mardian Shah},
  doi          = {10.1007/s00521-021-06448-y},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1385-1406},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved sine cosine algorithm with simulated annealing and singer chaotic map for hadith classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A fuzzy decision-making approach to analyze the design
principles for green ergonomics. <em>NCA</em>, <em>34</em>(2),
1373–1384. (<a
href="https://doi.org/10.1007/s00521-021-06494-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green ergonomics reflects on the bi-directional interaction between natural and human structures to ensure the well-being and efficacy of human and social systems. The concept of green ergonomics involves a number of principles, whose importance has become increasingly recognized in recent years. The green ergonomics compliance degree of a company is strongly related to how closely it adheres to these principles. Thus, the main objective of this study was to determine which of these principles and sub-principles take priority. Understanding them can only be achieved by determining their relative importance with respect to each other. For this prioritization, the study utilized the hesitant fuzzy analytic hierarchy process as one of the multi-criteria decision-making approaches to calculate the weight of the green ergonomics framework principles. The hesitant fuzzy linguistic term set approach was adopted to develop especially for the cases where experts hesitate during the decision-making process. With the participation of three experts, this paper determined the most critical principle to be “acknowledge how natural systems value design.” The findings of this study can be utilized in a number of ways, such as helping company managers to formulate green ergonomics strategies, presenting a guideline for companies and raising awareness about the relationship between green ergonomics and sustainability.},
  archive      = {J_NCA},
  author       = {Adem, Aylin and Çakıt, Erman and Dağdeviren, Metin},
  doi          = {10.1007/s00521-021-06494-6},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1373-1384},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fuzzy decision-making approach to analyze the design principles for green ergonomics},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiple classifier for concatenate-designed neural network.
<em>NCA</em>, <em>34</em>(2), 1359–1372. (<a
href="https://doi.org/10.1007/s00521-021-06462-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a multiple classifier method to improve the performance of concatenate-designed neural networks, such as ResNet and DenseNet, with the purpose of alleviating the pressure on the final classifier. We give the design of the classifiers, which collects the features produced between the network sets, and present the constituent layers and the activation function for the classifiers, to calculate the classification score of each classifier. We use the $$L2 \left( \sqrt{e^x}\right)$$ normalization method to obtain the classifier score instead of the $$Softmax$$ normalization. We also determine the conditions that can enhance convergence. As a result, the proposed classifiers are able to improve the accuracy in the experimental cases significantly and show that the method not only has better performance than the original models, but also produces faster convergence. Moreover, our classifiers are general and can be applied to all classification related concatenate-designed network models.},
  archive      = {J_NCA},
  author       = {Chan, Ka-Hou and Im, Sio-Kei and Ke, Wei},
  doi          = {10.1007/s00521-021-06462-0},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1359-1372},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multiple classifier for concatenate-designed neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective lyapunov-based controller design for
nonlinear systems via genetic programming. <em>NCA</em>, <em>34</em>(2),
1345–1357. (<a
href="https://doi.org/10.1007/s00521-021-06453-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In system control, stability is considered the most important factor as unstable system is impractical or dangerous to use. Lyapunov direct method, one of the most useful tools in the stability analysis of nonlinear systems, enables the design of a controller by determining the region of attraction (ROA). However, the two main challenges posed are—(1) it is hard to determine the scalar function referred to as Lyapunov function, and (2) the optimality of the designed controller is generally questionable. In this paper, multi-objective genetic programming (MOGP)-based framework is proposed to obtain both optimal Lyapunov and control functions at the same time. In other words, MOGP framework is employed to minimize several time-domain performances as well as the ROA radius to find the optimal Lyapunov and control functions. The proposed framework is tested in several nonlinear benchmark systems, and the control performance is compared with state-of-the-art algorithms.},
  archive      = {J_NCA},
  author       = {Ali, Mir Masoud Ale and Jamali, A. and Asgharnia, A. and Ansari, R. and Mallipeddi, Rammohan},
  doi          = {10.1007/s00521-021-06453-1},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1345-1357},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective lyapunov-based controller design for nonlinear systems via genetic programming},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A gradient-based neural network accelerated for
vision-based control of an RCM-constrained surgical endoscope robot.
<em>NCA</em>, <em>34</em>(2), 1329–1343. (<a
href="https://doi.org/10.1007/s00521-021-06465-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an accelerated gradient-based neural network (GNN) to achieve visual servoing of a surgical endoscope robot. A KUKA LWR 4+ robot with seven joints is used to serve as an endoscope holder. Kinematic mapping is established between the joint space of the robot and the image space of the camera. For surgical applications, the motions of the KUKA robot are constrained with respect to a remote-center-of-motion (RCM) point. Meanwhile, each joint of the KUKA robot has its own physical limits (e.g., joint-angle and joint velocity limits) that cannot be violated. By taking into account the kinematic equation, RCM constraints and physical limits, a control scheme possessing a quadratic programming (QP) formulation is constructed. To solve the QP problem, an inverse-free GNN model is accelerated to be finite-time convergent using a powerful activation function. Mathematical derivations of the accelerated GNN model and theoretical proofs relevant to the finite-time convergence are detailed. Comparative validations are conducted with the superior convergence performance of the accelerated GNN model substantiated. The effectiveness of the proposed GNN solution for vision-based control of the surgical endoscope is verified with RCM constraints and physical limits respected simultaneously.},
  archive      = {J_NCA},
  author       = {Li, Weibing and Han, Luyang and Xiao, Xiao and Liao, Bolin and Peng, Chen},
  doi          = {10.1007/s00521-021-06465-x},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1329-1343},
  shortjournal = {Neural Comput. Appl.},
  title        = {A gradient-based neural network accelerated for vision-based control of an RCM-constrained surgical endoscope robot},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep convolutional neural network for diabetes mellitus
prediction. <em>NCA</em>, <em>34</em>(2), 1319–1327. (<a
href="https://doi.org/10.1007/s00521-021-06431-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a widely known disease diabetes mellitus makes the human body produce quite less hormone and also tend to cause increased glucose that results in abnormal metabolism of varied organs in the body like eyes, kidneys, etc. Diabetic analysis has attracted the research community to treat some missing values and class imbalance issues. The performance of diabetes mellitus classification by the usage of machine learning techniques is comparatively low. We suggest this paper on imbalanced dataset with missing values, an efficient prediction algorithm for diabetes mellitus classification using Deep 1D-Convolutional Neural Network values. The outlier detection is used for removing missing values first. Then, oversampling method (SMOTE) is used to reduce the influence of imbalance class on prediction performance. Finally, predictions are produced using a DCNN classifier and are evaluated using a selective set of evaluation indicators. Experiments on the Pima Indian diabetes dataset (PIDD) from  UCI Repository (University of California at Irvine) have yielded positive results. Our proposed DCNN algorithm has been shown to be successful and superior.},
  archive      = {J_NCA},
  author       = {Alex, Suja A. and Nayahi, J. Jesu Vedha and Shine, H. and Gopirekha, Vaisshalli},
  doi          = {10.1007/s00521-021-06431-7},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1319-1327},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep convolutional neural network for diabetes mellitus prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep non-negative tensor factorization with multi-way EMG
data. <em>NCA</em>, <em>34</em>(2), 1307–1317. (<a
href="https://doi.org/10.1007/s00521-021-06474-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor decomposition is widely used in a variety of applications such as data mining, biomedical informatics, neuroscience, and signal processing. In this paper, we propose a deep non-negative tensor factorization (DNTF) model to learn intrinsic and hierarchical structures from multi-way data. The DNTF model takes the Tucker tensor decomposition as a building block to stack up a multi-layer structure. In such a way, we can gradually learn the more abstract structures in a higher layer. The benefit is that it helps to mine intrinsic correlations and hierarchical structures from multi-way data. The non-negative constraints allow for clustering interpretation of the extracted data-dependent components. The objective of DNTF is to minimize the total reconstruction loss resulting from using the core tensor in the highest layer and the mode matrices in each layer to reconstruct the data tensor. Then, a deep decomposition algorithm based on multiplicative update rules is proposed to solve the optimization problem. It first conducts layer-wise tensor factorization and then fine-tunes the weights of all layers to reduce the total reconstruction loss. The experimental results on biosignal sensor data demonstrate the effectiveness and robustness of the proposed approach.},
  archive      = {J_NCA},
  author       = {Tan, Qi and Yang, Pei and Wen, Guihua},
  doi          = {10.1007/s00521-021-06474-w},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1307-1317},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep non-negative tensor factorization with multi-way EMG data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated fruit grading using optimal feature selection and
hybrid classification by self-adaptive chicken swarm optimization:
Grading of mango. <em>NCA</em>, <em>34</em>(2), 1285–1306. (<a
href="https://doi.org/10.1007/s00521-021-06473-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Post-harvest grading is an essential and important process that affects the fruit quality, evaluation, health-intensive, and export market. Even though the sorting and grading can be performed by the human as going on, it is tedious, labor-intensive, slow, and error-prone. Hence, smart automation is required for the same. Computer vision advancements touching every area where there even a minimal chance of smart automation. In this paper, intelligent automation for mango fruit grading designed and developed. Initially, the fruit segmentation is done by the active contour model, and the abnormality segmentation is performed using enhanced fuzzy-based K-means clustering approach followed by features: discrete Fourier transform (DFT), local binary pattern (LBP), and gray-level co-occurrence matrix (GLCM) and shape features extraction. The self-adaptive chicken swarm optimization (SA-CSO) has been used to reduce and optimize features vector. The quality of the fruits has finally categorized based on surface defect and maturity classification. Hence, for defect classifications, optimal abnormality segmented features have been fed to the K-nearest neighbors (KNN). The optimally selected fruit segmented features are subjected to a fuzzy classifier and the fruit segmented images are subjected to a convolutional neural network (CNN). As an improvement, the proposed SA-CSO is used to optimize the hybrid classifier for maximizing the accuracy of classification. The maturity is classified using the hybrid fuzzy classifier and CNN as ripe, partially ripe, and unripe. Finally, the defect and maturity output have been used to decide the quality as good, average, and bad. The comparative analysis of diverse performance metrics proves the effectiveness of the proposed model over other traditional algorithms.},
  archive      = {J_NCA},
  author       = {Kumari, Neeraj and Dwivedi, Rakesh Kr. and Bhatt, Ashutosh Kr. and Belwal, Rajendra},
  doi          = {10.1007/s00521-021-06473-x},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1285-1306},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated fruit grading using optimal feature selection and hybrid classification by self-adaptive chicken swarm optimization: Grading of mango},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Saliency: A new selection criterion of important
architectures in neural architecture search. <em>NCA</em>,
<em>34</em>(2), 1269–1283. (<a
href="https://doi.org/10.1007/s00521-021-06418-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) has achieved great success in automatically designing high-performance neural networks for given tasks. But the early NAS approaches have a problem of excessive computational cost. Recently, some NAS approaches, such as gradient-based ones, have significantly reduced the computational cost. However, the gradient-based methods have a significant deviation in the architecture selection because they simply use the parameter values of the corresponding architectures as an importance index for architecture selection. This causes the architecture selected from the search space to generally fall into a sub-optimal state. To address this problem, we propose architecture saliency, as a new selection criterion of optimal architectures. Concretely, we define architecture saliency as the squared change in network loss induced by removing this architecture from the neural network. Our saliency directly reflects the contribution of a candidate architecture to the network performance. Therefore, our proposed selection criterion eliminates the deviation in architecture selection. Furthermore, we approximate architecture saliency with Taylor series expansion to get a more efficient implementation. Extensive experiments show that our approach achieves competitive even better model evaluation performance than other NAS approaches on multiple datasets.},
  archive      = {J_NCA},
  author       = {Hao, Jie and Cai, Zhiling and Li, Ruijia and Zhu, William},
  doi          = {10.1007/s00521-021-06418-4},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1269-1283},
  shortjournal = {Neural Comput. Appl.},
  title        = {Saliency: A new selection criterion of important architectures in neural architecture search},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient cybersecurity framework for facial video
forensics detection based on multimodal deep learning. <em>NCA</em>,
<em>34</em>(2), 1251–1268. (<a
href="https://doi.org/10.1007/s00521-021-06416-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cloud services and Internet-of-Things (IoT) applications, the cybersecurity in video transmission technologies has drawn much attention in recent researches due to the rapid growth of cyber-risks on both individuals and institutions. Unfortunately, the spoofing attack, a kind of cyber-risk, has increased the number of cyber-criminals in data transfer applications without being detected, especially in smart cities. Several applications based on online video communications, such as online testing and video conferences, are involved in smart cities. The video displays various variations of a person, which makes face recognition an important concept in security implementation. The face spoofing attacks are mainly based on the person&#39;s face replication by replaying a video or by printed photos. Therefore, video forgery detection and related spoof attack detection have become a new topic in cybersecurity research. From this perspective, this paper presents a deep learning approach for video face forensic detection with a cyber facial spoofing attack using two methodologies. The first methodology is based on a convolutional neural network (CNN) to extract features from the input video frames. The model has five convolutional layers followed by five pooling layers. The second methodology is based on convolutional long short-term memory (ConvLSTM). This model comprises two pooling layers, two convolutional layers, and a convolutional LSTM layer. Each methodology includes a fully-connected layer to interconnect between the feature map resulting from the feature extraction process and the classification layer. A SoftMax layer performs the classification task in each method. This paper aims to achieve an optimum modality for face forensic detection to overcome spoofing attacks. Simulation results reveal that the ConvLSTM with CNN methodology achieves better classification results as the extracted features are more comprehensive than those of other conventional approaches. Also, it achieves an accuracy of 99\%, and the works presented in the literature achieve an accuracy levels up to 95\%.},
  archive      = {J_NCA},
  author       = {Sedik, Ahmed and Faragallah, Osama S. and El-sayed, Hala S. and El-Banby, Ghada M. and El-Samie, Fathi E. Abd and Khalaf, Ashraf A. M. and El-Shafai, Walid},
  doi          = {10.1007/s00521-021-06416-6},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1251-1268},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient cybersecurity framework for facial video forensics detection based on multimodal deep learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tensor pooling-driven instance segmentation framework for
baggage threat recognition. <em>NCA</em>, <em>34</em>(2), 1239–1250. (<a
href="https://doi.org/10.1007/s00521-021-06411-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated systems designed for screening contraband items from the X-ray imagery are still facing difficulties with high clutter, concealment, and extreme occlusion. In this paper, we addressed this challenge using a novel multi-scale contour instance segmentation framework that effectively identifies the cluttered contraband data within the baggage X-ray scans. Unlike standard models that employ region-based or keypoint-based techniques to generate multiple boxes around objects, we propose to derive proposals according to the hierarchy of the regions defined by the contours. The proposed framework is rigorously validated on three public datasets, dubbed GDXray, SIXray, and OPIXray, where it outperforms the state-of-the-art methods by achieving the mean average precision score of 0.9779, 0.9614, and 0.8396, respectively. Furthermore, to the best of our knowledge, this is the first contour instance segmentation framework that leverages multi-scale information to recognize cluttered and concealed contraband data from the colored and grayscale security X-ray imagery.},
  archive      = {J_NCA},
  author       = {Hassan, Taimur and Akçay, Samet and Bennamoun, Mohammed and Khan, Salman and Werghi, Naoufel},
  doi          = {10.1007/s00521-021-06411-x},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1239-1250},
  shortjournal = {Neural Comput. Appl.},
  title        = {Tensor pooling-driven instance segmentation framework for baggage threat recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid machine learning model for classifying time series.
<em>NCA</em>, <em>34</em>(2), 1219–1237. (<a
href="https://doi.org/10.1007/s00521-021-06457-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A time series is a sequence of numerical data points in equal time intervals and/or successive order. Time series are used in many fields to understand the behavior of systems, to make predictions, to create solutions to problems, etc. Electroencephalogram (EEG) and electrocardiogram (ECG) are frequently used in the diagnosis of diseases and research in this field. EEG signals examine the neural activity of the brain, while ECG examines the work of the heart muscle and neural conduction system. These signs contain a large amount of information about the functioning of the brain and heart functions. In order to use this information, experts in the field of signal processing must evaluate these signals. Due to the successful application methods of EEG and ECG signals in classification problems, various fields of artificial intelligence applications are frequently used by experts. In this study, a new hybrid model has been developed to classify EEG and ECG signals. These signals of five different classes have been used as the feature vector in the training of machine learning algorithms with 10 statistical parameters (8 normalized, 2 real signals). These algorithms are designed to give the best performance. In the proposed hybrid model, a machine learning model consisting of four stages is used. In the experimental studies, it has been observed that the proposed hybrid method gives better results than the normal classification process. The obtained results are given in the experimental studies section in detail.},
  archive      = {J_NCA},
  author       = {Elen, Abdullah and Avuçlu, Emre},
  doi          = {10.1007/s00521-021-06457-x},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1219-1237},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid machine learning model for classifying time series},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feasibility assessment of kian-i mobile robot for autonomous
navigation. <em>NCA</em>, <em>34</em>(2), 1199–1218. (<a
href="https://doi.org/10.1007/s00521-021-06428-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A two-wheeled mobile robot, namely Kian-I, is designed and prototyped in this research. The Kian-I is comparable with Khepera-IV in terms of dimensional specifications, mounted sensors, and performance capabilities and can be used for educational purposes and cost-effective experimental tests. A motion control architecture is designed for Kian-I in this study to facilitate accurate navigation for the robot in an immersive environment. The implemented control structure consists of two main components of the path recommender system and trajectory tracking controller. Given partial knowledge about the operation field, the path recommender system adopts B-spline curves and particle swarm optimization algorithm to determine a collision-free path curve with translational velocity constraint. The provided optimal reference path feeds into the trajectory tracking controller enabling Kian-I to navigate autonomously in the operating field. The trajectory tracking module eliminates the error between the desired path and the followed trajectory through controlling the wheels’ velocity. To assess the feasibility of the proposed control architecture, the performance of Kian-I robot in autonomous navigation from any arbitrary initial pose to a target of interest is evaluated through numerous simulation and experimental studies. The experimental results demonstrate the functional capacities and performance of the prototyped robot to be used as a benchmark for investigation and verification of various mobile robot algorithms in the laboratory environment.},
  archive      = {J_NCA},
  author       = {Abbasi, Amin and MahmoudZadeh, Somaiyeh and Yazdani, Amirmehdi and Moshayedi, Ata Jahangir},
  doi          = {10.1007/s00521-021-06428-2},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1199-1218},
  shortjournal = {Neural Comput. Appl.},
  title        = {Feasibility assessment of kian-I mobile robot for autonomous navigation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human ethnics prediction using facial features and optimized
convolutional neural network. <em>NCA</em>, <em>34</em>(2), 1181–1198.
(<a href="https://doi.org/10.1007/s00521-021-06451-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the biggest outlooks of face recognition is to create a useful application for human identification at immigration offices for security purposes. The human face is a complex visual pattern that consists of general categorical information, identity specification, primary information, and eccentricity. In this domain, the ethnic identification of humans finds its uses in various real-time applications. Yet, automatic identification does not produce prompt results due to complex characteristics and computational complexity. This paper intends to propose automated human ethnicity identification using facial features, comprising three major processes: pre-processing, feature extraction, and classification. At first, the input image is subjected to a pre-processing method, in which the face detection is carried out using the Viola-Jones face detection algorithm. Then, the pre-processed image is subjected to the feature extraction process, where the color feature, texture feature, forehead area extraction, and the improved active appearance model (AAM) based on unique features are extracted. These extracted features are then subjected to the optimized convolutional neural network (CNN) for ethnicity classification. As the major contribution, training of CNN is carried out by the proposed Moth Spiral adopted Grey Wolf Algorithm (MSGWA) model via tuning the optimal weights. Finally, the performance of the proposed work is compared against the adopted and existing approaches on the basis of certain metrics such as NPV, sensitivity, FDR, accuracy, specificity, FPR, precision, MCC, FNR, and F1-score, respectively.},
  archive      = {J_NCA},
  author       = {Alotaibi, Saud S.},
  doi          = {10.1007/s00521-021-06451-3},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1181-1198},
  shortjournal = {Neural Comput. Appl.},
  title        = {Human ethnics prediction using facial features and optimized convolutional neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multilevel thresholding segmentation of color plant disease
images using metaheuristic optimization algorithms. <em>NCA</em>,
<em>34</em>(2), 1161–1179. (<a
href="https://doi.org/10.1007/s00521-021-06437-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we apply multilevel thresholding segmentation to color images of plant disease. Given that thresholding segmentation is just an optimization problem, we use Otsu’s function as the objective function. To solve this optimization problem, we implement five metaheuristic algorithms, namely artificial bee colony (ABC), cuckoo search (CS), teaching–learning-based optimization (TLBO), teaching–learning-based artificial bee colony (TLABC) and a modified version of TLABC proposed in this work, known as MTLABC. This version is a hybridization between TLABC and Levy flight where the search equations of TLABC are changed according to Levy flight equations; this modification, based on the experimental results, yields a significant improvement in TLABC. Various numbers of thresholding levels are tried to compare the performance of the optimization algorithms at multiple dimensions. The performance is measured according to five measures: the objective function, CPU time, peak noise-to-signal ratio, structural similarity index and color feature similarity. These measures indicate that our proposed algorithm, with the best values of the measures in most images and levels, ranks first. Also, Friedman and Wilcoxon signed-rank tests are used to analyze the results statistically. These two tests prove that our proposed algorithm is significantly different from the other four algorithms.},
  archive      = {J_NCA},
  author       = {Akay, Rustu and Saleh, Radhwan A. A. and Farea, Shawqi M. O. and Kanaan, Muzaffer},
  doi          = {10.1007/s00521-021-06437-1},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1161-1179},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multilevel thresholding segmentation of color plant disease images using metaheuristic optimization algorithms},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Arabic text classification: The need for multi-labeling
systems. <em>NCA</em>, <em>34</em>(2), 1135–1159. (<a
href="https://doi.org/10.1007/s00521-021-06390-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of tagging a given text or document with suitable labels is known as text categorization or classification. The aim of this work is to automatically tag a news article based on its vocabulary features. To accomplish this objective, 2 large datasets have been constructed from various Arabic news portals. The first dataset contains of 90k single-labeled articles from 4 domains (Business, Middle East, Technology and Sports). The second dataset has over 290 k multi-tagged articles. To examine the single-label dataset, we employed an array of ten shallow learning classifiers. Furthermore, we added an ensemble model that adopts the majority-voting technique of all studied classifiers. The performance of the classifiers on the first dataset ranged between 87.7\% (AdaBoost) and 97.9\% (SVM). Analyzing some of the misclassified articles confirmed the need for a multi-label opposed to single-label categorization for better classification results. For the second dataset, we tested both shallow learning and deep learning multi-labeling approaches. A custom accuracy metric, designed for the multi-labeling task, has been developed for performance evaluation along with hamming loss metric. Firstly, we used classifiers that were compatible with multi-labeling tasks such as Logistic Regression and XGBoost, by wrapping each in a OneVsRest classifier. XGBoost gave the higher accuracy, scoring 84.7\%, while Logistic Regression scored 81.3\%. Secondly, ten neural networks were constructed (CNN, CLSTM, LSTM, BILSTM, GRU, CGRU, BIGRU, HANGRU, CRF-BILSTM and HANLSTM). CGRU proved to be the best multi-labeling classifier scoring an accuracy of 94.85\%, higher than the rest of the classifies.},
  archive      = {J_NCA},
  author       = {El Rifai, Hozayfa and Al Qadi, Leen and Elnagar, Ashraf},
  doi          = {10.1007/s00521-021-06390-z},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1135-1159},
  shortjournal = {Neural Comput. Appl.},
  title        = {Arabic text classification: The need for multi-labeling systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The hodgkin–huxley neuron model for motion detection in
image sequences. <em>NCA</em>, <em>34</em>(2), 1123–1133. (<a
href="https://doi.org/10.1007/s00521-021-06446-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a biologically inspired spiking neural network model for motion detection. The proposed model simulates the neurons’ behavior in the cortical area MT to detect different kinds of motion in image sequences. We choose the conductance-based neuron model of the Hodgkin–Huxley to define MT cell responses. Based on the center-surround antagonism of MT receptive fields, we model the area MT by its great proportion of cells with directional selective responses. The network’s spiking output corresponds to an MT neuron population’s firing rates and enables to extract motion boundaries. We conduct several experiments on real image sequences. The experimental results show the proposed network’s ability to segregate multiple moving objects from an image sequence and reproduce the MT cells’ responses. We perform a quantitative evaluation on the YouTube Motion Boundaries (YMB) dataset, and we compare the result to state-of-the-art methods for boundary detection in videos: boundary flow estimation (BF) and temporal boundary difference (BD). The proposed network model provides the best results on YMB compared to BF and BD methods.},
  archive      = {J_NCA},
  author       = {Yedjour, Hayat and Meftah, Boudjelal and Yedjour, Dounia and Lézoray, Olivier},
  doi          = {10.1007/s00521-021-06446-0},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1123-1133},
  shortjournal = {Neural Comput. Appl.},
  title        = {The Hodgkin–Huxley neuron model for motion detection in image sequences},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An algorithm to compute the strength of competing
interactions in the bering sea based on pythagorean fuzzy hypergraphs.
<em>NCA</em>, <em>34</em>(2), 1099–1121. (<a
href="https://doi.org/10.1007/s00521-021-06414-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The networks of various problems have competing constituents, and there is a concern to compute the strength of competition among these entities. Competition hypergraphs capture all groups of predators that are competing in a community through their hyperedges. This paper reintroduces competition hypergraphs in the context of Pythagorean fuzzy set theory, thereby producing Pythagorean fuzzy competition hypergraphs. The data of real-world ecological systems posses uncertainty, and the proposed hypergraphs can efficiently deal with such information to model wide range of competing interactions. We suggest several extensions of Pythagorean fuzzy competition hypergraphs, including Pythagorean fuzzy economic competition hypergraphs, Pythagorean fuzzy row as well as column hypergraphs, Pythagorean fuzzy k-competition hypergraphs, m-step Pythagorean fuzzy competition hypergraphs and Pythagorean fuzzy neighborhood hypergraphs. The proposed graphical structures are good tools to measure the strength of direct and indirect competing and non-competing interactions. Their aptness is illustrated through examples, and results support their intrinsic interest. We propose algorithms that help to compose some of the presented graphical structures. We consider predator-prey interactions among organisms of the Bering Sea as an application: Pythagorean fuzzy competition hypergraphs encapsulate the competing relationships among its inhabitants. Specifically, the algorithm which constructs the Pythagorean fuzzy competition hypergraphs can also compute the strength of competing and non-competing relations of this scenario.},
  archive      = {J_NCA},
  author       = {Nawaz, Hafiza Saba and Akram, Muhammad and Alcantud, José Carlos R.},
  doi          = {10.1007/s00521-021-06414-8},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1099-1121},
  shortjournal = {Neural Comput. Appl.},
  title        = {An algorithm to compute the strength of competing interactions in the bering sea based on pythagorean fuzzy hypergraphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling and experimental validation of dry-type
transformers with multiobjective swarm intelligence-based optimization
algorithms for industrial application. <em>NCA</em>, <em>34</em>(2),
1079–1098. (<a
href="https://doi.org/10.1007/s00521-021-06447-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the optimum and efficient design of the transformer core and conductive materials is the most significant issues to overcome the high-temperature problems. The temperature increases on the transformer materials are directly related to the energy efficiency of it. The overheating of the core and coils of the transformer reduces the amount of energy to be obtained from the transformer. However, copper, core, eddy current and other losses can be minimized by obtaining an optimum design of the transformer for maximum efficiency. Thus, the transformer life and the energy efficiency to be obtained from the transformer are maximized. The temperature rise and temperature distribution of the windings can be monitored by computer technology and the transformer can be safely overloaded and the production cost can be minimized. Also, the operating life of the transformers can be further increased by specifying hot spot temperatures on the transformer coils and core. In this study, 3 kVA and 5 kVA Dyn 11 connected 380/220-V dry-type transformers are optimized by multiobjective swarm intelligence-based optimization methods. The main contribution of this study is to prevent the overheating of the transformers by reducing the losses in the transformer core and coils and to reduce the costs of the transformer. The thermal and electromagnetic analyses of the transformers are realized by ANSYS/Maxwell software program which utilizes the industry-leading ANSYS/Fluent computational fluid dynamics and finite element method solvers. Finally, the experimental analyses are realized under the loaded conditions for the transformers. The experimental results are verified with the simulation results. The optimization, modeling, thermal/electromagnetic analysis and experimental processes are carried out step by step in this study. The transformer manufacturers will realize the optimum cost, efficiency and thermal analysis before transformers are manufactured.},
  archive      = {J_NCA},
  author       = {Demirdelen, Tugce and Esenboga, Burak and Aksu, Inayet Ozge and Ozdogan, Alican and Yavuzdeger, Abdurrahman and Ekinci, Fırat and Tümay, Mehmet},
  doi          = {10.1007/s00521-021-06447-z},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1079-1098},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modeling and experimental validation of dry-type transformers with multiobjective swarm intelligence-based optimization algorithms for industrial application},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RDPOD: An unsupervised approach for outlier detection.
<em>NCA</em>, <em>34</em>(2), 1065–1077. (<a
href="https://doi.org/10.1007/s00521-021-06432-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outliers are the data points which deviate significantly from the majority of the data points. Finding outliers is an important task in various applications, especially in data mining. The unsupervised technique is very popular to mine outliers in a dataset over supervised techniques. Various unsupervised approaches have been proposed over the last decades. Clustering-based, distance-based, and density-based outlier approaches are found to be successful for detecting outlier points. However, the main focus of clustering-based method is to identifying clustering structure. Many distance-based and density-based techniques are not suitable for varying density datasets, and they are also very sensitive with their parameter (number of nearest-neighbor (k)). In this paper, we propose a hybrid approach named RDPOD, which utilizes distance-based and density-based clustering approaches efficiently for identifying the density of each point correctly. We obtain local density and relative distance of each data instance. From this density and distance information, we identify outlier points. Experimental results with real-world datasets show that our proposed approach outperforms the popular techniques LOF, LDOF, symmetric neighborhood, and recently introduced approaches NOF and RDOS.},
  archive      = {J_NCA},
  author       = {Abhaya, Abhaya and Patra, Bidyut Kr.},
  doi          = {10.1007/s00521-021-06432-6},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1065-1077},
  shortjournal = {Neural Comput. Appl.},
  title        = {RDPOD: An unsupervised approach for outlier detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward deep MRI segmentation for alzheimer’s disease
detection. <em>NCA</em>, <em>34</em>(2), 1047–1063. (<a
href="https://doi.org/10.1007/s00521-021-06430-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is an irreversible, progressive, and ultimately fatal brain degenerative disorder, no effective cures for it till now. Despite that, the available treatments can delay its progress. So, early detection of AD plays a crucial role in preventing and controlling its progress. Hippocampus (HC) is among the first impacted brain regions by AD. Its shape and volume are measured using a structural magnetic resonance image (MRI) to help AD diagnosis. Therefore, brain hippocampus segmentation is the building block for AD detection. This study’s main objective is to propose a deep learning Alzheimer’s disease hippocampus segmentation framework (DL-AHS) for automatic left and right hippocampus segmentation to detect and identify AD. The proposed DL-AHS framework is based on the U-Net architecture and estimated on the baseline coronal T1-weighted structural MRI data obtained from Alzheimer’s disease neuroimaging initiative (ADNI) and neuroimaging tools and resources collaboratory (NITRIC) datasets. The dataset is processed using the Medical Image Processing, Analysis, and Visualization (MIPAV) program. Besides, it is augmented using a deep convolutional generative adversarial network (DC-GAN). For left and right HC segmentation from other brain sub-regions, two architectures are proposed. The first utilizes simple hyperparameters tuning in the U-Net (SHPT-Net). The second employs a transfer learning technique in which the ResNet blocks are used in the U-Net (RESU-Net). The empirical results confirmed that the proposed framework achieves high performance, 94.34\% accuracy, and 93.5\% Dice similarity coefficient for SHPT-Net. Also, 97\% accuracy and 94\% Dice similarity coefficient are achieved for RESU-Net.},
  archive      = {J_NCA},
  author       = {Helaly, Hadeer A. and Badawy, Mahmoud and Haikal, Amira Y.},
  doi          = {10.1007/s00521-021-06430-8},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1047-1063},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward deep MRI segmentation for alzheimer’s disease detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EFLDet: Enhanced feature learning for object detection.
<em>NCA</em>, <em>34</em>(2), 1033–1045. (<a
href="https://doi.org/10.1007/s00521-021-06607-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an enhanced feature learning method for object detection regarding with backbone, neck and head, which are three main components of object detection. For the backbone network, we build a bi-residual network to extract salient information by extending residual block with aggregate connection for the global feature representation. For the neck network, we design an enhanced feature pyramid network to fuse spatial and channel-wise information within different receptive fields of feature maps, which introduces the attention module with the global context block and the dilated convolution module to reduce the decay of information in the feature fusion. For the detection head, we construct a trident head network to improve the confidence of classification and regression, which consists of a fully connected head, a convolution head and an attention head. The experiments conducted on COCO dataset show that the proposed approaches are widely applicable and can verity the effectiveness for object detection.},
  archive      = {J_NCA},
  author       = {Liao, Yongwei and Zhang, Guipeng and Yang, Zhenguo and Liu, Wenyin},
  doi          = {10.1007/s00521-021-06607-1},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1033-1045},
  shortjournal = {Neural Comput. Appl.},
  title        = {EFLDet: Enhanced feature learning for object detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Applications of deep learning for mobile malware detection:
A systematic literature review. <em>NCA</em>, <em>34</em>(2), 1007–1032.
(<a href="https://doi.org/10.1007/s00521-021-06597-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For detecting and resolving the various types of malware, novel techniques are proposed, among which deep learning algorithms play a crucial role. Although there has been a lot of research on the development of DL-based mobile malware detection approaches, they were not reviewed in detail yet. This paper aims to identify, assess, and synthesize the reported articles related to the application of DL techniques for mobile malware detection. A Systematic Literature Review is performed in which we selected 40 journal articles for in-depth analysis. This SLR presents and categorizes these articles based on machine learning categories, data sources, DL algorithms, evaluation parameters &amp; approaches, feature selection techniques, datasets, and DL implementation platforms. The study also highlights the challenges, proposed solutions, and future research directions on the use of DL in mobile malware detection. This study showed that Convolutional Neural Networks and Deep Neural Networks algorithms are the most used DL algorithms. API calls, Permissions, and System Calls are the most dominant features utilized. Keras and Tensorflow are the most popular platforms. Drebin and VirusShare are the most widely used datasets. Supervised learning and static features are the most preferred machine learning and data source categories.},
  archive      = {J_NCA},
  author       = {Catal, Cagatay and Giray, Görkem and Tekinerdogan, Bedir},
  doi          = {10.1007/s00521-021-06597-0},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1007-1032},
  shortjournal = {Neural Comput. Appl.},
  title        = {Applications of deep learning for mobile malware detection: A systematic literature review},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Face clustering using a weighted combination of deep
representations. <em>NCA</em>, <em>34</em>(2), 995–1006. (<a
href="https://doi.org/10.1007/s00521-021-06581-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering of face images is a well-known clustering problem with several applications as for example the automated face tagging in photo albums. The performance of face clustering algorithms largely depends on the face representations that are used. Therefore, the exploitation of the internal face representation (embedding) obtained by feeding the face image to a deep face network has led to increased clustering performance. In this work, we perform face clustering by combining multiple representations of each image obtained from several deep face networks. The multiple deep representations are not exploited in a straightforward manner (simple vector concatenation). Instead a weight is assigned to each representation to reflect its importance on the clustering result and a weighted clustering algorithm is employed to automatically adjust the weights and, consequently, the contribution of each representation on the clustering solution. It should also be noted that in the proposed approach, the number of clusters (number of faces) is not given as input, but it is automatically estimated using the silhouette criterion. The conducted experiments have shown that the weighted combination of deep face representations leads to improved clustering performance compared to using single representations.},
  archive      = {J_NCA},
  author       = {Skiadopoulou, Dafni and Likas, Aristidis},
  doi          = {10.1007/s00521-021-06581-8},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {995-1006},
  shortjournal = {Neural Comput. Appl.},
  title        = {Face clustering using a weighted combination of deep representations},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance improvement for metro passenger flow forecast
using spatio-temporal deep neural network. <em>NCA</em>, <em>34</em>(2),
983–994. (<a href="https://doi.org/10.1007/s00521-021-06522-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of transportation planning and management, passenger flow analysis is a significant problem with a wide range of applications. The prediction performance of forecast models is hence cardinal to any software analytic system. A predominant source of metro data is the automated fare card (AFC) system from which it is possible to gather a tremendous amount of information connected to passenger flow. Passenger flow represents a process whose dynamics are highly stochastic and dependent on a number of extrinsic and intrinsic parameters. This paper presents a restricted and simple model to study the intrinsic statistical influences governing the dynamics. These influences are either spatial or temporal. The feature space in which analysis algorithms run will be more effective if there is a collation of information from both spatial and temporal dimensions. The passenger flow parameter is fed into the layers of the deep neural network using the ST-LSTM (Spatio-Temporal Long Short-Term Memory) architecture. The architecture is evaluated with passenger movement data collected from the AFC information from the Kochi metro rail. To reduce the impact of irregular flow, the design uses the SVM-based outlier detection and elimination algorithm. A higher precision has been reached by the approach in comparison with SVR,ANN, LSTM algorithms.},
  archive      = {J_NCA},
  author       = {Mulerikkal, Jaison and Thandassery, Sajanraj and Rejathalal, Vinith and Kunnamkody, Deepa Merlin Dixon},
  doi          = {10.1007/s00521-021-06522-5},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {983-994},
  shortjournal = {Neural Comput. Appl.},
  title        = {Performance improvement for metro passenger flow forecast using spatio-temporal deep neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning for fake news detection on twitter regarding
the 2019 hong kong protests. <em>NCA</em>, <em>34</em>(2), 969–982. (<a
href="https://doi.org/10.1007/s00521-021-06230-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dissemination of fake news on social media platforms is an issue of considerable interest, as it can be used to misinform people or lead them astray, which is particularly concerning when it comes to political events. The recent event of Hong Kong protests triggered an outburst of fake news posts that were identified on Twitter, which were then promptly removed and compiled into datasets to promote research. These datasets focusing on linguistic content were used in previous work to classify between tweets spreading fake and real news using traditional machine learning algorithms (Zervopoulos et al., in: IFIP international conference on artificial intelligence applications and innovations, Springer, Berlin, 2020). In this paper, the experimentation process on the previously constructed dataset is extended using deep learning algorithms along with a diverse set of input features, ranging from raw text to handcrafted features. Experiments showed that the deep learning algorithms outperformed the traditional approaches, reaching scores as high as 99.3\% F1 Score, with the multilingual state-of-the-art model XLM-RoBERTa outperforming other algorithms using raw untranslated text. The combination of both traditional and deep learning algorithms allows for increased performance through the latter, while also gaining insight regarding tweet structure from the interpretability of the former.},
  archive      = {J_NCA},
  author       = {Zervopoulos, Alexandros and Alvanou, Aikaterini Georgia and Bezas, Konstantinos and Papamichail, Asterios and Maragoudakis, Manolis and Kermanidis, Katia},
  doi          = {10.1007/s00521-021-06230-0},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {969-982},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning for fake news detection on twitter regarding the 2019 hong kong protests},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On unifying deep learning and edge computing for human
motion analysis in exergames development. <em>NCA</em>, <em>34</em>(2),
951–967. (<a href="https://doi.org/10.1007/s00521-021-06181-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work describes a novel methodology for creating exergames on an edge-native platform with the integration of multiple deep neural networks. A prototype of the platform, which includes capabilities for innovative gameplay and advanced user interactivity, has been implemented and deployed in a real-world scenario. At core of the proposed methodology is the ad hoc training of classifiers for posture classification which can be dynamically adapted to the specific requirements of the usage scenario, operational and environmental conditions allowing for real-time identification of events and advanced game control. The proposed solution is ideal for individual consumers in a home environment since is supports by-design edge platforms minimizing the cost of the system and enabling in parallel the communication with state-of-the-art hardware (i.e., GPUs, TPUs, computer boards) for real-time operation. The proposed system allows the collection and analysis of game data, which can be exploited by specialized personnel in rehabilitation centers or for other purposes in the areas of healthcare and assisted living.},
  archive      = {J_NCA},
  author       = {Pardos, Antonis and Menychtas, Andreas and Maglogiannis, Ilias},
  doi          = {10.1007/s00521-021-06181-6},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {951-967},
  shortjournal = {Neural Comput. Appl.},
  title        = {On unifying deep learning and edge computing for human motion analysis in exergames development},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Thesaurus-based word embeddings for automated biomedical
literature classification. <em>NCA</em>, <em>34</em>(2), 937–950. (<a
href="https://doi.org/10.1007/s00521-021-06053-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The special nature, volume and broadness of biomedical literature pose barriers for automated classification methods. On the other hand, manually indexing is time-consuming, costly and error prone. We argue that current word embedding algorithms can be efficiently used to support the task of biomedical text classification even in a multilabel setting, with many distinct labels. The ontology representation of Medical Subject Headings provides machine-readable labels and specifies the dimensionality of the problem space. Both deep- and shallow network approaches are implemented. Predictions are determined by the similarity between extracted features from contextualized representations of abstracts and headings. The addition of a separate classifier for transfer learning is also proposed and evaluated. Large datasets of biomedical citations are harvested for their metadata and used for training and testing. These automated approaches are still far from entirely substituting human experts, yet they can be useful as a mechanism for validation and recommendation. Dataset balancing, distributed processing and training parallelization in GPUs, all play an important part regarding the effectiveness and performance of proposed methods.},
  archive      = {J_NCA},
  author       = {Koutsomitropoulos, Dimitrios A. and Andriopoulos, Andreas D.},
  doi          = {10.1007/s00521-021-06053-z},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {937-950},
  shortjournal = {Neural Comput. Appl.},
  title        = {Thesaurus-based word embeddings for automated biomedical literature classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discriminative attention-augmented feature learning for
facial expression recognition in the wild. <em>NCA</em>, <em>34</em>(2),
925–936. (<a href="https://doi.org/10.1007/s00521-021-06045-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) in-the-wild is challenging due to unconstraint settings such as varying head poses, illumination, and occlusions. In addition, the performance of a FER system significantly degrades due to large intra-class variation and inter-class similarity of facial expressions in real-world scenarios. To mitigate these problems, we propose a novel approach, Discriminative Attention-augmented Feature Learning Convolution Neural Network (DAF-CNN), which learns discriminative expression-related representations for FER. Firstly, we develop a 3D attention mechanism for feature refinement which selectively focuses on attentive channel entries and salient spatial regions of a convolution neural network feature map. Moreover, a deep metric loss termed Triplet-Center (TC) loss is incorporated to further enhance the discriminative power of the deeply-learned features with an expression-similarity constraint. It simultaneously minimizes intra-class distance and maximizes inter-class distance to learn both compact and separate features. Extensive experiments have been conducted on two representative facial expression datasets (FER-2013 and SFEW 2.0) to demonstrate that DAF-CNN effectively captures discriminative feature representations and achieves competitive or even superior FER performance compared to state-of-the-art FER methods.},
  archive      = {J_NCA},
  author       = {Zhou, Linyi and Fan, Xijian and Tjahjadi, Tardi and Das Choudhury, Sruti},
  doi          = {10.1007/s00521-021-06045-z},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {925-936},
  shortjournal = {Neural Comput. Appl.},
  title        = {Discriminative attention-augmented feature learning for facial expression recognition in the wild},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning-based approach for forecasting off-gas
production and consumption in the blast furnace. <em>NCA</em>,
<em>34</em>(2), 911–923. (<a
href="https://doi.org/10.1007/s00521-021-05984-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents the application of a recent neural network topology known as the deep echo state network to the prediction and modeling of strongly nonlinear systems typical of the process industry. The article analyzes the results by introducing a comparison with one of the most common and efficient topologies, the long short-term memories, in order to highlight the strengths and weaknesses of a reservoir computing approach compared to one currently considered as a standard of recurrent neural network. As benchmark application, two specific processes common in the integrated steelworks are selected, with the purpose of forecasting the future energy exchanges and transformations. The procedures of training, validation and test are based on data analysis, outlier detection and reconciliation and variable selection starting from real field industrial data. The analysis of results shows the effectiveness of deep echo state networks and their strong forecasting capabilities with respect to standard recurrent methodologies both in terms of training procedures and accuracy.},
  archive      = {J_NCA},
  author       = {Dettori, Stefano and Matino, Ismael and Colla, Valentina and Speets, Ramon},
  doi          = {10.1007/s00521-021-05984-x},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {911-923},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning-based approach for forecasting off-gas production and consumption in the blast furnace},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolving graph convolutional networks for neural
architecture search. <em>NCA</em>, <em>34</em>(2), 899–909. (<a
href="https://doi.org/10.1007/s00521-021-05979-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As neural architecture search (NAS) becomes an increasingly adopted method to design network architectures, various methods have been proposed to speedup the process. Besides proxy evaluation tasks, weight sharing, and scaling down the evaluated architectures, performance-predicting models exhibit multiple advantages. Eliminating the need to train candidate architectures and enabling transfer learning between datasets, researchers can also utilize them as a surrogate function for Bayesian optimization. On the other hand, graph convolutional networks (GCNs) have also been increasingly adopted for various tasks, enabling deep learning techniques on graphs without feature engineering. In this paper, we employ an evolutionary-based NAS method to evolve GCNs for the problem of predicting the relative performance of various architectures included in the NAS-Bench-101 dataset. By fine-tuning the architecture generated by our methodology, we manage to achieve a Kendall’s tau correlation coefficient of 0.907 between 1050 completely unseen architectures, utilizing only 450 samples, while also outperforming a strong baseline on the same task. Furthermore, we validate our method on custom global search space architectures, generated for the Fashion-MNIST dataset.},
  archive      = {J_NCA},
  author       = {Kyriakides, George and Margaritis, Konstantinos},
  doi          = {10.1007/s00521-021-05979-8},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {899-909},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evolving graph convolutional networks for neural architecture search},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). IBuilding: Artificial intelligence in intelligent
buildings. <em>NCA</em>, <em>34</em>(2), 875–897. (<a
href="https://doi.org/10.1007/s00521-021-05967-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents iBuilding: distributed artificial intelligence embedded into Intelligent or Smart Buildings in an Industry 4.0 application that enables the adaptation to the external environment and the different building users. Buildings are becoming more intelligent in the way they monitor the usage of its assets, functionality and space. The more efficiently a building can be monitored or predicted, the more return of investment can deliver as unused space or energy can be redeveloped or commercialized, therefore reducing energy consumption while increasing functionality. This article proposes distributed artificial intelligence embedded into a Building based on neural networks with a deep learning structure. (1) Sensorial neurons at the device level are dispersed through the intelligent building to gather, filter environment information and predict its next values. (2) Management neurons based on reinforcement learning algorithm at the edge level make predictions about values and trends for building managers or developers to make commercial or operational informed decisions. (3) Finally, transmission neurons based on the genetic algorithms and the genome codify, transmit iBuilding information and also multiplex its data entirely to generate clusters of buildings interconnected with each other at the cloud level. The proposed iBuilding based on distributed learning is validated with a public research dataset; the results show that artificial intelligence embedded into the intelligent building enables real-time monitoring and successful predictions about its variables. The key concept proposed by this article is that the learned information obtained by iBuilding after its adaptation to the environment is never lost when the building changes over time or is decommissioned but transmitted to future generations.},
  archive      = {J_NCA},
  author       = {Serrano, Will},
  doi          = {10.1007/s00521-021-05967-y},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {875-897},
  shortjournal = {Neural Comput. Appl.},
  title        = {IBuilding: Artificial intelligence in intelligent buildings},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). The random neural network in price predictions.
<em>NCA</em>, <em>34</em>(2), 855–873. (<a
href="https://doi.org/10.1007/s00521-021-05903-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Everybody likes to make a good prediction, in particular, when some sort of personal investment is involved in terms of finance, energy or time. The difficulty is to make a prediction that optimises the reward obtained from the original contribution; this is even more important when investments are the core service offered by a business or pension fund. The complexity of finance is that the human predictor may have other interests or bias than the human investor, the trust between predictor and investor will never be completely established as the investor will never know if the predictor has generated, intentionally or unintentionally, the optimum possible reward. This article presents the random neural network (RNN) in a recurrent configuration for the 4th industrial revolution on a Fintech application; the RNN is proposed to make predictions on time series data, specifically, prices. The biological model inspired by the brain structure and neural interconnections make predictions entirely on previous data from the time series rather than predictions based on several uncorrelated inputs. The model is validated against the property, stock and Fintech market: (1) UK property prices, (2) stock market indice prices, (3) cryptocurrency prices. Experimental results show that the proposed method makes accurate predictions on different investment portfolios. The prediction accuracy of the proposed RNN model is compared against long short-term memory (LSTM) and linear regression (LR) models.},
  archive      = {J_NCA},
  author       = {Serrano, Will},
  doi          = {10.1007/s00521-021-05903-0},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {855-873},
  shortjournal = {Neural Comput. Appl.},
  title        = {The random neural network in price predictions},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). <span class="math display"><em>λ</em></span> -DNNs and their
implementation in conjugate heat transfer shape optimization.
<em>NCA</em>, <em>34</em>(2), 843–854. (<a
href="https://doi.org/10.1007/s00521-021-05858-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A data-driven two-branch deep neural network (DNN), to be referred to as $$\lambda $$ -DNN, used to predict scalar fields is presented. The network architecture consists of two separate branches (input layers) connected to the main one towards its output. In multi-disciplinary shape optimization problems, such as those this paper is dealing with, the input to the $$\lambda $$ -DNN contains data relevant to the geometrical shape and the case itself. Herein, the $$\lambda $$ -DNN is used in conjugate heat transfer (CHT) analysis and shape optimization problems, synergistically with codes simulating flows over the fluid domain and solving the heat conduction equations over the solid one. It is used to optimize a duct and an internally cooled turbine blade-airfoil surrounded by hot gas. The $$\lambda $$ -DNNs, after being trained on fields computed using the CHT solver, are used as surrogates for either the heat conduction equation solver of the solid domain, replicating either one out of the two disciplines of the problem or the coupled CHT solver.},
  archive      = {J_NCA},
  author       = {Kontou, Marina and Kapsoulis, Dimitrios and Baklagis, Ioannis and Trompoukis, Xenofon and Giannakoglou, Kyriakos},
  doi          = {10.1007/s00521-021-05858-2},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {843-854},
  shortjournal = {Neural Comput. Appl.},
  title        = {$$\lambda $$ -DNNs and their implementation in conjugate heat transfer shape optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Smart city infrastructure protection: Real-time threat
detection employing online reservoir computing architecture.
<em>NCA</em>, <em>34</em>(2), 833–842. (<a
href="https://doi.org/10.1007/s00521-021-05733-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most important problems that occur during the extraction of knowledge from data streams are related to the properties characterizing “BigData,” namely high speed of information flow (velocity), variety of used forms, variability of data and diversity of information accuracy diagnosis methods (veracity). The use of online or sequential learning methods offers a specialized solution for solving real-time data processing problems. Data are provided without a clear knowledge of their particular inherent characteristics. Conventional approaches focus on applying heuristic or logical analysis rules. They fail to effectively handle new patterns (produced as a function of time) and to consider the dynamic change rate of their characteristics. In most cases, these methods approximate, by creating general rather than clear imprints of knowledge, which is hidden in the flows. Moreover, their function requires significant computational resources. This paper introduces (to the best of our knowledge, for the first time in the literature) the implementation of a specialized online reservoir computing architecture for smart city infrastructure protection which has low requirements in computing resources; it is efficient and suitable for real-time data flow analysis. More specifically, it describes the development of an echo state network, comprised of analog neurons with sparse random connections at the input levels and at the dynamical reservoir. Its training at the output level is performed with the recursive least square method. A complex data set was selected for the testing of the proposed model, which fully simulates the digital attacks that can be faced by the mechatronic equipment used in smart water supply networks located in the front end of the smart cities.},
  archive      = {J_NCA},
  author       = {Gao, Lili and Deng, Xiaopeng and Yang, Weimin},
  doi          = {10.1007/s00521-021-05733-0},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {833-842},
  shortjournal = {Neural Comput. Appl.},
  title        = {Smart city infrastructure protection: Real-time threat detection employing online reservoir computing architecture},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel energy-based online sequential extreme learning
machine to detect anomalies over real-time data streams. <em>NCA</em>,
<em>34</em>(2), 823–831. (<a
href="https://doi.org/10.1007/s00521-021-05731-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data flow learning algorithms must be very efficient in learning and predicting sequences. The model that monitors a sequence of data or events can predict the sequel and can act in such a way that it optimally achieves the desired result. Security and digital risk tracking systems are receiving a constant and unlimited input of observations. These data flows are characterized by high variability, as their properties can change drastically and unpredictably over time. Each incoming example can only be processed once, or it must be summarized with a small memory imprint. This research paper proposes the development of an intelligent system, for real-time detection of data flow anomalies related to information systems’ security. Specifically, it describes the implementation of an efficient and high-precision energy-based Online Sequential Extreme Learning Machine (e-b OSELM) that is proposed for the first time in the literature. It is an intelligent model that can detect data dependencies, by applying a measure of compatibility (scalable energy) to each configuration of its variables. It assigns low energy to the correct values and higher energy to the divergent (abnormal) ones. The innovative combination of energy models and ELMs offers high learning speed, ease of execution, minimum human involvement and minimum computational power and resources for anomaly detection and identification.},
  archive      = {J_NCA},
  author       = {Wang, Xiaoping and Tu, Shanshan and Zhao, Wei and Shi, Chengjie},
  doi          = {10.1007/s00521-021-05731-2},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {823-831},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel energy-based online sequential extreme learning machine to detect anomalies over real-time data streams},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Extensive framework based on novel
convolutional and variational autoencoder based on maximization of
mutual information for anomaly detection. <em>NCA</em>, <em>34</em>(1),
821. (<a href="https://doi.org/10.1007/s00521-021-06241-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Yu, Qien and Kavitha, Muthu Subash and Kurita, Takio},
  doi          = {10.1007/s00521-021-06241-x},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {821},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Extensive framework based on novel convolutional and variational autoencoder based on maximization of mutual information for anomaly detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Innovative deep learning models for EEG-based
vigilance detection. <em>NCA</em>, <em>34</em>(1), 819. (<a
href="https://doi.org/10.1007/s00521-021-06187-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A correction to this paper has been published: https://doi.org/10.1007/s00521-021-06187-0},
  archive      = {J_NCA},
  author       = {Khessiba, Souhir and Blaiech, Ahmed Ghazi and Khalifa, Khaled Ben and Abdallah, Asma Ben and Bedoui, Mohamed Hédi},
  doi          = {10.1007/s00521-021-06187-0},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {819},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Innovative deep learning models for EEG-based vigilance detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Linking place records using multi-view
encoders. <em>NCA</em>, <em>34</em>(1), 817. (<a
href="https://doi.org/10.1007/s00521-021-06076-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A correction to this paper has been published: https://doi.org/10.1007/s00521-021-06076-6},
  archive      = {J_NCA},
  author       = {Cousseau , Vinícius and Barbosa, Luciano},
  doi          = {10.1007/s00521-021-06076-6},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {817},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Linking place records using multi-view encoders},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Fault detection in distillation column using
NARX neural network. <em>NCA</em>, <em>34</em>(1), 815. (<a
href="https://doi.org/10.1007/s00521-021-05935-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A correction to this paper has been published: https://doi.org/10.1007/s00521-021-05935-6},
  archive      = {J_NCA},
  author       = {Taqvi, Syed A. and Tufa, Lemma Dendana and Zabiri, Haslinda and Maulud, Abdulhalim Shah and Uddin, Fahim},
  doi          = {10.1007/s00521-021-05935-6},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {815},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Fault detection in distillation column using NARX neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Building an efficient OCR system for
historical documents with little training data. <em>NCA</em>,
<em>34</em>(1), 813. (<a
href="https://doi.org/10.1007/s00521-020-05563-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the author(s)’ decision to order Open Choice, the copyright of the article changed on 3rd December 2020 to [The Authors] [2020] and the article is forthwith distributed under the terms of copyright.},
  archive      = {J_NCA},
  author       = {Martínek, Jiří and Lenc, Ladislav and Král, Pavel},
  doi          = {10.1007/s00521-020-05563-6},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {813},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Building an efficient OCR system for historical documents with little training data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new insight to the wind speed forecasting: Robust
multi-stage ensemble soft computing approach based on pre-processing
uncertainty assessment. <em>NCA</em>, <em>34</em>(1), 783–812. (<a
href="https://doi.org/10.1007/s00521-021-06424-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, monthly wind speed time series of the Kirsehir was investigated using the stand-alone, hybrid and ensemble models. The artificial neural networks, Gaussian process regression, support vector machines and multivariate adaptive regression splines were employed as stand-alone machine learning models, while the discrete wavelet transform was utilized as a pre-processing technique to create hybrid models. Moreover, for the first time in wind speed predictions, we generated a multi-stage ensemble model by using the M5 Model Tree (M5) algorithm to increase the model accuracies. Two major tasks considered to be necessary, in which the first is to obtain the lag times by using autocorrelation functions, and the latter is to determine the optimum mother wavelet as well as the decomposition level to reduce the uncertainties in wavelet modeling. The results revealed that the hybrid wavelet models outperformed the stand-alone models, while a significant improvement was also observed in M5 ensemble models as the highest Nash–Sutcliffe efficiency coefficient values were obtained in M5 hybrid wavelet multi-stage ensemble models for each lead time prediction. The findings of the study were assessed with respect to the various performance indicators and Kruskal–Wallis test to indicate whether the results are statically significant. The proposed multi-stage ensemble framework also benchmarked with the classical tree-based ensembles, such as Random forest, AdaBoost and XGBoost.},
  archive      = {J_NCA},
  author       = {Başakın, Eyyup Ensar and Ekmekcioğlu, Ömer and Çıtakoğlu, Hatice and Özger, Mehmet},
  doi          = {10.1007/s00521-021-06424-6},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {783-812},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new insight to the wind speed forecasting: Robust multi-stage ensemble soft computing approach based on pre-processing uncertainty assessment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AENeT: An attention-enabled neural architecture for fake
news detection using contextual features. <em>NCA</em>, <em>34</em>(1),
771–782. (<a href="https://doi.org/10.1007/s00521-021-06450-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current era of social media, the popularity of smartphones and social media platforms has increased exponentially. Through these electronic media, fake news has been rising rapidly with the advent of new sources of information, which are highly unreliable. Checking off a particular news article is genuine or fake is not easy for any end user. Search engines like Google are also not capable of telling about the fakeness of any news article due to its restriction with limited query keywords. In this paper, our end goal is to design an efficient deep learning model to detect the degree of fakeness in a news statement. We propose a simple network architecture that combines the use of contextual embedding as word embedding and uses attention mechanisms with relevant metadata available. The efficacy and efficiency of our models are demonstrated on several real-world datasets. Our model achieved 46.36\% accuracy on the LIAR dataset, which outperforms the current state of the art by 1.49\%.},
  archive      = {J_NCA},
  author       = {Jain, Vidit and Kaliyar, Rohit Kumar and Goswami, Anurag and Narang, Pratik and Sharma, Yashvardhan},
  doi          = {10.1007/s00521-021-06450-4},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {771-782},
  shortjournal = {Neural Comput. Appl.},
  title        = {AENeT: An attention-enabled neural architecture for fake news detection using contextual features},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). EPMC: Efficient parallel memory compression in deep neural
network training. <em>NCA</em>, <em>34</em>(1), 757–769. (<a
href="https://doi.org/10.1007/s00521-021-06433-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are getting deeper and larger, making memory become one of the most important bottlenecks during training. Researchers have found that the feature maps generated during DNN training occupy the major portion of memory footprint. To reduce memory demand, they proposed to encode the feature maps in the forward pass and decode them in the backward pass. However, we observe that the execution of encoding and decoding is time-consuming, leading to severe slowdown of the DNN training. To solve this problem, we present an efficient parallel memory compression framework—EPMC, which enables us to simultaneously reduce the memory footprint and the impact of encoding/decoding on DNN training. Our framework employs pipeline parallel optimization and specific-layer parallelism for encoding and decoding to reduce their impact on overall training. It also combines precision reduction with encoding for improving the data compressing ratio. We evaluate EPMC across four state-of-the-art DNNs. Experimental results show that EPMC can reduce the memory footprint during training to 2.3 times on average without accuracy loss. In addition, it can reduce the DNN training time by more than 2.1 times on average compared with the unoptimized encoding/decoding scheme. Moreover, compared with using the common compression scheme Compressed Sparse Row, EPMC can achieve data compression ratio by 2.2 times.},
  archive      = {J_NCA},
  author       = {Chen, Zailong and Yang, Shenghong and Liu, Chubo and Hu, Yikun and Li, Kenli and Li, Keqin},
  doi          = {10.1007/s00521-021-06433-5},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {757-769},
  shortjournal = {Neural Comput. Appl.},
  title        = {EPMC: Efficient parallel memory compression in deep neural network training},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel concept of domination in m-polar interval-valued
fuzzy graph and its application. <em>NCA</em>, <em>34</em>(1), 745–756.
(<a href="https://doi.org/10.1007/s00521-021-06405-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of domination is one of the most significant topics in graph theory to handle unpredictable phenomena. In this study, an unprecedented idea of domination is introduced in m-polar interval-valued fuzzy graph (m-PIVFG). Domination number (DN), isolated vertex, total dominating set, independent set of domination on m-PIVFG are discussed. Some algebraic properties of domination on m-PIVFG are investigated. Weak domination, strong domination, split and non-split domination, cototal and global dominating sets on m-PIVFG are investigated with some fundamental hypotheses and models. We explore the concept of domination in m-PIVFG by solving a case study of locating new facilities to handle a catastrophe reaction activity due to the “COVID-19 pandemic” in West Bengal, India. Ultimately, conclusions and avenues of future scopes are placed at the end of this study.},
  archive      = {J_NCA},
  author       = {Bera, Sanchari and Pal, Madhumangal},
  doi          = {10.1007/s00521-021-06405-9},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {745-756},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel concept of domination in m-polar interval-valued fuzzy graph and its application},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning for prediction of depressive symptoms in a
large textual dataset. <em>NCA</em>, <em>34</em>(1), 721–744. (<a
href="https://doi.org/10.1007/s00521-021-06426-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression is a common illness worldwide with potentially severe implications. Early identification of depressive symptoms is a crucial first step towards assessment, intervention, and relapse prevention. With an increase in data sets with relevance for depression, and the advancement of machine learning, there is a potential to develop intelligent systems to detect symptoms of depression in written material. This work proposes an efficient approach using Long Short-Term Memory (LSTM)-based Recurrent Neural Network (RNN) to identify texts describing self-perceived symptoms of depression. The approach is applied on a large dataset from a public online information channel for young people in Norway. The dataset consists of youth’s own text-based questions on this information channel. Features are then provided from a one-hot process on robust features extracted from the reflection of possible symptoms of depression pre-defined by medical and psychological experts. The features are better than conventional approaches, which are mostly based on the word frequencies (i.e., some topmost frequent words are chosen as features from the whole text dataset and applied to model the underlying events in any text message) rather than symptoms. Then, a deep learning approach is applied (i.e., RNN) to train the time-sequential features discriminating texts describing depression symptoms from posts with no such descriptions (non-depression posts). Finally, the trained RNN is used to automatically predict depression posts. The system is compared against conventional approaches where it achieved superior performance than others. The linear discriminant space clearly reveals the robustness of the features by generating better clustering than other traditional features. Besides, since the features are based on the possible symptoms of depression, the system may generate meaningful explanations of the decision from machine learning models using an explainable Artificial Intelligence (XAI) algorithm called Local Interpretable Model-Agnostic Explanations (LIME). The proposed depression symptom feature-based approach shows superior performance compared to the traditional general word frequency-based approaches where frequency of the features gets more importance than the specific symptoms of depression. Although the proposed approach is applied on a Norwegian dataset, a similar robust approach can be applied on other depression datasets developed in other languages with proper annotations and symptom-based feature extraction. Thus, the depression prediction approach can be adopted to contribute to develop better mental health care technologies such as intelligent chatbots.},
  archive      = {J_NCA},
  author       = {Uddin, Md Zia and Dysthe, Kim Kristoffer and Følstad, Asbjørn and Brandtzaeg, Petter Bae},
  doi          = {10.1007/s00521-021-06426-4},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {721-744},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning for prediction of depressive symptoms in a large textual dataset},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensemble deep transfer learning model for arabic (indian)
handwritten digit recognition. <em>NCA</em>, <em>34</em>(1), 705–719.
(<a href="https://doi.org/10.1007/s00521-021-06423-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognising handwritten digits or characters is a challenging task due to noisy data that results from different writing styles. Numerous applications essentially motivate to build an effective recognising model for such purposes by utilizing recent intelligent techniques. However, the difficulty emerges when using the Arabic language that suffers from diverse noises; because of the way of writing inherent in connecting characters and digits. Therefore, this work focuses on the Arabic (Indian) digits and propose an ensemble deep transfer learning (EDTL) model that efficaciously detect and recognise these digits. The EDTL model is a combination of two effective pre-trained transfer learning models that consume time and cost complexity in the training phase. The EDTL is trained on large datasets to extract relevant features as input to a fully-connected Artificial Neural Network classifier. The experimental results, using popular datasets, show significant performance obtained by the EDTL model with accuracy reached up to 99.83\% in comparison to baseline methods include deep transfer learning models, ensemble deep transfer learning models and state-of-the-art techniques.},
  archive      = {J_NCA},
  author       = {Alkhawaldeh, Rami S. and Alawida, Moatsum and Alshdaifat, Nawaf Farhan Funkur and Alma’aitah, Wafa’ Za’al and Almasri, Ammar},
  doi          = {10.1007/s00521-021-06423-7},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {705-719},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ensemble deep transfer learning model for arabic (Indian) handwritten digit recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid moth flame optimization and variable neighbourhood
search technique for optimal design of IIR filters. <em>NCA</em>,
<em>34</em>(1), 689–704. (<a
href="https://doi.org/10.1007/s00521-021-06379-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this manuscript, a hybrid optimization technique, which integrates moth flame optimization (MFO) technique and variable neighbourhood search (VNS) heuristic, has been proposed to search the optimal coefficients of infinite impulse response (IIR) filter. The search process of MFO technique is based on the navigation method of the moths. The moth updates its position around the flame. In order to improve the search ability and convergence precision of MFO technique, the VNS heuristic has been integrated with it. In VNS heuristic, a random solution is generated around the neighbourhood of the best MFO solution. The random solution is updated by local search ‘Powell’s pattern search’ (PPS) method. The PPS method has excellent exploitation capability, which avoids any possible stagnation at local optimal solution. The proposed optimization technique has been applied on the benchmark functions and for the optimal design of five low-pass and six high-pass IIR filters. For low-pass filter (LPF) design problems 1–5, the proposed optimization technique is able to minimize the objective function by at least 50.78\%, 205.72\%, 122.36\%, 20.48\% and 28.76\% more as compared to the results obtained by other state-of-the-art techniques, respectively. Hence, optimal IIR filter designed by the proposed optimization technique is able to achieve better desirable attributes, i.e. passband error, stopband error, square error, and stopband attenuation as compared to other state-of-the-art techniques.},
  archive      = {J_NCA},
  author       = {Mittal, Teena},
  doi          = {10.1007/s00521-021-06379-8},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {689-704},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid moth flame optimization and variable neighbourhood search technique for optimal design of IIR filters},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SSPSNet: A single shot panoptic segmentation network for
accurate scene parsing. <em>NCA</em>, <em>34</em>(1), 677–688. (<a
href="https://doi.org/10.1007/s00521-021-06350-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Panoptic segmentation is a challenging task which aims to provide a comprehensive scene parsing result. Researchers have been devoted to improve its accuracy and efficiency. In this paper, we propose a single shot panoptic segmentation network (SSPSNet) to handle this task more accurately. SSPSNet novelly develops the object detection network FCOS by adding a mask segmentation branch to predict the instance mask and a semantic segmentation branch to predict the classes of background pixels. In addition, we design a parameter-free identical mapping connection module that increases shortcut on the mask segmentation, FCOS classification and regression branches, respectively, to extract more expressive feature maps for instance segmentation and object detection subtasks. More importantly, we design a parameter-free category and location aware module that transfers the category and location information of FCOS to the mask and semantic segmentation branches for improving their ability of distinguishing instances and background. Experimental results show that the proposed SSPSNet gets 44.0 /45.8PQ, 11.6/10.0FPS on COCO-Panoptic 2017 when uses ResNet-50/101-FPN as backbone, which achieves the state-of-the-art performance with smaller parameters and computation.},
  archive      = {J_NCA},
  author       = {Wang, Qi and Wang, Yuanshuai and Zhou, Yuan and Wang, Jing and Jiang, Wuming and Zhang, Xiangde},
  doi          = {10.1007/s00521-021-06350-7},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {677-688},
  shortjournal = {Neural Comput. Appl.},
  title        = {SSPSNet: A single shot panoptic segmentation network for accurate scene parsing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). UQSCM-RFD: A query–knowledge interfacing approach for
diversified query recommendation in semantic search based on river flow
dynamics and dynamic user interaction. <em>NCA</em>, <em>34</em>(1),
651–675. (<a href="https://doi.org/10.1007/s00521-021-06404-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the exponential intensification of the web information content and transfiguration of the conventional Web into a more sophisticated Semantic Web, there is a mandated need for semantics aware web recommendation systems. In this paper, a graph-based semantic strategy for query recommendation has been proposed. Firstly, the paper aims at the construction of the proposed Query Sense Concept Tripartite graph for the initially built Query Click Graph. Secondly, a novel river flow dynamics strategy has been proposed for the selection of the best concept entailment path for integrating real-world knowledge from semantic wikis. Thirdly, an adaptation of the Tversky Index with parametric variations for computing the semantic similarity further contributes to novelty. Finally, a horizontal–vertical grid-based dynamic capture of user intents has been proposed for understanding the current informational needs of the user. Experimentations have been conducted for both the AOL and the SIGIR datasets for computing the performance of the Query Recommendation. An accuracy of 0.86 and 0.91 has been achieved for the AOL and the SIGIR datasets with a very low FDR of 0.11 and 0.07, respectively, which is the best-in-class performance when benchmarked with the baseline methods.},
  archive      = {J_NCA},
  author       = {Deepak, Gerard and Santhanavijayan, A.},
  doi          = {10.1007/s00521-021-06404-w},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {651-675},
  shortjournal = {Neural Comput. Appl.},
  title        = {UQSCM-RFD: A query–knowledge interfacing approach for diversified query recommendation in semantic search based on river flow dynamics and dynamic user interaction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection of surface defects on pharmaceutical solid oral
dosage forms with convolutional neural networks. <em>NCA</em>,
<em>34</em>(1), 631–650. (<a
href="https://doi.org/10.1007/s00521-021-06397-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep-learning-based approaches have proven to outperform other approaches in various computer vision tasks, making application-focused machine learning a promising area of research in automated visual inspection. In this work, we apply deep learning to the challenging real-world problem domain of automated visual inspection of pharmaceutical products. We focus on investigating whether compact network architectures, adhering to performance, resource, and accuracy requirements, are suitable for usage in the pharmaceutical visual inspection domain. We propose a compact and efficient convolutional neural network architecture design for segmentation and scoring of surface defects, which we evaluate on challenging real-world datasets from the pharmaceutical product-inspection domain. In comparison with other related segmentation approaches, we achieve state-of-the-art performance in terms of defect detection as well as real-time computational efficiency. Compared to the nearest best-performing architecture we achieve state-of-the-art performance with merely 3\% of the parameter count, an approximately 8-fold increase in inference speed, and increased surface defect detection performance.},
  archive      = {J_NCA},
  author       = {Rački, Domen and Tomaževič, Dejan and Skočaj, Danijel},
  doi          = {10.1007/s00521-021-06397-6},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {631-650},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection of surface defects on pharmaceutical solid oral dosage forms with convolutional neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive NN prescribed performance control design for
uncertain switching nonlinear systems with periodically time-varying
parameters. <em>NCA</em>, <em>34</em>(1), 617–629. (<a
href="https://doi.org/10.1007/s00521-021-06387-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a tracking control problem with prespecified accuracy for uncertain switching nonlinear systems under arbitrary switching with periodically time-varying parameters. To approximate the unknown nonlinear functions and unknown periodically time-varying parameters, the radial basis function neural network and Fourier series expansion are introduced, respectively. Compared with the previous results of unknown nonlinear switching system approximation, the upper bounds of the approximation errors are considered for the first time. And then, a new adaptive NN control scheme is constructed by using backstepping technique and common Lyapunov function theory. It can be proved that all the signals in the closed-loop system are semi-globally uniformly ultimately bounded and the tracking error converges to the prescribed neighborhood of zero. Two examples are provided to verify the feasibility and advantages of the proposed approach in this paper.},
  archive      = {J_NCA},
  author       = {Yang, Xiaoli and Li, Jing and Wu, Shuiyan and Li, Xiaobo},
  doi          = {10.1007/s00521-021-06387-8},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {617-629},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive NN prescribed performance control design for uncertain switching nonlinear systems with periodically time-varying parameters},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A neural network training algorithm for singular
perturbation boundary value problems. <em>NCA</em>, <em>34</em>(1),
607–615. (<a href="https://doi.org/10.1007/s00521-021-06364-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A training algorithm for the Neural Network solution of Singular Perturbation Boundary Value Problems is presented. The solution is based on a single hidden layer feed forward Neural Network with a small number of neurons. The training algorithm adapts the training points grid so to be more tense in areas of the integration interval that solution has a layer or a peek. The algorithm automatically detects the areas of interest in the integration interval. The resulted Neural Network solutions are very accurate in a uniform way. The numerical tests in various test problems justify our arguments as the produced solutions prove to give smaller errors compare to their competitors.},
  archive      = {J_NCA},
  author       = {Simos, T. E. and Famelis, Ioannis Th.},
  doi          = {10.1007/s00521-021-06364-1},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {607-615},
  shortjournal = {Neural Comput. Appl.},
  title        = {A neural network training algorithm for singular perturbation boundary value problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Context-guided feature enhancement network for automatic
check-out. <em>NCA</em>, <em>34</em>(1), 593–606. (<a
href="https://doi.org/10.1007/s00521-021-06394-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Powered by deep learning technology, automatic check-out (ACO) has made great breakthroughs. Nevertheless, because of the complex nature of real scenes, ACO is still an exceedingly testing task in the field of computer vision. Existing methods cannot fully exploit the contextual information, so that the improvement of checkout accuracy is inhibited. In this study, a novel context-guided feature enhancement network (CGFENet) is proposed, in which products are detected in multi-scale features by exploring the global and local context. Specifically, we design three customized modules: Global context learning module (GCLM), local context learning module (LCLM), and attention transfer module (ATM). GCLM is designed for enhancing the feature representation of feature maps by fully exploring global context information, the purpose of LCLM is that interactions between local and global features can be strengthened gradually, and ATM aims to make the model attach more attention to the challenging products. For the purpose of proving the effectiveness of the proposed CGFENet, extensive experiments are conducted on the large-scale retail product checkout dataset. Experimental results indicate that CGFENet accomplishes favorable performance and surpasses state-of-the-art methods. We achieve 85.88\% checkout accuracy in the averaged mode, by comparison with 56.68\% of the baseline methods.},
  archive      = {J_NCA},
  author       = {Sun, Yihan and Luo, Tiejian and Zuo, Zhen},
  doi          = {10.1007/s00521-021-06394-9},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {593-606},
  shortjournal = {Neural Comput. Appl.},
  title        = {Context-guided feature enhancement network for automatic check-out},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effective forecasting of stock market price by using extreme
learning machine optimized by PSO-based group oriented crow search
algorithm. <em>NCA</em>, <em>34</em>(1), 555–591. (<a
href="https://doi.org/10.1007/s00521-021-06403-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock index price forecasting is the influential indicator for investors and financial investigators by which decision making capability to achieve maximum benefit with minimum risk can be improved. So, a robust engine with capability to administer useful information is desired to achieve the success. The forecasting effectiveness of stock market is improved in this paper by integrating a modified crow search algorithm (CSA) and extreme learning machine (ELM). The effectiveness of proposed modified CSA entitled as Particle Swarm Optimization (PSO)-based Group oriented CSA (PGCSA) to outperform other existing algorithms is observed by solving 12 benchmark problems. PGCSA algorithm is used to achieve relevant weights and biases of ELM to improve the effectiveness of conventional ELM. The impact of hybrid PGCSA ELM model to predict next day closing price of seven different stock indices is observed by using performance measures, technical indicators and hypothesis test (paired t-test). The seven stock indices are considered by incorporating data during COVID-19 outbreak. This model is tested by comparing with existing techniques proposed in published works. The simulation results provide that PGCSA ELM model can be considered as a suitable tool to predict next day closing price.},
  archive      = {J_NCA},
  author       = {Das, Sudeepa and Sahu, Tirath Prasad and Janghel, Rekh Ram and Sahu, Binod Kumar},
  doi          = {10.1007/s00521-021-06403-x},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {555-591},
  shortjournal = {Neural Comput. Appl.},
  title        = {Effective forecasting of stock market price by using extreme learning machine optimized by PSO-based group oriented crow search algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A conjugate gradient algorithm based on double parameter
scaled broyden–fletcher–goldfarb–shanno update for optimization problems
and image restoration. <em>NCA</em>, <em>34</em>(1), 535–553. (<a
href="https://doi.org/10.1007/s00521-021-06383-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a three-term conjugate gradient algorithm and three approaches are used in the designed algorithm: (i) A modified weak Wolfe-Powell line search technique is introduced to obtain $$\alpha _k$$ . (ii) The search direction $$d_k$$ is given by a symmetrical Perry matrix which contains two positive parameters, and the sufficient descent property of the generated directions holds independent of the MWWP line search technique. (iii) A parabolic will be proposed and regarded as the projection surface, the next point $$x_{k+1}$$ is generated by a new projection technique. The global convergence of the new algorithm under a MWWP line search is obtained for general functions. Numerical experiments show that the given algorithm is promising.},
  archive      = {J_NCA},
  author       = {Luo, Dan and Li, Yong and Lu, Junyu and Yuan, Gonglin},
  doi          = {10.1007/s00521-021-06383-y},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {535-553},
  shortjournal = {Neural Comput. Appl.},
  title        = {A conjugate gradient algorithm based on double parameter scaled Broyden–Fletcher–Goldfarb–Shanno update for optimization problems and image restoration},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integration of extreme gradient boosting feature selection
approach with machine learning models: Application of weather relative
humidity prediction. <em>NCA</em>, <em>34</em>(1), 515–533. (<a
href="https://doi.org/10.1007/s00521-021-06362-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relative humidity (RH) is one of the important processes in the hydrology cycle which is highly stochastic. Accurate RH prediction can be highly beneficial for several water resources engineering practices. In this study, extreme gradient boosting (XGBoost) approach “as a selective input parameter” was coupled with support vector regression, random forest (RF), and multivariate adaptive regression spline (MARS) models for simulating the RH process. Meteorological data at two stations (Kut and Mosul), located in Iraq region, were selected as a case study. Numeric and graphic indicators were used for model’s evaluation. In general, all models revealed good prediction performance. In addition, research finding approved the importance of all the meteorological data for the RH simulation. Further, the integration of the XGBoost approach managed to abstract the essential parameters for the RH simulation at both stations and attained good predictability with less input parameters. At Kut station, RF model attained the best prediction results with minimum root mean square error (RMSE = 4.92) and mean absolute error (MAE = 3.89) using maximum air temperature and evaporation parameters. Whereas MARS model reported the best prediction results at Mosul station using all the utilized climate parameters with minimum (RMSE = 3.80 and MAE = 2.86). Overall, the research results evidenced the capability of the proposed coupled machine learning models for modeling the RH at different coordinates within a semi-arid environment.},
  archive      = {J_NCA},
  author       = {Tao, Hai and Awadh, Salih Muhammad and Salih, Sinan Q. and Shafik, Shafik S. and Yaseen, Zaher Mundher},
  doi          = {10.1007/s00521-021-06362-3},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {515-533},
  shortjournal = {Neural Comput. Appl.},
  title        = {Integration of extreme gradient boosting feature selection approach with machine learning models: Application of weather relative humidity prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asset criticality and risk prediction for an effective
cybersecurity risk management of cyber-physical system. <em>NCA</em>,
<em>34</em>(1), 493–514. (<a
href="https://doi.org/10.1007/s00521-021-06400-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Risk management plays a vital role in tackling cyber threats within the cyber-physical system (CPS). It enables identifying critical assets, vulnerabilities and threats and determining suitable proactive control measures for the risk mitigation. However, due to the increased complexity of the CPS, cyber-attacks nowadays are more sophisticated and less predictable, which makes risk management task more challenging. This paper aims for an effective cybersecurity risk management (CSRM) practice using assets criticality, predication of risk types and evaluating the effectiveness of existing controls. We follow a number of techniques for the proposed unified approach including fuzzy set theory for the asset criticality, machine learning classifiers for the risk predication and comprehensive assessment model (CAM) for evaluating the effectiveness of the existing controls. The proposed approach considers relevant CSRM concepts such as asset, threat actor, attack pattern, tactic, technique and procedure (TTP), and controls and maps these concepts with the VERIS community dataset (VCDB) features for the risk predication. The experimental results reveal that using the fuzzy set theory in assessing assets criticality supports stakeholder for an effective risk management practice. Furthermore, the results have demonstrated the machine learning classifiers exemplary performance to predict different risk types including denial of service, cyber espionage and crimeware. An accurate prediction of risk can help organisations to determine the suitable controls in proactive manner to manage the risk.},
  archive      = {J_NCA},
  author       = {Kure, Halima Ibrahim and Islam, Shareeful and Ghazanfar, Mustansar and Raza, Asad and Pasha, Maruf},
  doi          = {10.1007/s00521-021-06400-0},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {493-514},
  shortjournal = {Neural Comput. Appl.},
  title        = {Asset criticality and risk prediction for an effective cybersecurity risk management of cyber-physical system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive backpropagation algorithm for long-term
electricity load forecasting. <em>NCA</em>, <em>34</em>(1), 477–491. (<a
href="https://doi.org/10.1007/s00521-021-06384-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Neural Networks (ANNs) have been widely used to determine future demand for power in the short, medium, and long terms. However, research has identified that ANNs could cause inaccurate predictions of load when used for long-term forecasting. This inaccuracy is attributed to insufficient training data and increased accumulated errors, especially in long-term estimations. This study develops an improved ANN model with an Adaptive Backpropagation Algorithm (ABPA) for best practice in the forecasting long-term load demand of electricity. The ABPA includes proposing new forecasting formulations that adjust/adapt forecast values, so it takes into consideration the deviation between trained and future input datasets&#39; different behaviours. The architecture of the Multi-Layer Perceptron (MLP) model, along with its traditional Backpropagation Algorithm (BPA), is used as a baseline for the proposed development. The forecasting formula is further improved by introducing adjustment factors to smooth out behavioural differences between the trained and new/future datasets. A computational study based on actual monthly electricity consumption inputs from 2011 to 2020, provided by the Iraqi Ministry of Electricity, is conducted to verify the proposed adaptive algorithm&#39;s performance. Different types of energy consumption and the electricity cut period (unsatisfied demand) factor are also considered in this study as vital factors. The developed ANN model, including its proposed ABPA, is then compared with traditional and popular prediction techniques such as regression and other advanced machine learning approaches, including Recurrent Neural Networks (RNNs), to justify its superiority amongst them. The results reveal that the most accurate long-term forecasts with the minimum Mean Squared Error (MSE) and Mean Absolute Percentage Error (MAPE) values of (1.195.650) and (0.045), respectively, are successfully achieved by applying the proposed ABPA. It can be concluded that the proposed ABPA, including the adjustment factor, enables traditional ANN techniques to be efficiently used for long-term forecasting of electricity load demand.},
  archive      = {J_NCA},
  author       = {Mohammed, Nooriya A. and Al-Bazi, Ammar},
  doi          = {10.1007/s00521-021-06384-x},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {477-491},
  shortjournal = {Neural Comput. Appl.},
  title        = {An adaptive backpropagation algorithm for long-term electricity load forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decision-making in machine learning using novel picture
fuzzy divergence measure. <em>NCA</em>, <em>34</em>(1), 457–475. (<a
href="https://doi.org/10.1007/s00521-021-06353-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some tools such as entropy, divergence measures and similarity measures are applied to real-world phenomena like decision-making, robotics, pattern recognition, clustering, expert and knowledge-based system and medical diagnosis. An intuitionistic fuzzy set (IFS) comprises of membership function and non-membership function, but neutrality function is missing in IFS. Therefore, picture fuzzy set (PFS) is an excellent tool to handle such situations when there are answers like yes, no, abstain and refusal. PFS is the generalization of fuzzy set (FS) and intuitionistic fuzzy set (IFS) and shows better adaptation to various real-world problems. To draw conclusions for these problems, based on discrimination between two probability distributions, tools such as divergence measure play a crucial role. The aim of this study is to propose a divergence measure for picture fuzzy sets with its validity proof and to deliberate its key properties. Besides, the newly developed divergence measure is applied to decision-making in machine learning such as pattern recognition, medical diagnosis and clustering using numerical illustrations. To validate the proposed method and to check its effectiveness, expediency and legitimacy, a comparative analysis is given and also the superiority of the divergence measure is tested over the existing methods by comparing their results.},
  archive      = {J_NCA},
  author       = {Umar, Adeeba and Saraswat, Ram Naresh},
  doi          = {10.1007/s00521-021-06353-4},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {457-475},
  shortjournal = {Neural Comput. Appl.},
  title        = {Decision-making in machine learning using novel picture fuzzy divergence measure},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel meta-heuristic algorithm for solving numerical
optimization problems: Ali baba and the forty thieves. <em>NCA</em>,
<em>34</em>(1), 409–455. (<a
href="https://doi.org/10.1007/s00521-021-06392-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel meta-heuristic algorithm called Ali Baba and the forty thieves (AFT) for solving global optimization problems. Recall the famous tale of Ali Baba and the forty thieves, where Ali Baba once saw a gang of forty thieves enter a strange cave filled with all kinds of treasures. The strategies pursued by the forty thieves in the search for Ali Baba inspired us to design ideas and underlie the basic concepts to put forward the mathematical models and implement the exploration and exploitation processes of the proposed algorithm. The performance of the AFT algorithm was assessed on a set of basic benchmark test functions and two more challenging benchmarks called IEEE CEC-2017 and IEEE CEC-C06 2019 benchmark test functions. These benchmarks cover simple and complex test functions with various dimensions and levels of complexity. An extensive comparative study was performed between the AFT algorithm and other well-studied algorithms, and the significance of the results was proved by statistical test methods. To study the potential performance of AFT, its further development is discussed and carried out from five aspects. Finally, the applicability of the AFT algorithm was subsequently demonstrated in solving five engineering design problems. The results in both benchmark functions and engineering problems show that the AFT algorithm has stronger performance than other competitors’ algorithms.},
  archive      = {J_NCA},
  author       = {Braik, Malik and Ryalat, Mohammad Hashem and Al-Zoubi, Hussein},
  doi          = {10.1007/s00521-021-06392-x},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {409-455},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel meta-heuristic algorithm for solving numerical optimization problems: Ali baba and the forty thieves},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust penalized extreme learning machine regression with
applications in wind speed forecasting. <em>NCA</em>, <em>34</em>(1),
391–407. (<a href="https://doi.org/10.1007/s00521-021-06370-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In extreme learning machine (ELM) framework, the hidden layer setting determines its generalization ability; and in presence of outliers in the training set, weights between hidden layer and output layer based on the least squares would be overly estimated. To address these two problems in ELM implementation, we extend robust penalized statistical framework in ELM and propose a general robust penalized ELM, which consists of two components (robust loss function and regularization item), for regression to improve the efficiency of ELM training with more elegant neural network structure resulting in more accurate predictions. We investigate six different loss functions ( $$l_1$$ -norm loss, $$l_2$$ -norm loss, Huber loss, Bisquare loss, exponential squared loss and Lncosh loss) and two regularization strategies (lasso penalty and ridge penalty). Furthermore, we present two training procedures for our robust penalized ELM via iterative reweighted least squares method with hyper-parameter setting by cross-validation with lasso penalty and ridge penalty, respectively. Finally, the proposed robust penalized ELM is employed in an ultra-short-term wind speed forecasting study, and our framework is confirmed in this specific application producing more effective predictions according to the multi-step forecasting performance.},
  archive      = {J_NCA},
  author       = {Yang, Yang and Zhou, Hu and Gao, Yuchao and Wu, Jinran and Wang, You-Gan and Fu, Liya},
  doi          = {10.1007/s00521-021-06370-3},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {391-407},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust penalized extreme learning machine regression with applications in wind speed forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Infinite impulse response system identification using
average differential evolution algorithm with local search.
<em>NCA</em>, <em>34</em>(1), 375–390. (<a
href="https://doi.org/10.1007/s00521-021-06399-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a new metaheuristic algorithm named average differential evolution with local search (ADE-LS) has been developed and implemented to find the optimal coefficients of unknown infinite impulse response (IIR) system as a system identifier. The developed method minimizes the error between unknown system output and the adaptive IIR filter output. Rapid convergence is aimed for the global solution in system identification problem using the ADE-LS based adaptive IIR filter modelling with local search. In this way, more precise prediction of filter coefficients is ensured in the filter design with multimodal error surface. ADE-LS algorithm is applied to four benchmarked IIR systems commonly studies in literature to show its performance. Results found by using ADE-LS are compared to other methods reported in terms of convergence rate and the mean square error value. The attained results approve the efficiency of the suggested method.},
  archive      = {J_NCA},
  author       = {Durmuş, Burhanettin},
  doi          = {10.1007/s00521-021-06399-4},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {375-390},
  shortjournal = {Neural Comput. Appl.},
  title        = {Infinite impulse response system identification using average differential evolution algorithm with local search},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An integration framework of topology method, enhanced
adaptive neuro-fuzzy inference system, water cycle algorithm with
evaporation rate for design optimization for a flexure gripper.
<em>NCA</em>, <em>34</em>(1), 349–374. (<a
href="https://doi.org/10.1007/s00521-021-06374-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Design and analysis for flexure-based mechanisms are a challenging task thanks to their movements relied on elastic linkages. Hence, this paper presents a new optimization framework to provide a systematic design method for a flexure gripper. The optimization strategy includes the topology, modeling, and size optimization phases. In the first phase, the topology scheme for the gripper is proposed via the solids isotropic material with penalization method in terms of a full consideration of stress constraint and equal forces of both hands. In the next phase, modeling of the performances is implemented via an enhanced adaptive neuro-fuzzy inference system (EANFIS). The EANFIS’s architectures are optimized by the Taguchi. The EANFIS’s optimization is aimed to search the best parameters and improve the modeling accuracy. It showed that the EANFIS models have a good precision with root mean square error and standard deviation being close to zero, and coefficient of determination around one. In the last phase, the size optimization is performed by the evaporate rate-based water cycle algorithm. Two cases of the flexure gripper are considered in this phase. The results of case 1 found the hand’s stroke of 0.0078 mm, the strain energy of 0.0354 mJ, the stress of 65.332 MPa, and the safety factor of 3.169. The results of case 2 identified the hand’s stroke of 0.0075 mm, the stress of 66.208 MPa, and the safety factor of 3.795. Additionally, the optimized values are close to the finite element verifications. In comparison with the other methods, the results showed that the proposed framework is a best optimizer for the flexure gripper.},
  archive      = {J_NCA},
  author       = {Dinh, Van Bang and Tran, Ngoc Thoai and Dao, Thanh-Phong},
  doi          = {10.1007/s00521-021-06374-z},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {349-374},
  shortjournal = {Neural Comput. Appl.},
  title        = {An integration framework of topology method, enhanced adaptive neuro-fuzzy inference system, water cycle algorithm with evaporation rate for design optimization for a flexure gripper},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Thermal-based early breast cancer detection using inception
v3, inception v4 and modified inception MV4. <em>NCA</em>,
<em>34</em>(1), 333–348. (<a
href="https://doi.org/10.1007/s00521-021-06372-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the most significant causes of death for women around the world. Breast thermography supported by deep convolutional neural networks is expected to contribute significantly to early detection and facilitate treatment at an early stage. The goal of this study is to investigate the behavior of different recent deep learning methods for identifying breast disorders. To evaluate our proposal, we built classifiers based on deep convolutional neural networks modelling inception V3, inception V4, and a modified version of the latter called inception MV4. MV4 was introduced to maintain the computational cost across all layers by making the resultant number of features and the number of pixel positions equal. DMR database was used for these deep learning models in classifying thermal images of healthy and sick patients. A set of epochs 3–30 were used in conjunction with learning rates 1 × 10–3, 1 × 10–4 and 1 × 10–5, Minibatch 10 and different optimization methods. The training results showed that inception V4 and MV4 with color images, a learning rate of 1 × 10–4, and SGDM optimization method, reached very high accuracy, verified through several experimental repetitions. With grayscale images, inception V3 outperforms V4 and MV4 by a considerable accuracy margin, for any optimization methods. In fact, the inception V3 (grayscale) performance is almost comparable to inception V4 and MV4 (color) performance but only after 20–30 epochs. inception MV4 achieved 7\% faster classification response time compared to V4. The use of MV4 model is found to contribute to saving energy consumed and fluidity in arithmetic operations for the graphic processor. The results also indicate that increasing the number of layers may not necessarily be useful in improving the performance.},
  archive      = {J_NCA},
  author       = {Al Husaini, Mohammed Abdulla Salim and Habaebi, Mohamed Hadi and Gunawan, Teddy Surya and Islam, Md Rafiqul and Elsheikh, Elfatih A. A. and Suliman, F. M.},
  doi          = {10.1007/s00521-021-06372-1},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {333-348},
  shortjournal = {Neural Comput. Appl.},
  title        = {Thermal-based early breast cancer detection using inception v3, inception v4 and modified inception MV4},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Memristor-based circuit implementation of competitive neural
network based on online unsupervised hebbian learning rule for pattern
recognition. <em>NCA</em>, <em>34</em>(1), 319–331. (<a
href="https://doi.org/10.1007/s00521-021-06361-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a Competitive Neural Network circuit based on voltage-controlled memristors is proposed, of which the synapse structure is one memristor (1M). The designed circuit consists of the forward calculation part and the weight updating part. The forward calculation part is designed according to the winner-take-all mechanism, in which the m-LIF model and PMOS transistors with switching characteristics are combined to achieve the lateral inhibition. The weight updating part is designed based on the Hebbian learning rule. By using the voltage controlled switches, only the synaptic memristors connected to the winner output neuron obtained from the forward calculation part are adjusted. The whole circuit does not require the participation of CPU, FPGA or other microcontrollers, providing the possibility to realize computing-in-memory and parallel computing. We perform simulation experiments of unsupervised online learning of 5*3 pixels patterns and 28*28 pixels patterns based on the designed circuit in PSPICE. The changing trend of the network weights during the training phase and the high recognition accuracy in the recognition phase  verify the network can effectively learn and recognize different patterns.},
  archive      = {J_NCA},
  author       = {Li, Mian and Hong, Qinghui and Wang, Xiaoping},
  doi          = {10.1007/s00521-021-06361-4},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {319-331},
  shortjournal = {Neural Comput. Appl.},
  title        = {Memristor-based circuit implementation of competitive neural network based on online unsupervised hebbian learning rule for pattern recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel nature-inspired maximum power point tracking (MPPT)
controller based on ACO-ANN algorithm for photovoltaic (PV) system fed
arc welding machines. <em>NCA</em>, <em>34</em>(1), 299–317. (<a
href="https://doi.org/10.1007/s00521-021-06393-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a metaheuristic optimized multilayer feed‐forward artificial neural network (ANN) controller is proposed to extract the maximum power from available solar energy for a three-phase shunt active power filter (APF) grid connected photovoltaic (PV) system supplying an arc welding machine. Firstly, in order to improve the maximum power point (MPP) delivered by PV arrays and to overcome the drawbacks in the conventional MPPT method under irradiation variation, a hybrid MPPT controller is designed, in which the input parameters include the PV array voltage and current, and the output parameter is the duty cycle of the DC/DC boost converter. The proposed approach abbreviated as ANN-ACO MPPT controller is based on an ant colony optimization (ACO) algorithm which is useful to train the developed ANN and to evolve the connection weights and biases to get the optimal values of duty cycle converter corresponding to the MPP of a PV array. Secondly, aiming to meet the various grid requirements such as power quality improvement, distortion free signals etc., a three-phase shunt APF is utilized, and a direct power control algorithm is designed for distributing the solar energy between the DC-link capacitor, arc welding machine and the AC grid. Finally, the performance of proposed control system is confirmed by simulation tests on a 12.2 kW PV system. Both simulation and experimental results have demonstrated that the deigned ANN-ACO MPPT controller can provide a better MPP tracking with a faster speed and a high robustness with a minimal steady-state oscillation than those obtained with the conventional INC method. Also, with the use of a three-phase shunt APF, all the power fluctuations from the arc welding machine disturbances are damped out and the output active and reactive power become controllable.},
  archive      = {J_NCA},
  author       = {Babes, Badreddine and Boutaghane, Amar and Hamouda, Noureddine},
  doi          = {10.1007/s00521-021-06393-w},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {299-317},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel nature-inspired maximum power point tracking (MPPT) controller based on ACO-ANN algorithm for photovoltaic (PV) system fed arc welding machines},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multidomain image-to-image translation model based on hidden
space sharing. <em>NCA</em>, <em>34</em>(1), 283–298. (<a
href="https://doi.org/10.1007/s00521-021-06386-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-to-image translation translates an image from one domain to another. The goal is to learn the translation relationship between different image domains. Compared with the translation models to be trained using paired training data, CycleGAN has the advantage of learning to translate between domains without paired input–output training examples. However, when using CycleGAN to translate images among multiple domains, the complexity of the model increases nonlinearly with the number of domains. To reduce the model complexity of CycleGAN-based translation models, we assume that there is a hidden space shared by different domains, and this space stores the common features of images. Then, we design a common encoder to learn image features in the hidden space. Based on the hidden space, we propose a translation model that scales linearly with the number of domains. To further improve the common feature representation accuracy, we introduce the adversarial component in the hidden space to learn the common features. We test the proposed models on different datasets, including painting style and season transfer datasets and achieve good results.},
  archive      = {J_NCA},
  author       = {Yuxin, Ding and Longfei, Wang},
  doi          = {10.1007/s00521-021-06386-9},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {283-298},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multidomain image-to-image translation model based on hidden space sharing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial neural network for prediction of thermal
conductivity of rGO–metal oxide nanocomposite-based nanofluids.
<em>NCA</em>, <em>34</em>(1), 271–282. (<a
href="https://doi.org/10.1007/s00521-021-06366-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A four-input artificial neural network (ANN) model has been presented for the prediction of thermal conductivity of rGO–metal oxide nanocomposite-based nanofluids. For this, data of five types of water-based nanofluids containing rGO–metal oxide nanocomposites particles were used from the available literature. The four-input variables considered were molecular weight of nanocomposite, average particle size of nanocomposites, concentration, and temperature of nanofluid which exhibited thermal conductivity of the nanofluids as output. Using the same architecture, two ANN models were developed, one using a total of 185 data points and the other by dividing the data points in two sets (training and testing). The model agreed well with the experimental data and exhibited an R2 value of 0.956 for the testing data set. Also, the magnitude of deviation of the predicted thermal conductivity for all the data points was very less with an average residual of ± 0.048 W/mK.},
  archive      = {J_NCA},
  author       = {Barai, Divya P. and Bhanvase, Bharat A. and Pandharipande, Shekhar L.},
  doi          = {10.1007/s00521-021-06366-z},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {271-282},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial neural network for prediction of thermal conductivity of rGO–metal oxide nanocomposite-based nanofluids},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bi-directional facial attribute transfer framework:
Transfer your single facial attribute to a portrait illustration.
<em>NCA</em>, <em>34</em>(1), 253–270. (<a
href="https://doi.org/10.1007/s00521-021-06360-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial attribute transfer aims to transfer target facial attributes—such as beard, bangs and opening mouth—to a face without them in a source facial image while keeping non-target attributes of the face intact. Existing methods for facial attribute transfer are basically homogeneous images oriented, which focus on transferring target attributes to (or between) photorealistic facial images. In this paper, facial attribute transfer between heterogeneous images is addressed, which is a new and more challenging task. More specifically, we propose a bi-directional facial attribute transfer method based on GAN (generative adversarial network) and latent representation in a new way, for the instance based facial attribute transfer that aims to transfer a target facial attribute with its basic shape from a reference photorealistic facial image to a source realistic portrait illustration and vice versa (i.e., erasing the target attribute in the facial image). How to achieve visual style consistency of the transferred attribute in the heterogeneous result images and overcome information dimensionality imbalance between photorealistic facial images and realistic portrait illustrations are the key points in our work. We deal with content and visual style of an image separately in latent representation learning by the composite encoder designed with the architecture of convolutional neural network and fully connected neural network, which is different from previous latent representation based facial attribute transfer methods that mix content and visual style in a latent representation. The approach turns out to well preserve the visual style consistency. Besides, we introduce different multipliers for weights of loss items in our objective functions to balance information imbalance between heterogeneous images. Experiments show that our method is capable of achieving facial attribute transfer between heterogeneous images with good results. For purpose of quantitative analysis, FID scores of our method on a couple of datasets are also given to show its effectiveness.},
  archive      = {J_NCA},
  author       = {Shi, Rong-xiao and Ye, Dong-yi and Chen, Zhao-jiong},
  doi          = {10.1007/s00521-021-06360-5},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {253-270},
  shortjournal = {Neural Comput. Appl.},
  title        = {A bi-directional facial attribute transfer framework: Transfer your single facial attribute to a portrait illustration},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Inverse optimal synchronization control of competitive
neural networks with constant time delays. <em>NCA</em>, <em>34</em>(1),
241–251. (<a href="https://doi.org/10.1007/s00521-021-06358-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Competitive neural networks (CNNs) are a class of two-time-scale neural networks which can simultaneously represent fast neural activity and slow changes in synapses. In this paper, by means of the drive-response idea and inverse optimality techniques, the optimal synchronization control of two CNNs with constant time delays is solved by considering the inverse optimal synchronization control of the error system. Considering the coupling relationship between fast and slow dynamics of the error system, the control Lyapunov function (CLF) is constructed first. Then, based on the CLF, a state feedback inverse optimal synchronization controller design method is proposed to synchronize two CNNs and minimize a meaningful performance functional while avoiding solving the Hamilton–Jacobi–Bellman (HJB) equation. The designed controller is linear and easy to implement. Finally, the feasibility and superiority of the presented method is illustrated by an example.},
  archive      = {J_NCA},
  author       = {Liu, Xiaomin and Yang, Chunyu and Zhu, Song},
  doi          = {10.1007/s00521-021-06358-z},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {241-251},
  shortjournal = {Neural Comput. Appl.},
  title        = {Inverse optimal synchronization control of competitive neural networks with constant time delays},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Longitudinal wind field prediction based on DDPG.
<em>NCA</em>, <em>34</em>(1), 227–239. (<a
href="https://doi.org/10.1007/s00521-021-06356-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parafoil is a kind of flexible aircraft, which has strong load capacity and long flight time but is easily disturbed by wind field. In the homing stage of parafoil from a high-altitude wind field to a low-altitude wind field, the low-altitude wind field is unmeasurable, which has a bad effect on the parafoil trajectory planning. To solve this problem, longitudinal prediction of the low-altitude wind field is proposed by intelligent processing of the high-altitude wind field data estimated by the parafoil. Since spatial wind field has the characteristics of hierarchical recursion and dynamic change, a deep deterministic policy gradient prediction model with Elman neural network as the core is proposed in this paper. Finally, the prediction effect of high accuracy and low-level precision attenuation, which provide reference information for the parafoil track planning, is realized.},
  archive      = {J_NCA},
  author       = {Yu, Zhenping and Tan, Panlong and Sun, Qinglin and Sun, Hao and Chen, Zengqiang},
  doi          = {10.1007/s00521-021-06356-1},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {227-239},
  shortjournal = {Neural Comput. Appl.},
  title        = {Longitudinal wind field prediction based on DDPG},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Glioma segmentation of optimized 3D u-net and prediction of
multi-modal survival time. <em>NCA</em>, <em>34</em>(1), 211–225. (<a
href="https://doi.org/10.1007/s00521-021-06351-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is difficult to segment Glioma and its internal structure because the Glioma boundaries have edemas and complex internal structures. This paper proposes a new optimized, integrated 3D U-Net network to achieve accurate segmentation of Glioma and internal subareas. The contribution of this paper is twofold, it studies the clinical path of patients with Glioma and constructs an optimized 3D U-Net deep learning algorithm by combining them with the radiologic feature set. The proposed model was validated in the published Glioma operation data set of multi-modal MRI resonance images and clinicians manual segmentation data. The model can accurately segment the MRI multi-modality images of Glioma and intra-tumour nodes and achieve the multi-modality prediction of the overall survival period of patients. The experimental results further indicated that the segmentation accuracy of the proposed method was higher than other sophisticated methods. The Dice similarity coefficients of the whole tumor (WT) region, the core tumor (CT) region, and the augmentation / enhanced tumor (ET) region, were 0.9632, 0.8763, and 0.8421, respectively, which are better than the clinical experts’ manual segmentation results. Hence, this research can effectively promote the development of deep learning clinical precise diagnosis and medical technology for Glioma.},
  archive      = {J_NCA},
  author       = {Liu, Qihong and Liu, Kai and Bolufé-Röhler, Antonio and Cai, Jing and He, Ling},
  doi          = {10.1007/s00521-021-06351-6},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {211-225},
  shortjournal = {Neural Comput. Appl.},
  title        = {Glioma segmentation of optimized 3D U-net and prediction of multi-modal survival time},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A state-of-the-art review on shading mitigation techniques
in solar photovoltaics via meta-heuristic approach. <em>NCA</em>,
<em>34</em>(1), 171–209. (<a
href="https://doi.org/10.1007/s00521-021-06586-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the production of solar photovoltaic (SPV)-based cleaner energy, the maximum power point (MPP) tracking (MPPT) schemes are utilized. To ensure a reliable and effective MPP extraction from SPV systems, the exploitation and implementation of different MPPT schemes are of great significance. This article intends to present a rigorous and comprehensive review of MPPT schemes in SPV systems under partial shading (PS) conditions based on a meta-heuristic approach and artificial neural network (ANN). In recent years, modern optimization-based global MPP (GMPP) extraction schemes are gaining much attention from researchers. In this review article, thirteen modern optimizations and ANN-based GMPP tracking techniques are vividly described with their flowchart and detailed mathematical modeling. This work assesses all the schemes according to parameters like tracking efficacy, tracking time, application, sensed parameters, converter utilized, steady-state oscillations, experimental setup, and key notes. Based on the rigorous review, a novel GMPP extraction scheme based on a recently introduced meta-heuristic approach named artificial gorilla troops optimizer is proposed. This review work serves as a source of comprehensive information about applying these MPPT techniques to extract GMPP from the SPV system under PS conditions; furthermore, it can be considered a one-stop handbook for further study in this field.},
  archive      = {J_NCA},
  author       = {Pathak, Pawan Kumar and Yadav, Anil Kumar and Alvi, P. A.},
  doi          = {10.1007/s00521-021-06586-3},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {171-209},
  shortjournal = {Neural Comput. Appl.},
  title        = {A state-of-the-art review on shading mitigation techniques in solar photovoltaics via meta-heuristic approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of artificial intelligence applied to path planning
in UAV swarms. <em>NCA</em>, <em>34</em>(1), 153–170. (<a
href="https://doi.org/10.1007/s00521-021-06569-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path Planning problems with Unmanned Aerial Vehicles (UAVs) are among the most studied knowledge areas in the related literature. However, few of them have been applied to groups of UAVs. The use of swarms allows to speed up the flight time and, thus, reducing the operational costs. When combined with Artificial Intelligence (AI) algorithms, a single system or operator can control all aircraft while optimal paths for each one can be computed. In order to introduce the current situation of these AI-based systems, a review of the most novel and relevant articles was carried out. This review was performed in two steps: first, a summary of the found articles; second, a quantitative analysis of the publications found based on different factors, such as the temporal evolution or the number of articles found based on different criteria. Therefore, this review provides not only a summary of the most recent work but it gives an overview of the trend in the use of AI algorithms in UAV swarms for Path Planning problems. The AI techniques of the articles found can be separated into four main groups based on their technique: reinforcement Learning techniques, Evolutive Computing techniques, Swarm Intelligence techniques, and, Graph Neural Networks. The final results show an increase in publications in recent years and that there is a change in the predominance of the most widely used techniques.},
  archive      = {J_NCA},
  author       = {Puente-Castro, Alejandro and Rivero, Daniel and Pazos, Alejandro and Fernandez-Blanco, Enrique},
  doi          = {10.1007/s00521-021-06569-4},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {153-170},
  shortjournal = {Neural Comput. Appl.},
  title        = {A review of artificial intelligence applied to path planning in UAV swarms},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Continually trained life-long classification. <em>NCA</em>,
<em>34</em>(1), 135–152. (<a
href="https://doi.org/10.1007/s00521-021-06154-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two challenges can be found in a life-long classifier that learns continually: the concept drift, when the probability distribution of data is changing in time, and catastrophic forgetting when the earlier learned knowledge is lost. There are many proposed solutions to each challenge, but very little research is done to solve both challenges simultaneously. We show that both the concept drift and catastrophic forgetting are closely related to our proposed description of the life-long continual classification. We describe the process of continual learning as a wrap modification, where a wrap is a manifold that can be trained to cover or uncover a given set of samples. The notion of wraps and their cover/uncover modifiers are theoretical building blocks of a novel general life-long learning scheme, implemented as an ensemble of variational autoencoders. The proposed algorithm is examined on evaluation scenarios for continual learning and compared to state-of-the-art algorithms demonstrating the robustness to catastrophic forgetting and adaptability to concept drift but also showing the new challenges of the life-long classification.},
  archive      = {J_NCA},
  author       = {Szadkowski, Rudolf and Drchal, Jan and Faigl, Jan},
  doi          = {10.1007/s00521-021-06154-9},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {135-152},
  shortjournal = {Neural Comput. Appl.},
  title        = {Continually trained life-long classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic identification of the number of clusters in
hierarchical clustering. <em>NCA</em>, <em>34</em>(1), 119–134. (<a
href="https://doi.org/10.1007/s00521-021-05873-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical clustering is one of the most suitable tools to discover the underlying true structure of a dataset in the case of unsupervised learning where the ground truth is unknown and classical machine learning classifiers are not suitable. In many real applications, it provides a perspective on inner data structure and is preferred to partitional methods. However, determining the resulting number of clusters in hierarchical clustering requires human expertise to deduce this from the dendrogram and this represents a major challenge in making a fully automatic system such as the ones required for decision support in Industry 4.0. This research proposes a general criterion to perform the cut of a dendrogram automatically, by comparing six original criteria based on the Calinski-Harabasz index. The performance of each criterion on 95 real-life dendrograms of different topologies is evaluated against the number of classes proposed by the experts and a winner criterion is determined. This research is framed in a bigger project to build an Intelligent Decision Support system to assess the performance of 3D printers based on sensor data in real-time, although the proposed criteria can be used in other real applications of hierarchical clustering.The methodology is applied to a real-life dataset from the 3D printers and the huge reduction in CPU time is also shown by comparing the CPU time before and after this modification of the entire clustering method. It also reduces the dependability on human-expert to provide the number of clusters by inspecting the dendrogram. Further, such a process allows applying hierarchical clustering in an automatic mode in real-life industrial applications and allows the continuous monitoring of real 3D printers in production, and helps in building an Intelligent Decision Support System to detect operational modes, anomalies, and other behavioral patterns.},
  archive      = {J_NCA},
  author       = {Karna, Ashutosh and Gibert, Karina},
  doi          = {10.1007/s00521-021-05873-3},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {119-134},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic identification of the number of clusters in hierarchical clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Supervised learning in the presence of concept drift: A
modelling framework. <em>NCA</em>, <em>34</em>(1), 101–118. (<a
href="https://doi.org/10.1007/s00521-021-06035-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a modelling framework for the investigation of supervised learning in non-stationary environments. Specifically, we model two example types of learning systems: prototype-based learning vector quantization (LVQ) for classification and shallow, layered neural networks for regression tasks. We investigate so-called student–teacher scenarios in which the systems are trained from a stream of high-dimensional, labeled data. Properties of the target task are considered to be non-stationary due to drift processes while the training is performed. Different types of concept drift are studied, which affect the density of example inputs only, the target rule itself, or both. By applying methods from statistical physics, we develop a modelling framework for the mathematical analysis of the training dynamics in non-stationary environments. Our results show that standard LVQ algorithms are already suitable for the training in non-stationary environments to a certain extent. However, the application of weight decay as an explicit mechanism of forgetting does not improve the performance under the considered drift processes. Furthermore, we investigate gradient-based training of layered neural networks with sigmoidal activation functions and compare with the use of rectified linear units. Our findings show that the sensitivity to concept drift and the effectiveness of weight decay differs significantly between the two types of activation function.},
  archive      = {J_NCA},
  author       = {Straat, M. and Abadi, F. and Kan, Z. and Göpfert, C. and Hammer, B. and Biehl, M.},
  doi          = {10.1007/s00521-021-06035-1},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {101-118},
  shortjournal = {Neural Comput. Appl.},
  title        = {Supervised learning in the presence of concept drift: A modelling framework},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Passive concept drift handling via variations of learning
vector quantization. <em>NCA</em>, <em>34</em>(1), 89–100. (<a
href="https://doi.org/10.1007/s00521-020-05242-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept drift is a change of the underlying data distribution which occurs especially with streaming data. Besides other challenges in the field of streaming data classification, concept drift has to be addressed to obtain reliable predictions. Robust Soft Learning Vector Quantization as well as Generalized Learning Vector Quantization has already shown good performance in traditional settings and is modified in this work to handle streaming data. Further, momentum-based stochastic gradient descent techniques are applied to tackle concept drift passively due to increased learning capabilities. The proposed work is tested against common benchmark algorithms and streaming data in the field and achieved promising results.},
  archive      = {J_NCA},
  author       = {Heusinger, Moritz and Raab, Christoph and Schleif, Frank-Michael},
  doi          = {10.1007/s00521-020-05242-6},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {89-100},
  shortjournal = {Neural Comput. Appl.},
  title        = {Passive concept drift handling via variations of learning vector quantization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantum-inspired learning vector quantizers for
prototype-based classification. <em>NCA</em>, <em>34</em>(1), 79–88. (<a
href="https://doi.org/10.1007/s00521-020-05517-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prototype-based models like the Generalized Learning Vector Quantization (GLVQ) belong to the class of interpretable classifiers. Moreover, quantum-inspired methods get more and more into focus in machine learning due to its potential efficient computing. Further, its interesting mathematical perspectives offer new ideas for alternative learning scenarios. This paper proposes a quantum computing-inspired variant of the prototype-based GLVQ for classification learning. We start considering kernelized GLVQ with real- and complex-valued kernels and their respective feature mapping. Thereafter, we explain how quantum space ideas could be integrated into a GLVQ using quantum bit vector space in the quantum state space $${\mathcal {H}}^{n}$$ and show the relations to kernelized GLVQ. In particular, we explain the related feature mapping of data into the quantum state space $${\mathcal {H}}^{n}$$ . A key feature for this approach is that $${\mathcal {H}}^{n}$$ is an Hilbert space with particular inner product properties, which finally restrict the prototype adaptations to be unitary transformations. The resulting approach is denoted as Qu-GLVQ. We provide the mathematical framework and give exemplary numerical results.},
  archive      = {J_NCA},
  author       = {Villmann, Thomas and Engelsberger, Alexander and Ravichandran, Jensun and Villmann, Andrea and Kaden, Marika},
  doi          = {10.1007/s00521-020-05517-y},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {79-88},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quantum-inspired learning vector quantizers for prototype-based classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning vector quantization as an interpretable classifier
for the detection of SARS-CoV-2 types based on their RNA sequences.
<em>NCA</em>, <em>34</em>(1), 67–78. (<a
href="https://doi.org/10.1007/s00521-021-06018-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an approach to discriminate SARS-CoV-2 virus types based on their RNA sequence descriptions avoiding a sequence alignment. For that purpose, sequences are preprocessed by feature extraction and the resulting feature vectors are analyzed by prototype-based classification to remain interpretable. In particular, we propose to use variants of learning vector quantization (LVQ) based on dissimilarity measures for RNA sequence data. The respective matrix LVQ provides additional knowledge about the classification decisions like discriminant feature correlations and, additionally, can be equipped with easy to realize reject options for uncertain data. Those options provide self-controlled evidence, i.e., the model refuses to make a classification decision if the model evidence for the presented data is not sufficient. This model is first trained using a GISAID dataset with given virus types detected according to the molecular differences in coronavirus populations by phylogenetic tree clustering. In a second step, we apply the trained model to another but unlabeled SARS-CoV-2 virus dataset. For these data, we can either assign a virus type to the sequences or reject atypical samples. Those rejected sequences allow to speculate about new virus types with respect to nucleotide base mutations in the viral sequences. Moreover, this rejection analysis improves model robustness. Last but not least, the presented approach has lower computational complexity compared to methods based on (multiple) sequence alignment.},
  archive      = {J_NCA},
  author       = {Kaden, Marika and Bohnsack, Katrin Sophie and Weber, Mirko and Kudła, Mateusz and Gutowska, Kaja and Blazewicz, Jacek and Villmann, Thomas},
  doi          = {10.1007/s00521-021-06018-2},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {67-78},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning vector quantization as an interpretable classifier for the detection of SARS-CoV-2 types based on their RNA sequences},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Topographic mapping for quality inspection and intelligent
filtering of smart-bracelet data. <em>NCA</em>, <em>34</em>(1), 51–65.
(<a href="https://doi.org/10.1007/s00521-020-05600-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wrist-worn wearable devices equipped with heart activity sensors can provide valuable data that can be used for preventative health. However, hearth activity analysis from these devices suffers from noise introduced by motion artifacts. Methods traditionally used to remove outliers based on motion data can yield to discarding clean data, if some movement was present, and accepting noisy data, i.e., subject was still but the sensor was misplaced. This work shows that self-organizing maps (SOMs) can be used to effectively accept or reject sections of heart data collected from unreliable devices, such as wrist-worn devices. In particular, the proposed SOM-based filter can accept a larger amount of measurements (less false negatives) with an higher overall quality with respect to methods solely based on statistical analysis of motion data. We provide an empirical analysis on real-world wearable data, comprising heart and motion data of users. We show how topographic mapping can help identifying and interpreting patterns in the sensor data and help relating them to an assessment of user state. More importantly, our experimental results show the proposed approach is able to retain almost twice the amount of data while keeping samples with an error that is an order of magnitude lower with respect to a filter based on accelerometric data.},
  archive      = {J_NCA},
  author       = {Bacciu, Davide and Bertoncini, Gioele and Morelli, Davide},
  doi          = {10.1007/s00521-020-05600-4},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {51-65},
  shortjournal = {Neural Comput. Appl.},
  title        = {Topographic mapping for quality inspection and intelligent filtering of smart-bracelet data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-organizing mappings on the flag manifold with
applications to hyper-spectral image data analysis. <em>NCA</em>,
<em>34</em>(1), 39–49. (<a
href="https://doi.org/10.1007/s00521-020-05579-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A flag is a nested sequence of vector spaces. The type of the flag encodes the sequence of dimensions of the vector spaces making up the flag. A flag manifold is a manifold whose points parameterize all flags of a fixed type in a fixed vector space. This paper provides the mathematical framework necessary for implementing self-organizing mappings on flag manifolds. Flags arise implicitly in many data analysis contexts including wavelet, Fourier, and singular value decompositions. The proposed geometric framework in this paper enables the computation of distances between flags, the computation of geodesics between flags, and the ability to move one flag a prescribed distance in the direction of another flag. Using these operations as building blocks, we implement the SOM algorithm on a flag manifold. The basic algorithm is applied to the problem of parameterizing a set of flags of a fixed type.},
  archive      = {J_NCA},
  author       = {Ma, Xiaofeng and Kirby, Michael and Peterson, Chris},
  doi          = {10.1007/s00521-020-05579-y},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {39-49},
  shortjournal = {Neural Comput. Appl.},
  title        = {Self-organizing mappings on the flag manifold with applications to hyper-spectral image data analysis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DM-pruning CADJ graphs for SOM clustering. <em>NCA</em>,
<em>34</em>(1), 25–38. (<a
href="https://doi.org/10.1007/s00521-021-05831-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As topology representing networks, the Cumulative ADJacency graph CADJ and its symmetric version $${{\text{CONN}}} = {\text{CADJ}} + {\text{CADJ}}^T$$ Tasdemir and Merenyi (IEEE Trans Neural Netw 20(4): 549–562, 2009), can be utilized as inputs to graph-based clustering (GBC) paradigms for partitioning the learned prototypes of a vector quantizer. To express complex data faithfully, CADJ must typically be pruned (thresholded, or made sparse) to be most effective as an input to GBC routines, whether they be algorithmic or driven by human assessment. This work, given in two parts, develops a formal framework for CADJ pruning as a preprocessing (sparsifying) step to improve CADJ’s use in any GBC routine. That is, rather than advocating a particular GBC method, our goal is development of sensible logic for creating sparse CADJ inputs to the entire family of GBC methods. Part 1 defines an overall quality measure for each CADJ edge by extending lines of reasoning used successfully in the past to prune CONN graphs. Part 2 introduces a Bayesian Dirichlet-multinomial (DM) model of CADJ edge weights with an intelligent prior constructed through analysis of the Voronoi tessellation generated by the vector quantization. The DM likelihood offers an internal assessment of information loss resulting from iterative CADJ edge removal, which is used to determine an optimal stopping criterion for the pruning process. We show that DM-Pruned CADJ graphs lead to GBCs comparable to the best previously achieved on highly structured real data.},
  archive      = {J_NCA},
  author       = {Taylor, Josh and Merényi, Erzsébet},
  doi          = {10.1007/s00521-021-05831-z},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {25-38},
  shortjournal = {Neural Comput. Appl.},
  title        = {DM-pruning CADJ graphs for SOM clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SOM-based aggregation for graph convolutional neural
networks. <em>NCA</em>, <em>34</em>(1), 5–24. (<a
href="https://doi.org/10.1007/s00521-020-05484-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph property prediction is becoming more and more popular due to the increasing availability of scientific and social data naturally represented in a graph form. Because of that, many researchers are focusing on the development of improved graph neural network models. One of the main components of a graph neural network is the aggregation operator, needed to generate a graph-level representation from a set of node-level embeddings. The aggregation operator is critical since it should, in principle, provide a representation of the graph that is isomorphism invariant, i.e. the graph representation should be a function of graph nodes treated as a set. DeepSets (in: Advances in neural information processing systems, pp 3391–3401, 2017) provides a framework to construct a set-aggregation operator with universal approximation properties. In this paper, we propose a DeepSets aggregation operator, based on Self-Organizing Maps (SOM), to transform a set of node-level representations into a single graph-level one. The adoption of SOMs allows to compute node representations that embed the information about their mutual similarity. Experimental results on several real-world datasets show that our proposed approach achieves improved predictive performance compared to the commonly adopted sum aggregation and many state-of-the-art graph neural network architectures in the literature.},
  archive      = {J_NCA},
  author       = {Pasa, Luca and Navarin, Nicolò and Sperduti, Alessandro},
  doi          = {10.1007/s00521-020-05484-4},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {5-24},
  shortjournal = {Neural Comput. Appl.},
  title        = {SOM-based aggregation for graph convolutional neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A self-organizing world: Special issue of the 13th edition
of the workshop on self-organizing maps and learning vector
quantization, clustering and data visualization, WSOM + 2019.
<em>NCA</em>, <em>34</em>(1), 1–3. (<a
href="https://doi.org/10.1007/s00521-021-06307-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Vellido, Alfredo and Angulo, Cecilio and Gibert, Karina},
  doi          = {10.1007/s00521-021-06307-w},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {1-3},
  shortjournal = {Neural Comput. Appl.},
  title        = {A self-organizing world: Special issue of the 13th edition of the workshop on self-organizing maps and learning vector quantization, clustering and data visualization, WSOM + 2019},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
