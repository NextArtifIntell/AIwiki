<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MPC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mpc---21">MPC - 21</h2>
<ul>
<li><details>
<summary>
(2022). On technical debt in mathematical programming: An
exploratory study. <em>MPC</em>, <em>14</em>(4), 781–818. (<a
href="https://doi.org/10.1007/s12532-022-00225-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Technical Debt (TD) metaphor describes development shortcuts taken for expediency that cause the degradation of internal software quality. It has served the discourse between engineers and management regarding how to invest resources in maintenance and extend into scientific software (both the tools, the algorithms and the analysis conducted with it). Mathematical programming has been considered ‘special purpose programming’, meant to program and simulate particular problem types (e.g., symbolic mathematics through Matlab). Likewise, more traditional mathematical programming has been considered ‘modelling programming’ to program models by providing programming structures required for mathematical formulations (e.g., GAMS, AMPL, AIMMS). Because of this, other authors have argued the need to consider mathematical programming as closely related to software development. As a result, this paper presents a novel exploration of TD in mathematical programming by assessing self-reported practices through a survey, which gathered 168 complete responses. This study discovered potential debts manifested through smells and attitudinal causes towards them. Results uncovered a trend to refactor and polish the final mathematical model and use version control and detailed comments. Nonetheless, we uncovered traces of negative practices regarding Code Debt and Documentation Debt, alongside hints indicating that most TD is deliberately introduced (i.e., modellers are aware that their practices are not the best). We aim to discuss the idea that TD is also present in mathematical programming and that it may hamper the reproducibility and maintainability of the models created. The overall goal is to outline future areas of work that can lead to changing current modellers’ habits and assist in extending existing mathematical programming (both practice and research) to eventually manage TD in mathematical programming.},
  archive      = {J_MPC},
  author       = {Vidoni, Melina and Cunico, Maria Laura},
  doi          = {10.1007/s12532-022-00225-1},
  journal      = {Mathematical Programming Computation},
  number       = {4},
  pages        = {781-818},
  shortjournal = {Math. Program. Comput.},
  title        = {On technical debt in mathematical programming: An exploratory study},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An integrated local-search/set-partitioning refinement
heuristic for the capacitated vehicle routing problem. <em>MPC</em>,
<em>14</em>(4), 749–779. (<a
href="https://doi.org/10.1007/s12532-022-00224-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an effective heuristic algorithm for large-scale instances of the Capacitated Vehicle Routing Problem is proposed. The technique consists in a local search method entangled with a restricted Set Partitioning problem optimization. Helsgaun’s LKH-3 algorithm has been used for the local search phase, with a number of implementation improvements. The restricted Set Partitioning formulation is solved by means of an exact commercial Integer Liner Programming solver. The resulting algorithm is able to consistently improve the solutions obtained by a state-of-the-art heuristic from the literature, as well as some of the best-know solutions maintained by the CVRPLIB website.},
  archive      = {J_MPC},
  author       = {Cavaliere, Francesco and Bendotti, Emilio and Fischetti, Matteo},
  doi          = {10.1007/s12532-022-00224-2},
  journal      = {Mathematical Programming Computation},
  number       = {4},
  pages        = {749-779},
  shortjournal = {Math. Program. Comput.},
  title        = {An integrated local-search/set-partitioning refinement heuristic for the capacitated vehicle routing problem},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A graph-based modeling abstraction for optimization:
Concepts and implementation in plasmo.jl. <em>MPC</em>, <em>14</em>(4),
699–747. (<a href="https://doi.org/10.1007/s12532-022-00223-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a general graph-based modeling abstraction for optimization that we call an OptiGraph. Under this abstraction, any optimization problem is treated as a hierarchical hypergraph in which nodes represent optimization subproblems and edges represent connectivity between such subproblems. The abstraction enables the modular construction of complex models in an intuitive manner, facilitates the use of graph analysis tools (to perform partitioning, aggregation, and visualization tasks), and facilitates communication of structures to decomposition algorithms. We provide an open-source implementation of the abstraction in the Julia-based package Plasmo.jl. We provide tutorial examples and large application case studies to illustrate the capabilities.},
  archive      = {J_MPC},
  author       = {Jalving, Jordan and Shin, Sungho and Zavala, Victor M.},
  doi          = {10.1007/s12532-022-00223-3},
  journal      = {Mathematical Programming Computation},
  number       = {4},
  pages        = {699-747},
  shortjournal = {Math. Program. Comput.},
  title        = {A graph-based modeling abstraction for optimization: Concepts and implementation in plasmo.jl},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced formulation for the guillotine 2D cutting knapsack
problem. <em>MPC</em>, <em>14</em>(4), 673–697. (<a
href="https://doi.org/10.1007/s12532-022-00222-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We advance the state of the art in Mixed-Integer Linear Programming formulations for Guillotine 2D Cutting Problems by (i) adapting a previously-known reduction to our preprocessing phase (plate-size normalization) and by (ii) enhancing a previous formulation (PP-G2KP from Furini et alli) by cutting down its size and symmetries. Our focus is the Guillotine 2D Knapsack Problem with orthogonal and unrestricted cuts, constrained demand, unlimited stages, and no rotation – however, the formulation may be adapted to many related problems. The code is available. Concerning the set of 59 instances used to benchmark the original formulation, the enhanced formulation takes about 4 hours to solve all instances while the original formulation takes 12 hours to solve 53 of them (the other six runs hit a three-hour time limit each). We integrate, to both formulations, a pricing framework proposed for the original formulation; the enhanced formulation keeps a significant advantage in this situation. Finally, in a recently proposed set of 80 harder instances, the enhanced formulation (with and without the pricing framework) found: 22 optimal solutions (5 already known, 17 new); better lower bounds for 25 instances; better upper bounds for 58 instances.},
  archive      = {J_MPC},
  author       = {Becker, Henrique and Araújo, Olinto and Buriol, Luciana S.},
  doi          = {10.1007/s12532-022-00222-4},
  journal      = {Mathematical Programming Computation},
  number       = {4},
  pages        = {673-697},
  shortjournal = {Math. Program. Comput.},
  title        = {Enhanced formulation for the guillotine 2D cutting knapsack problem},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Political districting to minimize cut edges. <em>MPC</em>,
<em>14</em>(4), 623–672. (<a
href="https://doi.org/10.1007/s12532-022-00221-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When constructing political districting plans, prominent criteria include population balance, contiguity, and compactness. The compactness of a districting plan, which is often judged by the “eyeball test”, has been quantified in many ways, e.g., Length-Width, Polsby-Popper, and Moment-of-Inertia. This paper considers the number of cut edges, which has recently gained traction in the redistricting literature as a measure of compactness because it is simple and reasonably agrees with the eyeball test. We study the stylized problem of minimizing the number of cut edges, subject to constraints on population balance and contiguity. With the integer programming techniques proposed in this paper, all county-level instances in the USA (and some tract-level instances) can be solved to optimality. Our techniques extend to minimize weighted cut edges (e.g., to minimize district perimeter length) or to impose compactness constraints. All data, code, and results are on GitHub.},
  archive      = {J_MPC},
  author       = {Validi, Hamidreza and Buchanan, Austin},
  doi          = {10.1007/s12532-022-00221-5},
  journal      = {Mathematical Programming Computation},
  number       = {4},
  pages        = {623-672},
  shortjournal = {Math. Program. Comput.},
  title        = {Political districting to minimize cut edges},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Allocation of fungible resources via a fast, scalable price
discovery method. <em>MPC</em>, <em>14</em>(3), 593–622. (<a
href="https://doi.org/10.1007/s12532-022-00220-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of assigning or allocating resources to a set of jobs. We consider the case when the resources are fungible, that is, the job can be done with any mix of the resources, but with different efficiencies. In our formulation we maximize a total utility subject to a given limit on the resource usage, which is a convex optimization problem and so is tractable. In this paper we develop a custom, parallelizable algorithm for solving the resource allocation problem that scales to large problems, with millions of jobs. Our algorithm is based on the dual problem, in which the dual variables associated with the resource usage limit can be interpreted as resource prices. Our method updates the resource prices in each iteration, ultimately discovering the optimal resource prices, from which an optimal allocation is obtained. We provide an open-source implementation of our method, which can solve problems with millions of jobs in a few seconds on CPU, and under a second on a GPU; our software can solve smaller problems in milliseconds. On large problems, our implementation is up to three orders of magnitude faster than a commercial solver for convex optimization.},
  archive      = {J_MPC},
  author       = {Agrawal, Akshay and Boyd, Stephen and Narayanan, Deepak and Kazhamiaka, Fiodar and Zaharia, Matei},
  doi          = {10.1007/s12532-022-00220-6},
  journal      = {Mathematical Programming Computation},
  number       = {3},
  pages        = {593-622},
  shortjournal = {Math. Program. Comput.},
  title        = {Allocation of fungible resources via a fast, scalable price discovery method},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Limited-memory common-directions method for large-scale
optimization: Convergence, parallelization, and distributed
optimization. <em>MPC</em>, <em>14</em>(3), 543–591. (<a
href="https://doi.org/10.1007/s12532-022-00219-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a limited-memory common-directions method for smooth optimization that interpolates between first- and second-order methods. At each iteration, a subspace of a limited dimension size is constructed using first-order information from previous iterations, and an efficient Newton method is deployed to find an approximate minimizer within this subspace. With properly selected subspace of dimension as small as two, the proposed algorithm achieves the optimal convergence rates for first-order methods while remaining a descent method, and it also possesses fast convergence speed on nonconvex problems. Since the major operations of our method are dense matrix-matrix operations, the proposed method can be efficiently parallelized in multicore environments even for sparse problems. By wisely utilizing historical information, our method is also communication-efficient in distributed optimization that uses multiple machines as the Newton steps can be calculated with little communication. Numerical study shows that our method has superior empirical performance on real-world large-scale machine learning problems.},
  archive      = {J_MPC},
  author       = {Lee, Ching-pei and Wang, Po-Wei and Lin, Chih-Jen},
  doi          = {10.1007/s12532-022-00219-z},
  journal      = {Mathematical Programming Computation},
  number       = {3},
  pages        = {543-591},
  shortjournal = {Math. Program. Comput.},
  title        = {Limited-memory common-directions method for large-scale optimization: Convergence, parallelization, and distributed optimization},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). QPALM: A proximal augmented lagrangian method for nonconvex
quadratic programs. <em>MPC</em>, <em>14</em>(3), 497–541. (<a
href="https://doi.org/10.1007/s12532-022-00218-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose QPALM, a nonconvex quadratic programming (QP) solver based on the proximal augmented Lagrangian method. This method solves a sequence of inner subproblems which can be enforced to be strongly convex and which therefore admit a unique solution. The resulting steps are shown to be equivalent to inexact proximal point iterations on the extended-real-valued cost function, which allows for a fairly simple analysis where convergence to a stationary point at an $$R$$ -linear rate is shown. The QPALM algorithm solves the subproblems iteratively using semismooth Newton directions and an exact linesearch. The former can be computed efficiently in most iterations by making use of suitable factorization update routines, while the latter requires the zero of a monotone, one-dimensional, piecewise affine function. QPALM is implemented in open-source C code, with tailored linear algebra routines for the factorization in a self-written package LADEL. The resulting implementation is shown to be extremely robust in numerical simulations, solving all of the Maros-Meszaros problems and finding a stationary point for most of the nonconvex QPs in the Cutest test set. Furthermore, it is shown to be competitive against state-of-the-art convex QP solvers in typical QPs arising from application domains such as portfolio optimization and model predictive control. As such, QPALM strikes a unique balance between solving both easy and hard problems efficiently.},
  archive      = {J_MPC},
  author       = {Hermans, Ben and Themelis, Andreas and Patrinos, Panagiotis},
  doi          = {10.1007/s12532-022-00218-0},
  journal      = {Mathematical Programming Computation},
  number       = {3},
  pages        = {497-541},
  shortjournal = {Math. Program. Comput.},
  title        = {QPALM: A proximal augmented lagrangian method for nonconvex quadratic programs},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). <span
class="math display"><code>T</code><code>e</code><code>n</code><code>s</code><code>c</code><code>a</code><code>l</code><code>c</code></span>:
A toolbox to generate fast code to solve nonlinear constrained
minimizations and compute nash equilibria. <em>MPC</em>, <em>14</em>(3),
451–496. (<a href="https://doi.org/10.1007/s12532-022-00216-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe the toolbox $$\mathtt {Tenscalc}$$ that generates specialized C-code to solve nonlinear constrained optimizations and to compute Nash equilibria. $$\mathtt {Tenscalc}$$ is aimed at scenarios where one needs to solve very fast a large number of optimizations that are structurally similar. This is common in applications where the optimizations depend on measured data and one wants to compute optima for large or evolving datasets, e.g., in robust estimation and classification, maximum likelihood estimation, model predictive control (MPC), moving horizon estimation (MHE), and combined MPC-MHE (which requires the computation of a saddle-point equilibria). $$\mathtt {Tenscalc}$$ is mostly aimed at generating solvers for optimizations with up to a few thousands of optimization variables/constraints and solve times up to a few milliseconds. The speed achieved by the solver arises from a combination of features: reuse of intermediate computations across and within iterations of the solver, detection and exploitation of matrix sparsity, avoidance of run-time memory allocation and garbage collection, and reliance on flat code that improves the efficiency of the microprocessor pipelining and caching. All these features have been automated and embedded into the code generation process. We include a few representative examples to illustrate how the speed and memory footprint of the solver scale with the size of the problem.},
  archive      = {J_MPC},
  author       = {Hespanha, João P.},
  doi          = {10.1007/s12532-022-00216-2},
  journal      = {Mathematical Programming Computation},
  number       = {3},
  pages        = {451-496},
  shortjournal = {Math. Program. Comput.},
  title        = {$$\mathtt {Tenscalc}$$: A toolbox to generate fast code to solve nonlinear constrained minimizations and compute nash equilibria},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A penalized method of alternating projections for weighted
low-rank hankel matrix optimization. <em>MPC</em>, <em>14</em>(3),
417–450. (<a href="https://doi.org/10.1007/s12532-022-00217-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weighted low-rank Hankel matrix optimization has long been used to reconstruct contaminated signal or forecast missing values for time series of a wide class. The Method of Alternating Projections (MAP) (i.e., alternatively projecting to a low-rank matrix manifold and the Hankel matrix subspace) is a leading method. Despite its wide use, MAP has long been criticized of lacking convergence and of ignoring the weights used to reflect importance of the observed data. The most of known results are in a local sense. In particular, the latest research shows that MAP may converge at a linear rate provided that the initial point is close enough to a true solution and a transversality condition is satisfied. In this paper, we propose a globalized variant of MAP through a penalty approach. The proposed method inherits the favourable local properties of MAP and has the same computational complexity. Moreover, it is capable of handling a general weight matrix, is globally convergent, and enjoys local linear convergence rate provided that the cutting off singular values are significantly smaller than the kept ones. Furthermore, the new method also applies to complex data. Extensive numerical experiments demonstrate the efficiency of the proposed method against several popular variants of MAP.},
  archive      = {J_MPC},
  author       = {Shen, Jian and Chen, Jein-Shan and Qi, Hou-Duo and Xiu, Naihua},
  doi          = {10.1007/s12532-022-00217-1},
  journal      = {Mathematical Programming Computation},
  number       = {3},
  pages        = {417-450},
  shortjournal = {Math. Program. Comput.},
  title        = {A penalized method of alternating projections for weighted low-rank hankel matrix optimization},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Asynchronous lagrangian scenario
decomposition. <em>MPC</em>, <em>14</em>(2), 415–416. (<a
href="https://doi.org/10.1007/s12532-021-00211-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MPC},
  author       = {Aravena, Ignacio and Papavasiliou, Anthony},
  doi          = {10.1007/s12532-021-00211-z},
  journal      = {Mathematical Programming Computation},
  number       = {2},
  pages        = {415-416},
  shortjournal = {Math. Program. Comput.},
  title        = {Correction to: Asynchronous lagrangian scenario decomposition},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient unconstrained black box optimization.
<em>MPC</em>, <em>14</em>(2), 365–414. (<a
href="https://doi.org/10.1007/s12532-021-00215-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the unconstrained optimization of black box functions, this paper introduces a new randomized algorithm called VRBBO. In practice, VRBBO matches the quality of other state-of-the-art algorithms for finding, in small and large dimensions, a local minimizer with reasonable accuracy. Although our theory guarantees only local minimizers our heuristic techniques turn VRBBO into an efficient global solver. In very thorough numerical experiments, we found in most cases either a global minimizer, or where this could not be checked, at least a point of similar quality to the best competitive global solvers. For smooth, everywhere defined functions, it is proved that, with probability arbitrarily close to 1, a basic version of our algorithm finds with $${{\mathcal {O}}}(n\varepsilon ^{-2})$$ function evaluations a point whose unknown exact gradient 2-norm is below a given threshold $$\varepsilon &gt;0$$ , where n is the dimension. In the smooth convex case, this number improves to $${{\mathcal {O}}}(n\log \varepsilon ^{-1})$$ and in the smooth (strongly) convex case to $${{\mathcal {O}}}(n\log n\varepsilon ^{-1})$$ . This matches known recent complexity results for reaching a slightly different goal, namely the expected unknown exact gradient 2-norm is below a given threshold $$\varepsilon &gt;0$$ . Numerical results show that VRBBO is effective and robust in comparison with the state-of-the-art local and global solvers on the unconstrained CUTEst test problems of Gould et al. (Comput Optim Appl 60:545–557, 2014) for optimization and the test problems of Jamil and Yang (Int J Math Model Numer Optim 4:150, 2013) for global optimization with 2–5000 variables.},
  archive      = {J_MPC},
  author       = {Kimiaei, Morteza and Neumaier, Arnold},
  doi          = {10.1007/s12532-021-00215-9},
  journal      = {Mathematical Programming Computation},
  number       = {2},
  pages        = {365-414},
  shortjournal = {Math. Program. Comput.},
  title        = {Efficient unconstrained black box optimization},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive primal-dual stochastic gradient method for
expectation-constrained convex stochastic programs. <em>MPC</em>,
<em>14</em>(2), 319–363. (<a
href="https://doi.org/10.1007/s12532-021-00214-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient methods (SGMs) have been widely used for solving stochastic optimization problems. A majority of existing works assume no constraints or easy-to-project constraints. In this paper, we consider convex stochastic optimization problems with expectation constraints. For these problems, it is often extremely expensive to perform projection onto the feasible set. Several SGMs in the literature can be applied to solve the expectation-constrained stochastic problems. We propose a novel primal-dual type SGM based on the Lagrangian function. Different from existing methods, our method incorporates an adaptiveness technique to speed up convergence. At each iteration, our method inquires an unbiased stochastic subgradient of the Lagrangian function, and then it renews the primal variables by an adaptive-SGM update and the dual variables by a vanilla-SGM update. We show that the proposed method has a convergence rate of $$O(1/\sqrt{k})$$ in terms of the objective error and the constraint violation. Although the convergence rate is the same as those of existing SGMs, we observe its significantly faster convergence than an existing non-adaptive primal-dual SGM and a primal SGM on solving the Neyman–Pearson classification and quadratically constrained quadratic programs. Furthermore, we modify the proposed method to solve convex–concave stochastic minimax problems, for which we perform adaptive-SGM updates to both primal and dual variables. A convergence rate of $$O(1/\sqrt{k})$$ is also established to the modified method for solving minimax problems in terms of primal-dual gap. Our code has been released at https://github.com/RPI-OPT/APriD .},
  archive      = {J_MPC},
  author       = {Yan, Yonggui and Xu, Yangyang},
  doi          = {10.1007/s12532-021-00214-w},
  journal      = {Mathematical Programming Computation},
  number       = {2},
  pages        = {319-363},
  shortjournal = {Math. Program. Comput.},
  title        = {Adaptive primal-dual stochastic gradient method for expectation-constrained convex stochastic programs},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LMBOPT: A limited memory method for bound-constrained
optimization. <em>MPC</em>, <em>14</em>(2), 271–318. (<a
href="https://doi.org/10.1007/s12532-021-00213-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Neumaier and Azmi gave a comprehensive convergence theory for a generic algorithm for bound constrained optimization problems with a continuously differentiable objective function. The algorithm combines an active set strategy with a gradient-free line search CLS along a piecewise linear search path defined by directions chosen to reduce zigzagging. This paper describes LMBOPT, an efficient implementation of this scheme. It employs new limited memory techniques for computing the search directions, improves CLS by adding various safeguards relevant when finite precision arithmetic is used, and adds many practical enhancements in other details. The paper compares LMBOPT and several other solvers on the unconstrained and bound constrained problems from the CUTEst collection and makes recommendations on which solver to use and when. Depending on the problem class, the problem dimension, and the precise goal, the best solvers are LMBOPT, ASACG, and LMBFG-EIG-MS.},
  archive      = {J_MPC},
  author       = {Kimiaei, Morteza and Neumaier, Arnold and Azmi, Behzad},
  doi          = {10.1007/s12532-021-00213-x},
  journal      = {Mathematical Programming Computation},
  number       = {2},
  pages        = {271-318},
  shortjournal = {Math. Program. Comput.},
  title        = {LMBOPT: A limited memory method for bound-constrained optimization},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An augmented lagrangian method with constraint generation
for shape-constrained convex regression problems. <em>MPC</em>,
<em>14</em>(2), 223–270. (<a
href="https://doi.org/10.1007/s12532-021-00210-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape-constrained convex regression problem deals with fitting a convex function to the observed data, where additional constraints are imposed, such as component-wise monotonicity and uniform Lipschitz continuity. This paper provides a unified framework for computing the least squares estimator of a multivariate shape-constrained convex regression function in $${\mathbb {R}}^d$$ . We prove that the least squares estimator is computable via solving an essentially constrained convex quadratic programming (QP) problem with $$(d+1)n$$ variables, $$n(n-1)$$ linear inequality constraints and n possibly non-polyhedral inequality constraints, where n is the number of data points. To efficiently solve the generally very large-scale convex QP, we design a proximal augmented Lagrangian method (proxALM) whose subproblems are solved by the semismooth Newton method. To further accelerate the computation when n is huge, we design a practical implementation of the constraint generation method such that each reduced problem is efficiently solved by our proposed proxALM. Comprehensive numerical experiments, including those in the pricing of basket options and estimation of production functions in economics, demonstrate that our proposed proxALM outperforms the state-of-the-art algorithms, and the proposed acceleration technique further shortens the computation time by a large margin.},
  archive      = {J_MPC},
  author       = {Lin, Meixia and Sun, Defeng and Toh, Kim-Chuan},
  doi          = {10.1007/s12532-021-00210-0},
  journal      = {Mathematical Programming Computation},
  number       = {2},
  pages        = {223-270},
  shortjournal = {Math. Program. Comput.},
  title        = {An augmented lagrangian method with constraint generation for shape-constrained convex regression problems},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive large neighborhood search for mixed integer
programming. <em>MPC</em>, <em>14</em>(2), 185–221. (<a
href="https://doi.org/10.1007/s12532-021-00209-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Neighborhood Search (LNS) heuristics are among the most powerful but also most expensive heuristics for mixed integer programs (MIP). Ideally, a solver adaptively concentrates its limited computational budget by learning which LNS heuristics work best for the MIP problem at hand. To this end, this work introduces Adaptive Large Neighborhood Search (ALNS) for MIP, a primal heuristic that acts as a framework for eight popular LNS heuristics such as Local Branching and Relaxation Induced Neighborhood Search (RINS). We distinguish the available LNS heuristics by their individual search spaces, which we call auxiliary problems. The decision which auxiliary problem should be executed is guided by selection strategies for the multi armed bandit problem, a related optimization problem during which suitable actions have to be chosen to maximize a reward function. In this paper, we propose an LNS-specific reward function to learn to distinguish between the available auxiliary problems based on successful calls and failures. A second, algorithmic enhancement is a generic variable fixing prioritization, which ALNS employs to adjust the subproblem complexity as needed. This is particularly useful for some LNS problems which do not fix variables by themselves. The proposed primal heuristic has been implemented within the MIP solver SCIP. An extensive computational study is conducted to compare different LNS strategies within our ALNS framework on a large set of publicly available MIP instances from the MIPLIB and Coral benchmark sets. The results of this simulation are used to calibrate the parameters of the bandit selection strategies. A second computational experiment shows the computational benefits of the proposed ALNS framework within the MIP solver SCIP.},
  archive      = {J_MPC},
  author       = {Hendel, Gregor},
  doi          = {10.1007/s12532-021-00209-7},
  journal      = {Mathematical Programming Computation},
  number       = {2},
  pages        = {185-221},
  shortjournal = {Math. Program. Comput.},
  title        = {Adaptive large neighborhood search for mixed integer programming},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Acados—a modular open-source framework for fast embedded
optimal control. <em>MPC</em>, <em>14</em>(1), 147–183. (<a
href="https://doi.org/10.1007/s12532-021-00208-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the acados software package, a collection of solvers for fast embedded optimization intended for fast embedded applications. Its interfaces to higher-level languages make it useful for quickly designing an optimization-based control algorithm by putting together different algorithmic components that can be readily connected and interchanged. Since the core of acados is written on top of a high-performance linear algebra library, we do not sacrifice computational performance. Thus, we aim to provide both flexibility and performance through modularity, without the need to rely on automatic code generation, which facilitates maintainability and extensibility. The main features of acados are: efficient optimal control algorithms targeting embedded devices implemented in C, linear algebra based on the high-performance BLASFEO Frison (ACM Transactions on Mathematical Software (TOMS) 44: 1–30, 2018) library, user-friendly interfaces to Matlab and Python, and compatibility with the modeling language of CasADi Andersson (Mathematical Programming Computation 11: 136, 2019). acados is free and open-source software released under the permissive BSD 2-Clause license.},
  archive      = {J_MPC},
  author       = {Verschueren, Robin and Frison, Gianluca and Kouzoupis, Dimitris and Frey, Jonathan and Duijkeren, Niels van and Zanelli, Andrea and Novoselnik, Branimir and Albin, Thivaharan and Quirynen, Rien and Diehl, Moritz},
  doi          = {10.1007/s12532-021-00208-8},
  journal      = {Mathematical Programming Computation},
  number       = {1},
  pages        = {147-183},
  shortjournal = {Math. Program. Comput.},
  title        = {Acados—a modular open-source framework for fast embedded optimal control},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On scaled stopping criteria for a safeguarded augmented
lagrangian method with theoretical guarantees. <em>MPC</em>,
<em>14</em>(1), 121–146. (<a
href="https://doi.org/10.1007/s12532-021-00207-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the use of a stopping criterion based on the scaling of the Karush–Kuhn–Tucker (KKT) conditions by the norm of the approximate Lagrange multiplier in the ALGENCAN implementation of a safeguarded augmented Lagrangian method. Such stopping criterion is already used in several nonlinear programming solvers, but it has not yet been considered in ALGENCAN due to its firm commitment with finding a true KKT point even when the multiplier set is not bounded. In contrast with this view, we present a strong global convergence theory under the quasi-normality constraint qualification, that allows for unbounded multiplier sets, accompanied by an extensive numerical test which shows that the scaled stopping criterion is more efficient in detecting convergence sooner. In particular, by scaling, ALGENCAN is able to recover a solution in some difficult problems where the original implementation fails, while the behavior of the algorithm in the easier instances is maintained. Furthermore, we show that, in some cases, a considerable computational effort is saved, proving the practical usefulness of the proposed strategy.},
  archive      = {J_MPC},
  author       = {Andreani, R. and Haeser, G. and Schuverdt, M. L. and Secchin, L. D. and Silva, P. J. S.},
  doi          = {10.1007/s12532-021-00207-9},
  journal      = {Mathematical Programming Computation},
  number       = {1},
  pages        = {121-146},
  shortjournal = {Math. Program. Comput.},
  title        = {On scaled stopping criteria for a safeguarded augmented lagrangian method with theoretical guarantees},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dantzig–wolfe reformulations for binary quadratic problems.
<em>MPC</em>, <em>14</em>(1), 85–120. (<a
href="https://doi.org/10.1007/s12532-021-00206-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to provide strong reformulations for binary quadratic problems. We propose a first methodological analysis on a family of reformulations combining Dantzig–Wolfe and Quadratic Convex optimization principles. We show that a few reformulations of our family yield continuous relaxations that are strong in terms of dual bounds and computationally efficient to optimize. As a representative case study, we apply them to a cardinality constrained quadratic knapsack problem, providing extensive experimental insights. We report and analyze in depth a particular reformulation providing continuous relaxations whose solutions turn out to be integer optima in all our tests.},
  archive      = {J_MPC},
  author       = {Ceselli, Alberto and Létocart, Lucas and Traversi, Emiliano},
  doi          = {10.1007/s12532-021-00206-w},
  journal      = {Mathematical Programming Computation},
  number       = {1},
  pages        = {85-120},
  shortjournal = {Math. Program. Comput.},
  title        = {Dantzig–Wolfe reformulations for binary quadratic problems},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal patchings for consecutive ones matrices.
<em>MPC</em>, <em>14</em>(1), 43–84. (<a
href="https://doi.org/10.1007/s12532-021-00203-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a variant of the weighted consecutive ones property problem. Here, a 0/1-matrix is given with a cost associated to each of its entries and one has to find a minimum cost set of zero entries to be turned to ones in order to make the matrix have the consecutive ones property for rows. We investigate polyhedral and combinatorial properties of the problem and we exploit them in a branch-and-cut algorithm. In particular, we devise preprocessing rules and investigate variants of “local cuts”. We test the resulting algorithm on a number of instances, and we report on these computational experiments.},
  archive      = {J_MPC},
  author       = {Pfetsch, Marc E. and Rinaldi, Giovanni and Ventura, Paolo},
  doi          = {10.1007/s12532-021-00203-z},
  journal      = {Mathematical Programming Computation},
  number       = {1},
  pages        = {43-84},
  shortjournal = {Math. Program. Comput.},
  title        = {Optimal patchings for consecutive ones matrices},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scalable branching on dual decomposition of stochastic
mixed-integer programming problems. <em>MPC</em>, <em>14</em>(1), 1–41.
(<a href="https://doi.org/10.1007/s12532-021-00212-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a scalable branching method for the dual decomposition of stochastic mixed-integer programming. Our new branching method is based on the branching method proposed by Carøe and Schultz that creates branching disjunctions on first-stage variables only. We propose improvements to the process for creating branching disjunctions, including (1) branching on the optimal solutions of the Dantzig–Wolfe reformulation of the restricted master problem and (2) using a more comprehensive (yet simple) measure for the dispersions associated with subproblem solution infeasibility. We prove that the proposed branching process leads to an algorithm that terminates finitely, and we provide conditions under which globally optimal solutions can be identified after termination. We have implemented our new branching method, as well as the Carøe–Schultz method and a branch-and-price method, in the open-source software package DSP. Using SIPLIB test instances, we present extensive numerical results to demonstrate that the proposed branching method significantly reduces the number of node subproblems and solution times.},
  archive      = {J_MPC},
  author       = {Kim, Kibaek and Dandurand, Brian},
  doi          = {10.1007/s12532-021-00212-y},
  journal      = {Mathematical Programming Computation},
  number       = {1},
  pages        = {1-41},
  shortjournal = {Math. Program. Comput.},
  title        = {Scalable branching on dual decomposition of stochastic mixed-integer programming problems},
  volume       = {14},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
