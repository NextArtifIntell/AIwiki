<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>BCYB_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="bcyb---45">BCYB - 45</h2>
<ul>
<li><details>
<summary>
(2022a). Correction: Optimum trajectory learning in musculoskeletal
systems with model predictive control and deep reinforcement learning.
<em>BCYB</em>, <em>116</em>(5), 729. (<a
href="https://doi.org/10.1007/s00422-022-00949-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BCYB},
  author       = {Denizdurduran, Berat and Markram, Henry and Gewaltig, Marc-Oliver},
  doi          = {10.1007/s00422-022-00949-2},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {5},
  pages        = {729},
  shortjournal = {Biol. Cybern.},
  title        = {Correction: Optimum trajectory learning in musculoskeletal systems with model predictive control and deep reinforcement learning},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Correction: Optimum trajectory learning in musculoskeletal
systems with model predictive control and deep reinforcement learning.
<em>BCYB</em>, <em>116</em>(5), 727. (<a
href="https://doi.org/10.1007/s00422-022-00947-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BCYB},
  author       = {Denizdurduran, Berat and Markram, Henry and Gewaltig, Marc-Oliver},
  doi          = {10.1007/s00422-022-00947-4},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {5},
  pages        = {727},
  shortjournal = {Biol. Cybern.},
  title        = {Correction: Optimum trajectory learning in musculoskeletal systems with model predictive control and deep reinforcement learning},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Optimum trajectory learning in musculoskeletal systems with
model predictive control and deep reinforcement learning. <em>BCYB</em>,
<em>116</em>(5), 711–726. (<a
href="https://doi.org/10.1007/s00422-022-00940-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From the computational point of view, musculoskeletal control is the problem of controlling high degrees of freedom and dynamic multi-body system that is driven by redundant muscle units. A critical challenge in the control perspective of skeletal joints with antagonistic muscle pairs is finding methods robust to address this ill-posed nonlinear problem. To address this computational problem, we implemented a twofold optimization and learning framework to be specialized in addressing the redundancies in the muscle control . In the first part, we used model predictive control to obtain energy efficient skeletal trajectories to mimick human movements. The second part is to use deep reinforcement learning to obtain a sequence of stimulus to be given to muscles in order to obtain the skeletal trajectories with muscle control. We observed that the desired stimulus to muscles is only efficiently constructed by integrating the state and control input in a closed-loop setting as it resembles the proprioceptive integration in the spinal cord circuits. In this work, we showed how a variety of different reference trajectories can be obtained with optimal control and how these reference trajectories are mapped to the musculoskeletal control with deep reinforcement learning. Starting from the characteristics of human arm movement to obstacle avoidance experiment, our simulation results confirm the capabilities of our optimization and learning framework for a variety of dynamic movement trajectories. In summary, the proposed framework is offering a pipeline to complement the lack of experiments to record human motion-capture data as well as study the activation range of muscles to replicate the specific trajectory of interest. Using the trajectories from optimal control as a reference signal for reinforcement learning implementation has allowed us to acquire optimum and human-like behaviour of the musculoskeletal system which provides a framework to study human movement in-silico experiments. The present framework can also allow studying upper-arm rehabilitation with assistive robots given that one can use healthy subject movement recordings as reference to work on the control architecture of assistive robotics in order to compensate behavioural deficiencies. Hence, the framework opens to possibility of replicating or complementing labour-intensive, time-consuming and costly experiments with human subjects in the field of movement studies and digital twin of rehabilitation.},
  archive      = {J_BCYB},
  author       = {Denizdurduran, Berat and Markram, Henry and Gewaltig, Marc-Oliver},
  doi          = {10.1007/s00422-022-00940-x},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {5},
  pages        = {711-726},
  shortjournal = {Biol. Cybern.},
  title        = {Optimum trajectory learning in musculoskeletal systems with model predictive control and deep reinforcement learning},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variational and phase response analysis for limit cycles
with hard boundaries, with applications to neuromechanical control
problems. <em>BCYB</em>, <em>116</em>(5), 687–710. (<a
href="https://doi.org/10.1007/s00422-022-00951-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor systems show an overall robustness, but because they are highly nonlinear, understanding how they achieve robustness is difficult. In many rhythmic systems, robustness against perturbations involves response of both the shape and the timing of the trajectory. This makes the study of robustness even more challenging. To understand how a motor system produces robust behaviors in a variable environment, we consider a neuromechanical model of motor patterns in the feeding apparatus of the marine mollusk Aplysia californica (Shaw et al. in J Comput Neurosci 38(1):25–51, 2015; Lyttle et al. in Biol Cybern 111(1):25–47, 2017). We established in (Wang et al. in SIAM J Appl Dyn Syst 20(2):701–744, 2021. https://doi.org/10.1137/20M1344974 ) the tools for studying combined shape and timing responses of limit cycle systems under sustained perturbations and here apply them to study robustness of the neuromechanical model against increased mechanical load during swallowing. Interestingly, we discover that nonlinear biomechanical properties confer resilience by immediately increasing resistance to applied loads. In contrast, the effect of changed sensory feedback signal is significantly delayed by the firing rates’ hard boundary properties. Our analysis suggests that sensory feedback contributes to robustness in swallowing primarily by shifting the timing of neural activation involved in the power stroke of the motor cycle (retraction). This effect enables the system to generate stronger retractor muscle forces to compensate for the increased load, and hence achieve strong robustness. The approaches that we are applying to understanding a neuromechanical model in Aplysia, and the results that we have obtained, are likely to provide insights into the function of other motor systems that encounter changing mechanical loads and hard boundaries, both due to mechanical and neuronal firing properties.},
  archive      = {J_BCYB},
  author       = {Wang, Yangyang and Gill, Jeffrey P. and Chiel, Hillel J. and Thomas, Peter J.},
  doi          = {10.1007/s00422-022-00951-8},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {5},
  pages        = {687-710},
  shortjournal = {Biol. Cybern.},
  title        = {Variational and phase response analysis for limit cycles with hard boundaries, with applications to neuromechanical control problems},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploration of motion inhibition for the suppression of
false positives in biologically inspired small target detection
algorithms from a moving platform. <em>BCYB</em>, <em>116</em>(5),
661–685. (<a href="https://doi.org/10.1007/s00422-022-00950-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting small moving targets against a cluttered background in visual data is a challenging task. The main problems include spatio-temporal target contrast enhancement, background suppression and accurate target segmentation. When targets are at great distances from a non-stationary camera, the difficulty of these challenges increases. In such cases the moving camera can introduce large spatial changes between frames which may cause issues in temporal algorithms; furthermore targets can approach a single pixel, thereby affecting spatial methods. Previous literature has shown that biologically inspired methods, based on the vision systems of insects, are robust to such conditions. It has also been shown that the use of divisive optic-flow inhibition with these methods enhances the detectability of small targets. However, the location within the visual pathway the inhibition should be applied was ambiguous. In this paper, we investigated the tunings of some of the optic-flow filters and use of a nonlinear transform on the optic-flow signal to modify motion responses for the purpose of suppressing false positives and enhancing small target detection. Additionally, we looked at multiple locations within the biologically inspired vision (BIV) algorithm where inhibition could further enhance detection performance, and look at driving the nonlinear transform with a global motion estimate. To get a better understanding of how the BIV algorithm performs, we compared to other state-of-the-art target detection algorithms, and look at how their performance can be enhanced with the optic-flow inhibition. Our explicit use of the nonlinear inhibition allows for the incorporation of a wider dynamic range of inhibiting signals, along with spatio-temporal filter refinement, which further increases target-background discrimination in the presence of camera motion. Extensive experiments shows that our proposed approach achieves an improvement of 25% over linearly conditioned inhibition schemes and 2.33 times the detection performance of the BIV model without inhibition. Moreover, our approach achieves between 10 and 104 times better detection performance compared to any conventional state-of-the-art moving object detection algorithm applied to the same, highly cluttered and moving scenes. Applying the nonlinear inhibition to other algorithms showed that their performance can be increased by up to 22 times. These findings show that the application of optic-flow- based signal suppression should be applied to enhance target detection from moving platforms. Furthermore, they indicate where best to look for evidence of such signals within the insect brain.},
  archive      = {J_BCYB},
  author       = {Melville-Smith, Aaron and Finn, Anthony and Uzair, Muhammad and Brinkworth, Russell S. A.},
  doi          = {10.1007/s00422-022-00950-9},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {5},
  pages        = {661-685},
  shortjournal = {Biol. Cybern.},
  title        = {Exploration of motion inhibition for the suppression of false positives in biologically inspired small target detection algorithms from a moving platform},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contrast independent biologically inspired translational
optic flow estimation. <em>BCYB</em>, <em>116</em>(5), 635–660. (<a
href="https://doi.org/10.1007/s00422-022-00948-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The visual systems of insects are relatively simple compared to humans. However, they enable navigation through complex environments where insects perform exceptional levels of obstacle avoidance. Biology uses two separable modes of optic flow to achieve this: rapid gaze fixation (rotational motion known as saccades); and the inter-saccadic translational motion. While the fundamental process of insect optic flow has been known since the 1950’s, so too has its dependence on contrast. The surrounding visual pathways used to overcome environmental dependencies are less well known. Previous work has shown promise for low-speed rotational motion estimation, but a gap remained in the estimation of translational motion, in particular the estimation of the time to impact. To consistently estimate the time to impact during inter-saccadic translatory motion, the fundamental limitation of contrast dependence must be overcome. By adapting an elaborated rotational velocity estimator from literature to work for translational motion, this paper proposes a novel algorithm for overcoming the contrast dependence of time to impact estimation using nonlinear spatio-temporal feedforward filtering. By applying bioinspired processes, approximately 15 points per decade of statistical discrimination were achieved when estimating the time to impact to a target across 360 background, distance, and velocity combinations: a 17-fold increase over the fundamental process. These results show the contrast dependence of time to impact estimation can be overcome in a biologically plausible manner. This, combined with previous results for low-speed rotational motion estimation, allows for contrast invariant computational models designed on the principles found in the biological visual system, paving the way for future visually guided systems.},
  archive      = {J_BCYB},
  author       = {Skelton, Phillip S. M. and Finn, Anthony and Brinkworth, Russell S. A.},
  doi          = {10.1007/s00422-022-00948-3},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {5},
  pages        = {635-660},
  shortjournal = {Biol. Cybern.},
  title        = {Contrast independent biologically inspired translational optic flow estimation},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A dynamic spike threshold with correlated noise predicts
observed patterns of negative interval correlations in neuronal spike
trains. <em>BCYB</em>, <em>116</em>(5), 611–633. (<a
href="https://doi.org/10.1007/s00422-022-00946-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Negative correlations in the sequential evolution of interspike intervals (ISIs) are a signature of memory in neuronal spike-trains. They provide coding benefits including firing-rate stabilization, improved detectability of weak sensory signals, and enhanced transmission of information by improving signal-to-noise ratio. Primary electrosensory afferent spike-trains in weakly electric fish fall into two categories based on the pattern of ISI correlations: non-bursting units have negative correlations which remain negative but decay to zero with increasing lags (Type I ISI correlations), and bursting units have oscillatory (alternating sign) correlation which damp to zero with increasing lags (Type II ISI correlations). Here, we predict and match observed ISI correlations in these afferents using a stochastic dynamic threshold model. We determine the ISI correlation function as a function of an arbitrary discrete noise correlation function $${{\,\mathrm{\mathbf {R}}\,}}_k$$ , where k is a multiple of the mean ISI. The function permits forward and inverse calculations of the correlation function. Both types of correlation functions can be generated by adding colored noise to the spike threshold with Type I correlations generated with slow noise and Type II correlations generated with fast noise. A first-order autoregressive (AR) process with a single parameter is sufficient to predict and accurately match both types of afferent ISI correlation functions, with the type being determined by the sign of the AR parameter. The predicted and experimentally observed correlations are in geometric progression. The theory predicts that the limiting sum of ISI correlations is $$-0.5$$ yielding a perfect DC-block in the power spectrum of the spike train. Observed ISI correlations from afferents have a limiting sum that is slightly larger at $$-0.475 \pm 0.04$$ ( $$\text {mean} \pm \text {s.d.}$$ ). We conclude that the underlying process for generating ISIs may be a simple combination of low-order AR and moving average processes and discuss the results from the perspective of optimal coding.},
  archive      = {J_BCYB},
  author       = {Sidhu, Robin S. and Johnson, Erik C. and Jones, Douglas L. and Ratnam, Rama},
  doi          = {10.1007/s00422-022-00946-5},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {5},
  pages        = {611-633},
  shortjournal = {Biol. Cybern.},
  title        = {A dynamic spike threshold with correlated noise predicts observed patterns of negative interval correlations in neuronal spike trains},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integration of velocity-dependent spatio-temporal structure
of place cell activation during navigation in a reservoir model of
prefrontal cortex. <em>BCYB</em>, <em>116</em>(5), 585–610. (<a
href="https://doi.org/10.1007/s00422-022-00945-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential behavior unfolds both in space and in time. The same spatial trajectory can be realized in different manners in the same overall time by changing instantaneous speeds. The current research investigates how speed profiles might be given behavioral significance and how cortical networks might encode this information. We first demonstrate that rats can associate different speed patterns on the same trajectory with distinct behavioral choices. In this novel experimental paradigm, rats follow a small baited robot in a large megaspace environment where the rat’s speed is precisely controlled by the robot’s speed. Based on this proof of concept and research showing that recurrent reservoir networks are ideal for representing spatio-temporal structures, we then test reservoir networks in simulated navigation contexts and demonstrate they can discriminate between traversals of the same path with identical durations but different speed profiles. We then test the networks in an embodied robotic setup, where we use place cell representations from physically navigating robots as input and again successfully discriminate between traversals. To demonstrate that this capability is inherent to recurrent networks, we compared the model against simple linear integrators. Interestingly, although the linear integrators could also perform the speed profile discrimination, a clear difference emerged when examining information coding in both models. Reservoir neurons displayed a form of statistical mixed selectivity as a complex interaction between spatial location and speed that was not as abundant in the linear integrators. This mixed selectivity is characteristic of cortex and reservoirs and allows us to generate specific predictions about the neural activity that will be recorded in rat cortex in future experiments.},
  archive      = {J_BCYB},
  author       = {Scleidorovich, Pablo and Weitzenfeld, Alfredo and Fellous, Jean-Marc and Dominey, Peter Ford},
  doi          = {10.1007/s00422-022-00945-6},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {5},
  pages        = {585-610},
  shortjournal = {Biol. Cybern.},
  title        = {Integration of velocity-dependent spatio-temporal structure of place cell activation during navigation in a reservoir model of prefrontal cortex},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparison of event-related modulation index and traditional
methods for evaluating phase-amplitude coupling using simulated brain
signals. <em>BCYB</em>, <em>116</em>(5), 569–583. (<a
href="https://doi.org/10.1007/s00422-022-00944-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The investigation of brain oscillations and connectivity has become an important topic in the recent decade. There are several types of interactions between neuronal oscillations, and one of the most interesting among these interactions is phase-amplitude coupling (PAC). Several methods have been proposed to measure the strength of PAC, including the phase-locking value, circular-linear correlation, and modulation index. In the current study, we compared these traditional PAC methods with simulated electroencephalogram signals. Further, to assess the PAC value at each time point, we also compared two recently established methods, event-related phase-locking value and event-related circular-linear correlation, with our newly proposed event-related modulation index (ERMI). Results indicated that the ERMI has better temporal resolution and is more tolerant to noise than the other two event-related methods, suggesting the advantages of utilizing ERMI in evaluating the strength of PAC within a brain region.},
  archive      = {J_BCYB},
  author       = {Tsai, Chung-Chieh and Liu, Hong-Hsiang and Tseng, Yi-Li},
  doi          = {10.1007/s00422-022-00944-7},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {5},
  pages        = {569-583},
  shortjournal = {Biol. Cybern.},
  title        = {Comparison of event-related modulation index and traditional methods for evaluating phase-amplitude coupling using simulated brain signals},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Biologically plausible single-layer networks for nonnegative
independent component analysis. <em>BCYB</em>, <em>116</em>(5), 557–568.
(<a href="https://doi.org/10.1007/s00422-022-00943-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important problem in neuroscience is to understand how brains extract relevant signals from mixtures of unknown sources, i.e., perform blind source separation. To model how the brain performs this task, we seek a biologically plausible single-layer neural network implementation of a blind source separation algorithm. For biological plausibility, we require the network to satisfy the following three basic properties of neuronal circuits: (i) the network operates in the online setting; (ii) synaptic learning rules are local; and (iii) neuronal outputs are nonnegative. Closest is the work by Pehlevan et al. (Neural Comput 29:2925–2954, 2017), which considers nonnegative independent component analysis (NICA), a special case of blind source separation that assumes the mixture is a linear combination of uncorrelated, nonnegative sources. They derive an algorithm with a biologically plausible 2-layer network implementation. In this work, we improve upon their result by deriving 2 algorithms for NICA, each with a biologically plausible single-layer network implementation. The first algorithm maps onto a network with indirect lateral connections mediated by interneurons. The second algorithm maps onto a network with direct lateral connections and multi-compartmental output neurons.},
  archive      = {J_BCYB},
  author       = {Lipshutz, David and Pehlevan, Cengiz and Chklovskii, Dmitri B.},
  doi          = {10.1007/s00422-022-00943-8},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {5},
  pages        = {557-568},
  shortjournal = {Biol. Cybern.},
  title        = {Biologically plausible single-layer networks for nonnegative independent component analysis},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bursting hierarchy in an adaptive exponential
integrate-and-fire network synchronization. <em>BCYB</em>,
<em>116</em>(5), 545–556. (<a
href="https://doi.org/10.1007/s00422-022-00942-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuronal network synchronization has received wide interest. In the present manuscript, we study the influence of initial membrane potentials together with network topology on bursting synchronization, in particular the sequential order of stabilized bursting among neurons. We find a hierarchical phenomenon on their bursting order. With a focus on situations where network coupling advances spiking times of neurons, we grade neurons into different layers. Together with the neuronal network structure, we construct directed graphs to indicate bursting propagation between different layers. More explicitly, neurons in upper layers burst earlier than those in lower layers. More interestingly, we find that among the same layer, bursting order of neurons is mainly associated with the number of neurons they connected to the upper layer; more stimuli lead to earlier bursting. Receiving effectively the same stimuli from the upper layer, we observe neurons with fewer connections would burst earlier.},
  archive      = {J_BCYB},
  author       = {Lin, Congping and Wu, Xiaoyue and Zhang, Yiwei},
  doi          = {10.1007/s00422-022-00942-9},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {5},
  pages        = {545-556},
  shortjournal = {Biol. Cybern.},
  title        = {Bursting hierarchy in an adaptive exponential integrate-and-fire network synchronization},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Beyond wilson–cowan dynamics: Oscillations and chaos without
inhibition. <em>BCYB</em>, <em>116</em>(5), 527–543. (<a
href="https://doi.org/10.1007/s00422-022-00941-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fifty years ago, Wilson and Cowan developed a mathematical model to describe the activity of neural populations. In this seminal work, they divided the cells in three groups: active, sensitive and refractory, and obtained a dynamical system to describe the evolution of the average firing rates of the populations. In the present work, we investigate the impact of the often neglected refractory state and show that taking it into account can introduce new dynamics. Starting from a continuous-time Markov chain, we perform a rigorous derivation of a mean-field model that includes the refractory fractions of populations as dynamical variables. Then, we perform bifurcation analysis to explain the occurrence of periodic solutions in cases where the classical Wilson–Cowan does not predict oscillations. We also show that our mean-field model is able to predict chaotic behavior in the dynamics of networks with as little as two populations.},
  archive      = {J_BCYB},
  author       = {Painchaud, Vincent and Doyon, Nicolas and Desrosiers, Patrick},
  doi          = {10.1007/s00422-022-00941-w},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {5},
  pages        = {527-543},
  shortjournal = {Biol. Cybern.},
  title        = {Beyond Wilson–Cowan dynamics: Oscillations and chaos without inhibition},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal reaching trajectories based on feedforward control.
<em>BCYB</em>, <em>116</em>(4), 517–526. (<a
href="https://doi.org/10.1007/s00422-022-00939-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In human upper-arm reaching movements, the variance of the hand position increases until the middle of the movement and then decreases toward the endpoint. Such decrease in positional variance has been suggested as an evidence to support the hypothesis that our nervous system uses feedback control, rather than feedforward control, for arm reaching tasks. In this study, we computed the optimal trajectories based on feedforward control under several criteria for a one-link two-muscle arm model with considering the stochastic property of muscle activities in order to reexamine the hypothesis. The results showed that the feedforward control also represents the decrease in positional variance in the latter half of the movement when the control signal is planned under the minimum energy cost and minimum variance models. Furthermore, the optimal trajectory that minimizes energy cost represents not only the decrease in positional variance but also many other characteristics of the human reaching movements, e.g., the three-phasic activity of antagonistic muscle, bell-shaped speed curve, N-shaped equilibrium trajectory, and bimodal profile of joint stiffness. These results suggest that minimum energy cost model well expresses the characteristics of hand reaching movements, and our central nervous system would make use of not only a feedback control but also feedforward control.},
  archive      = {J_BCYB},
  author       = {Taniai, Yoshiaki and Naniwa, Tomohide and Nishii, Jun},
  doi          = {10.1007/s00422-022-00939-4},
  journal      = {Biological Cybernetics},
  month        = {8},
  number       = {4},
  pages        = {517-526},
  shortjournal = {Biol. Cybern.},
  title        = {Optimal reaching trajectories based on feedforward control},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Codimension-2 parameter space structure of continuous-time
recurrent neural networks. <em>BCYB</em>, <em>116</em>(4), 501–515. (<a
href="https://doi.org/10.1007/s00422-022-00938-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {If we are ever to move beyond the study of isolated special cases in theoretical neuroscience, we need to develop more general theories of neural circuits over a given neural model. The present paper considers this challenge in the context of continuous-time recurrent neural networks (CTRNNs), a simple but dynamically universal model that has been widely utilized in both computational neuroscience and neural networks. Here, we extend previous work on the parameter space structure of codimension-1 local bifurcations in CTRNNs to include codimension-2 local bifurcation manifolds. Specifically, we derive the necessary conditions for all generic local codimension-2 bifurcations for general CTRNNs, specialize these conditions to circuits containing from one to four neurons, illustrate in full detail the application of these conditions to example circuits, derive closed-form expressions for these bifurcation manifolds where possible, and demonstrate how this analysis allows us to find and trace several global codimension-1 bifurcation manifolds that originate from the codimension-2 bifurcations.},
  archive      = {J_BCYB},
  author       = {Beer, Randall D.},
  doi          = {10.1007/s00422-022-00938-5},
  journal      = {Biological Cybernetics},
  month        = {8},
  number       = {4},
  pages        = {501-515},
  shortjournal = {Biol. Cybern.},
  title        = {Codimension-2 parameter space structure of continuous-time recurrent neural networks},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Auditory cortex modelled as a dynamical network of
oscillators: Understanding event-related fields and their adaptation.
<em>BCYB</em>, <em>116</em>(4), 475–499. (<a
href="https://doi.org/10.1007/s00422-022-00936-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptation, the reduction of neuronal responses by repetitive stimulation, is a ubiquitous feature of auditory cortex (AC). It is not clear what causes adaptation, but short-term synaptic depression (STSD) is a potential candidate for the underlying mechanism. In such a case, adaptation can be directly linked with the way AC produces context-sensitive responses such as mismatch negativity and stimulus-specific adaptation observed on the single-unit level. We examined this hypothesis via a computational model based on AC anatomy, which includes serially connected core, belt, and parabelt areas. The model replicates the event-related field (ERF) of the magnetoencephalogram as well as ERF adaptation. The model dynamics are described by excitatory and inhibitory state variables of cell populations, with the excitatory connections modulated by STSD. We analysed the system dynamics by linearising the firing rates and solving the STSD equation using time-scale separation. This allows for characterisation of AC dynamics as a superposition of damped harmonic oscillators, so-called normal modes. We show that repetition suppression of the N1m is due to a mixture of causes, with stimulus repetition modifying both the amplitudes and the frequencies of the normal modes. In this view, adaptation results from a complete reorganisation of AC dynamics rather than a reduction of activity in discrete sources. Further, both the network structure and the balance between excitation and inhibition contribute significantly to the rate with which AC recovers from adaptation. This lifetime of adaptation is longer in the belt and parabelt than in the core area, despite the time constants of STSD being spatially homogeneous. Finally, we critically evaluate the use of a single exponential function to describe recovery from adaptation.},
  archive      = {J_BCYB},
  author       = {Hajizadeh, Aida and Matysiak, Artur and Wolfrum, Matthias and May, Patrick J. C. and König, Reinhard},
  doi          = {10.1007/s00422-022-00936-7},
  journal      = {Biological Cybernetics},
  month        = {8},
  number       = {4},
  pages        = {475-499},
  shortjournal = {Biol. Cybern.},
  title        = {Auditory cortex modelled as a dynamical network of oscillators: Understanding event-related fields and their adaptation},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modelling the effect of ephaptic coupling on spike
propagation in peripheral nerve fibres. <em>BCYB</em>, <em>116</em>(4),
461–473. (<a href="https://doi.org/10.1007/s00422-022-00934-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experimental and theoretical studies have shown that ephaptic coupling leads to the synchronisation and slowing down of spikes propagating along the axons within peripheral nerve bundles. However, the main focus thus far has been on a small number of identical axons, whereas realistic peripheral nerve bundles contain numerous axons with different diameters. Here, we present a computationally efficient spike propagation model, which captures the essential features of propagating spikes and their ephaptic interaction, and facilitates the theoretical investigation of spike volleys in large, heterogeneous fibre bundles. We first lay out the theoretical basis to describe how the spike in an active axon changes the membrane potential of a passive axon. These insights are then incorporated into the spike propagation model, which is calibrated with a biophysically realistic model based on Hodgkin–Huxley dynamics. The fully calibrated model is then applied to fibre bundles with a large number of axons and different types of axon diameter distributions. One key insight of this study is that the heterogeneity of the axonal diameters has a dispersive effect, and that a higher level of heterogeneity requires stronger ephaptic coupling to achieve full synchronisation between spikes.},
  archive      = {J_BCYB},
  author       = {Schmidt, Helmut and R. Knösche, Thomas},
  doi          = {10.1007/s00422-022-00934-9},
  journal      = {Biological Cybernetics},
  month        = {8},
  number       = {4},
  pages        = {461-473},
  shortjournal = {Biol. Cybern.},
  title        = {Modelling the effect of ephaptic coupling on spike propagation in peripheral nerve fibres},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Change in task conditions leads to changes in intermittency
in intermittent feedback control employed by CNS in control of human
stance. <em>BCYB</em>, <em>116</em>(4), 447–459. (<a
href="https://doi.org/10.1007/s00422-022-00927-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event-driven intermittent feedback control is a form of feedback control in which the corrective control action is only initiated intermittently when the variables of interest exceed certain threshold criteria. It has been reported in the literature that the CNS uses an event-driven intermittent control strategy to stabilize the human upright posture. However, whether the threshold criteria may change under different postural task conditions is not yet well understood. We employ a numerical study with inverted pendulum models and an experimental study with 51 young healthy individuals (13 females and 38 males; age: 27.8 ± 6.5 years) with stabilogram-diffusion, temporal and spectral analysis applied to COP (Center of Pressure) trajectories measured from these experiments to examine this aspect. The present study provides compelling evidence that inducing a natural arm swing during quiet stance appears to lead to higher sensory dead zone in neuronal control reflecting higher intermittency thresholds in active feedback control and a corresponding lower sensory dependence. Beyond the obvious scientific interest in understanding this aspect of how CNS controls the standing posture, an investigation of the said control strategy may subsequently help uncover insights about how control of quiet stance degrades with age and in diseased conditions. Additionally, such an understanding will also be of interest to the humanoid robotics community as it may lead to insights leading to improving control strategies for posture control in robots.},
  archive      = {J_BCYB},
  author       = {Dash, Ranjita and Palanthandalam-Madapusi, Harish J.},
  doi          = {10.1007/s00422-022-00927-8},
  journal      = {Biological Cybernetics},
  month        = {8},
  number       = {4},
  pages        = {447-459},
  shortjournal = {Biol. Cybern.},
  title        = {Change in task conditions leads to changes in intermittency in intermittent feedback control employed by CNS in control of human stance},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dissecting cell fate dynamics in pediatric glioblastoma
through the lens of complex systems and cellular cybernetics.
<em>BCYB</em>, <em>116</em>(4), 407–445. (<a
href="https://doi.org/10.1007/s00422-022-00935-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancers are complex dynamic ecosystems. Reductionist approaches to science are inadequate in characterizing their self-organized patterns and collective emergent behaviors. Since current approaches to single-cell analysis in cancer systems rely primarily on single time-point multiomics, many of the temporal features and causal adaptive behaviors in cancer dynamics are vastly ignored. As such, tools and concepts from the interdisciplinary paradigm of complex systems theory are introduced herein to decode the cellular cybernetics of cancer differentiation dynamics and behavioral patterns. An intuition for the attractors and complex networks underlying cancer processes such as cell fate decision-making, multiscale pattern formation systems, and epigenetic state-transitions is developed. The applications of complex systems physics in paving targeted therapies and causal pattern discovery in precision oncology are discussed. Pediatric high-grade gliomas are discussed as a model-system to demonstrate that cancers are complex adaptive systems, in which the emergence and selection of heterogeneous cellular states and phenotypic plasticity are driven by complex multiscale network dynamics. In specific, pediatric glioblastoma (GBM) is used as a proof-of-concept model to illustrate the applications of the complex systems framework in understanding GBM cell fate decisions and decoding their adaptive cellular dynamics. The scope of these tools in forecasting cancer cell fate dynamics in the emerging field of computational oncology and patient-centered systems medicine is highlighted.},
  archive      = {J_BCYB},
  author       = {Uthamacumaran, Abicumaran},
  doi          = {10.1007/s00422-022-00935-8},
  journal      = {Biological Cybernetics},
  month        = {8},
  number       = {4},
  pages        = {407-445},
  shortjournal = {Biol. Cybern.},
  title        = {Dissecting cell fate dynamics in pediatric glioblastoma through the lens of complex systems and cellular cybernetics},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Autoencoders reloaded. <em>BCYB</em>, <em>116</em>(4),
389–406. (<a href="https://doi.org/10.1007/s00422-022-00937-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Bourlard and Kamp (Biol Cybern 59(4):291–294, 1998), it was theoretically proven that autoencoders (AE) with single hidden layer (previously called “auto-associative multilayer perceptrons”) were, in the best case, implementing singular value decomposition (SVD) Golub and Reinsch (Linear algebra, Singular value decomposition and least squares solutions, pp 134–151. Springer, 1971), equivalent to principal component analysis (PCA) Hotelling (Educ Psychol 24(6/7):417–441, 1993); Jolliffe (Principal component analysis, springer series in statistics, 2nd edn. Springer, New York ). That is, AE are able to derive the eigenvalues that represent the amount of variance covered by each component even with the presence of the nonlinear function (sigmoid-like, or any other nonlinear functions) present on their hidden units. Today, with the renewed interest in “deep neural networks” (DNN), multiple types of (deep) AE are being investigated as an alternative to manifold learning Cayton (Univ California San Diego Tech Rep 12(1–17):1, 2005) for conducting nonlinear feature extraction or fusion, each with its own specific (expected) properties. Many of those AE are currently being developed as powerful, nonlinear encoder–decoder models, or used to generate reduced and discriminant feature sets that are more amenable to different modeling and classification tasks. In this paper, we start by recalling and further clarifying the main conclusions of Bourlard and Kamp (Biol Cybern 59(4):291–294, 1998), supporting them by extensive empirical evidences, which were not possible to be provided previously (in 1988), due to the dataset and processing limitations. Upon full understanding of the underlying mechanisms, we show that it remains hard (although feasible) to go beyond the state-of-the-art PCA/SVD techniques for auto-association. Finally, we present a brief overview on different autoencoder models that are mainly in use today and discuss their rationale, relations and application areas.},
  archive      = {J_BCYB},
  author       = {Bourlard, Hervé and Kabil, Selen Hande},
  doi          = {10.1007/s00422-022-00937-6},
  journal      = {Biological Cybernetics},
  month        = {8},
  number       = {4},
  pages        = {389-406},
  shortjournal = {Biol. Cybern.},
  title        = {Autoencoders reloaded},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Unveiling social distancing mechanisms via a
fish-robot hybrid interaction. <em>BCYB</em>, <em>116</em>(3), 387. (<a
href="https://doi.org/10.1007/s00422-022-00930-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BCYB},
  author       = {Romano, Donato and Stefanini, Cesare},
  doi          = {10.1007/s00422-022-00930-z},
  journal      = {Biological Cybernetics},
  month        = {6},
  number       = {3},
  pages        = {387},
  shortjournal = {Biol. Cybern.},
  title        = {Correction to: Unveiling social distancing mechanisms via a fish-robot hybrid interaction},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural kernels for recursive support vector regression as a
model for episodic memory. <em>BCYB</em>, <em>116</em>(3), 377–386. (<a
href="https://doi.org/10.1007/s00422-022-00926-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieval of episodic memories requires intrinsic reactivation of neuronal activity patterns. The content of the memories is thereby assumed to be stored in synaptic connections. This paper proposes a theory in which these are the synaptic connections that specifically convey the temporal order information contained in the sequences of a neuronal reservoir to the sensory-motor cortical areas that give rise to the subjective impression of retrieval of sensory motor events. The theory is based on a novel recursive version of support vector regression that allows for efficient continuous learning that is only limited by the representational capacity of the reservoir. The paper argues that hippocampal theta sequences are a potential neural substrate underlying this reservoir. The theory is consistent with confabulations and post hoc alterations of existing memories.},
  archive      = {J_BCYB},
  author       = {Leibold, Christian},
  doi          = {10.1007/s00422-022-00926-9},
  journal      = {Biological Cybernetics},
  month        = {6},
  number       = {3},
  pages        = {377-386},
  shortjournal = {Biol. Cybern.},
  title        = {Neural kernels for recursive support vector regression as a model for episodic memory},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pulse-frequency-dependent resonance in a population of
pyramidal neuron models. <em>BCYB</em>, <em>116</em>(3), 363–375. (<a
href="https://doi.org/10.1007/s00422-022-00925-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic resonance is known as a phenomenon whereby information transmission of weak signal or subthreshold stimuli can be enhanced by additive random noise with a suitable intensity. Another phenomenon induced by applying deterministic pulsatile electric stimuli with a pulse frequency, commonly used for deep brain stimulation (DBS), was also shown to improve signal-to-noise ratio in neuron models. The objective of this study was to test the hypothesis that pulsatile high-frequency stimulation could improve the detection of both sub- and suprathreshold synaptic stimuli by tuning the frequency of the stimulation in a population of pyramidal neuron models. Computer simulations showed that mutual information estimated from a population of neural spike trains displayed a typical resonance curve with a peak value of the pulse frequency at 80–120 Hz, similar to those utilized for DBS in clinical situations. It is concluded that a “pulse-frequency-dependent resonance” (PFDR) can enhance information transmission over a broad range of synaptically connected networks. Since the resonance frequency matches that used clinically, PFDR could contribute to the mechanism of the therapeutic effect of DBS.},
  archive      = {J_BCYB},
  author       = {Mori, Ryosuke and Mino, Hiroyuki and Durand, Dominique M.},
  doi          = {10.1007/s00422-022-00925-w},
  journal      = {Biological Cybernetics},
  month        = {6},
  number       = {3},
  pages        = {363-375},
  shortjournal = {Biol. Cybern.},
  title        = {Pulse-frequency-dependent resonance in a population of pyramidal neuron models},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The impact of sparse coding on memory lifetimes in simple
and complex models of synaptic plasticity. <em>BCYB</em>,
<em>116</em>(3), 327–362. (<a
href="https://doi.org/10.1007/s00422-022-00923-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models of associative memory with discrete state synapses learn new memories by forgetting old ones. In the simplest models, memories are forgotten exponentially quickly. Sparse population coding ameliorates this problem, as do complex models of synaptic plasticity that posit internal synaptic states, giving rise to synaptic metaplasticity. We examine memory lifetimes in both simple and complex models of synaptic plasticity with sparse coding. We consider our own integrative, filter-based model of synaptic plasticity, and examine the cascade and serial synapse models for comparison. We explore memory lifetimes at both the single-neuron and the population level, allowing for spontaneous activity. Memory lifetimes are defined using either a signal-to-noise ratio (SNR) approach or a first passage time (FPT) method, although we use the latter only for simple models at the single-neuron level. All studied models exhibit a decrease in the optimal single-neuron SNR memory lifetime, optimised with respect to sparseness, as the probability of synaptic updates decreases or, equivalently, as synaptic complexity increases. This holds regardless of spontaneous activity levels. In contrast, at the population level, even a low but nonzero level of spontaneous activity is critical in facilitating an increase in optimal SNR memory lifetimes with increasing synaptic complexity, but only in filter and serial models. However, SNR memory lifetimes are valid only in an asymptotic regime in which a mean field approximation is valid. By considering FPT memory lifetimes, we find that this asymptotic regime is not satisfied for very sparse coding, violating the conditions for the optimisation of single-perceptron SNR memory lifetimes with respect to sparseness. Similar violations are also expected for complex models of synaptic plasticity.},
  archive      = {J_BCYB},
  author       = {Elliott, Terry},
  doi          = {10.1007/s00422-022-00923-y},
  journal      = {Biological Cybernetics},
  month        = {6},
  number       = {3},
  pages        = {327-362},
  shortjournal = {Biol. Cybern.},
  title        = {The impact of sparse coding on memory lifetimes in simple and complex models of synaptic plasticity},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human motor learning is robust to control-dependent noise.
<em>BCYB</em>, <em>116</em>(3), 307–325. (<a
href="https://doi.org/10.1007/s00422-022-00922-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Noises are ubiquitous in sensorimotor interactions and contaminate the information provided to the central nervous system (CNS) for motor learning. An interesting question is how the CNS manages motor learning with imprecise information. Integrating ideas from reinforcement learning and adaptive optimal control, this paper develops a novel computational mechanism to explain the robustness of human motor learning to the imprecise information, caused by control-dependent noise that exists inherently in the sensorimotor systems. Starting from an initial admissible control policy, in each learning trial the mechanism collects and uses the noisy sensory data (caused by the control-dependent noise) to form an imprecise evaluation of the performance of the current policy and then constructs an updated policy based on the imprecise evaluation. As the number of learning trials increases, the generated policies mathematically provably converge to a (potentially small) neighborhood of the optimal policy under mild conditions, despite the imprecise information in the learning process. The mechanism directly synthesizes the policies from the sensory data, without identifying an internal forward model. Our preliminary computational results on two classic arm reaching tasks are in line with experimental observations reported in the literature. The model-free control principle proposed in the paper sheds more lights into the inherent robustness of human sensorimotor systems to the imprecise information, especially control-dependent noise, in the CNS.},
  archive      = {J_BCYB},
  author       = {Pang, Bo and Cui, Leilei and Jiang, Zhong-Ping},
  doi          = {10.1007/s00422-022-00922-z},
  journal      = {Biological Cybernetics},
  month        = {6},
  number       = {3},
  pages        = {307-325},
  shortjournal = {Biol. Cybern.},
  title        = {Human motor learning is robust to control-dependent noise},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of motor neural system robotic modeling approaches
and instruments. <em>BCYB</em>, <em>116</em>(3), 271–306. (<a
href="https://doi.org/10.1007/s00422-021-00918-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this review, we are considering an actively developing tool in neuroscience—robotic modeling. The new perspective and existing application fields, tools, and methods are discussed. We try to determine starting positions and approaches that are useful at the beginning of new research in this field. Among multiple directions of the research is robotic modeling on the level of muscles fibers and their afferents, skin surface sensors, muscles, and joints proprioceptors. Some examples of technical implementation for physical modeling are reviewed. They are software and hardware tools like event-related modeling algorithms, reduced neuron models, robotic drives constructions. We observe existing drives technologies and prospective electric motor types: switched reluctance and transverse flux motors. Next, we look at the existing examples and approaches for robotic modeling of the cerebellum and spinal cord neural networks. These examples show practical methods for the model neural network architecture and adaptation. Those methods allow the use of cortical and spinal cord reflexes for the network training and apply additional artificial blocks for data processing in other brain structures that transmit and receive data from biologically realistic models.},
  archive      = {J_BCYB},
  author       = {Migalev, Alexander S. and Vigasina, Kristina D. and Gotovtsev, Pavel M.},
  doi          = {10.1007/s00422-021-00918-1},
  journal      = {Biological Cybernetics},
  month        = {6},
  number       = {3},
  pages        = {271-306},
  shortjournal = {Biol. Cybern.},
  title        = {A review of motor neural system robotic modeling approaches and instruments},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sensory feedback expands dynamic complexity and aids in
robustness against noise. <em>BCYB</em>, <em>116</em>(3), 267–269. (<a
href="https://doi.org/10.1007/s00422-021-00917-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been hypothesized that sensory feedback is a critical component in determining the functionality of a central pattern generator. To test this, Yu and Thomas’s recent work Yu and Thomas (Biol Cybern 115(2):135–160, 2021) built a model of a half-center oscillator coupled to a simple muscular model with sensory feedback. They showed that sensory feedback increases robustness against external noise, while simultaneously expanding the potential repertoire of functions the half-center oscillator can perform. However, they show that this comes at the cost of robustness against internal noise.},
  archive      = {J_BCYB},
  author       = {White, Alexander J.},
  doi          = {10.1007/s00422-021-00917-2},
  journal      = {Biological Cybernetics},
  month        = {6},
  number       = {3},
  pages        = {267-269},
  shortjournal = {Biol. Cybern.},
  title        = {Sensory feedback expands dynamic complexity and aids in robustness against noise},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Drifting neuronal representations: Bug or feature?
<em>BCYB</em>, <em>116</em>(3), 253–266. (<a
href="https://doi.org/10.1007/s00422-021-00916-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The brain displays a remarkable ability to sustain stable memories, allowing animals to execute precise behaviors or recall stimulus associations years after they were first learned. Yet, recent long-term recording experiments have revealed that single-neuron representations continuously change over time, contravening the classical assumption that learned features remain static. How do unstable neural codes support robust perception, memories, and actions? Here, we review recent experimental evidence for such representational drift across brain areas, as well as dissections of its functional characteristics and underlying mechanisms. We emphasize theoretical proposals for how drift need not only be a form of noise for which the brain must compensate. Rather, it can emerge from computationally beneficial mechanisms in hierarchical networks performing robust probabilistic computations.},
  archive      = {J_BCYB},
  author       = {Masset, Paul and Qin, Shanshan and Zavatone-Veth, Jacob A.},
  doi          = {10.1007/s00422-021-00916-3},
  journal      = {Biological Cybernetics},
  month        = {6},
  number       = {3},
  pages        = {253-266},
  shortjournal = {Biol. Cybern.},
  title        = {Drifting neuronal representations: Bug or feature?},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mean-return-time phase of a stochastic oscillator provides
an approximate renewal description for the associated point process.
<em>BCYB</em>, <em>116</em>(2), 235–251. (<a
href="https://doi.org/10.1007/s00422-022-00920-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic oscillations can be characterized by a corresponding point process; this is a common practice in computational neuroscience, where oscillations of the membrane voltage under the influence of noise are often analyzed in terms of the interspike interval statistics, specifically the distribution and correlation of intervals between subsequent threshold-crossing times. More generally, crossing times and the corresponding interval sequences can be introduced for different kinds of stochastic oscillators that have been used to model variability of rhythmic activity in biological systems. In this paper we show that if we use the so-called mean-return-time (MRT) phase isochrons (introduced by Schwabedal and Pikovsky) to count the cycles of a stochastic oscillator with Markovian dynamics, the interphase interval sequence does not show any linear correlations, i.e., the corresponding sequence of passage times forms approximately a renewal point process. We first outline the general mathematical argument for this finding and illustrate it numerically for three models of increasing complexity: (i) the isotropic Guckenheimer–Schwabedal–Pikovsky oscillator that displays positive interspike interval (ISI) correlations if rotations are counted by passing the spoke of a wheel; (ii) the adaptive leaky integrate-and-fire model with white Gaussian noise that shows negative interspike interval correlations when spikes are counted in the usual way by the passage of a voltage threshold; (iii) a Hodgkin–Huxley model with channel noise (in the diffusion approximation represented by Gaussian noise) that exhibits weak but statistically significant interspike interval correlations, again for spikes counted when passing a voltage threshold. For all these models, linear correlations between intervals vanish when we count rotations by the passage of an MRT isochron. We finally discuss that the removal of interval correlations does not change the long-term variability and its effect on information transmission, especially in the neural context.},
  archive      = {J_BCYB},
  author       = {Holzhausen, Konstantin and Ramlow, Lukas and Pu, Shusen and Thomas, Peter J. and Lindner, Benjamin},
  doi          = {10.1007/s00422-022-00920-1},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {2},
  pages        = {235-251},
  shortjournal = {Biol. Cybern.},
  title        = {Mean-return-time phase of a stochastic oscillator provides an approximate renewal description for the associated point process},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantitative comparison of the mean–return-time phase and
the stochastic asymptotic phase for noisy oscillators. <em>BCYB</em>,
<em>116</em>(2), 219–234. (<a
href="https://doi.org/10.1007/s00422-022-00929-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seminal work by A. Winfree and J. Guckenheimer showed that a deterministic phase variable can be defined either in terms of Poincaré sections or in terms of the asymptotic (long-time) behaviour of trajectories approaching a stable limit cycle. However, this equivalence between the deterministic notions of phase is broken in the presence of noise. Different notions of phase reduction for a stochastic oscillator can be defined either in terms of mean–return-time sections or as the argument of the slowest decaying complex eigenfunction of the Kolmogorov backwards operator. Although both notions of phase enjoy a solid theoretical foundation, their relationship remains unexplored. Here, we quantitatively compare both notions of stochastic phase. We derive an expression relating both notions of phase and use it to discuss differences (and similarities) between both definitions of stochastic phase for (i) a spiral sink motivated by stochastic models for electroencephalograms, (ii) noisy limit-cycle systems-neuroscience models, and (iii) a stochastic heteroclinic oscillator inspired by a simple motor-control system.},
  archive      = {J_BCYB},
  author       = {Pérez-Cervera, Alberto and Lindner, Benjamin and Thomas, Peter J.},
  doi          = {10.1007/s00422-022-00929-6},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {2},
  pages        = {219-234},
  shortjournal = {Biol. Cybern.},
  title        = {Quantitative comparison of the mean–return-time phase and the stochastic asymptotic phase for noisy oscillators},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A biophysical counting mechanism for keeping time.
<em>BCYB</em>, <em>116</em>(2), 205–218. (<a
href="https://doi.org/10.1007/s00422-021-00915-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to estimate and produce appropriately timed responses is central to many behaviors including speaking, dancing, and playing a musical instrument. A classical framework for estimating or producing a time interval is the pacemaker-accumulator model in which pulses of a pacemaker are counted and compared to a stored representation. However, the neural mechanisms for how these pulses are counted remain an open question. The presence of noise and stochasticity further complicates the picture. We present a biophysical model of how to keep count of a pacemaker in the presence of various forms of stochasticity using a system of bistable Wilson-Cowan units asymmetrically connected in a one-dimensional array; all units receive the same input pulses from a central clock but only one unit is active at any point in time. With each pulse from the clock, the position of the activated unit changes thereby encoding the total number of pulses emitted by the clock. This neural architecture maps the counting problem into the spatial domain, which in turn translates count to a time estimate. We further extend the model to a hierarchical structure to be able to robustly achieve higher counts.},
  archive      = {J_BCYB},
  author       = {Zemlianova, Klavdia and Bose, Amitabha and Rinzel, John},
  doi          = {10.1007/s00422-021-00915-4},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {2},
  pages        = {205-218},
  shortjournal = {Biol. Cybern.},
  title        = {A biophysical counting mechanism for keeping time},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Phase response approaches to neural activity models with
distributed delay. <em>BCYB</em>, <em>116</em>(2), 191–203. (<a
href="https://doi.org/10.1007/s00422-021-00910-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In weakly coupled neural oscillator networks describing brain dynamics, the coupling delay is often distributed. We present a theoretical framework to calculate the phase response curve of distributed-delay induced limit cycles with infinite-dimensional phase space. Extending previous works, in which non-delayed or discrete-delay systems were investigated, we develop analytical results for phase response curves of oscillatory systems with distributed delay using Gaussian and log-normal delay distributions. We determine the scalar product and normalization condition for the linearized adjoint of the system required for the calculation of the phase response curve. As a paradigmatic example, we apply our technique to the Wilson–Cowan oscillator model of excitatory and inhibitory neuronal populations under the two delay distributions. We calculate and compare the phase response curves for the Gaussian and log-normal delay distributions. The phase response curves obtained from our adjoint calculations match those compiled by the direct perturbation method, thereby proving that the theory of weakly coupled oscillators can be applied successfully for distributed-delay-induced limit cycles. We further use the obtained phase response curves to derive phase interaction functions and determine the possible phase locked states of multiple inter-coupled populations to illuminate different synchronization scenarios. In numerical simulations, we show that the coupling delay distribution can impact the stability of the synchronization between inter-coupled gamma-oscillatory networks.},
  archive      = {J_BCYB},
  author       = {Winkler, Marius and Dumont, Grégory and Schöll, Eckehard and Gutkin, Boris},
  doi          = {10.1007/s00422-021-00910-9},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {2},
  pages        = {191-203},
  shortjournal = {Biol. Cybern.},
  title        = {Phase response approaches to neural activity models with distributed delay},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The voltage and spiking responses of subthreshold resonant
neurons to structured and fluctuating inputs: Persistence and loss of
resonance and variability. <em>BCYB</em>, <em>116</em>(2), 163–190. (<a
href="https://doi.org/10.1007/s00422-021-00919-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We systematically investigate the response of neurons to oscillatory currents and synaptic-like inputs and we extend our investigation to non-structured synaptic-like spiking inputs with more realistic distributions of presynaptic spike times. We use two types of chirp-like inputs consisting of (i) a sequence of cycles with discretely increasing frequencies over time, and (ii) a sequence having the same cycles arranged in an arbitrary order. We develop and use a number of frequency-dependent voltage response metrics to capture the different aspects of the voltage response, including the standard impedance (Z) and the peak-to-trough amplitude envelope ( $$V_{\text {ENV}}$$ ) profiles. We show that Z-resonant cells (cells that exhibit subthreshold resonance in response to sinusoidal inputs) also show $$ V_{\text {ENV}} $$ -resonance in response to sinusoidal inputs, but generally do not (or do it very mildly) in response to square-wave and synaptic-like inputs. In the latter cases the resonant response using Z is not predictive of the preferred frequencies at which the neurons spike when the input amplitude is increased above subthreshold levels. We also show that responses to conductance-based synaptic-like inputs are attenuated as compared to the response to current-based synaptic-like inputs, thus providing an explanation to previous experimental results. These response patterns were strongly dependent on the intrinsic properties of the participating neurons, in particular whether the unperturbed Z-resonant cells had a stable node or a focus. In addition, we show that variability emerges in response to chirp-like inputs with arbitrarily ordered patterns where all signals (trials) in a given protocol have the same frequency content and the only source of uncertainty is the subset of all possible permutations of cycles chosen for a given protocol. This variability is the result of the multiple different ways in which the autonomous transient dynamics is activated across cycles in each signal (different cycle orderings) and across trials. We extend our results to include high-rate Poisson distributed current- and conductance-based synaptic inputs and compare them with similar results using additive Gaussian white noise. We show that the responses to both Poisson-distributed synaptic inputs are attenuated with respect to the responses to Gaussian white noise. For cells that exhibit oscillatory responses to Gaussian white noise (band-pass filters), the response to conductance-based synaptic inputs are low-pass filters, while the response to current-based synaptic inputs may remain band-pass filters, consistent with experimental findings. Our results shed light on the mechanisms of communication of oscillatory activity among neurons in a network via subthreshold oscillations and resonance and the generation of network resonance.},
  archive      = {J_BCYB},
  author       = {Pena, Rodrigo F. O. and Rotstein, Horacio G.},
  doi          = {10.1007/s00422-021-00919-0},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {2},
  pages        = {163-190},
  shortjournal = {Biol. Cybern.},
  title        = {The voltage and spiking responses of subthreshold resonant neurons to structured and fluctuating inputs: Persistence and loss of resonance and variability},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic synchronization in nonlinear network systems
driven by intrinsic and coupling noise. <em>BCYB</em>, <em>116</em>(2),
147–162. (<a href="https://doi.org/10.1007/s00422-022-00928-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a noisy network of nonlinear systems in the sense that each system is driven by two sources of state-dependent noise: (1) an intrinsic noise that can be generated by the environment or any internal fluctuations and (2) a noisy coupling which is generated by interactions with other systems. Our goal is to understand the effect of noise and coupling on synchronization behaviors of such networks. First, we assume that all the systems are driven by a common noise and show how a common noise can be detrimental or beneficial for network synchronization behavior. Then, we assume that the systems are driven by independent noise and study network approximate synchronization behavior. We numerically illustrate our results using the example of coupled Van der Pol oscillators.},
  archive      = {J_BCYB},
  author       = {Aminzare, Zahra and Srivastava, Vaibhav},
  doi          = {10.1007/s00422-022-00928-7},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {2},
  pages        = {147-162},
  shortjournal = {Biol. Cybern.},
  title        = {Stochastic synchronization in nonlinear network systems driven by intrinsic and coupling noise},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mutual information resonances in delay-coupled limit cycle
and quasi-cycle brain rhythms. <em>BCYB</em>, <em>116</em>(2), 129–146.
(<a href="https://doi.org/10.1007/s00422-022-00932-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We elucidate how coupling delays and noise impact phase and mutual information relationships between two stochastic brain rhythms. This impact depends on the dynamical regime of each PING-based rhythm, as well as on network heterogeneity and coupling asymmetry. The number of peaks at positive and negative time lags in the delayed mutual information between the two bi-directionally communicating rhythms defines our measure of flexibility of information sharing and reflects the number of ways in which the two networks can alternately lead one another. We identify two distinct mechanisms for the appearance of qualitatively similar flexible information sharing. The flexibility in the quasi-cycle regime arises from the coupling delay-induced bimodality of the phase difference distribution, and the related bimodal mutual information. It persists in the presence of asymmetric coupling and heterogeneity but is limited to two routes of information sharing. The second mechanism in noisy limit cycle regime is not induced by the delay. However, delay-coupling and heterogeneity enable communication routes at multiple time lags. Noise disrupts the shared compromise frequency, allowing the expression of individual network frequencies which leads to a slow beating pattern. Simulations of an envelope-phase description for delay-coupled quasi-cycles yield qualitatively similar properties as for the full system. Near the bifurcation from in-phase to out-of-phase behaviour, a single preferred phase difference can coexist with two information sharing routes; further, the phase laggard can be the mutual information leader, or vice versa. Overall, the coupling delay endows a two-rhythm system with an array of lead-lag relationships and mutual information resonances that exist in spite of the noise and across the Hopf bifurcation. These beg to be mapped out experimentally with the help of our predictions.},
  archive      = {J_BCYB},
  author       = {Powanwe, Arthur S. and Longtin, André},
  doi          = {10.1007/s00422-022-00932-x},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {2},
  pages        = {129-146},
  shortjournal = {Biol. Cybern.},
  title        = {Mutual information resonances in delay-coupled limit cycle and quasi-cycle brain rhythms},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic bursting in networks of excitable units with
delayed coupling. <em>BCYB</em>, <em>116</em>(2), 121–128. (<a
href="https://doi.org/10.1007/s00422-021-00883-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the phenomenon of stochastic bursting in a noisy excitable unit with multiple weak delay feedbacks, by virtue of a directed tree lattice model. We find statistical properties of the appearing sequence of spikes and expressions for the power spectral density. This simple model is extended to a network of three units with delayed coupling of a star type. We find the power spectral density of each unit and the cross-spectral density between any two units. The basic assumptions behind the analytical approach are the separation of timescales, allowing for a description of the spike train as a point process, and weakness of coupling, allowing for a representation of the action of overlapped spikes via the sum of the one-spike excitation probabilities.},
  archive      = {J_BCYB},
  author       = {Zheng, Chunming and Pikovsky, Arkady},
  doi          = {10.1007/s00422-021-00883-9},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {2},
  pages        = {121-128},
  shortjournal = {Biol. Cybern.},
  title        = {Stochastic bursting in networks of excitable units with delayed coupling},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic oscillators in biology: Introduction to the
special issue. <em>BCYB</em>, <em>116</em>(2), 119–120. (<a
href="https://doi.org/10.1007/s00422-022-00931-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BCYB},
  author       = {MacLaurin, J. and Fellous, J. M. and Thomas, P. J. and Lindner, B.},
  doi          = {10.1007/s00422-022-00931-y},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {2},
  pages        = {119-120},
  shortjournal = {Biol. Cybern.},
  title        = {Stochastic oscillators in biology: Introduction to the special issue},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Excitable networks for finite state
computation with continuous time recurrent neural networks.
<em>BCYB</em>, <em>116</em>(1), 117. (<a
href="https://doi.org/10.1007/s00422-021-00911-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BCYB},
  author       = {Ashwin, Peter and Postlethwaite, Claire},
  doi          = {10.1007/s00422-021-00911-8},
  journal      = {Biological Cybernetics},
  month        = {2},
  number       = {1},
  pages        = {117},
  shortjournal = {Biol. Cybern.},
  title        = {Correction to: Excitable networks for finite state computation with continuous time recurrent neural networks},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep brain stimulation for movement disorder treatment:
Exploring frequency-dependent efficacy in a computational network model.
<em>BCYB</em>, <em>116</em>(1), 93–116. (<a
href="https://doi.org/10.1007/s00422-021-00909-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large-scale computational model of the basal ganglia network and thalamus is proposed to describe movement disorders and treatment effects of deep brain stimulation (DBS). The model of this complex network considers three areas of the basal ganglia region: the subthalamic nucleus (STN) as target area of DBS, the globus pallidus, both pars externa and pars interna (GPe-GPi), and the thalamus. Parkinsonian conditions are simulated by assuming reduced dopaminergic input and corresponding pronounced inhibitory or disinhibited projections to GPe and GPi. Macroscopic quantities are derived which correlate closely to thalamic responses and hence motor programme fidelity. It can be demonstrated that depending on different levels of striatal projections to the GPe and GPi, the dynamics of these macroscopic quantities (synchronisation index, mean synaptic activity and response efficacy) switch from normal to Parkinsonian conditions. Simulating DBS of the STN affects the dynamics of the entire network, increasing the thalamic activity to levels close to normal, while differing from both normal and Parkinsonian dynamics. Using the mentioned macroscopic quantities, the model proposes optimal DBS frequency ranges above 130 Hz.},
  archive      = {J_BCYB},
  author       = {Spiliotis, Konstantinos and Starke, Jens and Franz, Denise and Richter, Angelika and Köhling, Rüdiger},
  doi          = {10.1007/s00422-021-00909-2},
  journal      = {Biological Cybernetics},
  month        = {2},
  number       = {1},
  pages        = {93-116},
  shortjournal = {Biol. Cybern.},
  title        = {Deep brain stimulation for movement disorder treatment: Exploring frequency-dependent efficacy in a computational network model},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pattern formation revisited within nonequilibrium
thermodynamics: Burgers’-type equation. <em>BCYB</em>, <em>116</em>(1),
81–91. (<a href="https://doi.org/10.1007/s00422-021-00908-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the description of reaction–diffusion phenomena within nonequilibrium thermodynamics and investigate the role of a nonstandard splitting of the entropy balance into the entropy production and the divergence of entropy flux. As previously reported by Pavelka et al. (Int J Eng Sci 78:192-217, 2014), a new term is identified following from the kinetic energy of diffusion. This newly appearing term acts as a thermodynamic force driving the reaction kinetics. Using the standard constitutive relations within the linear nonequilibrium thermodynamics, the governing equations for a reaction–diffusion problem in a two-species system are derived. They turn out to be linked to Burgers’ equation. It is shown that the onset of stability is not altered, but a non-periodic pattern can emerge. The latter follows from the relation of the governing equation to Burger’s equation with a source term. Hence, transients formed by glued and merging parabolic profiles are expected to appear at least in certain parameter regimes. We explore the significance of this effect and observe that for a comparable magnitude of the diffusion and of the new term stemming from the kinetic energy of diffusion, the solution is expected to be linked to the saw-tooth like solution to Burger’s equation rather than to the eigenmodes of the Laplacian. We conclude that the reaction–diffusion model proposed by Turing is robust to the addition of this effect of the kinetic energy of diffusion, at least when this new term is sufficiently small. As the governing equations can be rewritten into the classical reaction–diffusion problem but with reaction kinetics outside of the classical law of mass action, the analysis presented in this study suggests that a yet richer behaviour of the classical reaction–diffusion problems can be expected, if nonstandard reaction kinetics are considered.},
  archive      = {J_BCYB},
  author       = {Klika, Václav},
  doi          = {10.1007/s00422-021-00908-3},
  journal      = {Biological Cybernetics},
  month        = {2},
  number       = {1},
  pages        = {81-91},
  shortjournal = {Biol. Cybern.},
  title        = {Pattern formation revisited within nonequilibrium thermodynamics: Burgers’-type equation},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On motion camouflage as proportional navigation.
<em>BCYB</em>, <em>116</em>(1), 69–79. (<a
href="https://doi.org/10.1007/s00422-021-00907-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion camouflage is a stealth behaviour by which an insect can appear stationary at a fixed point while approaching or escaping another moving insect. Although several approaches have been proposed to generate motion camouflage in simulated and real agents, the exact mechanisms insects use to perform this complex behaviour are not well understood, especially considering their limited perceptual and computational resources. This paper sheds light on the possible underlying control mechanisms insect might use to generate motion camouflage, by training and analysing a series of motion camouflage controllers using reinforcement learning. We first investigate through simulations the most relevant information available to the insect that can be used to perform motion camouflage and analyse the learnt controllers. The results of this analysis drove us to hypothesise two simpler control mechanisms which, we show, can also generate motion camouflage. The proposed controllers are an extension of proportional navigation, another interception technique found in nature, and therefore, both animal behaviours seem to be connected. Motion camouflage can lead, among others, to novel approaches to closely observe animals in the wild, record sports events or gather information in military operations without being noticed.},
  archive      = {J_BCYB},
  author       = {Rañó, Iñaki},
  doi          = {10.1007/s00422-021-00907-4},
  journal      = {Biological Cybernetics},
  month        = {2},
  number       = {1},
  pages        = {69-79},
  shortjournal = {Biol. Cybern.},
  title        = {On motion camouflage as proportional navigation},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Geodesic-based distance reveals nonlinear topological
features in neural activity from mouse visual cortex. <em>BCYB</em>,
<em>116</em>(1), 53–68. (<a
href="https://doi.org/10.1007/s00422-021-00906-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An increasingly popular approach to the analysis of neural data is to treat activity patterns as being constrained to and sampled from a manifold, which can be characterized by its topology. The persistent homology method identifies the type and number of holes in the manifold, thereby yielding functional information about the coding and dynamic properties of the underlying neural network. In this work, we give examples of highly nonlinear manifolds in which the persistent homology algorithm fails when it uses the Euclidean distance because it does not always yield a good approximation to the true distance distribution of a point cloud sampled from a manifold. To deal with this issue, we instead estimate the geodesic distance which is a better approximation of the true distance distribution and can therefore be used to successfully identify highly nonlinear features with persistent homology. To document the utility of the method, we utilize a toy model comprised of a circular manifold, built from orthogonal sinusoidal coordinate functions and show how the choice of metric determines the performance of the persistent homology algorithm. Furthermore, we explore the robustness of the method across different manifold properties, like the number of samples, curvature and amount of added noise. We point out strategies for interpreting its results as well as some possible pitfalls of its application. Subsequently, we apply this analysis to neural data coming from the Visual Coding-Neuropixels dataset recorded at the Allen Institute in mouse visual cortex in response to stimulation with drifting gratings. We find that different manifolds with a non-trivial topology can be seen across regions and stimulus properties. Finally, we interpret how these changes in manifold topology along with stimulus parameters and cortical region inform how the brain performs visual computation.},
  archive      = {J_BCYB},
  author       = {Beshkov, Kosio and Tiesinga, Paul},
  doi          = {10.1007/s00422-021-00906-5},
  journal      = {Biological Cybernetics},
  month        = {2},
  number       = {1},
  pages        = {53-68},
  shortjournal = {Biol. Cybern.},
  title        = {Geodesic-based distance reveals nonlinear topological features in neural activity from mouse visual cortex},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalized neural field theory of cortical plasticity
illustrated by an application to the linear phase of ocular dominance
column formation in primary visual cortex. <em>BCYB</em>,
<em>116</em>(1), 33–52. (<a
href="https://doi.org/10.1007/s00422-021-00901-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physiologically based neural field theory (NFT) is extended to encompass cortical plasticity dynamics. An illustrative application is provided which treats the evolution of the connectivity of left- and right-eye visual stimuli to neuronal populations in the primary visual cortex (V1), and the initial, linear phase of formation of approximately one-dimensional (1D) ocular dominance columns (ODCs) that sets their transverse spatial scale. This links V1 activity, structure, and physiology within a single theory that already accounts for a range of other brain activity and connectivity phenomena, thereby enabling ODC formation and many other phenomena to be interrelated and cortical parameters to be constrained across multiple domains. The results accord with experimental ODC widths for realistic cortical parameters and are based directly on a unified description of the neuronal populations involved, their connection strengths, and the neuronal activity they support. Other key results include simple analytic approximations for ODC widths and the parameters of maximum growth rate, constraints on cortical excitatory and inhibitory gains, elucidation of the roles of specific poles of the V1 response function, and the fact that ODCs are not formed when input stimuli are fully correlated between eyes. This work provides a basis for further generalization of NFT to model other plasticity phenomena, thereby linking them to the range multiscale phenomena accounted for by NFT.},
  archive      = {J_BCYB},
  author       = {Aghili Yajadda, M. M. and Robinson, P. A. and Henderson, J. A.},
  doi          = {10.1007/s00422-021-00901-w},
  journal      = {Biological Cybernetics},
  month        = {2},
  number       = {1},
  pages        = {33-52},
  shortjournal = {Biol. Cybern.},
  title        = {Generalized neural field theory of cortical plasticity illustrated by an application to the linear phase of ocular dominance column formation in primary visual cortex},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Auxiliary controller design and performance comparative
analysis in closed-loop brain–machine interface system. <em>BCYB</em>,
<em>116</em>(1), 23–32. (<a
href="https://doi.org/10.1007/s00422-021-00897-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain–machine interface (BMI) can realize information interaction between the brain and external devices, and yet the control accuracy is limited by the change of electroencephalogram signals. The introduction of auxiliary controller can overcome the above problems, but the performance of different auxiliary controllers is quite different. Hence, in this paper, we comprehensively compare and analyze the performance of different auxiliary controllers to provide a theoretical basis for designing BMI system. The main work includes: (1) designing four kinds of auxiliary controllers based on simultaneous perturbation stochastic approximation-function approximator (SPSA-FA), iterative feedback tuning-PID (IFT-PID), model predictive control (MPC) and model-free control (MFC); (2) based on the model of improved single-joint information transmission, constructing the closed-loop BMI systems with the decoder-based Wiener filter; and (3) comparing their performance in the constructed closed-loop BMI systems for dynamic motion restoration. The results show that the order of tracking accuracy is MPC, IFT-PID, SPSA-FA, MFC, and the order of time consumed is opposite. A good control effectiveness is achieved at the expense of time, so a suitable auxiliary controller should be selected according to the actual requirements.},
  archive      = {J_BCYB},
  author       = {Pan, Hongguang and Song, Haoqian and Zhang, Qi and Mi, Wenyu and Sun, Jinggao},
  doi          = {10.1007/s00422-021-00897-3},
  journal      = {Biological Cybernetics},
  month        = {2},
  number       = {1},
  pages        = {23-32},
  shortjournal = {Biol. Cybern.},
  title        = {Auxiliary controller design and performance comparative analysis in closed-loop brain–machine interface system},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A discrete magno–parvo additive model in early vision for
explaining brightness perception in varying contrastive contexts.
<em>BCYB</em>, <em>116</em>(1), 5–21. (<a
href="https://doi.org/10.1007/s00422-021-00896-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A varying contrastive context filter (VCCF)-based model of brightness perception has been proposed. It is motivated first by a recently proposed difference of difference-of-Gaussian (DDOG) filter. Alongside, it is also inspired from the fact that the nature evolves various discrete systems and mechanisms to carry out many of its complex tasks. A weight factor, used for the linear combination of two filters representing the magnocellular and parvocellular channels in the central visual pathway, has been defined and termed as the factor of contrastive context (FOCC) in the present model. This is a binary variable that lends a property of discretization to the DDOG filter. By analyzing important brightness contrast as well as brightness assimilation illusions, we arrive at the minimal set of values (only two) for FOCC, using which one is able to successfully predict the direction of brightness shift in both situations of brightness contrast, claimed and categorized here as low contrastive context, and those of brightness assimilation, claimed and categorized here as high contrastive context perception, depending upon whether the initial M-channel-filtered stimulus is above or below a threshold of the contrastive context. As distinct from Michelson/Weber/RMS contrast, high or low, the contrastive context claimed is dependent on the edge information in the stimulus determined by the Laplacian operator, also used in the DDOG model. We compared the proposed model against the already well-established oriented difference-of-Gaussian (ODOG) model of brightness perception. Extensive simulations suggest that though for most illusions both ODOG and VCCF produce correct output, for certain intricate cases in which the ODOG filter fails to correctly predict the illusory effect, our proposed VCCF model continues to remain effective.},
  archive      = {J_BCYB},
  author       = {Bakshi, Ashish and Roy, Sourya and Mallick, Arijit and Ghosh, Kuntal},
  doi          = {10.1007/s00422-021-00896-4},
  journal      = {Biological Cybernetics},
  month        = {2},
  number       = {1},
  pages        = {5-21},
  shortjournal = {Biol. Cybern.},
  title        = {A discrete magno–parvo additive model in early vision for explaining brightness perception in varying contrastive contexts},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial board of biological cybernetics: Advances in
computational neuroscience and in control and information theory for
biological systems. <em>BCYB</em>, <em>116</em>(1), 1–3. (<a
href="https://doi.org/10.1007/s00422-022-00921-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BCYB},
  doi          = {10.1007/s00422-022-00921-0},
  journal      = {Biological Cybernetics},
  month        = {2},
  number       = {1},
  pages        = {1-3},
  shortjournal = {Biol. Cybern.},
  title        = {Editorial board of biological cybernetics: Advances in computational neuroscience and in control and information theory for biological systems},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
