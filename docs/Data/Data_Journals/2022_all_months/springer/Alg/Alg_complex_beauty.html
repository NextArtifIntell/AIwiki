<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Alg_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="alg---140">Alg - 140</h2>
<ul>
<li><details>
<summary>
(2022). Distinct fringe subtrees in random trees. <em>Alg</em>,
<em>84</em>(12), 3686–3728. (<a
href="https://doi.org/10.1007/s00453-022-01013-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fringe subtree of a rooted tree is a subtree induced by one of the vertices and all its descendants. We consider the problem of estimating the number of distinct fringe subtrees in random trees under a generalized notion of distinctness, which allows for many different interpretations of what “distinct” trees are. The random tree models considered are simply generated trees and families of increasing trees (recursive trees, d-ary increasing trees and generalized plane-oriented recursive trees). We prove that the order of magnitude of the number of distinct fringe subtrees (under rather mild assumptions on what ‘distinct’ means) in random trees with n vertices is $$n/\sqrt{\log n}$$ for simply generated trees and $$n/\log n$$ for increasing trees.},
  archive      = {J_Alg},
  author       = {Seelbach Benkner, Louisa and Wagner, Stephan},
  doi          = {10.1007/s00453-022-01013-y},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3686-3728},
  shortjournal = {Algorithmica},
  title        = {Distinct fringe subtrees in random trees},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monotone circuit lower bounds from robust sunflowers.
<em>Alg</em>, <em>84</em>(12), 3655–3685. (<a
href="https://doi.org/10.1007/s00453-022-01000-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust sunflowers are a generalization of combinatorial sunflowers that have applications in monotone circuit complexity Rossman (SIAM J. Comput. 43:256–279, 2014), DNF sparsification Gopalan et al. (Comput. Complex. 22:275–310 2013), randomness extractors Li et al. (In: APPROX-RANDOM, LIPIcs 116:51:1–13, 2018), and recent advances on the Erdős-Rado sunflower conjecture Alweiss et al. (In: Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing, STOC. Association for Computing Machinery, New York, NY, USA, 2020) Lovett et al. (From dnf compression to sunflower theorems via regularity, 2019) Rao (Discrete Anal. 8,2020). The recent breakthrough of Alweiss, Lovett, Wu and Zhang Alweiss et al. (In: Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing, STOC. Association for Computing Machinery, New York, NY, USA, 2020) gives an improved bound on the maximum size of a w-set system that excludes a robust sunflower. In this paper, we use this result to obtain an $$\exp (n^{1/2-o(1)})$$ lower bound on the monotone circuit size of an explicit n-variate monotone function, improving the previous best known $$\exp (n^{1/3-o(1)})$$ due to Andreev (Algebra and Logic, 26:1–18, 1987) and Harnik and Raz (In: Proceedings of the Thirty-Second Annual ACM Symposium on Theory of Computing, ACM, New York, 2000). We also show an $$\exp (\varOmega (n))$$ lower bound on the monotone arithmetic circuit size of a related polynomial via a very simple proof. Finally, we introduce a notion of robust clique-sunflowers and use this to prove an $$n^{\varOmega (k)}$$ lower bound on the monotone circuit size of the CLIQUE function for all $$k \leqslant n^{1/3-o(1)}$$ , strengthening the bound of Alon and Boppana (Combinatorica, 7:1–22, 1987).},
  archive      = {J_Alg},
  author       = {Cavalar, Bruno Pasqualotto and Kumar, Mrinal and Rossman, Benjamin},
  doi          = {10.1007/s00453-022-01000-3},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3655-3685},
  shortjournal = {Algorithmica},
  title        = {Monotone circuit lower bounds from robust sunflowers},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximation algorithms for cost-robust discrete
minimization problems based on their LP-relaxations. <em>Alg</em>,
<em>84</em>(12), 3622–3654. (<a
href="https://doi.org/10.1007/s00453-022-00987-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider robust discrete minimization problems where uncertainty is defined by a convex set in the objective. Assuming the existence of an integrality gap verifier with a bounded approximation guarantee for the LP relaxation of the non-robust version of the problem, we derive approximation algorithms for the robust version under different types of uncertainty, including polyhedral and ellipsoidal uncertainty.},
  archive      = {J_Alg},
  author       = {Elbassioni, Khaled},
  doi          = {10.1007/s00453-022-00987-z},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3622-3654},
  shortjournal = {Algorithmica},
  title        = {Approximation algorithms for cost-robust discrete minimization problems based on their LP-relaxations},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exponential-time quantum algorithms for graph coloring
problems. <em>Alg</em>, <em>84</em>(12), 3603–3621. (<a
href="https://doi.org/10.1007/s00453-022-00976-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fastest known classical algorithm deciding the k-colorability of n-vertex graph requires running time $$\varOmega (2^n)$$ for $$k\ge 5$$ . In this work, we present an exponential-space quantum algorithm computing the chromatic number with running time $$O(1.9140^n)$$ using quantum random access memory (QRAM). Our approach is based on Ambainis et al’s quantum dynamic programming with applications of Grover’s search to branching algorithms. We also present a polynomial-space quantum algorithm not using QRAM for the graph 20-coloring problem with running time $$O(1.9575^n)$$ . For the polynomial-space quantum algorithm, we essentially develop $$(4-\epsilon )^n$$ -time classical algorithms that can be improved quadratically by Grover’s search.},
  archive      = {J_Alg},
  author       = {Shimizu, Kazuya and Mori, Ryuhei},
  doi          = {10.1007/s00453-022-00976-2},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3603-3621},
  shortjournal = {Algorithmica},
  title        = {Exponential-time quantum algorithms for graph coloring problems},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the maximum number of edges in chordal graphs of bounded
degree and matching number. <em>Alg</em>, <em>84</em>(12), 3587–3602.
(<a href="https://doi.org/10.1007/s00453-022-00953-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We determine the maximum number of edges that a chordal graph G can have if its degree, $$\varDelta (G)$$ , and its matching number, $$\nu (G)$$ , are bounded. To do so, we show that for every $$d,\nu \in \mathbb {N}$$ , there exists a chordal graph G with $$\varDelta (G)&lt;d$$ and $$\nu (G)&lt;\nu $$ whose number of edges matches the upper bound, while having a simple structure: G is a disjoint union of cliques and stars.},
  archive      = {J_Alg},
  author       = {Blair, Jean R. S. and Heggernes, Pinar and Lima, Paloma T. and Lokshtanov, Daniel},
  doi          = {10.1007/s00453-022-00953-9},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3587-3602},
  shortjournal = {Algorithmica},
  title        = {On the maximum number of edges in chordal graphs of bounded degree and matching number},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved upper bounds on the growth constants of polyominoes
and polycubes. <em>Alg</em>, <em>84</em>(12), 3559–3586. (<a
href="https://doi.org/10.1007/s00453-022-00948-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A d-dimensional polycube is a face-connected set of cells on $$\mathbb {Z}^d$$ . Let $$A_d(n)$$ denote the number of d-dimensional polycubes (distinct up to translations) with n cubes, and $$\lambda _d$$ denote their growth constant $$\displaystyle \lim _{n \rightarrow \infty } {\scriptstyle \frac{A_d(n+1)}{A_d(n)}}$$ . We revisit and extend the method for the best known upper bound on $$A_2(n)$$ . Our contributions include the following.},
  archive      = {J_Alg},
  author       = {Barequet, Gill and Shalah, Mira},
  doi          = {10.1007/s00453-022-00948-6},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3559-3586},
  shortjournal = {Algorithmica},
  title        = {Improved upper bounds on the growth constants of polyominoes and polycubes},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A 2-approximation for the k-prize-collecting steiner tree
problem. <em>Alg</em>, <em>84</em>(12), 3522–3558. (<a
href="https://doi.org/10.1007/s00453-021-00919-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the $$k$$ -Prize-Collecting Steiner Tree Problem. An instance is composed of an integer k and a graph G with costs on edges and penalties on vertices. The objective is to find a tree spanning at least k vertices which minimizes the cost of the edges in the tree plus the penalties of vertices not in the tree. This is one of the most fundamental network design problems and is a common generalization of the Prize-Collecting Steiner Tree Problem and the $$k$$ -Minimum Spanning Tree Problem. Our main result is a 2-approximation algorithm, which improves on the currently best known approximation factor of 3.96 and has a faster running time. The algorithm builds on a modification of the primal-dual framework of Goemans and Williamson, and reveals interesting properties that can be applied to other similar problems.},
  archive      = {J_Alg},
  author       = {Pedrosa, Lehilton Lelis Chaves and Rosado, Hugo Kooki Kasuya},
  doi          = {10.1007/s00453-021-00919-3},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3522-3558},
  shortjournal = {Algorithmica},
  title        = {A 2-approximation for the k-prize-collecting steiner tree problem},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editor’s note: Special issue dedicated to the 14th latin
american theoretical informatics symposium. <em>Alg</em>,
<em>84</em>(12), 3521. (<a
href="https://doi.org/10.1007/s00453-022-01056-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  doi          = {10.1007/s00453-022-01056-1},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3521},
  shortjournal = {Algorithmica},
  title        = {Editor’s note: Special issue dedicated to the 14th latin american theoretical informatics symposium},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Maximum matching in almost linear time on graphs of bounded
clique-width. <em>Alg</em>, <em>84</em>(11), 3489–3520. (<a
href="https://doi.org/10.1007/s00453-022-00999-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, independent groups of researchers have presented algorithms to compute a maximum matching in $$\tilde{\mathcal{O}}(f(k) \cdot (n+m))$$ time, for some computable function f, within the graphs where some clique-width upper bound is at most k (e.g., tree-width, modular-width and $$P_4$$ -sparseness). However, to the best of our knowledge, the existence of such algorithm within the graphs of bounded clique-width has remained open until this paper. Indeed, we cannot even apply Courcelle’s theorem to this problem directly, because a matching cannot be expressed in $$MSO_1$$ logic. Our first contribution is an almost linear-time algorithm to compute a maximum matching in any bounded clique-width graph, being given a corresponding clique-width expression. We also present how to compute the Edmonds-Gallai decomposition in almost linear time by using the same framework. For that, we do apply Courcelle’s theorem but to the classic Tutte-Berge formula, that can easily be expressed as a $$CMSO_1$$ optimization problem. Doing so, we can compute the cardinality of a maximum matching, but not the matching itself. To obtain with this approach a maximum matching, we need to combine it with a recursive dissection scheme for bounded clique-width graphs and with a distributed version of Courcelle’s theorem (Courcelle and Vanicat, DAM 2016) – of which we present here a slightly stronger version than the standard one in the literature. Finally, for the bipartite graphs of clique-width at most k, we present an alternative $$\tilde{\mathcal{O}}(k^2\cdot (n+m))$$ -time algorithm for the problem. The algorithm is randomized and it is based on a completely different approach than above: combining various reductions to matching and flow problems on bounded tree-width graphs with a very recent result on the parameterized complexity of linear programming (Dong et. al., STOC’21). Our results for bounded clique-width graphs extend many prior works on the complexity of Maximum Matching within cographs, distance-hereditary graphs, series-parallel graphs and other subclasses.},
  archive      = {J_Alg},
  author       = {Ducoffe, Guillaume},
  doi          = {10.1007/s00453-022-00999-9},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3489-3520},
  shortjournal = {Algorithmica},
  title        = {Maximum matching in almost linear time on graphs of bounded clique-width},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic kernels for hitting sets and set packing.
<em>Alg</em>, <em>84</em>(11), 3459–3488. (<a
href="https://doi.org/10.1007/s00453-022-00986-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing small kernels for the hitting set problem is a well-studied computational problem where we are given a hypergraph with n vertices and m hyperedges, each of size d for some small constant d, and a parameter k. The task is to compute a new hypergraph, called a kernel, whose size is polynomial with respect to the parameter k and which has a size-k hitting set if, and only if, the original hypergraph has one. State-of-the-art algorithms compute kernels of size $$k^d$$ (which is a polynomial as d is a constant), and they do so in time $$m\cdot 2^d {\text {poly}}(d)$$ for a small polynomial $${\text {poly}}(d)$$ (which is linear in the hypergraph size for d fixed). We generalize this task to the dynamic setting where hyperedges may continuously be added or deleted and one constantly has to keep track of a size- $$k^d$$ kernel. This paper presents a deterministic solution with worst-case time $$3^d {\text {poly}}(d)$$ for updating the kernel upon inserts and time $$5^d {\text {poly}}(d)$$ for updates upon deletions. These bounds nearly match the time $$2^d {\text {poly}}(d)$$ needed by the best static algorithm per hyperedge. Let us stress that for constant d our algorithm maintains a hitting set kernel with constant, deterministic, worst-case update time that is independent of n, m, and the parameter k. As a consequence, we also get a deterministic dynamic algorithm for keeping track of size-k hitting sets in d-hypergraphs with update times O(1) and query times $$O(c^k)$$ where $$c = d - 1 + O(1/d)$$ equals the best base known for the static setting.},
  archive      = {J_Alg},
  author       = {Bannach, Max and Heinrich, Zacharias and Reischuk, Rüdiger and Tantau, Till},
  doi          = {10.1007/s00453-022-00986-0},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3459-3488},
  shortjournal = {Algorithmica},
  title        = {Dynamic kernels for hitting sets and set packing},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Preprocessing for outerplanar vertex deletion: An elementary
kernel of quartic size. <em>Alg</em>, <em>84</em>(11), 3407–3458. (<a
href="https://doi.org/10.1007/s00453-022-00984-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the $${\varvec{\mathcal {F}}}$$ -Minor-Free Deletion problem one is given an undirected graph $${\varvec{G}}$$ , an integer $${\varvec{k}}$$ , and the task is to determine whether there exists a vertex set $${\varvec{S}}$$ of size at most $${\varvec{k}}$$ , so that $${\varvec{G}}-{\varvec{S}}$$ contains no graph from the finite family $${\varvec{\mathcal {F}}}$$ as a minor. It is known that whenever $${\varvec{\mathcal {F}}}$$ contains at least one planar graph, then $${\varvec{\mathcal {F}}}$$ -Minor-Free Deletion admits a polynomial kernel, that is, there is a polynomial-time algorithm that outputs an equivalent instance of size $${\varvec{k}}^{{\varvec{\mathcal {O}}}{} {\textbf {(1)}}}$$ [Fomin, Lokshtanov, Misra, Saurabh; FOCS 2012]. However, this result relies on non-constructive arguments based on well-quasi-ordering and does not provide a concrete bound on the kernel size. We study the Outerplanar Deletion problem, in which we want to remove at most $${\varvec{k}}$$ vertices from a graph to make it outerplanar. This is a special case of $${\varvec{\mathcal {F}}}$$ -Minor-Free Deletion for the family $${\varvec{\mathcal {F}}} = {{\varvec{K}}_{{\textbf {4}}}, {\varvec{K}}_{{{\textbf {2,3}}}}}$$ . The class of outerplanar graphs is arguably the simplest class of graphs for which no explicit kernelization size bounds are known. By exploiting the combinatorial properties of outerplanar graphs we present elementary reduction rules decreasing the size of a graph. This yields a constructive kernel with $${\varvec{\mathcal {O}}}({\varvec{k}}^{\textbf {4}})$$ vertices and edges. As a corollary, we derive that any minor-minimal obstruction to having an outerplanar deletion set of size $${\varvec{k}}$$ has $${\varvec{\mathcal {O}}}({\varvec{k}}^{\textbf {4}})$$ vertices and edges.},
  archive      = {J_Alg},
  author       = {Donkers, Huib and Jansen, Bart M. P. and Włodarczyk, Michał},
  doi          = {10.1007/s00453-022-00984-2},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3407-3458},
  shortjournal = {Algorithmica},
  title        = {Preprocessing for outerplanar vertex deletion: An elementary kernel of quartic size},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Introducing lop-kernels: A framework for kernelization lower
bounds. <em>Alg</em>, <em>84</em>(11), 3365–3406. (<a
href="https://doi.org/10.1007/s00453-022-00979-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Maximum Minimal Vertex Cover (MMVC) problem, we are given a graph G and a positive integer k, and the objective is to decide whether G contains a minimal vertex cover of size at least k. Motivated by the kernelization of MMVC with parameter k, our main contribution is to introduce a simple general framework to obtain kernelization lower bounds for a certain type of kernels for optimization problems, which we call lop -kernels. Informally, this type of kernel is required to preserve large optimal solutions in the reduced instance, and captures the vast majority of existing kernels in the literature. As a consequence of this framework, we show that the trivial quadratic kernel for MMVC is essentially optimal, answering a question of Boria et al. Discrete Appl Math 196:62–71, 2015. https://doi.org/10.1016/j.dam.2014.06.001 ), and that the known cubic kernel for Maximum Minimal Feedback Vertex Set is also essentially optimal. We present further applications for Tree Deletion Set and for Maximum Independent Set on $$K_t$$ -free graphs. Back to the MMVC problem, given the (plausible) non-existence of subquadratic kernels for MMVC on general graphs, we provide subquadratic kernels on H-free graphs for several graphs H, such as the bull, the paw, or the complete graphs, by making use of the Erdős–Hajnal property. Finally, we prove that MMVC does not admit polynomial kernels parameterized by the size of a minimum vertex cover of the input graph, even on bipartite graphs, unless $$\mathsf{NP} \subseteq \mathsf{coNP} / \mathsf{poly}$$ .},
  archive      = {J_Alg},
  author       = {Araújo, Júlio and Bougeret, Marin and Campos, Victor and Sau, Ignasi},
  doi          = {10.1007/s00453-022-00979-z},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3365-3406},
  shortjournal = {Algorithmica},
  title        = {Introducing lop-kernels: A framework for kernelization lower bounds},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). (Sub)linear kernels for edge modification problems toward
structured graph classes. <em>Alg</em>, <em>84</em>(11), 3338–3364. (<a
href="https://doi.org/10.1007/s00453-022-00969-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a (parameterized) graph edge modification problem, we are given a graph G, an integer k and a (usually well-structured) class $$\mathcal {G}$$ of graphs, and asked whether it is possible to transform G into a graph $$G&#39; \in \mathcal {G}$$ by adding and/or removing at most k edges. Parameterized graph edge modification problems received considerable attention in the last decades. In this paper, we focus on finding small kernels for edge modification problems. One of the most studied problems is the Cluster Editing problem, in which the goal is to partition the vertex set into a disjoint union of cliques. Even if a 2k-vertex kernel exists for Cluster Editing, this kernel does not reduce the size of the instance in most cases. Therefore, we explore the question of whether linear kernels are a theoretical limit in edge modification problems, in particular when the target graph class is very structured (such as a partition into cliques for instance). We prove, as far as we know, the first sublinear kernel for an edge modification problem. Namely, we show that Clique + Independent Set Deletion, which is a restriction of Cluster Deletion, admits a kernel of size $$O(k/\log k)$$ . We also obtain small kernels for several other edge modification problems. We first show that Cluster Deletion admits a 2k-vertex kernel as Cluster Editing, improving the previous 4k-vertex kernel. We prove that (Pseudo-)Split Completion (and the equivalent (Pseudo-)Split Deletion) admits a linear kernel, improving the existing quadratic kernel. We also prove that Trivially Perfect Completion admits a quadratic kernel (improving the cubic kernel), and finally prove that its triangle-free version (Starforest Deletion) admits a linear kernel, which is optimal under the Exponential Time Hypothesis.},
  archive      = {J_Alg},
  author       = {Bathie, Gabriel and Bousquet, Nicolas and Cao, Yixin and Ke, Yuping and Pierron, Théo},
  doi          = {10.1007/s00453-022-00969-1},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3338-3364},
  shortjournal = {Algorithmica},
  title        = {(Sub)linear kernels for edge modification problems toward structured graph classes},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Twin-width and polynomial kernels. <em>Alg</em>,
<em>84</em>(11), 3300–3337. (<a
href="https://doi.org/10.1007/s00453-022-00965-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the existence of polynomial kernels, for parameterized problems without a polynomial kernel on general graphs, when restricted to graphs of bounded twin-width. Our main result is that a polynomial kernel for k -Dominating Set on graphs of twin-width at most 4 would contradict a standard complexity-theoretic assumption. The reduction is quite involved, especially to get the twin-width upper bound down to 4, and can be tweaked to work for Connected k -Dominating Set and Total k -Dominating Set (albeit with a worse upper bound on the twin-width). The k -Independent Set problem admits the same lower bound by a much simpler argument, previously observed [ICALP ’21], which extends to k -Independent Dominating Set, k -Path, k -Induced Path, k -Induced Matching, etc. On the positive side, we obtain a simple quadratic vertex kernel for Connected k -Vertex Cover and Capacitated k -Vertex Cover on graphs of bounded twin-width. Interestingly the kernel applies to graphs of Vapnik–Chervonenkis density 1, and does not require a witness sequence. We also present a more intricate $$O(k^{1.5})$$ vertex kernel for Connected k -Vertex Cover. Finally we show that deciding if a graph has twin-width at most 1 can be done in polynomial time, and observe that most optimization/decision graph problems can be solved in polynomial time on graphs of twin-width at most 1.},
  archive      = {J_Alg},
  author       = {Bonnet, Édouard and Kim, Eun Jung and Reinald, Amadeus and Thomassé, Stéphan and Watrigant, Rémi},
  doi          = {10.1007/s00453-022-00965-5},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3300-3337},
  shortjournal = {Algorithmica},
  title        = {Twin-width and polynomial kernels},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CNF satisfiability in a subspace and related problems.
<em>Alg</em>, <em>84</em>(11), 3276–3299. (<a
href="https://doi.org/10.1007/s00453-022-00958-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the problem of finding a satisfying assignment to a CNF formula that must further belong to a prescribed input subspace. Equivalent formulations of the problem include finding a point outside a union of subspaces (the Union-of-Subspace Avoidance (USA) problem), and finding a common zero of a system of polynomials over $${\mathbb {F}}_2$$ each of which is a product of affine forms. We focus on the case of k-CNF formulas (the $${k}-\textsc {Sub}-\textsc {Sat}$$ problem). Clearly, $${k}-\textsc {Sub}-\textsc {Sat}$$ is no easier than k-SAT, and might be harder. Indeed, via simple reductions we show that $${2}-\textsc {Sub}-\textsc {Sat}$$ is NP-hard, and $${\small \mathrm {W}}[1]$$ -hard when parameterized by the co-dimension of the subspace. We also prove that the optimization version Max- $${2}-\textsc {Sub}-\textsc {Sat}$$ is NP-hard to approximate better than the trivial 3/4 ratio even on satisfiable instances. On the algorithmic front, we investigate fast exponential algorithms which give non-trivial savings over brute-force algorithms. We give a simple branching algorithm with running time $$O^*(1.5)^r$$ for $${2}-\textsc {Sub}-\textsc {Sat}$$ , where r is the subspace dimension, as well as an $$O^*(1.4312)^n$$ time algorithm where n is the number of variables. Turning to $${k}-\textsc {Sub}-\textsc {Sat}$$ for $$k \geqslant 3$$ , while known algorithms for solving a system of degree k polynomial equations already imply a solution with running time $$\approx 2^{r(1-1/2k)}$$ , we explore a more combinatorial approach. Based on an analysis of critical variables (a key notion underlying the randomized k-SAT algorithm of Paturi, Pudlak, and Zane), we give an algorithm with running time $$\approx {n\atopwithdelims (){\leqslant t}} 2^{n-n/k}$$ where n is the number of variables and t is the co-dimension of the subspace. This improves upon the running time of the polynomial equations approach for small co-dimension. Our combinatorial approach also achieves polynomial space in contrast to the algebraic approach that uses exponential space. We also give a PPZ-style algorithm for $${k}-\textsc {Sub}-\textsc {Sat}$$ with running time $$\approx 2^{n-n/2k}$$ . This algorithm is in fact oblivious to the structure of the subspace, and extends when the subspace-membership constraint is replaced by any constraint for which partial satisfying assignments can be efficiently completed to a full satisfying assignment. Finally, for systems of O(n) polynomial equations in n variables over $${\mathbb {F}}_2$$ , we give a fast exponential algorithm when each polynomial has bounded degree irreducible factors (but can otherwise have large degree) using a degree reduction trick.},
  archive      = {J_Alg},
  author       = {Arvind, V. and Guruswami, Venkatesan},
  doi          = {10.1007/s00453-022-00958-4},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3276-3299},
  shortjournal = {Algorithmica},
  title        = {CNF satisfiability in a subspace and related problems},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A polynomial kernel for bipartite permutation vertex
deletion. <em>Alg</em>, <em>84</em>(11), 3246–3275. (<a
href="https://doi.org/10.1007/s00453-022-01040-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a permutation graph, vertices represent the elements of a permutation, and edges represent pairs of elements that are reversed by the permutation. In the Permutation Vertex Deletion problem, given an undirected graph G and an integer k, the objective is to test whether there exists a vertex subset $$S\subseteq V(G)$$ such that $$|S| \le k$$ and $$G-S$$ is a permutation graph. The parameterized complexity of Permutation Vertex Deletion is a well-known open problem. Bożyk et al. [IPEC 2020] initiated a study on this problem by requiring that $$G-S$$ be a bipartite permutation graph (a permutation graph that is bipartite). They called this the Bipartite Permutation Vertex Deletion (BPVD) problem. They showed that the problem admits a factor 9-approximation algorithm as well as a fixed parameter tractable (FPT) algorithm running in time $${\mathcal {O}}(9^k |V(G)|^{9})$$ . Moreover, they posed the question whether BPVD admits a polynomial kernel. We resolve this question in the affirmative by designing a polynomial kernel for BPVD. In particular, we obtain the following: Given an instance (G, k) of BPVD, in polynomial time we obtain an equivalent instance $$(G&#39;,k&#39;)$$ of BPVD such that $$k&#39;\le k$$ , and $$|V(G&#39;)|+|E(G&#39;)|\le k^{\mathcal {O}(1)}$$ .},
  archive      = {J_Alg},
  author       = {Derbisz, Jan and Kanesh, Lawqueen and Madathil, Jayakrishnan and Sahu, Abhishek and Saurabh, Saket and Verma, Shaily},
  doi          = {10.1007/s00453-022-01040-9},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3246-3275},
  shortjournal = {Algorithmica},
  title        = {A polynomial kernel for bipartite permutation vertex deletion},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic data structures for timed automata acceptance.
<em>Alg</em>, <em>84</em>(11), 3223–3245. (<a
href="https://doi.org/10.1007/s00453-022-01025-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a variant of the classical membership problem in automata theory, which consists of deciding whether a given input word is accepted by a given automaton. We do so through the lenses of parameterized dynamic data structures: we assume that the automaton is fixed and its size is the parameter, while the input word is revealed as in a stream, one symbol at a time following the natural order on positions. The goal is to design a dynamic data structure that can be efficiently updated upon revealing the next symbol, while maintaining the answer to the query on whether the word consisting of symbols revealed so far is accepted by the automaton. We provide complexity bounds for this dynamic acceptance problem for timed automata that process symbols interleaved with time spans. The main contribution is a dynamic data structure that maintains acceptance of a fixed one-clock timed automaton $${\mathcal {A}}$$ with amortized update time $$2^{{\mathcal {O}}(|{\mathcal {A}}|)}$$ per input symbol.},
  archive      = {J_Alg},
  author       = {Grez, Alejandro and Mazowiecki, Filip and Pilipczuk, Michał and Puppis, Gabriele and Riveros, Cristian},
  doi          = {10.1007/s00453-022-01025-8},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3223-3245},
  shortjournal = {Algorithmica},
  title        = {Dynamic data structures for timed automata acceptance},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Optimal centrality computations within bounded clique-width
graphs. <em>Alg</em>, <em>84</em>(11), 3192–3222. (<a
href="https://doi.org/10.1007/s00453-022-01015-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an n-vertex m-edge graph G of clique-width at most k, and a corresponding k-expression, we present algorithms for computing some well-known centrality indices (eccentricity and closeness) that run in $${\mathcal {O}}(2^{{\mathcal {O}}(k)}(n+m)^{1+\epsilon })$$ time for any $$\epsilon &gt; 0$$ . Doing so, we can solve various distance problems within the same amount of time, including: the diameter, the center, the Wiener index and the median set. Our run-times match conditional lower bounds of Coudert et al. (SODA’18) under the Strong Exponential-Time Hypothesis. On our way, we get a distance-labeling scheme for n-vertex m-edge graphs of clique-width at most k, using $${\mathcal {O}}(k\log ^2{n})$$ bits per vertex and constructible in $$\tilde{\mathcal {O}}(k(n+m))$$ time from a given k-expression. Doing so, we match the label size obtained by Courcelle and Vanicat (DAM 2016), while we considerably improve the dependency on k in their scheme. As a corollary, we get an $$\tilde{\mathcal {O}}(kn^2)$$ -time algorithm for computing All-Pairs Shortest-Paths on n-vertex graphs of clique-width at most k, being given a k-expression. This partially answers an open question of Kratsch and Nelles (STACS’20). Our algorithms work for graphs with non-negative vertex-weights, under two different types of distances studied in the literature. For that, we introduce a new type of orthogonal range query as a side contribution of this work, that might be of independent interest.},
  archive      = {J_Alg},
  author       = {Ducoffe, Guillaume},
  doi          = {10.1007/s00453-022-01015-w},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3192-3222},
  shortjournal = {Algorithmica},
  title        = {Optimal centrality computations within bounded clique-width graphs},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The fine-grained complexity of multi-dimensional ordering
properties. <em>Alg</em>, <em>84</em>(11), 3156–3191. (<a
href="https://doi.org/10.1007/s00453-022-01014-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We define a class of problems whose input is an n-sized set of d-dimensional vectors, and where the problem is first-order definable using comparisons between coordinates. This class captures a wide variety of tasks, such as complex types of orthogonal range search, model-checking first-order properties on geometric intersection graphs, and elementary questions on multidimensional data like verifying Pareto optimality of a choice of data points. Focusing on constant dimension d, we show that any such k-quantifier, d-dimensional problem is solvable in $$O(n^{k-1} \log ^{d-1} n)$$ time. Furthermore, this algorithm is conditionally tight up to subpolynomial factors: we show that assuming the 3-uniform hyperclique hypothesis, there is a k-quantifier, $$(3k-3)$$ -dimensional problem in this class that requires time $$\Omega (n^{k-1-o(1)})$$ . Towards identifying a single representative problem for this class, we study the existence of complete problems for the 3-quantifier setting (since 2-quantifier problems can already be solved in near-linear time $$O(n\log ^{d-1} n)$$ , and k-quantifier problems with $$k&gt;3$$ reduce to the 3-quantifier case). We define a problem Vector Concatenated Non-Domination $$\mathsf {VCND}_d$$ (Given three sets of vectors X, Y and Z of dimension d, d and 2d, respectively, is there an $$x \in X$$ and a $$y \in Y$$ so that their concatenation $$x \circ y$$ is not dominated by any $$z \in Z$$ , where vector u is dominated by vector v if $$u_i \le v_i$$ for each coordinate $$1 \le i \le d$$ ), and determine it as the “unique” candidate to be complete for this class (under fine-grained assumptions).},
  archive      = {J_Alg},
  author       = {An, Haozhe and Gurumukhani, Mohit and Impagliazzo, Russell and Jaber, Michael and Künnemann, Marvin and Parga Nina, Maria Paula},
  doi          = {10.1007/s00453-022-01014-x},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3156-3191},
  shortjournal = {Algorithmica},
  title        = {The fine-grained complexity of multi-dimensional ordering properties},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hardness of metric dimension in graphs of constant
treewidth. <em>Alg</em>, <em>84</em>(11), 3110–3155. (<a
href="https://doi.org/10.1007/s00453-022-01005-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Metric Dimension problem asks for a minimum-sized resolving set in a given (unweighted, undirected) graph G. Here, a set $$S \subseteq V(G)$$ is resolving if no two distinct vertices of G have the same distance vector to S. The complexity of Metric Dimension in graphs of bounded treewidth remained elusive in the past years. Recently, Bonnet and Purohit [IPEC 2019] showed that the problem is W[1]-hard under treewidth parameterization. In this work, we strengthen their lower bound to show that Metric Dimension is NP-hard in graphs of treewidth $$24$$ .},
  archive      = {J_Alg},
  author       = {Li, Shaohua and Pilipczuk, Marcin},
  doi          = {10.1007/s00453-022-01005-y},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3110-3155},
  shortjournal = {Algorithmica},
  title        = {Hardness of metric dimension in graphs of constant treewidth},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue dedicated to the 16th international symposium
on parameterized and exact computation. <em>Alg</em>, <em>84</em>(11),
3107–3109. (<a
href="https://doi.org/10.1007/s00453-022-01042-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  author       = {Golovach, Petr A. and Zehavi, Meirav},
  doi          = {10.1007/s00453-022-01042-7},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3107-3109},
  shortjournal = {Algorithmica},
  title        = {Special issue dedicated to the 16th international symposium on parameterized and exact computation},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Selected papers of the 31st international workshop on
combinatorial algorithms, IWOCA 2020. <em>Alg</em>, <em>84</em>(10),
3103–3106. (<a
href="https://doi.org/10.1007/s00453-022-01029-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  author       = {Gąsieniec, Leszek and Klasing, Ralf and Radzik, Tomasz},
  doi          = {10.1007/s00453-022-01029-4},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3103-3106},
  shortjournal = {Algorithmica},
  title        = {Selected papers of the 31st international workshop on combinatorial algorithms, IWOCA 2020},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Guess free maximization of submodular and
linear sums. <em>Alg</em>, <em>84</em>(10), 3101–3102. (<a
href="https://doi.org/10.1007/s00453-022-01028-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Correction to this paper has been published: 10.1007/s00453-020-00757-9},
  archive      = {J_Alg},
  author       = {Feldman, Moran},
  doi          = {10.1007/s00453-022-01028-5},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3101-3102},
  shortjournal = {Algorithmica},
  title        = {Correction to: Guess free maximization of submodular and linear sums},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parameterized complexity of maximum edge colorable subgraph.
<em>Alg</em>, <em>84</em>(10), 3075–3100. (<a
href="https://doi.org/10.1007/s00453-022-01003-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A graph H is p-edge colorable if there is a coloring $$\psi : E(H) \rightarrow {1,2,\dots ,p}$$ , such that for distinct $$uv, vw \in E(H)$$ , we have $$\psi (uv) \ne \psi (vw)$$ . The Maximum Edge-Colorable Subgraph problem takes as input a graph G and integers l and p, and the objective is to find a subgraph H of G and a p-edge-coloring of H, such that $$|E(H)| \ge l$$ . We study the above problem from the viewpoint of Parameterized Complexity. We obtain FPT algorithms when parameterized by: (1) the vertex cover number of G, by using Integer Linear Programming, and (2) l, a randomized algorithm via a reduction to Rainbow Matching, and a deterministic algorithm by using color coding, and divide and color. With respect to the parameters $$p+k$$ , where k is one of the following: (1) the solution size, l, (2) the vertex cover number of G, and (3) $$l - {\texttt {mm}}(G)$$ , where $${\texttt {mm}}(G)$$ is the size of a maximum matching in G; we show that the (decision version of the) problem admits a kernel with $${\mathcal {O}}(k \cdot p)$$ vertices. Furthermore, we show that there is no kernel of size $${\mathcal {O}}(k^{1-\epsilon } \cdot f(p))$$ , for any $$\epsilon &gt; 0$$ and computable function f, unless $${\textsf {NP}}\subseteq \textsf {coNP/poly}$$ .},
  archive      = {J_Alg},
  author       = {Agrawal, Akanksha and Kundu, Madhumita and Sahu, Abhishek and Saurabh, Saket and Tale, Prafullkumar},
  doi          = {10.1007/s00453-022-01003-0},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3075-3100},
  shortjournal = {Algorithmica},
  title        = {Parameterized complexity of maximum edge colorable subgraph},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Algorithms for the unit-cost stochastic score classification
problem. <em>Alg</em>, <em>84</em>(10), 3054–3074. (<a
href="https://doi.org/10.1007/s00453-022-00982-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the following Stochastic Score Classification problem. A doctor is assessing a patient’s risk of developing a disease and can perform n different binary tests on the patient. The probability that test i is positive is $$p_i$$ and the outcomes of the n tests are independent. A patient’s score is the total number of positive tests. Possible scores thus range between 0 and n. This range is divided into subranges, corresponding to risk classes (e.g., LOW, MEDIUM, or HIGH risk). Each test has an associated cost. To reduce testing cost, instead of performing all tests and determining an exact score, the doctor can perform tests sequentially and stop testing when it is possible to determine the patient’s risk class. The problem is to determine the order in which the doctor should perform the tests, so as to minimize expected testing cost. We address the unit-cost case of the Stochastic Score Classification problem, and provide polynomial-time approximation algorithms for adaptive and non-adaptive versions of the problem. We also pose a number of open questions.},
  archive      = {J_Alg},
  author       = {Grammel, Nathaniel and Hellerstein, Lisa and Kletenik, Devorah and Liu, Naifeng},
  doi          = {10.1007/s00453-022-00982-4},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3054-3074},
  shortjournal = {Algorithmica},
  title        = {Algorithms for the unit-cost stochastic score classification problem},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Small candidate set for translational pattern search.
<em>Alg</em>, <em>84</em>(10), 3034–3053. (<a
href="https://doi.org/10.1007/s00453-022-00997-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the following pattern search problem: Given a pair of point sets A and B in fixed dimensional space $$\mathbb {R}^d$$ , with $$|B| = n,|A| = m$$ and $$n \ge m$$ , the pattern search problem is to find the translations $$\mathcal {T}$$ ’s of A such that each of the identified translations induces a matching between $$\mathcal {T}(A)$$ and a subset $$B&#39;$$ of B with cost no more than some given threshold, where the cost is defined as the minimum bipartite matching cost of $$\mathcal {T}(A)$$ and $$B&#39;$$ . We present a novel algorithm to produce a small set of candidate translations for the pattern search problem. For any $$B&#39; \subseteq B$$ with $$|B&#39;| = |A|$$ , there exists at least one translation $$\mathcal {T}$$ in the candidate set such that the minimum bipartite matching cost between $$\mathcal {T}(A)$$ and $$B&#39;$$ is no larger than $$(1+\epsilon )$$ times the minimum bipartite matching cost between A and $$B&#39;$$ under any translation (i.e., the optimal translational matching cost). We also show that there exists an alternative solution to this problem, which constructs a candidate set of size $$O_{d,\epsilon }(n \log ^2 n)$$ in $$O_{d,\epsilon }(n \log ^2 n)$$ time with high probability of success. As a by-product of our construction, we obtain a weak $$\epsilon $$ -net for hypercube ranges, which significantly improves the construction time and the size of the candidate set. Our technique can be applied to a number of applications, including the translational pattern matching problem.},
  archive      = {J_Alg},
  author       = {Huang, Ziyun and Feng, Qilong and Wang, Jianxin and Xu, Jinhui},
  doi          = {10.1007/s00453-022-00997-x},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3034-3053},
  shortjournal = {Algorithmica},
  title        = {Small candidate set for translational pattern search},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving string problems on graphs using the labeled direct
product. <em>Alg</em>, <em>84</em>(10), 3008–3033. (<a
href="https://doi.org/10.1007/s00453-022-00989-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suffix trees are an important data structure at the core of optimal solutions to many fundamental string problems, such as exact pattern matching, longest common substring, matching statistics, and longest repeated substring. Recent lines of research focused on extending some of these problems to vertex-labeled graphs, either by using efficient ad-hoc approaches which do not generalize to all input graphs, or by indexing difficult graphs and having worst-case exponential complexities. In the absence of an ubiquitous and polynomial tool like the suffix tree for labeled graphs, we introduce the labeled direct product of two graphs as a general tool for obtaining optimal algorithms in the worst case: we obtain conceptually simpler algorithms for the quadratic problems of string matching (SMLG) and longest common substring (LCSP) in labeled graphs. Our algorithms run in time linear in the size of the labeled product graph, which may be smaller than quadratic for some inputs, and their run-time is predictable, because the size of the labeled direct product graph can be precomputed efficiently. We also solve LCSP on graphs containing cycles, which was left as an open problem by Shimohira et al. in 2011. To show the power of the labeled product graph, we also apply it to solve the matching statistics (MSP) and the longest repeated string (LRSP) problems in labeled graphs. Moreover, we show that our (worst-case quadratic) algorithms are also optimal, conditioned on the Orthogonal Vectors Hypothesis. Finally, we complete the complexity picture around LRSP by studying it on undirected graphs.},
  archive      = {J_Alg},
  author       = {Rizzo, Nicola and Tomescu, Alexandru I. and Policriti, Alberto},
  doi          = {10.1007/s00453-022-00989-x},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3008-3033},
  shortjournal = {Algorithmica},
  title        = {Solving string problems on graphs using the labeled direct product},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Light spanners for high dimensional norms via stochastic
decompositions. <em>Alg</em>, <em>84</em>(10), 2987–3007. (<a
href="https://doi.org/10.1007/s00453-022-00994-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spanners for low dimensional spaces (e.g. Euclidean space of constant dimension, or doubling metrics) are well understood. This lies in contrast to the situation in high dimensional spaces, where except for the work of Har–Peled, Indyk and Sidiropoulos (SODA 2013), who showed that any n-point Euclidean metric has an O(t)-spanner with $$\tilde{O}(n^{1+1/t^2})$$ edges, little is known. In this paper we study several aspects of spanners in high dimensional normed spaces. First, we build spanners for finite subsets of $$\ell _p$$ with $$1&lt;p\le 2$$ . Second, our construction yields a spanner which is both sparse and also light, i.e., its total weight is not much larger than that of the minimum spanning tree. In particular, we show that any n-point subset of $$\ell _p$$ for $$1&lt;p\le 2$$ has an O(t)-spanner with $$n^{1+\tilde{O}(1/t^p)}$$ edges and lightness $$n^{\tilde{O}(1/t^p)}$$ . In fact, our results are more general, and they apply to any metric space admitting a certain low diameter stochastic decomposition. It is known that arbitrary metric spaces have an O(t)-spanner with lightness $$O(n^{1/t})$$ . We exhibit the following tradeoff: metrics with decomposability parameter $$\nu =\nu (t)$$ admit an O(t)-spanner with lightness $$\tilde{O}(\nu ^{1/t})$$ . For example, metrics with doubling constant $$\lambda $$ , graphs of genus g, and graphs of treewidth k, all have spanners with stretch O(t) and lightness $$\tilde{O}(\lambda ^{1/t})$$ , $$\tilde{O}(g^{1/t})$$ , $$\tilde{O}(k^{1/t})$$ respectively. While these families do admit a ( $$1+\epsilon $$ )-spanner, its lightness depend exponentially on the dimension (resp. $$\log g$$ , k). Our construction alleviates this exponential dependency, at the cost of incurring larger stretch.},
  archive      = {J_Alg},
  author       = {Filtser, Arnold and Neiman, Ofer},
  doi          = {10.1007/s00453-022-00994-0},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {2987-3007},
  shortjournal = {Algorithmica},
  title        = {Light spanners for high dimensional norms via stochastic decompositions},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Connected reconfiguration of lattice-based cellular
structures by finite-memory robots. <em>Alg</em>, <em>84</em>(10),
2954–2986. (<a
href="https://doi.org/10.1007/s00453-022-00995-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide algorithmic methods for connected reconfiguration of lattice-based cellular structures by finite-state robots, motivated by large-scale constructions in space. We present algorithms that are able to detect and reconfigure arbitrary polyominoes, while also preserving connectivity of a structure during reconfiguration; we also provide mathematical proofs and performance guarantees. Specific results include methods for determining a bounding box, scaling a given arrangement, and adapting more general algorithms for transforming polyominoes.},
  archive      = {J_Alg},
  author       = {Fekete, Sándor P. and Niehs, Eike and Scheffer, Christian and Schmidt, Arne},
  doi          = {10.1007/s00453-022-00995-z},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {2954-2986},
  shortjournal = {Algorithmica},
  title        = {Connected reconfiguration of lattice-based cellular structures by finite-memory robots},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Almost-smooth histograms and sliding-window graph
algorithms. <em>Alg</em>, <em>84</em>(10), 2926–2953. (<a
href="https://doi.org/10.1007/s00453-022-00988-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study algorithms for the sliding-window model, an important variant of the data-stream model, in which the goal is to compute some function of a fixed-length suffix of the stream. We extend the smooth-histogram framework of Braverman and Ostrovsky (FOCS 2007) to almost-smooth functions, which includes all subadditive functions. Specifically, we show that if a subadditive function can be $$\left( 1+{{\varepsilon }}\right) $$ -approximated in the insertion-only streaming model, then it can be $$\left( 2+{{\varepsilon }}\right) $$ -approximated also in the sliding-window model with space complexity larger by factor $$O{\negmedspace }\left( {{\varepsilon }}^{-1}\log w\right) $$ , where w is the window size. We demonstrate how our framework yields new approximation algorithms with relatively little effort for a variety of problems that do not admit the smooth-histogram technique. For example, in the frequency-vector model, a symmetric norm is subadditive and thus we obtain a sliding-window $$\left( 2+{{\varepsilon }}\right) $$ -approximation algorithm for it. Another example is for streaming matrices, where we derive a new sliding-window $$\left( \sqrt{2}+{{\varepsilon }}\right) $$ -approximation algorithm for Schatten 4-norm. We then consider graph streams and show that many graph problems are subadditive, including maximum submodular matching, minimum vertex-cover, and maximum k-cover, thereby deriving sliding-window $$O{\negmedspace }\left( 1\right) $$ -approximation algorithms for them almost for free (using known insertion-only algorithms). Finally, we design for every $$d\in \left( 1,2\right] $$ an artificial function, based on the maximum-matching size, whose almost-smoothness parameter is exactly d.},
  archive      = {J_Alg},
  author       = {Krauthgamer, Robert and Reitblat, David},
  doi          = {10.1007/s00453-022-00988-y},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {2926-2953},
  shortjournal = {Algorithmica},
  title        = {Almost-smooth histograms and sliding-window graph algorithms},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Facility reallocation on the line. <em>Alg</em>,
<em>84</em>(10), 2898–2925. (<a
href="https://doi.org/10.1007/s00453-022-00993-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a multi-stage facility reallocation problems on the real line, where a facility is being moved between time stages based on the locations reported by n agents. The aim of the reallocation algorithm is to minimise the social cost, i.e., the sum over the total distance between the facility and all agents at all stages, plus the cost incurred for moving the facility. We study this problem both in the offline setting and online setting. In the offline case the algorithm has full knowledge of the agent locations in all future stages, and in the online setting the algorithm does not know these future locations and must decide the location of the facility on a stage-per-stage basis. We derive the optimal algorithm in both cases. For the online setting we show that its competitive ratio is $$(n+2)/(n+1)$$ . As neither of these algorithms turns out to yield a strategy-proof mechanism, we propose another strategy-proof mechanism which has a competitive ratio of $$(n+3)/(n+1)$$ for odd n and $$(n+4)/n$$ for even n, which we conjecture to be the best possible. We also consider a generalisation with multiple facilities and weighted agents, for which we show that the optimum can be computed in polynomial time for a fixed number of facilities.},
  archive      = {J_Alg},
  author       = {de Keijzer, Bart and Wojtczak, Dominik},
  doi          = {10.1007/s00453-022-00993-1},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {2898-2925},
  shortjournal = {Algorithmica},
  title        = {Facility reallocation on the line},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Particle-based assembly using precise global control.
<em>Alg</em>, <em>84</em>(10), 2871–2897. (<a
href="https://doi.org/10.1007/s00453-022-00992-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In micro- and nano-scale systems, particles can be moved by using an external force like gravity or a magnetic field. In the presence of adhesive particles that can attach to each other, the challenge is to decide whether a shape is constructible. Previous work provides a class of shapes for which constructibility can be decided efficiently when particles move maximally into the same direction induced by a global signal. In this paper we consider the single step model, i.e., a model in which each particle moves one unit step into the given direction. We restrict the assembly process such that at each single time step actually one particle is added to and moved within the workspace. We prove that deciding constructibility is NP-complete for three-dimensional shapes, and that a maximum constructible shape can be approximated. The same approximation algorithm applies for 2D. We further present linear-time algorithms to decide whether or not a tree-shape in 2D or 3D is constructible. Scaling a shape yields constructibility; in particular we show that the 2-scaled copy of every non-degenerate polyomino is constructible. In the three-dimensional setting we show that the 3-scaled copy of every non-degenerate polycube is constructible.},
  archive      = {J_Alg},
  author       = {Keller, Jakob and Rieck, Christian and Scheffer, Christian and Schmidt, Arne},
  doi          = {10.1007/s00453-022-00992-2},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {2871-2897},
  shortjournal = {Algorithmica},
  title        = {Particle-based assembly using precise global control},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On subgraph complementation to h-free graphs. <em>Alg</em>,
<em>84</em>(10), 2842–2870. (<a
href="https://doi.org/10.1007/s00453-022-00991-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a class $$\mathcal {G}$$ of graphs, the problem Subgraph Complement to $$\mathcal {G}$$ asks whether one can find a subset S of vertices of the input graph G such that complementing the subgraph induced by S in G results in a graph in $$\mathcal {G}$$ . We investigate the complexity of the problem when $$\mathcal {G}$$ is H-free for H being a complete graph, a star, a path, or a cycle. We obtain the following results: Further, we prove that these hard problems do not admit subexponential-time algorithms (algorithms running in time $$2^{o(\mid V(G)\mid )}$$ ), assuming the Exponential Time Hypothesis. We show that the complexity results on a graph class $$\mathcal {G}$$ is also true for the class $$\overline{\mathcal {G}}$$ of the complement graphs of $$\mathcal {G}$$ . Therefore, each of the above results mentioned for the H-free class of graphs is also valid for the $$\overline{H}$$ -free class of graphs. It is noteworthy that our results generalize two main results, namely, Subgraph Complement to triangle-free graphs and Subgraph Complement to d-degenerate graphs, and resolves one open question due to Fomin et al. (Algorithmica, 2020).},
  archive      = {J_Alg},
  author       = {Antony, Dhanyamol and Garchar, Jay and Pal, Sagartanu and Sandeep, R. B. and Sen, Sagnik and Subashini, R.},
  doi          = {10.1007/s00453-022-00991-3},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {2842-2870},
  shortjournal = {Algorithmica},
  title        = {On subgraph complementation to H-free graphs},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reachability problems for transmission graphs. <em>Alg</em>,
<em>84</em>(10), 2820–2841. (<a
href="https://doi.org/10.1007/s00453-022-00985-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let P be a set of n points in the plane where each point p of P is associated with a radius $$r_p&gt;0$$ . The transmission graph $$G=(P,E)$$ of P is defined as the directed graph such that E contains an edge from p to q if and only if $$|pq|\le r_p$$ for any two points p and q in P, where |pq| denotes the Euclidean distance between p and q. In this paper, we present a data structure of size $$O(n^{5/3})$$ such that for any two points in P, we can check in $$O(n^{2/3})$$ time if there is a path in G between the two points. This is the first data structure for answering reachability queries whose performance depends only on n but not on the ratio between the largest and smallest radii.},
  archive      = {J_Alg},
  author       = {An, Shinwoo and Oh, Eunjin},
  doi          = {10.1007/s00453-022-00985-1},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {2820-2841},
  shortjournal = {Algorithmica},
  title        = {Reachability problems for transmission graphs},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Strongly polynomial FPTASes for monotone dynamic programs.
<em>Alg</em>, <em>84</em>(10), 2785–2819. (<a
href="https://doi.org/10.1007/s00453-022-00954-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce a framework for the automatic generation of Strongly Polynomial Fully Polynomial Time Approximation Schemes (SFPTASes) for monotone dynamic programs. While some ad-hoc SFPTASes for specific problems are already known, this is the first framework yielding such SFPTASes. In addition, it is possible to use our algorithm to get efficient (non strongly polynomial) FPTASes. Our results are derived by improving former (non strongly polynomial) FPTASes which were designed via the method of K-approximation sets and functions. We demonstrate our SFPTAS framework on five application problems, namely, 0/1 Knapsack, counting 0/1 Knapsack, Counting $$s-t$$ paths, Mobile agent routing and Counting n-tuples, for the last problem we get the fastest SFPTAS known to date. In addition, we use our algorithm to get the fastest (non strongly polynomial) FPTASes for the following other three application problems: Stochastic ordered knapsack, Bi-criteria path problem with maximum survival probability and Minimizing the makespan of deteriorating jobs.},
  archive      = {J_Alg},
  author       = {Alon, Tzvi and Halman, Nir},
  doi          = {10.1007/s00453-022-00954-8},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {2785-2819},
  shortjournal = {Algorithmica},
  title        = {Strongly polynomial FPTASes for monotone dynamic programs},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Component order connectivity in directed graphs.
<em>Alg</em>, <em>84</em>(9), 2767–2784. (<a
href="https://doi.org/10.1007/s00453-022-01004-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A directed graph D is semicomplete if for every pair x, y of vertices of D,  there is at least one arc between x and y. Thus, a tournament is a semicomplete digraph. In the Directed Component Order Connectivity (DCOC) problem, given a digraph $$D=(V,A)$$ and a pair of natural numbers k and $$\ell $$ , we are to decide whether there is a subset X of V of size k such that the largest strongly connected component in $$D-X$$ has at most $$\ell $$ vertices. Note that DCOC reduces to the Directed Feedback Vertex Set problem for $$\ell =1.$$ We study the parameterized complexity of DCOC for general and semicomplete digraphs with the following parameters: $$k, \ell ,\ell +k$$ and $$n-\ell $$ . In particular, we prove that DCOC with parameter k on semicomplete digraphs can be solved in time $$O^*(2^{16k})$$ but not in time $$O^*(2^{o(k)})$$ unless the Exponential Time Hypothesis (ETH) fails. The upper bound $$O^*(2^{16k})$$ implies the upper bound $$O^*(2^{16(n-\ell )})$$ for the parameter $$n-\ell .$$ We complement the latter by showing that there is no algorithm of time complexity $$O^*(2^{o({n-\ell })})$$ unless ETH fails. Finally, we improve (in dependency on $$\ell $$ ) the upper bound of Göke, Marx and Mnich (2019) for the time complexity of DCOC with parameter $$\ell +k$$ on general digraphs from $$O^*(2^{O(k\ell \log (k\ell ))})$$ to $$O^*(2^{O(k\log (k\ell ))}).$$ Note that Drange, Dregi and van ’t Hof (2016) proved that even for the undirected version of DCOC on split graphs there is no algorithm of running time $$O^*(2^{o(k\log \ell )})$$ unless ETH fails and it is a long-standing problem to decide whether Directed Feedback Vertex Set admits an algorithm of time complexity $$O^*(2^{o(k\log k)}).$$},
  archive      = {J_Alg},
  author       = {Bang-Jensen, Jørgen and Eiben, Eduard and Gutin, Gregory and Wahlström, Magnus and Yeo, Anders},
  doi          = {10.1007/s00453-022-01004-z},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2767-2784},
  shortjournal = {Algorithmica},
  title        = {Component order connectivity in directed graphs},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast and simple compact hashing via bucketing. <em>Alg</em>,
<em>84</em>(9), 2735–2766. (<a
href="https://doi.org/10.1007/s00453-022-00996-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compact hash tables store a set S of n key-value pairs, where the keys are from the universe $$U = {0,\ldots ,u-1}$$ , and the values are $$v$$ -bit integers, in close to $${{\mathcal {B}}(u, n)} + nv$$ bits of space, where $${{\mathcal {B}}(u, n)} = \log _2 {{u} \atopwithdelims (){n}}$$ is the information-theoretic lower bound for representing the set of keys in S, and support operations insert, delete and lookup on S. Compact hash tables have received significant attention in recent years, and approaches dating back to Cleary [IEEE T. Comput, 1984], as well as more recent ones have been implemented and used in a number of applications. However, the wins on space usage of these approaches are outweighed by their slowness relative to conventional hash tables. In this paper, we demonstrate that compact hash tables based upon a simple idea of bucketing practically outperform existing compact hash table implementations in terms of memory usage and construction time, and existing fast hash table implementations in terms of memory usage (and sometimes also in terms of construction time), while having competitive query times. A related notion is that of a compact hash ID map, which stores a set $${\hat{S}}$$ of n keys from U, and implicitly associates each key in $${\hat{S}}$$ with a unique value (its ID), chosen by the data structure itself, which is an integer of magnitude O(n), and supports inserts and lookups on $${\hat{S}}$$ , while using space close to $${{\mathcal {B}}(u,n)}$$ bits. One of our approaches is suitable for use as a compact hash ID map.},
  archive      = {J_Alg},
  author       = {Köppl, Dominik and Puglisi, Simon J. and Raman, Rajeev},
  doi          = {10.1007/s00453-022-00996-y},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2735-2766},
  shortjournal = {Algorithmica},
  title        = {Fast and simple compact hashing via bucketing},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mincut sensitivity data structures for the insertion of an
edge. <em>Alg</em>, <em>84</em>(9), 2702–2734. (<a
href="https://doi.org/10.1007/s00453-022-00978-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $$G=(V,E)$$ be an undirected graph on n vertices with non-negative capacities on its edges. The mincut sensitivity problem for the insertion of an edge is defined as follows. Build a compact data structure for G and a given set $$S\subseteq V$$ of vertices that, on receiving any edge $$(x,y)\in S\times S$$ of positive capacity as query input, can efficiently report the set of all pairs from $$S\times S$$ whose mincut value increases upon insertion of the edge (x, y) to G. The only result that exists for this problem is for a single pair of vertices (Picard and Queyranne, in: Rayward-Smith (ed) Combinatorial optimization II. Mathematical programming Studies, vol 13, no 1. Springer, Berlin, pp 8–16, 1980. https://doi.org/10.1007/BFb0120902 , and dates back to 1980. We present the following results for the single source and the all-pairs versions of this problem. For both these versions, we also address the problem of reporting the values of the mincuts upon insertion of any given edge. To derive our results, we use interesting insights into the nearest and the farthest mincuts for a pair of vertices. In addition, a crucial result, that we establish and use in our data structures, is that there exists a directed acyclic graph of $${\mathcal {O}}(n)$$ size that compactly stores the farthest mincuts from all vertices of V to a designated vertex s in the graph. We believe that this result is of independent interest, especially, because it also complements a previously existing result (Hariharan et al., in: Proceedings of the 39th annual ACM symposium on theory of computing, San Diego, California, USA, June 11–13, 2007, pp 605–614, 2007. https://doi.org/10.1145/1250790 ) that the nearest mincuts from all vertices of V to s is a laminar family, and hence, can be stored compactly in the form of a rooted tree of $${\mathcal {O}}(n)$$ size.},
  archive      = {J_Alg},
  author       = {Baswana, Surender and Gupta, Shiv and Knollmann, Till},
  doi          = {10.1007/s00453-022-00978-0},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2702-2734},
  shortjournal = {Algorithmica},
  title        = {Mincut sensitivity data structures for the insertion of an edge},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). <span
class="math display"><em>ℓ</em><sub><em>p</em></sub></span> -norm
multiway cut. <em>Alg</em>, <em>84</em>(9), 2667–2701. (<a
href="https://doi.org/10.1007/s00453-022-00983-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and study $$\ell _p$$ -norm-multiway-cut: the input here is an undirected graph with non-negative edge weights along with k terminals and the goal is to find a partition of the vertex set into k parts each containing exactly one terminal so as to minimize the $$\ell _p$$ -norm of the cut values of the parts. This is a unified generalization of min-sum multiway cut (when $$p=1$$ ) and min–max multiway cut (when $$p=\infty $$ ), both of which are well-studied classic problems in the graph partitioning literature. We show that $$\ell _p$$ -norm-multiway-cut is NP-hard for constant number of terminals and is NP-hard in planar graphs. On the algorithmic side, we design an $$O(\log ^{1.5}{n} \log ^{0.5}{k})$$ -approximation for all $$p\ge 1$$ . We also show an integrality gap of $$\Omega (k^{1-1/p})$$ for a natural convex program and an $$O(k^{1-1/p-\epsilon })$$ -inapproximability for any constant $$\epsilon &gt;0$$ assuming the small set expansion hypothesis.},
  archive      = {J_Alg},
  author       = {Chandrasekaran, Karthekeyan and Wang, Weihang},
  doi          = {10.1007/s00453-022-00983-3},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2667-2701},
  shortjournal = {Algorithmica},
  title        = {$$\ell _p$$ -norm multiway cut},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph searches and their end vertices. <em>Alg</em>,
<em>84</em>(9), 2642–2666. (<a
href="https://doi.org/10.1007/s00453-022-00981-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a graph search algorithm, the end vertex problem is concerned with which vertices of a graph can be the last visited by this algorithm. We characterize all maximum cardinality searches on chordal graphs and derive from this characterization a polynomial-time algorithm for the end vertex problem of maximum cardinality searches on chordal graphs. It is complemented by a proof of NP-completeness of the same problem on weakly chordal graphs. We also show linear-time algorithms for deciding end vertices of breadth-first searches on interval graphs and end vertices of lexicographic depth-first searches on chordal graphs.},
  archive      = {J_Alg},
  author       = {Rong, Guozhen and Cao, Yixin and Wang, Jianxin and Wang, Zhifeng},
  doi          = {10.1007/s00453-022-00981-5},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2642-2666},
  shortjournal = {Algorithmica},
  title        = {Graph searches and their end vertices},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast exact algorithms for survivable network design with
uniform requirements. <em>Alg</em>, <em>84</em>(9), 2622–2641. (<a
href="https://doi.org/10.1007/s00453-022-00959-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We design exact algorithms for the following two problems in survivable network design: (i) designing a minimum cost network with a desired value of edge connectivity, which is called Minimum Weight $$\lambda $$ -connected Spanning Subgraph and (ii) augmenting a given network to a desired value of edge connectivity at a minimum cost which is called Minimum Weight $$\lambda $$ -connectivity Augmentation. It is easy to see that a minimum solution to these problems contains at most $$2 \lambda (n-1)$$ edges. Using this fact one can design a brute-force algorithm which runs in time $$2^{{\mathcal {O}}(\lambda n \log n)}$$ , however no better algorithms were known previously. In this paper, we give the first single exponential time algorithm for these problems, i.e. running in time $$2^{{\mathcal {O}}(\lambda n)}$$ , for both undirected and directed networks. Our results are obtained via well known characterizations of $$\lambda $$ -connected graphs, their connections to linear matroids and the recently developed technique of dynamic programming with representative sets.},
  archive      = {J_Alg},
  author       = {Agrawal, Akanksha and Misra, Pranabendu and Panolan, Fahad and Saurabh, Saket},
  doi          = {10.1007/s00453-022-00959-3},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2622-2641},
  shortjournal = {Algorithmica},
  title        = {Fast exact algorithms for survivable network design with uniform requirements},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximation algorithms for replenishment problems with
fixed turnover times. <em>Alg</em>, <em>84</em>(9), 2597–2621. (<a
href="https://doi.org/10.1007/s00453-022-00974-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and study a class of optimization problems we call replenishment problems with fixed turnover times: a very natural model that has received little attention in the literature. Clients with capacity for storing a certain commodity are located at various places; at each client the commodity depletes within a certain time, the turnover time, which is constant but can vary between locations. Clients should never run empty. The natural feature that makes this problem interesting is that we may schedule a replenishment (well) before a client becomes empty, but then the next replenishment will be due earlier also. This added workload needs to be balanced against the cost of routing vehicles to do the replenishments. In this paper, we focus on the aspect of minimizing routing costs. However, the framework of recurring tasks, in which the next job of a task must be done within a fixed amount of time after the previous one is much more general and gives an adequate model for many practical situations. Note that our problem has an infinite time horizon. However, it can be fully characterized by a compact input, containing only the location of each client and a turnover time. This makes determining its computational complexity highly challenging and indeed it remains essentially unresolved. We study the problem for two objectives: min–avg  minimizes the average tour cost and min–max  minimizes the maximum tour cost over all days. For min–max  we derive a logarithmic factor approximation for the problem on general metrics and a 6-approximation for the problem on trees, for which we have a proof of NP-hardness. For min–avg  we present a logarithmic factor approximation on general metrics, a 2-approximation for trees, and a pseudopolynomial time algorithm for the line. Many intriguing problems remain open.},
  archive      = {J_Alg},
  author       = {Bosman, Thomas and van Ee, Martijn and Jiao, Yang and Marchetti-Spaccamela, Alberto and Ravi, R. and Stougie, Leen},
  doi          = {10.1007/s00453-022-00974-4},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2597-2621},
  shortjournal = {Algorithmica},
  title        = {Approximation algorithms for replenishment problems with fixed turnover times},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A faster reduction of the dynamic time warping distance to
the longest increasing subsequence length. <em>Alg</em>, <em>84</em>(9),
2581–2596. (<a
href="https://doi.org/10.1007/s00453-022-00968-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The similarity between a pair of time series, i.e., sequences of indexed values in time order, is often estimated by the dynamic time warping (DTW) distance, instead of any in the well-studied family of measures including the longest common subsequence (LCS) length and the edit distance. Although it may seem as if the DTW and the LCS(-like) measures are essentially different, we reveal that the DTW distance can be represented by the longest increasing subsequence (LIS) length of a sequence of integers, which is the LCS length between the integer sequence and itself sorted. For a given pair of time series of length n such that the dissimilarity between any elements is an integer between zero and c, we propose an integer sequence that represents any substring-substring DTW distance as its band-substring LIS length. The length of the produced integer sequence is $$O(c n^2)$$ , which can be translated to $$O(n^2)$$ for constant dissimilarity functions. To demonstrate that techniques developed under the LCS(-like) measures are directly applicable to analysis of time series via our reduction of DTW to LIS, we present time-efficient algorithms for DTW-related problems utilizing the semi-local sequence comparison technique developed for LCS-related problems.},
  archive      = {J_Alg},
  author       = {Sakai, Yoshifumi and Inenaga, Shunsuke},
  doi          = {10.1007/s00453-022-00968-2},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2581-2596},
  shortjournal = {Algorithmica},
  title        = {A faster reduction of the dynamic time warping distance to the longest increasing subsequence length},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Universal slope sets for upward planar drawings.
<em>Alg</em>, <em>84</em>(9), 2556–2580. (<a
href="https://doi.org/10.1007/s00453-022-00975-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study universal sets of slopes for computing upward planar drawings of planar st-graphs. We first consider a subfamily of planar st-graphs, called bitonic st-graphs. We prove that every set $$\mathcal {S}$$ of $$\varDelta $$ slopes containing the horizontal slope is universal for 1-bend upward planar drawings of bitonic st-graphs with maximum vertex degree $$\varDelta $$ , i.e., every such digraph admits a 1-bend upward planar drawing whose edge segments use only slopes in $$\mathcal {S}$$ . This result is worst-case optimal in terms of number of slopes, and, for a suitable choice of $$\mathcal {S}$$ , it gives rise to drawings with worst-case optimal angular resolution. We then prove that every such set $$\mathcal {S}$$ can be used to construct 2-bend upward planar drawings of n-vertex planar st-graphs with at most $$4n-9$$ bends in total.},
  archive      = {J_Alg},
  author       = {Bekos, Michael A. and Di Giacomo, Emilio and Didimo, Walter and Liotta, Giuseppe and Montecchiani, Fabrizio},
  doi          = {10.1007/s00453-022-00975-3},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2556-2580},
  shortjournal = {Algorithmica},
  title        = {Universal slope sets for upward planar drawings},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The largest connected subgraph game. <em>Alg</em>,
<em>84</em>(9), 2533–2555. (<a
href="https://doi.org/10.1007/s00453-022-00973-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the largest connected subgraph game played on an undirected graph G. In each round, Alice first colours an uncoloured vertex of G red, and then, Bob colours an uncoloured vertex of G blue, with all vertices initially uncoloured. Once all the vertices are coloured, Alice (Bob, resp.) wins if there is a red (blue, resp.) connected subgraph whose order is greater than the order of any blue (red, resp.) connected subgraph. We first prove that, if Alice plays optimally, then Bob can never win, and define a large class of graphs (called reflection graphs) in which the game is a draw. We then show that determining the outcome of the game is PSPACE-complete, even in bipartite graphs of small diameter, and that recognising reflection graphs is GI-hard. We also prove that the game is a draw in paths if and only if the path is of even order or has at least 11 vertices, and that Alice wins in cycles if and only if the cycle is of odd length. Lastly, we give an algorithm to determine the outcome of the game in cographs in linear time.},
  archive      = {J_Alg},
  author       = {Bensmail, Julien and Fioravantes, Foivos and Mc Inerney, Fionn and Nisse, Nicolas},
  doi          = {10.1007/s00453-022-00973-5},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2533-2555},
  shortjournal = {Algorithmica},
  title        = {The largest connected subgraph game},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymptotic analysis of q-recursive sequences. <em>Alg</em>,
<em>84</em>(9), 2480–2532. (<a
href="https://doi.org/10.1007/s00453-022-00950-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For an integer $$q\ge 2$$ , a q-recursive sequence is defined by recurrence relations on subsequences of indices modulo some powers of q. In this article, q-recursive sequences are studied and the asymptotic behavior of their summatory functions is analyzed. It is shown that every q-recursive sequence is q-regular in the sense of Allouche and Shallit and that a q-linear representation of the sequence can be computed easily by using the coefficients from the recurrence relations. Detailed asymptotic results for q-recursive sequences are then obtained based on a general result on the asymptotic analysis of q-regular sequences. Three particular sequences are studied in detail: We discuss the asymptotic behavior of the summatory functions of For the first two sequences, our analysis even leads to precise formulæ without error terms.},
  archive      = {J_Alg},
  author       = {Heuberger, Clemens and Krenn, Daniel and Lipnik, Gabriel F.},
  doi          = {10.1007/s00453-022-00950-y},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2480-2532},
  shortjournal = {Algorithmica},
  title        = {Asymptotic analysis of q-recursive sequences},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymptotic quasi-polynomial time approximation scheme for
resource minimization for fire containment. <em>Alg</em>,
<em>84</em>(9), 2462–2479. (<a
href="https://doi.org/10.1007/s00453-022-00972-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource Minimization Fire Containment (RMFC) is a natural model for optimal inhibition of harmful spreading phenomena on a graph. In the RMFC problem on trees, we are given an undirected tree G, and a vertex r where the fire starts at, called root. At each time step, the firefighters can protect up to B vertices of the graph while the fire spreads from burning vertices to all their neighbors that have not been protected so far. The task is to find the smallest B that allows for saving all the leaves of the tree. The problem is hard to approximate up to any factor better than 2 even on trees unless P = NP (King and MacGillivray in Discret Math 310(3):614–621, 2010). Chalermsook and Chuzhoy (In: Proceedings of the 21st annual ACM-SIAM symposium on discrete algorithms, SODA 2010, Austin, Texas, USA, 17–19 Jan 2010, SIAM, pp 1334–1349, 2010) presented a Linear Programming (LP) based $$O(\log ^* n)$$ approximation for RMFC on trees that matches the integrality gap of the natural Linear Programming relaxation. This was recently improved by Adjiashvili et al. (ACM Trans Algorithms 15(2):20:1–20:33, 2019) to a 12-approximation through a combination of LP rounding along with several new techniques. In this paper we present an asymptotic QPTAS for RMFC on trees. More specifically, let $$\epsilon &gt;0$$ , and $$\mathcal {I}$$ be an instance of RMFC where the optimum number of firefighters to save all the leaves is $$OPT(\mathcal {I})$$ . We present an algorithm which uses at most $$\lceil (1+\epsilon )OPT(\mathcal {I})\rceil $$ many firefighters at each time step and runs in time $$n^{O(\log \log n/\epsilon )}$$ . This suggests that the existence of an asymptotic PTAS is plausible especially since the exponent is $$O(\log \log n)$$ , not $$O(\log n)$$ . Our result combines a more refined height reduction lemma than the one in Adjiashvili et al. (2019) with LP rounding and dynamic programming to find the solution. We also apply our height reduction lemma to the algorithm provided in Adjiashvili et al. (2019) plus a more careful analysis to improve their 12-approximation and provide a polynomial time ( $$5+\epsilon $$ )-approximation.},
  archive      = {J_Alg},
  author       = {Rahgoshay, Mirmahdi and Salavatipour, Mohammad R.},
  doi          = {10.1007/s00453-022-00972-6},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2462-2479},
  shortjournal = {Algorithmica},
  title        = {Asymptotic quasi-polynomial time approximation scheme for resource minimization for fire containment},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Space-efficient vertex separators for treewidth.
<em>Alg</em>, <em>84</em>(9), 2414–2461. (<a
href="https://doi.org/10.1007/s00453-022-00967-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For n-vertex graphs with treewidth $$k = O(n^{1/2-\epsilon })$$ and an arbitrary $$\epsilon &gt;0$$ , we present a word-RAM algorithm to compute vertex separators using only O(n) bits of working memory. As an application of our algorithm, we give an O(1)-approximation algorithm for tree decomposition. Our algorithm computes a tree decomposition in $$c^k n (\log \log n) \log ^* n$$ time using O(n) bits for some constant $$c &gt; 0$$ . Together with the result of Banerjee et al. (Proceedings of 21st international conference on computing and combinatorics (COCOON 2015). LNCS, vol 9198, Springer, pp 349–360, 2015. https://doi.org/10.1007/978-3-319-21398-9_28 ) we are able to compute a solution for all monadic-second-order problems (MSO) with $$O(n + \tau (k) \cdot p (\log _{p} n) \log n)$$ bits in $$O(\tau (k) \cdot n^{2 + (2/\log p)})$$ time where k is the treewidth of the given graph, p is some arbitrary parameter with $$2 \le p \le n$$ and $$\tau $$ is some function depending on the MSO formula. We finally use the tree decomposition obtained by our algorithm to solve Vertex Cover, Independent Set, Dominating Set, MaxCut and q-Coloring by using polynomial time and O(n) bits as long as the treewidth of the graph is smaller than $$c&#39; \log n$$ for some problem dependent constant $$0&lt; c&#39; &lt; 1$$ .},
  archive      = {J_Alg},
  author       = {Kammer, Frank and Meintrup, Johannes and Sajenko, Andrej},
  doi          = {10.1007/s00453-022-00967-3},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2414-2461},
  shortjournal = {Algorithmica},
  title        = {Space-efficient vertex separators for treewidth},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximating the geometric edit distance. <em>Alg</em>,
<em>84</em>(9), 2395–2413. (<a
href="https://doi.org/10.1007/s00453-022-00966-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edit distance is a measurement of similarity between two sequences such as strings, point sequences, or polygonal curves. Many matching problems from a variety of areas, such as signal analysis, bioinformatics, etc., need to be solved in a geometric space. Therefore, the geometric edit distance (GED) has been studied. In this paper, we describe the first strictly sublinear approximate near-linear time algorithm for computing the GED of two point sequences in constant dimensional Euclidean space. Specifically, we present a randomized $$O(n\log ^2n)$$ time $$O(\sqrt{n})$$ -approximation algorithm. Then, we generalize our result to give a randomized $$\alpha $$ -approximation algorithm for any $$\alpha \in [\sqrt{\log n}, \sqrt{n/\log n}]$$ , running in time $$O(n^2/\alpha ^2 \log n)$$ . Both algorithms are Monte Carlo and return approximately optimal solutions with high probability.},
  archive      = {J_Alg},
  author       = {Fox, Kyle and Li, Xinyi},
  doi          = {10.1007/s00453-022-00966-4},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2395-2413},
  shortjournal = {Algorithmica},
  title        = {Approximating the geometric edit distance},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parameterized complexity of graph burning. <em>Alg</em>,
<em>84</em>(8), 2379–2393. (<a
href="https://doi.org/10.1007/s00453-022-00962-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Burning asks, given a graph $$G = (V,E)$$ and an integer k, whether there exists $$(b_{0},\dots ,b_{k-1}) \in V^{k}$$ such that every vertex in G has distance at most i from some $$b_{i}$$ . This problem is known to be NP-complete even on connected caterpillars of maximum degree 3. We study the parameterized complexity of this problem and answer all questions by Kare and Reddy [IWOCA 2019] about the parameterized complexity of the problem. We show that the problem is W[2]-complete parameterized by k and that it does not admit a polynomial kernel parameterized by vertex cover number unless $$\mathrm {NP} \subseteq \mathrm {coNP/poly}$$ . We also show that the problem is fixed-parameter tractable parameterized by clique-width plus the maximum diameter among all connected components. This implies the fixed-parameter tractability parameterized by modular-width, by treedepth, and by distance to cographs. Using a different technique, we show that parameterization by distance to split graphs is also tractable. We finally show that the problem parameterized by max leaf number is XP.},
  archive      = {J_Alg},
  author       = {Kobayashi, Yasuaki and Otachi, Yota},
  doi          = {10.1007/s00453-022-00962-8},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2379-2393},
  shortjournal = {Algorithmica},
  title        = {Parameterized complexity of graph burning},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A polynomial kernel for funnel arc deletion set.
<em>Alg</em>, <em>84</em>(8), 2358–2378. (<a
href="https://doi.org/10.1007/s00453-022-00960-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Directed Feedback Arc Set (DFAS) we search for a set of at most k arcs which intersect every cycle in the input digraph. It is a well-known open problem in parameterized complexity to decide if DFAS admits a kernel of polynomial size. We consider $$\mathcal {C}$$ -Arc Deletion Set ( $$\mathcal {C}$$ -ADS), a variant of DFAS where we want to remove at most k arcs from the input digraph in order to turn it into a digraph of a class $$\mathcal {C}$$ . In this work, we choose $$\mathcal {C}$$ to be the class of funnels. Funnel-ADS is NP-hard even if the input is a DAG, but is fixed-parameter tractable with respect to k. So far no polynomial kernels for this problem were known. Our main result is a kernel for Funnel-ADS with $$\mathcal {O}(k^6)$$ many vertices and $$\mathcal {O}(k^7)$$ many arcs, computable in $$\mathcal {O}(nm)$$ time, where n is the number of vertices and m the number of arcs in the input digraph.},
  archive      = {J_Alg},
  author       = {Garlet Milani, Marcelo},
  doi          = {10.1007/s00453-022-00960-w},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2358-2378},
  shortjournal = {Algorithmica},
  title        = {A polynomial kernel for funnel arc deletion set},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structural parameterizations with modulator oblivion.
<em>Alg</em>, <em>84</em>(8), 2335–2357. (<a
href="https://doi.org/10.1007/s00453-022-00971-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that problems like Vertex Cover, Feedback Vertex Set and Odd Cycle Transversal are polynomial time solvable in the class of chordal graphs. We consider these problems in a graph that has at most k vertices whose deletion results in a chordal graph when parameterized by k. While this investigation fits naturally into the recent trend of what is called ‘structural parameterizations’, here we assume that the deletion set is not given. One method to solve them is to compute a k-sized or an approximate (f(k) sized, for a function f) chordal vertex deletion set and then use the structural properties of the graph to design an algorithm. This method leads to at least $$k^{{{\mathcal {O}}}(k)}n^{{{\mathcal {O}}}(1)}$$ running time when we use the known parameterized or approximation algorithms for finding a k-sized chordal deletion set on an n vertex graph. In this work, we design $$2^{{{\mathcal {O}}}(k)}n^{{{\mathcal {O}}}(1)}$$ time algorithms for these problems. Our algorithms do not compute a chordal vertex deletion set (or even an approximate solution). Instead, we construct a tree decomposition of the given graph in $$2^{{{\mathcal {O}}}(k)}n^{{{\mathcal {O}}}(1)}$$ time where each bag is a union of four cliques and $${{\mathcal {O}}}(k)$$ vertices. We then apply standard dynamic programming algorithms over this special tree decomposition. This special tree decomposition can be of independent interest. Our algorithms are, what are sometimes called permissive in the sense that given an integer k, they detect whether the graph has no chordal vertex deletion set of size at most k or output the special tree decomposition and solve the problem. We also show lower bounds for the problems we deal with under the strong exponential time hypothesis.},
  archive      = {J_Alg},
  author       = {Jacob, Ashwin and Panolan, Fahad and Raman, Venkatesh and Sahlot, Vibha},
  doi          = {10.1007/s00453-022-00971-7},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2335-2357},
  shortjournal = {Algorithmica},
  title        = {Structural parameterizations with modulator oblivion},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the fine-grained parameterized complexity of partial
scheduling to minimize the makespan. <em>Alg</em>, <em>84</em>(8),
2309–2334. (<a
href="https://doi.org/10.1007/s00453-022-00970-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a natural variant of scheduling that we call partial scheduling: in this variant an instance of a scheduling problem along with an integer k is given and one seeks an optimal schedule where not all, but only k jobs, have to be processed. Specifically, we aim to determine the fine-grained parameterized complexity of partial scheduling problems parameterized by k for all variants of scheduling problems that minimize the makespan and involve unit/arbitrary processing times, identical/unrelated parallel machines, release/due dates, and precedence constraints. That is, we investigate whether algorithms with runtimes of the type $$f(k)n^{{\mathcal {O}}(1)}$$ or $$n^{{\mathcal {O}}(f(k))}$$ exist for a function f that is as small as possible. Our contribution is two-fold: First, we categorize each variant to be either in $${\mathsf {P}}$$ , $${{\mathsf {N}}}{{\mathsf {P}}}$$ -complete and fixed-parameter tractable by k, or $${\mathsf {W}}[1]$$ -hard parameterized by k. Second, for many interesting cases we further investigate the runtime on a finer scale and obtain run times that are (almost) optimal assuming the Exponential Time Hypothesis. As one of our main technical contributions, we give an $${\mathcal {O}}(8^kk(|V|+|E|))$$ time algorithm to solve instances of partial scheduling problems minimizing the makespan with unit length jobs, precedence constraints and release dates, where $$G=(V,E)$$ is the graph with precedence constraints.},
  archive      = {J_Alg},
  author       = {Nederlof, Jesper and Swennenhuis, Céline M. F.},
  doi          = {10.1007/s00453-022-00970-8},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2309-2334},
  shortjournal = {Algorithmica},
  title        = {On the fine-grained parameterized complexity of partial scheduling to minimize the makespan},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parameterized complexity of directed spanner problems.
<em>Alg</em>, <em>84</em>(8), 2292–2308. (<a
href="https://doi.org/10.1007/s00453-021-00911-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We initiate the parameterized complexity study of minimum t-spanner problems on directed graphs. For a positive integer t, a multiplicative t-spanner of a (directed) graph G is a spanning subgraph H such that the distance between any two vertices in H is at most t times the distance between these vertices in G, that is, H keeps the distances in G up to the distortion (or stretch) factor t. An additive t-spanner is defined as a spanning subgraph that keeps the distances up to the additive distortion parameter t, that is, the distances in H and G differ by at most t. The task of Directed Multiplicative Spanner is, given a directed graph G with m arcs and positive integers t and k, decide whether G has a multiplicative t-spanner with at most $$m-k$$ arcs. Similarly, Directed Additive Spanner asks whether G has an additive t-spanner with at most $$m-k$$ arcs. We show that (i) Directed Multiplicative Spanner admits a polynomial kernel of size $$\mathcal {O}(k^4t^5)$$ and can be solved in randomized $$(4t)^k\cdot n^{\mathcal {O}(1)}$$ time, (ii) the weighted variant of Directed Multiplicative Spanner can be solved in $$k^{2k}\cdot n^{\mathcal {O}(1)}$$ time on directed acyclic graphs, (iii) Directed Additive Spanner is $${{\,\mathrm{\mathsf{W}}\,}}[1]$$ -hard when parameterized by k for every fixed $$t\ge 1$$ even when the input graphs are restricted to be directed acyclic graphs. The latter claim contrasts with the recent result of Kobayashi from STACS 2020 that the problem for undirected graphs is $${{\,\mathrm{\mathsf{FPT}}\,}}$$ when parameterized by t and k.},
  archive      = {J_Alg},
  author       = {Fomin, Fedor V. and Golovach, Petr A. and Lochet, William and Misra, Pranabendu and Saurabh, Saket and Sharma, Roohani},
  doi          = {10.1007/s00453-021-00911-x},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2292-2308},
  shortjournal = {Algorithmica},
  title        = {Parameterized complexity of directed spanner problems},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vertex deletion into bipartite permutation graphs.
<em>Alg</em>, <em>84</em>(8), 2271–2291. (<a
href="https://doi.org/10.1007/s00453-021-00923-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A permutation graph can be defined as an intersection graph of segments whose endpoints lie on two parallel lines $$\ell _1$$ and $$\ell _2$$ , one on each. A bipartite permutation graph is a permutation graph which is bipartite. In this paper we study the parameterized complexity of the bipartite permutation vertex deletion problem, which asks, for a given n-vertex graph, whether we can remove at most k vertices to obtain a bipartite permutation graph. This problem is $$\mathsf {NP}$$ -complete by the classical result of Lewis and Yannakakis [20]. We analyze the structure of the so-called almost bipartite permutation graphs which may contain holes (large induced cycles) in contrast to bipartite permutation graphs. We exploit the structural properties of the shortest hole in a such graph. We use it to obtain an algorithm for the bipartite permutation vertex deletion problem with running time $${\mathcal {O}}(9^k \cdot n^9)$$ , and also give a polynomial-time 9-approximation algorithm.},
  archive      = {J_Alg},
  author       = {Bożyk, Łukasz and Derbisz, Jan and Krawczyk, Tomasz and Novotná, Jana and Okrasa, Karolina},
  doi          = {10.1007/s00453-021-00923-7},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2271-2291},
  shortjournal = {Algorithmica},
  title        = {Vertex deletion into bipartite permutation graphs},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finding optimal triangulations parameterized by edge clique
cover. <em>Alg</em>, <em>84</em>(8), 2242–2270. (<a
href="https://doi.org/10.1007/s00453-022-00932-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider problems that can be formulated as a task of finding an optimal triangulation of a graph w.r.t. some notion of optimality. We present algorithms parameterized by the size of a minimum edge clique cover ( $$\texttt {cc}$$ ) to such problems. This parameterization occurs naturally in many problems in this setting, e.g., in the perfect phylogeny problem $$\texttt {cc}$$ is at most the number of taxa, in fractional hypertreewidth $$\texttt {cc}$$ is at most the number of hyperedges, and in treewidth of Bayesian networks $$\texttt {cc}$$ is at most the number of non-root nodes. We show that the number of minimal separators of graphs is at most $$2^\texttt {cc}$$ , the number of potential maximal cliques is at most $$3^\texttt {cc}$$ , and these objects can be listed in times $$O^*(2^\texttt {cc})$$ and $$O^*(3^\texttt {cc})$$ , respectively, even when no edge clique cover is given as input; the $$O^*(\cdot )$$ notation omits factors polynomial in the input size. These enumeration algorithms imply $$O^*(3^\texttt {cc})$$ time algorithms for problems such as treewidth, weighted minimum fill-in, and feedback vertex set. For generalized and fractional hypertreewidth we give $$O^*(4^m)$$ time and $$O^*(3^m)$$ time algorithms, respectively, where m is the number of hyperedges. When an edge clique cover of size $$\texttt {cc}&#39;$$ is given as a part of the input we give $$O^*(2^{\texttt {cc}&#39;})$$ time algorithms for treewidth, minimum fill-in, and chordal sandwich. This implies an $$O^*(2^n)$$ time algorithm for perfect phylogeny, where n is the number of taxa. We also give polynomial space algorithms with time complexities $$O^*(9^{\texttt {cc}&#39;})$$ and $$O^*(9^{\texttt {cc}+ O(\log ^2 \texttt {cc})})$$ for problems in this framework.},
  archive      = {J_Alg},
  author       = {Korhonen, Tuukka},
  doi          = {10.1007/s00453-022-00932-0},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2242-2270},
  shortjournal = {Algorithmica},
  title        = {Finding optimal triangulations parameterized by edge clique cover},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Preface to the special issue on parameterized and exact
computation. <em>Alg</em>, <em>84</em>(8), 2240–2241. (<a
href="https://doi.org/10.1007/s00453-022-00998-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  author       = {Cao, Yixin and Pilipczuk, Marcin},
  doi          = {10.1007/s00453-022-00998-w},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2240-2241},
  shortjournal = {Algorithmica},
  title        = {Preface to the special issue on parameterized and exact computation},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Minimum hitting set of interval bundles problem:
Computational complexity and approximability. <em>Alg</em>,
<em>84</em>(8), 2222–2239. (<a
href="https://doi.org/10.1007/s00453-022-00964-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum hitting set of bundles problem (Mhsb) is a natural generalization of the minimum hitting set problem, where instead of hitting single elements, bundles of elements are hit. More specifically, we are given a ground set of elements and a family of sets. Every set in this family contains bundles of elements, which are subsets of the ground set. The task is to find a collection of elements of minimum size such that at least one bundle of every set in the family is hit. Motivated by several applications, we consider Mhsb restricted to interval and 2-dimensional interval bundles. We study the computational complexity and give polynomial-time algorithms for several classes of instances with these special structured bundles.},
  archive      = {J_Alg},
  author       = {Gottschau, Marinus and Leichter, Marilena},
  doi          = {10.1007/s00453-022-00964-6},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2222-2239},
  shortjournal = {Algorithmica},
  title        = {Minimum hitting set of interval bundles problem: Computational complexity and approximability},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient parameter estimation of truncated boolean product
distributions. <em>Alg</em>, <em>84</em>(8), 2186–2221. (<a
href="https://doi.org/10.1007/s00453-022-00961-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of estimating the parameters of a Boolean product distribution in d dimensions, when the samples are truncated by a set $$S \subseteq {0, 1}^d$$ accessible through a membership oracle. This is the first time that the computational and statistical complexity of learning from truncated samples is considered in a discrete setting. We introduce a natural notion of fatness of the truncation set S, under which truncated samples reveal enough information about the true distribution. We show that if the truncation set is sufficiently fat, samples from the true distribution can be generated from truncated samples. A stunning consequence is that virtually any statistical task (e.g., learning in total variation distance, parameter estimation, uniformity or identity testing) that can be performed efficiently for Boolean product distributions, can also be performed from truncated samples, with a small increase in sample complexity. We generalize our approach to ranking distributions over d alternatives, where we show how fatness implies efficient parameter estimation of Mallows models from truncated samples. Exploring the limits of learning discrete models from truncated samples, we identify three natural conditions that are necessary for efficient identifiability: (i) the truncation set S should be rich enough; (ii) S should be accessible through membership queries; and (iii) the truncation by S should leave enough randomness in all directions. By carefully adapting the Stochastic Gradient Descent approach of (Daskalakis et al., FOCS 2018), we show that these conditions are also sufficient for efficient learning of truncated Boolean product distributions.},
  archive      = {J_Alg},
  author       = {Fotakis, Dimitris and Kalavasis, Alkis and Tzamos, Christos},
  doi          = {10.1007/s00453-022-00961-9},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2186-2221},
  shortjournal = {Algorithmica},
  title        = {Efficient parameter estimation of truncated boolean product distributions},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conflict-free coloring bounds on open neighborhoods.
<em>Alg</em>, <em>84</em>(8), 2154–2185. (<a
href="https://doi.org/10.1007/s00453-022-00956-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an undirected graph G, a conflict-free coloring with respect to open neighborhoods (denoted by CFON coloring) is an assignment of colors to the vertices such that every vertex has a uniquely colored vertex in its open neighborhood. The minimum number of colors required for a CFON coloring of G is the CFON chromatic number of G, denoted by $$\chi _{ON}(G)$$ . The decision problem that asks whether $$\chi _{ON}(G)\le k$$ is NP-complete. Structural as well as algorithmic aspects of this problem have been well studied. We obtain the following results for $$\chi _{ON}(G)$$ : All our bounds are a result of constructive algorithmic procedures.},
  archive      = {J_Alg},
  author       = {Bhyravarapu, Sriram and Kalyanasundaram, Subrahmanyam and Mathew, Rogers},
  doi          = {10.1007/s00453-022-00956-6},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2154-2185},
  shortjournal = {Algorithmica},
  title        = {Conflict-free coloring bounds on open neighborhoods},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximating multistage matching problems. <em>Alg</em>,
<em>84</em>(8), 2135–2153. (<a
href="https://doi.org/10.1007/s00453-022-00951-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multistage perfect matching problems, we are given a sequence of graphs on the same vertex set and are asked to find a sequence of perfect matchings, corresponding to the sequence of graphs, such that consecutive matchings are as similar as possible. More precisely, we aim to maximize the intersections, or minimize the unions between consecutive matchings. We show that these problems are NP-hard even in very restricted scenarios. As our main contribution, we present the first non-trivial approximation algorithms for these problems: On the one hand, we devise a tight approximation on graph sequences of length two (2-stage graphs). On the other hand, we propose several general methods to deduce multistage approximations from blackbox approximations on 2-stage graphs.},
  archive      = {J_Alg},
  author       = {Chimani, Markus and Troost, Niklas and Wiedera, Tilo},
  doi          = {10.1007/s00453-022-00951-x},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2135-2153},
  shortjournal = {Algorithmica},
  title        = {Approximating multistage matching problems},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards constant-factor approximation for
chordal/distance-hereditary vertex deletion. <em>Alg</em>,
<em>84</em>(7), 2106–2133. (<a
href="https://doi.org/10.1007/s00453-022-00963-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a family of graphs $$\mathcal {F}$$ , Weighted $$\mathcal {F}$$ -Deletion is the problem for which the input is a vertex weighted graph $$G = (V, E)$$ and the goal is to delete $$S \subseteq V$$ with minimum weight such that $$G \setminus S \in \mathcal {F}$$ . Designing a constant-factor approximation algorithm for large subclasses of perfect graphs has been an interesting research direction. Block graphs, 3-leaf power graphs, and interval graphs are known to admit constant-factor approximation algorithms, but the question is open for chordal graphs and distance-hereditary graphs. In this paper, we add one more class to this list by presenting a constant-factor approximation algorithm when $$\mathcal {F}$$ is the intersection of chordal graphs and distance-hereditary graphs. They are known as ptolemaic graphs and form a superset of both block graphs and 3-leaf power graphs above. Our proof presents new properties and algorithmic results on inter-clique digraphs as well as an approximation algorithm for a variant of Feedback Vertex Set that exploits this relationship (named Feedback Vertex Set with Precedence Constraints), each of which may be of independent interest.},
  archive      = {J_Alg},
  author       = {Ahn, Jungho and Kim, Eun Jung and Lee, Euiwoong},
  doi          = {10.1007/s00453-022-00963-7},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2106-2133},
  shortjournal = {Algorithmica},
  title        = {Towards constant-factor approximation for Chordal/Distance-hereditary vertex deletion},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The heaviest induced ancestors problem: Better data
structures and applications. <em>Alg</em>, <em>84</em>(7), 2088–2105.
(<a href="https://doi.org/10.1007/s00453-022-00955-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $${{\mathcal {T}}}_1$$ and $${{\mathcal {T}}}_2$$ be two rooted trees with an equal number of leaves. The leaves are labeled, and the labeling of the leaves in $${{\mathcal {T}}}_2$$ is a permutation of those in $${{\mathcal {T}}}_1$$ . Nodes are associated with weight, such that the weight of a node u, denoted by W(u), is more than the weight of its parent. A node $$x \in {{\mathcal {T}}}_1$$ and a node $$y \in {{\mathcal {T}}}_2$$ are induced, iff their subtrees have at least one common leaf label. A heaviest induced ancestor query $$\mathsf {HIA} (u_1,u_2)$$ with input nodes $$u_1 \in {{\mathcal {T}}}_1$$ and $$u_2 \in {{\mathcal {T}}}_2$$ asks to output the pair $$(u_1^*,u_2^*)$$ of induced nodes with the highest combined weight $$\mathsf {W} (u^*_1) + \mathsf {W} (u^*_2)$$ , such that $$u_1^*$$ is an ancestor of $$u_1$$ and $$u^*_2$$ is an ancestor of $$u_2$$ . This is a useful primitive in several text processing applications. Gagie et al. (Proceedings of the 25th Canadian Conference on Computational Geometry, CCCG 2013, Waterloo, Ontario, Canada, 2013) introduced this problem and proposed three data structures with the following space-time trade-offs: (i) $$O(n\log ^2n)$$ space and $$O(\log n \log \log n)$$ query time, (ii) $$O(n\log n)$$ space and $$O(\log ^2 n)$$ query time, and (iii) O(n) space and $$O(\log ^{3+\epsilon }n)$$ query time. Here n is the number of nodes in both trees combined and $$\epsilon &gt;0$$ is an arbitrarily small constant. We present two new data structures with better space-time trade-offs: (i) $$O(n\log n)$$ space and $$O(\log n \log \log n)$$ query time, and (ii) O(n) space and $$O({\log ^2 n}/{\log \log n})$$ query time. Additionally, we present new applications of these results.},
  archive      = {J_Alg},
  author       = {Abedin, Paniz and Hooshmand, Sahar and Ganguly, Arnab and Thankachan, Sharma V.},
  doi          = {10.1007/s00453-022-00955-7},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2088-2105},
  shortjournal = {Algorithmica},
  title        = {The heaviest induced ancestors problem: Better data structures and applications},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New FPT algorithms for finding the temporal hybridization
number for sets of phylogenetic trees. <em>Alg</em>, <em>84</em>(7),
2050–2087. (<a
href="https://doi.org/10.1007/s00453-022-00946-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of finding a temporal hybridization network containing at most k reticulations, for an input consisting of a set of phylogenetic trees. First, we introduce an FPT algorithm for the problem on an arbitrary set of m binary trees with n leaves each with a running time of $$O(5^k\cdot n\cdot m)$$ . We also present the concept of temporal distance, which is a measure for how close a tree-child network is to being temporal. Then we introduce an algorithm for computing a tree-child network with temporal distance at most d and at most k reticulations in $$O((8k)^d5^ k\cdot k\cdot n\cdot m)$$ time. Lastly, we introduce an $$O(6^kk!\cdot k\cdot n^2)$$ time algorithm for computing a temporal hybridization network for a set of two nonbinary trees. We also provide an implementation of all algorithms and an experimental analysis on their performance.},
  archive      = {J_Alg},
  author       = {Borst, Sander and van Iersel, Leo and Jones, Mark and Kelk, Steven},
  doi          = {10.1007/s00453-022-00946-8},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2050-2087},
  shortjournal = {Algorithmica},
  title        = {New FPT algorithms for finding the temporal hybridization number for sets of phylogenetic trees},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fault tolerant depth first search in undirected graphs:
Simple yet efficient. <em>Alg</em>, <em>84</em>(7), 2028–2049. (<a
href="https://doi.org/10.1007/s00453-022-00947-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let G be an undirected graph. We address the problem of fault tolerant depth first search (DFS) tree defined as follows. Build a compact data structure that, given any set $${{\mathcal {F}}}$$ of failed vertices or edges, can efficiently report a DFS tree of $$G{\backslash } {{\mathcal {F}}}$$ . We present an algorithm which is drastically simpler and yet more efficient than the current state-of-the-art algorithms for this problem. Additionally, for achieving efficiency, the current-state-of-the-algorithms have to crucially rely on sophisticated data structures. The simplicity of our algorithm also enables us to replace these sophisticated data structures with much simpler and lighter data structures that occupy optimal space and take optimal preprocessing time. Our algorithm for the fault tolerant DFS tree also leads to a better time complexity for maintaining a DFS tree in a fully dynamic environment.},
  archive      = {J_Alg},
  author       = {Baswana, Surender and Gupta, Shiv and Tulsyan, Ayush},
  doi          = {10.1007/s00453-022-00947-7},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2028-2049},
  shortjournal = {Algorithmica},
  title        = {Fault tolerant depth first search in undirected graphs: Simple yet efficient},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the approximability of the single allocation p-hub center
problem with parameterized triangle inequality. <em>Alg</em>,
<em>84</em>(7), 1993–2027. (<a
href="https://doi.org/10.1007/s00453-022-00941-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For some $$\beta \ge 1/2$$ , a $$\varDelta _{\beta }$$ -metric graph $$G=(V,E,w)$$ is a complete edge-weighted graph such that $$w(v,v)=0$$ , $$w(u,v)=w(v,u)$$ , and $$w(u,v) \le \beta \cdot (w(u,x)+w(x,v))$$ for all vertices $$u,v,x\in V$$ . A graph $$H=(V&#39;, E&#39;)$$ is called a spanning subgraph of $$G=(V, E)$$ if $$V&#39;=V$$ and $$E&#39;\subseteq E$$ . Given a positive integer p, let H be a spanning subgraph of G satisfying the three conditions: (i) there exists a vertex subset $$C\subseteq V$$ such that C forms a clique of size p in H; (ii) the set $$V \setminus C$$ forms an independent set in H; and (iii) each vertex $$v\in V \setminus C$$ is adjacent to exactly one vertex in C. The vertices in C are called hubs and the vertices in $$V\setminus C$$ are called non-hubs. The $$\varDelta _{\beta }\text {-}p$$ -Hub Center Problem ( $$\varDelta _{\beta }\text {-}p$$ HCP) is to find a spanning subgraph H of G satisfying all the three conditions such that the diameter of H is minimized. In this paper, we study $$\varDelta _{\beta } \text {-} p$$ HCP for all $$\beta \ge \frac{1}{2}$$ . We show that for any $$\epsilon &gt;0$$ , to approximate $$\varDelta _{\beta }\text {-}p$$ HCP to a ratio $$g(\beta )-\epsilon $$ is NP-hard and we give $$r(\beta )$$ -approximation algorithms for the same problem where $$g(\beta )$$ and $$r(\beta )$$ are functions of $$\beta $$ . For $$\frac{3-\sqrt{3}}{2}&lt;\beta \le \frac{5+\sqrt{5}}{10}$$ , we give an approximation algorithm that reaches the lower bound of approximation ratio $$g(\beta )$$ where $$g(\beta )= \frac{3\beta -2\beta ^2}{3(1-\beta )}$$ if $$\frac{3-\sqrt{3}}{2} &lt; \beta \le \frac{2}{3}$$ and $$g(\beta ) = \beta +\beta ^2$$ if $$\frac{2}{3}\le \beta \le \frac{5+\sqrt{5}}{10}$$ . For $$\frac{5+\sqrt{5}}{10}\le \beta \le 1$$ , we show that $$g(\beta ) =\frac{4\beta ^2+3\beta -1}{5\beta -1}$$ and $$r(\beta )= \min {\beta +\beta ^2, \frac{4\beta ^2+5\beta +1}{5\beta +1}}$$ . Additionally, for $$\beta \ge 1$$ , we show that $$g(\beta ) = \beta \cdot \frac{4\beta -1}{3\beta -1}$$ and $$r(\beta )=\min {\frac{\beta ^2+4\beta }{3},2\beta }$$ . For $$\beta \ge 2$$ , the upper bound on the approximation ratio $$r(\beta ) =2\beta $$ is linear in $$\beta $$ . For $$\frac{3-\sqrt{3}}{2}&lt;\beta \le \frac{5+\sqrt{5}}{10}$$ , we give an approximation algorithm that reaches the lower bound of approximation ratio $$g(\beta )$$ where $$g(\beta )= \frac{3\beta -2\beta ^2}{3(1-\beta )}$$ if $$\frac{3-\sqrt{3}}{2} &lt; \beta \le \frac{2}{3}$$ and $$g(\beta ) = \beta +\beta ^2$$ if $$\frac{2}{3}\le \beta \le \frac{5+\sqrt{5}}{10}$$ . For $$\beta \le \frac{3 - \sqrt{3}}{2}$$ , we show that $$g(\beta )=r(\beta )=1$$ , i.e., $$\varDelta _{\beta }\text {-} p$$ HCP is polynomial-time solvable.},
  archive      = {J_Alg},
  author       = {Chen, Li-Hsuan and Hsieh, Sun-Yuan and Hung, Ling-Ju and Klasing, Ralf},
  doi          = {10.1007/s00453-022-00941-z},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {1993-2027},
  shortjournal = {Algorithmica},
  title        = {On the approximability of the single allocation p-hub center problem with parameterized triangle inequality},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximate generalized matching: F-matchings and f-edge
covers. <em>Alg</em>, <em>84</em>(7), 1952–1992. (<a
href="https://doi.org/10.1007/s00453-022-00949-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present almost linear time approximation schemes for several generalized matching problems on nonbipartite graphs. Our results include $$O_\epsilon (m\alpha (m, n))$$ -time algorithms for $$(1-\epsilon )$$ -maximum weight f-matching and $$(1+\epsilon )$$ -approximate minimum weight f-edge cover. As a byproduct, we also obtain direct algorithms for the exact cardinality versions of these problems running in $$O(m\alpha (m, n)\sqrt{f(V)})$$ time, where f(V) is the sum of degree constraint on the entire vertex set. The technical contributions of this work include an efficient method for maintaining relaxed complementary slackness in generalized matching problems and approximation-preserving reductions between the f-matching and f-edge cover problems.},
  archive      = {J_Alg},
  author       = {Huang, Dawei and Pettie, Seth},
  doi          = {10.1007/s00453-022-00949-5},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {1952-1992},
  shortjournal = {Algorithmica},
  title        = {Approximate generalized matching: F-matchings and f-edge covers},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Relaxing the irrevocability requirement for online graph
algorithms. <em>Alg</em>, <em>84</em>(7), 1916–1951. (<a
href="https://doi.org/10.1007/s00453-022-00944-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online graph problems are considered in models where the irrevocability requirement is relaxed. We consider the Late Accept model, where a request can be accepted at a later point, but any acceptance is irrevocable. Similarly, we consider a Late Reject model, where an accepted request can later be rejected, but any rejection is irrevocable (this is sometimes called preemption). Finally, we consider the Late Accept/Reject model, where late accepts and rejects are both allowed, but any late reject is irrevocable. We consider four classical graph problems: For Maximum Independent Set, the Late Accept/Reject model is necessary to obtain a constant competitive ratio, for Minimum Vertex Cover the Late Accept model is sufficient, and for Minimum Spanning Forest the Late Reject model is sufficient. The Maximum Matching problem admits constant competitive ratios in all cases. We also consider Maximum Acyclic Subgraph and Maximum Planar Subgraph, which exhibit patterns similar to Maximum Independent Set.},
  archive      = {J_Alg},
  author       = {Boyar, Joan and Favrholdt, Lene M. and Kotrbčík, Michal and Larsen, Kim S.},
  doi          = {10.1007/s00453-022-00944-w},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {1916-1951},
  shortjournal = {Algorithmica},
  title        = {Relaxing the irrevocability requirement for online graph algorithms},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deterministic constructions of high-dimensional sets with
small dispersion. <em>Alg</em>, <em>84</em>(7), 1897–1915. (<a
href="https://doi.org/10.1007/s00453-022-00943-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dispersion of a point set $$P\subset [0,1]^d$$ is the volume of the largest box with sides parallel to the coordinate axes, which does not intersect P. It was observed only recently that, for any $$\varepsilon &gt;0$$ , certain randomized constructions provide point sets with dispersion smaller than $$\varepsilon $$ and number of elements growing only logarithmically in d. Based on deep results from coding theory, we present explicit, deterministic algorithms to construct such point sets in time that is only polynomial in d. Note that, however, the running-time will be super-exponential in $$\varepsilon ^{-1}$$ . Our construction is based on the apparently new insight that low-dispersion point sets can be deduced from solutions of certain k-restriction problems, which are well-known in coding theory.},
  archive      = {J_Alg},
  author       = {Ullrich, Mario and Vybíral, Jan},
  doi          = {10.1007/s00453-022-00943-x},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {1897-1915},
  shortjournal = {Algorithmica},
  title        = {Deterministic constructions of high-dimensional sets with small dispersion},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reconstructing phylogenetic trees from multipartite quartet
systems. <em>Alg</em>, <em>84</em>(7), 1875–1896. (<a
href="https://doi.org/10.1007/s00453-022-00945-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A phylogenetic tree is a graphical representation of an evolutionary history of taxa in which the leaves correspond to the taxa and the non-leaves correspond to speciations. One of important problems in phylogenetic analysis is to assemble a global phylogenetic tree from small phylogenetic trees, particularly, quartet trees. Quartet Compatibility is the problem of deciding whether there is a phylogenetic tree inducing a given collection of quartet trees, and to construct such a phylogenetic tree if it exists. It is known that Quartet Compatibility is NP-hard and that there are only a few results known for polynomial-time solvable subclasses. In this paper, we introduce two novel classes of quartet systems, called complete multipartite quartet system and full multipartite quartet system, and present polynomial-time algorithms for Quartet Compatibility for these systems.},
  archive      = {J_Alg},
  author       = {Hirai, Hiroshi and Iwamasa, Yuni},
  doi          = {10.1007/s00453-022-00945-9},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {1875-1896},
  shortjournal = {Algorithmica},
  title        = {Reconstructing phylogenetic trees from multipartite quartet systems},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Restricted max-min allocation: Integrality gap and
approximation algorithm. <em>Alg</em>, <em>84</em>(7), 1835–1874. (<a
href="https://doi.org/10.1007/s00453-022-00942-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a set of players P, a set of indivisible resources R, and a set of non-negative values $${v_{pr}}_{p\in P, r\in R}$$ , an allocation is a partition of R into disjoint subsets $${C_p}_{p \in P}$$ so that each player p is assigned the resources in $$C_p$$ . The max-min fair allocation problem is to determine the allocation that maximizes $$\min _p \sum _{r\in C_p}v_{pr}$$ . In the restricted case of this problem, each resource r has an intrinsic value $$v_r$$ , and $$v_{pr} = v_r$$ for every player p who desires r and $$v_{pr} = 0$$ for every player p who does not. We study the restricted max-min fair allocation problem in this paper. For this problem, the configuration LP has played an important role in estimating and approximating the optimal solution. Our first result is an upper bound of $$3\frac{21}{26}$$ on the integrality gap, which is currently the best. It is obtained by a tighter analysis of the local search of Asadpour et al. [TALG’12]. It remains unknown whether this local search runs in polynomial time or not. Our second result is a polynomial-time algorithm that achieves an approximation ratio of $$4 + \delta $$ for any constant $$\delta \in (0,1)$$ . Our algorithm can be seen as a generalization of the aforementioned local search.},
  archive      = {J_Alg},
  author       = {Cheng, Siu-Wing and Mao, Yuchen},
  doi          = {10.1007/s00453-022-00942-y},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {1835-1874},
  shortjournal = {Algorithmica},
  title        = {Restricted max-min allocation: Integrality gap and approximation algorithm},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tree automata and pigeonhole classes of matroids: i.
<em>Alg</em>, <em>84</em>(7), 1795–1834. (<a
href="https://doi.org/10.1007/s00453-022-00939-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hliněný’s Theorem shows that any sentence in the monadic second-order logic of matroids can be tested in polynomial time, when the input is limited to a class of $${\mathbb {F}}$$ -representable matroids with bounded branch-width (where $${\mathbb {F}}$$ is a finite field). If each matroid in a class can be decomposed by a subcubic tree in such a way that only a bounded amount of information flows across displayed separations, then the class has bounded decomposition-width. We introduce the pigeonhole property for classes of matroids: if every subclass with bounded branch-width also has bounded decomposition-width, then the class is pigeonhole. An efficiently pigeonhole class has a stronger property, involving an efficiently-computable equivalence relation on subsets of the ground set. We show that Hliněný’s Theorem extends to any efficiently pigeonhole class. In a sequel paper, we use these ideas to extend Hliněný’s Theorem to the classes of fundamental transversal matroids, lattice path matroids, bicircular matroids, and $$H$$ -gain-graphic matroids, where H is any finite group. We also give a characterisation of the families of hypergraphs that can be described via tree automata: a family is defined by a tree automaton if and only if it has bounded decomposition-width. Furthermore, we show that if a class of matroids has the pigeonhole property, and can be defined in monadic second-order logic, then any subclass with bounded branch-width has a decidable monadic second-order theory.},
  archive      = {J_Alg},
  author       = {Funk, Daryl and Mayhew, Dillon and Newman, Mike},
  doi          = {10.1007/s00453-022-00939-7},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {1795-1834},
  shortjournal = {Algorithmica},
  title        = {Tree automata and pigeonhole classes of matroids: I},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fixed-target runtime analysis. <em>Alg</em>, <em>84</em>(6),
1762–1793. (<a
href="https://doi.org/10.1007/s00453-021-00881-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Runtime analysis aims at contributing to our understanding of evolutionary algorithms through mathematical analyses of their runtimes. In the context of discrete optimization problems, runtime analysis classically studies the time needed to find an optimal solution. However, both from a practical and from a theoretical viewpoint, more fine-grained performance measures are needed to gain a more detailed understanding of the main working principles and their resulting performance implications. Two complementary approaches have been suggested: fixed-budget analyses and fixed-target analyses. In this work, we conduct an in-depth study on the advantages and the limitations of fixed-target analyses. We show that, different from fixed-budget analyses, many classical methods from the runtime analysis of discrete evolutionary algorithms yield fixed-target results without greater effort. We use this to conduct a number of new fixed-target analyses. However, we also point out examples where an extension of existing runtime results to fixed-target results is highly non-trivial.},
  archive      = {J_Alg},
  author       = {Buzdalov, Maxim and Doerr, Benjamin and Doerr, Carola and Vinokurov, Dmitry},
  doi          = {10.1007/s00453-021-00881-0},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1762-1793},
  shortjournal = {Algorithmica},
  title        = {Fixed-target runtime analysis},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast mutation in crossover-based algorithms. <em>Alg</em>,
<em>84</em>(6), 1724–1761. (<a
href="https://doi.org/10.1007/s00453-022-00957-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The heavy-tailed mutation operator proposed in Doerr et al. (GECCO 2017), called fast mutation to agree with the previously used language, so far was proven to be advantageous only in mutation-based algorithms. There, it can relieve the algorithm designer from finding the optimal mutation rate and nevertheless obtain a performance close to the one that the optimal mutation rate gives. In this first runtime analysis of a crossover-based algorithm using a heavy-tailed choice of the mutation rate, we show an even stronger impact. For the $$(1+(\lambda ,\lambda ))$$ genetic algorithm optimizing the OneMax benchmark function, we show that with a heavy-tailed mutation rate a linear runtime can be achieved. This is asymptotically faster than what can be obtained with any static mutation rate, and is asymptotically equivalent to the runtime of the self-adjusting version of the parameters choice of the $$(1+(\lambda ,\lambda ))$$ genetic algorithm. This result is complemented by an empirical study which shows the effectiveness of the fast mutation also on random satisfiable MAX-3SAT instances.},
  archive      = {J_Alg},
  author       = {Antipov, Denis and Buzdalov, Maxim and Doerr, Benjamin},
  doi          = {10.1007/s00453-022-00957-5},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1724-1761},
  shortjournal = {Algorithmica},
  title        = {Fast mutation in crossover-based algorithms},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-adjusting evolutionary algorithms for multimodal
optimization. <em>Alg</em>, <em>84</em>(6), 1694–1723. (<a
href="https://doi.org/10.1007/s00453-022-00933-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent theoretical research has shown that self-adjusting and self-adaptive mechanisms can provably outperform static settings in evolutionary algorithms for binary search spaces. However, the vast majority of these studies focuses on unimodal functions which do not require the algorithm to flip several bits simultaneously to make progress. In fact, existing self-adjusting algorithms are not designed to detect local optima and do not have any obvious benefit to cross large Hamming gaps. We suggest a mechanism called stagnation detection that can be added as a module to existing evolutionary algorithms (both with and without prior self-adjusting schemes). Added to a simple (1+1) EA, we prove an expected runtime on the well-known Jump benchmark that corresponds to an asymptotically optimal parameter setting and outperforms other mechanisms for multimodal optimization like heavy-tailed mutation. We also investigate the module in the context of a self-adjusting (1+ $$\lambda $$ ) EA. To explore the limitations of the approach, we additionally present an example where both self-adjusting mechanisms, including stagnation detection, do not help to find a beneficial setting of the mutation rate. Finally, we investigate our module for stagnation detection experimentally.},
  archive      = {J_Alg},
  author       = {Rajabi, Amirhossein and Witt, Carsten},
  doi          = {10.1007/s00453-022-00933-z},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1694-1723},
  shortjournal = {Algorithmica},
  title        = {Self-adjusting evolutionary algorithms for multimodal optimization},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Does comma selection help to cope with local optima?
<em>Alg</em>, <em>84</em>(6), 1659–1693. (<a
href="https://doi.org/10.1007/s00453-021-00896-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One hope when using non-elitism in evolutionary computation is that the ability to abandon the current-best solution aids leaving local optima. To improve our understanding of this mechanism, we perform a rigorous runtime analysis of a basic non-elitist evolutionary algorithm (EA), the $$(\mu ,\lambda )$$ EA, on the most basic benchmark function with a local optimum, the jump function. We prove that for all reasonable values of the parameters and the problem, the expected runtime of the $$(\mu ,\lambda )$$ EA is, apart from lower order terms, at least as large as the expected runtime of its elitist counterpart, the $$(\mu +\lambda )$$ EA (for which we conduct the first runtime analysis on jump functions to allow this comparison). Consequently, the ability of the $$(\mu ,\lambda )$$ EA to leave local optima to inferior solutions does not lead to a runtime advantage. We complement this lower bound with an upper bound that, for broad ranges of the parameters, is identical to our lower bound apart from lower order terms. This is the first runtime result for a non-elitist algorithm on a multi-modal problem that is tight apart from lower order terms.},
  archive      = {J_Alg},
  author       = {Doerr, Benjamin},
  doi          = {10.1007/s00453-021-00896-7},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1659-1693},
  shortjournal = {Algorithmica},
  title        = {Does comma selection help to cope with local optima?},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tight bounds on the expected runtime of a standard steady
state genetic algorithm. <em>Alg</em>, <em>84</em>(6), 1603–1658. (<a
href="https://doi.org/10.1007/s00453-021-00893-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in the runtime analysis of evolutionary algorithms (EAs) has allowed the derivation of upper bounds on the expected runtime of standard steady-state genetic algorithms (GAs). These upper bounds have shown speed-ups of the GAs using crossover and mutation over the same algorithms that only use mutation operators (i.e., steady-state EAs) both for standard unimodal (i.e., OneMax) and multimodal (i.e., Jump) benchmark functions. The bounds suggest that populations are beneficial to the GA as well as higher mutation rates than the default 1/n rate. However, making rigorous claims was not possible because matching lower bounds were not available. Proving lower bounds on crossover-based EAs is a notoriously difficult task as it is hard to capture the progress that a diverse population can make. We use a potential function approach to prove a tight lower bound on the expected runtime of the (2+1) GA for OneMax for all mutation rates c/n with $$c &lt; 1.422$$ . This provides the last piece of the puzzle that completes the proof that larger population sizes improve the performance of the standard steady-state GA for OneMax for various mutation rates, and it proves that the optimal mutation rate for the (2+1) GA on OneMax is $$(\sqrt{97}-5)/(4n) \approx 1.2122/n$$ .},
  archive      = {J_Alg},
  author       = {Oliveto, Pietro S. and Sudholt, Dirk and Witt, Carsten},
  doi          = {10.1007/s00453-021-00893-w},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1603-1658},
  shortjournal = {Algorithmica},
  title        = {Tight bounds on the expected runtime of a standard steady state genetic algorithm},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A rigorous runtime analysis of the <span
class="math display">(1 + (<em>λ</em>, <em>λ</em>))</span> GA on jump
functions. <em>Alg</em>, <em>84</em>(6), 1573–1602. (<a
href="https://doi.org/10.1007/s00453-021-00907-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The $$(1 + (\lambda ,\lambda ))$$ genetic algorithm is a younger evolutionary algorithm trying to profit also from inferior solutions. Rigorous runtime analyses on unimodal fitness functions showed that it can indeed be faster than classical evolutionary algorithms, though on these simple problems the gains were only moderate. In this work, we conduct the first runtime analysis of this algorithm on a multimodal problem class, the jump functions benchmark. We show that with the right parameters, the $${(1 + (\lambda , \lambda ))}$$ GA optimizes any jump function with jump size $$2 \le k \le n/4$$ in expected time $$O(n^{(k+1)/2} e^{O(k)} k^{-k/2})$$ , which significantly and already for constant k outperforms standard mutation-based algorithms with their $$\Theta (n^k)$$ runtime and standard crossover-based algorithms with their $${\tilde{O}}(n^{k-1})$$ runtime guarantee. For the isolated problem of leaving the local optimum of jump functions, we determine provably optimal parameters that lead to a runtime of $$(n/k)^{k/2} e^{\Theta (k)}$$ . This suggests some general advice on how to set the parameters of the $${(1 + (\lambda , \lambda ))}$$ GA, which might ease the further use of this algorithm.},
  archive      = {J_Alg},
  author       = {Antipov, Denis and Doerr, Benjamin and Karavaev, Vitalii},
  doi          = {10.1007/s00453-021-00907-7},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1573-1602},
  shortjournal = {Algorithmica},
  title        = {A rigorous runtime analysis of the $$(1 + (\lambda , \lambda ))$$ GA on jump functions},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial. <em>Alg</em>, <em>84</em>(6), 1571–1572. (<a
href="https://doi.org/10.1007/s00453-022-00980-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  author       = {Lengler, Johannes and Neumann, Frank},
  doi          = {10.1007/s00453-022-00980-6},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1571-1572},
  shortjournal = {Algorithmica},
  title        = {Editorial},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Polynomial time algorithms for tracking path problems.
<em>Alg</em>, <em>84</em>(6), 1548–1570. (<a
href="https://doi.org/10.1007/s00453-022-00931-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a graph G, and terminal vertices s and t, the Tracking Paths problem asks to compute a set of minimum number of vertices to be marked as trackers, such that the sequence of trackers encountered in each $$s$$ - $$t$$ path is unique. Tracking Paths is NP-hard in both directed and undirected graphs in general. In this paper we give a collection of polynomial time algorithms for some restricted versions of Tracking Paths. We prove that Tracking Paths is polynomial time solvable for undirected chordal graphs and tournament graphs. We also show that Tracking Paths is NP-hard in graphs with bounded maximum degree $$\Delta \ge 6$$ , and give a $$2(\Delta +1)$$ -approximate algorithm for this case. Further, we give a polynomial time algorithm which, given an undirected graph G, a tracking set $$T\subseteq V(G)$$ , and a sequence of trackers $$\pi $$ , returns the unique $$s$$ - $$t$$ path in G that corresponds to $$\pi $$ , if one exists. Finally we analyze the version of tracking $$s$$ - $$t$$ paths where paths are tracked using edges instead of vertices, and we give a polynomial time algorithm for the same.},
  archive      = {J_Alg},
  author       = {Choudhary, Pratibha},
  doi          = {10.1007/s00453-022-00931-1},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1548-1570},
  shortjournal = {Algorithmica},
  title        = {Polynomial time algorithms for tracking path problems},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On 3-coloring of ( <span
class="math display">2<em>P</em><sub>4</sub>, <em>C</em><sub>5</sub></span>
)-free graphs. <em>Alg</em>, <em>84</em>(6), 1526–1547. (<a
href="https://doi.org/10.1007/s00453-022-00937-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 3-coloring of hereditary graph classes has been a deeply-researched problem in the last decade. A hereditary graph class is characterized by a (possibly infinite) list of minimal forbidden induced subgraphs $$H_1,H_2,\ldots $$ ; the graphs in the class are called $$(H_1,H_2,\ldots )$$ -free. The complexity of 3-coloring is far from being understood, even for classes defined by a few small forbidden induced subgraphs. For H-free graphs, the complexity is settled for any H on up to seven vertices. There are only two unsolved cases on eight vertices, namely $$2P_4$$ and $$P_8$$ . For $$P_8$$ -free graphs, some partial results are known, but to the best of our knowledge, $$2P_4$$ -free graphs have not been explored yet. In this paper, we show that the 3-coloring problem is polynomial-time solvable on $$(2P_4,C_5)$$ -free graphs.},
  archive      = {J_Alg},
  author       = {Jelínek, Vít and Klimošová, Tereza and Masařík, Tomáš and Novotná, Jana and Pokorná, Aneta},
  doi          = {10.1007/s00453-022-00937-9},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1526-1547},
  shortjournal = {Algorithmica},
  title        = {On 3-coloring of ( $$2P_4,C_5$$ )-free graphs},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximating k-connected m-dominating sets. <em>Alg</em>,
<em>84</em>(6), 1511–1525. (<a
href="https://doi.org/10.1007/s00453-022-00935-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A subset S of nodes in a graph G is a k-connected m-dominating set ((k ,  m)-cds) if the subgraph G[S] induced by S is k-connected and every $$v \in V {\setminus } S$$ has at least m neighbors in S. In the k -Connected m -Dominating Set ((k ,  m)-CDS) problem, the goal is to find a minimum weight (k, m)-cds in a node-weighted graph. For $$m \ge k$$ we obtain the following approximation ratios. For unit disk graphs we improve the ratio $$O(k \ln k)$$ of Nutov (Inf Process Lett 140:30–33, 2018) to $$\min \left{ \frac{m^2}{(m-k+1)^2},k^{2/3}\right} \cdot O(\ln ^2 k)$$ —this is the first sublinear ratio for the problem, and the first polylogarithmic ratio $$O(\ln ^2 k)/\epsilon ^2$$ when $$m \ge (1+\epsilon )k$$ ; furthermore, we obtain ratio $$\min \left{ \frac{m}{m-k+1},\sqrt{k}\right} \cdot O(\ln ^2 k)$$ for uniform weights. For general graphs our ratio $$O(k \ln n)$$ improves the previous best ratio $$O(k^2 \ln n)$$ of Nutov (2018) and matches the best known ratio for unit weights of Zhang et al. (INFORMS J Comput 30(2):217–224, 2018). These results are obtained by showing the same ratios for the Subset k -Connectivity problem when the set of terminals is an m-dominating set.},
  archive      = {J_Alg},
  author       = {Nutov, Zeev},
  doi          = {10.1007/s00453-022-00935-x},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1511-1525},
  shortjournal = {Algorithmica},
  title        = {Approximating k-connected m-dominating sets},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multidimensional period recovery. <em>Alg</em>,
<em>84</em>(6), 1490–1510. (<a
href="https://doi.org/10.1007/s00453-022-00926-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multidimensional data are widely used in real-life applications. Intel’s new brand of SSDs, called 3D XPoint, is an example of three-dimensional data. Motivated by a structural analysis of multidimensional data, we introduce the multidimensional period recovery problem, defined as follows. The input is a d-dimensional text array, with dimensions $$n_1 \times n_2 \times \dots \times n_d$$ , that contains corruptions, while the original text without the corruptions is periodic. The goal is then to report the period of the original text. We show that, if the number of corruptions is at most $$\left\lfloor \frac{1}{2 + \epsilon }\left\lfloor \frac{n_1}{p_1}\right\rfloor \cdots \left\lfloor \frac{n_d}{p_d}\right\rfloor \right\rfloor $$ , where $$\epsilon &gt; 0$$ and $$p_1 \times \cdots \times p_d$$ are the period’s dimensions, then the amount of possible period candidates is $$O(\log N)$$ , where $$N = \varPi _{i=1}^{d}n_i$$ . The independency of this bound of the number of dimensions is a surprising key contribution of this paper. We present an $$O(\varPi _{i=1}^{d} n_i \varPi _{i=1}^{d} \log n_i)$$ algorithm for any constant dimension d (linear time up to logarithmic factor), to report these candidates. The tightness of the bound on the number of errors enabling a small size candidate set is demonstrated by showing that if the number of errors is equal to $$\left\lfloor \frac{1}{2}\left\lfloor \frac{n_1}{p_1}\right\rfloor \cdots \left\lfloor \frac{n_d}{p_d}\right\rfloor \right\rfloor $$ , a family of texts with $$\varTheta (N)$$ period candidates can be constructed for any dimension $$d \ge 2$$ .},
  archive      = {J_Alg},
  author       = {Amir, Amihood and Butman, Ayelet and Kondratovsky, Eitan and Levy, Avivit and Sokol, Dina},
  doi          = {10.1007/s00453-022-00926-y},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1490-1510},
  shortjournal = {Algorithmica},
  title        = {Multidimensional period recovery},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Preclustering algorithms for imprecise points. <em>Alg</em>,
<em>84</em>(6), 1467–1489. (<a
href="https://doi.org/10.1007/s00453-022-00929-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of preclustering a set B of imprecise points in $${\mathbb {R}}^d$$ : we wish to cluster the regions specifying the potential locations of the points such that, no matter where the points are located within their regions, the resulting clustering approximates the optimal clustering for those locations. We consider k-center, k-median, and k-means clustering, and obtain the following results. Let $$B := {b_1,\ldots ,b_n}$$ be a collection of disjoint balls in $${\mathbb {R}}^d$$ , where each ball $$b_i$$ specifies the possible locations of an input point $$p_i$$ . A partition $$\mathcal {C}$$ of B into subsets is called an $$(f(k),\alpha )$$ -preclustering (with respect to the specific k-clustering variant under consideration) if (i) $$\mathcal {C}$$ consists of f(k) preclusters, and (ii) for any realization P of the points $$p_i$$ inside their respective balls, the cost of the clustering on P induced by $$\mathcal {C}$$ is at most $$\alpha $$ times the cost of an optimal k-clustering on P. We call f(k) the size of the preclustering and we call $$\alpha $$ its approximation ratio. We prove that, even in $${\mathbb {R}}^1$$ , one may need at least $$3k-3$$ preclusters to obtain a bounded approximation ratio—this holds for the k-center, the k-median, and the k-means problem—and we present a (3k, 1) preclustering for the k-center problem in $${\mathbb {R}}^1$$ . We also present various preclusterings for balls in $${\mathbb {R}}^d$$ with $$d\geqslant 2$$ , including a $$(3k,\alpha )$$ -preclustering with $$\alpha \approx 13.9$$ for the k-center and the k-median problem, and $$\alpha \approx 193.9$$ for the k-means problem.},
  archive      = {J_Alg},
  author       = {Abam, Mohammad Ali and de Berg, Mark and Farahzad, Sina and Haji Mirsadeghi, Mir Omid and Saghafian, Morteza},
  doi          = {10.1007/s00453-022-00929-9},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1467-1489},
  shortjournal = {Algorithmica},
  title        = {Preclustering algorithms for imprecise points},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Metric violation distance: Hardness and approximation.
<em>Alg</em>, <em>84</em>(5), 1441–1465. (<a
href="https://doi.org/10.1007/s00453-022-00940-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metric data plays an important role in various settings, for example, in metric-based indexing, clustering, classification, and approximation algorithms in general. Due to measurement error, noise, or an inability to completely gather all the data, a collection of distances may not satisfy the basic metric requirements, most notably the triangle inequality. In this paper we initiate the study of the metric violation distance problem: given a set of pairwise distances, modify the minimum number of distances such that the resulting set forms a metric. Three variants of the problem are considered, based on whether distances are allowed to only decrease, only increase, or the general case which allows both decreases and increases. We show that while the decrease only variant is polynomial time solvable, the increase only and general variants are NP-Complete, and moreover cannot in polynomial time be approximated to any ratio better than the minimum vertex cover problem. We then provide approximation algorithms for the increase only and general variants of the problem, by proving interesting necessary and sufficient conditions on the optimal solution, which are used to approximately reduce to a purely combinatorial problem for which we provide matching asymptotic upper and lower bounds.},
  archive      = {J_Alg},
  author       = {Fan, Chenglin and Raichel, Benjamin and Buskirk, Gregory Van},
  doi          = {10.1007/s00453-022-00940-0},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1441-1465},
  shortjournal = {Algorithmica},
  title        = {Metric violation distance: Hardness and approximation},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient computation of sequence mappability. <em>Alg</em>,
<em>84</em>(5), 1418–1440. (<a
href="https://doi.org/10.1007/s00453-022-00934-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequence mappability is an important task in genome resequencing. In the (k, m)-mappability problem, for a given sequence T of length n, the goal is to compute a table whose ith entry is the number of indices $$j \ne i$$ such that the length-m substrings of T starting at positions i and j have at most k mismatches. Previous works on this problem focused on heuristics computing a rough approximation of the result or on the case of $$k=1$$ . We present several efficient algorithms for the general case of the problem. Our main result is an algorithm that, for $$k=O(1)$$ , works in $$O(n)$$ space and, with high probability, in $$O(n \cdot \min {m^k,\log ^k n})$$ time. Our algorithm requires a careful adaptation of the k-errata trees of Cole et al. [STOC 2004] to avoid multiple counting of pairs of substrings. Our technique can also be applied to solve the all-pairs Hamming distance problem introduced by Crochemore et al. [WABI 2017]. We further develop $$O(n^2)$$ -time algorithms to compute all (k, m)-mappability tables for a fixed m and all $$k\in {0,\ldots ,m}$$ or a fixed k and all $$m\in {k,\ldots ,n}$$ . Finally, we show that, for $$k,m = \Theta (\log n)$$ , the (k, m)-mappability problem cannot be solved in strongly subquadratic time unless the Strong Exponential Time Hypothesis fails. This is an improved and extended version of a paper presented at SPIRE 2018.},
  archive      = {J_Alg},
  author       = {Charalampopoulos, Panagiotis and Iliopoulos, Costas S. and Kociumaka, Tomasz and Pissis, Solon P. and Radoszewski, Jakub and Straszyński, Juliusz},
  doi          = {10.1007/s00453-022-00934-y},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1418-1440},
  shortjournal = {Algorithmica},
  title        = {Efficient computation of sequence mappability},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Node multiway cut and subset feedback vertex set on graphs
of bounded mim-width. <em>Alg</em>, <em>84</em>(5), 1385–1417. (<a
href="https://doi.org/10.1007/s00453-022-00936-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two weighted graph problems Node Multiway Cut (NMC) and Subset Feedback Vertex Set (SFVS) both ask for a vertex set of minimum total weight, that for NMC disconnects a given set of terminals, and for SFVS intersects all cycles containing a vertex of a given set. We design a meta-algorithm that allows to solve both problems in time $$2^{O(rw^3)}\cdot n^{4}$$ , $$2^{O(q^2\log (q))}\cdot n^{4}$$ , and $$n^{O(k^2)}$$ where rw is the rank-width, q the $${\mathbb {Q}}$$ -rank-width, and k the mim-width of a given decomposition. This answers in the affirmative an open question raised by Jaffke et al. (Algorithmica 82(1):118–145, 2020) concerning an XP algorithm for SFVS parameterized by mim-width. By a unified algorithm, this solves both problems in polynomial-time on the following graph classes: Interval, Permutation, and Bi-Interval graphs, Circular Arc and Circular Permutation graphs, Convex graphs, k-Polygon, Dilworth-k and Co-k-Degenerate graphs for fixed k; and also on Leaf Power graphs if a leaf root is given as input, on H -Graphs for fixed H if an H-representation is given as input, and on arbitrary powers of graphs in all the above classes. Prior to our results, only SFVS was known to be tractable restricted only on Interval and Permutation graphs, whereas all other results are new.},
  archive      = {J_Alg},
  author       = {Bergougnoux, Benjamin and Papadopoulos, Charis and Telle, Jan Arne},
  doi          = {10.1007/s00453-022-00936-w},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1385-1417},
  shortjournal = {Algorithmica},
  title        = {Node multiway cut and subset feedback vertex set on graphs of bounded mim-width},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Randomized online computation with high probability
guarantees. <em>Alg</em>, <em>84</em>(5), 1357–1384. (<a
href="https://doi.org/10.1007/s00453-022-00925-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the relationship between the competitive ratio and the tail distribution of randomized online problems. To this end, we identify a broad class of online problems for which the existence of a randomized online algorithm with constant expected competitive ratio r implies the existence of a randomized online algorithm that has a competitive ratio of $$(1+\varepsilon )r$$ with high probability, measured with respect to the optimal profit or cost, respectively. The class of problems includes some of the well-studied online problems such as paging, k-server, and metrical task systems on finite metric spaces.},
  archive      = {J_Alg},
  author       = {Komm, Dennis and Královič, Rastislav and Královič, Richard and Mömke, Tobias},
  doi          = {10.1007/s00453-022-00925-z},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1357-1384},
  shortjournal = {Algorithmica},
  title        = {Randomized online computation with high probability guarantees},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Faster minimization of tardy processing time on a single
machine. <em>Alg</em>, <em>84</em>(5), 1341–1356. (<a
href="https://doi.org/10.1007/s00453-022-00928-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the $$1|| \sum p_j U_j$$ problem, the problem of minimizing the total processing time of tardy jobs on a single machine. This is not only a fundamental scheduling problem, but also an important problem from a theoretical point of view as it generalizes the Subset Sum problem and is closely related to the 0/1-Knapsack problem. The problem is well-known to be NP-hard, but only in a weak sense, meaning it admits pseudo-polynomial time algorithms. The best known running time follows from the famous Lawler and Moore algorithm that solves a more general weighted version in $$O(P \cdot n)$$ time, where P is the total processing time of all n jobs in the input. This algorithm has been developed in the late 60s, and has yet to be improved to date. In this paper we develop two new algorithms for problem, each improving on Lawler and Moore’s algorithm in a different scenario. Both algorithms rely on basic primitive operations between sets of integers and vectors of integers for the speedup in their running times. The second algorithm relies on fast polynomial multiplication as its main engine, and can be easily extended to the case of a fixed number of machines. For the first algorithm we define a new “skewed” version of $$(\max ,\min )$$ -Convolution which is interesting in its own right.},
  archive      = {J_Alg},
  author       = {Bringmann, Karl and Fischer, Nick and Hermelin, Danny and Shabtay, Dvir and Wellnitz, Philip},
  doi          = {10.1007/s00453-022-00928-w},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1341-1356},
  shortjournal = {Algorithmica},
  title        = {Faster minimization of tardy processing time on a single machine},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local routing in sparse and lightweight geometric graphs.
<em>Alg</em>, <em>84</em>(5), 1316–1340. (<a
href="https://doi.org/10.1007/s00453-022-00930-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online routing in a planar embedded graph is central to a number of fields and has been studied extensively in the literature. For most planar graphs no O(1)-competitive online routing algorithm exists. A notable exception is the Delaunay triangulation for which Bose and Morin (SIAM J Comput 33(4):937–951, 2004) showed that there exists an online routing algorithm that is O(1)-competitive. However, a Delaunay triangulation can have $$\varOmega (n)$$ vertex degree and a total weight that is a linear factor greater than the weight of a minimum spanning tree. We show a simple construction, given a set V of n points in the Euclidean plane, of a planar geometric graph on V that has small weight (within a constant factor of the weight of a minimum spanning tree on V), constant degree, and that admits a local routing strategy that is O(1)-competitive. Moreover, the technique used to bound the weight works generally for any planar geometric graph whilst preserving the admission of an O(1)-competitive routing strategy.},
  archive      = {J_Alg},
  author       = {Ashvinkumar, Vikrant and Gudmundsson, Joachim and Levcopoulos, Christos and Nilsson, Bengt J. and Renssen, André van},
  doi          = {10.1007/s00453-022-00930-2},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1316-1340},
  shortjournal = {Algorithmica},
  title        = {Local routing in sparse and lightweight geometric graphs},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enumeration of support-closed subsets in confluent systems.
<em>Alg</em>, <em>84</em>(5), 1279–1315. (<a
href="https://doi.org/10.1007/s00453-022-00927-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a finite set V of elements, a confluent system is a set system $$(V, {{\mathcal {C}}}\subseteq 2^V)$$ such that every three sets $$X,Y,Z\in {{\mathcal {C}}}$$ with $$Z\subseteq X\cap Y$$ implies $$X\cup Y\in {{\mathcal {C}}}$$ , where we call a set $$C\in {{\mathcal {C}}}$$ a component. We assume that two oracles $$\mathrm {L}_1$$ and $$\mathrm {L}_2$$ are available, where given two subsets $$X,Y\subseteq V$$ , $$\mathrm {L}_1$$ returns a maximal component $$C\in {{\mathcal {C}}}$$ with $$X\subseteq C\subseteq Y$$ ; and given a set $$Y\subseteq V$$ , $$\mathrm {L}_2$$ returns all maximal components $$C\in {{\mathcal {C}}}$$ with $$C\subseteq Y$$ . Given a set I of items and a function $$\sigma :V\rightarrow 2^I$$ in a confluent system, a component $$C\in {{\mathcal {C}}}$$ is called a solution (or support-closed) if the set of common items in C is inclusively maximal; i.e., $$\bigcap _{v\in C}\sigma (v)\supsetneq \bigcap _{v\in X}\sigma (v)$$ for any component $$X\in {{\mathcal {C}}}$$ with $$C\subsetneq X$$ . We prove that there exists an algorithm of enumerating all solutions in polynomial delay and in polynomial space. The proposed algorithm yields polynomial-delay and polynomial-space algorithms for enumerating connectors in an attributed graph (i.e., a graph such that each vertex is assigned items) and for enumerating all subgraphs with various types of connectivities such as all k-edge/vertex-connected induced subgraphs and all k-edge/vertex-connected spanning subgraphs in a given undirected/directed graph for a fixed k.},
  archive      = {J_Alg},
  author       = {Haraguchi, Kazuya and Nagamochi, Hiroshi},
  doi          = {10.1007/s00453-022-00927-x},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1279-1315},
  shortjournal = {Algorithmica},
  title        = {Enumeration of support-closed subsets in confluent systems},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On approximating degree-bounded network design problems.
<em>Alg</em>, <em>84</em>(5), 1252–1278. (<a
href="https://doi.org/10.1007/s00453-022-00924-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directed Steiner Tree (DST) is a central problem in combinatorial optimization and theoretical computer science: Given a directed graph $$G=(V, E)$$ with edge costs $$c \in {\mathbb {R}}_{\ge 0}^E$$ , a root $$r \in V$$ and k terminals $$K\subseteq V$$ , we need to output the minimum-cost arborescence in G that contains an $$r \rightarrow t$$ path for every $$t \in K$$ . Recently, Grandoni, Laekhanukit and Li, and independently Ghuge and Nagarajan, gave quasi-polynomial time $$O(\log ^2k/\log \log k)$$ -approximation Algorithms for the problem, which are tight under popular complexity assumptions. In this paper, we consider the more general Degree-Bounded Directed Steiner Tree (DB-DST) problem, where we are additionally given a degree bound $$d_v$$ on each vertex $$v \in V$$ , and we require that every vertex v in the output tree has at most $$d_v$$ children. We give a quasi-polynomial time $$(O(\log n \log k), O(\log ^2 n))$$ -bicriteria approximation: The Algorithm produces a solution with cost at most $$O(\log n\log k)$$ times the cost of the optimum solution that violates the degree constraints by at most a factor of $$O(\log ^2n)$$ . This is the first non-trivial result for the problem. While our cost-guarantee is nearly optimal, the degree violation factor of $$O(\log ^2n)$$ is an $$O(\log n)$$ -factor away from the approximation lower bound of $$\Omega (\log n)$$ from the set-cover hardness. The hardness result holds even on the special case of the Degree-Bounded Group Steiner Tree problem on trees (DB-GST-T). With the hope of closing the gap, we study the question of whether the degree violation factor can be made tight for this special case. We answer the question in the affirmative by giving an $$(O(\log n\log k), O(\log n))$$ -bicriteria approximation Algorithm for DB-GST-T.},
  archive      = {J_Alg},
  author       = {Guo, Xiangyu and Kortsarz, Guy and Laekhanukit, Bundit and Li, Shi and Vaz, Daniel and Xian, Jiayi},
  doi          = {10.1007/s00453-022-00924-0},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1252-1278},
  shortjournal = {Algorithmica},
  title        = {On approximating degree-bounded network design problems},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online coloring and a new type of adversary for online graph
problems. <em>Alg</em>, <em>84</em>(5), 1232–1251. (<a
href="https://doi.org/10.1007/s00453-021-00920-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new type of adversary for online graph problems thus allowing parametrized analysis of online algorithms with respect to a natural parameter. The new adversary is parameterized by a single integer $$\kappa $$ , which upper bounds the number of connected components that the adversary can use at any time during the presentation of the online graph G. We call this adversary “ $$\kappa $$ -components-bounded”, or $$\kappa $$ -CB for short. On one hand, this adversary is restricted compared to the classical adversary because of the $$\kappa $$ -CB constraint. On the other hand, we seek competitive ratios parameterized only by $$\kappa $$ with no dependence on the input length n, thereby giving the new adversary power to use arbitrarily large inputs. We study online coloring under the $$\kappa $$ -CB adversary. We obtain a finer analysis of the existing algorithms FirstFit and CBIP by computing their competitive ratios on trees and bipartite graphs under the new adversary: (1) Perhaps surprisingly, FirstFit outperforms CBIP on trees; (2) The competitive ratio of CBIP on bipartite graphs is simply $$\kappa $$ . We also study several well known classes of graphs, such as 3-colorable, $$C_k$$ -free, d-inductive, planar, and bounded treewidth, with respect to online coloring under the $$\kappa $$ -CB adversary. We demonstrate that the extra adversarial power of unbounded input length outweighs the restriction on the number of connected components leading to non-existence of competitive algorithms for these classes.},
  archive      = {J_Alg},
  author       = {Li, Yaqiao and Narayan, Vishnu V. and Pankratov, Denis},
  doi          = {10.1007/s00453-021-00920-w},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1232-1251},
  shortjournal = {Algorithmica},
  title        = {Online coloring and a new type of adversary for online graph problems},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online unit clustering and unit covering in higher
dimensions. <em>Alg</em>, <em>84</em>(5), 1213–1231. (<a
href="https://doi.org/10.1007/s00453-021-00916-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the online Unit Clustering and Unit Covering problems in higher dimensions: Given a set of n points in a metric space, that arrive one by one, Unit Clustering asks to partition the points into the minimum number of clusters (subsets) of diameter at most one; whereas Unit Covering asks to cover all points by the minimum number of balls of unit radius. In this paper, we work in $${\mathbb {R}}^d$$ using the $$L_\infty $$ norm. We show that the competitive ratio of any online algorithm (deterministic or randomized) for Unit Clustering is $$\Omega (d)$$ . In particular, it depends on the dimension d, and this resolves an open problem raised by Epstein and van Stee (Theor Comput Sci 407(1–3):85–96, 2008). We also give a randomized online algorithm with competitive ratio $$O(d^2)$$ for Unit Clustering of integer points (i.e., points in $${\mathbb {Z}}^d$$ , $$d\in {\mathbb {N}}$$ , under the $$L_{\infty }$$ norm). We show that the competitive ratio of any deterministic online algorithm for Unit Covering is at least $$2^d$$ . This ratio is the best possible, as it can be attained by a simple deterministic algorithm that assigns points to a predefined set of unit hypercubes. We complement these results with some additional lower bounds for related problems in higher dimensions.},
  archive      = {J_Alg},
  author       = {Dumitrescu, Adrian and Tóth, Csaba D.},
  doi          = {10.1007/s00453-021-00916-6},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1213-1231},
  shortjournal = {Algorithmica},
  title        = {Online unit clustering and unit covering in higher dimensions},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph modification for edge-coloured and signed graph
homomorphism problems: Parameterized and classical complexity.
<em>Alg</em>, <em>84</em>(5), 1183–1212. (<a
href="https://doi.org/10.1007/s00453-021-00918-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the complexity of graph modification problems with respect to homomorphism-based colouring properties of edge-coloured graphs. A homomorphism from an edge-coloured graph G to an edge-coloured graph H is a vertex-mapping from G to H that preserves adjacencies and edge-colours. We consider the property of having a homomorphism to a fixed edge-coloured graph H, which generalises the classic vertex-colourability property. The question we are interested in is the following: given an edge-coloured graph G, can we perform k graph operations so that the resulting graph admits a homomorphism to H? The operations we consider are vertex-deletion, edge-deletion and switching (an operation that permutes the colours of the edges incident to a given vertex). Switching plays an important role in the theory of signed graphs, that are 2-edge-coloured graphs whose colours are the signs $$+$$ and −. We denote the corresponding problems (parameterized by k) by VD-H -Colouring, ED-H-Colouring and SW-H-Colouring. These problems generalise the extensively studied H-Colouring problem (where one has to decide if an input graph admits a homomorphism to a fixed target H). For 2-edge-coloured H, it is known that H-Colouring already captures the complexity of all fixed-target Constraint Satisfaction Problems. Our main focus is on the case where H is an edge-coloured graph with at most two vertices, a case that is already interesting since it includes standard problems such as Vertex Cover, Odd Cycle Transversal and Edge Bipartization. For such a graph H, we give a P/NP-complete complexity dichotomy for all three VD-H -Colouring, ED-H-Colouring and SW-H-Colouring problems. Then, we address their parameterized complexity. We show that all VD-H -Colouring and ED-H-Colouring problems for such H are FPT. This is in contrast with the fact that already for some H of order 3, unless P = NP, none of the three considered problems is in XP, since 3- Colouring is NP-complete. We show that the situation is different for SW-H-Colouring: there are three 2-edge-coloured graphs H of order 2 for which SW-H-Colouring is W[1]-hard, and assuming the ETH, admits no algorithm in time $$f(k)n^{o(k)}$$ for inputs of size n and for any computable function f. For the other cases, SW-H-Colouring is FPT.},
  archive      = {J_Alg},
  author       = {Foucaud, Florent and Hocquard, Hervé and Lajou, Dimitri and Mitsou, Valia and Pierron, Théo},
  doi          = {10.1007/s00453-021-00918-4},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1183-1212},
  shortjournal = {Algorithmica},
  title        = {Graph modification for edge-coloured and signed graph homomorphism problems: Parameterized and classical complexity},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Linear-time recognition of double-threshold graphs.
<em>Alg</em>, <em>84</em>(4), 1163–1181. (<a
href="https://doi.org/10.1007/s00453-021-00921-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A graph $$G = (V,E)$$ is a double-threshold graph if there exist a vertex-weight function $$w :V \rightarrow \mathbb {R}$$ and two real numbers $$\mathtt {lb}, \mathtt {ub}\in \mathbb {R}$$ such that $$uv \in E$$ if and only if $$\mathtt {lb}\le \mathtt {w}(u) + \mathtt {w}(v) \le \mathtt {ub}$$ . In the literature, those graphs are studied also as the pairwise compatibility graphs that have stars as their underlying trees. We give a new characterization of double-threshold graphs that relates them to bipartite permutation graphs. Using the new characterization, we present a linear-time algorithm for recognizing double-threshold graphs. Prior to our work, the fastest known algorithm by Xiao and Nagamochi [Algorithmica 2020] ran in $$O(n^{3} m)$$ time, where n and m are the numbers of vertices and edges, respectively.},
  archive      = {J_Alg},
  author       = {Kobayashi, Yusuke and Okamoto, Yoshio and Otachi, Yota and Uno, Yushi},
  doi          = {10.1007/s00453-021-00921-9},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {1163-1181},
  shortjournal = {Algorithmica},
  title        = {Linear-time recognition of double-threshold graphs},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A #SAT algorithm for small constant-depth circuits with PTF
gates. <em>Alg</em>, <em>84</em>(4), 1132–1162. (<a
href="https://doi.org/10.1007/s00453-021-00915-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that there is a better-than-brute-force algorithm that, when given a small constant-depth Boolean circuit C made up of gates that compute constant-degree Polynomial Threshold functions or PTFs (i.e., Boolean functions that compute signs of constant-degree polynomials), counts the number of satisfying assignments to C in significantly better than brute-force time. Formally, for any constants d, k, there is an $$\varepsilon &gt; 0$$ such that the zero-error randomized algorithm counts the number of satisfying assignments to a given depth-d circuit C made up of k-PTF gates such that C has at most $$n^{1+\varepsilon }$$ many wires. The algorithm runs in time $$2^{n-n^{\Omega (\varepsilon )}}.$$ Before our result, no algorithm for beating brute-force search was known for counting the number of satisfying assignments even for a single degree-k PTF (which is a depth-1 circuit with linearly many wires).We give two different algorithms for the case of a single PTF. The first uses a learning algorithm for learning degree-1 PTFs (or Linear Threshold Functions) using comparison queries due to Kane, Lovett and Moran (STOC 2018), and the second uses a proof of Hofmeister (COCOON 1996) for converting a degree-1 PTF to a depth-two threshold circuit with small weights. We show that both these ideas fit nicely into a memoization approach that yields the #SAT algorithms.},
  archive      = {J_Alg},
  author       = {Bajpai, Swapnam and Krishan, Vaibhav and Kush, Deepanshu and Limaye, Nutan and Srinivasan, Srikanth},
  doi          = {10.1007/s00453-021-00915-7},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {1132-1162},
  shortjournal = {Algorithmica},
  title        = {A #SAT algorithm for small constant-depth circuits with PTF gates},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Posimodular function optimization. <em>Alg</em>,
<em>84</em>(4), 1107–1131. (<a
href="https://doi.org/10.1007/s00453-021-00910-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A function $$f: 2^V \rightarrow \mathbb {R}$$ on a finite set V is posimodular if $$f(X)+f(Y) \ge f(X{\setminus } Y)+f(Y{\setminus } X)$$ , for all $$X,Y\subseteq V$$ . Posimodular functions often arise in combinatorial optimization such as undirected cut functions. We consider the problem of finding a nonempty subset X minimizing f(X), when the posimodular function f is given by oracle access. We show that posimodular function minimization requires exponential time, contrasting with the polynomial solvability of submodular function minimization that forms another generalization of cut functions. On the other hand, the problem is fixed-parameter tractable in terms of the size D of the image (or range) of f. In more detail, we show that $$\varOmega (2^{0.32n} T_f)$$ time is necessary and $$O(2^{0.92n}T_f)$$ sufficient, where $$T_f$$ denotes the time for one function evaluation and $$n = |V|$$ . When the image of f is $$D={0,1,\ldots ,d}$$ for integer d, $$O(2^{1.218d}nT_f)$$ time is sufficient. We can also generate all sets minimizing f in time $$2^{O(d)} n^2 T_f$$ . Finally, we also consider the problem of maximizing a given posimodular function, showing that it requires at least $$2^{n-1}T_f$$ time in general, while it has time complexity $$\varTheta ({n \atopwithdelims ()d-1}T_f)$$ when $$D={0,1,\ldots , d}$$ is the image of f, for integer $$d=O(n^{1/4})$$ .},
  archive      = {J_Alg},
  author       = {Halldórsson, Magnús M. and Ishii, Toshimasa and Makino, Kazuhisa and Takazawa, Kenjiro},
  doi          = {10.1007/s00453-021-00910-y},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {1107-1131},
  shortjournal = {Algorithmica},
  title        = {Posimodular function optimization},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast and longest rollercoasters. <em>Alg</em>,
<em>84</em>(4), 1081–1106. (<a
href="https://doi.org/10.1007/s00453-021-00908-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For $$k\ge 3$$ , a k-rollercoaster is a sequence of numbers whose every maximal contiguous subsequence, that is increasing or decreasing, has length at least k; 3-rollercoasters are called simply rollercoasters. Given a sequence of distinct real numbers, we are interested in computing its maximum-length (not necessarily contiguous) subsequence that is a k-rollercoaster. Biedl et al. (in: ICALP, volume 107 of LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, pp 18:1–18:15, 2018) have shown that each sequence of n distinct real numbers contains a rollercoaster of length at least $$\lceil n/2\rceil $$ for $$n&gt;7$$ , and that a longest rollercoaster contained in such a sequence can be computed in $$O(n\log n)$$ -time (or faster, in $$O(n \log \log n)$$ time, when the input sequence is a permutation of $${1,\ldots ,n}$$ ). They have also shown that every sequence of $$n\geqslant (k-1)^2+1$$ distinct real numbers contains a k-rollercoaster of length at least $$\frac{n}{2(k-1)}-\frac{3k}{2}$$ , and gave an $$O(nk\log n)$$ -time (respectively, $$O(n k\log \log n)$$ -time) algorithm computing a longest k-rollercoaster in a sequence of length n (respectively, a permutation of $${1,\ldots ,n}$$ ). In this paper, we give an $$O(nk^2)$$ -time algorithm computing the length of a longest k-rollercoaster contained in a sequence of n distinct real numbers; hence, for constant k, our algorithm computes the length of a longest k-rollercoaster in optimal linear time. The algorithm can be easily adapted to output the respective k-rollercoaster. In particular, this improves the results of Biedl et al. (2018), by showing that a longest rollercoaster can be computed in optimal linear time. We also present an algorithm computing the length of a longest k-rollercoaster in $$O(n \log ^2 n)$$ -time, that is, subquadratic even for large values of $$k\le n$$ . Again, the rollercoaster can be easily retrieved. Finally, we show an $$\Omega (n \log k)$$ lower bound for the number of comparisons in any comparison-based algorithm computing the length of a longest k-rollercoaster.},
  archive      = {J_Alg},
  author       = {Gawrychowski, Paweł and Manea, Florin and Serafin, Radosław},
  doi          = {10.1007/s00453-021-00908-6},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {1081-1106},
  shortjournal = {Algorithmica},
  title        = {Fast and longest rollercoasters},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Linear-time algorithms for maximum-weight induced matchings
and minimum chain covers in convex bipartite graphs. <em>Alg</em>,
<em>84</em>(4), 1064–1080. (<a
href="https://doi.org/10.1007/s00453-021-00904-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A bipartite graph $$G=(U,V,E)$$ is convex if the vertices in V can be linearly ordered such that for each vertex $$u\in U$$ , the neighbors of u are consecutive in the ordering of V. An induced matching H of G is a matching for which no edge of E connects endpoints of two different edges of H. We show that in a convex bipartite graph with n vertices and m weighted edges, an induced matching of maximum total weight can be computed in $$O(n+m)$$ time. An unweighted convex bipartite graph has a representation of size O(n) that records for each vertex $$u\in U$$ the first and last neighbor in the ordering of V. Given such a compact representation, we compute an induced matching of maximum cardinality in O(n) time. In convex bipartite graphs, maximum-cardinality induced matchings are dual to minimum chain covers. A chain cover is a covering of the edge set by chain subgraphs, that is, subgraphs that do not contain induced matchings of more than one edge. Given a compact representation, we compute a representation of a minimum chain cover in O(n) time. If no compact representation is given, the cover can be computed in $$O(n+m)$$ time. All of our algorithms achieve optimal linear running time for the respective problem and model, and they improve and generalize the previous results in several ways: The best algorithms for the unweighted problem versions had a running time of $$O(n^2)$$ (Brandstädt et al. in Theor. Comput. Sci. 381(1–3):260–265, 2007. https://doi.org/10.1016/j.tcs.2007.04.006 ). The weighted case has not been considered before.},
  archive      = {J_Alg},
  author       = {Klemz, Boris and Rote, Günter},
  doi          = {10.1007/s00453-021-00904-w},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {1064-1080},
  shortjournal = {Algorithmica},
  title        = {Linear-time algorithms for maximum-weight induced matchings and minimum chain covers in convex bipartite graphs},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On proper labellings of graphs with minimum label sum.
<em>Alg</em>, <em>84</em>(4), 1030–1063. (<a
href="https://doi.org/10.1007/s00453-021-00903-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 1–2–3 Conjecture, raised by Karoński, Łuczak and Thomason, states that almost every graph G admits a proper 3-labelling, i.e., a labelling of the edges with 1, 2, 3 such that no two adjacent vertices are incident to the same sum of labels. Another interpretation of this conjecture, that may be attributed to Chartrand et al., is that almost every graph G can be turned into a locally irregular multigraph M, i.e., with no two adjacent vertices having the same degree, by replacing each of its edges by at most three parallel edges. In other words, for almost every graph G there should be a locally irregular multigraph M with the same adjacencies and having a relatively small number of edges. The 1–2–3 Conjecture, if true, would indeed imply that there is such an M with $$|E(M)| \le 3|E(G)|$$ . In this work, we study proper labellings of graphs with the extra requirement that the sum of assigned labels must be as small as possible. In other words, given a graph G, we are looking for a locally irregular multigraph $$M^*$$ with the smallest number of edges possible that can be obtained from G by multiplying edges. This problem is actually quite different from the 1–2–3 Conjecture, as we prove that there is no absolute constant k such that $$M^*$$ can always be obtained from G by replacing each edge with at most k parallel edges. We investigate several aspects of this problem, covering algorithmic and combinatorial aspects. In particular, we prove that the problem of designing proper labellings with minimum label sum is $${\mathcal {N}}{\mathcal {P}}$$ -hard in general, but solvable in polynomial time for graphs with bounded treewidth. We also conjecture that for almost every connected graph G there should be a proper labelling with label sum at most 2|E(G)|, which we verify for several classes of graphs.},
  archive      = {J_Alg},
  author       = {Bensmail, Julien and Fioravantes, Foivos and Nisse, Nicolas},
  doi          = {10.1007/s00453-021-00903-x},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {1030-1063},
  shortjournal = {Algorithmica},
  title        = {On proper labellings of graphs with minimum label sum},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic averaging load balancing on cycles. <em>Alg</em>,
<em>84</em>(4), 1007–1029. (<a
href="https://doi.org/10.1007/s00453-021-00905-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the following dynamic load-balancing process: given an underlying graph G with n nodes, in each step $$t\ge 0$$ , a random edge is chosen, one unit of load is created, and placed at one of the endpoints. In the same step, assuming that loads are arbitrarily divisible, the two nodes balance their loads by averaging them. We are interested in the expected gap between the minimum and maximum loads at nodes as the process progresses, and its dependence on n and on the graph structure. Peres et al. (Random Struct Algorithms 47(4):760–775, 2015) studied the variant of this process, where the unit of load is placed in the least loaded endpoint of the chosen edge, and the averaging is not performed. In the case of dynamic load balancing on the cycle of length n the only known upper bound on the expected gap is of order $$\mathcal {O}( n \log n )$$ , following from the majorization argument due to the same work. In this paper, we leverage the power of averaging and provide an improved upper bound of $$\mathcal {O} ( \sqrt{n} \log n )$$ . We introduce a new potential analysis technique, which enables us to bound the difference in load between k-hop neighbors on the cycle, for any $$k \le n/2$$ . We complement this with a “gap covering” argument, which bounds the maximum value of the gap by bounding its value across all possible subsets of a certain structure, and recursively bounding the gaps within each subset. We also show that our analysis can be extended to the specific instance of Harary graphs. On the other hand, we prove that the expected second moment of the gap is lower bounded by $$\Omega (n)$$ . Additionally, we provide experimental evidence that our upper bound on the gap is tight up to a logarithmic factor.},
  archive      = {J_Alg},
  author       = {Alistarh, Dan and Nadiradze, Giorgi and Sabour, Amirmojtaba},
  doi          = {10.1007/s00453-021-00905-9},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {1007-1029},
  shortjournal = {Algorithmica},
  title        = {Dynamic averaging load balancing on cycles},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A refined branching algorithm for the maximum satisfiability
problem. <em>Alg</em>, <em>84</em>(4), 982–1006. (<a
href="https://doi.org/10.1007/s00453-022-00938-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Maximum satisfiability problem (MaxSAT) is a fundamental NP-hard problem which has significant applications in many areas. Based on refined observations, we derive a branching algorithm of running time $$O^{*}(1.2989^m)$$ for the MaxSAT problem, where m denotes the number of clauses in the given CNF formula. Our algorithm considerably improves the previous best result $$O^*(1.3248^m)$$ published in 2004. For our purpose, we derive improved branching strategies for variables of degrees 3, 4, and 5. The worst case of our branching algorithm is at certain degree-4 variables. To serve the branching rules, we also propose a variety of reduction rules which can be exhaustively applied in polynomial time.},
  archive      = {J_Alg},
  author       = {Li, Wenjun and Xu, Chao and Yang, Yongjie and Chen, Jianer and Wang, Jianxin},
  doi          = {10.1007/s00453-022-00938-8},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {982-1006},
  shortjournal = {Algorithmica},
  title        = {A refined branching algorithm for the maximum satisfiability problem},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parameter analysis for guarding terrains. <em>Alg</em>,
<em>84</em>(4), 961–981. (<a
href="https://doi.org/10.1007/s00453-021-00913-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Terrain Guarding problem is a well-known variant of the famous Art Gallery problem. Only second to Art Gallery, it is the most well-studied visibility problem in Discrete and Computational Geometry, which has also attracted attention from the viewpoint of Parameterized complexity. In this paper, we focus on the parameterized complexity of Terrain Guarding (both discrete and continuous) with respect to two natural parameters. First we show that, when parameterized by the number r of reflex vertices in the input terrain, the problem has a polynomial kernel. We also show that, when parameterized by the number c of minima in the terrain, Discrete Orthogonal Terrain Guarding has an XP algorithm.},
  archive      = {J_Alg},
  author       = {Agrawal, Akanksha and Kolay, Sudeshna and Zehavi, Meirav},
  doi          = {10.1007/s00453-021-00913-9},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {961-981},
  shortjournal = {Algorithmica},
  title        = {Parameter analysis for guarding terrains},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A practical fixed-parameter algorithm for constructing
tree-child networks from multiple binary trees. <em>Alg</em>,
<em>84</em>(4), 917–960. (<a
href="https://doi.org/10.1007/s00453-021-00914-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the first fixed-parameter algorithm for constructing a tree-child phylogenetic network that displays an arbitrary number of binary input trees and has the minimum number of reticulations among all such networks. The algorithm uses the recently introduced framework of cherry picking sequences and runs in $$O((8k)^k \mathrm {poly}(n, t))$$ time, where n is the number of leaves of every tree, t is the number of trees, and k is the reticulation number of the constructed network. Moreover, we provide an efficient parallel implementation of the algorithm and show that it can deal with up to 100 input trees on a standard desktop computer, thereby providing a major improvement over previous phylogenetic network construction methods.},
  archive      = {J_Alg},
  author       = {van Iersel, Leo and Janssen, Remie and Jones, Mark and Murakami, Yukihiro and Zeh, Norbert},
  doi          = {10.1007/s00453-021-00914-8},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {917-960},
  shortjournal = {Algorithmica},
  title        = {A practical fixed-parameter algorithm for constructing tree-child networks from multiple binary trees},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Streaming dictionary matching with mismatches. <em>Alg</em>,
<em>84</em>(4), 896–916. (<a
href="https://doi.org/10.1007/s00453-021-00876-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the k-mismatch problem we are given a pattern of length n and a text and must find all locations where the Hamming distance between the pattern and the text is at most k. A series of recent breakthroughs have resulted in an ultra-efficient streaming algorithm for this problem that requires only $$\mathcal {O}(k \log \frac{n}{k})$$ space and $$\mathcal {O}(\log \frac{n}{k} (\sqrt{k \log k} + \log ^3 n))$$ time per letter (Clifford, Kociumaka, Porat, SODA 2019). In this work, we consider a strictly harder problem called dictionary matching with k mismatches. In this problem, we are given a dictionary of d patterns, where the length of each pattern is at most n, and must find all substrings of the text that are within Hamming distance k from one of the patterns. We develop a streaming algorithm for this problem with $$\mathcal {O}(k d \log ^k d \mathop {\mathrm {polylog} {\,n}})$$ space and $$\mathcal {O}(k \log ^{k} d \mathop {\mathrm {polylog} {\,n}} + |\mathrm {output}|)$$ time per position of the text. The algorithm is randomised and outputs correct answers with high probability. On the lower bound side, we show that any streaming algorithm for dictionary matching with k mismatches requires $$\varOmega (k d)$$ bits of space.},
  archive      = {J_Alg},
  author       = {Gawrychowski, Paweł and Starikovskaya, Tatiana},
  doi          = {10.1007/s00453-021-00876-x},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {896-916},
  shortjournal = {Algorithmica},
  title        = {Streaming dictionary matching with mismatches},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parameterized complexity of <span
class="math display">(<em>A</em>, <em>ℓ</em>)</span> -path packing.
<em>Alg</em>, <em>84</em>(4), 871–895. (<a
href="https://doi.org/10.1007/s00453-021-00875-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a graph $$G = (V,E)$$ , $$A \subseteq V$$ , and integers k and $$\ell $$ , the $$(A,\ell )$$ -Path Packing problem asks to find k vertex-disjoint paths of length exactly $$\ell $$ that have endpoints in A and internal points in $$V{\setminus }A$$ . We study the parameterized complexity of this problem with parameters |A|, $$\ell $$ , k, treewidth, pathwidth, and their combinations. We present sharp complexity contrasts with respect to these parameters. Among other results, we show that the problem is polynomial-time solvable when $$\ell \le 3$$ , while it is NP-complete for constant $$\ell \ge 4$$ . We also show that the problem is W[1]-hard parameterized by pathwidth $${}+|A|$$ , while it is fixed-parameter tractable parameterized by treewidth $${}+\ell $$ . Additionally, we study a variant called Short A -Path Packing that asks to find k vertex-disjoint paths of length at most $$\ell $$ . We show that all our positive results on the exact-length version can be translated to this version and show the hardness of the cases where |A| or $$\ell $$ is a constant.},
  archive      = {J_Alg},
  author       = {Belmonte, Rémy and Hanaka, Tesshu and Kanzaki, Masaaki and Kiyomi, Masashi and Kobayashi, Yasuaki and Kobayashi, Yusuke and Lampis, Michael and Ono, Hirotaka and Otachi, Yota},
  doi          = {10.1007/s00453-021-00875-y},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {871-895},
  shortjournal = {Algorithmica},
  title        = {Parameterized complexity of $$(A,\ell )$$ -path packing},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An axiomatic approach to time-dependent shortest path
oracles. <em>Alg</em>, <em>84</em>(3), 815–870. (<a
href="https://doi.org/10.1007/s00453-021-00922-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing shortest paths in networks that exhibit a time-dependent metric is a core routine for many applications, with route planning in road networks being a prime example. In this work, we present an axiomatic approach which shows that for directed networks that satisfy certain properties we can provide time-dependent distance oracles that provably exhibit subquadratic preprocessing time and space (independent of the metric’s amount of disconcavity), query time sublinear on the network size or the actual Dijkstra rank of the query at hand (measuring the distance ordering of the destination from the origin), and small stretch factor (approximation error).},
  archive      = {J_Alg},
  author       = {Kontogiannis, Spyros and Wagner, Dorothea and Zaroliagis, Christos},
  doi          = {10.1007/s00453-021-00922-8},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {815-870},
  shortjournal = {Algorithmica},
  title        = {An axiomatic approach to time-dependent shortest path oracles},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the complexity of recognizing wheeler graphs.
<em>Alg</em>, <em>84</em>(3), 784–814. (<a
href="https://doi.org/10.1007/s00453-021-00917-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, several compressed indexes based on variants of the Burrows–Wheeler transform have been introduced. Some of these are used to index structures far more complex than a single string, as was originally done with the FM-index (Ferragina and Manzini in J. ACM 52(4):552–581, https://doi.org/10.1145/1082036.1082039, 2005). As such, there has been an increasing effort to better understand under which conditions such an indexing scheme is possible. This has led to the introduction of Wheeler graphs (Gagie et al. in Theor Comput Sci 698:67–78, https://doi.org/10.1016/j.tcs.2017.06.016, 2017). Gagie et al. showed that de Bruijn graphs, generalized compressed suffix arrays, and several other BWT related structures can be represented as Wheeler graphs, and that Wheeler graphs can be indexed in a space-efficient way. Hence, being able to recognize whether a given graph is a Wheeler graph, or being able to approximate a given graph by a Wheeler graph, could have numerous applications in indexing. Here we resolve the open question of whether there exists an efficient algorithm for recognizing if a given graph is a Wheeler graph. We show: The above findings suggest that most problems under this theme are computationally difficult. However, we identify a class of graphs for which the recognition problem is polynomial-time solvable, raising the question of which properties determine this problem’s difficulty.},
  archive      = {J_Alg},
  author       = {Gibney, Daniel and Thankachan, Sharma V.},
  doi          = {10.1007/s00453-021-00917-5},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {784-814},
  shortjournal = {Algorithmica},
  title        = {On the complexity of recognizing wheeler graphs},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enumeration of maximal common subsequences between two
strings. <em>Alg</em>, <em>84</em>(3), 757–783. (<a
href="https://doi.org/10.1007/s00453-021-00898-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A maximal common subsequence (MCS) between two strings X and Y is an inclusion-maximal subsequence of both X and Y. MCSs are a natural generalization of the classical concept of longest common subsequence (LCS), which can be seen as a longest MCS. We study the problem of efficiently listing all the distinct MCSs between two strings. As discussed in the paper, this problem is algorithmically challenging as the same MCS cannot be listed multiple times: for example, dynamic programming [Fraser et al., CPM 1998] incurs in an exponential waste of time, and a recent algorithm for finding an MCS [Sakai, CPM 2018] does not seem to immediately extend to listing. We follow an alternative and novel graph-based approach, proposing the first output-sensitive algorithm for this problem: it takes polynomial time in n per MCS found, where $$n = \max { |X|, |Y|}$$ , with polynomial preprocessing time and space.},
  archive      = {J_Alg},
  author       = {Conte, Alessio and Grossi, Roberto and Punzi, Giulia and Uno, Takeaki},
  doi          = {10.1007/s00453-021-00898-5},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {757-783},
  shortjournal = {Algorithmica},
  title        = {Enumeration of maximal common subsequences between two strings},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computing the maximum exponent in a stream. <em>Alg</em>,
<em>84</em>(3), 742–756. (<a
href="https://doi.org/10.1007/s00453-021-00883-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the streaming version of the following problem: given an input string s of length n, find the maximum exponent of a substring of s. We prove that any algorithm deciding, w.h.p., whether a string contains a square, uses memory of size $$\varOmega (n)$$ , and thus does not satisfy the limitations of the streaming model. Thus the considered problem has no exact solution in the streaming model. Our main result is a Monte Carlo algorithm which computes the maximum exponent up to an additive error $$\varepsilon &lt;1/2$$ : it outputs a number $$\alpha $$ such that s has a substring of exponent $$\alpha $$ but no substrings of exponent $$\alpha +\varepsilon $$ or higher. The algorithm uses $$\mathcal {O}(\frac{\log ^2 n}{\varepsilon })$$ words of memory and performs $$\mathcal {O}(\log n)$$ operations, including dictionary operations, per input symbol.},
  archive      = {J_Alg},
  author       = {Merkurev, Oleg and Shur, Arseny M.},
  doi          = {10.1007/s00453-021-00883-y},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {742-756},
  shortjournal = {Algorithmica},
  title        = {Computing the maximum exponent in a stream},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Safety in s-t paths, trails and walks. <em>Alg</em>,
<em>84</em>(3), 719–741. (<a
href="https://doi.org/10.1007/s00453-021-00877-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a directed graph G and a pair of nodes s and t, an s-t bridge of G is an edge whose removal breaks all s-t paths of G (and thus appears in all s-t paths). Computing all s-t bridges of G is a basic graph problem, solvable in linear time. In this paper, we consider a natural generalisation of this problem, with the notion of “safety” from bioinformatics. We say that a walk W is safe with respect to a set $${\mathcal {W}}$$ of s-t walks, if W is a subwalk of all walks in $${\mathcal {W}}$$ . We start by considering the maximal safe walks when $${\mathcal {W}}$$ consists of: all s-t paths, all s-t trails, or all s-t walks of G. We show that the solutions for the first two problems immediately follow from finding all s-t bridges after incorporating simple characterisations. However, solving the third problem requires non-trivial techniques for incorporating its characterisation. In particular, we show that there exists a compact representation computable in linear time, that allows outputting all maximal safe walks in time linear in their length. Our solutions also directly extend to multigraphs, except for the second problem, which requires a more involved approach. We further generalise these problems, by assuming that safety is defined only with respect to a subset of visible edges. Here we prove a dichotomy between the s-t paths and s-t trails cases, and the s-t walks case: the former two are NP-hard, while the latter is solvable with the same complexity as when all edges are visible. We also show that the same complexity results hold for the analogous generalisations of s-t articulation points (nodes appearing in all s-t paths). We thus obtain the best possible results for natural “safety”-generalisations of these two fundamental graph problems. Moreover, our algorithms are simple and do not employ any complex data structures, making them ideal for use in practice.},
  archive      = {J_Alg},
  author       = {Cairo, Massimo and Khan, Shahbaz and Rizzi, Romeo and Schmidt, Sebastian and Tomescu, Alexandru I.},
  doi          = {10.1007/s00453-021-00877-w},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {719-741},
  shortjournal = {Algorithmica},
  title        = {Safety in s-t paths, trails and walks},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive succinctness. <em>Alg</em>, <em>84</em>(3),
694–718. (<a href="https://doi.org/10.1007/s00453-021-00872-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representing a static set of integers S, $$|S| = n$$ from a finite universe $$U = [1{..}u]$$ is a fundamental task in computer science. Our concern is to represent S in small space while supporting the operations of $$\mathsf {rank}$$ and $$\mathsf {select}$$ on S; if S is viewed as its characteristic vector, the problem becomes that of representing a bit-vector, which is arguably the most fundamental building block of succinct data structures. Although there is an information-theoretic lower bound of $${\mathcal {B}}(n, u)= \lg {u\atopwithdelims ()n}$$ bits on the space needed to represent S, this applies to worst-case (random) sets S, and sets found in practical applications are compressible. We focus on the case where elements of S contain runs of| $$\ell &gt;1$$ consecutive elements, one that occurs in many practical situations. Let $${\mathcal {C}}^{{\scriptscriptstyle (}n{\scriptscriptstyle )}}$$ denote the class of $${u\atopwithdelims ()n}$$ distinct sets of $$n$$ elements over the universe $$[1{..}u]$$ . Let also $${\mathcal {C}}^{{\scriptscriptstyle (}n{\scriptscriptstyle )}}_{g}\subset {\mathcal {C}}^{{\scriptscriptstyle (}n{\scriptscriptstyle )}}$$ contain the sets whose $$n$$ elements are arranged in $$g \le n$$ runs of $$\ell _i \ge 1$$ consecutive elements from U for $$i=1,\ldots , g$$ , and let $${\mathcal {C}}^{{\scriptscriptstyle (}n{\scriptscriptstyle )}}_{g,r}\subset {\mathcal {C}}^{{\scriptscriptstyle (}n{\scriptscriptstyle )}}_{g}$$ contain all sets that consist of g runs, such that $$r \le g$$ of them have at least 2 elements. This paper yields the following insights and contributions related to $$\mathsf {rank}$$ / $$\mathsf {select}$$ succinct data structures:},
  archive      = {J_Alg},
  author       = {Arroyuelo, Diego and Raman, Rajeev},
  doi          = {10.1007/s00453-021-00872-1},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {694-718},
  shortjournal = {Algorithmica},
  title        = {Adaptive succinctness},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computing minimal unique substrings for a sliding window.
<em>Alg</em>, <em>84</em>(3), 670–693. (<a
href="https://doi.org/10.1007/s00453-021-00864-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A substring u of a string T is called a minimal unique substring (MUS) of T if u occurs exactly once in T and any proper substring of u occurs at least twice in T. In this paper, we study the problem of computing MUSs for a sliding window over a given string T. We first show how the set of MUSs can change when the window slides over T. We then present an $$O(n\log \sigma &#39;)$$ -time and O(d)-space algorithm to compute MUSs for a sliding window of size d over the input string T of length n, where $$\sigma &#39;\le d$$ is the maximum number of distinct characters in every window.},
  archive      = {J_Alg},
  author       = {Mieno, Takuya and Fujishige, Yuta and Nakashima, Yuto and Inenaga, Shunsuke and Bannai, Hideo and Takeda, Masayuki},
  doi          = {10.1007/s00453-021-00864-1},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {670-693},
  shortjournal = {Algorithmica},
  title        = {Computing minimal unique substrings for a sliding window},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Space efficient merging of de bruijn graphs and wheeler
graphs. <em>Alg</em>, <em>84</em>(3), 639–669. (<a
href="https://doi.org/10.1007/s00453-021-00855-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The merging of succinct data structures is a well established technique for the space efficient construction of large succinct indexes. In the first part of the paper we propose a new algorithm for merging succinct representations of de Bruijn graphs. Our algorithm has the same asymptotic cost of the state of the art algorithm for the same problem but it uses less than half of its working space. A novel important feature of our algorithm, not found in any of the existing tools, is that it can compute the Variable Order succinct representation of the union graph within the same asymptotic time/space bounds. In the second part of the paper we consider the more general problem of merging succinct representations of Wheeler graphs, a recently introduced graph family which includes as special cases de Bruijn graphs and many other known succinct indexes based on the BWT or one of its variants. In this paper we provide a space efficient algorithm for Wheeler graph merging; our algorithm works under the assumption that the union of the input Wheeler graphs has an ordering that satisfies the Wheeler conditions and which is compatible with the ordering of the original graphs.},
  archive      = {J_Alg},
  author       = {Egidi, Lavinia and Louza, Felipe A. and Manzini, Giovanni},
  doi          = {10.1007/s00453-021-00855-2},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {639-669},
  shortjournal = {Algorithmica},
  title        = {Space efficient merging of de bruijn graphs and wheeler graphs},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comparative study of dictionary matching with gaps:
Limitations, techniques and challenges. <em>Alg</em>, <em>84</em>(3),
590–638. (<a href="https://doi.org/10.1007/s00453-021-00851-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber security is a critical modern concern. Network intrusion detection systems (NIDS) perform protocol analysis, content searching and content matching, in order to detect harmful software. The high performance demands of NIDS applications in both speed and space consumption, as well as the diverse characteristics of the scenario conditions, have motivated a recent line of research on several formal problems all within the broad scope of dictionary matching with gaps. The goal of this paper is to supply a comparative survey of this line of research in terms of the problems, the formally proven limitations of any solution suggested, the techniques developed to deal with the limitations and different problems, to supply complementary techniques, and finally, to point out existing challenges still to be handled by future work.},
  archive      = {J_Alg},
  author       = {Levy, Avivit and Shalom, B. Riva},
  doi          = {10.1007/s00453-021-00851-6},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {590-638},
  shortjournal = {Algorithmica},
  title        = {A comparative study of dictionary matching with gaps: Limitations, techniques and challenges},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). K-approximate quasiperiodicity under hamming and edit
distance. <em>Alg</em>, <em>84</em>(3), 566–589. (<a
href="https://doi.org/10.1007/s00453-021-00842-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quasiperiodicity in strings was introduced almost 30 years ago as an extension of string periodicity. The basic notions of quasiperiodicity are cover and seed. A cover of a text T is a string whose occurrences in T cover all positions of T. A seed of text T is a cover of a superstring of T. In various applications exact quasiperiodicity is still not sufficient due to the presence of errors. We consider approximate notions of quasiperiodicity, for which we allow approximate occurrences in T with a small Hamming, Levenshtein or weighted edit distance. In previous work Sim et al. (J Korea Inf Sci Soc 29(1):16–21, 2002) and Christodoulakis et al. (J Autom Lang Comb 10(5/6), 609–626, 2005) showed that computing approximate covers and seeds, respectively, under weighted edit distance is NP-hard. They, therefore, considered restricted approximate covers and seeds which need to be factors of the original string T and presented polynomial-time algorithms for computing them. Further algorithms, considering approximate occurrences with Hamming distance bounded by k, were given in several contributions by Guth et al. They also studied relaxed approximate quasiperiods. We present more efficient algorithms for computing restricted approximate covers and seeds. In particular, we improve upon the complexities of many of the aforementioned algorithms, also for relaxed quasiperiods. Our solutions are especially efficient if the number (or total cost) of allowed errors is small. We also show conditional lower bounds for computing restricted approximate covers and prove NP-hardness of computing non-restricted approximate covers and seeds under the Hamming distance.},
  archive      = {J_Alg},
  author       = {Kędzierski, Aleksander and Radoszewski, Jakub},
  doi          = {10.1007/s00453-021-00842-7},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {566-589},
  shortjournal = {Algorithmica},
  title        = {K-approximate quasiperiodicity under hamming and edit distance},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue of algorithmica for the 28th london
stringology days &amp; london algorithmic workshop (LSD &amp; LAW).
<em>Alg</em>, <em>84</em>(3), 565. (<a
href="https://doi.org/10.1007/s00453-021-00901-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  author       = {Alzamel, Mai and Iliopoulos, Costas S. and Letsios, Dimitrios and Prezza, Nicola},
  doi          = {10.1007/s00453-021-00901-z},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {565},
  shortjournal = {Algorithmica},
  title        = {Special issue of algorithmica for the 28th london stringology days &amp; london algorithmic workshop (LSD &amp; LAW)},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Matching regular expressions on uncertain data.
<em>Alg</em>, <em>84</em>(2), 532–564. (<a
href="https://doi.org/10.1007/s00453-021-00906-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study regular expression matching in cases in which the identity of the symbols received is subject to uncertainty. We develop a model of symbol emission and uses a modification of the shortest path algorithm to find optimal matches on the Cartesian Graph of an expression provided that the input is a finite list. In the case of infinite streams, we show that the problem is in general undecidable but, if each symbols is received with probability 0 infinitely often, then with probability 1 the problem is decidable.},
  archive      = {J_Alg},
  author       = {Gil, José Arturo and Santini, Simone},
  doi          = {10.1007/s00453-021-00906-8},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {532-564},
  shortjournal = {Algorithmica},
  title        = {Matching regular expressions on uncertain data},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contraction bidimensionality of geometric intersection
graphs. <em>Alg</em>, <em>84</em>(2), 510–531. (<a
href="https://doi.org/10.1007/s00453-021-00912-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a graph G, we define $$\mathbf{bcg}(G)$$ as the minimum k for which G can be contracted to the uniformly triangulated grid $$\Gamma _{k}$$ . A graph class $${\mathcal {G}}$$ has the SQGC property if every graph $$G\in {\mathcal {G}}$$ has treewidth $$\mathcal {O}(\mathbf{bcg}(G)^{c})$$ for some $$1\le c&lt;2$$ . The SQGC property is important for algorithm design as it defines the applicability horizon of a series of meta-algorithmic results, in the framework of bidimensionality theory, related to fast parameterized algorithms, kernelization, and approximation schemes. These results apply to a wide family of problems, namely problems that are contraction-bidimensional. Our main combinatorial result reveals a wide family of graph classes that satisfy the SQGC property. This family includes, in particular, bounded-degree string graphs. This considerably extends the applicability of bidimensionality theory for contraction bidimensional problems.},
  archive      = {J_Alg},
  author       = {Baste, Julien and Thilikos, Dimitrios M.},
  doi          = {10.1007/s00453-021-00912-w},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {510-531},
  shortjournal = {Algorithmica},
  title        = {Contraction bidimensionality of geometric intersection graphs},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the parameterized complexity of reconfiguration of
connected dominating sets. <em>Alg</em>, <em>84</em>(2), 482–509. (<a
href="https://doi.org/10.1007/s00453-021-00909-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a reconfiguration version of a decision problem $$\mathcal {Q}$$ the input is an instance of $$\mathcal {Q}$$ and two feasible solutions S and T. The objective is to determine whether there exists a step-by-step transformation between S and T such that all intermediate steps also constitute feasible solutions. In this work, we study the parameterized complexity of the Connected Dominating Set Reconfiguration problem (CDS-R). It was shown in previous work that the Dominating Set Reconfiguration problem (DS-R) parameterized by k, the maximum allowed size of a dominating set in a reconfiguration sequence, is fixed-parameter tractable on all graphs that exclude a biclique $$K_{d,d}$$ as a subgraph, for some constant $$d \ge 1$$ . We show that the additional connectivity constraint makes the problem much harder, namely, that CDS-R is W[1]-hard parameterized by $$k+\ell $$ , the maximum allowed size of a dominating set plus the length of the reconfiguration sequence, already on 5-degenerate graphs. On the positive side, we show that CDS-R parameterized by k is fixed-parameter tractable, and in fact admits a polynomial kernel on planar graphs.},
  archive      = {J_Alg},
  author       = {Lokshtanov, Daniel and Mouawad, Amer E. and Panolan, Fahad and Siebertz, Sebastian},
  doi          = {10.1007/s00453-021-00909-5},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {482-509},
  shortjournal = {Algorithmica},
  title        = {On the parameterized complexity of reconfiguration of connected dominating sets},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Additive approximation of generalized turán questions.
<em>Alg</em>, <em>84</em>(2), 464–481. (<a
href="https://doi.org/10.1007/s00453-021-00899-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For graphs G and T, and a family of graphs $$\mathcal {F}$$ let $$\mathrm {ex}(G,T,\mathcal {F})$$ denote the maximum possible number of copies of T in an $$\mathcal {F}$$ -free subgraph of G. We investigate the algorithmic aspects of calculating and estimating this function. We show that for every graph T, finite family $$\mathcal {F}$$ and constant $$\epsilon &gt;0$$ there is a polynomial time algorithm that approximates $$\mathrm {ex}(G,T,\mathcal {F})$$ for an input graph G on n vertices up to an additive error of $$\epsilon n^{v(T)}$$ . We also consider the possibility of a better approximation, proving several positive and negative results, and suggesting a conjecture on the exact relation between T and $$\mathcal {F}$$ for which no significantly better approximation can be found in polynomial time unless $$P=NP$$ .},
  archive      = {J_Alg},
  author       = {Alon, Noga and Shikhelman, Clara},
  doi          = {10.1007/s00453-021-00899-4},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {464-481},
  shortjournal = {Algorithmica},
  title        = {Additive approximation of generalized turán questions},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast exact algorithms using hadamard product of polynomials.
<em>Alg</em>, <em>84</em>(2), 436–463. (<a
href="https://doi.org/10.1007/s00453-021-00900-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let C be an arithmetic circuit of size s, given as input that computes a polynomial $$f\in {\mathbb {F}}[x_1,x_2,\ldots ,x_n]$$ , where $${\mathbb {F}}$$ is a finite field or the field of rationals. Using the Hadamard product of polynomials, we obtain new algorithms for the following two problems first studied by Koutis and Williams (Faster algebraic algorithms for path and packing problems, 2008, https://doi.org/10.1007/978-3-540-70575-8_47 ; ACM Trans Algorithms 12(3):31:1–31:18, 2016, https://doi.org/10.1145/2885499 ; Inf Process Lett 109(6):315–318, 2009, https://doi.org/10.1016/j.ipl.2008.11.004 ): Other results include fast deterministic algorithms for $${{{(\textit{k,n}){-}\mathrm{M{L}\normalsize {C}}}}}$$ and $${{{\textit{k}{-}\mathrm{M{M}\normalsize {D}}}}}$$ problems for depth three circuits.},
  archive      = {J_Alg},
  author       = {Arvind, V. and Chatterjee, Abhranil and Datta, Rajit and Mukhopadhyay, Partha},
  doi          = {10.1007/s00453-021-00900-0},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {436-463},
  shortjournal = {Algorithmica},
  title        = {Fast exact algorithms using hadamard product of polynomials},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the parameterized complexity of maximum degree
contraction problem. <em>Alg</em>, <em>84</em>(2), 405–435. (<a
href="https://doi.org/10.1007/s00453-021-00897-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Maximum Degree Contraction problem, the input is a graph G on n vertices, and integers k, d, and the objective is to check whether G can be transformed into a graph of maximum degree at most d, using at most k edge contractions. A simple brute-force algorithm that checks all possible sets of edges for a solution runs in time $$n^{\mathcal {O}(k)}$$ . As our first result, we prove that this algorithm is asymptotically optimal, upto constants in the exponents, under Exponential Time Hypothesis (ETH). Belmonte, Golovach, van’t Hof, and Paulusma studied the problem in the realm of parameterized complexity and proved, among other things, that it admits an FPT algorithm running in time $$(d + k)^{2k} \cdot n^{\mathcal {O}(1)} = 2^{\mathcal {O}(k \log (k+d) )} \cdot n^{\mathcal {O}(1)}$$ , and remains NP-hard for every constant $$d \ge 2$$ (Acta Informatica (2014)). We present a different FPT algorithm that runs in time $$2^{\mathcal {O}(dk)} \cdot n^{\mathcal {O}(1)}$$ . In particular, our algorithm runs in time $$2^{\mathcal {O}(k)} \cdot n^{\mathcal {O}(1)}$$ , for every fixed d. In the same article, the authors asked whether the problem admits a polynomial kernel, when parameterized by $$k + d$$ . We answer this question in the negative and prove that it does not admit a polynomial compression unless $$\textsf {NP}\subseteq \textsf {coNP}/poly$$ .},
  archive      = {J_Alg},
  author       = {Saurabh, Saket and Tale, Prafullkumar},
  doi          = {10.1007/s00453-021-00897-6},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {405-435},
  shortjournal = {Algorithmica},
  title        = {On the parameterized complexity of maximum degree contraction problem},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Counting induced subgraphs: An algebraic approach to
#w[1]-hardness. <em>Alg</em>, <em>84</em>(2), 379–404. (<a
href="https://doi.org/10.1007/s00453-021-00894-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem $$\#\textsc {IndSub}(\varPhi )$$ of counting all induced subgraphs of size k in a graph G that satisfy the property $$\varPhi $$ . It is shown that, given any graph property $$\varPhi $$ that distinguishes independent sets from bicliques, $$\#\textsc {IndSub}(\varPhi )$$ is hard for the class $$\#\mathsf {W[1]}$$ , i.e., the parameterized counting equivalent of $${{\mathsf {N}}}{{\mathsf {P}}}$$ . Under additional suitable density conditions on $$\varPhi $$ , satisfied e.g. by non-trivial monotone properties on bipartite graphs, we strengthen $$\#\mathsf {W[1]}$$ -hardness by establishing that $$\#\textsc {IndSub}(\varPhi )$$ cannot be solved in time $$f(k)\cdot n^{o(k)}$$ for any computable function f, unless the Exponential Time Hypothesis fails. Finally, we observe that our results remain true even if the input graph G is restricted to be bipartite and counting is done modulo a fixed prime.},
  archive      = {J_Alg},
  author       = {Dörfler, Julian and Roth, Marc and Schmitt, Johannes and Wellnitz, Philip},
  doi          = {10.1007/s00453-021-00894-9},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {379-404},
  shortjournal = {Algorithmica},
  title        = {Counting induced subgraphs: An algebraic approach to #W[1]-hardness},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mechanisms for (mis)allocating scientific credit.
<em>Alg</em>, <em>84</em>(2), 344–378. (<a
href="https://doi.org/10.1007/s00453-021-00902-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific communities confer many forms of credit on their successful members. The motivation provided by these forms of credit helps shaping a community’s collective attention toward different lines of research. The allocation of scientific credit, however, has also been the focus of long-documented pathologies: certain research questions are said to command more credit then they deserve; and certain researchers seem to receive a disproportionate share of the credit. Here we show that each of these pathologies can actually increase the collective productivity of a community. We consider a model for the allocation of credit, in which individuals pick a project among projects of varying importance and difficulty levels, and compete to receive credit with others who choose the same project. Under the most natural allocation mechanism, in which credit is divided equally among those who succeed at a project in proportion to the project’s importance, the resulting selection of projects by self-interested, credit-maximizing individuals will in general be socially sub-optimal. However, we show that there exist ways of allocating credit both out of proportion to the true importance of the projects and out of proportion to the relative contributions of the individuals, that lead credit-maximizing individuals to achieve social optimality. These results therefore suggest how well-known forms of misallocation of scientific credit can in fact serve to channel self-interested behavior into socially optimal outcomes.},
  archive      = {J_Alg},
  author       = {Kleinberg, Jon and Oren, Sigal},
  doi          = {10.1007/s00453-021-00902-y},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {344-378},
  shortjournal = {Algorithmica},
  title        = {Mechanisms for (Mis)allocating scientific credit},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximation schemes for the generalized extensible bin
packing problem. <em>Alg</em>, <em>84</em>(2), 325–343. (<a
href="https://doi.org/10.1007/s00453-021-00895-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new generalization of the extensible bin packing with unequal bin sizes problem. In our generalization the cost of exceeding the bin size (also known as the bin capacity) depends on the index of the bin and not only on the amount in which the size of the bin is exceeded. This generalization does not satisfy the assumptions on the cost function that were used to present the existing polynomial time approximation scheme (PTAS) for the extensible bin packing with unequal bin sizes problem. In this work, we show the existence of an efficient PTAS (EPTAS) for this new generalization and thus in particular we improve the earlier PTAS for the extensible bin packing with unequal bin sizes problem into an EPTAS. Our new scheme is based on using the shifting technique followed by a solution of a polynomial number of n-fold programming instances. In addition, we present an asymptotic fully polynomial time approximation scheme for the related bin packing type variant of the problem.},
  archive      = {J_Alg},
  author       = {Levin, Asaf},
  doi          = {10.1007/s00453-021-00895-8},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {325-343},
  shortjournal = {Algorithmica},
  title        = {Approximation schemes for the generalized extensible bin packing problem},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tight bounds for online weighted tree augmentation.
<em>Alg</em>, <em>84</em>(2), 304–324. (<a
href="https://doi.org/10.1007/s00453-021-00888-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Weighted Tree Augmentation problem (WTAP) is a fundamental problem in network design. In this paper, we consider this problem in the online setting. We are given an n-vertex tree $$T = (V,E)$$ and an additional set $$L \subseteq {V \atopwithdelims ()2}$$ of edges (called links) with costs. Then, terminal pairs arrive one-by-one and our task is to maintain a low-cost subset of links F such that every terminal pair that has arrived so far is 2-edge-connected in $$T \cup F$$ . This online problem was first studied by Gupta, Krishnaswamy and Ravi (SICOMP 2012) who used it as a subroutine for the online survivable network design problem. They gave a deterministic $$O(\log ^2 n)$$ -competitive algorithm and showed an $$\varOmega (\log n)$$ lower bound on the competitive ratio of randomized algorithms. The case when T is a path is also interesting: it is exactly the online interval set cover problem, which also captures as a special case the parking permit problem studied by Meyerson (FOCS 2005). The contribution of this paper is to give tight results for online weighted tree and path augmentation problems. The main result of this work is a deterministic $$O(\log n)$$ -competitive algorithm for online WTAP, which is tight up to constant factors.},
  archive      = {J_Alg},
  author       = {Naor, Joseph (Seffi) and Umboh, Seeun William and Williamson, David P.},
  doi          = {10.1007/s00453-021-00888-7},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {304-324},
  shortjournal = {Algorithmica},
  title        = {Tight bounds for online weighted tree augmentation},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structural parameterizations of clique coloring.
<em>Alg</em>, <em>84</em>(2), 273–303. (<a
href="https://doi.org/10.1007/s00453-021-00890-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A clique coloring of a graph is an assignment of colors to its vertices such that no maximal clique is monochromatic. We initiate the study of structural parameterizations of the Clique Coloring problem which asks whether a given graph has a clique coloring with q colors. For fixed $$q \ge 2$$ , we give an $$\mathscr {O}^{\star }(q^{{\mathsf {tw}}})$$ -time algorithm when the input graph is given together with one of its tree decompositions of width $${\mathsf {tw}} $$ . We complement this result with a matching lower bound under the Strong Exponential Time Hypothesis. We furthermore show that (when the number of colors is unbounded) Clique Coloring is $$\mathsf {XP}$$ parameterized by clique-width.},
  archive      = {J_Alg},
  author       = {Jaffke, Lars and Lima, Paloma T. and Philip, Geevarghese},
  doi          = {10.1007/s00453-021-00890-z},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {273-303},
  shortjournal = {Algorithmica},
  title        = {Structural parameterizations of clique coloring},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bounding the inefficiency of compromise in opinion
formation. <em>Alg</em>, <em>84</em>(1), 234–271. (<a
href="https://doi.org/10.1007/s00453-021-00892-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks on the Internet have seen an enormous growth recently and play a crucial role in different aspects of today’s life. They have facilitated information dissemination in ways that have been beneficial for their users but they are often used strategically in order to spread information that only serves the objectives of particular users. These properties have inspired a revision of classical opinion formation models from sociology using game-theoretic notions and tools. We follow the same modeling approach, focusing on scenarios where the opinion expressed by each user is a compromise between her internal belief and the opinions of a small number of neighbors among her social acquaintances. We formulate simple games that capture this behavior and quantify the inefficiency of equilibria using the well-known notion of the price of anarchy. Our results indicate that compromise comes at a cost that strongly depends on the neighborhood size.},
  archive      = {J_Alg},
  author       = {Caragiannis, Ioannis and Kanellopoulos, Panagiotis and Voudouris, Alexandros A.},
  doi          = {10.1007/s00453-021-00892-x},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {234-271},
  shortjournal = {Algorithmica},
  title        = {Bounding the inefficiency of compromise in opinion formation},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Agglomerative clustering of growing squares. <em>Alg</em>,
<em>84</em>(1), 216–233. (<a
href="https://doi.org/10.1007/s00453-021-00873-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study an agglomerative clustering problem motivated by interactive glyphs in geo-visualization. Consider a set of disjoint square glyphs on an interactive map. When the user zooms out, the glyphs grow in size relative to the map, possibly with different speeds. When two glyphs intersect, we wish to replace them by a new glyph that captures the information of the intersecting glyphs. We present a fully dynamic kinetic data structure that maintains a set of n disjoint growing squares. Our data structure uses $$O\bigl (n \log n \log \log n\bigr )$$ space, supports queries in worst case $$O\bigl (\log ^2 n\bigr )$$ time, and updates in $$O\bigl (\log ^5 n\bigr )$$ amortized time. This leads to an $$O\bigl (n\,\alpha (n)\log ^5 n\bigr )$$ time algorithm to solve the agglomerative clustering problem. This is a significant improvement over the current best $$O\bigl (n^2\bigr )$$ time algorithms.},
  archive      = {J_Alg},
  author       = {Castermans, Thom and Speckmann, Bettina and Staals, Frank and Verbeek, Kevin},
  doi          = {10.1007/s00453-021-00873-0},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {216-233},
  shortjournal = {Algorithmica},
  title        = {Agglomerative clustering of growing squares},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A polynomial kernel for diamond-free editing. <em>Alg</em>,
<em>84</em>(1), 197–215. (<a
href="https://doi.org/10.1007/s00453-021-00891-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a fixed graph H, the H-free editing problem asks whether we can edit at most k edges to make a graph contain no induced copy of H. We obtain a polynomial kernel for this problem when H is a diamond. The incompressibility dichotomy for H being a 3-connected graph and the classical complexity dichotomy suggest that except for H being a complete/empty graph, H-free editing problems admit polynomial kernels only for a few small graphs H. Therefore, we believe that our result is an essential step toward a complete dichotomy on the compressibility of H-free editing. Additionally, we give a cubic-vertex kernel for the diamond-free edge deletion problem, which is far simpler than the previous kernel of the same size for the problem.},
  archive      = {J_Alg},
  author       = {Cao, Yixin and Rai, Ashutosh and Sandeep, R. B. and Ye, Junjie},
  doi          = {10.1007/s00453-021-00891-y},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {197-215},
  shortjournal = {Algorithmica},
  title        = {A polynomial kernel for diamond-free editing},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Level-planar drawings with few slopes. <em>Alg</em>,
<em>84</em>(1), 176–196. (<a
href="https://doi.org/10.1007/s00453-021-00884-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and study level-planar straight-line drawings with a fixed number $$\lambda $$ of slopes. For proper level graphs (all edges connect vertices of adjacent levels), we give an $$O(n \log ^2 n / \log \log n)$$ -time algorithm that either finds such a drawing or determines that no such drawing exists. Moreover, we consider the partial drawing extension problem, where we seek to extend an immutable drawing of a subgraph to a drawing of the whole graph, and the simultaneous drawing problem, which asks about the existence of drawings of two graphs whose restrictions to their shared subgraph coincide. We present $$O(n^{4/3} \log n)$$ -time and $$O(\lambda n^{10/3} \log n)$$ -time algorithms for these respective problems on proper level-planar graphs. We complement these positive results by showing that testing whether non-proper level graphs admit level-planar drawings with $$\lambda $$ slopes is NP-hard even in restricted cases.},
  archive      = {J_Alg},
  author       = {Brückner, Guido and Krisam, Nadine and Mchedlidze, Tamara},
  doi          = {10.1007/s00453-021-00884-x},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {176-196},
  shortjournal = {Algorithmica},
  title        = {Level-planar drawings with few slopes},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bounded-angle minimum spanning trees. <em>Alg</em>,
<em>84</em>(1), 150–175. (<a
href="https://doi.org/10.1007/s00453-021-00889-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the connectivity problem in wireless networks with directional antennas, we study bounded-angle spanning trees. Let P be a set of points in the plane and let $$\alpha $$ be an angle. An $$\alpha $$ -ST of P is a spanning tree of the complete Euclidean graph on P with the property that all edges incident to each point $$p\in P$$ lie in a wedge of angle $$\alpha $$ centered at p. We study the following closely related problems for $$\alpha =2\pi /3$$ (however, our approximation ratios hold for any $$\alpha \geqslant 2\pi /3$$ ).},
  archive      = {J_Alg},
  author       = {Biniaz, Ahmad and Bose, Prosenjit and Lubiw, Anna and Maheshwari, Anil},
  doi          = {10.1007/s00453-021-00889-6},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {150-175},
  shortjournal = {Algorithmica},
  title        = {Bounded-angle minimum spanning trees},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximating dynamic weighted vertex cover with soft
capacities. <em>Alg</em>, <em>84</em>(1), 124–149. (<a
href="https://doi.org/10.1007/s00453-021-00886-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study considers the soft capacitated vertex cover problem in a dynamic setting. This problem generalizes the dynamic model of the vertex cover problem, which has been intensively studied in recent years. Given a dynamically changing vertex-weighted graph $$G=(V,E)$$ , which allows edge insertions and edge deletions, the goal is to design a data structure that maintains an approximate minimum vertex cover while satisfying the capacity constraint of each vertex. That is, when picking a copy of a vertex v in the cover, the number of v’s incident edges covered by the copy is up to a given capacity of v. We extend Bhattacharya et al.’s work [SODA’15 and ICALP’15] to obtain a deterministic primal-dual algorithm for maintaining a constant-factor approximate minimum capacitated vertex cover with $$O(\log n / \epsilon )$$ amortized update time, where n is the number of vertices in the graph. The algorithm can be extended to (1) a more general model in which each edge is associated with a non-uniform and unsplittable demand, and (2) the more general capacitated set cover problem.},
  archive      = {J_Alg},
  author       = {Wei, Hao-Ting and Hon, Wing-Kai and Horn, Paul and Liao, Chung-Shou and Sadakane, Kunihiko},
  doi          = {10.1007/s00453-021-00886-9},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {124-149},
  shortjournal = {Algorithmica},
  title        = {Approximating dynamic weighted vertex cover with soft capacities},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimized silent self-stabilizing scheme for tree-based
constructions. <em>Alg</em>, <em>84</em>(1), 85–123. (<a
href="https://doi.org/10.1007/s00453-021-00878-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a general scheme to compute tree-based data structures on arbitrary networks. This scheme is self-stabilizing, silent, and despite its generality, also efficient. It is written in the locally shared memory model with composite atomicity assuming the distributed unfair daemon, the weakest scheduling assumption of the model. Its stabilization time is in at most $$4{n_{\mathtt {maxCC}}}$$ rounds, where $${n_{\mathtt {maxCC}}}$$ is the maximum number of processes in any connected component of the network. We illustrate the versatility and efficiency of our approach by proposing several instantiations solving classical spanning tree problems such as DFS, BFS, shortest-path, or unconstrained spanning tree/forest constructions, as well as other fundamental problems like leader election or finding maximum-bottleneck-bandwidth paths. We also exhibit polynomial upper bounds on its stabilization time in steps and process moves, holding for a large class of instantiations. In several cases, the polynomial step and move complexities we obtain for those instantiations match the best known complexities of existing algorithms, despite the latter being dedicated to particular problems. Furthermore, a significant set of instantiations of our scheme requires only bounded memory space per process. This set includes, but is not limited to, DFS, BFS, and shortest-path spanning tree constructions.},
  archive      = {J_Alg},
  author       = {Devismes, Stéphane and Ilcinkas, David and Johnen, Colette},
  doi          = {10.1007/s00453-021-00878-9},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {85-123},
  shortjournal = {Algorithmica},
  title        = {Optimized silent self-stabilizing scheme for tree-based constructions},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximate minimum selection with unreliable comparisons.
<em>Alg</em>, <em>84</em>(1), 60–84. (<a
href="https://doi.org/10.1007/s00453-021-00880-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the approximate minimum selection problem in presence of independent random comparison faults. This problem asks to select one of the smallest k elements in a linearly-ordered collection of n elements by only performing unreliable pairwise comparisons: whenever two elements are compared, there is a small probability that the wrong comparison outcome is observed. We design a randomized algorithm that solves this problem with a success probability of at least $$1-q$$ for $$q \in (0, \frac{n-k}{n})$$ and any $$k \in [1, n-1]$$ using $$O\big ( \frac{n}{k} \big \lceil \log \frac{1}{q} \big \rceil \big )$$ comparisons in expectation (if $$k \ge n$$ or $$q \ge \frac{n-k}{n}$$ the problem becomes trivial). Then, we prove that the expected number of comparisons needed by any algorithm that succeeds with probability at least $$1-q$$ must be $${\varOmega }(\frac{n}{k}\log \frac{1}{q})$$ whenever q is bounded away from $$\frac{n-k}{n}$$ , thus implying that the expected number of comparisons performed by our algorithm is asymptotically optimal in this range. Moreover, we show that the approximate minimum selection problem can be solved using $$O( (\frac{n}{k} + \log \log \frac{1}{q}) \log \frac{1}{q})$$ comparisons in the worst case, which is optimal when q is bounded away from $$\frac{n-k}{n}$$ and $$k = O\big ( \frac{n}{\log \log \frac{1}{q}}\big )$$ .},
  archive      = {J_Alg},
  author       = {Leucci, Stefano and Liu, Chih-Hung},
  doi          = {10.1007/s00453-021-00880-1},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {60-84},
  shortjournal = {Algorithmica},
  title        = {Approximate minimum selection with unreliable comparisons},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiple-edge-fault-tolerant approximate shortest-path
trees. <em>Alg</em>, <em>84</em>(1), 37–59. (<a
href="https://doi.org/10.1007/s00453-021-00879-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let G be an n-node and m-edge positively real-weighted undirected graph. For any given integer $$f \ge 1$$ , we study the problem of designing a sparse f-edge-fault-tolerant (f-EFT) $$\sigma $$ -approximate single-source shortest-path tree ( $$\sigma $$ -ASPT), namely a subgraph of G having as few edges as possible and which, following the failure of a set F of at most f edges in G, contains paths from a fixed source that are stretched by a factor of at most $$\sigma $$ . To this respect, we provide an algorithm that efficiently computes an f-EFT $$(2|F|+1)$$ -ASPT of size O(fn). Our structure improves on a previous related construction designed for unweighted graphs, having the same size but guaranteeing a larger stretch factor of $$3(f+1)$$ , plus an additive term of $$(f+1) \log n$$ . Then, we show how to convert our structure into an efficient f-EFT single-source distance oracle, that can be built in $$O(f m\, \alpha (m,n)+fn \log ^3 n)$$ time, has size $$O(fn \log ^2 n)$$ , and in $$O(|F|^2 \log ^2 n)$$ time is able to report a $$(2|F|+1)$$ -approximate distance from the source to any node in $$G-F$$ . Moreover, our oracle can return a corresponding approximate path in the same amount of time plus the path’s size. The oracle is obtained by tackling another fundamental problem, namely that of updating a minimum spanning forest (MSF) of G following a batch of k simultaneous modification (i.e., edge insertions, deletions and weight changes). For this problem, we build in $$O(m \log ^3 n)$$ time an oracle of size $$O(m \log ^2 n)$$ , that reports in $$O(k^2 \log ^2 n)$$ time the (at most 2k) edges either exiting from or entering into the MSF. Finally, for any integer $$k \ge 1$$ , we complement all our results with a lower bound of $$\Omega \left( n^{1+\frac{1}{k}}\right) $$ to the size of any f-EFT $$\sigma $$ -ASPT with $$f \ge \log n$$ and $$\sigma &lt; \frac{3k+1}{k+1}$$ , that holds if the Erdős’ girth conjecture is true.},
  archive      = {J_Alg},
  author       = {Bilò, Davide and Gualà, Luciano and Leucci, Stefano and Proietti, Guido},
  doi          = {10.1007/s00453-021-00879-8},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {37-59},
  shortjournal = {Algorithmica},
  title        = {Multiple-edge-fault-tolerant approximate shortest-path trees},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On perturbation resilience of non-uniform k-center.
<em>Alg</em>, <em>84</em>(1), 13–36. (<a
href="https://doi.org/10.1007/s00453-021-00887-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Non-Uniform k-center (NUkC) problem has recently been formulated by Chakrabarty et al. [ICALP, 2016; ACM Trans Algorithms 16(4):46:1–46:19, 2020] as a generalization of the classical k-center clustering problem. In NUkC, given a set of n points P in a metric space and non-negative numbers $$r_1, r_2, \ldots , r_k$$ , the goal is to find the minimum dilation $$\alpha $$ and to choose k balls centered at the points of P with radius $$\alpha \cdot r_i$$ for $$1\le i\le k$$ , such that all points of P are contained in the union of the chosen balls. They showed that the problem is $$\mathsf {NP}$$ -hard to approximate within any factor even in tree metrics. On the other hand, they designed a “bi-criteria” constant approximation algorithm that uses a constant times k balls. Surprisingly, no true approximation is known even in the special case when the $$r_i$$ ’s belong to a fixed set of size 3. In this paper, we study the NUkC problem under perturbation resilience, which was introduced by Bilu and Linial (Comb Probab Comput 21(5):643–660, 2012). We show that the problem under 2-perturbation resilience is polynomial time solvable when the $$r_i$$ ’s belong to a constant-sized set. However, we show that perturbation resilience does not help in the general case. In particular, our findings imply that even with perturbation resilience one cannot hope to find any “good” approximation for the problem.},
  archive      = {J_Alg},
  author       = {Bandyapadhyay, Sayan},
  doi          = {10.1007/s00453-021-00887-8},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {13-36},
  shortjournal = {Algorithmica},
  title        = {On perturbation resilience of non-uniform k-center},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximation algorithm for vertex cover with multiple
covering constraints. <em>Alg</em>, <em>84</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s00453-021-00885-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the vertex cover problem with multiple coverage constraints in hypergraphs. In this problem, we are given a hypergraph $$G=(V,E)$$ with a maximum edge size f, a cost function $$w: V\rightarrow {\mathbb {Z}}^+$$ , and edge subsets $$P_1,P_2,\ldots ,P_r$$ of E along with covering requirements $$k_1,k_2,\ldots ,k_r$$ for each subset. The objective is to find a minimum cost subset S of V such that, for each edge subset $$P_i$$ , at least $$k_i$$ edges of it are covered by S. This problem is a basic yet general form of classical vertex cover problem and the edge-partitioned vertex cover problem considered by Bera et al. We present a primal-dual algorithm yielding an $$\left( f \cdot H_r + H_r\right) $$ -approximation for this problem, where $$H_r$$ is the $$r^{th}$$ harmonic number. This improves over the previous ratio of $$(3cf\log r)$$ , where c is a large constant used to ensure a low failure probability for Monte-Carlo randomized algorithms. Compared to the previous result, our algorithm is deterministic and pure combinatorial, meaning that no Ellipsoid solver is required for this basic problem. Our result can be seen as a novel reinterpretation of a few classical tight results using the language of LP primal-duality.},
  archive      = {J_Alg},
  author       = {Hung, Eunpyeong and Kao, Mong-Jen},
  doi          = {10.1007/s00453-021-00885-w},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Algorithmica},
  title        = {Approximation algorithm for vertex cover with multiple covering constraints},
  volume       = {84},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
