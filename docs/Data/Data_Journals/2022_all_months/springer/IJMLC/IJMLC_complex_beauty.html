<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJMLC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijmlc---246">IJMLC - 246</h2>
<ul>
<li><details>
<summary>
(2022). Hierarchical metric learning with intra-level and
inter-level regularization. <em>IJMLC</em>, <em>13</em>(12), 4033–4042.
(<a href="https://doi.org/10.1007/s13042-022-01664-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metric learning for hierarchical classification is a significant problem whose purpose is to learn more discriminative metrics by exploiting the dataset’s hierarchical structure and achieving higher accuracy rates for hierarchical classification. However, most of the existing hierarchical metric learning methods fail to consider the irrelevance between the metrics of sibling nodes in a hierarchical tree, which makes the metric of each node not well distinguish child nodes. This paper proposes a hierarchical metric learning model based on intra-level and inter-level regularization. The model mines the idiosyncrasies of sibling nodes and learns a more discriminative metric for each non-leaf node. At the same time, by exploiting the commonalities of parent-child nodes to control inter-level error propagation. Extensive experiments on five hierarchical datasets demonstrate that the proposed algorithm can perform better than the existing ones.},
  archive      = {J_IJMLC},
  author       = {Li, Lin and Li, Ting and Wei, Wei and Guo, Xinyao and Liang, Jiye},
  doi          = {10.1007/s13042-022-01664-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4033-4042},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hierarchical metric learning with intra-level and inter-level regularization},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalized rough and fuzzy rough automata for semantic
computing. <em>IJMLC</em>, <em>13</em>(12), 4013–4032. (<a
href="https://doi.org/10.1007/s13042-022-01637-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical automata, fuzzy finite automata, and rough finite state automata are some formal models of computing used to perform the task of computation and are considered to be the input device. These computational models are valid only for fixed input alphabets for which they are defined and, therefore, are less user-friendly and have limited applications. The semantic computing techniques provide a way to redefine them to improve their scope and applicability. In this paper, the concept of semantically equivalent concepts and semantically related concepts in information about real-world applications datasets are used to introduce and study two new formal models of computations with semantic computing (SC), namely, a rough finite-state automaton for SC and a fuzzy finite rough automaton for SC as extensions of rough finite-state automaton and fuzzy finite-state automaton, respectively, in two different ways. The traditional rough finite-state automata can not deal with situations when external alphabet or semantically equivalent concepts are given as inputs. The proposed rough finite-state automaton for SC can handle such situations and accept such inputs and is shown to have successful real-world applications. Similarly, a fuzzy finite rough automaton corresponding to a fuzzy automaton is also failed to process input alphabet different from their input alphabet, the proposed fuzzy finite rough automaton for SC corresponding to a given fuzzy finite automaton is capable of processing semantically related input, and external input alphabet information from the dataset obtained by real-world applications and provide better user experience and applicability as compared to classical fuzzy finite rough automaton.},
  archive      = {J_IJMLC},
  author       = {Yadav, Swati and Tiwari, S. P. and Kumari, Mausam and Yadav, Vijay K.},
  doi          = {10.1007/s13042-022-01637-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4013-4032},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Generalized rough and fuzzy rough automata for semantic computing},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An accelerated optimization algorithm for the elastic-net
extreme learning machine. <em>IJMLC</em>, <em>13</em>(12), 3993–4011.
(<a href="https://doi.org/10.1007/s13042-022-01636-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme learning machine (ELM) has received considerable attention due to its rapid learning speed and powerful fitting capabilities. One of its important variants, the elastic-net ELM (Enet-ELM), was recently proposed to improve its sparsity and stability of simulations simultaneously. However, entering the era of big data, the explosive growth of data volume and dimensions poses a huge challenge to Enet-ELM. On the other hand, the alternating direction method of multipliers (ADMM) is a powerful iterative algorithm for solving large-scale optimization problems by splitting a large problem into a set of executable sub-problems. But its performance is highly restricted by its astringency and convergence rates. In this paper, we therefore develop a novel Enet-ELM algorithm based on the over-relaxed ADMM, termed over-relaxed Enet-ELM (OE-ELM), which accelerates model training by applying the results of the previous iteration to the next iteration. Besides, we also propose a parallel version of OE-ELM (POE-ELM) to implement parallel and distributed computation, which is trained by the consensus over relaxation ADMM algorithm. Finally, the convergence analysis conducted on the two proposed algorithms proves the effectiveness of model training, and extensive experiments on classification and regression datasets demonstrate their competitiveness in accuracy and convergence rate.},
  archive      = {J_IJMLC},
  author       = {Zhang, Yuao and Dai, Yunwei and Wu, Qingbiao},
  doi          = {10.1007/s13042-022-01636-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3993-4011},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An accelerated optimization algorithm for the elastic-net extreme learning machine},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Confidence estimation for t-SNE embeddings using random
forest. <em>IJMLC</em>, <em>13</em>(12), 3981–3992. (<a
href="https://doi.org/10.1007/s13042-022-01635-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensionality reduction algorithms are commonly used for reducing the dimension of multi-dimensional data to visualize them on a standard display. Although many dimensionality reduction algorithms such as the t-distributed Stochastic Neighborhood Embedding aim to preserve close neighborhoods in low-dimensional space, they might not accomplish that for every sample of the data and eventually produce erroneous representations. In this study, we developed a supervised confidence estimation algorithm for detecting erroneous samples in embeddings. Our algorithm generates a confidence score for each sample in an embedding based on a distance-oriented score and a random forest regressor. We evaluate its performance on both intra- and inter-domain data and compare it with the neighborhood preservation ratio as our baseline. Our results showed that the resulting confidence score provides distinctive information about the correctness of any sample in an embedding compared to the baseline. The source code is available at https://github.com/gsaygili/dimred .},
  archive      = {J_IJMLC},
  author       = {Ozgode Yigin, Busra and Saygili, Gorkem},
  doi          = {10.1007/s13042-022-01635-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3981-3992},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Confidence estimation for t-SNE embeddings using random forest},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-granulation-based knowledge discovery in incomplete
generalized multi-scale decision systems. <em>IJMLC</em>,
<em>13</em>(12), 3963–3979. (<a
href="https://doi.org/10.1007/s13042-022-01634-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-granulation rough sets and multi-scale data analysis are two active topics in granular computing. This study aims to investigate knowledge discovery in incomplete generalized multi-scale decision systems based on multi-granulation rough sets. Multi-granulation structures in incomplete generalized multi-scale decision systems are first discussed and updating mechanisms of information granules with the scale coarsening and refinement are described. Concepts of pessimistic upper and lower optimal scale combinations based on pessimistic multi-granulation rough sets are then defined and their uniqueness is verified. Evidence-theory-based numerical algorithms for finding optimal scale combinations are further designed. Notions of optimistic upper and lower optimal scale combinations based on optimistic multi-granulation rough sets are also introduced and their properties are examined. Finally, reducts of scale combinations are explored and an illustrative example is employed to elaborate multi-granulation rule acquisition approach in incomplete generalized multi-scale decision systems.},
  archive      = {J_IJMLC},
  author       = {Wang, Jinbo and Wu, Wei-Zhi and Tan, Anhui},
  doi          = {10.1007/s13042-022-01634-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3963-3979},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-granulation-based knowledge discovery in incomplete generalized multi-scale decision systems},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Bee: Towards a robust attribute reduction. <em>IJMLC</em>,
<em>13</em>(12), 3927–3962. (<a
href="https://doi.org/10.1007/s13042-022-01633-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem solving of attribute reduction is popular in reducing dimensions of data. Note that besides the efficiency of searching expected reducts, the performance related to the derived reducts should also be paid much attention to. Among various representative performance, it is worth mentioning that the robustness of reduct is crucial to downstream learning tasks. The reason is contributed to the fact that unstable results of attribute reduction may shake the confidence of domain experts when experimentally validating the selected attributes in reducts. In view of this, a novel framework called Bucket based Ensemble sElector (Bee) was developed, which outputs robust reduct with higher stability. Firstly, raw sample space was partitioned by a bucket mechanism. Secondly, over each bucket, candidate attributes were evaluated and then an appropriate attribute was identified. Finally, a voting was executed to identify a universal attribute which should be added into reduct pool for each iteration in the process of searching. Additionally, our framework was introduced into not only the searchings of approximation quality, regularization loss, unsupervised relevance related reducts, but also a quick searching procedure called attribute group. By testing 20 UCI benckmark data sets with raw label and 4 different ratios (10\%, 20\%, 30\%, 40\%) of noisy label, comprehensive experiments demonstrated the superiorities of our Bee: it not only offers robust results of attribute reduction but also guarantees comparable predictions than some other popular algorithms.},
  archive      = {J_IJMLC},
  author       = {Chen, Yining and Wang, Pingxin and Yang, Xibei and Yu, Hualong},
  doi          = {10.1007/s13042-022-01633-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3927-3962},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Bee: Towards a robust attribute reduction},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A novel multi-scale and sparsity auto-encoder for
classification. <em>IJMLC</em>, <em>13</em>(12), 3909–3925. (<a
href="https://doi.org/10.1007/s13042-022-01632-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inspiration for generating the multi-scale feature representation originates from the basic observation that multi-scale is closely related to human visual physiological characteristics. Also, since the increase of hidden layer neurons and the amount of data leads to the rise of redundant information, a large amount of calculation makes a model more complex. This paper proposes a novel learning method, namely, multi-scale feature consistency regularization and L21-norm minimization sparse auto-encoder (LR21-MSAE). The multi-scale feature consistency regularization can achieve the latent representations and the visual details while retaining multi-scale information. This method ensures that LR21-MSAE can get valid information for better classification accuracy. By implementing the L21-norm minimization constraint, the LR21-MSAE can adaptively eliminate the potential noise and redundant neurons by enforcing some rows and columns of the weight matrix to be reduced to zero. It can reduce the complexity of the learning model and promote learning sparsity features to generate a compact network. Moreover, introducing the Wasserstein distance in the sparse auto-encoder to measure the difference between the two distributions allows for a more stable training process and faster convergence. To complete the test of the LR21-MSAE model, we choose to conduct the experiments on some publicly available datasets MNIST, Fashion-MNIST, CIFAR-10, USPS, ISOLET, Pendigits, and Ecoli. We demonstrate the advantages of LR21-MSAE, through the experimental results, compared with state-of-the-art feature extraction methods.},
  archive      = {J_IJMLC},
  author       = {Wang, Huiling and Sun, Jun and Gu, Xiaofeng and Song, Wei},
  doi          = {10.1007/s13042-022-01632-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3909-3925},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel multi-scale and sparsity auto-encoder for classification},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Some novel distance and similarity measures for
probabilistic dual hesitant fuzzy sets and their applications to MAGDM.
<em>IJMLC</em>, <em>13</em>(12), 3887–3907. (<a
href="https://doi.org/10.1007/s13042-022-01631-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic dual hesitant fuzzy set is a more powerful and important tool to express uncertain information. As we all know, the distance and similarity measures are very useful tool in decision-making field. In this study, the distance measure and similarity measure of probabilistic dual hesitation fuzzy set are systematically proposed from the perspectives of discrete and continuous, ordered and unordered, which provides a theoretical support for the research of decision-making problems in probabilistic dual hesitation fuzzy environment. Firstly, we proposed some novel distance and similarity degrees for two probabilistic dual hesitant fuzzy sets and their weighted forms. Secondly, we proposed a decision technique based on the novel built weighted distance and similarity measures to solve the multi-attribute group decision-making problem in the PDHF environment. Finally, the proposed technique was applied to the suitability evaluation of new urbanization. Meanwhile, the technique built in this study was compared with the existed methods to verify the practicability and feasibility, and the superiorities of the built in this study were put forward, which has a better effect in solving multi-attribute group decision-making problems.},
  archive      = {J_IJMLC},
  author       = {Ning, Baoquan and Wei, Guiwu and Guo, Yanfeng},
  doi          = {10.1007/s13042-022-01631-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3887-3907},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Some novel distance and similarity measures for probabilistic dual hesitant fuzzy sets and their applications to MAGDM},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent development of hashing-based image retrieval in
non-stationary environments. <em>IJMLC</em>, <em>13</em>(12), 3867–3886.
(<a href="https://doi.org/10.1007/s13042-022-01630-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous development of mobile devices, the number of images on the Internet increases explosively. Hashing methods solve retrieval problems with large datasets by converting images into binary hash codes. However,the image dataset on the Internet is updating and its data distribution may change as time goes by. In this situation, the retrieval effectiveness of ordinary hashing methods designed for stationary environments will decline. Thus, hashing methods for non-stationary environments are developed to learn from newly arrived data and adapt to new data environments for better retrieval accuracy in non-stationary environments. In this paper, goals of ideal hashing methods for non-stationary environments are proposed. State-of-the-art hashing methods for non-stationary environments are introduced and analyzed for their advantages and disadvantages according to goals. Experiments are presented to show characteristics of these methods. Suggestions for future development of non-stationary hashing are also given at the end of this paper.},
  archive      = {J_IJMLC},
  author       = {Li, Qihua and Tian, Xing and Ng, Wing W. Y. and Kwong, Sam},
  doi          = {10.1007/s13042-022-01630-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3867-3886},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Recent development of hashing-based image retrieval in non-stationary environments},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dominance-based fuzzy rough sets in multi-scale decision
tables. <em>IJMLC</em>, <em>13</em>(12), 3849–3866. (<a
href="https://doi.org/10.1007/s13042-022-01629-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the situation that fuzzy condition attribute values in multi-scale decision table have dominance relations and the decision attribute values are fuzzy, we establish dominance-based fuzzy rough set model (DFRS) in multi-scale decision table (MSDT). In order to investigate the knowledge acquisition efficiency of DFRS in MSDT, we give the optimal scale selection and reduction method to obtain all the optimal scales and all the optimal scale reducts. Besides, we also propose a simple algorithm to obtain an optimal scale reduct. Finally, we verify the effectiveness and practicability of our method through an example of information system security audit risk judgment and a comparative experiment. Experimental results show that our method has obviously improved the knowledge acquisition efficiency compared with the traditional dominance-based fuzzy rough set and effectively integrates the optimal scale selection of the multi-scale decision table with attribute reduction.},
  archive      = {J_IJMLC},
  author       = {Yang, Xuan and Huang, Bing},
  doi          = {10.1007/s13042-022-01629-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3849-3866},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dominance-based fuzzy rough sets in multi-scale decision tables},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A simple combined projection method for conservative
decision-making. <em>IJMLC</em>, <em>13</em>(12), 3837–3848. (<a
href="https://doi.org/10.1007/s13042-022-01628-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning and artificial intelligence based techniques have brought great convenience to human life but along with a series of algorithmic “black box”, discrimination and ethical issues. One of the solutions is to integrate human and machine like the expert evaluation based research of multi-attribute decision-making where “human brain intelligence” is used for the support of “artificial intelligence”. In this article, we proposed a new and effective method to evaluate and rank alternatives in multi-attribute decision-making. Different from many existing approaches, this proposed method employs both the projection lengths and the projection angles of alternatives to make decisions. It supports psychological desirableness of decision makers and uses a Relu function to further enhance the output qualities. This proposed method is very simple to construct and applicable for much wider situations than the existing similar methods.},
  archive      = {J_IJMLC},
  author       = {Cui, Honglei and Xu, Libo and Pang, Chaoyi},
  doi          = {10.1007/s13042-022-01628-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3837-3848},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A simple combined projection method for conservative decision-making},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved adaptive ORB-SLAM method for monocular vision
robot under dynamic environments. <em>IJMLC</em>, <em>13</em>(12),
3821–3836. (<a
href="https://doi.org/10.1007/s13042-022-01627-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vision-based simultaneous localization and mapping (SLAM) method is a hot spot in the robotic research field, and Oriented FAST and Rotated BRIEF (ORB) SLAM algorithm is one of the most effective methods. However, there are some problems of the general ORB-SLAM algorithm in the dynamic environment, which need to be solved further, including the control of the number of the feature points and the treatment of the dynamic objects. In this paper, an improved ORB-SLAM method is proposed for the monocular vision robot under dynamic environments. In the proposed method, a concept of reliability is proposed to mark the feature points, which can control the number of the feature points dynamically into the preset range. Then an improved frame difference method based on the partial detection strategy is used to detect the dynamic objects in the environment. In addition, a novel treatment mechanism for the tracking failure issue is introduced into the ORB-SLAM algorithm, which can improve the accuracy of the localization and mapping. Finally, the experiments on the public datasets and private datasets are conducted and the results show that the proposed method is effective.},
  archive      = {J_IJMLC},
  author       = {Ni, Jianjun and Wang, Xiaotian and Gong, Tao and Xie, Yingjuan},
  doi          = {10.1007/s13042-022-01627-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3821-3836},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An improved adaptive ORB-SLAM method for monocular vision robot under dynamic environments},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ordinal unsupervised multi-target domain adaptation with
implicit and explicit knowledge exploitation. <em>IJMLC</em>,
<em>13</em>(12), 3807–3820. (<a
href="https://doi.org/10.1007/s13042-022-01626-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging research topic in the field of machine learning, unsupervised domain adaptation (UDA) aims to transfer prior knowledge from the source domain to help training the unsupervised target domain model. Although a variety of UDA works have been proposed, they mainly concentrate on scenarios from one source to one target (1S1T) or multi-source to one target domain (mS1T), the works on UDA from one source to multi-target (1SmT) is rare and they are mainly designed for ordinary problems. When countered with ordinal 1SmT tasks where there exists order relationship among the data labels, the existing methods degenerate in performance since the label relationships are not preserved. In this article, we propose an ordinal 1SmT UDA model which transfers both explicit and implicit knowledge from the supervised source and unsupervised target domains respectively via distribution alignment and dictionary transmission. We also design an efficient algorithm to solve the model and evaluate its convergence and complexity. Finally, the effectiveness of the proposed method is evaluated with extensive experiments.},
  archive      = {J_IJMLC},
  author       = {Tian, Qing and Sun, Heyang and Chu, Yi and Peng, Shun},
  doi          = {10.1007/s13042-022-01626-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3807-3820},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Ordinal unsupervised multi-target domain adaptation with implicit and explicit knowledge exploitation},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive hierarchical hyper-gradient descent.
<em>IJMLC</em>, <em>13</em>(12), 3785–3805. (<a
href="https://doi.org/10.1007/s13042-022-01625-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive learning rate strategies can lead to faster convergence and better performance for deep learning models. There are some widely known human-designed adaptive optimizers such as Adam and RMSProp, gradient based adaptive methods such as hyper-descent and practical loss-based stepsize adaptation (L4), and meta learning approaches including learning to learn. However, the existing studies did not take into account the hierarchical structures of deep neural networks in designing the adaptation strategies. Meanwhile, the issue of balancing adaptiveness and convergence is still an open question to be answered. In this study, we investigate novel adaptive learning rate strategies at different levels based on the hyper-gradient descent framework and propose a method that adaptively learns the optimizer parameters by combining adaptive information at different levels. In addition, we show the relationship between regularizing over-parameterized learning rates and building combinations of adaptive learning rates at different levels. Moreover, two heuristics are introduced to guarantee the convergence of the proposed optimizers. The experiments on several network architectures, including feed-forward networks, LeNet-5 and ResNet-18/34, show that the proposed multi-level adaptive approach can significantly outperform many baseline adaptive methods in a variety of circumstances.},
  archive      = {J_IJMLC},
  author       = {Jie, Renlong and Gao, Junbin and Vasnev, Andrey and Tran, Minh-Ngoc},
  doi          = {10.1007/s13042-022-01625-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3785-3805},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive hierarchical hyper-gradient descent},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CorrNet: Pearson correlation based pruning for efficient
convolutional neural networks. <em>IJMLC</em>, <em>13</em>(12),
3773–3783. (<a
href="https://doi.org/10.1007/s13042-022-01624-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are quickly evolving, which usually results in a surge of computational cost and model size. In this article, we present a correlation-based filter pruning (CFP) approach to train more reliable CNN models. Unlike several available filter pruning methodologies, our presented approach eliminates useless filters according to the volume of information available in their related feature maps. We apply correlation to compute the duplication of information carried in the feature maps and created a feature selection scheme to obtain pruning approaches. Pruning and fine-tuning are cycled many times, producing slim and denser networks with similar accuracy to the original unpruned model. We practically calculate the success of our technique with various state-of-art CNN models on many standard datasets. Specifically, for ResNet-50 on ImageNet, our approach eliminates 44.6\% filter weights and saves 51.6\% Float-Point-Operations (FLOPs) with 0.5\% accuracy gain and obtained state-of-art performance.},
  archive      = {J_IJMLC},
  author       = {Kumar, Aakash and Yin, Baoqun and Shaikh, Ali Muhammad and Ali, Munawar and Wei, Wenyue},
  doi          = {10.1007/s13042-022-01624-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3773-3783},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {CorrNet: Pearson correlation based pruning for efficient convolutional neural networks},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hyper-heuristic guided by a probabilistic graphical model
for single-objective real-parameter optimization. <em>IJMLC</em>,
<em>13</em>(12), 3743–3772. (<a
href="https://doi.org/10.1007/s13042-022-01623-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics algorithms are designed to find approximate solutions for challenging optimization problems. The success of the algorithm over a given optimization task relies on the suitability of its search heuristics for the problem-domain. Thus, the design of custom metaheuristic algorithms leads to more accurate solutions. Hyper-heuristics (HH) are important tools commonly used to select low-level heuristics (LLHs) to solve a specific problem. HH are able to acquire knowledge from the problems where they are used. However, as other artificial intelligence tools it is necessary to identify how the knowledge affects the performance of the algorithm. One way to generate such knowledge is to capture interactions between variables using probabilistic graphical models such as Bayesian networks (BN) in conjunction with estimation of distribution algorithms (EDA). This article presents a method based on that used an EDA based on BN as a high-level selection mechanism for HH called Hyper-heuristic approach based on Bayesian learning and evolutionary operators (HHBNO). Here the knowledge is extracted form BN to evolve the sequences of LLHs in an online learning process by exploring the inter-dependencies among the LLHs. The proposes approach is tested over CEC’17 set of benchmark function of single-objective real-parameter optimization. Statical tests verifies that the HHBNO  presents competitive results in comparison with other metaheuristic algorithms with high performance in terms of convergence. The generated BN is further visually investigated to display the acquired knowledge during the evolutionary process, and it is constructed with the probabilities of each LLHs.},
  archive      = {J_IJMLC},
  author       = {Oliva, Diego and Martins, Marcella S. R. and Hinojosa, Salvador and Elaziz, Mohamed Abd and dos Santos, Paulo Victor and da Cruz, Gelson and Mousavirad, Seyed Jalaleddin},
  doi          = {10.1007/s13042-022-01623-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3743-3772},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A hyper-heuristic guided by a probabilistic graphical model for single-objective real-parameter optimization},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Representation learning from noisy user-tagged data for
sentiment classification. <em>IJMLC</em>, <em>13</em>(12), 3727–3742.
(<a href="https://doi.org/10.1007/s13042-022-01622-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment classification aims to identify the sentiment orientation of an opinionated text, which is widely used for market research, product recommendation, and etc. Supervised deep learning approaches are prominent in sentiment classification and have shown the power in representation learning, however such methods suffer from the costly human annotations. Massive user-tagged opinionated texts on the Internet provide a new source for annotation, such as twitter with emoji. However, the texts may contain noisy labels, which may cause ambiguity during training process. In this paper, we propose a novel Weakly-supervised Anti-noise Contrastive Learning framework for sentiment classification, and name it as WACL. We first adopt the supervised contrastive training strategy during the pre-training phase to fully explore potential contrast patterns of weakly-labeled data to learn robust representations. Then we design a simple dropping-layer strategy to remove the top layers from the pre-trained model that are susceptible to noisy data. Last, we add a classification layer on top of the remaining model and fine tune it with labeled data. The proposed framework can learn rich contrastive sentiment patterns in the case of label noise and is applicable to a variety of deep encoders. The experimental results on the Amazon product review, Twitter and SST5 datasets demonstrate the superiority of our method.},
  archive      = {J_IJMLC},
  author       = {Chen, Long and Wang, Fei and Yang, Ruijing and Xie, Fei and Wang, Wenjing and Xu, Cai and Zhao, Wei and Guan, Ziyu},
  doi          = {10.1007/s13042-022-01622-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3727-3742},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Representation learning from noisy user-tagged data for sentiment classification},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A reduced nonstationary discrete convolution kernel for
multimode process monitoring. <em>IJMLC</em>, <em>13</em>(12),
3711–3725. (<a
href="https://doi.org/10.1007/s13042-022-01621-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multimodal behavior is common in industrial process. Since multimodal data distribution can be regarded as a special kind of nonlinearity, kernel method is empirically effective in constructing the multimode process monitoring model. However, kernel methods suffer its high complexity when a large number of data are collected. In order to improve the fault detection performance in multimodal data and reduce the computational complexity, we propose a reduced nonstationary discrete convolution kernel which is inspired by the structural design of radial basis function (RBF) neural network, as an alternative to the RBF kernel and the nonstationary discrete convolution (NSDC) kernel. By deleting the unnecessary accumulated terms in the NSDC kernel, the computational complexity of the proposed NSDC kernel algorithm is effectively reduced and the speed of fault detection is accelerated on the premise of ensuring the fault detection performance. The effectiveness of the proposed algorithm is demonstrated on a numerical example and multimodal TE process under the standard kernel principal component analysis framework.},
  archive      = {J_IJMLC},
  author       = {Wang, Kai and Yan, Caoyin and Yuan, Xiaofeng and Wang, Yalin and Liu, Chenliang},
  doi          = {10.1007/s13042-022-01621-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3711-3725},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A reduced nonstationary discrete convolution kernel for multimode process monitoring},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A dynamic hypergraph regularized non-negative tucker
decomposition framework for multiway data analysis. <em>IJMLC</em>,
<em>13</em>(12), 3691–3710. (<a
href="https://doi.org/10.1007/s13042-022-01620-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-negative tensor decomposition has achieved significant success in machine learning due to its superiority in extracting the non-negative parts-based features and physically meaningful latent components from high-order data. To improve its representation ability, hypergraph has been incorporated into the tensor decomposition model to capture the nonlinear manifold structure of data. However, previous hypergraph regularized tensor decomposition methods rely on the original data space. This may result in inaccurate manifold structure and representation performance degeneration when original data suffer from noise corruption. To solve these problems, in this paper, we propose a dynamic hypergraph regularized non-negative Tucker decomposition (DHNTD) method for multiway data analysis. Specifically, to take full advantage of the multilinear structure and nonlinear manifold of tensor data, we learn the dynamic hypergraph and non-negative low-dimensional representation in a unified framework. Moreover, we develop a multiplicative update (MU) algorithm to solve our optimization problem and theoretically prove its convergence. Experimental results in clustering tasks using six image datasets demonstrate the superiority of our proposed method compared with the state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Huang, Zhenhao and Zhou, Guoxu and Qiu, Yuning and Yu, Yuyuan and Dai, Haolei},
  doi          = {10.1007/s13042-022-01620-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3691-3710},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A dynamic hypergraph regularized non-negative tucker decomposition framework for multiway data analysis},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pythagorean fuzzy soft decision-making method for cache
replacement policy selection in fog computing. <em>IJMLC</em>,
<em>13</em>(12), 3663–3690. (<a
href="https://doi.org/10.1007/s13042-022-01619-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cache replacement policy in fog computing is of great concern to improve CPU cache hit ratio, reduce CPU access to memory time, decrease CPU data acquisition time, and improve system efficiency. When discussing the cache replacement policy selection, the primary problem involves enormous indeterminacy. Pythagorean fuzzy soft set (PFSS), characterized by the parameterized modality of membership and non-membership, is a more useful means to depict indeterminacy. In this article, the comparison issue of Pythagorean fuzzy soft numbers (PFSNs) is managed by novel score function. Subsequently, certain properties for Pythagorean fuzzy soft matrix are explored in detail. In addition, the objective weight is determined by Criteria Importance Through Inter-criteria Correlation (CRITIC) approach while the integrated weight is calculated by simultaneously revealing subjective weight information and the objective weight preference. Then, Pythagorean fuzzy soft decision-making method based on Combined Compromise Solution (CoCoSo) is investigated for solving the low discrimination issue. Finally, the efficacy of our method is verified by the cache replacement policy selection in fog computing.},
  archive      = {J_IJMLC},
  author       = {Peng, Xindong and Sun, Dongting and Luo, Zhigang},
  doi          = {10.1007/s13042-022-01619-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3663-3690},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Pythagorean fuzzy soft decision-making method for cache replacement policy selection in fog computing},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised attribute reduction: Improving effectiveness
and efficiency. <em>IJMLC</em>, <em>13</em>(11), 3645–3662. (<a
href="https://doi.org/10.1007/s13042-022-01618-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction has shown its effectiveness in improving the performance of classifiers. Different from widely studied supervised attribute reduction, unsupervised attribute reduction faces great challenges from two main aspects: performance requirement and computationally demanding. Therefore, both effectiveness of selected attributes and efficiency of searching qualified reduct are addressed in the problem solving of unsupervised attribute reduction. Firstly, an ensemble selector is introduced into forward greedy searching. The objective is to identify more suitable attribute for each iteration in the process of searching. Secondly, both sample and attribute based acceleration mechanisms are introduced into our ensemble selector. The first stage is used to derive reduct with better performance, and the second stage is used to speed up the procedure of searching. Finally, our approach is compared with several well-established attribute reductions over 16 UCI datasets. The comprehensive experiments clearly validate the superiorities of our study from the perspectives of both effectiveness and efficiency.},
  archive      = {J_IJMLC},
  author       = {Gong, Zhice and Liu, Yuxin and Xu, Taihua and Wang, Pingxin and Yang, Xibei},
  doi          = {10.1007/s13042-022-01618-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3645-3662},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Unsupervised attribute reduction: Improving effectiveness and efficiency},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An enhanced mayfly optimization algorithm based on
orthogonal learning and chaotic exploitation strategy. <em>IJMLC</em>,
<em>13</em>(11), 3625–3643. (<a
href="https://doi.org/10.1007/s13042-022-01617-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a new method proposed to solve optimization problems, the mayfly algorithm that possesses the advantages of other advanced algorithms can play a very sound effect. However, there are still some shortcomings of local optimization and slow convergence speed when dealing with complex optimization problems. In this paper, two effective strategies are first integrated into the basic mayfly algorithm to enhance algorithm performance. Firstly, the orthogonal learning is applied to increase the diversity of primary male mayfly operators to guide the male mayfly to move more steadily, rather than oscillatory. Secondly, the chaotic exploitation is added to form the new position of an offspring to improve search capability. In order to verify the effectiveness of the enhanced algorithm, it is evaluated and compared with other excellent algorithms using benchmark functions. The Wilcoxon test, exploration–exploitation analysis and the time complexity analysis are also performed to analyze whether it yield promising results. In addition, three kinds of engineering optimization problems are also tested in the experiments including with constraints and without constraints. Computational results show that enhanced mayfly optimization algorithm achieves sound performance on all test problems and can attain high-quality solutions for different engineering optimization problems.},
  archive      = {J_IJMLC},
  author       = {Zhou, Dashuang and Kang, Zhengyang and Su, Xiaoping and Yang, Chuang},
  doi          = {10.1007/s13042-022-01617-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3625-3643},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An enhanced mayfly optimization algorithm based on orthogonal learning and chaotic exploitation strategy},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MSSL: A memetic-based sparse subspace learning algorithm for
multi-label classification. <em>IJMLC</em>, <em>13</em>(11), 3607–3624.
(<a href="https://doi.org/10.1007/s13042-022-01616-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers have considered multi-label learning because of its presence in various real-world applications, in which each entity is associated with more than one class label. Since multi-label data suffers from the curse of high-dimensionality, providing effective feature selection methods is necessary to enhance the learning process. Various multi-label feature selection methods have been proposed so far. However, the existing methods have not yet reached acceptable performance in this research field due to the existence of datasets with various dimensions. This paper proposes a new feature selection algorithm based on subspace learning and a memetic algorithm to provide global and local search in multi-label data. This is the first try that uses a filter-based memetic algorithm for multi-label feature selection. The objective function consists of two conflicting objectives: reconstruction error and sparsity regularization. Finally, nine filter-based multi-label feature selection methods are compared with the proposed method. The comparisons are conducted based on the famous performance evaluation criteria for multi-label classification, such as classification accuracy, hamming-loss, average precision, and one-error. Based on the results obtained in eight real-world datasets, the proposed method is superior to comparing methods according to all evaluation criteria.},
  archive      = {J_IJMLC},
  author       = {Bayati, Hamid and Dowlatshahi, Mohammad Bagher and Hashemi, Amin},
  doi          = {10.1007/s13042-022-01616-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3607-3624},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MSSL: A memetic-based sparse subspace learning algorithm for multi-label classification},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised video object segmentation: An affinity and edge
learning approach. <em>IJMLC</em>, <em>13</em>(11), 3589–3605. (<a
href="https://doi.org/10.1007/s13042-022-01615-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new approach, called TMNet, to solve unsupervised video object segmentation (UVOS) problem. The UVOS is still a challenging problem as prior methods suffer from issues like generalization errors in unseen test videos, over reliance on optic flow, and capturing fine details at object boundaries. These issues make the UVOS an ill-defined problem, particularly in presence of multiple objects. Our focus is to constrain the problem and improve the segmentation results by fusion of multiple available cues such as appearance and motion, as well as image and flow edges. To constrain the problem, instead of predicting segmentation directly, we predict affinities between neighbouring pixels for being part of the same object and cluster those to obtain category agnostic segmentation. To further improve the segmentation, we fuse multiple-sources of information through a novel Temporal Motion Attention (TMA) module that uses neural attention to learn powerful spatio-temporal features. In addition, we also design an edge refinement module (using image and optic flow edges) to refine and improve the accuracy of object segmentation boundaries. The overall framework is capable of segmenting and finding accurate objects’ boundaries without any heuristic post processing. This enables the method to be used for unseen videos. Experimental results on challenging DAVIS16 and multi object DAVIS17 datasets show that our proposed TMNet performs favorably compared to the state-of-the-art methods without post processing.},
  archive      = {J_IJMLC},
  author       = {Muthu, Sundaram and Tennakoon, Ruwan and Hoseinnezhad, Reza and Bab-Hadiashar, Alireza},
  doi          = {10.1007/s13042-022-01615-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3589-3605},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Unsupervised video object segmentation: An affinity and edge learning approach},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-supervised nonnegative matrix factorization with
pairwise constraints for image clustering. <em>IJMLC</em>,
<em>13</em>(11), 3577–3587. (<a
href="https://doi.org/10.1007/s13042-022-01614-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional clustering method is a kind of unsupervised learning, which is widely used in practical applications. However, the actual acquired data contains a part of prior information, that is the label of some data is known or the relationship of some pairs of data is known. The clustering method using this information is semi-supervised clustering. The pairwise constraints information is a kind of commonly used prior information, including must-link constraints and cannot-link constraints. Compared with unsupervised clustering algorithms, semi-supervised clustering algorithms have better clustering performance due to the guidance of prior information. Nonnegative matrix factorization (NMF) is an efficient clustering method, but it is an unsupervised method and can not take advantage of pairwise constraints information. To this end, by combining pairwise constraints information with NMF framework, a semi-supervised nonnegative matrix factorization with pairwise constraints (SNMFPC) is proposed in this paper. SNMFPC requires that the low-dimensional representations satisfy these constraints, that is, a pair of must-link data should be close to each other, and a pair of cannot-link data is as distant as possible to each other. Experiments are carried out on several data sets and compared with some semi-supervised methods. The validity of the proposed method is verified.},
  archive      = {J_IJMLC},
  author       = {Zhang, Ying and Li, Xiangli and Jia, Mengxue},
  doi          = {10.1007/s13042-022-01614-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3577-3587},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Semi-supervised nonnegative matrix factorization with pairwise constraints for image clustering},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new rotation forest ensemble algorithm. <em>IJMLC</em>,
<em>13</em>(11), 3569–3576. (<a
href="https://doi.org/10.1007/s13042-022-01613-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random forest, a popular ensemble approach in machine learning, has received much attention of researchers in different fields due to its excellent performance. Especially, in the study of classification, it is often used as an effective classifier. Considering that the accuracy and diversity of each base classifier are two main factors that affect the performance of random forest, this paper proposes a new rotation forest ensemble method to increase the diversity of each tree in the forest, which is based on feature extension and transformation. Also, a weighting vote for base classifiers is applied to integrate the final ensemble results instead of to average the accuracy of ensemble learners. In order to illustrate the effectiveness of the proposed algorithm, the experiments conduct with thirty benchmark classification datasets available from the UCI repository and two face recognition databases. Experimental results demonstrate that the proposed algorithm can achieve higher classification accuracy in most cases compared to the other ensemble classifiers.},
  archive      = {J_IJMLC},
  author       = {Wen, Chenglin and Huai, Tingting and Zhang, Qinghua and Song, Zhihuan and Cao, Feilong},
  doi          = {10.1007/s13042-022-01613-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3569-3576},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new rotation forest ensemble algorithm},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hidden features extraction and amplification based on
eigenvalue imaging and gray-level grouping for bearing fault diagnosis.
<em>IJMLC</em>, <em>13</em>(11), 3555–3568. (<a
href="https://doi.org/10.1007/s13042-022-01612-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incipient faults in rolling bearings can corrupt the overall performance of the industrial process; however, it is challenging to detect them due to strong background noise in complicated conditions. In these situations, this paper proposes a novel eigenvalue imaging and gray-level grouping (EV-GLG) method to extract and amplify the features for improving incipient faults’ detectability and accuracy. The problems of noise influences and weak features are solved by an eigenvalue imaging (EV) method and a modified gray-level grouping (GLG) method without expert knowledge and physical models. In addition, a block contrast (BlkCont) method is proposed to calculate image contrast, which is more suitable for noisy images. The effectiveness of the proposed EV-GLG is validated by the support vector machine (SVM) on the Case Western Reserve University (CWRU) bearing dataset, with the detection and classification accuracy of 98.62 $$\%$$ and 99.47 $$\%$$ . The results indicate that the proposed EV-GLG method can achieve higher accuracy and less time than the other methods, highlighting the practicality in industrial applications.},
  archive      = {J_IJMLC},
  author       = {Han, Huanying and Yang, Dongsheng and Qin, Jia},
  doi          = {10.1007/s13042-022-01612-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3555-3568},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hidden features extraction and amplification based on eigenvalue imaging and gray-level grouping for bearing fault diagnosis},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). No-reference image quality assessment by using convolutional
neural networks via object detection. <em>IJMLC</em>, <em>13</em>(11),
3543–3554. (<a
href="https://doi.org/10.1007/s13042-022-01611-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have been widely applied in the image quality assessment (IQA) field, but the size of the IQA databases severely limits the performance of the CNN-based IQA models. The most popular method to extend the size of database in previous works is to resize the images into patches. However, human visual system (HVS) can only perceive the qualities of objects in an image rather than the qualities of patches in it. Motivated by this fact, we propose a CNN-based algorithm for no-reference image quality assessment (NR-IQA) based on object detection. The network has three parts: an object detector, an image quality prediction network, and a self-correction measurement (SCM) network. First, we detect objects from input image by the object detector. Second, a ResNet-18 network is applied to extract features of the input image and a fully connected (FC) layer is followed to estimate image quality. Third, another ResNet-18 network is used to extract features of both the images and its detected objects, where the features of the objects are concatenated to the features of the image. Then, another FC layer is followed to compute the correction value of each object. Finally, the predicted image quality is amended by the SCM values. Experimental results demonstrate that the proposed NR-IQA model has state-of-the-art performance. In addition, cross-database evaluation indicates the great generalization ability of the proposed model.},
  archive      = {J_IJMLC},
  author       = {Cao, Jingchao and Wu, Wenhui and Wang, Ran and Kwong, Sam},
  doi          = {10.1007/s13042-022-01611-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3543-3554},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {No-reference image quality assessment by using convolutional neural networks via object detection},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Selective relation-aware representations for person
re-identification. <em>IJMLC</em>, <em>13</em>(11), 3523–3541. (<a
href="https://doi.org/10.1007/s13042-022-01610-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have shown the effectiveness of the joint learning of global and part-level features for person re-identification (Re-ID) task, as they target to enhance the discriminative feature representations of pedestrian from the perspective of multiple granularities. However, most of these methods ignore the global structural relation information under adaptive receptive fields, and the local structural relation between parts, making it hard to fully utilize rich structural relation information of pedestrian to form the stable coherent structural patterns. In this paper, we propose selective relation-aware representations (SRAR) for person Re-ID. The framework of SRAR mainly consists of a distinctive attention module and a part relation-aware (PRA) module. Firstly, the distinctive attention module embraces selective position attention module and channel attention (CA) module, which are designed to selectively exploit spatial-wise and channel-wise relation-aware salient feature representations under adaptive receptive fields for the pedestrian. Furthermore, to comprehensively grasp the coherent structural patterns of pedestrian, the PRA module is introduced to promote the interaction between part-level features, and further obtain relation-aware fine-grained feature representations. Extensive experiments are performed on the three popular datasets, including Market1501, DukeMTMC-reID, CUHK03, which validate that our method achieves a competitive performance.},
  archive      = {J_IJMLC},
  author       = {Luo, Xi and Jiang, Min and Kong, Jun},
  doi          = {10.1007/s13042-022-01610-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3523-3541},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Selective relation-aware representations for person re-identification},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-label causal feature selection based on neighbourhood
mutual information. <em>IJMLC</em>, <em>13</em>(11), 3509–3522. (<a
href="https://doi.org/10.1007/s13042-022-01609-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection has gained significant attention over the past decades. However, most existing algorithms are lack of interpretability and uncover the causal mechanisms. As we know, Markov blanket (MB) is a key concept in Bayesian network, which can be used to represent the local causal structure of a variable and the selected optimal features for multi-label feature selection. To select casual features for multi-label learning, in this paper, Parents and Children (PC) of each label are discovered via the Hiton method. Then, we distinguish P &amp; C and search Spouses (SP) of each label based on neighborhood conditional mutual information. Moreover, the equivalent information phenomenon brought by multi-label datasets will cause some features to be ignored. A metric of conditional independence test is designed, which can be used to retrieve ignored features. In addition, we search common features between relevant labels and label-specific features for a single label. Finally, we propose a Multi-label Causal Feature Selection with Neighbourhood Mutual Information algorithm, called MCFS-NMI. To verify the performance of MCFS-NMI, we compare it with five well-established multi-label feature selection algorithms on six datasets. Experiment results show that the proposed algorithm achieves highly competitive performance against all comparing algorithms.},
  archive      = {J_IJMLC},
  author       = {Wang, Jie and Lin, Yaojin and Li, Longzhu and Wang, Yun-an and Xu, Meiyan and Chen, Jinkun},
  doi          = {10.1007/s13042-022-01609-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3509-3522},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-label causal feature selection based on neighbourhood mutual information},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). When to transfer: A dynamic domain adaptation method for
effective knowledge transfer. <em>IJMLC</em>, <em>13</em>(11),
3491–3508. (<a
href="https://doi.org/10.1007/s13042-022-01608-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning has achieved a lot of success recently in saving training samples. However, most of the existing methods only focus on what and how to transfer, but ignore when is the proper transfer time. In the study, we find that transfer useful knowledge at proper time is also significant for the performance. To address this issue, we propose a dynamic domain adaptation approach based on the particle swarm optimization evolutionary algorithm, which searches transfer opportunity automatically for different data domains and training stages. We evaluate the proposed method on various deep learning network structures, and find that the transfer coefficient has large variance in the first several training epochs, and becomes smaller later. This indicates that the features learned in the first several epochs are not stable and is not suitable for static transfer. In addition, the proposed method is not sensitive to the hyper-parameters generated, and it searches suitable transfer coefficients dynamically and automatically instead of conventional manual way. Extensive experiments conducted on various datasets and network structures demonstrate the superiority of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Xie, Xiurui and Cai, Qing and Zhang, Hongjie and Zhang, Malu and Yang, Zeheng and Liu, Guisong},
  doi          = {10.1007/s13042-022-01608-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3491-3508},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {When to transfer: A dynamic domain adaptation method for effective knowledge transfer},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On rough set based fuzzy clustering for graph data.
<em>IJMLC</em>, <em>13</em>(11), 3463–3490. (<a
href="https://doi.org/10.1007/s13042-022-01607-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data clustering refers to partition the original data set into some subsets such that every vertex belongs to one or more subsets at the same time. For graph data that composed by attribute information of vertices as well as structural information between vertices, how to make an efficient clustering is not an easy thing. In this paper, we propose a novel method of how to partition graph data into some overlapping subgraph data in aspect of rough set theory. At first, we introduce a detailed description about the global similarity measurement of vertices. After that, an objective-function oriented optimization model is constructed in terms of updating fuzzy membership degree and cluster center that based on the theory of rough set. Obviously, the determined cluster is no longer a fuzzy set, but a rough set, that is to say, the cluster is expressed by the upper approximation set and lower approximation set. Finally, eleven real-world graph data and four synthetic graph data are applied to verify the validity of the proposed fuzzy clustering algorithm. The experimental results show that our algorithm is better than existing clustering approach to some extent.},
  archive      = {J_IJMLC},
  author       = {He, Wenqian and Liu, Shihu and Xu, Weihua and Yu, Fusheng and Li, Wentao and Li, Fang},
  doi          = {10.1007/s13042-022-01607-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3463-3490},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {On rough set based fuzzy clustering for graph data},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Consistency measure of the WH-PLPR under the risk
identification of PPP projects. <em>IJMLC</em>, <em>13</em>(11),
3441–3461. (<a
href="https://doi.org/10.1007/s13042-022-01606-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Risk identification is the primary link and a significant basis for risk management. It is difficult to identify critical risk factors (CRFs) in terms of the uncertainty, diversity, and incompleteness of risk factors. The various preferences for different stakeholders could cause different identification results. Hence, we propose the weakened hedged probabilistic linguistic preference relation (WH-PLPR) to identify CRFs from the stakeholders’ preferences. For the WH-PLPR, checking and revising individual consistency is the basic part of the decision support model. Hence, the main contribution of this paper is studied in three parts: First, the concept of the WH-PLPR is given. Some consistency concepts, namely, weakened consistency, additive consistency, and satisfactory consistency of the WH-PLPR are defined. After that, the algorithms for improving the consistency of the WH-PLPR are studied. Then, we identify CRFs from stakeholders’ perspectives with the WH-PLPR information. A case study of a PPP project illustrates the utility and effectiveness of the proposed model. A sensitivity analysis of the WH-PLPR is introduced to illustrate the focus on consistency in the WH-PLPR, as well as the comparison of the consistency of the WH-PLPR with the linguistic hedged preference relations (LHPR) and the probabilistic linguistic preference relations (PLPR), which illustrates that weak consistency is the basis for satisfactory consistency. Moreover, the ranking results of CRFs show robustness for WH-PLPRs reaching satisfactory consistency.},
  archive      = {J_IJMLC},
  author       = {Wang, Lina and Xu, Zeshui and Hao, Zhinan},
  doi          = {10.1007/s13042-022-01606-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3441-3461},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Consistency measure of the WH-PLPR under the risk identification of PPP projects},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RLIM: Representation learning method for influence
maximization in social networks. <em>IJMLC</em>, <em>13</em>(11),
3425–3440. (<a
href="https://doi.org/10.1007/s13042-022-01605-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A core issue in influence propagation is influence maximization, which aims to find a set of nodes that maximize influence spread by adopting a specific information diffusion model. The limitation of the existing algorithms is they excessively depend on the information diffusion model and randomly set the propagation ability. Therefore, most algorithms are difficult to apply in large-scale social networks. A method to solve the problem is neural network architecture. Based on the architecture, the paper proposes Representation Learning for Influence Maximization (RLIM) algorithm. The algorithm consists of three main parts: the influence cascade of each source node is the premise; the multi-task deep learning neural network to classify influenced nodes and predict propagation ability is the fundamental bridge; the prediction model applying to the influence maximization problem by the greedy strategy is the purpose. Furthermore, the experimental results show that the RLIM algorithm has greater influence spread than the state-of-the-art algorithms in different online social network datasets, and the information diffusion is more accurate.},
  archive      = {J_IJMLC},
  author       = {Sun, Chengai and Duan, Xiuliang and Qiu, Liqing and Shi, Qiang and Li, Tengteng},
  doi          = {10.1007/s13042-022-01605-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3425-3440},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {RLIM: Representation learning method for influence maximization in social networks},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FewJoint: Few-shot learning for joint dialogue
understanding. <em>IJMLC</em>, <em>13</em>(11), 3409–3423. (<a
href="https://doi.org/10.1007/s13042-022-01604-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning (FSL) is one of the key future steps in machine learning and raises a lot of attention. In this paper, we focus on the FSL problem of dialogue understanding, which contains two closely related tasks: intent detection and slot filling. Dialogue understanding has been proven to benefit a lot from jointly learning the two sub-tasks. However, such joint learning becomes challenging in the few-shot scenarios: on the one hand, the sparsity of samples greatly magnifies the difficulty of modeling the connection between the two tasks; on the other hand, how to jointly learn multiple tasks in the few-shot setting is still less investigated. In response to this, we introduce FewJoint, the first FSL benchmark for joint dialogue understanding. FewJoint provides a new corpus with 59 different dialogue domains from real industrial API and a code platform to ease FSL experiment set-up, which are expected to advance the research of this field. Further, we find that insufficient performance of the few-shot setting often leads to noisy sharing between two sub-task and disturbs joint learning. To tackle this, we guide slot with explicit intent information and propose a novel trust gating mechanism that blocks low-confidence intent information to ensure high quality sharing. Besides, we introduce a Reptile-based meta-learning strategy to achieve better generalization in unseen few-shot domains. In the experiments, the proposed method brings significant improvements on two datasets and achieve new state-of-the-art performance.},
  archive      = {J_IJMLC},
  author       = {Hou, Yutai and Wang, Xinghao and Chen, Cheng and Li, Bohan and Che, Wanxiang and Chen, Zhigang},
  doi          = {10.1007/s13042-022-01604-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3409-3423},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {FewJoint: Few-shot learning for joint dialogue understanding},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Universum based kernelized weighted extreme learning machine
for imbalanced datasets. <em>IJMLC</em>, <em>13</em>(11), 3387–3408. (<a
href="https://doi.org/10.1007/s13042-022-01601-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced classification is a challenging problem in the fields of machine learning and data mining. Cost-sensitive methods can handle this issue by considering different misclassification costs of classes. Various modifications of support vector machine (SVM) and extreme learning machine (ELM) have been proposed to handle the class imbalance problem, which focuses on different aspects to resolve the class imbalance. Such as Weighted ELM (WELM) and weighted SVM (WSVM). The Universum SVM (USVM) incorporates the prior information in the classification model by adding Universum sample to the training sample to handle the class imbalance problem. Various other modifications of SVM have been proposed, which use Universum sample in the classification model generation. Moreover, the existing ELM-based classification models intended to tackle class imbalance do not consider the prior information about the sample distribution for training. An ELM-based classification model creates two symmetry planes, one for each class. The Universum-based ELM classification model tries to create a third plane between the two symmetric planes using Universum sample. This paper proposes a novel hybrid framework called Universum-based kernelized WELM (UKWELM) and Universum-based reduced kernelized WELM (URKWELM), which combines the Universum learning with WELM for the first time to inherit the advantages of both techniques. Universum samples are the training samples from the same domain but they do not belong to any of the target classes. The proposed UKWELM, URKWELM, and other classifiers in consideration are evaluated by using Knowledge Extraction based on Evolutionary Learning dataset repository. The experimental results demonstrate that UKWELM and URKWELM achieve better performance in contrast to the rest of the classifiers for imbalance learning.},
  archive      = {J_IJMLC},
  author       = {Raghuwanshi, Bhagat Singh and Mangal, Akansha and Shukla, Sanyam},
  doi          = {10.1007/s13042-022-01601-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3387-3408},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Universum based kernelized weighted extreme learning machine for imbalanced datasets},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-paced latent embedding space learning for multi-view
clustering. <em>IJMLC</em>, <em>13</em>(11), 3373–3386. (<a
href="https://doi.org/10.1007/s13042-022-01600-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering (MVC) can integrate the complementary information between different views to remarkably improve clustering performance. However, the existing methods suffer from the following drawbacks: (1) multi-view data are often lying on high-dimensional space and inevitably corrupted by noise and even outliers, which poses challenges for fully exploiting the intrinsic structure of views; (2) the non-convex objective functions prone to becoming stuck into bad local minima; and (3) the high-order structure information has been largely ignored, resulting in suboptimal solution. To alleviate these problems, this paper proposes a novel method, namely Self-paced Latent Embedding Space Learning (SLESL). Specifically, the views are projected into a latent embedding space to dimensional-reduce and clean the data, from simplicity to complexity in a self-paced manner. Meanwhile, multiple candidate graphs are learned in the latent space by using embedded self-expressiveness learning. After that, these graphs are stacked into a tensor to exploit the high-order structure information of views, such that a refined consensus affinity graph can be obtained for spectral clustering. The experimental results demonstrate the effectiveness of our proposed method.},
  archive      = {J_IJMLC},
  author       = {Li, Haoran and Ren, Zhenwen and Zhao, Chunyu and Xu, Zhi and Dai, Jian},
  doi          = {10.1007/s13042-022-01600-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3373-3386},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Self-paced latent embedding space learning for multi-view clustering},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Consistency regularization for deep semi-supervised
clustering with pairwise constraints. <em>IJMLC</em>, <em>13</em>(11),
3359–3372. (<a
href="https://doi.org/10.1007/s13042-022-01599-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its powerful learning capabilities for high-dimensional and complex data, deep semi-supervised clustering algorithms often outperform traditional semi-supervised clustering methods. However, most deep semi-supervised clustering methods cannot fully utilize prior knowledge and unlabeled data. Deep semi-supervised classification algorithms have recently made significant progress in using unlabeled data during training by combining a consistency regularization method. Consistency training encourages network predictions to remain consistent when the input is perturbed. Motivated by the success of consistency regularization methods, we proposed a new semi-supervised clustering framework based on Siamese networks. To leverage the additional structure of unlabeled data and to uncover more information hidden by pairwise constraints, we add a consistency regularization loss, calculated on unlabeled data and pairwise constraints, to our objective function. After consistency training, the connected data can be closer in the learned feature space, while the disconnected data can be far away. To verify the effectiveness of the proposed method, we conducted extensive experiments on several real-world data sets. Experimental results show that the proposed method is more effective than other state-of-the-art methods in clustering performance.},
  archive      = {J_IJMLC},
  author       = {Huang, Dan and Hu, Jie and Li, Tianrui and Du, Shengdong and Chen, Hongmei},
  doi          = {10.1007/s13042-022-01599-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3359-3372},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Consistency regularization for deep semi-supervised clustering with pairwise constraints},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Risk-averse support vector classifier machine via moments
penalization. <em>IJMLC</em>, <em>13</em>(11), 3341–3358. (<a
href="https://doi.org/10.1007/s13042-022-01598-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machine (SVM) has always been one of the most successful learning methods, with the idea of structural risk minimization which minimizes the upper bound of the generalization error. Recently, a tighter upper bound of the generalization error, related to the variance of loss, is proved as the empirical Bernstein bound. Based on this result, we propose a novel risk-averse support vector classifier machine (RA-SVCM), which can achieve a better generalization performance by considering the second order statistical information of loss function. It minimizes the empirical first- and second-moments of loss function, i.e., the mean and variance of loss function, to achieve the “right” bias-variance trade-off for general classes. The proposed method can be solved by the kernel reduced and Newton-type technique under certain conditions. Empirical studies show that the RA-SVCM achieves the best performance in comparison with other classical and state of art methods. The additional analysis shows that the proposed method is insensitive to the parameters, so abroad range of parameters lead to satisfactory performance. The proposed method is a general form of standard SVM, so it enriches the related studies of SVM.},
  archive      = {J_IJMLC},
  author       = {Fu, Cui and Zhou, Shuisheng and Zhang, Junna and Han, Banghe and Chen, Yuxue and Ye, Feng},
  doi          = {10.1007/s13042-022-01598-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3341-3358},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Risk-averse support vector classifier machine via moments penalization},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Group decision-making method with directed graph under
linguistic environment. <em>IJMLC</em>, <em>13</em>(11), 3329–3340. (<a
href="https://doi.org/10.1007/s13042-022-01597-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a group decision-making method of neighborhood operator based on the directed graph is proposed under a linguistic environment, which considers only the dominance relation of elements of linguistic term sets and not consider the algebraic operations of its elements. In linguistic-valued expert information system, the linguistic term set opinions of experts are compared one by one, and the directed graph between objects is established based on the dominance matrix between objects. Then, the neighborhood operator is used between objects to fuse expert opinions. A new group decision-making method is designed in linguistic environment, and this method overcomes the semantic distortion and information loss by linguistic information processing, and reduces the restriction on linguistic term sets. Finally, the effectiveness and non-randomness of the new method are verified by applying it in the film evaluation of Douban film review website ( https://movie.douban.com ).},
  archive      = {J_IJMLC},
  author       = {Fu, Yu and Cai, Ruipeng and Yu, Bin},
  doi          = {10.1007/s13042-022-01597-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3329-3340},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Group decision-making method with directed graph under linguistic environment},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BUS-net: A bimodal ultrasound network for breast cancer
diagnosis. <em>IJMLC</em>, <em>13</em>(11), 3311–3328. (<a
href="https://doi.org/10.1007/s13042-022-01596-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasound (US) is a fast and non-invasive imaging approach, which is recommended by current practice guidelines as early breast cancer screening. B-mode and contrast-enhanced ultrasound(CEUS) are two US modalities proven to detect abnormal tissues. However, no one has been able to make full use of these two modal ultrasound data characteristically to complete the classification problem. This paper proposed a bimodal ultrasound network (BUS-Net) capable of simultaneously dealing with the B-mode US and CEUS video. In the CEUS branch, We use seven CEUS pathological characteristics as multiple labels instead of the traditional two labels (benign and malignant) to extract the pathological semantic representative features. The model can be more general and robust by transforming the binary learning task into a multi-class learning task. In the B-mode US branch, we use a group of shape descriptors to identify hard samples with abnormal morphology. A shape constraint loss term is proposed to impose the shape constraints in the training phase and enhance its distinguish ability for hard samples. Finally, the two modal ultrasound data features are fused to realize the classification of benign and malignant tumors. Our experiments show that the classification accuracy is significantly improved using our bimodal strategy. Compared with existing breast ultrasound classification methods, our method increased by an average of 3 percentage points in each evaluation index, and the TNR and AUC index both exceeded 92\%. This also demonstrates that our approach can more accurately classify ultrasound images with more complex imaging. In general, the bimodal ultrasound network proposed in this paper, which integrates bimodal data features, further improves the classification ability of the model. The multi-label learning task of the CEUS branch enhances the robustness of the model. The shape constraint loss term of the B-mode US branch improves its ability to distinguish between hard samples. The algorithm in this paper has good clinical guidance value.},
  archive      = {J_IJMLC},
  author       = {Gong, Xun and Zhao, Xu and Fan, Lin and Li, Tianrui and Guo, Ying and Luo, Jun},
  doi          = {10.1007/s13042-022-01596-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3311-3328},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {BUS-net: A bimodal ultrasound network for breast cancer diagnosis},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel multiple temporal-spatial convolution network for
anode current signals classification. <em>IJMLC</em>, <em>13</em>(11),
3299–3310. (<a
href="https://doi.org/10.1007/s13042-022-01595-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anode current signals (ACS) play an important role in aluminum reduction production. Owing to the complexity dynamic and temporal-spatial dependency characteristics, classification of ACS is a challenging problem and the existing classification methods are failed to capture these characteristics. To address this issue, a multiple temporal-spatial convolution network (MTSCN) combining graph convolutional network (GCN) and one-dimension convolutional neural network (1-D-CNN) is proposed in this paper. Firstly, a adjacency matrix is first introduced to characterize spatial structure of ACS. Secondly, based on the spatial structure, a novel machine learning framework which combines GCN and 1-D-CNN is proposed. Specifically, multi-layer of 1-D-CNN and multi-layer of GCN are used to capture temporal and spatial dependencies of ACS, respectively. The obtained data-dirved model is able to identify abnormalities of ACS. Finally, results carried out in real-world ACS data set are given to verify the effectiveness of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Wan, Xiaoxue and Cen, Lihui and Chen, Xiaofang and Xie, Yongfang},
  doi          = {10.1007/s13042-022-01595-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3299-3310},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel multiple temporal-spatial convolution network for anode current signals classification},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ACP based reinforcement learning for long-term recommender
system. <em>IJMLC</em>, <em>13</em>(11), 3285–3297. (<a
href="https://doi.org/10.1007/s13042-022-01594-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems aim to suggest the items which can best fit the needs of the users and thus play an important role in online services. To get a satisfactory recommendation, some researchers model the recommendation procedure as a Markov decision process where the recommender is the agent and the users are the environment. Then, they use reinforcement learning to perform the recommendation by sharing the browsing histories of different users. However, when the number of users is large, there will be much noise in the sharing process, limiting the ability of reinforcement learning to generate a satisfactory recommendation. ACP approach is proposed to deal with social computing by learning a parallel system from the real system. There can be less noise in the parallel system than that in the real system with an effective learning process, thus the ACP approach has the potential to address the noise in the recommendation. In this paper, we combine the ACP approach into the reinforcement learning based recommender system to deal with the noise and thus improve the recommendation. Firstly, based on the ACP approach, we train a parallel environment of the real environment. Then we use the trained parallel environment to predict the future state in the Markov decision process of the recommender system. There will be less noise in the predicted states than that in the original states, since the output of our parallel environment is effectively learned by the expectation of the future state in the deep neural network. Finally, instead of the original states, we use the predicted states to generate the recommendation list in the reinforcement learning for the recommendation. In this way, the generated recommendation list can be better with less noise from the states. The theoretical analysis and the experiment illustrate that our recommender system can better perform the recommendation than existing recommender systems.},
  archive      = {J_IJMLC},
  author       = {Huang, Tianyi and Li, Min and Zhu, William},
  doi          = {10.1007/s13042-022-01594-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3285-3297},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {ACP based reinforcement learning for long-term recommender system},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-paced and bayes-decision-rule linear KNN prediction.
<em>IJMLC</em>, <em>13</em>(11), 3267–3283. (<a
href="https://doi.org/10.1007/s13042-022-01593-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While a testing sample may be first encoded linearly with labeled samples and then classified with KNN on the sum of the obtained weights of the samples in each class so as to avoid the consistent distribution assumption explicitly or implicitly used in most of the existing classification methods for training and testing samples, a novel self-paced and Bayes-decision-rule linear KNN prediction method SBLD-KNN in this study will be proposed to achieve three goals: (1) class-ware information will be explicitly reflected in a grouping effect regularization term so as to share the sparsity of a linear encoder and simultaneously have grouping effect of weights on each class; (2) the resultant predictor behaves like Bayes-decision-rule for minimum error; (3) self-paced regularized term is designed to adaptively truncate the weights of labeled samples for enhancing generalization. In order to do so, the corresponding objective function of SBLD-KNN is designed and then optimized by using the alternating optimization strategy, and its Bayes-decision-rule is theoretically analyzed. Our experimental results on benchmark datasets witness the effectiveness of SBLD-KNN, in contrast to the comparative methods, including SBLD-KNN’s simplified version BD-KNN with weight’s truncating rather than self-pacing.},
  archive      = {J_IJMLC},
  author       = {Zhang, Jin and Bian, Zekang and Wang, Shitong},
  doi          = {10.1007/s13042-022-01593-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3267-3283},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Self-paced and bayes-decision-rule linear KNN prediction},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Empirical study on virtual order of class labels in nominal
classification. <em>IJMLC</em>, <em>13</em>(11), 3255–3266. (<a
href="https://doi.org/10.1007/s13042-022-01592-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary Decomposition can be adopted in ordered and unordered ways. Inspired by the case that label order information can be exploited to improve the ordinal classification performance through adopting an ordered decomposition strategy, this paper explores whether the effectiveness of binary decomposition in nominal classification tasks can be improved by setting a virtual label order. The essential purpose of setting a virtual order is to obtain small intra-class distances and large inter-class distances after binary decomposition, such that simpler binary classification tasks are obtained. The experimental results show that setting a virtual order results in an improvement of the classification performance as expected. However, the performance obtained by setting a virtual order does not show significant superiority in comparison with the one produced by some unordered decomposition strategies, and the reasons have been analysed in the context of the relationship between virtual orders and inter-class distances.},
  archive      = {J_IJMLC},
  author       = {Li, Chengwei and Liu, Han and Ming, Zhong},
  doi          = {10.1007/s13042-022-01592-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3255-3266},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Empirical study on virtual order of class labels in nominal classification},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Aquila coyote-tuned deep convolutional neural network for
the classification of bare skinned images in websites. <em>IJMLC</em>,
<em>13</em>(10), 3239–3254. (<a
href="https://doi.org/10.1007/s13042-022-01591-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pornographic websites become increasingly obdurate via disguising and misleading the under-aged people, which obstruct the development of a healthy and safe network environment. The conventional strategies of bare skin classification perform the detection process through a single feature of these sites, which would be unsuccessful to solve the more complicated and tedious situations. Hence, this research focuses on proposing a well-adapted port image classification model using an optimized deep convolutional neural network (Deep CNN). The significance of this research relies on the proposed Aquila Coyote (AqCO) optimization algorithm, developed with the integration of Aquila hunters and the coyote hunters, which engages in tuning the hyper-parameters of the Deep CNN classifier. Moreover, the significant features of the image are utilized by the classifier, which further boosts the classification accuracy of the proposed model. The analysis is done based on performance parameters, such as accuracy, sensitivity, and specificity in such a way to evaluate the efficiency of the proposed porn image classification model. The maximal accuracy of the proposed model is 95.91\% for the B-Praneeth dataset, which is high as compared to the existing methods of porn image classification methods.},
  archive      = {J_IJMLC},
  author       = {Gupta, Jaya and Pathak, Sunil and Kumar, Gireesh},
  doi          = {10.1007/s13042-022-01591-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3239-3254},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Aquila coyote-tuned deep convolutional neural network for the classification of bare skinned images in websites},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A universal emotion recognition method based on feature
priority evaluation and classifier reinforcement. <em>IJMLC</em>,
<em>13</em>(10), 3225–3237. (<a
href="https://doi.org/10.1007/s13042-022-01590-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotions play an indispensable role in human behaviors, and interaction based on emotion perception is attracting more attention. A method based on feature priority evaluation and classifier reinforcement is proposed in order to improve the accuracy of four-type subject-cross emotion identification. Firstly, the mixed-cross data processing strategy is employed to reduce the sample differences of extracted features. Then the feature selection method of feature priority evaluation with symmetric uncertainty is proposed to implement feature optimization for fused multi-channel features, which can effectively achieve representation of emotion states. Finally, the classifier reinforcement method of SVM-Adaboost is suggested to improve the classification performance of conventional SVM. The database DEAP is employed to verify the validity of the proposed method. Experimental results from different point of view show that the proposed method present a good emotion identification performance with accuracy 86.44\%.},
  archive      = {J_IJMLC},
  author       = {Pan, Lizheng and Wang, Shunchao and Ding, Yi and Zhao, Lu and Song, Aiguo},
  doi          = {10.1007/s13042-022-01590-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3225-3237},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A universal emotion recognition method based on feature priority evaluation and classifier reinforcement},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constrained class-wise feature selection (CCFS).
<em>IJMLC</em>, <em>13</em>(10), 3211–3224. (<a
href="https://doi.org/10.1007/s13042-022-01589-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection plays a vital role as a preprocessing step for high dimensional data in machine learning. The basic purpose of feature selection is to avoid “curse of dimensionality” and reduce time and space complexity of training data. Several techniques, including those that use information theory, have been proposed in the literature as a means to measure the information content of a feature. Most of them incrementally select features with max dependency with the category but minimum redundancy with already selected features. A key missing idea in these techniques is the fair representation of features with max dependency among the different categories, i.e., skewed selection of features having high mutual information (MI) with a particular class. This can result in a biased classification in favor of that particular class while other classes have low matching scores during classification. We propose a novel approach based on information theory that selects features in a class-wise fashion rather than based on their global max dependency. In addition, a constrained search is used instead of a global sequential forward search. We prove that our proposed approach enhances Maximum Relevance while keeping Minimum Redundancy under a constrained search. Results on multiple benchmark datasets show that our proposed method improves accuracy as compared to other state-of-the-art feature selection algorithms while having a lower time complexity.},
  archive      = {J_IJMLC},
  author       = {Hussain, Syed Fawad and Shahzadi, Fatima and Munir, Badre},
  doi          = {10.1007/s13042-022-01589-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3211-3224},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Constrained class-wise feature selection (CCFS)},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ESRM: An efficient regression model based on random kernels
for side channel analysis. <em>IJMLC</em>, <em>13</em>(10), 3199–3209.
(<a href="https://doi.org/10.1007/s13042-022-01588-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many researches transform the traditional side channel analysis (SCA) into a classification problem. However, there are some inconsistencies in the evaluation metrics and excessive training overhead. A regression model theory is proposed from power traces to intermediate values in this work. It leads us to design a random convolution model that can closely fit the timing features of power consumption and transform them directly to intermediate values. In training phase, the raw power traces on ASCAD is processed to the dataset with six subsets, which is similar to the form of UCR sets. The determination coefficient ( $$R^2$$ ), time and correlation coefficient are used in training and evaluation. The experiments show that the model has a faster training speed and better attack effect. Our model can address two problems in combining deep learning with SCA. Further, the model can quickly adapt to new cryptographic algorithms by greatly reducing the training time.},
  archive      = {J_IJMLC},
  author       = {Ou, Yu and Li, Lang and Li, Di and Zhang, Jian},
  doi          = {10.1007/s13042-022-01588-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3199-3209},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {ESRM: An efficient regression model based on random kernels for side channel analysis},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MAGDM in hesitant interval-valued pythagorean linguistic
z-number based on combined score function and entropy. <em>IJMLC</em>,
<em>13</em>(10), 3173–3198. (<a
href="https://doi.org/10.1007/s13042-022-01587-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new linguistic fuzzy model is proposed by combining a linguistic fuzzy set and a linguistic Z-number and is named hesitant interval-valued Pythagorean linguistic Z-number (HIVPLZN). It can be used as an effective tool for actual uncertain decision-making, which can effectively enhance the reliability of decision-making information, reflect the fuzziness, flexibility and practicability of decision-making information, and offer wide application prospects in economics, risk assessment, decision-making and other fields. This paper mainly studies a method to solve the problem of multi-attribute group decision-making. First, three new linguistic scale functions are presented, and HIVPLZN is then proposed. Next, some related operators and the aggregation operator of HIVPLZN are proposed, three kinds of score functions of HIVPLZN are presented to measure the strengths and weaknesses of HIVPLZNs, and a combined score function method is proposed based on the optimal model. Furthermore, the distance formula of HIVPLZN is proposed based on the risk attitude of the decision-maker, and entropy is suggested to measure the uncertainty of HIVPLZN. Finally, a multi-attribute group decision-making (MAGDM) model is constructed, and an example is provided to verify the feasibility and validity of this method by sensitivity analysis and comparison with some existing methods.},
  archive      = {J_IJMLC},
  author       = {Yang, Jinxin and Gu, Dongxiao and Yang, Shanlin and Mei, Kongchun and Cao, Yunxia},
  doi          = {10.1007/s13042-022-01587-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3173-3198},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MAGDM in hesitant interval-valued pythagorean linguistic Z-number based on combined score function and entropy},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection and quantification of anomalies in communication
networks based on LSTM-ARIMA combined model. <em>IJMLC</em>,
<em>13</em>(10), 3159–3172. (<a
href="https://doi.org/10.1007/s13042-022-01586-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The anomaly detection for communication networks is significant for improve the quality of communication services and network reliability. However, traditional communication monitoring methods lack proactive monitoring and real-time alerts and the prediction effect of a single machine learning model on communication data containing multiple features is not ideal. To solve the problem, A prediction-then-detection anomaly detection method was proposed, and quantitative assessment of network anomalies was developed. Specifically, anomaly-free data was obtained by eliminating outliers, and the long short-term memory (LSTM) and autoregressive integral moving average (ARIMA) were combined via residual weighting to predict the future state of the key performance indicators (KPI) without outliers. Anomalies were identified using the error comparison between the prediction and actual values, and the network condition was quantified using the scoring method. It is observed that the proposed LSTM-ARIMA hybrid model has better prediction effect, which can well represent the performance of KPIs of the future state, and the prediction-then-detection anomaly detection method has excellent performance on both precision and recall.},
  archive      = {J_IJMLC},
  author       = {Xue, Sheng and Chen, Hualiang and Zheng, Xiaoliang},
  doi          = {10.1007/s13042-022-01586-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3159-3172},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Detection and quantification of anomalies in communication networks based on LSTM-ARIMA combined model},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). KSRFB-net: Detecting and identifying butterflies in
ecological images based on human visual mechanism. <em>IJMLC</em>,
<em>13</em>(10), 3143–3158. (<a
href="https://doi.org/10.1007/s13042-022-01585-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic butterfly identification using ecological images is essentially an object detection task, but it is far more challenging than a common object detection task. Therefore, an improved RFB (Receptive Field Block) referred to RFB-r module is proposed by reducing the receptive field of original RFB, so as to address the challenges that the folding wings and the overlapping butterflies and the very small ratios of butterflies to an ecological image making feature learning very demanding. Furthermore, K-means algorithm is adopted to select the appropriate sizes and aspect ratios of default boxes, so as to advance the efficiency and accuracy of locating the butterflies in ecological images. Finally, the Soft-NMS (Non-maximum suppression) algorithm is introduced to detect overlapping butterflies in ecological images. At last, the human visual based system referred to KSRFB-net is proposed in this paper by embedding the above three contributions. The extensive ablation experiments on 1408 butterfly ecological images from 94 species show that the KSRFB-net achieves better performance than the SOTA algorithms. Its mAP (mean average precision) is higher than that of the current two-stage object detectors while its speed matches the one-stage object detectors. It realizes the fast and accurate butterfly detection and species identification using ecological images. The proposed RFB-r module is a plug-and-play module and it will be beneficial to the object detection and computer vision and deep learning fields.},
  archive      = {J_IJMLC},
  author       = {Xie, Juanying and Kong, Weixuan and Lu, Yinyuan and Grant, Philip W. and Xu, Shengquan},
  doi          = {10.1007/s13042-022-01585-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3143-3158},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {KSRFB-net: Detecting and identifying butterflies in ecological images based on human visual mechanism},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-granularity information fusion method based on
logistic regression model and dempster-shafer evidence theory and its
application. <em>IJMLC</em>, <em>13</em>(10), 3131–3142. (<a
href="https://doi.org/10.1007/s13042-022-01584-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logistic regression model is a commonly used data correlation analysis model in statistical analysis methods which has been widely used in economics, medicine, sociology, psychology and other fields. Information fusion method based on granular computing is an important big data analysis method in which clustering ensemble method is an important branch. Clustering ensemble method can granulate a data set into a multi granular structure, integrate multiple clustering results, and obtain a better clustering effect than a single clustering algorithm. However it is only applicable to specific data sets and the clustering results have no practical significance, and therefore it is difficult to construct a consistent fusion function. To solve the above problems, this paper proposes a multi-granularity information fusion method based on logistic regression model and D-S evidence theory, and applies it to multi-attribute group decision-making. Firstly, the data set is granulated into multi granular structure by using logistic regression model, and the output result is the probability that each object belongs to each category at different granularities; Secondly, the output results are used to construct the mass functions of all objects at each granularity, and the Dempster synthesis formula in evidence theory is used to fuse the mass functions at each granularity. Then, a multi-granularity information fusion algorithm (LDIF) based on logistic regression model and D-S evidence theory is proposed, and the complexity and experimental analysis of the algorithm are carried out. Finally, the multi-granularity information fusion method based on logistic regression model and D-S evidence theory is applied to multi-attribute group decision-making. The results show that compared with other methods, this method has the advantages of simple calculation, convenient construction of mass function and high classification accuracy. It is very suitable for multi-attribute group decision-making problems and has excellent performance.},
  archive      = {J_IJMLC},
  author       = {Zhao, Huijuan and Mi, Jusheng and Liang, Meishe},
  doi          = {10.1007/s13042-022-01584-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3131-3142},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multi-granularity information fusion method based on logistic regression model and dempster-shafer evidence theory and its application},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fault detection and diagnosis for industrial processes based
on clustering and autoencoders: A case of gas turbines. <em>IJMLC</em>,
<em>13</em>(10), 3113–3129. (<a
href="https://doi.org/10.1007/s13042-022-01583-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial machinery maintenance constitutes an important part of the manufacturing company’s budget. Fault Detection and Diagnosis (henceforth referenced as FDD) plays a key role on maintenance, since it allows for shorter maintenance times and, in the long run, to train predictive maintenance algorithms. The impact of proper maintenance is reflected on an especially costly type of industrial machine: gas turbines. These devices are complex, large pieces of machinery that cause considerable service disruption when downtime occurs. In an effort to shorten these service disruptions and establish the basis for the development of predictive maintenance, we present in this paper an approach to FDD of industrial machinery, such as gas turbines. Our approach exploits the data generated by industrial machinery to train a machine-learning based architecture, combining several algorithms with autoencoders and sliding windows. Our proposed solution helps to achieve early malfunctioning detection and has been tested using real data from real working environments. In order to build our solution, first, we analyze the behavior of the gas turbine from a mathematical point of view. Then, we develop an architecture that is capable of detecting when the gas turbine presents an abnormal behavior. The great advantage of our proposal is that (i) does not require existing disruption data, which can be difficult to obtain, (ii) is not limited to processes with specific time windows, and (iii) provides crucial information in real time to the monitoring staff, generating valuable data for further predictive maintenance. It is worth highlighting that although we exemplify our approach using gas turbines, our approach can be tailored to other FDD problems in complex industrial processes with variable duration that could benefit from the aforementioned advantages.},
  archive      = {J_IJMLC},
  author       = {Barrera, Jose M. and Reina, Alejandro and Mate, Alejandro and Trujillo, Juan C.},
  doi          = {10.1007/s13042-022-01583-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3113-3129},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fault detection and diagnosis for industrial processes based on clustering and autoencoders: A case of gas turbines},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neutrosophic multi-objective green four-dimensional
fixed-charge transportation problem. <em>IJMLC</em>, <em>13</em>(10),
3089–3112. (<a
href="https://doi.org/10.1007/s13042-022-01582-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main inquisition of this paper is to introduce two methods for solving a multi-objective green 4-dimensional fixed-charge transportation problem (MG4FTP) under neutrosophic environment. The increasing use of transportation vehicles, the condition of roads, vehicle type in daily life to meet our needs that create a lot of problems such as global warming, greenhouse gas (GHG) emissions in the nature. In this paper, we minimize transportation cost, carbon emission and transportation time. In real-life situation, all parameters of transportation problem are not tackled by crisp value, fuzzy numbers and intuitionistic fuzzy numbers, then to accommodate the fact we choice here single valued trapezoidal neutrosophic number (SVTNN) for designing such type of transportation problem. Thereafter we use $$\left( \alpha , \beta , \gamma \right) $$ -cut of SVTNN to convert the parameters in interval form of the proposed model. Two new approaches based on neutrosophic programming (NP) and Pythagorean hesitant fuzzy programming (PHFP) are used to extract a better compromise solution of the proposed problem. A comparison is drawn among the compromise solutions that are derived from the programming, by using the score function of SVTNN. Two numerical examples are included to illustrate the applicability and validity of the proposed problem.},
  archive      = {J_IJMLC},
  author       = {Giri, Binoy Krishna and Roy, Sankar Kumar},
  doi          = {10.1007/s13042-022-01582-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3089-3112},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Neutrosophic multi-objective green four-dimensional fixed-charge transportation problem},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Streamer temporal action detection in live video by
co-attention boundary matching. <em>IJMLC</em>, <em>13</em>(10),
3071–3088. (<a
href="https://doi.org/10.1007/s13042-022-01581-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the we-media era, live video is being sought after by more and more web users. How to effectively identify and supervise the streamer activities in the live video is of great significance to promote the high-quality development of the live video industry. The streamer activity can be characterized by the temporal composition of a series of actions. To improve the accuracy of streamer temporal action detection, it is a promising path to utilize the temporal action location and co-attention mechanism to overcome the problem of blurring action boundary. Therefore, a streamer temporal action detection method by co-attention boundary matching in live video is proposed. (1) The global spatiotemporal features and action template features of live video are extracted by using two-stream convolutional network and action spatiotemporal attention network respectively. (2) The probability sequences are generated from the global spatiotemporal features through temporal action evaluation, and the boundary matching confidence maps are produced by confidence evaluation of global spatiotemporal features and action template features under the co-attention mechanism. (3) The streamer temporal actions are detected based on the action proposals generated by probability sequences and boundary matching maps. We establish a real-world streamer action BJUT-SAD dataset and conduct extensive experiments to verify that our method can boost the accuracy of streamer temporal action detection in live video. In particular, our temporal action proposal generation and streamer action detection task produce competitive results to prior methods, demonstrating the effectiveness of our method.},
  archive      = {J_IJMLC},
  author       = {Li, Chenhao and He, Chen and Zhang, Hui and Yao, Jiacheng and Zhang, Jing and Zhuo, Li},
  doi          = {10.1007/s13042-022-01581-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3071-3088},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Streamer temporal action detection in live video by co-attention boundary matching},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uncertainty measurement for incomplete set-valued data with
application to attribute reduction. <em>IJMLC</em>, <em>13</em>(10),
3031–3069. (<a
href="https://doi.org/10.1007/s13042-022-01580-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A set-valued information system (SVIS) is the generalization of a single-valued information system. A SVIS with missing information values is called an incomplete set-valued information system (ISVIS). This paper focuses on studying uncertainty measurement for an ISVIS with application to attribute reduction. First, the similarity degree between information values on each attribute is presented in an ISVIS. Then, the tolerance relation induced by each subsystem is given and rough approximations based on this relation is considered. Next, some tools to measure the uncertainty of an ISVIS are put forwarded. Moreover, the validity of the proposed measures is analyzed from the statistical point of view. Finally, information granulation and information entropy are applied to attribute reduction, the incomplete rate is adopted, and the effectiveness under different incomplete rates is analyzed and verified by k-means clustering algorithm and Mean Shift clustering algorithm.},
  archive      = {J_IJMLC},
  author       = {Song, Yan and Luo, Damei and Xie, Ningxin and Li, Zhaowen},
  doi          = {10.1007/s13042-022-01580-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3031-3069},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Uncertainty measurement for incomplete set-valued data with application to attribute reduction},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised modeling and feature selection of sequential
spherical data through nonparametric hidden markov models.
<em>IJMLC</em>, <em>13</em>(10), 3019–3029. (<a
href="https://doi.org/10.1007/s13042-022-01579-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As spherical data (i.e. $$L_2$$ normalized vectors) are often encountered in a variety of real-life applications (such as gesture recognition, gene expression analysis, etc.), sequential spherical data modeling has become an important research topic in recent years. Hidden Markov models (HMMs), as probabilistic graph models, have shown their effectiveness in modeling sequential data in previous research works. In this article, we propose a nonparametric hidden Markov model (NHMM) for modeling time series or sequential spherical data vectors. In our model, the emission distribution of each hidden state obeys a mixture of von Mises (VM) distributions which has better capability for modeling spherical data than other popular distributions (e.g. the Gaussian distribution). As we construct our NHMM by leveraging a Bayesian nonparametric model namely the Dirichlet process, the amount of hidden states and the number of mixture components for each state can be automatically adjusted according to observed data set. In addition, to handle high-dimensional data sets which may contain irrelevant or noisy features, feature selection, which is the process of selecting the “best” feature subset for describing the given data set, is adopted in our framework. In our case, an unsupervised localized feature selection method is incorporated with the developed NHMM, which results in a unified framework that can simultaneously perform data modeling and feature selection. Our model is learned by theoretically developing a convergence-guaranteed algorithm through variational Bayes. The advantages of our model are demonstrated by conducting experiments on both synthetic and real-world sequential data sets.},
  archive      = {J_IJMLC},
  author       = {Fan, Wentao and Hou, Wenjuan},
  doi          = {10.1007/s13042-022-01579-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3019-3029},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Unsupervised modeling and feature selection of sequential spherical data through nonparametric hidden markov models},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary neural networks for deep learning: A review.
<em>IJMLC</em>, <em>13</em>(10), 3001–3018. (<a
href="https://doi.org/10.1007/s13042-022-01578-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary neural networks (ENNs) are an adaptive approach that combines the adaptive mechanism of Evolutionary algorithms (EAs) with the learning mechanism of Artificial Neural Network (ANNs). In view of the difficulties in design and development of DNNs, ENNs can optimize and supplement deep learning algorithm, and the more powerful neural network systems are hopefully built. Many valuable conclusions and results have been obtained in this field, especially in the construction of automated deep learning systems. This study conducted a systematic review of the literature on ENNs by using the PRISMA protocol. In literature analysis, the basic principles and development background of ENNs are firstly introduced. Secondly, the main research techniques are introduced in terms of connection weights, architecture design and learning rules, and the existing research results are summarized and the advantages and disadvantages of different research methods are analyzed. Then, the key technologies and related research progress of ENNs are summarized. Finally, the applications of ENNs are summarized and the direction of future work is proposed.},
  archive      = {J_IJMLC},
  author       = {Ma, Yongjie and Xie, Yirong},
  doi          = {10.1007/s13042-022-01578-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3001-3018},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Evolutionary neural networks for deep learning: A review},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Concept learning consistency under three-way decision
paradigm. <em>IJMLC</em>, <em>13</em>(10), 2977–2999. (<a
href="https://doi.org/10.1007/s13042-022-01576-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept Mining is one of the main challenges both in Cognitive Computing and in Machine Learning. The ongoing improvement of solutions to address this issue raises the need to analyze whether the consistency of the learning process is preserved. This paper addresses a particular problem, namely, how the concept mining capability changes under the reconsideration of the hypothesis class. The issue will be raised from the point of view of the so-called Three-Way Decision (3WD) paradigm. The paradigm provides a sound framework to reconsider decision-making processes, including those assisted by Machine Learning. Thus, the paper aims to analyze the influence of 3WD techniques in the Concept Learning Process itself. For this purpose, we introduce new versions of the Vapnik-Chervonenkis dimension. Likewise, to illustrate how the formal approach can be instantiated in a particular model, the case of concept learning in (Fuzzy) Formal Concept Analysis is considered.},
  archive      = {J_IJMLC},
  author       = {Aranda-Corral, Gonzalo A. and Borrego-Díaz, Joaquín and Galán-Páez, Juan},
  doi          = {10.1007/s13042-022-01576-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2977-2999},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Concept learning consistency under three-way decision paradigm},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Imbalanced driving scene recognition with class focal loss
and data augmentation. <em>IJMLC</em>, <em>13</em>(10), 2957–2975. (<a
href="https://doi.org/10.1007/s13042-022-01575-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving scene recognition based on visual features is essential to develop intelligent transportation systems. However, real-world driving scene data is class imbalanced by nature, leading to the majority classes and the minority classes present different distribution patterns. Specifically, some classes have sufficient samples, while for other massive classes, only very few samples are available. With this distribution, deep neural networks have been found to perform poorly on minority classes. To handle the class Imbalance of Driving Scene Recognition (IDSR), this paper presents a novel class focal loss for imbalanced driving scene recognition to improve recognition performance in minority scenes. It introduces the quantity distribution of categories based on focal loss, which can better balance quantity and difficulty in the training process. In addition, this paper explores a data augmentation method for imbalanced driving scene to improve performance. To evaluate the performance of the proposed method, comprehensive experiments were conducted on real-world driving scene datasets. The results show that the proposed method can substantially outperform state-of-the-art methods in class imbalanced driving scene recognition.},
  archive      = {J_IJMLC},
  author       = {Zhu, Xianglei and Men, Jianfeng and Yang, Liu and Li, Keqiu},
  doi          = {10.1007/s13042-022-01575-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2957-2975},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Imbalanced driving scene recognition with class focal loss and data augmentation},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Global-locality preserving projection for word embedding.
<em>IJMLC</em>, <em>13</em>(10), 2943–2956. (<a
href="https://doi.org/10.1007/s13042-022-01574-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-trained word embedding has a significant impact on constructing representations for sentences, paragraphs and documents. However, existing word embedding methods are typically learned in the Euclidean space. Distributed word embedding suffers from inaccurate semantic similarity and high computational cost in the Euclidean metric space. In this study, we propose global-locality preserving projection to refine word representation by re-embedding word vectors from the original embedding space to a manifold semantic space. Our method extracts the local feature of the word vector and preserves the global feature of the word vector as well. It can discover the local geometric structure that also indicates the latent semantic structure and obtain a compact word embedding subspace. The performance of the method is assessed on several lexical-level intrinsic tasks of semantic similarity and semantic relatedness, and the experimental results demonstrate its advantages over other word embedding-based methods.},
  archive      = {J_IJMLC},
  author       = {Wang, Bolin and Sun, Yuanyuan and Chu, Yonghe and Yang, Zhihao and Lin, Hongfei},
  doi          = {10.1007/s13042-022-01574-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2943-2956},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Global-locality preserving projection for word embedding},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective optimization based on hyperparameter random
forest regression for linear motor design. <em>IJMLC</em>,
<em>13</em>(10), 2929–2942. (<a
href="https://doi.org/10.1007/s13042-022-01573-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing method of multi-objective optimization for linear motors provides poor consideration for model robustness, thus, the models of linear motor which are implemented to multi-objective optimization may not be optimal. A multi-objective optimization design combined Random Forest after hyperparameter optimization and non-dominated sorting genetic algorithm-II (NSGA-II) for Double-sided Linear Flux Switching Permanent Magnet motor (DLFSPMs) is proposed. The average thrust and the thrust ripple which generated by operation of DLFSPMs are selected as objectives. A machine learning algorithm, Random Forest (RF), is introduced to establish the regression models between structural parameters and performances of DLFSPMs. Furthermore, in order to improve the stability and accuracy of the regression models, a hyperparameter optimization, which is called Bayesian Optimization and HyperBand (BOHB), is proposed to search for the best hyperparametric configuration to obtain predicted performance of DLFSPMs. Moreover, the proposed BOHB-RF model is compared with the Bayesian optimization-RF (BO-RF) model and the HyperBand-RF (HB-RF) model to verify the advantages of BOHB-RF model. Then, NSGA-II is adopted to design for multi-objective optimization of DLFSPMs to calculate Pareto front of DLFSPMs performances based on BOHB-RF models. Finally, the results of finite element analysis (FEA) prove the effectiveness and feasibility for proposed modeling and optimizing method.},
  archive      = {J_IJMLC},
  author       = {Wen, Cheng and Zhao, Qiankai and Li, Mingye and Liu, Jingna and Li, Mingwei and Zhao, Xingqiao},
  doi          = {10.1007/s13042-022-01573-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2929-2942},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-objective optimization based on hyperparameter random forest regression for linear motor design},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-way recommendation for a node and a community on
social networks. <em>IJMLC</em>, <em>13</em>(10), 2909–2927. (<a
href="https://doi.org/10.1007/s13042-022-01571-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to the traditional two-way decision making, three-way decision model with a third pending decision has been widely applied since it was put forward. Now it has become a methodology for solving problems in many fields. In social networks, recommending each other between a node and a community has attracted lots of attention. In this paper, we make three-way recommendation for a node and a community, which leads to three results: recommended, not recommended, and pending. Firstly, we divide the network into attribute information table and network structure, and analyze several forces that may affect the relationship between nodes and communities. On the attribute information table, we define the first force based on equivalence relation and conditional probability. In the network structure, we apply the double bounded rough set model of a pair of nodes to a pair of node and community to define other forces. To construct three-way recommendation model, we use the Logistic Regression algorithm to determine the weights of the forces and the evaluation function. Next, inspired by the threshold calculation algorithm based on the maximum weighted entropy, we propose a supervised one. We tested the model on five real networks, and the methods of determining evaluation function and threshold pair are compared with the existing works. Moreover, compared with the existing node-community recommendation models, the rationality and feasibility of the model are shown.},
  archive      = {J_IJMLC},
  author       = {Chen, Yingxiao and Zhu, Ping},
  doi          = {10.1007/s13042-022-01571-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2909-2927},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Three-way recommendation for a node and a community on social networks},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A robust novelty detection framework based on ensemble
learning. <em>IJMLC</em>, <em>13</em>(10), 2891–2908. (<a
href="https://doi.org/10.1007/s13042-022-01569-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novelty detection techniques have been used extensively to discover interesting data patterns in practical applications. However, real-world training data are often contaminated by unknown anomalous examples (outliers), leading to deteriorated detectors. In order to alleviate this problem, this paper proposes a robust novelty detection framework based on ensemble learning. In contrast to traditional parallel outlier ensembles based on variance-reduction, both bias and variance are considered in our ensemble framework. Specifically, we aim to reduce the bias induced by unknown outliers with an iterative mechanism. A weighting scheme is used to combine the result of current iteration with the previous iteration. By gradually removing outliers in the training set, performance of the detector can be improved. In addition, base detectors at all iterations will be aggregated by the weighting scheme in order to realize the variance reduction. Moreover, a flexible function that provides reference ground-truth is proposed so that our detection framework can be effective on different types of data sets. We conduct experiments on 15 benchmark data sets to verify the superiority over parallel ensembles and single models. A case study concerning wind tunnel is also carried out on 10 data sets from a real-world wind tunnel system. Experimental results have shown the superiority of our detector over several competitors.},
  archive      = {J_IJMLC},
  author       = {Wang, Biao and Wang, Wenjing and Wang, Na and Mao, Zhizhong},
  doi          = {10.1007/s13042-022-01569-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2891-2908},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A robust novelty detection framework based on ensemble learning},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NEWTR: A multipath routing for next hop destination in
internet of things with artificial recurrent neural network (RNN).
<em>IJMLC</em>, <em>13</em>(10), 2869–2889. (<a
href="https://doi.org/10.1007/s13042-022-01568-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) and Wireless Sensor Networks (WSN) are a set of low-cost wireless sensors that can collect, process and send environment’s data. WSN nodes are battery powered, therefore energy management is a key factor for long live network. One way to prolong lifetime of network is to utilize routing protocols to manage energy consumption. To have an energy efficient protocol in environment interactions, we can apply ZigBee protocols. Among these Artificial Intelligence Interactions routing methods, Tree Routing (TR) that acts in the tree network topology is considered a simple routing protocol with low overhead for ZigBee. In a tree topology, every nodes can be recognized as a parent or child of another node and in this regard, there is no circling. The most important problem of TR is increasing the number of steps to get data to the destination. To solve this problem several algorithms were proposed that its focus is on fewer steps. In this research we present an artificial Intelligence Tree Routing based on RNN and ZigBee protocol in IoT environment. Simulation results show that NEWTR improve the network lifetime by 5.549\% and decreases the energy consumption (EC) of the network by 5.817\% as compared with AODV routing protocol.},
  archive      = {J_IJMLC},
  author       = {Sumathi, A. C. and Javadpour, Amir and Pinto, Pedro and Sangaiah, Arun Kumar and Zhang, Weizhe and Mahmoodi Khaniabadi, Shadi},
  doi          = {10.1007/s13042-022-01568-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2869-2889},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {NEWTR: A multipath routing for next hop destination in internet of things with artificial recurrent neural network (RNN)},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Label enhancement with label-specific feature learning.
<em>IJMLC</em>, <em>13</em>(10), 2857–2867. (<a
href="https://doi.org/10.1007/s13042-022-01567-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning (LDL) is a novel machine learning paradigm. It addresses the problem of label ambiguity by emphasizing the relevance of each label to a particular instance. Unlike the simple logic vectors in single label learning (SLL) and multi-label learning (MLL), LDL assigns descriptive labels to each instance. Since it is often difficult to collect training sets with precise labels, label enhancement (LE) can be used to recover label distributions from logical labels. Most existing LE models construct label distributions based on a mapping from the feature space to the label space and include two main assumptions: (1) the relationship between features and labels is linear, and (2) all features are shared by all labels. However, in reality, the relationship between features and labels is not purely linear, and different labels may be determined by different features. To solve this problem, in this paper, we propose a new algorithm, that first maps features to a high-dimensional space to explore the nonlinear mapping relationship between features and labels, and then takes full advantage of the labels’ properties determined by specific features, while considering the correlation between labels. The experimental comparison with the existing algorithms verifies the effectiveness of the algorithm proposed in this paper.},
  archive      = {J_IJMLC},
  author       = {Li, Weiwei and Chen, Jin and Gao, Peixue and Huang, Zhiqiu},
  doi          = {10.1007/s13042-022-01567-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2857-2867},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Label enhancement with label-specific feature learning},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic configuration networks for imbalanced data
classification. <em>IJMLC</em>, <em>13</em>(10), 2843–2855. (<a
href="https://doi.org/10.1007/s13042-022-01565-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic configuration networks (SCNs), as a class of advanced randomized learner models, play an important role in predictive data analytics. Given an imbalanced data classification task, the original SCN classifiers may fail to provide satisfied performance because of the density difference of data distribution. This paper contributes to a development of imbalanced learning for SCNs (IL-SCNs) classifier design with skewed class distribution. Concretely, a balancer is proposed and used in IL-SCNs to compromise between the majority class and the minority class. In addition, a fast computation algorithm is adopted to update the output weights, which achieves lower computation complexity of IL-SCNs. Experimental results show that IL-SCNs significantly outperforms the existing state-of-the-art learning models.},
  archive      = {J_IJMLC},
  author       = {Dai, Wei and Ning, Chuanfeng and Nan, Jing and Wang, Dianhui},
  doi          = {10.1007/s13042-022-01565-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2843-2855},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Stochastic configuration networks for imbalanced data classification},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online visual tracking via background-aware siamese
networks. <em>IJMLC</em>, <em>13</em>(10), 2825–2842. (<a
href="https://doi.org/10.1007/s13042-022-01564-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Siamese network based trackers, a set of related methods have produced considerable performance improvement. However, the tracking results are often disturbed due to the background noise from the template image and background distractor objects from the search image. In this paper, we present an elegant background-aware Siamese tracker for online single object visual tracking. Specifically, a new basic tracking framework is firstly proposed to implement the target localization, bounding box regression, and IoU prediction with offline multi-task learning. During the online tracking stage, we design a novel background-aware tracker with two strategies. Firstly, a spatial mask is introduced to reduce the impacts of background noise from the template image. Secondly, we predict a background-aware salient map to discover and suppress the distractor features in the search image. To validate the effectiveness, we conduct extensive experiments and exhaustive comparisons on OTB2013, OTB2015, VOT2019, UAV123, and GOT10k tracking datasets. Experimental results demonstrate that the proposed tracker, dubbed BaSiamIoU, can achieve state-of-the-art performance while running over 50 FPS.},
  archive      = {J_IJMLC},
  author       = {Tan, Ke and Xu, Ting-Bing and Wei, Zhenzhong},
  doi          = {10.1007/s13042-022-01564-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2825-2842},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Online visual tracking via background-aware siamese networks},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep clustering by multi-level feature fusion.
<em>IJMLC</em>, <em>13</em>(10), 2813–2823. (<a
href="https://doi.org/10.1007/s13042-022-01557-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep clustering extracts non-linear features through neural networks to improve the clustering performance. At present, deep clustering algorithms mostly only use single-level features for clustering, ignoring shallow features information. To address this issue, we propose a joint learning framework that combines features extraction, features fusion and clustering. Different levels of features are extracted through dual convolutional autoencoders and fused. Moreover, the clustering loss function jointly updates the dual network parameters and cluster centers. The experimental results show that the proposed network architecture fusing different levels of features effectively improves clustering results without increasing model complexity. Compared with traditional and deep clustering algorithms, the Clustering Accuracy (ACC) and the Normalized Mutual Information (NMI) metrics are significantly improved.},
  archive      = {J_IJMLC},
  author       = {Hou, Haiwei and Ding, Shifei and Xu, Xiao},
  doi          = {10.1007/s13042-022-01557-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2813-2823},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A deep clustering by multi-level feature fusion},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Clustering mixed type data: A space structure-based
approach. <em>IJMLC</em>, <em>13</em>(9), 2799–2812. (<a
href="https://doi.org/10.1007/s13042-022-01602-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering mixed type data is important for the areas such as knowledge discovery and machine learning. Although many clustering algorithms have been developed for mixed type data, clustering mixed type data is still a challenging task. The challenges mainly come from the fact that the numerical attributes and categorical attributes of mixed type data are not in the same space. Most of the mixed data clustering methods handle the two types of attributes separately. The gap between the numerical attributes and categorical attributes is not handled very well. To handle the above issues, we expand the space structure representation scheme for categorical data to mixed type data. In the new scheme, all the attributes of the mixed type data are expressed as the numerical type, which is in a Euclidean space. In addition, we propose an accelerated approximate space structure based on the Nyström method, which reduces the time cost and memory cost of constructing a space structure. We then propose general frameworks based on the space structure data (SBM) and accelerated approximate space structure (Ap-SBM) for mixed type data clustering. Experimental analyses reflect the ability of the space structure to express the original mixed type data and the ability of the accelerated approximate space structure to express the space structure. The experimental results on thirteen mixed type data sets from UCI show superiority of the proposed frameworks compared with the other six representative mixed type data clustering algorithms.},
  archive      = {J_IJMLC},
  author       = {Li, Feijiang and Qian, Yuhua and Wang, Jieting and Peng, Furong and Liang, Jiye},
  doi          = {10.1007/s13042-022-01602-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2799-2812},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Clustering mixed type data: A space structure-based approach},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RD-NMSVM: Neural mapping support vector machine based on
parameter regularization and knowledge distillation. <em>IJMLC</em>,
<em>13</em>(9), 2785–2798. (<a
href="https://doi.org/10.1007/s13042-022-01563-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) model has made remarkable achievements in many fields. Therefore, we have greater expectation for it, expecting it to have the same intelligence as human beings. However, ANNs still can’t perform continual learning like humans at present. The serious defect of ANNs model is called the catastrophic forgetting problem. For this problem, we put forward a novel method called neural mapping support vector machine based on Parameter Regularization and Knowledge Distillation or RD-NMSVM for short. Our model consists of three parts: firstly, the shared neural network module, which is used to extract common features of different tasks; Secondly, the specific task module, which employs multi-classification support vector machine as classifier, and it is equivalent to using neural networks as neural kernel mapping of support vector machine; Thirdly, the parameter regularization and knowledge distillation module, which inhibits the parameters of the shared network module from updating greatly and learns previous knowledge. Note that RD-NMSVM doesn’t utilize samples of previous tasks. From our experiments, we can see that RD-NMSVM has obvious advantages in eliminating catastrophic forgetting of ANNs model.},
  archive      = {J_IJMLC},
  author       = {Han, Jidong and Zhang, Ting and Li, Yujian and Liu, Zhaoying},
  doi          = {10.1007/s13042-022-01563-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2785-2798},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {RD-NMSVM: Neural mapping support vector machine based on parameter regularization and knowledge distillation},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incremental calculation approaches for granular reduct in
formal context with attribute updating. <em>IJMLC</em>, <em>13</em>(9),
2763–2784. (<a
href="https://doi.org/10.1007/s13042-022-01561-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction in formal concept analysis is a highly concerned dimensionality reduction method, which purifies formal context by removing unimportant attributes. Current trends of dealing with attribute reduction problem for large-scale datasets is mainly based on object updating, thus, ignore the fact that attributes may also be modified with evolving time. With that in mind, this study considers the attribute reduction of the data with attribute dynamic environments. Specifically, we first analyze the incremental mechanism of granular reduct in a formal context, as well as develop the corresponding incremental algorithms. Then, in a consistent formal decision context, we address the consistency-based incremental attribute reduction problem on the premise that the decision attribute set remains unchanged. In addition, to obtain a smaller reduction, attribute significance is defined to measure the identification ability of attributes to inconsistent objects. Different from the existing methods, the algorithms proposed in this paper can realize dynamic calculation of granular reduct and the numerical experiments conducted show that the algorithm proposed in this paper is more efficient than other algorithms in the face of large-scale datasets. In the meantime, the generated granular reduct can improve the accuracy of classifiers in the classification task.},
  archive      = {J_IJMLC},
  author       = {Niu, Jiaojiao and Chen, Degang},
  doi          = {10.1007/s13042-022-01561-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2763-2784},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Incremental calculation approaches for granular reduct in formal context with attribute updating},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Video person re-identification using key frame screening
with index and feature reorganization based on inter-frame relation.
<em>IJMLC</em>, <em>13</em>(9), 2745–2761. (<a
href="https://doi.org/10.1007/s13042-022-01560-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, there are many video person re-identification networks that do not consider screening the input video frame sequence, which result in the high-similarity of the video frames used for training the neural network. In this way, the temporal information in the video cannot be effectively modeled. To address that, we try to propose a video person re-identification scheme based on inter-frame reorganization, which consists of two modules. First, the Key Frame Screening with Index (KFSI) is proposed to screen the similar frames, and a frame sequence with richer information is extracted when loading the training dataset. Second, the Feature Reorganization Based on Inter-Frame Relation (FRBIFR) is proposed to reorganize the features of key frame sequence by calculating the correlation between the frames, and the reorganized features are more robust by eliminating some distractions (such as occlusion etc.). The experimental results show that our method outperforms the state-of-the-art methods on four mainstream datasets MARS, ILIDS-VID, PRID-2011 and DukeMTMC-VideoReID.},
  archive      = {J_IJMLC},
  author       = {Lu, Zeng and Zhang, Ganghan and Huang, Guoheng and Yu, Zhiwen and Pun, Chi-Man and Zhang, Weiwen and Chen, Junan and Ling, Wing-Kuen},
  doi          = {10.1007/s13042-022-01560-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2745-2761},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Video person re-identification using key frame screening with index and feature reorganization based on inter-frame relation},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A finger-vein recognition method based on double-weighted
group sparse representation classification. <em>IJMLC</em>,
<em>13</em>(9), 2725–2744. (<a
href="https://doi.org/10.1007/s13042-022-01558-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finger-vein recognition is a new type of biometric identification technology compared to traditional biometric identification methods such as fingerprint recognition. Finger-vein is considered a safe and reliable biometric pattern due to its vivo nature and has been widely used in various fields. However, finger-vein images are susceptible to finger thickness and near-infrared light distribution during the process of acquisition, which often results in low-quality images (e.g., low contrast and overexposure), causing feature loss and affecting the final recognition accuracy. In this paper, a method based on double-weighted group sparse representation classification is proposed to improve the recognition performance for low-quality finger-vein images. The proposed method represents the test sample by a sparse linear combination of the training samples while making full use of those training samples’ data and label information through the group sparsity constraint. In addition, considering the large intra-class differences and small inter-class differences in low-quality finger-vein images, weight constraints for sparse coefficient vectors are added at the individual and group levels to reduce the impact of low-similarity training samples and heterogeneous training samples on the final recognition results, respectively. Compared with the state-of-the-art methods on three public datasets, experimental results demonstrate that the proposed approach achieves better recognition accuracy and robustness, especially for low-quality finger-vein images.},
  archive      = {J_IJMLC},
  author       = {Fang, Chunxin and Ma, Hui and Yang, Zedong and Tian, Wenbo},
  doi          = {10.1007/s13042-022-01558-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2725-2744},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A finger-vein recognition method based on double-weighted group sparse representation classification},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to share by masking the non-shared for multi-domain
sentiment classification. <em>IJMLC</em>, <em>13</em>(9), 2711–2724. (<a
href="https://doi.org/10.1007/s13042-022-01556-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-domain sentiment classification deals with the scenario where labeled data exists for multiple domains but is insufficient for training effective sentiment classifiers that work across domains. Thus, fully exploiting sentiment knowledge shared across domains is crucial for real-world applications. While many existing works try to extract domain-invariant features in high-dimensional space, such models fail to explicitly distinguish between shared and private features at the text level, which to some extent lacks interpretability. Based on the assumption that removing domain-related tokens from texts would help improve their domain invariance, we instead first transform original sentences to be domain-agnostic. To this end, we propose the BERTMasker model which explicitly masks domain-related words from texts, learns domain-invariant sentiment features from these domain-agnostic texts and uses those masked words to form domain-aware sentence representations. Empirical experiments on the benchmark multiple domain sentiment classification datasets demonstrate the effectiveness of our proposed model, which improves the accuracy on multi-domain and cross-domain settings by 1.91\% and 3.31\% respectively. Further analysis on masking proves that removing those domain-related and sentiment irrelevant tokens decreases texts’ domain separability, resulting in the performance degradation of a BERT-based domain classifier by over 12\%.},
  archive      = {J_IJMLC},
  author       = {Yuan, Jianhua and Zhao, Yanyan and Qin, Bing},
  doi          = {10.1007/s13042-022-01556-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2711-2724},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning to share by masking the non-shared for multi-domain sentiment classification},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Restricted subgradient descend method for sparse signal
learning. <em>IJMLC</em>, <em>13</em>(9), 2691–2709. (<a
href="https://doi.org/10.1007/s13042-022-01551-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sparse signal learning is essentially a sparse solution optimization problem. This technique is especially applicable to the field of signal recovery, e.g. image reconstruction. Such a problem can be solved by the gradient or subgradient descend method. However, conventional method normally needs to introduce extra quadratic term to construct complex objective function, whose solution costs many iteration steps. To address this problem, this paper proposes a novel method called restricted subgradient descend to learn the sparse signals. Our idea is based on the fact that the subgradient of 1-norm function exits at any n-dimensional point, and such a function even can obtain the gradient on the point without zero coordinate components. Thus, to decrease the objective function with regard to 1-norm value, the gradient or subgradient direction can be used to search next update of estimation, which facilitates the learning of the proposed method for high quality sparse solution with quick convergence time. Specifically, two algorithms are proposed, among which the first one uses merely restricted subspace projection scheme and the refined one is based on an improved version of the pivot step of simplex algorithm. It is analyzed that the refined algorithm is able to learn exactly the source sparse signal in finite iteration steps if the subgradient condition is satisfied. This theoretical result is also verified by numerical simulation with good experimental results compared with other state-of-the-art sparse signal learning algorithms.},
  archive      = {J_IJMLC},
  author       = {Wen, Jiajun and Wong, Wai Keung and Hu, Xiao-Li and Chu, Honglin and Lai, Zhihui},
  doi          = {10.1007/s13042-022-01551-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2691-2709},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Restricted subgradient descend method for sparse signal learning},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convergence analysis on the deterministic mini-batch
learning algorithm for noise resilient radial basis function networks.
<em>IJMLC</em>, <em>13</em>(9), 2677–2690. (<a
href="https://doi.org/10.1007/s13042-022-01550-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper gives a formal convergence analysis on the mini-batch training algorithm for noise resilient radial basis function (RBF) networks. Unlike the conventional analysis which assumes that the mini-batch process is operated in a stochastic manner, we consider that the mini-batch training process is operated in a deterministic manner. The deterministic process divides the training samples into a number of fixed mini-batches, and the mini-batches are presented in a fixed order. This paper first states the noise resilient objective function for weight noise and weight fault. We then derive the mini-batch training algorithm for this noise resilient objective function. Our main contribution is the convergence analysis on the mini-batch training algorithm. We show that under the deterministic setting, the mini-batch training algorithm converges. The converged weight vector is asymptotically close to the optimal batch mode solution. Also, we derive the sufficient conditions (the learning rate range) for convergence. Our theoretical results can be applied to not only the noise resilient objective function but also a large class of objective functions.},
  archive      = {J_IJMLC},
  author       = {Wong, Hiu Tung and Leung, Chi-Sing and Kwong, Sam},
  doi          = {10.1007/s13042-022-01550-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2677-2690},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Convergence analysis on the deterministic mini-batch learning algorithm for noise resilient radial basis function networks},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A sequential attention interface with a dense reward
function for mitosis detection. <em>IJMLC</em>, <em>13</em>(9),
2663–2675. (<a
href="https://doi.org/10.1007/s13042-022-01549-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The work aims to develop a fast detection method for instances of mitosis in breast cell sections, which needs time-consuming and labor-intensive searches. The system consists of two sequential processes. The first involves data pre-processing to avoid confusing images transferring to the successive detection procedure from wasteful computations. The input data is filtered using the blue ratio threshold to remove unnecessary background information and increase the color difference between the target and the non-target. Cropped images of suspicious candidates are classified as mitotic or non-mitotic employing a hard attention model, which only grapes the fine trained features locally and detailly instead of the entire picture. There is less computational complexity in terms of efficiency and performance because there are fewer parameters and smaller image sizes, so the proposed classification system outperforms traditional models, such as LEnet-5 and VGG-19, for the benchmarked data set provided in the TPAC2016 competition data sets. The proposed method is also compared to other methods listed on a ranking table for the ICPR2012 competition using its official test data set.},
  archive      = {J_IJMLC},
  author       = {Hwang, Maxwell and Wu, Cai and Jiang, Wei-Cheng and Hung, Wei-Chen},
  doi          = {10.1007/s13042-022-01549-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2663-2675},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A sequential attention interface with a dense reward function for mitosis detection},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CIRAN: Extracting crowd interaction with residual attention
network for pedestrian trajectory prediction. <em>IJMLC</em>,
<em>13</em>(9), 2649–2662. (<a
href="https://doi.org/10.1007/s13042-022-01548-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new deep learning network based on the spatial attention mechanism—crowd interaction with residual attention network (CIRAN), which combines the position and velocity information of neighbor pedestrians for trajectory prediction. It adaptively selects the most effective areas of the scene by using the residual attention module to obtain more accurate and reasonable pedestrian trajectories. Therefore, the accuracy of prediction can be improved. In addition, the velocity encoding module is introduced to transform the coordinate based pedestrian social interaction process into the spatial grid based pedestrian social interaction process. Based on two public data, ETH and UCY, this paper obtains the most advanced experimental results up to now, and these results show the validity of the proposed CIRAN.},
  archive      = {J_IJMLC},
  author       = {Liu, Shang and Chen, Xiaoyu and Chen, Hao},
  doi          = {10.1007/s13042-022-01548-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2649-2662},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {CIRAN: Extracting crowd interaction with residual attention network for pedestrian trajectory prediction},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computing formal concepts in parallel via a workload
rebalance approach. <em>IJMLC</em>, <em>13</em>(9), 2637–2648. (<a
href="https://doi.org/10.1007/s13042-022-01547-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scalability issue has always been a bottleneck for formal concept analysis (FCA) since the number of formal concepts is possibly exponential in the formal context. Motivated by the need to handle large formal contexts efficiently, we propose a parallel algorithm for computing formal concepts, the aim of which is to make Close-by-One (CbO) and its variants highly parallelized and easy to apply. Current approaches to parallelization of CbO-type algorithms such as PCbO (Parallel CbO) compute concepts in the top L recursion levels in serial and then turn to parallel computation after that. To avoid massive serial computations and the hassle of choosing the hyperparameter L in real applications, our proposed algorithm enters parallelization at once after the computation of the top concept and its direct successors, and then uses a parallel reshuffle approach to rebalance the workload distribution among worker threads without communication with the main thread. We describe the algorithm and present an experimental evaluation of its performance and comparison with PCbO on various datasets. Empirical analyses demonstrate that our algorithm is superior when applied to various types of formal contexts.},
  archive      = {J_IJMLC},
  author       = {Zou, Ligeng and Chen, Xiaozhi and He, Tingting and Dai, Jianhua},
  doi          = {10.1007/s13042-022-01547-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2637-2648},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Computing formal concepts in parallel via a workload rebalance approach},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review on machine learning techniques for the assessment
of image grading in breast mammogram. <em>IJMLC</em>, <em>13</em>(9),
2609–2635. (<a
href="https://doi.org/10.1007/s13042-022-01546-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is the 2nd leading cancer of death among women around the world. In Asia and Africa due to low income, the mortality rates are very high as compared to Europe and America. Initially, image interpretation is manually conducted by the radiologist and physicians that requires expertise; thus, the computer-aided diagnostic is necessary to enhance the accuracy of cancer diagnostics in mammograms at early stages. To overcome human error computer-aided system was developed based on machine learning and deep learning algorithm to process medical images with efficient accuracy for the diagnosis of cancer and assist the physician for better decisions making. This research aims to present the state-of-the-art machine learning techniques for the detection of breast cancer, and critically analysis of the current literature in this area to identify the research gap. There are many studies presented in the literature to achieve similar goals. The main difference between these studies and this review is that this paper is more focused on those modalities that can figure out breast composition, mass, density, calcification, and architectural distortion. This study includes a summary of 110 papers, pointing out which techniques are applied for image preprocessing and classification, which method is implemented for the detection of breast density, mass, and calcification from mammogram images. Furthermore, we critically analyzed the performance measuring parameters for the evaluation of results and the datasets that have been used for experiments. Another focus in this review is to assess the modalities and features that can be helpful for the assessment of grading in mammogram images.},
  archive      = {J_IJMLC},
  author       = {Rehman, Khalil ur and Li, Jianqiang and Pei, Yan and Yasin, Anaa},
  doi          = {10.1007/s13042-022-01546-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2609-2635},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A review on machine learning techniques for the assessment of image grading in breast mammogram},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A dynamic multi-swarm cooperation particle swarm
optimization with dimension mutation for complex optimization problem.
<em>IJMLC</em>, <em>13</em>(9), 2581–2608. (<a
href="https://doi.org/10.1007/s13042-022-01545-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) has been used to solve numerous real-world problems because of its strong optimization ability. However, PSO still has some shortcomings in solving complex optimization problems, such as premature convergence and poor balance between exploration and exploitation. To overcome these drawbacks of PSO, a dynamic multi-swarm cooperation PSO with dimension mutation (MSCPSO) is proposed in this paper. There are two contributions in MSCPSO, which are the adaptive sample selection strategy (ASS) and the adaptive dimension mutation strategy (ADM). Firstly, in ASS, particles in each sub-swarm are sorted into three states (elite, ordinary and inferior) according to their fitness. Three samples pool are used to save elite, ordinary and inferior particles. Particles in each sub-swarm can select their learning samples in their sample pools adaptively according to their fitness. Therefore, ASS can facilitate information interaction among the sub-swarms and increase the diversity of the population. Secondly, ADM generates the mutation positions for the whole population according to the information and knowledge acquired by particles during the evolution. In this case, ADM is used to enhance the exploitation ability of DMS-PSO without losing population diversity. Finally, two test suites (CEC2013 and CEC2017) and four practical engineering problems are used to verify the performance of MSCPSO. Experimental results verify that MSCPSO has a remarkable performance compared with 7 recent state-of-the-art PSO variants in most complex and multimodal conditions.},
  archive      = {J_IJMLC},
  author       = {Yang, Xu and Li, Hongru and Yu, Xia},
  doi          = {10.1007/s13042-022-01545-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2581-2608},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A dynamic multi-swarm cooperation particle swarm optimization with dimension mutation for complex optimization problem},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A heuristically self-organised linguistic attribute deep
learning for edge intelligence. <em>IJMLC</em>, <em>13</em>(9),
2559–2579. (<a
href="https://doi.org/10.1007/s13042-022-01544-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the internet of things (IoT), IoT intelligence is becoming a new technology. The “curse of dimensionality” is the barrier of data fusion in edge devices to the success of IoT intelligence. Deep Learning has attracted a lot of attention recently due to its successful application in various fields such as image processing and natural language processing. However, the success of Deep Learning benefits from the Graphics Processing Unit (GPU) computing. Similar to conventional Deep Learning, the computational complexity of optimising LAHs blocks the applications of LAHs. However, unlike conventional Deep Learning, an Linguistic Attribute Hierarchy (LAH) embedded with Linguistic Decision Trees (LDTs) could overcome the shortcoming of the lack of interpretation by providing transparent information propagation through the rules created by LDTs in the LAH. To address the challenge in the construction of high-performance LAHs, we propose a heuristic approach for constructing an LAH embedded with LDTs for decision making or classification by using the distance correlations between attributes and between attributes and the target variable. The set of attributes is divided into some attribute clusters and then heuristically organised into an LAH. The proposed approach has been validated on some benchmark decision or classification problems from the UCI machine learning repository. The experimental results show that the proposed self-organisation algorithm can create an effective and efficient LAH. Such a self-organised LAH embedded with LDTs can not only efficiently address “curse of dimensionality” in a single LDT for data fusion with massive attributes, but also achieve better or comparable performance in decision making or classification compared to a single LDT for the problem to be solved. The main contribution of this work is that (1) an LAH provides a new attribute Deep Learning approach with good transparency and extends the conventional Deep Learning, which usually denotes a black-box deep neural network; (2) the self-organisation algorithm for SOLAH is much more efficient than the genetic algorithm in the wrapper for optimising LAHs, and SOLAH can achieve comparable results to the LAH, which was optimised by the genetic algorithm in the wrapper (GAW). This is crucial for edge intelligence and makes it feasible to embed SOLAH and the self-organisation algorithm in edge devices for IoT applications. Hence, this research will take a step towards edge intelligence.},
  archive      = {J_IJMLC},
  author       = {He, Hongmei and Zhu, Zhenhuan},
  doi          = {10.1007/s13042-022-01544-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2559-2579},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A heuristically self-organised linguistic attribute deep learning for edge intelligence},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A shadowed set-based three-way clustering ensemble approach.
<em>IJMLC</em>, <em>13</em>(9), 2545–2558. (<a
href="https://doi.org/10.1007/s13042-022-01543-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the essential topics in ensemble learning, a clustering ensemble is employed to aggregate multiple base patterns to generate a single clustering output for improving robustness and quality. In this work, we proposed a novel clustering ensemble method, a shadowed set-based multi-granular three-way clustering ensemble (S-M3WCE). In particular, the approach generated a set of clustering members via the possibilistic C-means clustering (PCM) approach. Then all objects initially are partitioned into three regions by shadowed sets: the core region, shadowed region, and exclusion region, according to their possibilistic membership degrees. The procedure will capture the uncertainty and noisy objects in the data set through multiple different clustering results. Second, objects are further assigned to four approximate regions borrowed from the idea of multi-granularity rough sets by analyzing the uncertainty between objects and clusters. Objects in different approximation regions have diverse importance to clusters, and there has a partially ordered relationship between different approximation regions. Finally, we again handle the above four regions using the shadowed set, which eventually produces the output of the three-way clustering. The proposed method is evaluated using four artificial data sets and eight UCI data sets based on three evaluation criteria: clustering accuracy, adjusted rand index, and normalized mutual information. The experimental results show that the proposed algorithm achieves optimal effectiveness and efficiency against the other six representative clustering ensemble algorithms.},
  archive      = {J_IJMLC},
  author       = {Jiang, ChunMao and Li, ZhiCong and Yao, JingTao},
  doi          = {10.1007/s13042-022-01543-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2545-2558},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A shadowed set-based three-way clustering ensemble approach},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uncertain random portfolio optimization via semi-variance.
<em>IJMLC</em>, <em>13</em>(9), 2533–2543. (<a
href="https://doi.org/10.1007/s13042-022-01542-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-variance is a similar measure to variance, but it only considers values that are below the expected value. As important roles of semi-variance in finance, this paper proposes the concept of semi-variance for uncertain random variables. Also, a computational approach for semi-variance is provided via inverse uncertainty distribution. As an application in finance, portfolio selection problems of uncertain random returns are solved by minimizing semi-variance in mean-semi variance models. For better illustration, mean-semi variance model is compared with mean-variance one. Finally, for better understanding, some tables, figures and outputs are provided.},
  archive      = {J_IJMLC},
  author       = {Cheng, Guangquan and Ahmadzade, Hamed and Farahikia, Mehran and Yarmohammadi, Masoud},
  doi          = {10.1007/s13042-022-01542-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2533-2543},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Uncertain random portfolio optimization via semi-variance},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A temporal-attribute attention neural network for mixed
frequency data forecasting. <em>IJMLC</em>, <em>13</em>(9), 2519–2531.
(<a href="https://doi.org/10.1007/s13042-022-01541-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the dilemmas faced by forecasting is that the data are collected at different frequencies in some practical applications. This paper treats mixed frequency data as a special kind of multi-source data, that is, data from each source is collected at a different sampling frequency. Based on this cognition, this paper draws on the idea of neural network processing multi-source data to proposes a temporal-attribute attention neural network (TAA-NN for short) model to study the raw mixed frequency data. The new method avoids the problems caused by frequency alignments, such as information loss and artificial assumption of data distribution. First, this paper proposes a new sliding window strategy for mixed frequency data to determine the amount of data input into the model from each source data. Then, a group of convolutional neural network (CNN) with the same number of filters is used to extract or expand temporal features from the hidden state for each source data (a frequency data), so as to realize the information fusion of mixed frequency data at the feature layer. In addition, a temporal-attribute attention mechanism is proposed to mine essential information from the fused feature matrix in temporal and attribute dimensions. Experiments on two simulations and real-world datasets demonstrate that TAA-NN outperforms the compared methods and provides a new solution to the mixed frequency data forecasting.},
  archive      = {J_IJMLC},
  author       = {Wu, Peng and Yu, Hong and Hu, Feng and Xie, Yongfang},
  doi          = {10.1007/s13042-022-01541-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2519-2531},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A temporal-attribute attention neural network for mixed frequency data forecasting},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hierarchical reasoning graph neural network for the
automatic scoring of answer transcriptions in video job interviews.
<em>IJMLC</em>, <em>13</em>(9), 2507–2517. (<a
href="https://doi.org/10.1007/s13042-022-01540-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the task of automatically scoring the competency of candidates based on textual features, from the automatic speech recognition transcriptions in the asynchronous video job interviews. The key challenge is to construct the dependency relations and semantic level interaction over each question–answer (QA) pair. However, most recent studies focus on the representation of questions and answers, but ignore the dependency information and interaction between them, which is critical for QA evaluation. In this work, we propose a hierarchical reasoning graph neural network for the automatic assessment of question–answer pairs. Specifically, we construct a sentence-level relational graph neural network to capture the dependency information of sentences in or between the question and the answer. Based on these graphs, we employ a semantic-level reasoning graph attention network to model the interaction states of the current QA session. Finally, we propose a gated recurrent unit encoder to represent the temporal question–answer pairs for the final prediction. Empirical results on CHNAT (a real-world dataset) validate that our proposed model significantly outperforms matching-based benchmark models. Ablation studies and experimental results with 10 random seeds also show the effectiveness and stability of our models.},
  archive      = {J_IJMLC},
  author       = {Chen, Kai and Niu, Meng and Chen, Qingcai},
  doi          = {10.1007/s13042-022-01540-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2507-2517},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A hierarchical reasoning graph neural network for the automatic scoring of answer transcriptions in video job interviews},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-distance metric network for few-shot learning.
<em>IJMLC</em>, <em>13</em>(9), 2495–2506. (<a
href="https://doi.org/10.1007/s13042-022-01539-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning aims to make classification when few samples are available. In general, metric-based methods map images into a space by learning the embedding function. However, conventional metric-based methods rely on a single distance value, which does not pay attention to the shallow features. In this paper, we propose a multi-distance metric network (MDM-Net) by employing a multi-output embedding network to map samples into different feature spaces. In addition, we maximize the inter-class distance which is popular in metric learning field to improve the performance of few-shot classifier. Furthermore, we design a task-adaptive margin to adjust the distance between different sample pairs, and we found that the distance loss combined with cross-entropy loss is beneficial to achieve better results in meta-task training. The proposed method is verified by tests on miniImageNet and FC100 these two benchmarks for 5-way 1-shot classification task and 5-way 5-shot classification task with competitive results.},
  archive      = {J_IJMLC},
  author       = {Gao, Farong and Cai, Lijie and Yang, Zhangyi and Song, Shiji and Wu, Cheng},
  doi          = {10.1007/s13042-022-01539-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2495-2506},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-distance metric network for few-shot learning},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring correlation of relationship reasoning for scene
graph generation. <em>IJMLC</em>, <em>13</em>(9), 2479–2493. (<a
href="https://doi.org/10.1007/s13042-022-01538-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately reasoning about the relationship between objects play a central role in scene understanding. Due to the complexity of modeling visual relationships and the unbalanced distribution of relationship types, the results obtained by the existing methods are far from satisfying. In this work, we find that the interplay between contextual information of object pairs and their relationships can effectively regularize the space of visual relationship types to improve the accuracy of relationship reasoning. To this end, we incorporate the interplay into deep neural networks to facilitate scene graph generation by developing a Relationship Reasoning Network (ReRN). Specifically, the model uses a feature updating structure to mutual connection and iterative update the semantic features of objects and relationships to explore contextual information between objects. Then a graph attention mechanism is used to obtain the correlation information between object pairs and their relationships. Finally, our model adopts the correlation information to facilitate interactions recognition between objects while leveraging the mutual connections and joint refines of different semantic features to improve the accuracy of scene graph generation. Extensive experiments on the Visual Genome dataset demonstrate that our method outperforms the other state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Tian, Peng and Mo, Hongwei and Jiang, Laihao},
  doi          = {10.1007/s13042-022-01538-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2479-2493},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Exploring correlation of relationship reasoning for scene graph generation},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved multi-population whale optimization algorithm.
<em>IJMLC</em>, <em>13</em>(9), 2447–2478. (<a
href="https://doi.org/10.1007/s13042-022-01537-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering techniques and metaheuristic algorithms (MA) have demonstrated being efficient tools in their respective action fields. However, working together is an area marginally explored. One of the main disadvantages of MA is the lack of diversity in the solutions. Besides, most of them use only a single population to analyze the search space; this affects the capabilities to find the optimal solutions. This article proposes an approach called K-WOA that merges the benefits of two methods into a single algorithm. The K-means is a popular clustering technique based on centroids. Due to its simplicity and efficiency, combining it with a MA as the whale optimization algorithm (WOA) is ideal. This proposed K-WOA aims to increase the diversity of solutions in optimization problems by creating multiple groups of search agents operating cooperatively to explore the search space. To perform this task, the K-means is used in the initialization process to separate the population into different subgroups that the WOA independently evolves. In each sub-population, the best search agent is chosen to compare with the best agents of the other whale groups. By doing this, the algorithm can explore different regions of the search space simultaneously with more than one element. The K-WOA is proposed as an improved optimization algorithm that simultaneously searches for optimal solutions in multiple regions of the search space. The experimental results and comparisons with state-of-the-art approaches show that the proposed algorithm is competitive for solving complex optimization problems.},
  archive      = {J_IJMLC},
  author       = {Navarro, Mario A. and Oliva, Diego and Ramos-Michel, Alfonso and Zaldívar, Daniel and Morales-Castañeda, Bernardo and Pérez-Cisneros, Marco and Valdivia, Arturo and Chen, Huiling},
  doi          = {10.1007/s13042-022-01537-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2447-2478},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An improved multi-population whale optimization algorithm},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Brain tumor segmentation based on region of interest-aided
localization and segmentation u-net. <em>IJMLC</em>, <em>13</em>(9),
2435–2445. (<a
href="https://doi.org/10.1007/s13042-022-01536-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since magnetic resonance imaging (MRI) has superior soft tissue contrast, contouring (brain) tumor accurately by MRI images is essential in medical image processing. Segmenting tumor accurately is immensely challenging, since tumor and normal tissues are often inextricably intertwined in the brain. It is also extremely time consuming manually. Late deep learning techniques start to show reasonable success in brain tumor segmentation automatically. The purpose of this study is to develop a new region-of-interest-aided (ROI-aided) deep learning technique for automatic brain tumor MRI segmentation. The method consists of two major steps. Step one is to use a 2D network with U-Net architecture to localize the tumor ROI, which is to reduce the impact of normal tissue’s disturbance. Then a 3D U-Net is performed in step 2 for tumor segmentation within identified ROI. The proposed method is validated on MICCAI BraTS 2015 Challenge with 220 high Gliomas grade (HGG) and 54 low Gliomas grade (LGG) patients’ data. The Dice similarity coefficient and the Hausdorff distance between the manual tumor contour and that segmented by the proposed method are 0.876 ±0.068 and 3.594±1.347 mm, respectively. These numbers are indications that our proposed method is an effective ROI-aided deep learning strategy for brain MRI tumor segmentation, and a valid and useful tool in medical image processing.},
  archive      = {J_IJMLC},
  author       = {Li, Shidong and Liu, Jianwei and Song, Zhanjie},
  doi          = {10.1007/s13042-022-01536-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2435-2445},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Brain tumor segmentation based on region of interest-aided localization and segmentation U-net},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A gaussian RBM with binary auxiliary units. <em>IJMLC</em>,
<em>13</em>(9), 2425–2433. (<a
href="https://doi.org/10.1007/s13042-022-01534-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Restricted Boltzmann Machines (RBM) have been widely applied in image processing. For RBM-based models on image recognition and image generation tasks, extracting expressive real-valued features and alleviating the overfitting problem are extremely important. In this paper, we propose a Gaussian Restricted Boltzmann Machine with binary Auxiliary units (GARBM), which designs binary auxiliary units in its visible layer and constructs parameterized real-valued features in its hidden layer. Specifically, based on the designed energy function in GARBM, activated auxiliary units are directly used to control probabilities of visible units and hidden units to extract real-valued features. Moreover, auxiliary units and their resulting feature selection mechanism not only alleviate the “gradient-variance” problem, but also provide certain randomness to other units to alleviate overfitting without introducing more hyperparameters. To build more effective deep models, we propose GARBM-based deep neural networks, and the effectiveness of proposed neural networks is verified in experiments.},
  archive      = {J_IJMLC},
  author       = {Zhang, Jian and Ding, Shifei and Sun, Tongfeng and Guo, Lili},
  doi          = {10.1007/s13042-022-01534-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2425-2433},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A gaussian RBM with binary auxiliary units},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Unsupervised image clustering algorithm based on
contrastive learning and k-nearest neighbors. <em>IJMLC</em>,
<em>13</em>(9), 2415–2423. (<a
href="https://doi.org/10.1007/s13042-022-01533-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the times, people generate a huge amount of data every day, most of which are unlabeled data, but manual labeling needs a lot of time and effort, so unsupervised algorithms are being used more often. This paper proposes an unsupervised image clustering algorithm based on contrastive learning and K-nearest neighbors (CLKNN). CLKNN is trained in two steps, which are the representation learning step and the clustering step. Contrastive learning and K-nearest neighbors have a huge impact on CLKNN. In the representation learning step, firstly CLKNN processes the image by double data augmentation to get two different augmented images; then CLKNN uses double contrastive loss to extract the high-level feature information of the augmented images, maximizing the similarity of row space and maximizing the similarity of column space to ensure the invariance of information. In the clustering step, CLKNN finds the nearest neighbors of each image by K-nearest neighbors, then it maximizes the similarity between each image and its nearest neighbors to get the final result. To test the performance of CLKNN, the experiments are conducted on CIFAR-10, CIFAR-100 and STL-10 in this paper. From the final results, it is clear that CLKNN has better performance than other advanced algorithms.},
  archive      = {J_IJMLC},
  author       = {Zhang, Xiuling and Wang, Shuo and Wu, Ziyun and Tan, Xiaofei},
  doi          = {10.1007/s13042-022-01533-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2415-2423},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Unsupervised image clustering algorithm based on contrastive learning and K-nearest neighbors},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Network pruning via probing the importance of filters.
<em>IJMLC</em>, <em>13</em>(9), 2403–2414. (<a
href="https://doi.org/10.1007/s13042-022-01530-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Filter pruning is one of the most effective approaches to reduce the storage and computational cost of convolutional neural networks. How to measure the importance of each filter is the key problem for filter pruning. In this work, we propose a novel method that can evaluate the importance of each filter and gradually prunes those filters with small scores. Specifically, the importance is obtained via probing the effect of each filter on the task-related loss function by randomly pruning the original network. The smaller the effect on the task-related loss function, the lower the importance of the filter. It’s worth noting that our method is scale consistent across all layers without requiring layer-wise sensitivity analysis, which can be used to prune various networks, including ResNet and DenseNet. Extensive experiments demonstrate the outstanding performance of our method. For example, on ILSVRC-2012, our method can prune 42.74\% floating point operations and 39.61\% parameters of ResNet-50 with only 0.73\% Top-1 accuracy loss and 0.37\% Top-5 accuracy loss.},
  archive      = {J_IJMLC},
  author       = {Kuang, Jiandong and Shao, Mingwen and Wang, Ran and Zuo, Wangmeng and Ding, Weiping},
  doi          = {10.1007/s13042-022-01530-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2403-2414},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Network pruning via probing the importance of filters},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective uncertain project selection considering
synergy. <em>IJMLC</em>, <em>13</em>(8), 2383–2402. (<a
href="https://doi.org/10.1007/s13042-022-01532-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses a multi-objective mean-variance model and its solution algorithms for the project selection considering synergy under the uncertain environment. Two objective functions have been considered: maximizing the expected net present value (NPV) of the selected projects and minimizing the risk measured by variance of NPV. Here, the profits and investment outlays for candidate projects and synergistic profits and outlays of interdependent projects are considered as uncertain variables whose distributions are determined by experts’ evaluations. According to uncertainty theory, the deterministic equivalents are obtained. The effect of uncertainty on project selection is analyzed through comparison between the proposed uncertain model and the certain model with exact parameters. And the effect of synergy on the project selection is also analyzed. To get the Pareto-optimal solutions of the proposed multi-objective project selection model, we provide a new multi-objective modified binary Jaya (MOMB-Jaya) algorithm and a new multi-objective modified binary Rao (MOMB-Rao) algorithm, which respectively are modifications of the Jaya and Rao algorithms for solving the proposed multi-objective problems. Through numerical experiments on 15 example problems, including large-scale problems, the performances of the proposed multi-objective binary algorithms are tested. Comparison with the binary version of non-dominated teaching-learning-based optimization (NSTLBO) algorithm shows the better performance of the MOMB-Rao algorithm. Finally, a numerical example is given to demonstrate the validity of the proposed multi-objective uncertain model.},
  archive      = {J_IJMLC},
  author       = {Huang, Xiaoxia and Hong, Kwon Ryong and Kim, Jang Su and Choe, Il Jong},
  doi          = {10.1007/s13042-022-01532-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2383-2402},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-objective uncertain project selection considering synergy},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel feature selection method using generalized inverted
dirichlet-based HMMs for image categorization. <em>IJMLC</em>,
<em>13</em>(8), 2365–2381. (<a
href="https://doi.org/10.1007/s13042-022-01529-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hidden Markov Models (HMMs) have consistently been a powerful tool for performing numerous challenging machine learning tasks such as automatic recognition. The latter perceives all objects of the universe through information carried by their characteristics or features. However, not all available data is always valuable for distinguishing between the different objects, scenes, scenarios; referring analogically to states. More often than not, automatic recognition is accompanied by a feature selection to reduce the number of collected features to a relevant subset. Although sparse, the majority of literature resources available on feature selection for HMMs, presuppose either a single Gaussian or employ a Gaussian mixture model (GMM) as emission distribution. The proposed method builds upon the feature saliency model introduced by Adams, Cogill, and Beling (in IEEE Access 4:1642–1657), and is adjusted to handle complex multidimensional data by using as a novel experiment, GID (Generalized Inverted Dirichlet) mixture models) as emission probabilities. We make use of an Expectation-Maximization (EM) algorithm (Dempster et al. in J R Stat Soc 39(1):1–22) to compute maximum a posteriori (MAP) [Gauvain and Lee in IEEE Transact Speech Audio Process 2(2):291–298] estimates for model parameters. The complete inference and parameter estimation of our GID-FSHMM (GID Feature Selection-based HMM) are detailed in this work. Automatic recognition applications such as facial expression recognition and scenes categorization demonstrate comparable to higher performance compared to the extensively used Gaussian mixture-based HMM (GHMM), the Dirichlet-based (DHMM) and the inverted Dirichlet-based HMM (IDHMM) without feature selection and also when the latter is embedded in all of the aforementioned models.},
  archive      = {J_IJMLC},
  author       = {Nasfi, Rim and Bouguila, Nizar},
  doi          = {10.1007/s13042-022-01529-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2365-2381},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel feature selection method using generalized inverted dirichlet-based HMMs for image categorization},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local rough set-based feature selection for label
distribution learning with incomplete labels. <em>IJMLC</em>,
<em>13</em>(8), 2345–2364. (<a
href="https://doi.org/10.1007/s13042-022-01528-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning, as a new learning paradigm under the machine learning framework, is widely applied to address label ambiguity. However, most existing label distribution learning methods require complete supervised information, which is obtained through costly and laborious efforts to label the data. In reality, the annotation information may be incomplete and traditional methods cannot directly deal with the incomplete data. Hence, a new theoretical framework is proposed to handle the limited labeled data, which is called the local rough set. In addition, label distribution learning also experiences the “curse of dimensionality” problem, and it is essential to adopt some pre-processing methods, such as feature selection, to reduce the data dimensionality. Nevertheless, few feature selection algorithms are designed for handling label distribution data. Motivated by this, a model based on local rough set and neighborhood granularity, which can effectively and efficiently work with incompletely labeled data, is introduced in this paper. Furthermore, a local rough set-based incomplete label distribution feature selection algorithm is proposed to reduce the data dimensionality. Experimental results on 12 real-world label distribution datasets indicate that the proposed method outperforms the global rough set in computational efficiency and achieves better classification performance than the other five methods.},
  archive      = {J_IJMLC},
  author       = {Qian, Wenbin and Dong, Ping and Wang, Yinglong and Dai, Shiming and Huang, Jintao},
  doi          = {10.1007/s13042-022-01528-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2345-2364},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Local rough set-based feature selection for label distribution learning with incomplete labels},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalized fuzzy variable precision rough sets based on
bisimulations and the corresponding decision-making. <em>IJMLC</em>,
<em>13</em>(8), 2313–2344. (<a
href="https://doi.org/10.1007/s13042-022-01527-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the classical rough set has been extended in many ways. However, some of them are based on binary relations which only excavate “one step” information to distinguish objects. The “one step” in the binary relation means that the ordered pair of the starting and end points of the step belongs to the relation. Faced with some complex data sets, the “one step” information may be not feasible. Motivated by the notion of bisimulation in computer science, three types of bisimulation-based generalized fuzzy variable precision rough set (BGFVPRS) models are constructed. Different from many existed rough set models which are based on binary relations, the BGFVPRS models can distinguish objects by excavating the “multi-step” information of underlying relations. The related properties and relationships of BGFVPRS models are investigated. The uncertainty measure of BGFVPRS models and the reduction of fuzzy bisimulations are also discussed. Furthermore, learning from the PROMETHEE II method and combining it with our presented BGFVPRS models, a novel multiple-attribute decision-making method is provided. This method can effectively deal with complex problems including attribute data and relational data. The flexibility and effectiveness of our decision-making method are illustrated by comparative analysis and sensitivity analysis in the Zachary karate club network.},
  archive      = {J_IJMLC},
  author       = {Zhang, Li and Zhu, Ping},
  doi          = {10.1007/s13042-022-01527-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2313-2344},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Generalized fuzzy variable precision rough sets based on bisimulations and the corresponding decision-making},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Water atom search algorithm-based deep recurrent neural
network for the big data classification based on spark architecture.
<em>IJMLC</em>, <em>13</em>(8), 2297–2312. (<a
href="https://doi.org/10.1007/s13042-022-01524-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The innovation of big data has an intense impact on data context analytics. The big data processing platforms have gained immense popularity in evaluating big data as they offer low latency needed for Big Data applications. This paper introduces a novel method for big data classification using spark architecture that follows master–slave nodes. The input data is initially partitioned by data griding in the master node using Black Hole Entropy Fuzzy Clustering (BHEFC). Then, the feature selection is executed for each slave node based on Renyi entropy for choosing better features for further processing. Finally, the features selected from each slave node are concatenated together to form the feature vector. Consequently, obtained features from the slave node are passed to the classification module in the master node for performing the classification of big data. In this case, classification is carried out using the Deep Recurrent Neural network (DeepRNN), tuned by the novel Water Atom Search Optimization (WASO). The WASO is newly designed by integrating the Water Wave Optimization (WWO) algorithm and Atom Search Optimization (ASO) characteristics. Thus, the proposed WASO-based DeepRNN method effectively classifies big data using reduced dimension features to produce satisfactory results. Therefore, the output of developed WASO enabled DeepRNN is employed for big data classification. The proposed method is compared with Neural Network (NN), Support Vector Machine (SVM), Edited Nearest Neighbor for Big Data (ENN-BD), Speed-up Dendritic Cell Algorithm (Sp-DCA), Compact Fuzzy Models in Big Data (CFM-BD), and DeepRNN. The proposed method obtained improved results with a high specificity of 0.979, accuracy of 0.951, sensitivity of 0.963, and precision of 0.988 based on the skin disease dataset.},
  archive      = {J_IJMLC},
  author       = {Dabbu, Murali and Karuppusamy, Loheswaran and Pulugu, Dileep and Vootla, Subba Ramaiah and Reddyvari, Venkateswar Reddy},
  doi          = {10.1007/s13042-022-01524-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2297-2312},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Water atom search algorithm-based deep recurrent neural network for the big data classification based on spark architecture},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Investigating human reading behavior during sentiment
judgment. <em>IJMLC</em>, <em>13</em>(8), 2283–2296. (<a
href="https://doi.org/10.1007/s13042-022-01523-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is an essential task in natural language processing researches. Although existing works have gained much success with both statistical and neural-based solutions, little is known about the human decision process while performing this kind of complex cognitive task. Considering recent advances in human-inspired model design for NLP tasks, it is necessary to investigate the human reading and judging behavior in sentiment classification and adopt these findings to reconsider the sentiment analysis problem. In this paper, we carefully design a lab-based user study in which users’ fine-grained reading behaviors during microblog sentiment classification are recorded with an eye-track device. Through systematic analysis of the collected data, we look into the differences between human and machine attention distributions and the differences in human attention while performing different tasks. We find that (1) sentiment judgment is more like an auxiliary task of content comprehension for humans. (2) people have different reading behavior patterns while reading microblog posts with varying labels of sentiment. Based on these findings, we build a human behavior-inspired sentiment prediction model for microblog posts. Experiment results on public-available benchmarks show that the proposed classification model outperforms existing solutions over 2.13\% in terms of macro F1-score by introducing behavior features. Our findings may bring insight into the research of designing more effective and explainable sentiment analysis methods.},
  archive      = {J_IJMLC},
  author       = {Chen, Xuesong and Mao, Jiaxin and Liu, Yiqun and Zhang, Min and Ma, Shaoping},
  doi          = {10.1007/s13042-022-01523-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2283-2296},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Investigating human reading behavior during sentiment judgment},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A few-shot fine-grained image classification method
leveraging global and local structures. <em>IJMLC</em>, <em>13</em>(8),
2273–2281. (<a
href="https://doi.org/10.1007/s13042-022-01522-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot fine-grained image classification aims to recognize sub-categories of the same super-category given only a few labeled samples. To deal with the low inter-class variation and the high intra-class discordance, both the supervised guidance from the global view and the detail information hidden in the local structure are necessary. However, such global structure and local detail are usually applied separately by existing methods, as a result, the features are not discriminative enough. To address this issue, we propose a novel few-shot fine-grained image classification framework which enhances the Discriminative ability of Local structures utilizing class-aware Global structures (DLG). Firstly, the DLG model calculates the global structures utilizing prototype representations of each class, and then constructs class-aware attention maps for query images to enhance their discriminative local structures with the aid of global structures. Finally, a classification module based on local structures is performed to make predictions. Results of case studies demonstrate that the class-aware attention maps can focus on class discriminative regions. Extensive experiments on fine-grained datasets demonstrate that DLG outperforms the state-of-the-art methods. Taking Stanford Dogs as an example, the proposed DLG outperforms the baselines. More specifically, DLG obtains at least 13.4\% and 17.9\% average gain on accuracy for 1-shot and 5-shot classification problem respectively. Code can be found at https://gitee.com/csy213/few-shot-dlg .},
  archive      = {J_IJMLC},
  author       = {Cao, Siyu and Wang, Wen and Zhang, Jing and Zheng, Min and Li, Qingyong},
  doi          = {10.1007/s13042-022-01522-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2273-2281},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A few-shot fine-grained image classification method leveraging global and local structures},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven decision-making with weights and reliabilities
for diagnosis of thyroid cancer. <em>IJMLC</em>, <em>13</em>(8),
2257–2271. (<a
href="https://doi.org/10.1007/s13042-022-01521-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data science has revolutionized the paradigms of medical decision-making. In the past, medical data could not be recorded and stored indefinitely. In the present day, huge volumes of medical data have been collected electronically, such as medical records, medical images, and heterogeneous surgical data. Under this condition, how to help the radiologists diagnose the thyroid cancer by using the accumulated examination reports and pathologic findings has been a challenge needing to face. From the analysis of historical examination reports, the problem of diagnosing thyroid cancer is evidently considered as a multi-criteria decision-making problem. Thus, a data-driven fusion method of weights and reliabilities in decision-making is proposed in this paper to cope with the above challenge. Linguistic term sets are introduced to model and portray the assessments on each criterion in the problem of diagnosing thyroid cancer by using three types of linguistic scale functions. A data-driven way is then designed to determine the weights and reliabilities of the assessments on each criterion for each radiologist by considering the similarity between the assessments on each criterion and the overall assessments and the similarity between the assessments on criterion and the golden standard, which are derived from the historical data. Subsequently, assessments on each criterion will be combined with the weights and reliabilities to generate a data-driven solution to the problem. The applicability and effectiveness of the data-driven fusion method are verified by solving a real problem of diagnosing thyroid cancer using historical data collected from five radiologists in a tertiary hospital from January 2011 to February 2019.},
  archive      = {J_IJMLC},
  author       = {Xue, Min and Cao, Peipei and Hou, Bingbing and Liu, Weiyong},
  doi          = {10.1007/s13042-022-01521-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2257-2271},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Data-driven decision-making with weights and reliabilities for diagnosis of thyroid cancer},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid deep graph convolutional networks. <em>IJMLC</em>,
<em>13</em>(8), 2239–2255. (<a
href="https://doi.org/10.1007/s13042-022-01520-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) leverage graph convolutions or their approximations to cope with graph-structured data. According to whether convolution is applied to the spectral domain or spatial domain, advances in this direction are generally divided into spectral approaches and spatial approaches. However, current study generally utilizes one of the approaches, while ignoring the combination of the two approaches. In this paper, we propose hybrid deep graph convolutional networks (HDGCNs), novel neural network architectures that combine the spectral approach and the spatial approach to calculate the adjacency matrix, leveraging the deep graph convolutional networks (GCNs) to release the advantages of this combination. In this way, the gap between spectral approaches and spatial approaches is eliminated, and the characteristics of the two approaches are merged together. Extensive experiments on citation networks and web networks offer evidence that the proposed models outperform state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Yang, Fei and Zhang, Huyin and Tao, Shiming},
  doi          = {10.1007/s13042-022-01520-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2239-2255},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hybrid deep graph convolutional networks},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature fusion network for clothing parsing. <em>IJMLC</em>,
<em>13</em>(8), 2229–2238. (<a
href="https://doi.org/10.1007/s13042-022-01519-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clothing parsing tasks have attracted considerable attention because of their wide application. The challenge of clothing parsing is that clothing images have many characteristics, such as complex textures, different styles, and changeful human postures, so the task of clothing analysis needs to consider rich semantic features and accurate spatial information. However, due to repeated down-sampling operations, the current semantic segmentation networks are easy to lose a lot of spatial information. We propose a feature fusion network, which consists of multistage fusion network and edge perceiving network, can better capture the details. Experimental results show that our proposed method achieves state-of-art performance on the fashion clothing and the LIP datasets. Especially, our model achieves an average f1-score of 61.54 $$\%$$ on the fashion clothing test set and a mean IoU score of 53.58 $$\%$$ on the LIP validation set.},
  archive      = {J_IJMLC},
  author       = {Chen, Lifang and Yu, Enting and Cong, Honglian},
  doi          = {10.1007/s13042-022-01519-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2229-2238},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature fusion network for clothing parsing},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to optimise general TSP instances. <em>IJMLC</em>,
<em>13</em>(8), 2213–2228. (<a
href="https://doi.org/10.1007/s13042-022-01516-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Travelling Salesman Problem is a classical combinatorial optimisation problem (COP). In recent years, learning to optimise approaches have shown success in solving TSP problems. However, they focus on one type of TSP instance, where the points are uniformly distributed in Euclidean spaces (easy instances). Such approaches cannot generalise to other embedding spaces that represent various levels of difficult instances, e.g., TSP instances where the points are distributed in a non-uniform manner and spherical spaces. Obtain optimal solutions for easy instances is achievable and can be used as training data to solve various TSP instances. However, acquire optimal solutions for complex TSP instances is difficult and time-consuming. Hence, this paper introduces a new learning-based approach based on a convolutional neural network combined with a Long Short-Term Memory, referred to as the non-Euclidean TSP network (NETSP), that utilises randomly generated instances (easy instances) to solve various common TSP instances (complex TSP instances). We have demonstrated its superiority over state-of-the-art methods for various TSP instances. We performed extensive experiments that indicate our approach generalises across many instances and scales to larger instances.},
  archive      = {J_IJMLC},
  author       = {Sultana, Nasrin and Chan, Jeffrey and Sarwar, Tabinda and Qin, A. K.},
  doi          = {10.1007/s13042-022-01516-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2213-2228},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning to optimise general TSP instances},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to refine source representations for neural machine
translation. <em>IJMLC</em>, <em>13</em>(8), 2199–2212. (<a
href="https://doi.org/10.1007/s13042-022-01515-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine translation is one of the most classic application technologies in artificial intelligence and natural language processing. Neural machine translation models generally adopt an encoder–decoder architecture for modeling the entire translation process. However, without considering target context (e.g., decoding state) to guide the encoding, encoded source representations struggle to put great emphasis on important information for predicting some target word, yielding the weakness in generating more discriminative attentive representations across different decoding steps. Towards tackling this issue, we propose a novel encoder–refiner–decoder framework, which dynamically refines the source representations based on the generated target-side information at each decoding step. Since the refining operations are time-consuming, we propose a policy network to decide when to refine at specific decoding steps. We solve such a problem using the Gumbel-Softmax reparameterization, which makes our network differentiable and trainable through standard stochastic gradient methods. Experimental results on both Chinese–English and English–German translation tasks show that the proposed approach significantly and consistently improves translation performance over the standard encoder–decoder framework. Furthermore, when refining strategy is applied, experimental results still show a reasonable improvement over the baseline with much decrease in decoding speed.},
  archive      = {J_IJMLC},
  author       = {Geng, Xinwei and Wang, Longyue and Wang, Xing and Yang, Mingtao and Feng, Xiaocheng and Qin, Bing and Tu, Zhaopeng},
  doi          = {10.1007/s13042-022-01515-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2199-2212},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning to refine source representations for neural machine translation},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Global contextual attention for pure regression object
detection. <em>IJMLC</em>, <em>13</em>(8), 2189–2197. (<a
href="https://doi.org/10.1007/s13042-022-01514-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most object detection frameworks rely on rectangular bounding boxes and recognizing object instances individually. However, the bounding box provides only a coarse localization of objects and the context information between objects is not fully utilized, which result in a degradation of classification performance. In this paper, combining a lightweight contextual attention module with the representation of pure regression points, we present a novel context-based pure regression object detector. Moreover, a threshold filter mask module is designed to speed up the detector by removing a few insignificant points and keeping meaningful positions. Nonetheless, both of them do not require handcrafted clustering or post-processing steps and are easy to embed in networks. The proposed contextual attention module and threshold filter mask not only improve detection performance, but also promote training speed. We show through experiments that the proposed context-based pure regression detector can improve the representation of the regression points method about 1.5–1.8 AP on the COCO test-dev detection benchmark.},
  archive      = {J_IJMLC},
  author       = {Fan, Bingbing and Shao, Mingwen and Li, Yunhao and Li, Cunhe},
  doi          = {10.1007/s13042-022-01514-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2189-2197},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Global contextual attention for pure regression object detection},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online sequential fuzzy dropout extreme learning machine
compensate for sliding-mode control system errors of uncertain robot
manipulator. <em>IJMLC</em>, <em>13</em>(8), 2171–2187. (<a
href="https://doi.org/10.1007/s13042-022-01513-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An online sequential fuzzy dropout scheme is proposed to track the position of robot manipulators in this paper. The scheme is based on the extreme learning machine–inherited sliding-mode control (OSFDELMISMC). In this scheme, an improved extreme learning machine, called the online sequential fuzzy dropout extreme learning machine (OSFDELM), is utilized to mimic the control law of sliding-mode, update the network parameters through online cyclic training, and relax the detailed system information using the fuzzy method. To ensure network convergence and stable control performance, this paper obtains the network adaptive learning law through the Lyapunov stability theorem. The simulation results indicate that the OSFDELMISMC scheme is a feasible control scheme under which the trajectories of the two-link robot manipulator are accurately tracked, and chattering is effectively reduced.},
  archive      = {J_IJMLC},
  author       = {Zhou, Zhiyu and Ji, Haodong and Zhu, Zefei},
  doi          = {10.1007/s13042-022-01513-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2171-2187},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Online sequential fuzzy dropout extreme learning machine compensate for sliding-mode control system errors of uncertain robot manipulator},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross channel aggregation similarity network for salient
object detection. <em>IJMLC</em>, <em>13</em>(8), 2153–2169. (<a
href="https://doi.org/10.1007/s13042-022-01512-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection is an efficient preprocessing technique to deal with binary segmentation task. Existing works based on deep learning have achieved an enormous leap forward with outstanding performance in the field of computer vision. Most of the previous methods mainly adopted multi-scale fusion and attention mechanisms to facilitate efficient feature extraction yet ignored necessary global context characteristics and general models computational limitation. To mitigate the adverse effects of feature dilution during the top-to-down transmission, we propose a cross channel aggregation similarity network (CCANet) with three modules. Cross channel aggregation module retains high-response channels from integrated different layer feature maps to extract efficient global context information. Similarity fusion module calculates the similarity among various features consisting of high-level semantic, low-level spatial, and global context information to enhance the complementary of maps. Dense residual module extracts denser features under multi-scale receptive fields to improve the density of prediction maps. Besides, a combined loss function with modified weighted binary cross-entropy is applied to alleviate the class imbalance issue incurred in the training process. Benefited from the overall harmonious design, experimental results show that CCANet achieves state-of-the-art performance on six public benchmark datasets. Without any post-processing operations, it runs real-time inference at a speed of around 32 FPS when processing a 320 $$\times$$ 320 image.},
  archive      = {J_IJMLC},
  author       = {Chen, Liyuan and Liu, Huawen and Mo, Jiashuaizi and Zhang, Dawei and Yang, Jie and Lin, Feilong and Zheng, Zhonglong and Jia, Riheng},
  doi          = {10.1007/s13042-022-01512-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2153-2169},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Cross channel aggregation similarity network for salient object detection},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bilateral sensitivity analysis: A better understanding of a
neural network. <em>IJMLC</em>, <em>13</em>(8), 2135–2152. (<a
href="https://doi.org/10.1007/s13042-022-01511-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A model-independent sensitivity analysis for (deep) neural network, Bilateral sensitivity analysis (BiSA), is proposed to measure the relationship or dependency between neurons and layers. For any feed-forward neural networks including deep networks, we have defined the BiSA between a pair of layers as well as the same between any pair neurons in different layers. This sensitivity can quantify the influence or contribution from any layer to any other higher level layer. It provides a helpful tool to interpret the learned model. The BiSA can also measure the influence from any neuron to another neuron in a subsequent layer and it is critical to analyze the relationship between neurons in different layers. Then the BiSA from any input to any output of the network is easily defined to assess the strength of connection between the inputs and outputs. We have applied BiSA to characterize the well connectivity in oil fields—a very important and challenging problem in reservoir engineering. Given a network trained by Water Injection Rates and Liquid Production Rates data, the well connectivity can be efficiently discovered through BiSA. The empirical results verify the effectiveness of BiSA. Our comparison with exiting methods demonstrates the robustness and the superior performance. Besides, we also investigate the effectiveness of BiSA for a feature selection task using a deep neural network. The experimental results on MNIST data set demonstrate a satisfactory performance of BiSA on this issue with 1,536,640,000 parameters in the neural network.},
  archive      = {J_IJMLC},
  author       = {Zhang, Huaqing and Jiang, Yunqi and Wang, Jian and Zhang, Kai and Pal, Nikhil R.},
  doi          = {10.1007/s13042-022-01511-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2135-2152},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Bilateral sensitivity analysis: A better understanding of a neural network},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An active unseen sample selection framework for generalized
zero-shot classification. <em>IJMLC</em>, <em>13</em>(8), 2119–2134. (<a
href="https://doi.org/10.1007/s13042-022-01509-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of generalized zero-shot classification (GZSC) is to classify the test samples no matter whether training classes (seen classes) or new classes (unseen classes) they are from. However, there are no labeled samples from new classes in the training process. Thus, selecting some unseen samples and labeling them are significant for GZSC. We present two novel ideas for GZSC: (1) splitting target samples into seen and unseen ones; (2) improving the GZSC performance with less manual annotations of the unseen samples. We propose an active unseen sample selection framework for GZSC tasks (AUSS). Specifically, a two-stage coarse-to-fine-grained selection method is first used to split target samples into seen and unseen ones. The selected unseen samples can be divided into high-confidence and informative ones. Unlike traditional active learning methods focusing on only the informative samples, we especially focus on the large number of high-confidence unseen samples. The high-confidence unseen samples are assigned with pseudo labels which do not need to be manually labeled. We select as few as possible informative unseen samples for manually labeling. Thanks to these high-confidence unseen samples and informative unseen samples, we do not need to train generative models for generating virtual unseen samples. Experiments on widely-adopted GZSC benchmarks demonstrate the advantages of AUSS over existing methods.},
  archive      = {J_IJMLC},
  author       = {Li, Xiao and Fang, Min and Chen, Bo},
  doi          = {10.1007/s13042-022-01509-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2119-2134},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An active unseen sample selection framework for generalized zero-shot classification},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SPAN: Siampillars attention network for 3D object tracking
in point clouds. <em>IJMLC</em>, <em>13</em>(8), 2105–2117. (<a
href="https://doi.org/10.1007/s13042-022-01508-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D point clouds produce rich geometric information to address the scale variation in 2D image-based object tracking. Although siamese-based trackers are widely used and achieve great performance, their applications in 3D point clouds have not been seriously considered because of different data formats and structural information. To utilize a 2D siamese-based tracker for object tracking in raw point clouds, we propose a siampillars attention network in this paper. SPAN firstly converts 3D point clouds into 2D pseudo images so that 2D tracking methods can be applied. In response to the sparsity of raw point clouds, a separate attention module (SAM) consists of a height-and-width (HW) attention module, and a cross-channel attention module is designed to enrich the extracted features. A modulated deformable convolutional network (MDCN) is further applied to handle the deformations during tracking. The anchor-based region proposal network (RPN) with depth-wise correlation is deployed finally to locate the object and regress the 3D bounding box, which makes SPAN work single-shortly in an end-to-end learning manner. Our experiments on the KITTI dataset demonstrate the superiority of SPAN. SPAN runs with 46.6 frames per second (FPS) on a single NVIDIA 1080ti GPU. Codes are available at https://github.com/ZCHILLAXY/SPAN .},
  archive      = {J_IJMLC},
  author       = {Zhuang, Yi and Zhao, Haitao},
  doi          = {10.1007/s13042-022-01508-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2105-2117},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {SPAN: Siampillars attention network for 3D object tracking in point clouds},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel method for financial distress prediction based on
sparse neural networks with <span
class="math display"><em>L</em><sub>1/2</sub></span> regularization.
<em>IJMLC</em>, <em>13</em>(7), 2089–2103. (<a
href="https://doi.org/10.1007/s13042-022-01566-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corporate financial distress is related to the interests of the enterprise and stakeholders. Therefore, its accurate prediction is of great significance to avoid huge losses from them. Despite significant effort and progress in this field, the existing prediction methods are either limited by the number of input variables or restricted to those financial predictors. To alleviate those issues, both financial variables and non-financial variables are screened out from the existing accounting and finance theory to use as financial distress predictors. In addition, a novel method for financial distress prediction (FDP) based on sparse neural networks is proposed, namely FDP-SNN, in which the weight of the hidden layer is constrained with $$L_{1/2}$$ regularization to achieve the sparsity, so as to select relevant and important predictors, improving the predicted accuracy. It also provides support for the interpretability of the model. The results show that non-financial variables, such as investor protection and governance structure, play a key role in financial distress prediction than those financial ones, especially when the forecast period grows longer. By comparing those classic models proposed by predominant researchers in accounting and finance, the proposed model outperforms in terms of accuracy, precision, and AUC performance.},
  archive      = {J_IJMLC},
  author       = {Chen, Ying and Guo, Jifeng and Huang, Junqin and Lin, Bin},
  doi          = {10.1007/s13042-022-01566-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2089-2103},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel method for financial distress prediction based on sparse neural networks with $$L_{1/2}$$ regularization},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-granular attributed network representation learning.
<em>IJMLC</em>, <em>13</em>(7), 2071–2087. (<a
href="https://doi.org/10.1007/s13042-022-01507-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, increasing attention has been paid to network representation learning, which aims to map nodes into low dimensional vectors while preserving topology and node attribute information, which are both backbone information of the network. Existing studies mainly focus on fusing structure and node attributes on single granularity for the attributed network. However, many complex networks present multi-granular characteristics. In this paper, we propose MultI-granular attributed network Representation Learning (MIRL), an algorithm that captures the relationship between different granular attributed networks. Firstly, topological structure and attributes are fused from fine to coarse under different granularities to mine the node potential relationship between different granular networks. The coarser-grained node is composed of a number of fine-grained nodes that are similar in structure and attributes. For the attributed network at the coarsest granularity which is much smaller than the original attributed network, one of the existing network representation learning methods can be used to learn the representation of the coarsest granularity. To obtain more accurate representation of the original network, we train a graph convolutional neural network (GCN) at the coarsest granulation. The parameters of GCN passing from coarse to fine are shared between two adjacent granularities, so as to trade off time consumption and embedding performance. We evaluate our algorithm on three real-world datasets and two benchmark applications. Our experimental results demonstrate that MIRL significantly increases effectiveness compared to state-of-art network representation methods.},
  archive      = {J_IJMLC},
  author       = {Zou, Jiaxian and Du, Ziwei and Zhao, Shu},
  doi          = {10.1007/s13042-022-01507-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2071-2087},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-granular attributed network representation learning},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning cross-modality features for image caption
generation. <em>IJMLC</em>, <em>13</em>(7), 2059–2070. (<a
href="https://doi.org/10.1007/s13042-022-01506-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning is a challenging task in the research area of vision and language. Traditionally in a deep learning-based image captioning model, two types of input features are utilized for generating the token of the current inference step, including the attended visual feature and the previous word embedding. However, the sentence level embeddings are ignored in this typical working pipeline for captioning. In this paper, we propose Intrinsic Cross-Modality Captioning (ICMC), a new method to improve image captioning with sentence level embedding and Cross-Modality Alignment. The novelty of our proposed model mainly comes from the text encoder and the Cross-Modality module. In the feature encoding stage, we use an adaptation module to map the global visual features to the joint domain. In the decoding stage we then use the adapted features to guide the visual attention process with the RCNN features. With the proposed method we not only attend to the visual features and previous word for captions but also include the sentence level clues from the ground truths at training phase. The evaluation on the benchmark of MSCOCO and extensive ablation studies are performed to validate the effectiveness of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Zeng, Chao and Kwong, Sam},
  doi          = {10.1007/s13042-022-01506-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2059-2070},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning cross-modality features for image caption generation},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hindsight-aware deep reinforcement learning algorithm for
multi-agent systems. <em>IJMLC</em>, <em>13</em>(7), 2045–2057. (<a
href="https://doi.org/10.1007/s13042-022-01505-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classic reinforcement learning algorithms generate experiences by the agent&#39;s constant trial and error, which leads to a large number of failure experiences stored in the replay buffer. As a result, the agents can only learn through these low-quality experiences. In the case of multi-agent systems, this problem is more serious. MADDPG (Multi-Agent Deep Deterministic Policy Gradient) has achieved significant results in solving multi-agent problems by using a framework of centralized training with decentralized execution. Nevertheless, the problem of too many failure experiences in the replay buffer has not been resolved. In this paper, we propose HMADDPG (Hindsight Multi-Agent Deep Deterministic Policy Gradient) to mitigate the negative impact of failure experience. HMADDPG has a hindsight unit, which allows the agents to reflect and produces pseudo experiences that tend to succeed. Pseudo experiences are stored in the replay buffer, so that the agents can combine two kinds of experiences to learn. We have evaluated our algorithm on a number of environments. The results show that the algorithm can guide agents to learn better strategies and can be applied in multi-agent systems which are cooperative, competitive, or mixed cooperative and competitive.},
  archive      = {J_IJMLC},
  author       = {Li, Chengjing and Wang, Li and Huang, Zirong},
  doi          = {10.1007/s13042-022-01505-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2045-2057},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hindsight-aware deep reinforcement learning algorithm for multi-agent systems},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Augmentation and heterogeneous graph neural network for
AAAI2021-COVID-19 fake news detection. <em>IJMLC</em>, <em>13</em>(7),
2033–2043. (<a
href="https://doi.org/10.1007/s13042-021-01503-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Misinformation has become a frightening specter of society, especially fake news that concerning Covid-19. It massively spreads on the Internet, and then induces misunderstandings of information to the national and global communities during the pandemic. Detecting massive misinformation on the Internet is crucial and challenging because humans have struggled against this phenomenon for a long time. Our research concerns detecting fake news related to covid-19 using augmentation [random deletion (RD), random insertion (RI), random swap (RS), synonym replacement (SR)] and several graph neural network [graph convolutional network (GCN), graph attention network (GAT), and GraphSAGE (SAmple and aggreGatE)] model. We constructed nodes and edges in the graph, word-word node, and word-document node to graph neural network. Then, we tested those models in different amounts of sample training data to obtain accuracy for each model and compared them. For our fake news detection task, we found training accuracy steadily increasing for GCN, GAT, and SAGE models from the beginning to the end of the epochs. This result proved that the performance of GNN, whether GCN, GAT, or SAGE gained an entirely insignificant difference precision result.},
  archive      = {J_IJMLC},
  author       = {Karnyoto, Andrea Stevens and Sun, Chengjie and Liu, Bingquan and Wang, Xiaolong},
  doi          = {10.1007/s13042-021-01503-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2033-2043},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Augmentation and heterogeneous graph neural network for AAAI2021-COVID-19 fake news detection},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Global structure-guided neighborhood preserving embedding
for dimensionality reduction. <em>IJMLC</em>, <em>13</em>(7), 2013–2032.
(<a href="https://doi.org/10.1007/s13042-021-01502-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph embedding is one of the most efficient dimensionality reduction methods in machine learning and pattern recognition. Many local or global graph embedding methods have been proposed and impressive results have been achieved. However, little attention has been paid to the methods that integrate both local and global structural information without constructing complex graphs. In this paper, we propose a simple and effective global structure guided neighborhood preserving embedding method for dimensionality reduction called GSGNPE. Specifically, instead of constructing global graph, principal component analysis (PCA) projection matrix is first introduced to extract the global structural information of the original data, and then the induced global information is integrated with local neighborhood preserving structure to generate a discriminant projection. Moreover, the $$L_{2,1}$$ -norm regularization is employed in our method to enhance the robustness to occlusion. Finally, we propose an iterative optimization algorithm to solve the proposed problem, and its convergence is also theoretically analyzed. Extensive experiments on four face and six non-face benchmark data sets demonstrate the competitive performance of our proposed method in comparison with the state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Gao, Can and Li, Yong and Zhou, Jie and Pedrycz, Witold and Lai, Zhihui and Wan, Jun and Lu, Jianglin},
  doi          = {10.1007/s13042-021-01502-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2013-2032},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Global structure-guided neighborhood preserving embedding for dimensionality reduction},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3D transfer learning network for classification of
alzheimer’s disease with MRI. <em>IJMLC</em>, <em>13</em>(7), 1997–2011.
(<a href="https://doi.org/10.1007/s13042-021-01501-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a kind of dementia, Alzheimer’s disease (AD) cannot be cured once diagnosed. Hence, it is very important to diagnose early and delay the deterioration of the disease through drugs. To reduce the computational complexity of conventional 3D convolutional networks, this paper uses machine learning as an auxiliary diagnosis of AD, and proposes three-dimensional (3D) transfer network which is based on two-dimensional (2D) transfer network to classify AD and normal groups with magnetic resonance imaging (MRI). First, the method uses a 2D transfer Mobilenet to extract features from 2D slices of MRI, and further perform dimension reduction for the extracted features. Then, all of the 2D slice features of one subject are merged to classify. The experiment in this paper uses an open access Alzheimer&#39;s disease database to evaluate the method. The experiment result show that the classification accuracy of the proposed 3D network is better than that of the existing 2D transfer network, increased by about 10 percentage points and the classification time is only about 1/4 of the existing one. The proposed method is to realize the classification of 3D MRI data through an existing 2D transfer network, and it not only reduces the complexity of conventional 3D networks, but also improves the classification accuracy. Because of the shared weight of the transfer network, besides, the classification time is reduced.},
  archive      = {J_IJMLC},
  author       = {Wu, Haifeng and Luo, Jinling and Lu, Xiaoling and Zeng, Yu},
  doi          = {10.1007/s13042-021-01501-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1997-2011},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {3D transfer learning network for classification of alzheimer’s disease with MRI},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Supervised learning algorithm based on spike optimization
mechanism for multilayer spiking neural networks. <em>IJMLC</em>,
<em>13</em>(7), 1981–1995. (<a
href="https://doi.org/10.1007/s13042-021-01500-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised learning is one of the significant research contents in spiking neural networks (SNNs). Aiming at enhancing the performance and efficiency of supervised learning algorithms for multilayer SNNs, this paper proposes a spike optimization mechanism to select optimal presynaptic spikes for computing the change amount of synaptic weights during the learning process. The proposed spike optimization mechanism comprehensively considers the correlation between the desired and actual output spikes of the network. The synaptic weight adjustment is determined by the presynaptic spikes within an optimized time interval, which makes the network output spikes similar to the desired output spikes as much as possible. The spike optimization mechanism is applied to two representative supervised learning algorithms of multilayer SNNs (Multi-STIP and Multi-ReSuMe) to improve their learning performance. The spike train learning results show that the improved algorithms can achieve higher learning accuracy and require fewer learning epochs than the original algorithms. In addition, the spike optimization mechanism can shorten the running time of the algorithms. It indicates that the learning algorithms based on spike optimization are very efficient for learning spatio-temporal spike patterns.},
  archive      = {J_IJMLC},
  author       = {Hu, Tiandou and Lin, Xianghong and Wang, Xiangwen and Du, Pangao},
  doi          = {10.1007/s13042-021-01500-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1981-1995},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Supervised learning algorithm based on spike optimization mechanism for multilayer spiking neural networks},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Study on deduction process and inference methods of decision
implications. <em>IJMLC</em>, <em>13</em>(7), 1959–1979. (<a
href="https://doi.org/10.1007/s13042-021-01499-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision implication is a basic form of knowledge representation of Formal Concept Analysis in the setting of decision-making. Inference rules are generally utilized to infer new decision implications from a given set of decision implications. Three inference rules have been proposed for the deduction process on decision implications, i.e., Augmentation, Combination and Con-Combination. How to apply the inference rules, however, is not discussed in literature. To this end, we studied the properties of the inference rules and found that in the deduction process, Augmentation should be applied only once and that both Combination and Con-Combination need to be applied at most $$\lceil \log _{2}m\rceil$$ times. Moreover, by analyzing the interchangeabilities of the inference rules, we found that Augmentation and Combination are interchangeable, but Augmentation and Con-Combination are not. Based on these results, three inference methods were then proposed and their efficiencies were verified by experiments. The experimental results show that one of the inference methods, namely, applying Augmentation once and then applying Con-Combination at most $$\lceil \log _{2}m\rceil$$ times, is the most efficient inference method.},
  archive      = {J_IJMLC},
  author       = {Zhai, Yanhui and Jia, Nan and Zhang, Shaoxia and Li, Deyu and Xu, Weihua},
  doi          = {10.1007/s13042-021-01499-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1959-1979},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Study on deduction process and inference methods of decision implications},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-stacking random weight neural network with multi-layer
features fusion. <em>IJMLC</em>, <em>13</em>(7), 1945–1957. (<a
href="https://doi.org/10.1007/s13042-021-01498-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomized methods are practical and efficient for training the connectionist models. In this paper, we contribute to develop a self-stacking random weight neural network. Two different methods of feature fusion are proposed in this paper. The first one inter-connects the coarse and high level features to make the classification decision more diverse by using the proposed hierarchical network architecture with dense connectivity. On the other hand, the different decisions all-throughout the network are incorporated by a novel non-linear ensemble learning in an end-to-end manner. Through experiments, we verified the effectiveness of random features fusion, and even if each hierarchical branch in the network has very unfavorable accuracy, the proposed ensemble learning presents the impressive performance to boost the classification results. Moreover, the proposed connectionist model is applied to address one practice engineering problem of gearbox fault diagnosis, and the simulation demonstrates that our method has better robust to the noise in vibration signal of working gearbox.},
  archive      = {J_IJMLC},
  author       = {Fu, Aimin and Liu, Jingna and Zhang, Tian-Lun},
  doi          = {10.1007/s13042-021-01498-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1945-1957},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Self-stacking random weight neural network with multi-layer features fusion},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SCC-rFMQ: A multiagent reinforcement learning method in
cooperative markov games with continuous actions. <em>IJMLC</em>,
<em>13</em>(7), 1927–1944. (<a
href="https://doi.org/10.1007/s13042-021-01497-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although many multiagent reinforcement learning (MARL) methods have been proposed for learning the optimal solutions in continuous-action domains, multiagent cooperation domains with independent learners (ILs) have received relatively few investigations, especially in traditional RL domain. In this paper, we propose an sample based independent learning method, named Sample Continuous Coordination with recursive Frequency Maximum Q-Value (SCC-rFMQ), which divides the multiagent cooperative problem with continuous actions into two layers. The first layer samples a finite set of actions from the continuous action spaces by a re-sampling mechanism with variable exploratory rates, and the second layer evaluates the actions in the sampled action set and updates the policy using a reinforcement learning cooperative method. By constructing cooperative mechanisms at both levels, SCC-rFMQ can handle cooperative problems in continuous action cooperative Markov games effectively. The effectiveness of SCC-rFMQ is experimentally demonstrated on two well-designed games, i.e., a continuous version of the climbing game and a cooperative version of the boat problem. Experimental results show that SCC-rFMQ outperforms other reinforcement learning algorithms.},
  archive      = {J_IJMLC},
  author       = {Zhang, Chengwei and Han, Zhuobing and Liu, Bingfu and Xue, Wanli and Hao, Jianye and Li, Xiaohong and An, Dou and Chen, Rong},
  doi          = {10.1007/s13042-021-01497-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1927-1944},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {SCC-rFMQ: A multiagent reinforcement learning method in cooperative markov games with continuous actions},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new multi-granularity probabilistic linguistic two-sided
matching method considering peer effect and its application in pension
services. <em>IJMLC</em>, <em>13</em>(7), 1907–1926. (<a
href="https://doi.org/10.1007/s13042-021-01495-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {China is now facing a serious aging trend. With the increase in the demand for pension, the pension mode tends to be diversified. On one hand, the elderly want to select suitable pension modes based on their family situations. On the other hand, different pension modes should choose applicable elderly people according to their service characteristics. This two-way selection can be seen as a two-sided matching problem. Because this matching environment is usually complex and uncertain, multi-granularity probabilistic linguistic term set (PLTS) is an effective tool to describe the uncertain evaluation process. Furthermore, complex social relations of decision makers will affect decision-making results. Therefore, this paper aims to provide a two-sided matching method based on the peer effect using multi-granularity PLTSs, which can handle uncertain evaluation information accurately considering influence of social network relationships. Firstly, we propose a conversion method of multi-granularity PLTSs based on two-tuple linguistics. Then, we put forward a calculation formula for matching satisfaction with PLTSs with the consideration of the expectations and sensitivity to satisfaction for subjects. Furthermore, a multi-objective two-sided matching model with maximum satisfaction is established. Finally, we apply our method to a real case for matching of pension services and make comparisons with a traditional two-sided method.},
  archive      = {J_IJMLC},
  author       = {Wang, Nannan and Li, Peng},
  doi          = {10.1007/s13042-021-01495-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1907-1926},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new multi-granularity probabilistic linguistic two-sided matching method considering peer effect and its application in pension services},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). MGRL: Attributed multiplex heterogeneous network
representation learning based on multi-granularity information fusion.
<em>IJMLC</em>, <em>13</em>(7), 1891–1906. (<a
href="https://doi.org/10.1007/s13042-021-01494-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, attributed multiplex heterogeneous network (AMHN) representation learning has shown superiority in many network analysis tasks due to its ability to preserve both the structure of the network and the semantics of the nodes. However, few people consider the correlation between content attributes within each node. No personalized analysis model is designed for different semantics of heterogeneous relations. To address these issues, this paper proposes an MGRL model. MGRL adopts a filter based on variance discrimination to filter out the noise information in the node content attributes. To better utilize semantic characteristics of heterogeneous relations, personalized fusion models are designed according to heterogeneous relation categories: peer relations and subordinate relations. Results of experiments conducted on three real-world datasets show an obvious advantage of the proposed MGRL model over state-of-the-art baseline methods.},
  archive      = {J_IJMLC},
  author       = {Chen, Ke and Wang, Guoyin and Fu, Shun and Hu, Jun and Liu, Li},
  doi          = {10.1007/s13042-021-01494-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1891-1906},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MGRL: Attributed multiplex heterogeneous network representation learning based on multi-granularity information fusion},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-way improved neighborhood entropies based on
three-level granular structures. <em>IJMLC</em>, <em>13</em>(7),
1861–1890. (<a
href="https://doi.org/10.1007/s13042-021-01493-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood systems and their rough sets have robustness and adaptability, and relevant neighborhood information measures underlie uncertainty analysis and intelligent processing. The classical conditional neighborhood entropy becomes fundamental and representative for dependency measurement, but it has three limitations: interaction incompleteness, hierarchy lack, and inconclusive monotonicity/non-monotonicity. This paper aims to improve the conditional neighborhood entropy, and thus we establish three-way neighborhood entropies based on three-level granular structures. At first, three-level granular structures are proposed for neighborhood decision systems, and the conditional neighborhood entropy is improved to hierarchical conditional neighborhood entropies, mainly by information enrichment and hierarchical decomposition. According to simulation extension, three-way neighborhood entropies are then hierarchically constructed by logarithmic information function on three-way probabilities, and they acquire systematicness equations, monotonicity/non-monotonicity mechanisms, and integration algorithms. Finally, all concerned neighborhood information measures and their calculations, relationships, properties are effectively verified by both decision table examples and data set experiments. Three-way neighborhood entropies adhere to three levels and three modes to realize criss-cross informatization for neighborhood decision systems, and they achieve four improvement merits regarding accuracy, hierarchy, systematicness, and monotonicity. This study facilitates uncertainty measurement, information processing, and knowledge discovery.},
  archive      = {J_IJMLC},
  author       = {Zhang, Xianyong and Zhou, Yanhong and Tang, Xiao and Fan, Yunrui},
  doi          = {10.1007/s13042-021-01493-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1861-1890},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Three-way improved neighborhood entropies based on three-level granular structures},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Candidate region acquisition optimization algorithm based on
multi-granularity data enhancement. <em>IJMLC</em>, <em>13</em>(7),
1847–1860. (<a
href="https://doi.org/10.1007/s13042-021-01492-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the deepening network hierarchy of deep learning, improving the accuracy of the candidate region acquisition algorithm can help save time and improve operational efficiency in subsequent work. Since the traditional methods overly rely on single-grain size, color and texture features of images, which can easily lead to candidate frames cutting off the foreground object when acquiring candidate regions, this paper proposes a multi-granularity selective search algorithm (MGSS) for candidate region acquisition by extracting the main features such as outline, texture and color of images with multiple grain sizes and improving the subgraph similarity calculation method.This paper mainly compares the performance of previous common algorithms on Pascal VOC 2012 and 2007 datasets, and the experiments show that the method used in this paper maintains the Mean Average Best Overlap (MABO) values of 0.909 and 0.890, which is 9.55 $$\%$$ and 2.05 $$\%$$ better than the Selective Search (SS)“Fast” and SS “Quality” results, respectively. The experiments show that both R-CNN and Fast R-CNN algorithms improve mAP (mean Average Precision) values by 1.5, 0.8 and 0.6 $$\%$$ with MGSS respectively, over with the traditional SS algorithm and RPN algorithm.},
  archive      = {J_IJMLC},
  author       = {Chen, Dong and Miao, Duoqian and Zhao, Cairong and Zhou, Hailong},
  doi          = {10.1007/s13042-021-01492-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1847-1860},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Candidate region acquisition optimization algorithm based on multi-granularity data enhancement},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A joint extraction model of entities and relations based on
relation decomposition. <em>IJMLC</em>, <em>13</em>(7), 1833–1845. (<a
href="https://doi.org/10.1007/s13042-021-01491-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting entities and relations from unstructured text is an essential task in the field of information extraction. Existing work mainly pipeline extraction and joint decoding methods. However, these methods are unable to extract overlapping entities and relations, and ignore the task correlation between entity and relation extraction. In this paper, we first introduce the BERT pre-training model to model the text more finely. Then, we decompose the extraction into relation extraction and entity recognition. Relation extraction is transformed into a relation classification task. Entity recognition is transformed into a sequence labeling task. The recognition entity includes a head entity and a tail entity. We evaluate the model on the New York Times (NYT) and WebNLG datasets. Compared with most existing models, excellent results have been obtained. Experimental results show that our model can fully capture the semantic interdependence between the two tasks of entity and relation extraction, reduce the interference of unrelated entity pairs, and effectively solve the problem of entity overlap.},
  archive      = {J_IJMLC},
  author       = {Gao, Chen and Zhang, Xuan and Liu, Hui and Yun, Wei and Jiang, Jiahao},
  doi          = {10.1007/s13042-021-01491-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1833-1845},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A joint extraction model of entities and relations based on relation decomposition},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving recommendation quality through outlier removal.
<em>IJMLC</em>, <em>13</em>(7), 1819–1832. (<a
href="https://doi.org/10.1007/s13042-021-01490-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rating data collected by recommendation systems contain noise caused by human uncertainty and malicious attacks. Existing outlier removal approaches usually aim at detecting noise inserted into ground-truth ratings. However, in real applications, the ground-truth of the training data are unavailable, or even unimportant for the prediction task. In this paper, we propose an efficient and effective outlier removal algorithm to improve the quality of the training data. The noise is modeled by the mixture of Gaussian distribution, which can approximate any continuous distribution. First, we employ the expectation-maximization algorithm to calculate the low-rank matrices, whose product forms the recovered ratings. Second, we compare the original and recovered ratings to solicit suspected outliers. This process is repeated a number of times, and ratings that are suspected enough times will be treated as outliers. To validate the effectiveness of our algorithm, we compared the prediction quality of four popular recommendation algorithms. Results showed that several measures on the algorithms were improved with the new training data.},
  archive      = {J_IJMLC},
  author       = {Xu, Yuan-Yuan and Gu, Shen-Ming and Min, Fan},
  doi          = {10.1007/s13042-021-01490-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1819-1832},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improving recommendation quality through outlier removal},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic maintenance of variable precision fuzzy neighborhood
three-way regions in interval-valued fuzzy decision system.
<em>IJMLC</em>, <em>13</em>(7), 1797–1818. (<a
href="https://doi.org/10.1007/s13042-021-01489-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a typical generalization of classical rough set, variable precision fuzzy neighborhood rough set (VPFNRS) can effectively handle the datasets with noise. At the same time, the three-way regions induced by VPFNRS can determine some decision rules. However, data usually changes over time in real life, such as the addition of new objects and the removal of obsolete objects. Therefore, the rules determined by the three-way regions may change with time. To address this issue, we investigate the dynamic maintenance of the variable precision fuzzy neighborhood three-way regions under the background of interval-valued fuzzy decision system (IvFDS), aiming to effectively update the three-way regions in dynamic environment. Firstly, the $$\delta$$ -fuzzy neighborhood relation and its induced $$\delta$$ -fuzzy neighborhood class are defined. On this basis, a novel VPFNRS model suitable for IvFDS is proposed. Secondly, the variable precision fuzzy neighborhood three-way regions induced by the proposed model and its matrix representations are introduced. Subsequently, the matrix-based incremental mechanisms to update the three-way regions when the objects change are constructed. Meanwhile, corresponding incremental algorithms are designed. Finally, a series of numerical comparative experiments are executed on nine datasets, and the results indicate that incremental algorithms are not only effective, but also highly efficient under the dynamic data environment.},
  archive      = {J_IJMLC},
  author       = {Yang, Lei and Qin, Keyun and Sang, Binbin and Xu, Weihua},
  doi          = {10.1007/s13042-021-01489-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1797-1818},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dynamic maintenance of variable precision fuzzy neighborhood three-way regions in interval-valued fuzzy decision system},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: Binary domain adaptation with independence
maximization. <em>IJMLC</em>, <em>13</em>(6), 1795. (<a
href="https://doi.org/10.1007/s13042-021-01468-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {Abdi, Lida and Hashemi, Sattar},
  doi          = {10.1007/s13042-021-01468-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1795},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Correction to: Binary domain adaptation with independence maximization},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fault detection of train mechanical parts using multi-mode
aggregation feature enhanced convolution neural network. <em>IJMLC</em>,
<em>13</em>(6), 1781–1794. (<a
href="https://doi.org/10.1007/s13042-021-01488-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Faults in train mechanical parts pose a significant safety hazard to railway transportation. Although some image detection methods have replaced manual fault detection of train mechanical parts, the detection effect on small mechanical parts under low illumination conditions is not ideal. To improve the accuracy and efficiency of the detection of train faults under different environments, we propose a multi-mode aggregation feature enhanced network (MAFENet) based on a single-stage detector (SSD). This network uses the idea of a two-step adjustment structure from coarse to fine and uses the K-means algorithm to design anchors. The receptive field enhancement module (RFEM) is designed to obtain the fusion features of different receptive fields. The attention-guided detail feature enhancement module (ADEM) is designed to complement the detailed features of deep-level feature maps. Meanwhile, the complete intersection over union (CIoU) loss is used to obtain more accurate bounding boxes. The experimental results on the train mechanical parts fault (TMPF) dataset showed that the detection performance of MAFENet is better than those of other SSD models. MAFENet with an input size of 320 × 320 pixels can achieve a mean average precision (mAP) of 0.9787 and a detection speed of 33 frames per second (FPS), which indicates that it can realize real-time detection, has good robustness to images under different environmental conditions, and can be used to improve the efficiency of the detection of faulty train parts.},
  archive      = {J_IJMLC},
  author       = {Tao, Ye and Jun, Zhang and Zhi-hao, Zhang and Yi, Zhang and Fu-qiang, Zhou and Xiao-zhi, Gao},
  doi          = {10.1007/s13042-021-01488-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1781-1794},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fault detection of train mechanical parts using multi-mode aggregation feature enhanced convolution neural network},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deconfounded classification by an intervention approach.
<em>IJMLC</em>, <em>13</em>(6), 1763–1779. (<a
href="https://doi.org/10.1007/s13042-021-01486-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For an automatic system, image classification is much challenging, partly due to noises that obscure or reduce the clarity of data. Thus, noise suppression has become one of the core tasks of classification. There is often a key assumption in classification that any noise source only affects one side of images and labels. However, this assumption overlooks the confounding scenario that the same noise source affects both images and labels. In this paper, we propose an intervention approach to learn a deconfounded classification model. Classification problem is firstly formulated as causal inference, where intervention is used to untangle the causal from the correlatives, and derive a causal effect formula for deconfounded classification. The WAE (Wasserstein Auto-Encoder) objective is then expanded for classification, with a new regularizer defined for learning unobserved confounders. To build a robust network architecture, a probability factorization is performed in conjunction with d-separation rule to find useful dependency patterns in data. The deconfounded classification model is finally obtained by rearranging the components of the learnt decoder according to the causal effect formula. The experimental results demonstrate our approach outperforms significantly the existing state-of-the-art classification models, particularly on imbalanced data.},
  archive      = {J_IJMLC},
  author       = {Yang, Fenglei and Han, Jingling and Li, Baomin},
  doi          = {10.1007/s13042-021-01486-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1763-1779},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deconfounded classification by an intervention approach},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-granulation multi-scale relation network for abstract
reasoning. <em>IJMLC</em>, <em>13</em>(6), 1751–1762. (<a
href="https://doi.org/10.1007/s13042-021-01484-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract reasoning, one of the representative works of logic learning, is to make machines intelligent. To test the intelligence of machines, researchers have proposed multiple benchmark data sets and these date sets mainly consist of a few simple geometries and traced reasoning paths. There are three issues for these data sets: (1) it is relatively easy for machines to reason the right answer from the simple geometries; (2) due to the limited number of geometric shapes, these data sets are prone to disclosure of information about reasoning; (3) all traced reasoning paths in these data sets have been known beforehand, some state-of-the-art reasoning models are specially designed according to these paths. Hence, these benchmark data sets cannot truly reflect the reasoning ability of reasoning models. To address these issues, we propose a Fashion Non-descending Path data set (FNP). FNP is designed using a mass of complex samples from Fashion-MNIST data set as objects of FNP and the non-descending path that is a more complex path as the variation directions of logical patterns. For gaining reasoning performance on FNP, inspired by the multi-granulation and multi-scale ideas, we propose a multi-granulation multi-scale relation network (M2RN) to consider the multi-wise relations rather than the simple pair-wise relations. Experimental results show that the M2RN is effective for abstract reasoning task.},
  archive      = {J_IJMLC},
  author       = {Guo, Qian and Qian, Yuhua and Liang, Xinyan and Chen, Junyu and Cheng, Honghong},
  doi          = {10.1007/s13042-021-01484-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1751-1762},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-granulation multi-scale relation network for abstract reasoning},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-supervised attribute reduction for interval data based
on misclassification cost. <em>IJMLC</em>, <em>13</em>(6), 1739–1750.
(<a href="https://doi.org/10.1007/s13042-021-01483-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction is a key issue in rough set theory which is widely used to handle uncertain knowledge. In reality, partially labeled interval data exist widely. So far, there are very few studies on partially labeled interval information systems. In this paper, we first define the concept of interval neighborhood by means of Kullback–Leibler (KL) divergence and standard deviation. Then a method is proposed to estimate the missing label by the nearest labeled objects to an unlabeled object and the cost of misclassification is constructed. Next a new entropy structure based on misclassification cost is proposed. After that, a semi-supervised attribute reduction method for partially labeled interval data is advanced. Finally, The rationality and validity of the method are demonstrated by experimental comparison.},
  archive      = {J_IJMLC},
  author       = {Dai, Jianhua and Liu, Qiong},
  doi          = {10.1007/s13042-021-01483-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1739-1750},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Semi-supervised attribute reduction for interval data based on misclassification cost},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SEMG based hand gesture recognition with deformable
convolutional network. <em>IJMLC</em>, <em>13</em>(6), 1729–1738. (<a
href="https://doi.org/10.1007/s13042-021-01482-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing interest in human machine interface and their applications using surface electromyography (sEMG). sEMG based gesture recognition plays a crucial role in interfacing with peripheral devices such as prosthetic hands. Give the challenges in the state of the art of sEMG based gesture recognition using deep learning, we propose a deformable convolutional network (DCN) to optimise the conventional convolution kernels with a goal of achieving better performance of sEMG based gesture recognition. The DCN first apply traditional convolutional layer to obtain low-dimensional feature maps, then use deformable convolutional layer to get high-dimensional feature maps. Moreover, we propose and compare two new image representation methods based on traditional feature extraction, which enable deep learning architectures to extract implicit correlations between different channels from the sparse multichannel sEMG signals. The experiments are conducted to evaluate the proposed methods on three groups of different types and numbers of gestures on the Ninapro-DB1 data set, the proposed DCN has an improvement of 1.1\%, 2.6\%, and 4.9\% compared with traditional CNN, respectively. In addition, the results of experiments indicate that the DCN shows robustness and feasibility in both feature extraction and classification recognition for the sEMG based gesture recognition.},
  archive      = {J_IJMLC},
  author       = {Wang, Hao and Zhang, Yue and Liu, Chao and Liu, Honghai},
  doi          = {10.1007/s13042-021-01482-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1729-1738},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {SEMG based hand gesture recognition with deformable convolutional network},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A safe acceleration method for multi-task twin support
vector machine. <em>IJMLC</em>, <em>13</em>(6), 1713–1728. (<a
href="https://doi.org/10.1007/s13042-021-01481-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task twin support vector machine (DMTSVM) performs better than twin support vector machine (TSVM) since it takes full advantage of the shared information among all tasks. However, it remains challenging to apply DMTSVM to large-scale problems directly. Inspired by the sparsity of DMTSVM, two safe sample screening rules SSRC-DMTSVM and SSRR-DMTSVM for DMTSVM are proposed in this paper. The two rules can identify and delete most inactive instances before solving the optimization problem. Therefore, the computational cost can be reduced greatly. More importantly, they are safe in the sense that the proposed methods could achieve the exactly same solution as solving the original problem. Besides, our screening rules are independent of the solver, thus they can be combined with other fast algorithms. To further accelerate the computational speed, we employ a dual coordinate descent method (DCDM) for DMTSVM. Numerical experiments on eight synthetic data sets, nine multi-task benchmark data sets, a real Chinese grape wine data set and two popular image data sets demonstrate that the computational cost can be dramatically reduced without sacrificing the accuracy by our proposed methods.},
  archive      = {J_IJMLC},
  author       = {Xie, Fan and Xu, Yitian and Ma, Mengdan and Pang, Xinying},
  doi          = {10.1007/s13042-021-01481-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1713-1728},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A safe acceleration method for multi-task twin support vector machine},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Kernel alignment-based three-way clustering on attribute
space and its application in stroke risk identification. <em>IJMLC</em>,
<em>13</em>(6), 1697–1711. (<a
href="https://doi.org/10.1007/s13042-021-01478-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying the key risk factors of disease from a large amount of clinical data is a prerequisite for further scientific decision-making. In medical practice, the clinical symptom information of patients usually includes various types of data. Meanwhile, the occurrence and development of diseases are joint result of the mutual influence factors. Therefore, there is usually a correlation between attributes. In this paper, we discuss a kind of hybrid attribute feature selection problem considering the correlation between attributes. Firstly, we take the identification of disease pathogenic factors in medical decision as the background, and construct a hybrid attribute decision system. Secondly, by introducing kernel alignment, the uncertain relationship between attributes is defined. Based on this, a three-way clustering model in attribute space is established. Furthermore, a feature selection method for hybrid attribute data based on three-way clustering in attribute space is proposed. Finally, we applied the proposed model to identify the pathogenic factors of stroke and used 279 clinical random samples for simulation analysis. The results verified the applicability and validity of the model. The main contributions of this paper include two aspects. In terms of theory, by introducing kernel alignment, a three-way clustering algorithm in attribute space is established. Meanwhile, a hybrid attribute feature selection method based on three-way clustering is proposed. In terms of application, the proposed method is applied to identify risk factors of stroke.},
  archive      = {J_IJMLC},
  author       = {Wang, Ting and Sun, Bingzhen and Jiang, Chao and Weng, Heng and Chu, Xiaoli},
  doi          = {10.1007/s13042-021-01478-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1697-1711},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Kernel alignment-based three-way clustering on attribute space and its application in stroke risk identification},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature extraction and classification algorithm, which one
is more essential? An experimental study on a specific task of vibration
signal diagnosis. <em>IJMLC</em>, <em>13</em>(6), 1685–1696. (<a
href="https://doi.org/10.1007/s13042-021-01477-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of machine learning, a data-driven model has been widely used in vibration signal fault diagnosis. Most data-driven machine learning algorithms are built based on well-designed features, but feature extraction is usually required to be completed in advance. In the deep learning era, feature extraction and classifier learning are conducted simultaneously, which will lead to an end-to-end learning system. This paper explores which one of the two key factors, i.e., feature extraction and classification algorithm, is more essential for a specific task of vibration signal diagnosis during a learning system is generated. Feature extractions from vibration signal based on both well-known Gaussian model and statistical characteristics are discussed, respectively. And several classification algorithms are selected to experimentally validate the comparative impact of both feature extraction and classification algorithm on prediction performance.},
  archive      = {J_IJMLC},
  author       = {Liu, Qiang and Zhang, Jiade and Liu, Jingna and Yang, Zhi},
  doi          = {10.1007/s13042-021-01477-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1685-1696},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature extraction and classification algorithm, which one is more essential? an experimental study on a specific task of vibration signal diagnosis},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multigranulation double-quantitative decision-theoretic
rough sets based on logical operations. <em>IJMLC</em>, <em>13</em>(6),
1661–1684. (<a
href="https://doi.org/10.1007/s13042-021-01476-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As two important expanded quantification rough sets models, the multigranulation decision-theoretic rough sets mainly uses conditional probability to show relative quantitative information in multigranulation framework, and the graded multigranulation rough set is used to measure absolute quantitative information. However, they only consider the absolute quantitative (relative quantitative) information in granular structure, but do not consider the relative quantitative (absolute quantitative) information. It means that they cannot reflect a complete information. In order to overcome the defect, this paper proposes two pairs of multigranulation double-quantitative decision-theoretic rough sets models based on Bayesian decision and graded multigranulation rough sets, which essentially indicate the relative and absolute information quantification. After further studies to discuss decision rules and the inner relationship between these two models. Furthermore, we introduce an illustrative case to show the effectiveness and superiority of our proposed models, and the results show that our methods are effective for dealing with practical problems. Finally, we present some experiments based on UCI data sets showing the advantages of our proposed models in classification performance.},
  archive      = {J_IJMLC},
  author       = {Li, Mengmeng and Zhang, Chiping and Chen, Minghao and Xu, Weihua},
  doi          = {10.1007/s13042-021-01476-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1661-1684},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multigranulation double-quantitative decision-theoretic rough sets based on logical operations},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Speed control of electric vehicle by using type-2 fuzzy
neural network. <em>IJMLC</em>, <em>13</em>(6), 1647–1660. (<a
href="https://doi.org/10.1007/s13042-021-01475-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The forces of drag, tire and road surface friction resistance, the drive motor characteristics, the hill climbing angle, and other non-linear dynamic factors affect the performance of electric vehicles (EV) tremendously. The proposed self-construction of type-2 fuzzy neural network (SCT2FNN) controller was based on the robust typical type-2 fuzzy neural network (T2FNN) controller. T2FNN with the self-construct parameter and online learning could estimate the angular velocity of the motor operation to control the EV. Hence, SCT2FNN with the self-construct parameter and online learning could promptly track the speed of EV. SCT2FNN also could estimate the torque control of DC motor. The simulation results showed that SCT2FNN controller was more efficient than PID controller, while the speed was controlled by considering the difference of the climbing slope.},
  archive      = {J_IJMLC},
  author       = {Chang, Ming-Hung and Wu, Yi-Chao},
  doi          = {10.1007/s13042-021-01475-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1647-1660},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Speed control of electric vehicle by using type-2 fuzzy neural network},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incremental sequential three-way decision based on continual
learning network. <em>IJMLC</em>, <em>13</em>(6), 1633–1645. (<a
href="https://doi.org/10.1007/s13042-021-01472-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning has attracted much attention in recent years, and many continual learning methods based on deep neural networks have been proposed. However, several important problems about these methods may lead to high decision cost and affect the practical application of continual learning networks. First, continual learning networks treat all categories equally, although the unbalance of misclassification cost happens in real-world cases. Second, there is a trade-off between learning new knowledge and keep old knowledge, which leads to the forgetting of old knowledge (i.e., the catastrophic forgetting). Third, even if low confidence of a sample, the continual learning methods based on the neural network will still give a clear classification result. We propose a sequential three-way decision model for continual learning to address these problems, named Incremental Sequential Three-Way Decision model (ISTWD). Introducing cost-sensitive sequential three-way decision to continual learning network, ISTWD reduces the decision cost of continual learning, which may alleviate the potentially high cost caused by the accuracy loss in continual learning. Besides, ISTWD includes a checkpoint procedure to judge whether the process of continual learning should stop. Experimental results on CIFAR-100 and Tiny-ImageNet verify the effectiveness of our method.},
  archive      = {J_IJMLC},
  author       = {Li, Hongyuan and Yu, Hong and Min, Fan and Liu, Dun and Li, Huaxiong},
  doi          = {10.1007/s13042-021-01472-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1633-1645},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Incremental sequential three-way decision based on continual learning network},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Community discovery algorithm of complex network attention
model. <em>IJMLC</em>, <em>13</em>(6), 1619–1631. (<a
href="https://doi.org/10.1007/s13042-021-01471-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In terms of understanding the structure of complex networks or the functional characteristics of complex networks, community discovery is of great significance. This paper uses the attention model to combine the second-order neighbor similarity matrix with the modularity matrix, extracts relatively more comprehensive complex network feature information from multiple angles for network division. Firstly, perform complex network preprocessing, and perform division preprocessing according to the value of the attention similarity matrix. Secondly, complete the merger of the community game according to the connection strength between the two different communities. By comparing with other algorithms on computer-generated networks and real-world networks, it is proved that this algorithm has obtained good results in terms of the number of communities, running time, normalized mutual information and modularity.},
  archive      = {J_IJMLC},
  author       = {Wang, Jinghong and Li, Haokang and Liang, Lina and Zhou, Yi},
  doi          = {10.1007/s13042-021-01471-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1619-1631},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Community discovery algorithm of complex network attention model},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Active partial label learning based on adaptive sample
selection. <em>IJMLC</em>, <em>13</em>(6), 1603–1617. (<a
href="https://doi.org/10.1007/s13042-021-01470-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial label learning is a type of weak supervised learning which uses samples with candidate label sets to train a classifier. Most of the related researches assume that there are a lot of available training samples with partial labels in advance, that is to assume that the candidate label set is easy to obtain. In many practical problems, however, there are still a large number of unlabeled samples, and obtaining their partial labels is costly. In this paper, we consider using a small number of partially labeled samples and a large number of unlabeled samples to form the training set, and propose a partial label learning method based on active learning mechanism to construct an effective classifier. Firstly, the weak supervised information in candidate label set is used to determine the possible labels of the partially labeled samples by using iterative label transfer process; then an adaptive sample selection strategy in active learning framework is proposed to comprehensively measure the labeling value of each unlabeled sample based on its uncertainty, graph density and label transfer ability, and the most valuable samples are selected from unlabeled sample set for manual labeling. Finally, the labeled samples are used to re-optimize the existing partially labeled samples, and the final classifier is trained. The experimental results on some benchmark datasets show that the proposed active partial label learning method has higher classification accuracy than the representative similar methods, and only needs to label a small number of samples to achieve stable performance.},
  archive      = {J_IJMLC},
  author       = {Li, Yan and Liu, Chang and Zhao, Suyun and Hua, Qiang},
  doi          = {10.1007/s13042-021-01470-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1603-1617},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Active partial label learning based on adaptive sample selection},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view multi-label active learning with conditional
bernoulli mixtures. <em>IJMLC</em>, <em>13</em>(6), 1589–1601. (<a
href="https://doi.org/10.1007/s13042-021-01467-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification is very common in practical applications. Compared with multi-class classification, multi-label classification has larger label space and thus the annotations of multi-label instances are typically more time-consuming. It is significant to develop active learning methods for multi-label classification problems. In addition, multi-view learning is more and more popular, which treats data from different views discriminatively and integrates information from all the views effectively. Introducing multi-view methods into active learning can further enhance its performance when processing multi-view data. In this paper, we propose multi-view active learning methods for multi-label classifications. The proposed methods are developed based on the conditional Bernoulli mixture model which is an effective model for multi-label classification. For making active selection criteria, we consider selecting informative and representative instances. From the informative perspective, least confidence and entropy of the predicting results are employed. From the representative perspective, clustering results on the unlabeled data are exploited. Particularly for multi-view active learning, novel multi-view prediction methods are designed to make final prediction and view consistency is additionally considered to make selection criteria. Finally, we demonstrate the effectiveness of the proposed methods through experiments on real-world datasets.},
  archive      = {J_IJMLC},
  author       = {Zhao, Jing and Qiu, Zengyu and Sun, Shiliang},
  doi          = {10.1007/s13042-021-01467-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1589-1601},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-view multi-label active learning with conditional bernoulli mixtures},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Concentrated hashing with neighborhood embedding for image
retrieval and classification. <em>IJMLC</em>, <em>13</em>(6), 1571–1587.
(<a href="https://doi.org/10.1007/s13042-021-01466-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hashing learning is efficient for large-scale image retrieval by using the nearest neighbor search with binary codes instead of continuous representations. With the success of deep neural networks in related tasks such as data representation, recent hashing methods based on deep learning can further improve image retrieval quality and classification accuracy. However, most existing methods are primarily designed to maximize the performance of retrieval based on linear scan of hash codes which is still time-consuming on large-scale datasets. Fortunately, Hamming space retrieval is an alternative as it is less time-consuming by retrieving data points that are within a Hamming ball with a given Hamming radius, but few works focus on that. In this paper, we propose a concentrated hashing method with neighborhood embedding (CHNE) for efficient and effective image retrieval and classification. By integrating Cauchy cross-entropy and pair-wise weighted similarity loss, CHNE can enable similar data pairs with smaller Hamming distance and dissimilar data pairs with larger Hamming distance. In addition, existing hashing methods are usually designed for retrieval, thus the performance of classification using the binary codes is not guaranteed. To tackle this problem, we jointly minimize the regression quantization and neighborhood structure reconstruction errors in the loss function to improve the classification accuracy. The proposed end-to-end deep hashing method can be optimized by back-propagation in a standard manner. Experimental results on several datasets demonstrate that the proposed method can improve the performance of retrieval and classification. Due to its generality, the proposed method is expected to be useful for image retrieval and classification in broader areas.},
  archive      = {J_IJMLC},
  author       = {Mo, Dongmei and Wong, Wai Keung and Liu, Xianjing and Ge, Yao},
  doi          = {10.1007/s13042-021-01466-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1571-1587},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Concentrated hashing with neighborhood embedding for image retrieval and classification},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Meta-path-based heterogeneous graph neural networks in
academic network. <em>IJMLC</em>, <em>13</em>(6), 1553–1569. (<a
href="https://doi.org/10.1007/s13042-021-01465-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graph representation learning is designed to learn meaningful representation vectors from heterogeneous networks in few dimensions to extract the structure and features of the attributes of these networks. The embedding vector is the basis of and crucial to complex network analysis, and can be used in such downstream tasks as classification, clustering, link prediction, and recommendation. Key issues in heterogeneous graph neural networks pertain to ways to define heterogeneous neighbors and ways to aggregate them. Although considerable research has been devoted to homogeneous and heterogeneous network representation, the effective combination of information on the network structure and the attributes of nodes, especially effective use of meta-paths containing specific semantic information, remains rare. Here a meta-path-based heterogeneous graph neural network model is proposed. The meta-path is applied to sample the heterogeneous neighbors of each node in the network, and aggregate features of the same types of nodes to form type-related embedding. A multi-head attention mechanism is then applied to aggregate information on neighbors of different types of nodes and the model is trained by reducing context loss. Experiments on classification, clustering, link prediction, and recommendation tasks verified the validity of this model, which significantly improved the results of baseline methods.},
  archive      = {J_IJMLC},
  author       = {Liang, Xingxing and Ma, Yang and Cheng, Guangquan and Fan, Changjun and Yang, Yuling and Liu, Zhong},
  doi          = {10.1007/s13042-021-01465-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1553-1569},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Meta-path-based heterogeneous graph neural networks in academic network},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Relative measure-based approaches for ranking single-valued
neutrosophic values and their applications. <em>IJMLC</em>,
<em>13</em>(6), 1535–1552. (<a
href="https://doi.org/10.1007/s13042-021-01464-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During uncertain information processing on generalized fuzzy values, how to rank two single-valued neutrosophic values is an important and omnipresent issue in all kinds of intelligent decision problems solving. Although many orders have been proposed to compare any two single-valued neutrosophic values, some shortcomings may exist when they are utilized. Inspired by the Euclidean approach for ranking intuitionistic fuzzy values, we present two types of orders by using the notion of relative geometric distance and relative similarity degree, respectively. First, we present two relative distance-based and relative similarity-based measures to describe the favorable degree of the single-valued neutrosophic value by considering three distances and similarity degrees between a single-valued neutrosophic value and the ideal negative point, ideal positive point, and most uncertain point. Second, two orders over the set of all single-valued neutrosophic values and the corresponding ranking methods for single-valued neutrosophic sets are devised on the basis of the presented measures of an single-valued neutrosophic value, and their properties are discussed. Third, we extend the presented ranking method for single-valued neutrosophic values and single-valued neutrosophic sets by introducing human attitudes using different weights. Finally, we apply the presented methods to optimal alternative selection and group decision making and obtain the effective and reasonable results. The main thoughts of this study can be applied in various generalized fuzzy decision problem solving.},
  archive      = {J_IJMLC},
  author       = {Huang, Bing and Yang, Xuan and Feng, Guofu and Guo, Chunxiang},
  doi          = {10.1007/s13042-021-01464-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1535-1552},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Relative measure-based approaches for ranking single-valued neutrosophic values and their applications},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The interval probabilistic double hierarchy linguistic EDAS
method based on natural language processing basic techniques and its
application to hotel online reviews. <em>IJMLC</em>, <em>13</em>(6),
1517–1534. (<a
href="https://doi.org/10.1007/s13042-021-01463-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, double hierarchy linguistic expression models have developed rapidly in the field of decision making because their rich semantics are closer to people’s actual language environment. However, the existing double hierarchy linguistic expression models are difficult to deal with incomplete or missing information application situations. For example, online reviews provide some references for consumers to make decisions, but the information of many reviews is not necessarily complete. Therefore, we try to solve this problem and propose the concept of interval probabilistic double hierarchy linguistic term set (IP-DHLTS). At the same time, in order to ensure stability under different criteria weights, we choose to combine the EDAS method to obtain the average solution based on two measures. To sum up, we develop the interval probabilistic double hierarchy linguistic EDAS method and solve a real case with the natural language processing basic techniques about the hotel online reviews. Finally, the feasibility of the proposed method is verified by comparison with other methods.},
  archive      = {J_IJMLC},
  author       = {Wang, Xindi and Xu, Zeshui and Gou, Xunjie},
  doi          = {10.1007/s13042-021-01463-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1517-1534},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {The interval probabilistic double hierarchy linguistic EDAS method based on natural language processing basic techniques and its application to hotel online reviews},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A further study on optimal scale selection in dynamic
multi-scale decision information systems based on sequential three-way
decisions. <em>IJMLC</em>, <em>13</em>(5), 1505–1515. (<a
href="https://doi.org/10.1007/s13042-021-01474-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimal scale selection is the key problem in the study of multi-scale decision information systems. Dynamic change is one of the main features of big data, and the amount of information will often increase sharply with the passing of time. As is well known, the issue of updating the optimal scale of a multi-scale decision information system has been becoming a challenging problem in recent years, and it indeed has important theoretical and practical research values. Note that adding multiple objects can be viewed as adding one object multiple times. So, it just needs to clarify the change laws of optimal scale under the case of adding one object. Although the existing work has considered this problem in terms of the sufficient condition of updating the optimal scale, the results seem to be inaccurate. In other words, both sufficient and necessary conditions are still missing. In this paper, using sequential three-way decisions, the sufficient and necessary conditions of updating the optimal scale of a multi-scale decision information system are developed for the addition of an object, which makes the theoretical study on updating the optimal scale more complete.},
  archive      = {J_IJMLC},
  author       = {Chen, Yingsheng and Li, Jinhai and Li, Jinjin and Lin, Rongde and Chen, Dongxiao},
  doi          = {10.1007/s13042-021-01474-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1505-1515},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A further study on optimal scale selection in dynamic multi-scale decision information systems based on sequential three-way decisions},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TSLOD: A coupled generalized subsequence local outlier
detection model for multivariate time series. <em>IJMLC</em>,
<em>13</em>(5), 1493–1504. (<a
href="https://doi.org/10.1007/s13042-021-01462-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised subsequence outlier detection on multivariate time series (MTS) is a valuable problem in practice that can observably save the cost of labeling and provide interpretability in real applications. For the task, most of the classic methods are under two strong assumptions: (i) stationary MTS. it may have difficulty coping with the phenomenon of time drift. (ii) Attribute-level IIDness (independent and identically distributed), it may ignore the relationship between attribute when measuring the similarity between multivariate subsequences. The above assumptions limit the availability of existing methods in real scenarios. To address this issue, this paper introduces a novel coupled generalized local outlier detection model for MTS, which extends the traditional generalized local outlier detection model to cope with subsequence outlier detection tasks by incorporating a novel Non-IID similarity metric. Specifically, the proposed method mainly includes three aspects: (i) represents the MTS relationship in symbolic space which provides a lower complexity and satisfactory sensitivity. (ii) Proposes a Non-IID coupled similarity metric (TSDis) which considers the intrinsic intra-attribute and inter-attribute coupling between segments. (iii) Extends the traditional generalized local outlier detection model to handle subsequence outlier detection tasks by embedding Non-IID coupled similarity metric. Experimental results show the proposed method can utilize the potential characteristics of MTS effectively and stably. Meanwhile, it detects outliers more accurately than baseline approaches on 12 time-series datasets.},
  archive      = {J_IJMLC},
  author       = {Meng, Fan and Gao, Yang and Wang, Huihui and Liu, Yi and Wang, Hairong},
  doi          = {10.1007/s13042-021-01462-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1493-1504},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {TSLOD: A coupled generalized subsequence local outlier detection model for multivariate time series},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A fuzzy system with common linear-term consequents
equivalent to FLNN and GMM. <em>IJMLC</em>, <em>13</em>(5), 1475–1492.
(<a href="https://doi.org/10.1007/s13042-021-01460-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a novel Takagi–Sugeno–Kang (TSK) fuzzy system termed as CLT–TSK in which the consequent of each fuzzy rule owns a common linear term is exploited to demonstrate its four distinctive merits. They are: (1) since much less parameters are involved, CLT–TSK has enhanced interpretability. (2) As an extensively used computational intelligence tool, a slightly changed function-link neural network (FLNN) is provably equivalent to CLT–TSK. As a result, FLNN is actually revisited with the first attempt from the philosophy of fuzzy models. (3) With a mild assumption that each component in Gaussian mixture model (GMM) equally contributes to the formulation of GMM in the sense of the effect of the intrinsic structure of training samples in each component on the corresponding label structure, CLT–TSK is theoretically proved to be equivalent to GMM, which actually helps us understand both CLT–TSK and FLNN from a new statistical perspective. (4) The output expression of CLT–TSK is exactly in accordance with the recently-drawn observation that a simple regression should be a basic yet very important component of final prediction models for various data modeling tasks. Owing to the equivalence among CLT–TSK, FLNN and GMM, their respective effective learning methods can be mutually employed from now on, and any new effort in training one model will actually provide a potential new learning method for another among these three models. In particular, with the help of our previous work about the least learning machine, we develop a fast-learning method for CLT–TSK in this study. Experimental results on different kinds of datasets demonstrate the promising classification and runtime performance of CLT–TSK.},
  archive      = {J_IJMLC},
  author       = {Zhang, Yuanpeng and Wang, Guanjin and Chung, Fu-lai and Wang, Shitong},
  doi          = {10.1007/s13042-021-01460-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1475-1492},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A fuzzy system with common linear-term consequents equivalent to FLNN and GMM},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel method for image segmentation: Two-stage decoding
network with boundary attention. <em>IJMLC</em>, <em>13</em>(5),
1461–1473. (<a
href="https://doi.org/10.1007/s13042-021-01459-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation often suffers from the challenges of class imbalance, blurred target boundaries, and small data. How to establish a framework to automatically segment medical images with these problems is an important task. Although there have been some studies on the issue, there is still a large room for improving the efficiency and quality of medical service. This paper utilizes the powerful ability of deep learning to extract features, and develops a two-stage decoding network with boundary attention (TSD-BA), which can locate the regions of interest in the target locating stage and obtain more spatial structure features in the detail refinement stage. Specifically, a deep fusion model (DFM) is used to aggregate high-level semantic features for accurately capturing the position of targets. Subsequently, a boundary attention module (BAM) is applied to further excavate the boundary features. Moreover, data augmentation and transfer learning are employed to avoid overfitting caused by small datasets. Finally, a pixel position aware (PPA) loss is introduced to focus on hard pixels and mitigate the class imbalance issues. Numerous experimental results indicate that the proposed TSD-BA achieves the best performance compared with state-of-the-art approaches.},
  archive      = {J_IJMLC},
  author       = {Cao, Feilong and Gao, Chengling and Ye, Hailiang},
  doi          = {10.1007/s13042-021-01459-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1461-1473},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel method for image segmentation: Two-stage decoding network with boundary attention},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DRCW-FRkNN-OVO: Distance-based related competence weighting
based on fixed radius k nearest neighbour for one-vs-one scheme.
<em>IJMLC</em>, <em>13</em>(5), 1441–1459. (<a
href="https://doi.org/10.1007/s13042-021-01458-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The one-versus-one (OVO) binarization decomposition scheme is considered as one of the most effective techniques to deal with multi-class classification problems. Its inherent mechanism is to use the “divide-and-conquer” strategy to decompose the multi-class classification problem into as many pairs of easier-to-solve binary sub-problems as possible. One common issue in the OVO scheme is that of non-competent classifiers. In this study, we proposed a novel OVO scheme strategy, named DRCW-FRkNN-OVO, to reduce the negative effect of non-competent classifiers. Specifically, we focused on the definition of region of competence, which plays a crucial role in managing the non-competent classifiers. To overcome the issue of skew and sparse distribution during the management of non-competent classifiers, we developed a relative competence weighting combination method via the fixed radius nearest neighbour search to find the local region within each class for the query sample. Our proposed DRCW-FRkNN-OVO is tested on 30 real-world multi-class datasets compared with several well-known related works. Experimental results supported by thorough statistical analysis confirmed the effectiveness and robustness of our proposed method.},
  archive      = {J_IJMLC},
  author       = {Zhang, Zhong-Liang and Luo, Xing-Gang and Zhou, Qing},
  doi          = {10.1007/s13042-021-01458-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1441-1459},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {DRCW-FRkNN-OVO: Distance-based related competence weighting based on fixed radius k nearest neighbour for one-vs-one scheme},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correntropy metric-based robust low-rank subspace clustering
for motion segmentation. <em>IJMLC</em>, <em>13</em>(5), 1425–1440. (<a
href="https://doi.org/10.1007/s13042-021-01456-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The subspace clustering methods for motion segmentation are widely used in the field of computer vision. However, the existing methods ignore the low-rank property of motion trajectory with nonlinear structure and are sensitive to non-Gaussian noise. To this end, we seek to improve the performance of motion segmentation by effectively modeling some important characteristics of the motion trajectories, such as nonlinear structure and contained non-Gaussian noise. Specifically, we propose to use kernel function to model motion trajectory, design a variant of the correntropy-induced metric to measure noise, and integrate the block diagonal regularizer into the kernel subspace clustering to strengthen the block diagonal structure of the learned affinity matrix. More importantly, we propose a unified rank-constrained block diagonal subspace clustering method for motion segmentation, which can handle not only rigid body motion segmentation, but also non-rigid motion segmentation. And we further extend this method to deal with various noises in motion data, such as missing trajectories, corrupted trajectory and outlying trajectory. An effective algorithm HQ&amp; AM, which is integrated by Half-quadratic theory and alternating minimization, is designed to optimize these models. Experimental results on several commonly used motion datasets indicate the effectualness and robustness of our methods.},
  archive      = {J_IJMLC},
  author       = {Guo, Li and Zhang, Xiaoqian and Liu, Zhigui and Wang, Qian and Zhou, Jianping},
  doi          = {10.1007/s13042-021-01456-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1425-1440},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Correntropy metric-based robust low-rank subspace clustering for motion segmentation},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A critical state identification approach to inverse
reinforcement learning for autonomous systems. <em>IJMLC</em>,
<em>13</em>(5), 1409–1423. (<a
href="https://doi.org/10.1007/s13042-021-01454-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse reinforcement learning features a reward function based on reward features and positive demonstrations. When complex learning tasks are performed, the entire state space is used to form the set of reward features, but this large set results in a long computational time. Retrieving important states from the full state space addresses this problem. This study formulated a method that extracts critical features by combining negative and positive demonstrations of searching for critical states from the entire state space to increase learning efficiency. In this method, two types of demonstrations are used: positive demonstrations, which are given by experts and agents imitate, and negative demonstrations, which demonstrate incorrect motions to be avoided by agents. All significant features are extracted by identifying the critical states over the entire state space. This is achieved by comparing the difference between the negative and positive demonstrations. When these critical states are identified, they form the set of reward features, and a reward function is derived that enables agents to learn a policy using reinforcement learning quickly. A speeding car simulation was used to verify the proposed method. The simulation results demonstrate that the proposed approach allows an agent to search for a positive strategy and that the agent then displays intelligent expert-like behavior.},
  archive      = {J_IJMLC},
  author       = {Hwang, Maxwell and Jiang, Wei-Cheng and Chen, Yu-Jen},
  doi          = {10.1007/s13042-021-01454-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1409-1423},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A critical state identification approach to inverse reinforcement learning for autonomous systems},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sparse robust multiview feature selection via
adaptive-weighting strategy. <em>IJMLC</em>, <em>13</em>(5), 1387–1408.
(<a href="https://doi.org/10.1007/s13042-021-01453-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rich and comprehensive information of multiview data, multi-view learning has been attracted widely attention. Efficiently exploiting multiview data to select discriminative features to improve classification performance is very important in multi-view learning. Most existing supervised methods learn an entire projection matrix by concatenating multiple views into a long vector, thus they often ignore the relationship between views. To solve this problem, in this paper, we propose a novel sparse robust multiview feature selection model, which simultaneously considers the robustness, individuality and commonality of views via adaptive-weighting strategy. The model adopts the soft capped-norm loss to calculate the residual in each view to effectively reduce the impact of noises and outliers. Moreover, the model employs the adaptive-weighting strategy to show the individuality and commonality of views without introducing extra parameters. In addition, it introduces structured sparsity regularization to select the discriminative features. An efficient iterative algorithm is proposed to individually learn each block of the projection matrix with low computational complexity, and the convergence of the proposed optimization algorithm is verified theoretically and experimentally. The comparative experiments are conducted on multiview datasets with several state-of-the-art algorithms, and the experimental results show that the proposed method gets better performance than the others.},
  archive      = {J_IJMLC},
  author       = {Wang, Zhi and Zhong, Jing and Chen, Yuqing and Zhong, Ping},
  doi          = {10.1007/s13042-021-01453-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1387-1408},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Sparse robust multiview feature selection via adaptive-weighting strategy},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hypergraph based semi-supervised support vector machine for
binary and multi-category classifications. <em>IJMLC</em>,
<em>13</em>(5), 1369–1386. (<a
href="https://doi.org/10.1007/s13042-021-01452-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, most graph regularization algorithms including LapSVM and LapPPSVM utilize unlabeled data for semi-supervised learning by introducing manifold regularization term. However, the graph construction in the manifold regularization term ignores the higher-order relation between data and cannot accurately express the multivariate and complex relation between data. In this paper, we propose a semi-supervised support vector machine algorithm based on hypergraph (HGSVM) for semi-supervised classification. Hypergraph is used to replace simple graph to fully explore the inherent manifold structure between labeled data and unlabeled data, and the hypergraph Laplacian matrix is calculated to form the manifold regularization term, which is embedded in the semi-supervised SVM model. Furthermore, a multi-category semi-supervised algorithm terms as KSRU-HGSVM is proposed, which introduces OVR strategy, oversampling and undersampling techniques into HGSVM. Experiments validate the effectiveness of the proposed semi-supervised classification algorithms in binary classification and multi-category classification.},
  archive      = {J_IJMLC},
  author       = {Sun, Yuting and Ding, Shifei and Zhang, ZiChen and Zhang, Chenglong},
  doi          = {10.1007/s13042-021-01452-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1369-1386},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hypergraph based semi-supervised support vector machine for binary and multi-category classifications},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-task learning for collaborative filtering.
<em>IJMLC</em>, <em>13</em>(5), 1355–1368. (<a
href="https://doi.org/10.1007/s13042-021-01451-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recommender system, the user’s historical behavior data is one of the most important sources of the system’s input data. According to the user’s feedback mechanism, behavior data can be divided into explicit feedback data and implicit feedback data. However, most recommendation algorithms focus separately on explicit feedback or implicit feedback. How to combine explicit and implicit feedback for recommendation tasks has always been a research problem. In recent years, deep learning technology has dominated the research on recommendation algorithms. But even the latest neural network-based recommendation algorithm cannot exceed classic methods (such as matrix factorization) in most cases. In this work, we propose a new collaborative filtering framework with neural network architecture. On the one hand, we use both explicit feedback data and implicit feedback data as input to learn multiple representations of users and items. On the other hand, we use multi-task learning to optimize our framework and use two relatively simple auxiliary tasks to enhance the generalization ability of our framework. Extensive experiments on five real-world datasets show significant improvements in our proposed framework over the state-of-the-art methods and vanilla matrix factorization.},
  archive      = {J_IJMLC},
  author       = {Long, Lianjie and Huang, Faliang and Yin, Yunfei and Xu, Youquan},
  doi          = {10.1007/s13042-021-01451-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1355-1368},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-task learning for collaborative filtering},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weak-label-based global and local multi-view multi-label
learning with three-way clustering. <em>IJMLC</em>, <em>13</em>(5),
1337–1354. (<a
href="https://doi.org/10.1007/s13042-021-01450-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a weak-label-based global and local multi-view multi-label learning with three-way clustering (WL-GLMVML-ATC) to solve multi-view multi-label data sets and exploit more authentic global and local label correlations of both the whole data set and each view simultaneously. Different from the traditional learning methods, WL-GLMVML-ATC pays more attention to the solutions of weak-label cases and uncertain relationships of clusters with the usage of Universum and active three-way clustering. According to Universum notion, even though the size of labeled instances is much more smaller than the unlabeled ones, the useful sample information can still be enhanced. Through the active three-way clustering strategy, the belongingness of instances to a cluster depend on the probabilities of uncertain instances belonging to core regions. This strategy brings a more authentic local label correlation since many traditional methods suppose that instances and the corresponding clusters always exhibit certain relationships such as belong-to definitely and not belong-to definitely. This hypothesis is not ubiquitous in real-world applications. According to the experiments, we can see WL-GLMVML-ATC (1) achieves a better performance, be superior to the classical multi-view learning methods and multi-label learning methods in statistical, advances the development of these learning methods in final; (2) won’t add too much running time; (3) has a good convergence and ability to process multi-view multi-label data sets.},
  archive      = {J_IJMLC},
  author       = {Zhu, Changming and Cao, Dujuan and Guo, Shuaiping and Zhou, Rigui and Wei, Lai and Dong, YiLing and Miao, Duoqian},
  doi          = {10.1007/s13042-021-01450-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1337-1354},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Weak-label-based global and local multi-view multi-label learning with three-way clustering},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An unsupervised multi-manifold discriminant isomap algorithm
based on the pairwise constraints. <em>IJMLC</em>, <em>13</em>(5),
1317–1336. (<a
href="https://doi.org/10.1007/s13042-021-01449-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an unsupervised multi-manifold Isomap algorithm, which is named UMD-Isomap, is proposed for the purpose of dimensionality reduction and clustering of multi-manifold data. First, the global pairwise constraints are constructed by training m mixtures of probabilistic principal component analyzers (MPPCA) and propagating their local tangent subspaces. At the same time, the sub-manifolds are also clustered, and their classes information are recorded in the pairwise constraints. If the number of sub-manifolds is known, a new pairwise constraints is computed by using a cluster ensemble algorithm, which creates a similarity matrix by accumulating c sets of pairwise constraints. Subsequently, a new objective function with pairwise constraints and two supervised solutions are proposed to achieve the dimensionality reduction of the multi-manifolds. The proposed UMD-Isomap algorithm achieved better performance in terms of dimensionality reduction and clustering accuracy than other commonly used methods and its effectiveness was verified.},
  archive      = {J_IJMLC},
  author       = {Gao, Xiaofang and Liang, Jiye and Wang, Wenjian and Bai, Xuefei and Jia, Lina},
  doi          = {10.1007/s13042-021-01449-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1317-1336},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An unsupervised multi-manifold discriminant isomap algorithm based on the pairwise constraints},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attention recurrent cross-graph neural network for selecting
premises. <em>IJMLC</em>, <em>13</em>(5), 1301–1315. (<a
href="https://doi.org/10.1007/s13042-021-01448-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Premise selection is a task that selects likely useful premises from a large-scale premise set, which is one of the challenges for automated theorem proving. Nowadays, using graph neural networks to encode logical formulae becomes more and more appealing, as graph representations demonstrate the ability to preserve the semantic and syntactic information of logical formulae. However, graph neural networks in the prior works iteratively update each node’s embedding via information aggregated solely from its neighbors and always ignore the types of nodes. Besides, evidence shows that sharing and exchanging some information between formula pairs can ensure neural-based models more robust in measuring graph relevance. Unluckily, previous graph neural networks generate final graph embeddings independently in the premise selection task. To overcome these shortages, we propose a novel graph neural network, called ARCG-NN, for embedding the first-order logical formulae. The embedding model firstly takes the node types into full consideration and utilizes an attention mechanism based on newly proposed node types to compute weights in the message aggregation. Except for the message from the local neighborhood, ARCG-NN also dynamically exchange the cross-graph information of particular nodes along with the propagation rounds. Besides, an extra gate function on node types is used to filter out irrelevant information in the graph aggregation phase. To train, validate, and test our approach, we build balanced and unbalanced datasets based on the MPTP2078 benchmark. The experimental results demonstrate that the proposed graph neural architecture achieves state-of-the-art classification accuracy on the first-order premise selection task and helps the automated theorem prover E prove more problems in the test dataset.},
  archive      = {J_IJMLC},
  author       = {Liu, Qinghua and Xu, Yang and He, Xingxing},
  doi          = {10.1007/s13042-021-01448-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1301-1315},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Attention recurrent cross-graph neural network for selecting premises},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Segmentation-based multi-scale attention model for KRAS
mutation prediction in rectal cancer. <em>IJMLC</em>, <em>13</em>(5),
1283–1299. (<a
href="https://doi.org/10.1007/s13042-021-01447-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kirsten Ras (KRAS) mutation identification has great clinical significance to formulate the rectal cancer treatment scheme. Recently, the development of deep learning does much help to improve the computer-aided diagnosis technology. However, deep learning models are usually designed for only one task, ignoring the potential benefits in jointly performing both tasks. In this paper, we proposed a joint network named segmentation-based multi-scale attention model (SMSAM) to predict the mutation status of KRAS gene in rectal cancer. More specifically, the network performs segmentation and prediction tasks at the same time. The two tasks mutually transfer knowledge between each other by sharing the same encoder. Meanwhile, two universal multi-scale attention blocks are introduced to ensure that the network more focuses on the region of interest. Besides, we also proposed an entropy branch to provide more discriminative features for the model. Finally, the method is evaluated on internal and external datasets. The results show that the comprehensive performance of SMSAM is better than the existing methods. The code and model have been publicly available.},
  archive      = {J_IJMLC},
  author       = {Song, Kai and Zhao, Zijuan and Wang, Jiawen and Qiang, Yan and Zhao, Juanjuan and Zia, Muhammad Bilal},
  doi          = {10.1007/s13042-021-01447-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1283-1299},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Segmentation-based multi-scale attention model for KRAS mutation prediction in rectal cancer},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ranking defects and solving countermeasures for pythagorean
fuzzy sets with hesitant degree. <em>IJMLC</em>, <em>13</em>(5),
1265–1281. (<a
href="https://doi.org/10.1007/s13042-021-01446-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pythagorean fuzzy set (PFS) is the most concerned and effective tool to describe fuzzy information in the research of machine learning and decision science, its unique representation ability and theoretical method will be gradually applied to the field of machine learning and even artificial intelligence, which lays a theoretical foundation for further solving complex scientific problems in machine learning. Actually, the PFS is not only a generalization of traditional intuitionistic fuzzy set (IFS), but also a more favorable tool of dealing with uncertain multi-attribute decision-making problem. In particular, it relaxes a certain constraint condition, which greatly increases the range of domain value. Firstly, through counter examples, some defects in the original sorting criteria of Pythagorean fuzzy numbers (PFNs) are pointed out. According to geometric interpretation and theoretical analysis, it is obtained that the reason for the defects is that the definitions of the score function and accuracy function are unreasonable, and the hesitation of PFNs is not considered. Secondly, after abandoning the original score function and accuracy function, concepts of distance index and area of lower triangle are proposed by comparing with the maximum PFN (1, 0). Especially, by considering degrees of hesitation (non-zero) for PFNs, several calculation formulas of curve triangle centroid coordinates corresponding to each PFN are given by using the centroid formula in physics, and then a new centroid distance index is obtained. Finally, two ranking methods for PFNs are established based on centroid distance, including synthetic index ranking and centroid distance ranking. Some examples are given to verify the effectiveness of the proposed methods. The example results show that both ranking methods can overcome the shortcomings in existing approaches, and the centroid distance ranking is better than the synthetic index ranking.},
  archive      = {J_IJMLC},
  author       = {Sun, Gang and Li, Xiaoping and Chen, Degang},
  doi          = {10.1007/s13042-021-01446-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1265-1281},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Ranking defects and solving countermeasures for pythagorean fuzzy sets with hesitant degree},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new two-stage hybrid feature selection algorithm and its
application in chinese medicine. <em>IJMLC</em>, <em>13</em>(5),
1243–1264. (<a
href="https://doi.org/10.1007/s13042-021-01445-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional small sample data are prone to the curse of dimensionality and overfitting and contain many irrelevant and redundant features. In order to solve these feature selection problems, a new Two-stage Hybrid Feature Selection Algorithm (Ts-HFSA) is proposed. The first stage uses the Filter method combined with the Wrapper method to adaptively remove irrelevant features. In the second stage, a De-redundancy Algorithm of Fusing Approximate Markov Blanket with L1 Regular Term (DA2MBL1) is used to solve the AMB’s problem of information loss when deleting redundant features and potential redundancy in the subset of features obtained by AMB. The experimental results on multiple UCI public data sets and datasets from the material foundation of Chinese medicine showed that the Ts-HFSA better deleted irrelevant features and redundant features, found smaller and higher quality feature subsets, and improved stability, indicating that it offers more advantages than AMB, FCBF, RF, GBDT, XGBoost, Lasso, and CI_AMB. Moreover, in the face of data of the material foundation of Chinese medicine, with higher feature dimensions and fewer sample sizes, Ts-HFSA performed better, which can also improve the precision of the model after greatly reducing the dimension. The results indicated that Ts-HFSA is an effective method for feature selection of high-dimensional small samples and an excellent research method for the material foundation of Chinese medicine.},
  archive      = {J_IJMLC},
  author       = {Li, Zhiqin and Du, Jianqiang and Nie, Bin and Xiong, Wangping and Xu, Guoliang and Luo, Jigen},
  doi          = {10.1007/s13042-021-01445-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1243-1264},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new two-stage hybrid feature selection algorithm and its application in chinese medicine},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards unified on-road object detection and depth
estimation from a single image. <em>IJMLC</em>, <em>13</em>(5),
1231–1241. (<a
href="https://doi.org/10.1007/s13042-021-01444-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On-road object detection based on convolutional neural network (CNN) is an important problem in the field of automatic driving. However, traditional 2D object detection aims to accomplish object classification and location in image space, lacking the ability to acquire the depth information. Besides, it is inefficient to cascade the object detection and monocular depth estimation network for realizing 2.5D object detection. To address this problem, we propose a unified multi-task learning mechanism of object detection and depth estimation. Firstly, we propose an innovative loss function, namely projective consistency loss, which uses the perspective projection principle to model the transformation relationship between the target size and the depth value. Therefore, the object detection task and the depth estimation task can be mutually constrained. Then, we propose a global multi-scale feature extracting scheme by combining the Global Context (GC) and Atrous Spatial Pyramid Pooling (ASPP) block in an appropriate way, which can promote effective feature learning and collaborative learning between object detection and depth estimation. Comprehensive experiments conducted on KITTI and Cityscapes dataset show that our approach achieves high mAP and low distance estimation error, outperforming other state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Lian, Guofei and Wang, Yan and Qin, Huabiao and Chen, Guancheng},
  doi          = {10.1007/s13042-021-01444-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1231-1241},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Towards unified on-road object detection and depth estimation from a single image},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dual discriminator adversarial distillation for data-free
model compression. <em>IJMLC</em>, <em>13</em>(5), 1213–1230. (<a
href="https://doi.org/10.1007/s13042-021-01443-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation has been widely used to produce portable and efficient neural networks which can be well applied on edge devices for computer vision tasks. However, almost all top-performing knowledge distillation methods need to access the original training data, which usually has a huge size and is often unavailable. To tackle this problem, we propose a novel data-free approach in this paper, named Dual Discriminator Adversarial Distillation (DDAD) to distill a neural network without the need of any training data or meta-data. To be specific, we use a generator to create samples through dual discriminator adversarial distillation, which mimics the original training data. The generator not only uses the pre-trained teacher’s intrinsic statistics in existing batch normalization layers but also obtains the maximum discrepancy from the student model. Then the generated samples are used to train the compact student network under the supervision of the teacher. The proposed method obtains an efficient student network which closely approximates its teacher network, without using the original training data. Extensive experiments are conducted to demonstrate the effectiveness of the proposed approach on CIFAR, Caltech101 and ImageNet datasets for classification tasks. Moreover, we extend our method to semantic segmentation tasks on several public datasets such as CamVid, NYUv2, Cityscapes and VOC 2012. To the best of our knowledge, this is the first work on generative model based data-free knowledge distillation on large-scale datasets such as ImageNet, Cityscapes and VOC 2012. Experiments show that our method outperforms all baselines for data-free knowledge distillation.},
  archive      = {J_IJMLC},
  author       = {Zhao, Haoran and Sun, Xin and Dong, Junyu and Manic, Milos and Zhou, Huiyu and Yu, Hui},
  doi          = {10.1007/s13042-021-01443-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1213-1230},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dual discriminator adversarial distillation for data-free model compression},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep semantic-aware network for zero-shot visual urban
perception. <em>IJMLC</em>, <em>13</em>(5), 1197–1211. (<a
href="https://doi.org/10.1007/s13042-021-01401-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual urban perception has recently attracted a lot of research attention owing to its importance in many fields. Traditional methods for visual urban perception mostly need to collect adequate training instances for newly-added perception attributes. In this paper, we consider a novel formulation, zero-shot learning, to free this cumbersome curation. Based on the idea of different images containing similar objects are more likely to possess the same perceptual attribute, we learn the semantic correlation space formed by objects semantic information and perceptual attributes. For newly-added attributes, we attempt to synthesize their prototypes by transferring similar object vector representations between the unseen attributes and the training (seen) perceptual attributes. For this purpose, we leverage a deep semantic-aware network for zero-shot visual urban perception model. It is a new two step zero-shot learning architecture, which includes supervised visual urban perception step for training attributes and zero-shot prediction step for unseen attributes. In the first step, we highlight the important role of semantic information and introduce it into supervised deep visual urban perception framework for training attributes. In the second step, we use the visualization techniques to obtain the correlations between semantic information and visual perception attributes from the well trained supervised model, and learn the prototype of unseen attributes and testing images to predict perception score on unseen attributes. The experimental results on a large-scale benchmark dataset validate the effectiveness of our method.},
  archive      = {J_IJMLC},
  author       = {Zhang, Chunyun and Wu, Tianze and Zhang, Yunfeng and Zhao, Baolin and Wang, Tingwen and Cui, Chaoran and Yin, Yilong},
  doi          = {10.1007/s13042-021-01401-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1197-1211},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep semantic-aware network for zero-shot visual urban perception},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Clustering analysis through artificial algae algorithm.
<em>IJMLC</em>, <em>13</em>(4), 1179–1196. (<a
href="https://doi.org/10.1007/s13042-022-01518-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering analysis is widely used in many areas such as document grouping, image recognition, web search, business intelligence, bio information, and medicine. Many algorithms with different clustering approaches have been proposed in the literature. As they are easy and straightforward, partitioning methods such as K-means and K-medoids are the most commonly used algorithms. These are greedy methods that gradually improve clustering quality, highly dependent on initial parameters, and stuck a local optima. For this reason, in recent years, heuristic optimization methods have also been used in clustering. These heuristic methods can provide successful results because they have some mechanism to escape local optimums. In this study, for the first time, Artificial Algae Algorithm was used for clustering and compared with ten well-known bio-inspired metaheuristic clustering approaches. The proposed AAA clustering efficiency is evaluated using statistical analysis, convergence rate analysis, Wilcoxon’s test, and different cluster evaluating measures ranking on 25 well-known public datasets with different difficulty levels (features and instances). The results demonstrate that the AAA clustering method provides more accurate solutions with a high convergence rate than other existing heuristic clustering techniques.},
  archive      = {J_IJMLC},
  author       = {Turkoglu, Bahaeddin and Uymaz, Sait Ali and Kaya, Ersin},
  doi          = {10.1007/s13042-022-01518-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1179-1196},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Clustering analysis through artificial algae algorithm},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On attribute importance measure and its application to
supplier selection. <em>IJMLC</em>, <em>13</em>(4), 1167–1178. (<a
href="https://doi.org/10.1007/s13042-022-01510-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set theory is a powerful mathematical technique of decision making, which can be exploited to feature selection and rule induction from uncertain and ambiguous data. Generally, the attribute significance degree is one of the fundamental metrics used to measure the contained information of each attribute. However, in the most existing rough based methods, some attributes share the identical or zero significance degrees, that cannot reflect the situations in the realistic scenarios. We are then motivated to improve the attribute significance degree of rough set, based on the new attribute significance degree of rough set, a new method of supplier evaluation and selection is presented, it solves the problems existing in current research and verifies the scientific nature and effectiveness of the method with a case.},
  archive      = {J_IJMLC},
  author       = {Sun, Xiaowen and Sun, Limin},
  doi          = {10.1007/s13042-022-01510-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1167-1178},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {On attribute importance measure and its application to supplier selection},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid two-stream dynamic CNN for view adaptive human action
recognition using ensemble learning. <em>IJMLC</em>, <em>13</em>(4),
1157–1166. (<a
href="https://doi.org/10.1007/s13042-021-01441-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human actions are sequential, and structured patterns of the body parts and their movements. In this paper, we present a hybrid two-stream convolutional neural network (H2SCNN) for the recognition of actions from sequences by exploring the statistical information like skeletons. This aims to exploit the skeletons completely and identify the actions properly by merging the different motion related features. These features include motion and joint features. The framework calculates the distance between consecutive sequences to form the temporal information required for the recognition process. The proposed H2SCNN is based on two stages. The neighbourhood feature model will be used to process both inputs individually in the first step. In the second stage, it performs ensemble learning and takes advantage of the diversity of multiple features by fusing them together. The multi-task ensemble learning model helps the system to improve the prediction ability of H2SCNN. Experiments on the benchmark dataset have shown the superiority of the proposed model with other recent approaches.},
  archive      = {J_IJMLC},
  author       = {Javed, Muhammad Hafeez and Yu, Zeng and Li, Tianrui and Rajeh, Taha M. and Rafique, Fahad and Waqar, Syed},
  doi          = {10.1007/s13042-021-01441-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1157-1166},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hybrid two-stream dynamic CNN for view adaptive human action recognition using ensemble learning},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Empower parameterized generative adversarial networks using
a novel particle swarm optimizer: Algorithms and applications.
<em>IJMLC</em>, <em>13</em>(4), 1145–1155. (<a
href="https://doi.org/10.1007/s13042-021-01440-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel parameterized generative adversarial network (GAN) is proposed where the parameters are introduced to enhance the performance of image segmentation. The developed algorithm is applied to the image-based crack detection problem on the thermal data obtained through the non-destructive testing process. A new regularization term, which contains three tunable hyperparameters, embedded into the objective function of the GAN in order to improve the contrast ratio of certain areas of the image so as to benefit the crack detection process. To automate the selection of the optimal hyperparameters of the GAN, a new particle swarm optimization (PSO) algorithm is put forward where a neighborhood-based velocity updating strategy is developed for the purpose of thoroughly exploring the problem space. The proposed PSO-based GAN algorithm is shown to 1) work well in detecting cracks on the thermal data generated by the eddy current pulsed thermography technique; and 2) outperforms other conventional GAN algorithms.},
  archive      = {J_IJMLC},
  author       = {Tian, Lulu and Wang, Zidong and Liu, Weibo and Cheng, Yuhua and Alsaadi, Fuad E. and Liu, Xiaohui},
  doi          = {10.1007/s13042-021-01440-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1145-1155},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Empower parameterized generative adversarial networks using a novel particle swarm optimizer: Algorithms and applications},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-supervised label enhancement via structured semantic
extraction. <em>IJMLC</em>, <em>13</em>(4), 1131–1144. (<a
href="https://doi.org/10.1007/s13042-021-01439-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label enhancement (LE) is a process of recovering the label distribution from logical labels in the datasets, the goal of which is to better express the label ambiguity through the form of label distribution. Existing LE work mainly focus on exploring the data distribution in the feature space based on complete features and complete logical labels. However, it is not always easy to obtain multi-label datasets with logical labels for all samples in real world, most of datasets have only a few samples with annotated labels. To this end, we propose a novel semi-supervised label enhancement method via structured semantic extraction (SLE-SSE), which can recover the complete label distribution from only a few logical labels. Firstly, we extract self-semantic of samples by expressing inherent ambiguity of each sample in the input space appropriately, and fill in the missing labels based on this kind of information. Secondly, we take advantage of low rank representation to extract the inter-semantics of between samples and between labels, respectively. Finally, we apply a simple but effective linear model to recover the complete label distribution by utilizing the structured semantic information including intra-sample, inter-sample and inter-label based information. Extensive comparative experiments validate the effectiveness of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Wen, Tao and Li, Weiwei and Chen, Lei and Jia, Xiuyi},
  doi          = {10.1007/s13042-021-01439-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1131-1144},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Semi-supervised label enhancement via structured semantic extraction},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evidence theory based optimal scale selection for
multi-scale ordered decision systems. <em>IJMLC</em>, <em>13</em>(4),
1115–1129. (<a
href="https://doi.org/10.1007/s13042-021-01438-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real data sets, objects are usually measured by multiple scales under the same attribute. Many information systems are given dominance relations on account of various factors which make classical equivalence relations change accordingly. This paper investigates the optimal scale selection for multi-scale ordered decision systems based on evidence theory. Five concepts of optimal scales related to rough set theory and the Dempster–Shafer theory of evidence in multi-scale ordered information/decision systems are first defined. Relationships are then clarified among $$\ge$$ -optimal scale, $$\ge$$ -lower approximation and $$\ge$$ -upper approximation optimal scales as well as $$\ge$$ -belief and $$\ge$$ -plausibility optimal scales in multi-scale ordered information systems and consistent multi-scale ordered decision systems respectively. Finally, in inconsistent multi-scale ordered decision systems, by introducing a notion of $$\ge$$ -generalized decision optimal scale, relationships among different types of optimal scales are also examined.},
  archive      = {J_IJMLC},
  author       = {Zheng, Jia-Wen and Wu, Wei-Zhi and Bao, Han and Tan, An-Hui},
  doi          = {10.1007/s13042-021-01438-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1115-1129},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Evidence theory based optimal scale selection for multi-scale ordered decision systems},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved local-feature-based few-shot learning with sinkhorn
metrics. <em>IJMLC</em>, <em>13</em>(4), 1099–1114. (<a
href="https://doi.org/10.1007/s13042-021-01437-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local-feature-based Few-Shot Learning (FSL) has attracked a lot of attention and achieved great progress recently. Given an image, the model extracts a group of local features through the Fully Convolutional Network (FCN), each of which contains information from the corresponding receptive field of the image. The challenging problem is that how to exploit the local-feature-level similarities to generate the image-level similarity. Towards this, many existing works have proposed different heuristic rules or settings. In this paper, we first follow existing works and systematically propose several modified methods for local feature matching, induced by a novel and improved heterogeneous matching mechanism. However, these heuristic methods are not optimal to highlight the most informative local feature pairs to represent the image-level similarity, and also can not generalize well to different tasks. Therefore, we propose a new idea called Sinkhorn Metrics (SM). We consider the local-feature-based FSL as the Regularized Optimal Transport (ROT) problem. The cost matrix is formed by the similarities of local feature pairs. The marginals indicating the importance of each local feature are obtained by a new attentive cross-comparison module. The optimal transportation plan is used as weights to aggregate all the local-feature-level similarities to obtain the image-level similarity. We exploit the Sinkhorn algorithm to solve the ROT problem, which is efficient for the end-to-end training. We conduct a hybrid experiment on SM with some heuristic baselines to demonstrate its compatibility. Extensive ablation studies are performed to fully evaluate important hyper-parameters and settings. Our method achieves a series of state-of-the-arts on multiple datasets in both the single-domain and cross-domain FSL scenarios (The code for evaluation, trained model, and datasets in this study are available at https://github.com/Wangduo428/few-shot-learning-SM ).},
  archive      = {J_IJMLC},
  author       = {Wang, Duo and Ma, Qianxia and Zheng, Qingyuan and Cheng, Yu and Zhang, Tao},
  doi          = {10.1007/s13042-021-01437-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1099-1114},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improved local-feature-based few-shot learning with sinkhorn metrics},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Selection of data products: A hybrid AFSA-MABAC approach.
<em>IJMLC</em>, <em>13</em>(4), 1079–1097. (<a
href="https://doi.org/10.1007/s13042-021-01436-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing demands of data products, the selection of satellite image data products becomes a challenging decision issue for customers. The objective of this study is to propose a practically sound decision-making approach for solving the satellite image data products selection problems. First, the influencing factors of selecting satellite image data products are identified. Then, hybrid evaluation information is recommended to represent these criteria. That is, numerical and interval-valued quantification is used for quantitative criteria, and picture fuzzy numbers (PFNs) are considered to express qualitative criteria. To reflect decision makers’ preferences, a non-linear optimization is implemented to treat criteria weights with constraints. Thereafter, some penalty functions are defined and the artificial fish swarm algorithm (AFSA) is improved to calculate weight values. Furthermore, six main parameters of AFSA are analyzed. Compared with other commonly used algorithms (such as genetic algorithm (GA) and particle swarm optimization (PSO)), the largest advantage of AFSA is its high robustness of parameters and initial values. Finally, the traditional multi-attributive border approximation area comparison (MABAC) is modified with likelihood measures to obtain the best data product in hybrid evaluation environments. Furthermore, the feasibility and effectiveness of the proposed approach is validated by comparing with existing methods in some representative literature. The results demonstrate that the proposed method is feasible and can provide useful guidelines for the selection and pricing of satellite image data products.},
  archive      = {J_IJMLC},
  author       = {Luo, Suizhi and Pedrycz, Witold and Xing, Lining},
  doi          = {10.1007/s13042-021-01436-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1079-1097},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Selection of data products: A hybrid AFSA-MABAC approach},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Really natural adversarial examples. <em>IJMLC</em>,
<em>13</em>(4), 1065–1077. (<a
href="https://doi.org/10.1007/s13042-021-01435-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The phenomenon of Adversarial Examples has become one of the most intriguing topics associated to deep learning. The so-called adversarial attacks have the ability to fool deep neural networks with inappreciable perturbations. While the effect is striking, it has been suggested that such carefully selected injected noise does not necessarily appear in real-world scenarios. In contrast to this, some authors have looked for ways to generate adversarial noise in physical scenarios (traffic signs, shirts, etc.), thus showing that attackers can indeed fool the networks. In this paper we go beyond that and show that adversarial examples also appear in the real-world without any attacker or maliciously selected noise involved. We show this by using images from tasks related to microscopy and also general object recognition with the well-known ImageNet dataset. A comparison between these natural and the artificially generated adversarial examples is performed using distance metrics and image quality metrics. We also show that the natural adversarial examples are in fact at a higher distance from the originals that in the case of artificially generated adversarial examples.},
  archive      = {J_IJMLC},
  author       = {Pedraza, Anibal and Deniz, Oscar and Bueno, Gloria},
  doi          = {10.1007/s13042-021-01435-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1065-1077},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Really natural adversarial examples},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel approach to concept-cognitive learning in
interval-valued formal contexts: A granular computing viewpoint.
<em>IJMLC</em>, <em>13</em>(4), 1049–1064. (<a
href="https://doi.org/10.1007/s13042-021-01434-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept-cognitive learning (CCL) is to make machines like human beings have the ability of summarizing and reasoning. Automatically learn and find concepts from given information clues is a research focus of CCL. The existing researches mainly focuses on the concept learning methods in classical and fuzzy formal contexts, but there are few researches on the CCL of interval-valued contexts. In view of the universality of interval values in practical applications, we study the mechanism of CCL in interval-valued formal contexts. Firstly, we propose interval-valued formal contexts and a pair of dual cognitive operators as the fundamental foundation of concept learning. Then we mine the relationship between interval-valued information granules and concepts from cognitive learning and granular computing perspective. Then we systematically study the mechanism of interval-valued CCL from the establishment of interval-valued information granules (IvIGs) and its mathematical properties, and the transformation between different information granules (IGs) and clue oriented concept learning. Moreover, three algorithms are established to automatically learn concepts from different clue information. Finally, we download eight public data sets to verify the effectiveness and feasibility of the proposed algorithms from the perspective of the size of extension of concepts, running time of concept learning algorithms and the number of concepts learned by the concept learning algorithms. The experimental comparison indicates that the proposed algorithms are effective and feasible for interval-valued CCL.},
  archive      = {J_IJMLC},
  author       = {Hu, Meng and Tsang, Eric C. C. and Guo, Yanting and Zhang, Qingshuo and Chen, Degang and Xu, Weihua},
  doi          = {10.1007/s13042-021-01434-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1049-1064},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel approach to concept-cognitive learning in interval-valued formal contexts: A granular computing viewpoint},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Double-quantitative multigranulation rough fuzzy set based
on logical operations in multi-source decision systems. <em>IJMLC</em>,
<em>13</em>(4), 1021–1048. (<a
href="https://doi.org/10.1007/s13042-021-01433-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy phenomena exist widely in real life, and with the rapid development of big data technology we may gather information from multiple sources. So it is extremely meaningful to study fuzzy concepts in the context of multiple information sources. In this study, six novel kinds of double-quantitative multigranulation rough fuzzy set models are proposed. Both absolute and relative information are taken into account by utilizing the logical conjunction and disjunction operators to define the lower and upper approximations. Four decision regions can be computed based on the results of approximations, and the corresponding four decision rules are established. Some basic propositions of these models are discussed. The relationships among the six double-quantitative multigranulation rough fuzzy set models are analysed. The corresponding algorithms of obtaining four decision regions are given and the time complexity of them are analysed. Later a weather example is employed to illustrate that our models can divide data sets to the positive region, the negative region, the lower boundary region, and the upper boundary region, where the samples in the positive region completely support the concept set, the samples in the negative region completely oppose the concept set, and the samples in the lower and upper boundary may support or oppose the concept set. Finally, an experiment is conducted to demonstrate that our models perform better than the mean fusion method in terms of decision-making.},
  archive      = {J_IJMLC},
  author       = {Chen, Xiuwei and Xu, Weihua},
  doi          = {10.1007/s13042-021-01433-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1021-1048},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Double-quantitative multigranulation rough fuzzy set based on logical operations in multi-source decision systems},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-label space reshape for semantic-rich label-specific
features learning. <em>IJMLC</em>, <em>13</em>(4), 1005–1019. (<a
href="https://doi.org/10.1007/s13042-021-01432-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing label-specific features learning techniques mainly use embedding-based researching methods. However, there exist many problems such as inadequate consideration of label semantics, the sparseness of selected features and so on. Herein, the LSR-LSF (multi-label space reshape for semantic-rich label-specific features learning) algorithm is proposed in this paper to solve these problems. Firstly, the sparse logical matrix is constructed into a numerical label matrix through the label propagation dependency matrix. Secondly, constraint propagation is added to avoid the differences that may exist in the label matrix before or after the reshaping process. The alternate iteration method is used to obtain the numerical label vector. At the same time, the reshaped label correlation matrix is constructed by the cosine similarity to constrain the solution space. Then, measuring whether the learning ability of label-specific features has been improved. Finally, extensive experiments on benchmark datasets show the superiority of LSR-LSF over other state-of-the-art label-specific features learning methods.},
  archive      = {J_IJMLC},
  author       = {Cheng, Yusheng and Zhang, Chao and Pang, Shufang},
  doi          = {10.1007/s13042-021-01432-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1005-1019},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-label space reshape for semantic-rich label-specific features learning},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A tiny deep capsule network. <em>IJMLC</em>, <em>13</em>(4),
989–1004. (<a href="https://doi.org/10.1007/s13042-021-01431-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capsule network (CapsNet) is a novel network model that can learn spatial information in images. However, the performance of CapsNet on complex datasets (such as CIFAR10) is limited and it requires a large number of parameters. These disadvantages make CapsNet less useful, especially in some resource-constrained devices. To solve this problem, we propose a novel tiny deep capsule architecture (CapsInfor), which consists of many fast tensor capsule layers (FastCaps) with a novel routing process. CapsInfor requires only a few parameters to achieve satisfactory performance. For example, on CIFAR10, the accuracy of CapsInfor is 9.32\% higher than that of CapsNet, but the parameters are reduced by 97.53\%. CapsInfor is composed of multiple pipelines each of which processes a kind of image information. To achieve information interaction between pipelines, a novel cross node is proposed to implement pipeline-level capsule routing. A new decision maker is used to analyze the predicted values of pipelines and gives the final classification result. Using these proposed methods, CapsInfor achieves competitive results on CIFAR10, CIFAR100, FMNIST, and SVHN. Besides, it is proved that CapsInfor has satisfactory affine robustness on affNIST. To alleviate the problem that the parameter explosion with increasing the number of classes, a novel two-level classification method is proposed. This method can effectively reduce the parameters of the model on the 10 categories and 100 categories tasks. The experimental results confirm that CapsInfor is a tiny deep capsule model with satisfactory classification accuracy and affine robustness.},
  archive      = {J_IJMLC},
  author       = {Sun, Kun and Xu, Haixia and Yuan, Liming and Wen, Xianbin},
  doi          = {10.1007/s13042-021-01431-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {989-1004},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A tiny deep capsule network},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust semi-supervised spatial picture fuzzy clustering with
local membership and KL-divergence for image segmentation.
<em>IJMLC</em>, <em>13</em>(4), 963–987. (<a
href="https://doi.org/10.1007/s13042-021-01429-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at existing symmetric regularized picture fuzzy clustering with weak robustness, and it is difficult to meet the need for image segmentation in the presence of high noise. Hence, a robust dynamic semi-supervised symmetric regularized picture fuzzy clustering with KL-divergence and spatial information constraints is presented in this paper. Firstly, a weighted squared Euclidean distance from current pixel value, its neighborhood mean and median to clustering center is firstly proposed, and it is embedded into the objective function of symmetric regularized picture fuzzy clustering to obtain spatial picture fuzzy clustering. Secondly, the idea of maximum entropy fuzzy clustering is introduced into picture fuzzy clustering, and an entropy-based picture fuzzy clustering with clear physical meaning is constructed to avoid the problem of selecting weighted factors. Subsequently, the prior information of the current pixel is obtained by means of weighted local membership of neighborhood pixels, and it is embedded into the objective function of maximum entropy picture fuzzy clustering with multiple complementary spatial information constraints through KL-divergence, a robust dynamic semi-supervised picture fuzzy clustering optimization model and its iterative algorithm are given. In the end, this proposed algorithm is strictly proved to be convergent by Zangwill theorem. The experiments on various images and standard datasets illustrate how our proposed algorithm works. This proposed algorithm has excellent segmentation performance and anti-noise robustness, and outperforms eight state-of-the-art fuzzy or picture fuzzy clustering-related algorithms in the presence of high noise.},
  archive      = {J_IJMLC},
  author       = {Wu, Chengmao and Zhang, Jiajia},
  doi          = {10.1007/s13042-021-01429-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {963-987},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust semi-supervised spatial picture fuzzy clustering with local membership and KL-divergence for image segmentation},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Iterative joint classifier and domain adaptation for visual
transfer learning. <em>IJMLC</em>, <em>13</em>(4), 947–961. (<a
href="https://doi.org/10.1007/s13042-021-01428-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current available supervised classifiers cannot generalize across various domains due to distribution mismatch among them. Domain adaptation and transfer learning algorithms are proposed to tackle domain shift problem that originates from different data collection conditions. In this paper, we propose a transfer learning framework called iterative joint classifier and domain adaptation for visual transfer learning (ICDAV), which utilizes the balanced maximum mean discrepancy to better transfer knowledge across domains. Also, for learning a robust classifier against domain shift, a set of graph manifold regularizer and modified joint probability maximum mean discrepancy are simultaneously exploited to capture the domain structures and adapt the distribution of projected samples during the model learning process. Variety of experiments on several public datasets indicates that our approach achieves remarkable performance on visual domain adaptation and transfer learning tasks.},
  archive      = {J_IJMLC},
  author       = {Noori Saray, Shiva and Tahmoresnezhad, Jafar},
  doi          = {10.1007/s13042-021-01428-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {947-961},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Iterative joint classifier and domain adaptation for visual transfer learning},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conflict analysis based on three-way decision for
trapezoidal fuzzy information systems. <em>IJMLC</em>, <em>13</em>(4),
929–945. (<a href="https://doi.org/10.1007/s13042-021-01427-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision is a decision-making model in line with people’s cognition and aims to think and deal with problems at three levels or three aspects. One of the main purposes of conflict analysis is to partition the set of agents into three coalitions called positive alliance, central alliance and negative alliance in order to determine the relationship between two agents. Recently, researchers combine these two closely related directions to form a new research topic: three-way conflict analysis. This paper consider the case that the attitude of an agent on an issue is a trapezoidal fuzzy number. Firstly, we provide a trapezoidal fuzzy information system for conflict analysis and then we transform attitudes of agents from trapezoidal fuzzy numbers to real numbers through the expectation of trapezoidal fuzzy numbers. Secondly, conflict analysis for a single issue is investigated and three alliances based on a pair of thresholds are obtained. As for multiple issues, it is necessary to integrate multiple attitudes for a collection of issues to one. Considering different importance of issues, we develop a new method to integrate attitudes based on the variance of trapezoidal fuzzy numbers, and then we come up with a conflict analysis model for multiple issues. Thirdly, a method to calculate thresholds is proposed based on decision-theoretic rough sets so as to acquire three alliances based on a single issue or multiple issues more reasonably. Finally, we devote to ranking all the issues according to the conflict degree among agents and our method may be instructive to promote the resolution of conflict situations.},
  archive      = {J_IJMLC},
  author       = {Li, Xiaonan and Yang, Yanpo and Yi, Huangjian and Yu, Qianqian},
  doi          = {10.1007/s13042-021-01427-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {929-945},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Conflict analysis based on three-way decision for trapezoidal fuzzy information systems},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel intuitionistic fuzzy three-way decision model based
on an intuitionistic fuzzy incomplete information system.
<em>IJMLC</em>, <em>13</em>(4), 907–927. (<a
href="https://doi.org/10.1007/s13042-021-01426-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a new method of granular computing, the three-way decision (3WD) approach has unique advantages in handling uncertain and imprecise problems. Based on decision-theoretic rough sets (DTRSs) and Bayesian minimum risk theory, conditional probability and loss function are the key research issues in 3WD. Many approaches for handling deterministic and complete information have been developed. However, few studies have focused on the construction of an intuitionistic fuzzy three-way decision (IF3WD) model for an intuitionistic fuzzy incomplete information system (IFIIS). In this paper, an IF3WD model based on an IFIIS is proposed to improve the ability to process complex fuzzy incomplete information systems, which extends the application range of the traditional 3WD. Concretely, we first propose a calculation method to measure the degree of information retention of missing data and describe it in two dimensions: coarse-grained and fine-grained. Next, an intuitionistic fuzzy number approximation (IFNA) strategy for missing data is presented. Then, a loss function with three states is given. Furthermore, combined with the Choquet integral, the interaction and influence between acceptance, rejection, and delay decision costs are investigated, and the corresponding IF3WD rules are induced. Finally, the rationality and effectiveness of our proposed model are verified through case analysis and are compared with those of existing methods.},
  archive      = {J_IJMLC},
  author       = {Xin, Xian-Wei and Sun, Jing-Bo and Xue, Zhan-Ao and Song, Ji-Hua and Peng, Wei-Ming},
  doi          = {10.1007/s13042-021-01426-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {907-927},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel intuitionistic fuzzy three-way decision model based on an intuitionistic fuzzy incomplete information system},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Group decision-making analysis based on linguistic q-rung
orthopair fuzzy generalized point weighted aggregation operators.
<em>IJMLC</em>, <em>13</em>(4), 883–906. (<a
href="https://doi.org/10.1007/s13042-021-01425-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The q-rung orthopair fuzzy sets (q-ROFSs), originally proposed by Yager, can express uncertain data to give decision-makers more space. The q-ROFS is a useful tool for describing imprecision, ambiguity, and inaccuracy, and the point operator is a useful aggregation operator which can manage the uncertainty and thus obtain intensive information within the decision-making process. In the latest realization, the linguistic q-rung orthopair fuzzy number (Lq-ROFN) is suggested where the linguistic variables are expressed as membership and non-membership of the Lq-ROFN. In this article, we propose the q-rung orthopair fuzzy linguistic family of point aggregation operators for linguistic q-rung orthopair fuzzy sets (Lq-ROFSs). Firstly, with the arithmetic and geometric operators, we introduce a new class of point-weighted aggregation operators to aggregate linguistic q-rung orthopair fuzzy information such as linguistic q-rung orthopair fuzzy point weighted averaging (Lq-ROFPWA) operators, linguistic q-rung orthopair fuzzy point weighted geometric (Lq-ROFPWG) operators, linguistic q-rung orthopair fuzzy generalized point weighted averaging (Lq-ROFGPWA) operators and linguistic q-rung orthopair fuzzy generalized point weighted geometric (Lq-ROFGPWG) operators. Then, we discuss some special cases and study the properties of these proposed operators. Based on Lq-ROFPWA and Lq-ROFPWG operators, a novel multi attribute group decision-making (MAGDM) methodology is designed to process the linguistic q-rung orthopair fuzzy information. Finally, we provide an example to demonstrate the applicability of the MAGDM. Consequently, the outstanding superiority of the developed methodology is assisted in a variety of ways by parameter exploration and thorough comparative analysis.},
  archive      = {J_IJMLC},
  author       = {Liu, Peide and Naz, Sumera and Akram, Muhammad and Muzammal, Mamoona},
  doi          = {10.1007/s13042-021-01425-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {883-906},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Group decision-making analysis based on linguistic q-rung orthopair fuzzy generalized point weighted aggregation operators},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mixed attention hourglass network for robust face alignment.
<em>IJMLC</em>, <em>13</em>(4), 869–881. (<a
href="https://doi.org/10.1007/s13042-021-01424-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unconstrained face alignment is still a challenging problem due to the large poses, partial occlusions and complicated illuminations. To address these issues, in this paper, we propose a mixed attention hourglass network (MAttHG) to learn more discriminative representations by modeling the correlated relationships between features. Specifically, by integrating the attention module from features of different levels in the stacked hourglass networks, MAttHG can capture rich contextual correlations, which can be further used to combine local features to better model the spatial position relationship of facial landmarks. Furthermore, by combining the hourglass network and the attention module, MAttHG can effectively model the global attention and local attention to enhance the facial shape constraints for robust face alignment. Moreover, a head pose prediction module is designed to adaptively adjust the weight of each sample in the training set and redefine the loss function for addressing the problem of data imbalance. Experimental results on challenging benchmark datasets demonstrate the superiority of our MAttHG over state-of-the-art face alignment methods.},
  archive      = {J_IJMLC},
  author       = {Yang, Zou and Shao, Xiongkai and Wan, Jun and Gao, Rong and Lai, Zhihui},
  doi          = {10.1007/s13042-021-01424-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {869-881},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Mixed attention hourglass network for robust face alignment},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards an improved label noise proportion estimation in
small data: A bayesian approach. <em>IJMLC</em>, <em>13</em>(4),
851–867. (<a href="https://doi.org/10.1007/s13042-021-01423-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today’s classification task is getting more and more complex. This inevitably renders unanticipated compromises on the quality of data labels. In this paper, we consider learning label noise robust classifiers with focus on the tasks with limited training examples relative to the number of data classes and data dimensionality. In such cases, the existing label noise models tend to inaccurately estimate the noise proportions leading to suboptimal performance. To alleviate the problem, we formulated a regularised label noise model capable of expressing preference on the noise parameters. In addition, we treated the regularisation from a Bayesian perspective so that the regularisation parameters can be inferred from the data through the noise model, thereby facilitating model selection in the presence of label noise. This results in a more data and computationally efficient Bayesian label noise model which could be incorporated into any probabilistic classifier, including those that are known to be data intensive such as deep neural networks. We demonstrated the generality of the proposed method through its integrations with logistic regression, multinomial logistic regression and convolutional neural networks. Extensive empirical evaluations demonstrate that the proposed regularised label noise model can significantly improve, in terms of both the quality of noise parameters estimation and the classification accuracy, upon the existing ones when data is scarce, and is no worse than the existing approaches in the abundance of training data.},
  archive      = {J_IJMLC},
  author       = {Bootkrajang, Jakramate and Chaijaruwanich, Jeerayut},
  doi          = {10.1007/s13042-021-01423-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {851-867},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Towards an improved label noise proportion estimation in small data: A bayesian approach},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Emotion-enhanced classification based on fuzzy reasoning.
<em>IJMLC</em>, <em>13</em>(3), 839–850. (<a
href="https://doi.org/10.1007/s13042-021-01356-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Texts and emoticons expressing sentiment can be used to analyse emotion. In an Internet environment, emoticons are frequently used, which have explicated information for emotion analysis. Considering the characteristics of short texts including sparseness, non-standardization and ambiguities in a subject, two models based on word embedding, emotion-dictionary and fuzzy reasoning are proposed: the low-dimensional hybrid feature model and the emotion-enhanced inference model. The low-dimensional hybrid feature model includes the number of emoticons, the emotion-word number and the negative-word number in a text. The emotion-enhanced reference model includes some fuzzy reasoning rules and a variety of the combinations of emotion-words, negative-words, and question marks and exclamation points. The validity of the model has been verified based on Douyin reviews and the data of the 2nd CCF Conference on Natural Language Processing and Chinese Computing (NLPCC 2013), where the average accuracy rate on Douyin reviews achieved is $$89.16\%$$ . Through the comparative experiment, the results show that the models are more effective in ultra-short emotion text classification than the comparison models.},
  archive      = {J_IJMLC},
  author       = {Yan, Ruiteng and Yu, Yan and Qiu, Dong},
  doi          = {10.1007/s13042-021-01356-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {839-850},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Emotion-enhanced classification based on fuzzy reasoning},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing extended belief rule-based systems for
classification problems using decomposition strategy and overlap
function. <em>IJMLC</em>, <em>13</em>(3), 811–837. (<a
href="https://doi.org/10.1007/s13042-021-01355-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-class and multi-attribute are two important features of classification problems and have different effects on the requirements and performance of the classifier. Decomposition strategy and overlap function are two effective ways to enhance the performance of classifiers, because the former decomposes a complex multi-class problem into multiple simple sub-problems; the latter uses various functions to specify the conjunctive relationship of input variables in a multi-attribute problem. Extended belief rule-based system (EBRBS) is an advanced rule-based system that has been widely used in classification problems. In order to apply decomposition strategies and overlap functions to enhance the performance of EBRBSs, the present work focuses on the investigative research and comparative evaluation of the commonly used one-versus-one (OVO) decomposition strategy and five common overlap functions to improve the performance of EBRBSs on multi-class and multi-attribute problems. More specifically, three typical kinds of EBRBSs, namely original EBRBS (O-EBRBS), EBRBS with dynamic rule activation (DRA-EBRBS), and a latest EBRBS for big data (Micro-EBRBS), are selected to conduct extensive experimental studies on twenty classification problems. To best of our knowledge, this present work is the first time to provide a meaningful and useful study in revealing the potential capability of the EBRBSs with decomposition strategy and overlap function for multi-class and multi-attribute problems. Experimental results demonstrate that the square product overlap function and the OVO strategy can enhance the performance of EBRBSs over others for twenty classification problems.},
  archive      = {J_IJMLC},
  author       = {Yang, Long-Hao and Liu, Jun and Wang, Ying-Ming and Wang, Hui and Martínez, Luis},
  doi          = {10.1007/s13042-021-01355-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {811-837},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhancing extended belief rule-based systems for classification problems using decomposition strategy and overlap function},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic configuration broad learning system and its
approximation capability analysis. <em>IJMLC</em>, <em>13</em>(3),
797–810. (<a href="https://doi.org/10.1007/s13042-021-01341-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a kind of stochastic configuration broad learning system (SCBLS) is proposed for data modeling. The proposed SCBLS is established in the form of a flat network and its architecture is determined by a constructive learning approach. The input parameters of feature nodes and enhancement nodes of SCBLS are randomly assigned in the light of a supervisory mechanism. Inequality constraints are used to randomly assign the hidden parameters and adaptively select the scopes of random parameters. The output parameters of SCBLS are determined either by a constructive manner or by solving a global least squares problem. It is proved that the proposed SCBLS possesses universal approximation properties. The performances of the proposed SCBLS are evaluated by function approximation, benchmark datasets and time series prediction. Numerical examples show that SCBLS can achieve satisfactory approximation accuracy.},
  archive      = {J_IJMLC},
  author       = {Zhou, Wei and Wang, Degang and Li, Hongxing and Bao, Menghong},
  doi          = {10.1007/s13042-021-01341-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {797-810},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Stochastic configuration broad learning system and its approximation capability analysis},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MGPOOL: Multi-granular graph pooling convolutional networks
representation learning. <em>IJMLC</em>, <em>13</em>(3), 783–796. (<a
href="https://doi.org/10.1007/s13042-021-01328-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional network (GCN) nowadays become new state-of-the-art for networks representation learning. Most of the existing methods are single-granular methods that failed to analyze the graph at multi-granular views so as to lose abundant information. Advanced graph pooling techniques can be successfully benefiting from semi-supervised networks representation learning. How to capture multi-granular information through the graph pooling techniques on graphs without additional input features is a great challenge. Technically speaking, we propose our graph node embeddings framework, MGPOOL. First, inspired by the triadic influence learning, we use the 3-clique algorithm to coarsen the graph repeatedly. Three nodes of a triangle form a supernode. We treat the supernodes as key nodes for our graph pooling operations. That keeps the local relationship. These graphs capture consecutive 3-cliques from the finest to the coarsest to preserve global structural relationships. Second, we use the unsupervised single-granular algorithms on the coarsest graph to acquire its node embeddings. Based on that, our graph pooling operations combining with that node embeddings to generate another same size of the coarsest graph. This makes up for the uniqueness of the coarsening result at a time and expands the receptive field for each node to avoid high-proximity information lost. Third, we take the embeddings, the coarsest graph and new coarsest graph as uniform input of MGPOOL. We restore the coarsest graph to the original graph to get the original graph node embeddings. The experimental results on four public datasets, Wiki, Cora, CiteSeer, and DBLP, demonstrate that our method has a better Macro F1 value for node classification tasks and AUC and Ap value for link prediction than the baseline methods.},
  archive      = {J_IJMLC},
  author       = {Xin, Zhenghua and Chen, Guolong and Chen, Jie and Zhao, Shu and Wang, Zongchao and Fang, Aidong and Pan, Zhenggao and Cui, Lin},
  doi          = {10.1007/s13042-021-01328-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {783-796},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MGPOOL: Multi-granular graph pooling convolutional networks representation learning},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data reduction based on NN-kNN measure for NN classification
and regression. <em>IJMLC</em>, <em>13</em>(3), 765–781. (<a
href="https://doi.org/10.1007/s13042-021-01327-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data reduction processes are designed not only to reduce the amount of data, but also to reduce noise interference. In this study, we focus on researching sample reduction algorithms for the classification and regression data. A sample quality evaluation measure denoted by NN-kNN, which is inspired by human social behavior, is proposed. This measure is a local evaluation method that can accurately evaluate the quality of samples under uneven and irregular data distribution. Additionally, the measure is easy to understand and applies to both supervised and unsupervised data. Consequently, it respectively studies the sample reduction algorithms based on the NN-kNN measure for classification and regression data. Experiments are carried out to verify the proposed quality evaluation measure and data reduction algorithms. Experimental results show that NN-kNN can evaluate data quality effectively. High quality samples selected by the reduction algorithms can generate high classification and prediction performance. Furthermore, the robustness of the sample reduction algorithms is also validated.},
  archive      = {J_IJMLC},
  author       = {An, Shuang and Hu, Qinghua and Wang, Changzhong and Guo, Ge and Li, Piyu},
  doi          = {10.1007/s13042-021-01327-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {765-781},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Data reduction based on NN-kNN measure for NN classification and regression},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sustainable competitiveness evaluation of container liners
based on granular computing and social network group decision making.
<em>IJMLC</em>, <em>13</em>(3), 751–764. (<a
href="https://doi.org/10.1007/s13042-021-01325-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the shipping industry, the sustainability of the shipping companies has received more attention besides the economic benefits. A suitable evaluation model can provide a credible sustainable improvement test and guide the operation and management of shipping companies. This study is concerned with a granular evaluation model for the sustainable competitiveness evaluation of container liners, where the interval linguistic version of the analytic hierarchy process is designed for comparing alternatives comprehensively. To obtain ideal consistent preference relations, we propose a modification method by constructing information granules and using particle swarm optimization. Moreover, based on the combination of individual preference relations and experts’ weights obtained from the social network, the aggregated overall opinion of alternatives is achieved. Furthermore, a case study evaluating the sustainable competitiveness of container liners is conducted to support the proposed evaluation framework’s feasibility and practicality.},
  archive      = {J_IJMLC},
  author       = {Liu, Xueqin and Wang, Yanjun and Wang, Lidong},
  doi          = {10.1007/s13042-021-01325-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {751-764},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Sustainable competitiveness evaluation of container liners based on granular computing and social network group decision making},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Imbalanced data classification based on diverse sample
generation and classifier fusion. <em>IJMLC</em>, <em>13</em>(3),
735–750. (<a href="https://doi.org/10.1007/s13042-021-01321-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance problems are pervasive in many real-world applications, yet classifying imbalanced data remains to be a very challenging task in machine learning. SMOTE is the most influential oversampling approach. Based on SMOTE, many variants have been proposed. However, SMOTE and its variants have three drawbacks: (1) the probability distribution of the minority class samples is not considered; (2) the generated minority samples lack diversity; (3) the generated minority class samples overlap severely when oversampled many times for balancing with majority class samples. In order to overcome these three drawbacks, a generative adversarial network (GAN) based framework is proposed in this paper. The framework includes an oversampling method and a two-class imbalanced data classification approach. The oversampling method is based on an improved GAN model, and the classification approach is based on classifier fusion via fuzzy integral, which can well model the interactions among the base classifiers trained on the balanced data subsets constructed by the proposed oversampling method. Extensive experiments are conducted to compare the proposed methods with related methods on 5 aspects: MMD-score, Silhouette-score, F-measure, G-means, and AUC-area. The experimental results demonstrate that the proposed methods are more effective and efficient than the compared approaches.},
  archive      = {J_IJMLC},
  author       = {Zhai, Junhai and Qi, Jiaxing and Zhang, Sufang},
  doi          = {10.1007/s13042-021-01321-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {735-750},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Imbalanced data classification based on diverse sample generation and classifier fusion},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Biomedical event trigger extraction based on multi-layer
residual BiLSTM and contextualized word representations. <em>IJMLC</em>,
<em>13</em>(3), 721–733. (<a
href="https://doi.org/10.1007/s13042-021-01315-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomedical event extraction is an important branch of biomedical information extraction. Trigger extraction is the most essential sub-task in event extraction, which has been widely concerned. Existing trigger extraction studies are mostly based on conventional machine learning or neural networks. But they neglect the ambiguity of word representations and the insufficient feature extraction by shallow hidden layers. In this paper, trigger extraction is treated as a sequence labeling problem. We introduce the language model to dynamically compute contextualized word representations and propose a multi-layer residual bidirectional long short-term memory (BiLSTM) architecture. First, we concatenate contextualized word embedding, pretrained word embedding and character-level embedding as the feature representations, which effectively solves the tokens’ ambiguity in biomedical corpora. Then, the designed BiLSTM block with residual connection and gated multi-layer perceptron is adopted to extract features iteratively. This architecture improves the ability of our model to capture information and avoids gradient exploding or vanishing. Finally, we combine the multi-layer residual BiLSTM with CRF layer to obtain more reasonable label sequences. Comparing with other state-of-the-art methods, the proposed model achieves the competitive performance (F1-score: 80.74\%) on the biomedical multi-level event extraction (MLEE) corpus without any manual participation and feature engineering.},
  archive      = {J_IJMLC},
  author       = {Wei, Hao and Zhou, Ai and Zhang, Yijia and Chen, Fei and Qu, Wen and Lu, Mingyu},
  doi          = {10.1007/s13042-021-01315-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {721-733},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Biomedical event trigger extraction based on multi-layer residual BiLSTM and contextualized word representations},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Steadiness analysis of means-end conceptual paths and
problem-chains based on concept lattices and similarity measuring.
<em>IJMLC</em>, <em>13</em>(3), 691–719. (<a
href="https://doi.org/10.1007/s13042-021-01309-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal concept analysis has shown much potential in supporting personalized learning. This paper is motivated by several application scenarios of concept lattices in supporting mathematics education. The aim of the paper is to develop a scheme for designing problem-chains based on concept lattices and provide evaluation methods towards steadiness of the corresponding learning processes. Particularly, a model is developed to study the sensitivity of conversion from effort on problems to efficacy on knowledge/skills. Then the notion of successive trails is introduced to describe means-end chains of learning states. Towards steadiness of the corresponding learning processes, evaluation methods are developed and data experiments are conducted from aspects of effort on problems, efficacy on knowledge/skills and conversion sensitivity. Moreover, the notion of conceptual paths is introduced in order to describe personalized learning strategies. Subsequently, a scheme for designing problem-chains is given based on conceptual paths and similarity measuring. Finally, a method of evaluating the steadiness of problem-chains is proposed by taking advantage of linear regression analysis on problem-chains.},
  archive      = {J_IJMLC},
  author       = {Guo, Lankun and Jia, Zhenhua and Li, Qingguo and Dai, Jianhua},
  doi          = {10.1007/s13042-021-01309-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {691-719},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Steadiness analysis of means-end conceptual paths and problem-chains based on concept lattices and similarity measuring},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view data clustering via non-negative matrix
factorization with manifold regularization. <em>IJMLC</em>,
<em>13</em>(3), 677–689. (<a
href="https://doi.org/10.1007/s13042-021-01307-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, non-negative matrix factorization (NMF) based cluster analysis for multi-view data shows impressive behavior in machine learning. Usually, multi-view data have complementary information from various views. The main concern behind the NMF is how to factorize the data to achieve a significant clustering solution from these complementary views. However, NMF does not focus to conserve the geometrical structures of the data space. In this article, we intensify on the above issue and evolve a new NMF clustering method with manifold regularization for multi-view data. The manifold regularization factor is exploited to retain the locally geometrical structure of the data space and gives extensively common clustering solution from multiple views. The weight control term is adopted to handle the distribution of each view weight. An iterative optimization strategy depended on multiplicative update rule is applied on the objective function to achieve optimization. Experimental analysis on the real-world datasets are exhibited that the proposed approach achieves better clustering performance than some state-of-the-art algorithms.},
  archive      = {J_IJMLC},
  author       = {Khan, Ghufran Ahmad and Hu, Jie and Li, Tianrui and Diallo, Bassoma and Wang, Hongjun},
  doi          = {10.1007/s13042-021-01307-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {677-689},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-view data clustering via non-negative matrix factorization with manifold regularization},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view document clustering based on geometrical
similarity measurement. <em>IJMLC</em>, <em>13</em>(3), 663–675. (<a
href="https://doi.org/10.1007/s13042-021-01295-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous works implemented multi-view clustering algorithms in document clustering. A challenging problem in document clustering is the similarity metric. Existing multi-view document clustering methods broadly utilized two measurements: the Cosine similarity (CS) and the Euclidean distance (ED). The first did not consider the magnitude difference (MD) between the two vectors. The second can’t register the divergence of two vectors that offer a similar ED. In this paper, we originally created five models of similarity metric. This methodology foils the downside of the CS and ED similarity metrics by figuring the divergence between documents with the same ED while thinking about their sizes. Furthermore, we proposed our multi-view document clustering plan which dependent on the proposed similarity metric. Firstly, CS, ED, triangle’s area similarity and sector’s area similarity metric, and our five similarity metrics have been applied to every view of a dataset to generate a corresponding similarity matrix. Afterward, we ran clustering algorithms on these similarity matrices to evaluate the performance of single view. Later, we aggregated these similarity matrices to obtain a unified similarity matrix and apply spectral clustering algorithm on it to generate the final clusters. The experimental results show that the proposed similarity functions can gauge the similitude between documents more accurately than the existing metrics, and the proposed clustering scheme surpasses considerably up-to-date algorithms.},
  archive      = {J_IJMLC},
  author       = {Diallo, Bassoma and Hu, Jie and Li, Tianrui and Khan, Ghufran Ahmad and Hussein, Ahmed Saad},
  doi          = {10.1007/s13042-021-01295-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {663-675},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-view document clustering based on geometrical similarity measurement},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel multiple attribute decision-making approach for
evaluation of emergency management schemes under picture fuzzy
environment. <em>IJMLC</em>, <em>13</em>(3), 633–661. (<a
href="https://doi.org/10.1007/s13042-021-01280-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency schemes assessment (ESA) is a momentous activity for the country or government to improve emergency management, which can effectively reduce casualties and economic losses as much as possible. The choice of emergency scheme involves many quantitative or qualitative attributes, thus it can be viewed as a complicated multiple attribute decision making (MADM) issue. Whereas the business and unpredictability characteristics of emergency events, the nondeterminacy, ambiguity and impreciseness always arise in ESA. Picture fuzzy set is deemed as an efficacious technique to seize the ambiguity and indeterminacy of preference information. Because the extant picture fuzzy aggregation operators cannot ponder the priority and relevance of attribute in coping with decision issues. Hence, the goal of this essay is to propound an innovative decision algorithm which takes the prioritized relations and correlation of the ascertained attributes into account based upon the generalized picture fuzzy archimedean copula prioritized operators and a novel score function. Firstly, we develope an innovate score function to more reasonable compare the picture fuzzy numbers. Then, by synthesizing the picture fuzzy number, archimedean copula and prioritized operator, we design the picture fuzzy Archimedean copula prioritized weighted averaging operator, picture fuzzy Archimedean copula prioritized weighted geometric operator and their ordered weighted form to fuse picture fuzzy assessment data and study several remarkable properties, particular cases of these operators. Moreover, we design a novel decision methodology on the basis of the proffered generalized operators and score function to resolve MADM problems. Furthermore, we employ it to dispose of the problem of assessing emergency management schemes in a real-life situation, in which the evaluation information provided via specialists in the form of voting. Ultimately, the outstanding superiority and efficiency of the designed method is justified through the aforementioned numerical and detailed comparative analysis.},
  archive      = {J_IJMLC},
  author       = {Rong, Yuan and Liu, Yi and Pei, Zheng},
  doi          = {10.1007/s13042-021-01280-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {633-661},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel multiple attribute decision-making approach for evaluation of emergency management schemes under picture fuzzy environment},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel fusion strategies for continuous interval-valued
q-rung orthopair fuzzy information: A case study in quality assessment
of SmartWatch appearance design. <em>IJMLC</em>, <em>13</em>(3),
609–632. (<a href="https://doi.org/10.1007/s13042-020-01269-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of Yager’s q-rung orthopair fuzzy set (QROFS) have gained considerable and continuously increasing attention as a useful tool for imprecision and uncertainty representation due to its capability to discard the constraints on the membership and nonmembership functions as generally required by its intuitionistic fuzzy counterpart. Among the generalizations and variants established in the past few years, the interval-valued QROFSs (IVQROFSs) have been diffusely considered to be a powerful generalization of the interval-valued fuzzy sets. The continuous ordered weighted averaging (COWA) operator has been extended successfully to some special cases of IVQROFSs, including interval-valued intuitionistic and Pythagorean fuzzy sets. Thus, to expand on previous studies, several continuous IVQROF (C-IVQROF) aggregation operators are proposed in this study. First, the dual C-GOWA operator is defined on the basis of the continuous generalized ordered weighted averaging (C-GOWA) operator and Yager class of fuzzy negation. Subsequently, the C-IVQROFOWA operator with two independent parameters is constructed, and the weighted C-IVQROFOWA operator is then proposed for aggregating a collection of IVQROFSs. The C-IVQROFOWA operator and its weighted version can model commendably the attitudinal characteristics of the decision-maker. Second, a parameter optimization model and its algorithm-solving strategy driven by consensus measures are built to develop a group decision-making method. Finally, a case study to evaluate the SmartWatch design alternatives is provided to demonstrate the proposed approach, and the results of a comparative analysis verify the rationality and efficiency of the proposed operators.},
  archive      = {J_IJMLC},
  author       = {Yang, Yi and Chen, Zhen-Song and Rodríguez, Rosa M. and Pedrycz, Witold and Chin, Kwai-Sang},
  doi          = {10.1007/s13042-020-01269-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {609-632},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Novel fusion strategies for continuous interval-valued q-rung orthopair fuzzy information: A case study in quality assessment of SmartWatch appearance design},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Q-ROF-SIR methods and their applications to multiple
attribute decision making. <em>IJMLC</em>, <em>13</em>(3), 595–607. (<a
href="https://doi.org/10.1007/s13042-020-01267-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {q-rung orthopair fuzzy set (q-ROFS) is a useful tool to express uncertain information. With the parameter q increasing, q-ROFSs have broader space for describing uncertain information than intuitionistic fuzzy sets (IFSs) and Pythagorean fuzzy sets (PFSs). This paper extends the superiority and inferiority ranking (SIR) methods to solve multiple attribute decision making (MADM) problems within the q-ROF environment, named q-ROF-SIR methods. In the q-ROF-SIR methods, the possibility degree (PD) for q-rung orthopair fuzzy numbers (q-ROFNs) is introduced to improve the preference intensity. Further, the q-ROF entropy weight (q-ROF-EW) method is constructed to determine the attribute weights suppose the weights of attribute are unknown. Finally, the effectiveness and applicability of the q-ROF-SIR methods are verified.},
  archive      = {J_IJMLC},
  author       = {Zhu, Hua and Zhao, Jianbin and Li, Hua},
  doi          = {10.1007/s13042-020-01267-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {595-607},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Q-ROF-SIR methods and their applications to multiple attribute decision making},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Group decision making for internet public opinion emergency
based upon linguistic intuitionistic fuzzy information. <em>IJMLC</em>,
<em>13</em>(3), 579–594. (<a
href="https://doi.org/10.1007/s13042-020-01262-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the wide use of network, the outbreak of network public opinion emergencies has changed from single to multiple. The goal of the current study is to construct the emergency group decision-making (EGDM) model for multiple network public opinion emergencies under the linguistic intuitionistic environment. First of all, we introduce a new version of Copula and Co-copula named extended Copula (EAC) and extended Co-Copula (EACC), respectively, which can be used to capture the relation of attributes (indexes) in the group decision making problems of network public opinion emergencies; Some special cases of EAC and EACC are gained to manage intuitionistic fuzzy information (IFI). Besides, the novel operational rules of linguisitic intuitionistic fuzzy numbers (LIFNs) based upon EAC and EACC are also defined under linguistic intuitionistic environment. What’s more, by integrating the Choquet integral and the proposed operational rules of LIFNs, the linguistic intuitionistic fuzzy Choquet-Copula aggregation operators (LIFCCA) are proposed together with their properties are also investigated; whilst, five specific forms of LIFCCA are obtained when EAC and EACC take different generators. Last but not least, an EGDM approach is constructed based upon proposed LIFCCA; Consequently, the validities and merits of the proposed EGDM approach are shown by comparing with existing approaches.},
  archive      = {J_IJMLC},
  author       = {Liu, Yi and Wei, Guiwu and Liu, Haobin and Xu, Lei},
  doi          = {10.1007/s13042-020-01262-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {579-594},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Group decision making for internet public opinion emergency based upon linguistic intuitionistic fuzzy information},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge granularity reduction for decision tables.
<em>IJMLC</em>, <em>13</em>(3), 569–577. (<a
href="https://doi.org/10.1007/s13042-020-01254-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction is a difficult topic in rough set theory and knowledge granularity reduction is one of the important types of reduction. However, up to now, its reduction algorithm based on a discernibility matrix has not been given. In this paper, we show that knowledge granularity reduction is equivalent to both positive region reduction and X-absolute reduction, and derive its corresponding algorithm based on a discernibility matrix to fill the gap. Particularly, knowledge granularity reduction is the usual positive region reduction for consistent decision tables. Finally, we provide a simple knowledge granularity reduction algorithm for finding a reduct with the help of binary integer programming, and consider six UCI datasets to illustrate our algorithms.},
  archive      = {J_IJMLC},
  author       = {Liu, Guilong and Feng, Yanbin},
  doi          = {10.1007/s13042-020-01254-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {569-577},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Knowledge granularity reduction for decision tables},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: New trends on machine learning applied to
information processing under uncertainty. <em>IJMLC</em>,
<em>13</em>(3), 567–568. (<a
href="https://doi.org/10.1007/s13042-022-01504-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {Zou, Li and Martínez, Luis and Liu, Jun and Qiu, Xiaoping and He, Xingxing},
  doi          = {10.1007/s13042-022-01504-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {567-568},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Editorial: New trends on machine learning applied to information processing under uncertainty},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Correction to: Recent advances in multiple criteria
decision making techniques. <em>IJMLC</em>, <em>13</em>(2), 565. (<a
href="https://doi.org/10.1007/s13042-021-01469-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {He, Yulin and Wang, Xizhao and Huang, Joshua Zhexue},
  doi          = {10.1007/s13042-021-01469-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {565},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Correction to: Recent advances in multiple criteria decision making techniques},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Recent advances in multiple criteria decision making
techniques. <em>IJMLC</em>, <em>13</em>(2), 561–564. (<a
href="https://doi.org/10.1007/s13042-015-0490-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {He, Yulin and Wang, Xizhao and Huang, Joshua Zhexue},
  doi          = {10.1007/s13042-015-0490-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {561-564},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Recent advances in multiple criteria decision making techniques},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Correction to: Building heterogeneous ensembles by pooling
homogeneous ensembles. <em>IJMLC</em>, <em>13</em>(2), 559. (<a
href="https://doi.org/10.1007/s13042-021-01479-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {Sabzevari, Maryam and Martínez-Muñoz, Gonzalo and Suárez, Alberto},
  doi          = {10.1007/s13042-021-01479-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {559},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Correction to: Building heterogeneous ensembles by pooling homogeneous ensembles},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Building heterogeneous ensembles by pooling homogeneous
ensembles. <em>IJMLC</em>, <em>13</em>(2), 551–558. (<a
href="https://doi.org/10.1007/s13042-021-01442-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous ensembles consist of predictors of different types, which are likely to have different biases. If these biases are complementary, the combination of their decisions is beneficial and could be superior to homogeneous ensembles. In this paper, a family of heterogeneous ensembles is built by pooling classifiers from M homogeneous ensembles of different types of size T. Depending on the fraction of base classifiers of each type, a particular heterogeneous combination in this family is represented by a point in a regular simplex in M dimensions. The M vertices of this simplex represent the different homogeneous ensembles. A displacement away from one of these vertices effects a smooth transformation of the corresponding homogeneous ensemble into a heterogeneous one. The optimal composition of such heterogeneous ensemble can be determined using cross-validation or, if bootstrap samples are used to build the individual classifiers, out-of-bag data. The proposed heterogeneous ensemble building strategy, composed of neural networks, SVMs, and random trees (i.e. from a standard random forest), is analyzed in a comprehensive empirical analysis and compared to a benchmark of other heterogeneous and homogeneous ensembles. The achieved results illustrate the gains that can be achieved by the proposed ensemble creation method with respect to both homogeneous ensembles and to the tested heterogeneous building strategy at a fraction of the training cost.},
  archive      = {J_IJMLC},
  author       = {Sabzevari, Maryam and Martínez-Muñoz, Gonzalo and Suárez, Alberto},
  doi          = {10.1007/s13042-021-01442-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {551-558},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Building heterogeneous ensembles by pooling homogeneous ensembles},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Correction to: Rotation forest for multi-target regression.
<em>IJMLC</em>, <em>13</em>(2), 549–550. (<a
href="https://doi.org/10.1007/s13042-021-01354-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {Rodríguez, Juan J. and Juez-Gil, Mario and López-Nozal, Carlos and Arnaiz-González, Álvar},
  doi          = {10.1007/s13042-021-01354-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {549-550},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Correction to: Rotation forest for multi-target regression},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Rotation forest for multi-target regression.
<em>IJMLC</em>, <em>13</em>(2), 523–548. (<a
href="https://doi.org/10.1007/s13042-021-01329-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of multiple numeric outputs at the same time is called multi-target regression (MTR), and it has gained attention during the last decades. This task is a challenging research topic in supervised learning because it poses additional difficulties to traditional single-target regression (STR), and many real-world problems involve the prediction of multiple targets at once. One of the most successful approaches to deal with MTR, although not the only one, consists in transforming the problem in several STR problems, whose outputs will be combined building up the MTR output. In this paper, the Rotation Forest ensemble method, previously proposed for single-label classification and single-target regression, is adapted to MTR tasks and tested with several regressors and data sets. Our proposal rotates the input space in an efficient and novel fashion, avoiding extra rotations forced by MTR problem decomposition. Four approaches for MTR are used: single-target (ST), stacked-single target (SST), Ensembles of Regressor Chains (ERC), and Multi-target Regression via Quantization (MRQ). For assessing the benefits of the proposal, a thorough experimentation with 28 MTR data sets and statistical tests are used, concluding that Rotation Forest, adapted by means of these approaches, outperforms other popular ensembles, such as Bagging and Random Forest.},
  archive      = {J_IJMLC},
  author       = {Rodríguez, Juan J. and Juez-Gil, Mario and López-Nozal, Carlos and Arnaiz-González, Álvar},
  doi          = {10.1007/s13042-021-01329-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {523-548},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Rotation forest for multi-target regression},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dimensionality reduction of tensors based on
manifold-regularized tucker decomposition and its iterative solution.
<em>IJMLC</em>, <em>13</em>(2), 509–522. (<a
href="https://doi.org/10.1007/s13042-021-01422-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, tensor data appear more frequently in machine learning. Tucker decomposition is a powerful tool for processing tensor data. However, from the perspective of dimensionality reduction, Tucker decomposition without any regularization is only a tensor version of principal component analysis (PCA) that learning a linear subspace to minimize the distance between the data and their projections on the subspace. However, many high-dimensional tensor data usually reside in low-dimensional submanifolds, rather than low-dimensional linear subspaces. It is necessary to fill the gap between submanifolds and linear subspaces to achieve superior performance. In this paper, we proposed a new dimensionality reduction algorithm of tensor data based on manifold regularized Tucker decomposition (called MRTD for short), in which manifold regularization is in addition to Tucker decomposition. Furthermore, unlike many other similar algorithms that ignore the matrices of Tucker decomposition by absorbing them into a whole matrix, in this paper, we proposed an iterative solution to MRTD that the matrices are calculated based on each other iteratively. Matrices in Tucker decomposition represent different dimensionality reduction operations for each dimension of tensor. Therefore, MRTD is a dimensionality reduction algorithm specially designed for tensor data, not for vector data. The experimental results of MRTD and 5 other related state-of-the-art algorithms on 6 commonly-used real-world datasets are presented, showing the better performance of MRTD.},
  archive      = {J_IJMLC},
  author       = {Huang, Haidong and Ma, Zhengming and Zhang, Guokai},
  doi          = {10.1007/s13042-021-01422-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {509-522},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dimensionality reduction of tensors based on manifold-regularized tucker decomposition and its iterative solution},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust graph-based multi-view clustering in latent embedding
space. <em>IJMLC</em>, <em>13</em>(2), 497–508. (<a
href="https://doi.org/10.1007/s13042-021-01421-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view graph-based clustering (MGC) aims to cluster multi-view data via a graph learning scheme, and has aroused widespread research interests in behavior detection, face recognition, and information retrieval in recent years. However, most of the existing MGC methods usually learn the affinity graph in the original space, such that they are inevitably hindered by the curse of dimensionality and corrupted features. Moreover, they usually learn the affinity between paired-samples by using Euclidean-distance metric; nevertheless, such a metric is sensitive to noise and outliers. In this paper, we propose a novel MGC method, namely latent embedding space learning (LESL), which aims to learn a latent embedding space and a robust affinity graph simultaneously. Specifically, a latent embedding representation is firstly learned, which can reduce the corruption and redundancy of the original views, and can effectively utilize the complementary information of multiple views. Afterwards, a robust estimator is used to automatically cut the connections among inter-cluster in the affinity graph. Finally, alternating direction minimization on the augmented Lagrangian multiplier (ALM-ADM) is adopted to optimize the unified objective function. Experimental results show that LESL outperforms state-of-the-art methods obviously.},
  archive      = {J_IJMLC},
  author       = {Mei, Yanying and Ren, Zhenwen and Wu, Bin and Shao, Yanhua and Yang, Tao},
  doi          = {10.1007/s13042-021-01421-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {497-508},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust graph-based multi-view clustering in latent embedding space},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving offline handwritten chinese text recognition with
glyph-semanteme fusion embedding. <em>IJMLC</em>, <em>13</em>(2),
485–496. (<a href="https://doi.org/10.1007/s13042-021-01420-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose the Glyph-Semanteme fusion Embedding (GSE) for Chinese character and apply it to Offline Handwritten Chinese Text Recognition (offline-HCTR). It is well known that the number of Chinese characters is very large and the glyphs of these characters are complex, but few researchers realize that the underlying reason for this phenomenon is that Chinese is a form of ideogram, which indicates that there are correlations between the glyph and semanteme of a character. In order to utilize this feature and create better representations for Chinese characters, firstly, we extract the glyph embedding and semanteme embedding for each Chinese character; then we propose a parameterized gated fusion strategy to automatically calculate the Glyph-Semanteme fusion Embedding for each character by fusing its glyph embedding and semanteme embedding. We apply the proposed GSE to an attention-based Encoder-decoder network for the offline-HCTR task. Furthermore, two kinds of GSE, Character-level GSE (CGSE) and Text-level GSE (TGSE), are applied to the decoder phase to yield the predictions. On the standard benchmark ICDAR-2013 HCTR competition dataset, the proposed method achieves 96.65\% character-level recognition accuracy, which demonstrates the effectiveness of the proposed glyph-semanteme fusion embedding.},
  archive      = {J_IJMLC},
  author       = {Zhan, Hongjian and Lyu, Shujing and Lu, Yue},
  doi          = {10.1007/s13042-021-01420-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {485-496},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improving offline handwritten chinese text recognition with glyph-semanteme fusion embedding},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An automatic framework for perioperative risks
classification from retinal images of complex congenital heart disease
patients. <em>IJMLC</em>, <em>13</em>(2), 471–483. (<a
href="https://doi.org/10.1007/s13042-021-01419-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of patient suffering from complex congenital heart diseases (CHDs) increases gradually each year. The perioperative parameters assessment of complex CHDs patients is critical in choosing a suitable surgery method, but there is still a lack of an accurate and interpretable approach to preoperatively assess surgical risks and prognosis. The vascular patterns in retinal images of patients with complex CHDs reflect the severity of heart disease, so retinal images are used to predict the risk of perioperative parameters of heart disease. Perioperative parameters classification from retinal images is challenging due to the limited available retinal image data in patients with CHDs and the interference caused by retinal images with poor quality. In this work, a method called deep learning based perioperative parameter classifier is proposed to classify perioperative parameter risk from retinal images of patients with complex CHDs. To evaluate its effectiveness, our method is verified with 6 perioperative parameters, respectively. Experimental results show that the proposed method is superior to several popular classification networks in this task. Saliency maps are also provided to enhance the interpretability in our model and may be of great use for future medical researches.},
  archive      = {J_IJMLC},
  author       = {Ng, Wing W. Y. and Liang, Haicong and Peng, Qingsheng and Zhong, Cankun and Dong, Xinran and Huang, Zhongning and Zhong, Pingting and Li, Cong and Xu, Minghui and Sun, Yunxia and Yu, Honghua and Yang, Xiaohong},
  doi          = {10.1007/s13042-021-01419-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {471-483},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An automatic framework for perioperative risks classification from retinal images of complex congenital heart disease patients},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Antenna optimization based on master-apprentice broad
learning system. <em>IJMLC</em>, <em>13</em>(2), 461–470. (<a
href="https://doi.org/10.1007/s13042-021-01418-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the efficiency of antenna optimization design, a surrogate model is often used to replace the full-wave electromagnetic simulation software. Broad learning system (BLS) provides an alternative method for deep structure, aiming to overcome the drawback of excessive time-consuming training process, however, usually not with satisfactory accuracy. In order to further improve the performance of the model, master-apprentice (MA) behavior is proposed in this paper, using the current BLS training results as the priori knowledge, which are taken as fixed features to the next BLS hidden layer for further training. Each MA behavior forms a double BLS structure, which is composed of two parts, the models trained before and after are called master BLS (MBLS) and apprentice BLS (ABLS) respectively. These two subsystems together constitute a master-apprentice BLS (MABLS). Two antenna examples, rectangular microstrip antenna (RMSA) and WLAN dual-band monopole antenna (DBMA), and 10 UCI regression datasets are employed to demonstrate the effectiveness of the proposed model.},
  archive      = {J_IJMLC},
  author       = {Ding, Weitong and Tian, Yubo and Li, Pengfei and Yuan, Huining and Li, Rui},
  doi          = {10.1007/s13042-021-01418-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {461-470},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Antenna optimization based on master-apprentice broad learning system},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient hierarchical policy network with fuzzy rules.
<em>IJMLC</em>, <em>13</em>(2), 447–459. (<a
href="https://doi.org/10.1007/s13042-021-01417-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical reinforcement learning (HRL) is a promising method, which decomposes complex tasks into a series of sub-tasks. However, at present, most HRL methods have slow convergence speed and are difficult to be widely applied to such scenarios in real life. In this paper, we propose an efficient hierarchical reinforcement learning algorithm with fuzzy rules (HFR), a novel framework for integrating human prior knowledge with hierarchical policy network, which can effectively accelerate the optimization of policy. The model presented in this paper uses fuzzy rules to represent the human prior knowledge, making the rules trainable because of the derivability of the fuzzy rules. In addition, a switch module that adaptively adjusts the decision-making frequency of the upper-level policy is proposed to solve the limitation of manual tuning. Experiment results demonstrate that HFR has a faster convergence rate than the current state-of-the-art HRL algorithms, especially in complex scenarios, such as robot control tasks.},
  archive      = {J_IJMLC},
  author       = {Shi, Wei and Feng, Yanghe and Huang, Honglan and Liu, Zhong and Huang, Jincai and Cheng, Guangquan},
  doi          = {10.1007/s13042-021-01417-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {447-459},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Efficient hierarchical policy network with fuzzy rules},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generating robust real-time object detector with uncertainty
via virtual adversarial training. <em>IJMLC</em>, <em>13</em>(2),
431–445. (<a href="https://doi.org/10.1007/s13042-021-01416-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite remarkable accuracy improvement in convolutional neural networks (CNNs) based object detectors, there are still some problems in applying on some safety–critical domain, such as the self-driving domain, in part due to the complexity of verifying the correctness of detecting results and the lack of safety guarantees. By simply modeling the bounding box parameters with a Gaussian distribution in a real-time object detector, we propose a new method for predicting uncertainty, which can quantify the reliability of the neural networks’ prediction, to validate the correctness of detecting results with low computational complexity. In addition, we redesign the loss function by adding a new regularization term, called virtual adversarial training (VAT). The use of VAT, which is defined as the robustness of the conditional label distribution around input data against local perturbation, can smooth the output distribution robust with lower uncertainty and the prediction from the regularized model will be better. In consideration of the trade-off between the size and speed, we choose some lightweight models as the backbone of a YOLOv3 detector and the experimental results on PASCAL VOC dataset and MS COCO demonstrate the effectiveness of the proposed approach.},
  archive      = {J_IJMLC},
  author       = {Chen, Yipeng and Xu, Ke and He, Di and Ban, Xiaojuan},
  doi          = {10.1007/s13042-021-01416-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {431-445},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Generating robust real-time object detector with uncertainty via virtual adversarial training},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EEG-based emotion recognition with feature fusion networks.
<em>IJMLC</em>, <em>13</em>(2), 421–429. (<a
href="https://doi.org/10.1007/s13042-021-01414-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Human-computer interaction, automatic emotion recognition based on multichannel electroencephalography (EEG) signals has attracted much attention in recent years. However, many existing studies on EEG-based emotion recognition ignore the correlation information between different EEG channels and cannot fully capture the contextual information of EEG signals. In this paper, a novel multi-feature fusion network is proposed, which consists of spatial and temporal neural network structures to learn discriminative spatio-temporal emotional information to recognize emotion. In this experiment, two common types of features, time-domain features (Hjorth, Differential Entropy, Sample Entropy) and frequency domain features (Power Spectral Density), are extracted. Then, to learn the spatial and contextual information, a convolution neural network, inspired by GoogleNet with inception structure, was adopted to capture the intrinsic spatial relationship of EEG electrodes and contextual information, respectively. Fully connected layers are used for feature fusion, instead of the SoftMax function, SVM is selected to classify the high-level emotion features. Finally, to evaluate the proposed method, we conduct leave-one-subject-out EEG emotion recognition experiments on the DEAP dataset, and the experiment results show that the proposed method achieves excellent performance and average emotion recognition accuracies of 80.52\% and 75.22\% in the valence and arousal classification tasks of the DEAP database, respectively.},
  archive      = {J_IJMLC},
  author       = {Gao, Qiang and Yang, Yi and Kang, Qiaoju and Tian, Zekun and Song, Yu},
  doi          = {10.1007/s13042-021-01414-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {421-429},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {EEG-based emotion recognition with feature fusion networks},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning deep representation for action unit detection with
auxiliary facial attributes. <em>IJMLC</em>, <em>13</em>(2), 407–419.
(<a href="https://doi.org/10.1007/s13042-021-01413-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action unit (AU) occurrence detection refers to the recognition of the presence or absence of the AU, and it is a challenging task due to rigid and non-rigid facial motion, subtle facial changes, and short duration. Recently, most studies focus on automatic AU detection by local representation learning or exploiting the correlation of AU to enhance recognition performance, and it has made significant progress. However, the relationships among AUs and other facial attributes are ignored. This study implements the AU occurrence detection task by multi-task learning instead of traditional single-task learning, so AU detection is beneficial from auxiliary facial attributes analysis. The main contributions of this study include: (1) This study constructs a multitask-based facial analysis system (MTFAS), which integrates several facial attributes (facial landmarks, head pose, gender, and emotion). (2) Due to the diversity of tasks, the features of lower and higher layers are combined to avoid the loss of information. (3) This work applies online difficult sample selection and weighted loss function to weaken the impact of imbalanced data. Experiments are conducted on well applied BP4D and DISFA databases, and the proposed MTFAS method is compared with state-of-art. MFTAS obtains the average F1 score of 0.622 and recognition accuracy of 0.787 on BP4D. On the DISFA dataset, MTFAS acquires the average F1 score of 0.600 and recognition accuracy of 0.909.},
  archive      = {J_IJMLC},
  author       = {Zhou, Caixia and Zhi, Ruicong},
  doi          = {10.1007/s13042-021-01413-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {407-419},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning deep representation for action unit detection with auxiliary facial attributes},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A collaborative emergency decision making approach based on
BWM and TODIM under interval 2-tuple linguistic environment.
<em>IJMLC</em>, <em>13</em>(2), 383–405. (<a
href="https://doi.org/10.1007/s13042-021-01412-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergencies require various emergency departments to collaborate to achieve timely and effective emergency responses. Thus, the overall performance of emergency response is influenced not only by the efficiency of each department alternative but also by the coordination effect among different department alternatives. This paper proposes a collaborative emergency decision making (CEDM) approach considering the synergy among different department alternatives based on the best–worst method (BWM) and TODIM (an acronym in Portuguese of interactive and multiple attribute decision making) method within an interval 2-tuple linguistic environment. First, the evaluation information provided by decision makers (DMs) is represented by interval 2-tuple linguistic variables to reflect and model the underlying diversity and uncertainty. On the basis of the DMs’ evaluations, the individual and collaborative performance evaluations of multi-alternative combinations composed of different department alternatives are constructed. Then, the BWM is extended into interval 2-tuple linguistic environment to obtain the weights of evaluation criteria, where the group decision making is taken into account in an interval fuzzy mathematical programming model. Furthermore, to derive more practical and accurate decision results, an interval 2-tuple linguistic TODIM (ITL-TODIM) method is proposed by considering the DMs’ psychological behaviours. In the developed ITL-TODIM method, both the gain and loss degrees of one alternative relative to another are simultaneously computed. Finally, a numerical example is presented to illustrate the applicability of the proposed method. Sensitivity and comparative analyses are also provided to demonstrate the effectiveness and advantages of the proposed approach.},
  archive      = {J_IJMLC},
  author       = {Qi, Kaixuan and Chai, Hua and Duan, Qiangling and Du, Yongjian and Wang, Qingsong and Sun, Jinhua and Liew, K. M.},
  doi          = {10.1007/s13042-021-01412-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {383-405},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A collaborative emergency decision making approach based on BWM and TODIM under interval 2-tuple linguistic environment},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CSHE: Network pruning by using cluster similarity and matrix
eigenvalues. <em>IJMLC</em>, <em>13</em>(2), 371–382. (<a
href="https://doi.org/10.1007/s13042-021-01411-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep convolutional neural networks (CNNs) have achieved significant success in computer vision applications, the real-world deployment of CNNs is often limited by computing resources and memory constraints. As a mainstream deep model compression technology, neural network pruning offers a promising prospect to reduce models’ parameters and calculation. In this paper, we proposed a novel filter pruning method that combines convolution filters and feature maps information for convolutional neural network compression, namely network pruning by using cluster similarity and large eigenvalues (CSHE). First, based on the convolution operation, we explore the similarity relationship of feature maps generated by the corresponding filters. Concretely, the clustering algorithm is used to classify the similarity of filter to guide the classification of feature map. Secondly, the proposed method utilizes the information of the large eigenvalues of the feature maps to rank the importance of filters. Finally, we prune the low-ranking filters and remain the high-ranking ones. The proposed method eliminates redundancy in convolution filters by applying large eigenvalues of feature maps based on filters similarity. In this way, most of the representative information in the network can be retained and the pruned results can be easily reproduced. Experiments show that the accuracy of the pruned sparse deep network obtained by the CSHE method in the classification tasks of CIFAR-10 and ImageNet ILSVRC-12 is almost the same as that of the reference network without any additional constraints.},
  archive      = {J_IJMLC},
  author       = {Shao, Mingwen and Dai, Junhui and Wang, Ran and Kuang, Jiandong and Zuo, Wangmeng},
  doi          = {10.1007/s13042-021-01411-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {371-382},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {CSHE: Network pruning by using cluster similarity and matrix eigenvalues},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Implicit social recommendation algorithm based on multilayer
fuzzy perception similarity. <em>IJMLC</em>, <em>13</em>(2), 357–369.
(<a href="https://doi.org/10.1007/s13042-021-01409-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most recommender systems are essentially a contextually accurate matching between users and items with similarities. Thus, similarity is particularly important to the recommendation process. Furthermore, the highest goal of similarity is to simulate the subjective human feeling of similarity, i.e., to simulate objective feature engineering in a way that is as consistent with subjective feeling as possible. By studying the subjective cognition of similarity, we found that the process could be divided into two stages, namely, perception and comprehension. Perception has fuzziness in that deterministic data cannot accurately describe subjective perception and judge emotional tendencies. Second, comprehension has gradations such that a linear model easily underfits the similarity. To address these two problems, we proposed a new implicit social recommendation algorithm based on multilayer fuzzy perception similarity. An extensive experimental study conducted on benchmark datasets showed that the proposed algorithm is very competitive with some of the traditional recommendation algorithms and state-of-the-art neural network algorithms, especially in terms of the obtained rankings.},
  archive      = {J_IJMLC},
  author       = {Han, Di and Chen, Yijun and Zhang, Shuya},
  doi          = {10.1007/s13042-021-01409-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {357-369},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Implicit social recommendation algorithm based on multilayer fuzzy perception similarity},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Triple-g: A new MGRS and attribute reduction.
<em>IJMLC</em>, <em>13</em>(2), 337–356. (<a
href="https://doi.org/10.1007/s13042-021-01404-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different from classical rough set, Multigranulation Rough Set (MGRS) is frequently designed for approximating target through using multiple results of information granulation. Presently, though many forms of MGRS have been intensively explored, most of them are constructed based on the homogeneous information granulation with respect to different scales or levels. They lack the multi-view which involves the results of heterogeneous information granulation. To fill such a gap, a Triple-G MGRS is developed. Such a Triple-G is composed of three different heterogeneous information granulations: (1) neiGhborhood based information granulation; (2) Gap based information granulation; (3) Granular ball based information granulation. Neighborhood provides a parameterized mechanism while gap and granular ball offer two representative data-adaptive strategies for performing information granulation. Immediately, both optimistic and pessimistic MGRS can be re-constructed. Furthermore, the problem of attribute reduction is also addressed based on the proposed models. Not only the forward greedy searching is used for deriving the Triple-G MGRS related reducts, but also an attribute grouping based accelerator is reported for further speeding up the process of searching reducts. The experimental results over 20 UCI data sets demonstrate the follows: (1) from the viewpoint of the generalization performance, the reducts obtained by our Triple-G MGRS is superior to those obtained by previous researches; (2) attribute grouping does speed up the process of searching reducts.},
  archive      = {J_IJMLC},
  author       = {Ba, Jing and Liu, Keyu and Ju, Hengrong and Xu, Suping and Xu, Taihua and Yang, Xibei},
  doi          = {10.1007/s13042-021-01404-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {337-356},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Triple-G: A new MGRS and attribute reduction},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A self-adaptive harris hawks optimization algorithm with
opposition-based learning and chaotic local search strategy for global
optimization and feature selection. <em>IJMLC</em>, <em>13</em>(2),
309–336. (<a href="https://doi.org/10.1007/s13042-021-01326-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harris Hawks Optimization is a recently proposed algorithm inspired by the cooperative manner and chasing behavior of harris. However, from the experimental results, it can be noticed that HHO may fall in local optima or have a slow convergence curve in some complex optimization tasks. In this paper, an improved version of HHO called IHHO is proposed which enhances the performance of HHO by combining HHO with opposition-based learning (OBL), Chaotic Local Search (CLS), and a self-adaptive technique. In order to show the performance of the proposed algorithm, several experiments are conducted using the Standard IEEE CEC 2017 benchmark. IHHO is compared with the classical HHO and other 10 state-of-art algorithms. Moreover, IHHO is used to solve 5 constrained engineering problems. IHHO has also been applied to solve feature selection problem using 7 UCI dataset. The numerical results and analysis show the superiority of IHHO in solving real-world problems.},
  archive      = {J_IJMLC},
  author       = {Hussien, Abdelazim G. and Amin, Mohamed},
  doi          = {10.1007/s13042-021-01326-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {309-336},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A self-adaptive harris hawks optimization algorithm with opposition-based learning and chaotic local search strategy for global optimization and feature selection},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Fuzzy portfolio selection based on three-way decision and
cumulative prospect theory. <em>IJMLC</em>, <em>13</em>(1), 293–308. (<a
href="https://doi.org/10.1007/s13042-021-01402-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of fuzzy portfolio selection is to make a combination of securities which can maximize the return or minimize the risk. Most of existing studies assumed that the investor has all the cash in hand and no securities position before portfolio optimization, which is sometimes inconsistent to reality. Besides, many studies are based on expected utility theory, which is in conflict with the behavior of some investors and may also lead to over-concentration of capital. Therefore, in this paper, we propose a fuzzy portfolio selection model based on three-way decision and cumulative prospect theory, which can mitigate the two shortcomings mentioned above. In this model, every action in the action set to the candidate securities is assigned to a prospect value and we can construct a tri-partition of the candidate securities according to three-way decision theory. To validate the effectiveness of our approach, we adopted two case studies on the basis of real market data. The experimented results prove that the using of three-way decision and cumulative prospect theory increases the investment return, meanwhile, reduces the risk for the investor.},
  archive      = {J_IJMLC},
  author       = {Wang, Xianhe and Wang, Bo and Liu, Shu and Li, Huaxiong and Wang, Tianxing and Watada, Junzo},
  doi          = {10.1007/s13042-021-01402-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {293-308},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fuzzy portfolio selection based on three-way decision and cumulative prospect theory},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive coefficient-based kernelized network for
personalized activity recognition. <em>IJMLC</em>, <em>13</em>(1),
269–291. (<a href="https://doi.org/10.1007/s13042-021-01455-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) based on wearable devices has found wide applications in fitness, health care, etc. Given the personalized wearing styles of such devices and distinctive motion patterns, the activities of daily living normally vary from person to person in terms of strength, amplitude, speed, category, etc. The specialization of a universal HAR model to a specific subject without experiencing catastrophic forgetting is a significant challenge. In this paper, we propose a novel incremental learning method, namely, an adaptive coefficient-based kernelized and regularized network (KeRNet-AC), for personalized activity recognition. During the adaptation stage of the model training process, KeRNet-AC consistently monitors the probable ill-conditioned degree of the generated solution, which we believe is strongly correlated with the catastrophic forgetting problem, and automatically makes the solution well conditioned. To reduce the computational complexity of KeRNet-AC, we also introduce an active data selection principle into KeRNet-AC. This variation is called A-KeRNet-AC. To evaluate the performance of KeRNet-AC and A-KeRNet-AC, we conduct extensive experiments on five public activity datasets. The experimental results demonstrate that KeRNet-AC outperforms related state-of-the-art methods in most cases and that A-KeRNet-AC can quickly perform model training and activity prediction. Moreover, the performance of the proposed methods steadily improves during the adaptation stage and ultimately converges without degradation, demonstrating the strong potential of KeRNet-AC and A-KeRNet-AC for personalized activity recognition.},
  archive      = {J_IJMLC},
  author       = {Hu, Lisha and Hu, Chunyu and Jiang, Xinlong and Huo, Zheng},
  doi          = {10.1007/s13042-021-01455-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {269-291},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive coefficient-based kernelized network for personalized activity recognition},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain adaptive attention-based dropout for one-shot person
re-identification. <em>IJMLC</em>, <em>13</em>(1), 255–268. (<a
href="https://doi.org/10.1007/s13042-021-01399-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain person re-identification (re-ID) has attracted much attention due to its wide applications in the field of computer vision and surveillance. However, the domain shift issue leads to unsatisfactory generalization performance of a model on an unseen target domain when the model is trained on the source domain. Current methods usually adopt clustering methods to assign pseudo labels for unlabeled target images, resulting in high dependence on the performance of clustering method. In this paper, we firstly focus on extracting universal domain-adaptive features by designing a domain-adaptive-attention-based-dropout (DAAD) layer. DAAD layer is achieved by a universal attention-based dropout adapter (ADA) bank to hide the most discriminative region stochastically and a domain attention module to assign weights to the two domains (source and target). Then two feature memories are introduced according to one-shot learning in which only one image is annotated for each target identity. These two memories are designed to store target features from labeled and unlabeled images, respectively. The labeled feature memory is leveraged to estimate pseudo labels for these unlabeled images while the unlabeled feature memory aims to maximize distances between all the unlabeled images and minimize distances between similar images simultaneously. Extensive experiments on three re-ID datasets (DukeMTMC-reID, Market-1501, and MSMT17) demonstrate that the proposed model is effective to improve the domain adaptation performance than existing techniques.},
  archive      = {J_IJMLC},
  author       = {Song, Xulin and Jin, Zhong},
  doi          = {10.1007/s13042-021-01399-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {255-268},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Domain adaptive attention-based dropout for one-shot person re-identification},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view low rank sparse representation method for
three-way clustering. <em>IJMLC</em>, <em>13</em>(1), 233–253. (<a
href="https://doi.org/10.1007/s13042-021-01394-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the past years, multi-view clustering algorithms have demonstrated satisfactory clustering results by fusing the multiple views of the dataset. Nowadays, the researches of dimensionality reduction and learning discriminative features from multi-view data have soared in the literatures. As for clustering, generating the suitable subspace of the high dimensional multi-view data is crucial to boost the clustering performance. In addition, the relationship between the original data and the clusters still remains uncovered. In this article, we design a new multi-view low rank sparse representation method based on three-way clustering to tackle these challenges, which derive the common consensus low dimensional representation from the multi-view data and further proceed to get the relationship between the data items and clusters. Specifically, we accomplish this goal by taking advantage of the low-rank and the sparse factor on the data representation matrix. The $$L_{2,1}$$ norm is imposed on error matrix to reduce the impact of noise contained in the data. Finally, a new objective function is constructed to preserve the consistency between the views by using the low-rank sparse representation technique. The weighted low-rank matrix is utilized to build the consensus low rank matrix. Then, the whole objective function is optimized by using the Augmented Lagrange’s Multiplier algorithm. Further, to find the uncertain relationship between the data items and the clusters, we pursue the neighborhood based three-way clustering technique to reflect the data items into core and fringe regions. Experiments conducted on the real-world datasets show the superior performance of the proposed method compared with the state-of-the-art algorithms.},
  archive      = {J_IJMLC},
  author       = {Khan, Ghufran Ahmad and Hu, Jie and Li, Tianrui and Diallo, Bassoma and Zhao, Yimiao},
  doi          = {10.1007/s13042-021-01394-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {233-253},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-view low rank sparse representation method for three-way clustering},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Do gradient-based explanations tell anything about
adversarial robustness to android malware? <em>IJMLC</em>,
<em>13</em>(1), 217–232. (<a
href="https://doi.org/10.1007/s13042-021-01393-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While machine-learning algorithms have demonstrated a strong ability in detecting Android malware, they can be evaded by sparse evasion attacks crafted by injecting a small set of fake components, e.g., permissions and system calls, without compromising intrusive functionality. Previous work has shown that, to improve robustness against such attacks, learning algorithms should avoid overemphasizing few discriminant features, providing instead decisions that rely upon a large subset of components. In this work, we investigate whether gradient-based attribution methods, used to explain classifiers’ decisions by identifying the most relevant features, can be used to help identify and select more robust algorithms. To this end, we propose to exploit two different metrics that represent the evenness of explanations, and a new compact security measure called Adversarial Robustness Metric. Our experiments conducted on two different datasets and five classification algorithms for Android malware detection show that a strong connection exists between the uniformity of explanations and adversarial robustness. In particular, we found that popular techniques like Gradient*Input and Integrated Gradients are strongly correlated to security when applied to both linear and nonlinear detectors, while more elementary explanation techniques like the simple Gradient do not provide reliable information about the robustness of such classifiers.},
  archive      = {J_IJMLC},
  author       = {Melis, Marco and Scalas, Michele and Demontis, Ambra and Maiorca, Davide and Biggio, Battista and Giacinto, Giorgio and Roli, Fabio},
  doi          = {10.1007/s13042-021-01393-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {217-232},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Do gradient-based explanations tell anything about adversarial robustness to android malware?},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Kernel risk-sensitive mean p-power error based robust
extreme learning machine for classification. <em>IJMLC</em>,
<em>13</em>(1), 199–216. (<a
href="https://doi.org/10.1007/s13042-021-01391-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, extreme learning machine (ELM) has attracted a lot of attention due to its high performance and extreme speed. However, how to improve the robustness of ELM has always been a problem. Considering the problems of noise and outliers in the experimental data, in this paper, we introduce the kernel risk-sensitive mean p-power error (KRP) into ELM and propose a robust ELM method named kernel risk-sensitive mean p-power error based robust extreme learning machine (KRPELM), on the basis of the high efficiency and robustness of KRP. In KRPELM, KRP function instead of square loss is integrated into ELM as the loss function, which can improve the robustness of ELM to noise and outliers. We also propose an efficient iterative adjustment strategy to optimize KRPELM. Nine benchmark datasets are utilized to verify the classification performance of the proposed KRPELM. In addition, we apply the proposed method to the classification of cancer samples. The experimental results on five cancer gene expression datasets show that KRPELM can identify different cancer types more accurately.},
  archive      = {J_IJMLC},
  author       = {Ren, Liang-Rui and Gao, Ying-Lian and Shang, Junliang and Liu, Jin-Xing},
  doi          = {10.1007/s13042-021-01391-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {199-216},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Kernel risk-sensitive mean p-power error based robust extreme learning machine for classification},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tradeoff-optimal-controller based on compact fuzzy
data-driven model and multi-gradient learning. <em>IJMLC</em>,
<em>13</em>(1), 187–198. (<a
href="https://doi.org/10.1007/s13042-021-01388-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A substantial change of the control direction is observed for the prototyping inner-loop-torque control of robotic systems. To deal with this problem, the fuzzy data-driven model (FDM) is utilized in the switchable control direction by a multi-input fuzzy rule emulated network (MiFREN). The multi-gradient leaning scheme is developed to tune all adjustable parameters of MiFREN with the convergence analysis. The adaptive control law is synthesized by the approximated optimal controller when the tracking performance and the control energy minimization can be compromised by two designed parameters. The performance validation is conducted on the experimental system and results.},
  archive      = {J_IJMLC},
  author       = {Treesatayapun, C.},
  doi          = {10.1007/s13042-021-01388-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {187-198},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Tradeoff-optimal-controller based on compact fuzzy data-driven model and multi-gradient learning},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning discriminative feature via a generic auxiliary
distribution for unsupervised domain adaptation. <em>IJMLC</em>,
<em>13</em>(1), 175–185. (<a
href="https://doi.org/10.1007/s13042-021-01381-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional methods for unsupervised domain adaptation often leverage a projection matrix or a neural network as the feature extractor or classifier, where the feature extractor shared by the source and target domains enables the sample distributions to be aligned in the feature space, and simultaneously makes the source domain features separability enough for the classifier. However, only the alignment of both domains is not enough because the inter-class distance of some categories in the target domain may be too small, i.e., the feature separability is poor, which often leads to the bad condition that some samples are projected to the classification boundaries and thus misclassified. To solve this problem, we propose a pluggable generic auxiliary distribution (GAD) module for target domain in this paper. The proposed GAD module can iteratively refine the prediction of the target domain samples to increase the separability of the learned features, thereby increasing the distance between features of different categories. This operation can finally reduce the possibility of the target domain samples falling near the classification boundary, and leads to the improvement of classification accuracy for the target domain. Extensive experiments on several popular datasets are conducted, and the results demonstrate the effectiveness of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Chen, Qipeng and Zhang, Haofeng and Ye, Qiaolin and Zhang, Zheng and Yang, Wankou},
  doi          = {10.1007/s13042-021-01381-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {175-185},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning discriminative feature via a generic auxiliary distribution for unsupervised domain adaptation},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A model of three-way approximation of intuitionistic fuzzy
sets. <em>IJMLC</em>, <em>13</em>(1), 163–174. (<a
href="https://doi.org/10.1007/s13042-021-01380-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A three-way approximation of a fuzzy set, as a generalization of the core and the support of the fuzzy set, provides a generalized qualitatively interpretation of a fuzzy set. An intuitionistic fuzzy set (IFS) generalizes a fuzzy set by using jointly a membership function and a nonmembership function. In this paper, we present a model for constructing a three-way approximation of an IFS according to the TAO (trisecting-acting-outcome) framework of three-way decision (3WD). Given an IFS, we use its membership and nonmembership functions as a pair of evaluations to trisect a universe of objects to produce a three-way approximation of the IFS. We present a general optimization model for determining the required parameters according to the principle of the minimum cost with respect to a distance function and costs of three actions. We use Manhattan distance to illustrate the basic ideas of the optimization model.},
  archive      = {J_IJMLC},
  author       = {Yang, Jilin and Yao, Yiyu and Zhang, Xianyong},
  doi          = {10.1007/s13042-021-01380-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {163-174},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A model of three-way approximation of intuitionistic fuzzy sets},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Seasonal decomposition and combination model for short-term
forecasting of subway ridership. <em>IJMLC</em>, <em>13</em>(1),
145–162. (<a href="https://doi.org/10.1007/s13042-021-01377-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The subway ridership is related with the social activities, such as, commuting, festival, holiday, and so on, which makes the time series of subway ridership presents seasonal characteristic. This characteristic inspires us to decompose the time series into a seasonal component and an epoch component, and employ a combination forecasting method to estimate the future ridership. We first transform the raw ridership into a time series matrix, then decompose the ridership into a seasonal component and an epoch component, and at last combine the individual forecasting results of the seasonal component and the epoch component to make forecast. Contributions of this paper include formulating the combination forecasting problem as an optimization problem, proposing an In-Sample Algorithm (ISA) and an Out-of-Sample Algorithm (OSA), and conducting extensive experiments based on the individual forecasting model named Auto Regressive Integrated Moving Average (ARIMA) model and the data provided by Chongqing Rail Transit. We prove that the decomposition and combination forecasting model possesses smallest variance than individual forecasting models from the theory aspect. The experiments further demonstrate that the ISA algorithm can effectively fit original ridership time series and the OSA algorithm can make better forecasting performance than individual forecasting models. Most importantly, the ISA algorithm and the OSA algorithm both possess advantages of smaller forecasting error deviation and smaller absolute forecasting errors.},
  archive      = {J_IJMLC},
  author       = {Tang, Jiqiang and Zuo, Ankang and Liu, Jian and Li, Tianrui},
  doi          = {10.1007/s13042-021-01377-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {145-162},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Seasonal decomposition and combination model for short-term forecasting of subway ridership},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Few-shot learning with deep balanced network and
acceleration strategy. <em>IJMLC</em>, <em>13</em>(1), 133–144. (<a
href="https://doi.org/10.1007/s13042-021-01373-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep networks are widely used in few-shot learning methods, but deep networks suffer from large-scale network parameters and computational effort. Aiming at the above problems, we present a novel few-shot learning method with deep balanced network and acceleration strategy. Firstly, a series of simple linear operations are applied to few original features to obtain the more features. More features are obtained with fewer parameters, thus reducing the network parameters and computational effort. Then the local cross-channel interaction mechanism without dimensionality reduction is used to further improve the performance with nearly no increase in parameters and computational effort, so as to obtain a deep balanced network to balance performance, parameters, and computational effort. Finally, an acceleration strategy is designed to solve the problem that the gradient update in the deep network takes a tremendous amount of time in new tasks, speeding up the adaptation process. The experimental results of traditional and fine-grained image classification show that the few-shot learning method with deep balanced network can achieve or even exceed the classification accuracy of some existing methods with fewer network parameters and computational effort. The cross-domain experiments further demonstrate the advantages of the method above the domain shift. Simultaneously, the time required for classification in new tasks can be significantly decreased by using the acceleration strategy.},
  archive      = {J_IJMLC},
  author       = {Wang, Kang and Wang, Xuesong and Zhang, Tong and Cheng, Yuhu},
  doi          = {10.1007/s13042-021-01373-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {133-144},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Few-shot learning with deep balanced network and acceleration strategy},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical multilabel classification by exploiting label
correlations. <em>IJMLC</em>, <em>13</em>(1), 115–131. (<a
href="https://doi.org/10.1007/s13042-021-01371-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical multilabel classification (HMC) aims to classify the complex data such as text with multiple topics and image with multiple semantics, in which the multiple labels are organized in hierarchical structures such as trees and direct acyclic graphs (DAG). To reduce the computational complexity, HMC methods generally assume that the class labels of different branches in a hierarchical structure are conditional independent. However, these class-independent HMC methods neglect the correlation between labels and thereby the precision of classification is affected. To tackle the problem, in this paper we propose a hierarchical multilabel classification method with class label correlation (HMC-CLC) which exploits the label correlations of different branches to benefit the discrimination of HMC. Specifically, in the training stage, for each label in the hierarchy, we use feature incremental learning to encode the labels of different branches into the input space. Based on this, the label correlations of different branches are reflected by the weights of classification model in corresponding dimensions. Then in the test stage, considering that the different samples have different label distributions, we propose a greedy label selection method to dynamically decide the correlated labels of different branches for each label. Therefore, for the same label in the hierarchy, the correlated labels could be different in different samples. Experimental results on a number of real-world data sets show that the proposed method outperforms the state-of-the-art HMC methods.},
  archive      = {J_IJMLC},
  author       = {Xu, Zhikang and Zhang, Bofeng and Li, Deyu and Yue, Xiaodong},
  doi          = {10.1007/s13042-021-01371-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {115-131},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hierarchical multilabel classification by exploiting label correlations},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Democratic three-way decisions based on voting mechanism.
<em>IJMLC</em>, <em>13</em>(1), 99–114. (<a
href="https://doi.org/10.1007/s13042-021-01367-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some cases, the decision process of three-way decisions (3WD) is costly, and sequential three-way decisions (S3WD) may cause errors beyond tolerance. To solve the above problems, in this paper, democratic three-way decisions based on voting mechanism (D3WD-VM) is proposed from the perspective of all conditional attributes. By obtaining decision opinions of different attributes at the coarse granularity level, the final decision results is obtained. First, a voting mechanism is established to realize the idea of the democratic three-way, which is an ensemble decision space based on conditional attributes. Next, in order to make the decision results more reasonable, the normalized information gain ratio is utilized to optimize the voting weight of conditional attributes in the voting mechanism. Then, based on cognitive science, two different decision strategies are devised to make the final decision. Finally, the experimental results demonstrate that the accuracy rate and the comprehensive evaluation index of the D3WD-VM have also been improved to some extent compared with the S3WD, and the decision efficiency is better than 3WD.},
  archive      = {J_IJMLC},
  author       = {Zhang, Qinghua and Zhi, Xuechao and Dai, Yongyang and Wang, Guoyin},
  doi          = {10.1007/s13042-021-01367-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {99-114},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Democratic three-way decisions based on voting mechanism},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Linguistic-valued layered concept lattice and its rule
extraction. <em>IJMLC</em>, <em>13</em>(1), 83–98. (<a
href="https://doi.org/10.1007/s13042-021-01351-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal concept analysis as an effective tool for data analysis and knowledge acquisition can be used to describe the potential relation between objects and attributes. In order to handle linguistic uncertainty information with comparability and incomparability, we propose a kind of linguistic-valued formal concept analysis approach based on lattice implication algebra. Firstly, by setting different linguistic-valued trust degrees, we put forward a linguistic-valued layered concept lattice for meeting the requirements of different experts at different levels. Secondly, the rule extraction algorithm of the linguistic-valued layered concept lattice with the trust degree is given to acquire non-redundant linguistic-valued rules with different trust degrees by using the linguistic-valued weakly consistent formal decision context. Then, aiming at the same premise or conclusion for the different rules, we adopt the deleting or uniting strategy to deal with the redundant rules. The updated and simplified rules can make the rule acquisition easier and the linguistic-valued decision rules extracted are more compact. Finally, the effectiveness and practicability of the proposed approach are illustrated by the comparison analysis.},
  archive      = {J_IJMLC},
  author       = {Zou, Li and Kang, Ning and Che, Lu and Liu, Xin},
  doi          = {10.1007/s13042-021-01351-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {83-98},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Linguistic-valued layered concept lattice and its rule extraction},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of the number of students taking make-up
examinations using artificial neural networks. <em>IJMLC</em>,
<em>13</em>(1), 71–81. (<a
href="https://doi.org/10.1007/s13042-021-01348-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three different examinations for any course are primarily defined in higher education in Turkey: midterm, final and make-up exams. Whether a student has passed a course is decided by using the scores of midterm and final exams. If this student fails the course as a result of these exams, he can take a make-up exam of this course, and the score of the make-up exam is replaced with the final exam. However, some of the students do not take the make-up exam although it is expected that they take the make-up exam, due to different reasons such as average score, distance, low score of midterm exam, etc. Because the make-up exam plans and schedule have been performed in accordance with the number of students who failed the course, some resources such as the number of classrooms, invigilators, exam papers, toner are wasted. In order to reduce these wastages, we applied artificial neural networks, ANN, trained by different approaches for predicting the number of students taking make-up examinations in this study. In the proposed framework, some features of students and courses have been determined, the data has been collected and ANNs have been trained on these datasets. By using the trained ANNs, each student who fails the course is classified as positive (taking the make-up exam) or negative (not taking the make-up exam). In the experiments, the data of ten different courses are used for training ANNs by random weight network, error back propagation algorithm, some metaheuristic algorithms such as grey wolf optimizer, artificial bee colony, particle swarm optimization, ant colony optimization, etc. The performances of the trained ANNs have been compared with each other by considering training accuracy, testing accuracy, training time. BP achieves the best mean training accuracy on both unnormalized and normalized datasets with 99.36\% and 99.7\%, respectively. GWO achieves the best mean testing accuracy on both unnormalized and normalized datasets with 80.39\% and 82.39\%, respectively. Moreover, RWN has the best running time of less than a second for training the ANN on both normalized and unnormalized datasets. The experiments and comparisons show that an ANN-based classifier can be used for determining the number of students taking the make-up exam.},
  archive      = {J_IJMLC},
  author       = {Kiran, Mustafa Servet and Siramkaya, Eyup and Esme, Engin and Senkaya, Miyase Nur},
  doi          = {10.1007/s13042-021-01348-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {71-81},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Prediction of the number of students taking make-up examinations using artificial neural networks},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensemble of feature selection algorithms: A multi-criteria
decision-making approach. <em>IJMLC</em>, <em>13</em>(1), 49–69. (<a
href="https://doi.org/10.1007/s13042-021-01347-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the first time, the ensemble feature selection is modeled as a Multi-Criteria Decision-Making (MCDM) process in this paper. For this purpose, we used the VIKOR method as a famous MCDM algorithm to rank the features based on the evaluation of several feature selection methods as different decision-making criteria. Our proposed method, EFS-MCDM, first obtains a decision matrix using the ranks of every feature according to various rankers. The VIKOR approach is then used to assign a score to each feature based on the decision matrix. Finally, a rank vector for the features generates as an output in which the user can select a desired number of features. We have compared our approach with some ensemble feature selection methods using feature ranking strategy and basic feature selection algorithms to illustrate the proposed method&#39;s optimality and efficiency. The results show that our approach in terms of accuracy, F-score, and algorithm run-time is superior to other similar methods and performs in a short time, and it is more efficient than the other methods.},
  archive      = {J_IJMLC},
  author       = {Hashemi, Amin and Dowlatshahi, Mohammad Bagher and Nezamabadi-pour, Hossein},
  doi          = {10.1007/s13042-021-01347-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {49-69},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Ensemble of feature selection algorithms: A multi-criteria decision-making approach},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PointCSE: Context-sensitive encoders for efficient 3D object
detection from point cloud. <em>IJMLC</em>, <em>13</em>(1), 39–47. (<a
href="https://doi.org/10.1007/s13042-021-01342-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few modern 3D object detectors achieve fast inference speed and high accuracy at the same time. To achieve high performance, they usually directly operate on raw point clouds, or convert point clouds to 3D representation and then apply 3D convolution. However, those methods come with sizable computation overhead and complex operations. As for high-speed 2D-representation-based 3D detectors, their performance is still restricted. In this paper, we investigate how to leverage context knowledge to empower the 2D representation of point clouds for computation and memory-efficient 3D object detection with state-of-the-art performance. The proposed encoder has two parts: a context-sensitive point sampling network and a point set learning network. Specifically, our point sampling network samples points with dense localization information. With high-quality sampled points, we are allowed to utilize a deeper point set learning network to aggregate semantic details in a light manner. The proposed encoder is lightweight and very supportive of hardware acceleration like TensorRT and TVM. Extensive experiments on the KITTI benchmark show the proposed encoder called PointCSE outperforms prior real-time encoders by a large margin with 1.5 $$\times$$ memory reduction; it also achieves state-of-the-art performance with 49 FPS inference speed (4 $$\times$$ speedup on average compared to previous best methods).},
  archive      = {J_IJMLC},
  author       = {Wu, Kuoliang and Xu, Guodong and Liu, Zili and Liu, Haifeng and Cai, Deng and He, Xiaofei},
  doi          = {10.1007/s13042-021-01342-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {39-47},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {PointCSE: Context-sensitive encoders for efficient 3D object detection from point cloud},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Accelerating ReliefF using information granulation.
<em>IJMLC</em>, <em>13</em>(1), 29–38. (<a
href="https://doi.org/10.1007/s13042-021-01334-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an essential preprocessing requirement when solving a classification problem. In this respect, the Relief algorithm and its derivatives have been demonstrated to be a class of successful feature selectors. However, the computational cost of these algorithms is very high when large-scale datasets are processed. To solve this problem, we propose the fast ReliefF algorithm based on the information granulation of instances (IG-FReliefF). The algorithm uses K-means to granulate the dataset and selects the significant granules among them using the criteria defined by information entropy and information granulation, and then evaluates each feature on the dataset composed of the selected granules. Extensive experiments show that the proposed algorithm is more efficient than the existing representative algorithms, especially on large-scale data sets, and the proposed algorithm is almost the same as the comparison algorithm in terms of classification performance.},
  archive      = {J_IJMLC},
  author       = {Wei, Wei and Wang, Da and Liang, Jiye},
  doi          = {10.1007/s13042-021-01334-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {29-38},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Accelerating ReliefF using information granulation},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stability analysis of incremental concept tree for concept
cognitive learning. <em>IJMLC</em>, <em>13</em>(1), 11–28. (<a
href="https://doi.org/10.1007/s13042-021-01332-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incremental concept cognitive learning is an emerging active issue that concerning incremental concept learning and dynamic knowledge processing in the dynamic context environments. As the development of that, how to measure the stability of a concept structure in the view of concept cognitive learning has become an urgent issue need to be solved. Motivated by that, we propose a method to analyze the stability of incremental concept tree (ICT) for concept cognitive learning. First, the incremental concept cognitive learning process is visualized in the form of ICT, and then the structure similarity based on concept subtree and the node similarity based on concept importance are carried out to measure the similarity along the evolution of ICT. At last, the global similarity of ICT is obtained by integrating these two similarity measurements by the regulatory factor according to different scenarios. Some numerical experiments compared with classical tree similarity algorithm were conducted to evaluate the effectiveness of our method. The results show that our method is effective to analyze the stability of concept cognitive learning by measuring the similar of ICT and promising to expand it to the field of incremental concept cognitive learning.},
  archive      = {J_IJMLC},
  author       = {Zhang, Tao and Rong, Mei and Shan, Haoran and Liu, Mingxin},
  doi          = {10.1007/s13042-021-01332-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {11-28},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Stability analysis of incremental concept tree for concept cognitive learning},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Triplet-object loss for large scale deep image retrieval.
<em>IJMLC</em>, <em>13</em>(1), 1–9. (<a
href="https://doi.org/10.1007/s13042-021-01330-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep hashing has been widely applied in large scale image retrieval due to its high computation efficiency and retrieval performance. Recently, training deep hashing networks with a triplet ranking loss become a common framework. However, most of the triplet ranking loss based deep hashing methods cannot obtain satisfactory retrieval performance due to their ignoring the relative similarities among the objects. In this paper, we propose a method to learn the discriminative object features and utilize these features to compute the adaptive margins of the proposed loss for learning powerful hash codes. Experimental results show that our learned hash codes can yield state-of-the-art retrieval performance on three challenging datasets},
  archive      = {J_IJMLC},
  author       = {Zhu, Jie and Shu, Yang and Zhang, Junsan and Wang, Xuanye and Wu, Shufang},
  doi          = {10.1007/s13042-021-01330-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {1-9},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Triplet-object loss for large scale deep image retrieval},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
