<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Constr_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="constr---17">Constr - 17</h2>
<ul>
<li><details>
<summary>
(2022). An algorithm-independent measure of progress for linear
constraint propagation. <em>Constr</em>, <em>27</em>(4), 432–455. (<a
href="https://doi.org/10.1007/s10601-022-09338-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Propagation of linear constraints has become a crucial sub-routine in modern Mixed-Integer Programming (MIP) solvers. In practice, iterative algorithms with tolerance-based stopping criteria are used to avoid problems with slow or infinite convergence. However, these heuristic stopping criteria can pose difficulties for fairly comparing the efficiency of different implementations of iterative propagation algorithms in a real-world setting. Most significantly, the presence of unbounded variable domains in the problem formulation makes it difficult to quantify the relative size of reductions performed on them. In this work, we develop a method to measure—independently of the algorithmic design—the progress that a given iterative propagation procedure has made at a given point in time during its execution. Our measure makes it possible to study and better compare the behavior of bounds propagation algorithms for linear constraints. We apply the new measure to answer two questions of practical relevance: (i) We investigate to what extent heuristic stopping criteria can lead to premature termination on real-world MIP instances. (ii) We compare a GPU-parallel propagation algorithm against a sequential state-of-the-art implementation and show that the parallel version is even more competitive in a real-world setting than originally reported.},
  archive      = {J_Constr},
  author       = {Sofranac, Boro and Gleixner, Ambros and Pokutta, Sebastian},
  doi          = {10.1007/s10601-022-09338-9},
  journal      = {Constraints},
  month        = {12},
  number       = {4},
  pages        = {432-455},
  shortjournal = {Constraints},
  title        = {An algorithm-independent measure of progress for linear constraint propagation},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Short- and medium-term optimization of underground mine
planning using constraint programming. <em>Constr</em>, <em>27</em>(4),
414–431. (<a href="https://doi.org/10.1007/s10601-022-09337-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few years, the mining industry has seen a lot of operational changes. Digitalization and automation of many processes have paved the way for an increase in its general productivity. In keeping with this trend, this article presents a novel approach for optimizing underground mine scheduling for the short- and medium-term. This problem is similar to the Resource-Constrained Project Scheduling Problem, with the difference that all task completions are optional. The model uses Constraint Programming principles to maximize the Net Present Value of a mining project. It plans work shifts for up to a year in advance, considering specialized equipment, rock support and operational constraints. This is the first published paper using optional variables to model optional tasks in a real-life application. Results from its applications to datasets based on a Canadian gold mine demonstrate its ability to find optimal solutions in a reasonable time. A comparison with an equivalent Mixed Integer Programing model proves that the Constraint Programming approach offers clear gains in terms of computability and readability of the constraints.},
  archive      = {J_Constr},
  author       = {Campeau, Louis-Pierre and Gamache, Michel},
  doi          = {10.1007/s10601-022-09337-w},
  journal      = {Constraints},
  month        = {12},
  number       = {4},
  pages        = {414-431},
  shortjournal = {Constraints},
  title        = {Short- and medium-term optimization of underground mine planning using constraint programming},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solution sampling with random table constraints.
<em>Constr</em>, <em>27</em>(4), 381–413. (<a
href="https://doi.org/10.1007/s10601-022-09329-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constraint programming provides generic techniques to efficiently solve combinatorial problems. In this paper, we tackle the natural question of using constraint solvers to sample combinatorial problems in a generic way. We propose an algorithm, inspired from Meel’s ApproxMC algorithm on SAT, to add hashing constraints to a CP model in order to split the search space into small cells. By uniformly sampling the solutions in one cell, we can generate random solutions without revamping the model of the problem. We ensure the randomness by introducing a new family of hashing constraints: randomly generated tables, which keeps the cost of the hashing process tractable. We implemented this solving method using the constraint solver Choco-solver. The quality of the randomness and the running time of our approach are experimentally compared to a random branching strategy. We show that our approach improves the randomness while being in the same order of magnitude in terms of running time. We also use our algorithm with an other, more powerful, set of hashing constraints: linear modular equalities. We experimentally show that the resulting sampling is uniform, at the cost of a longer running time.},
  archive      = {J_Constr},
  author       = {Vavrille, Mathieu and Truchet, Charlotte and Prud’homme, Charles},
  doi          = {10.1007/s10601-022-09329-w},
  journal      = {Constraints},
  month        = {12},
  number       = {4},
  pages        = {381-413},
  shortjournal = {Constraints},
  title        = {Solution sampling with random table constraints},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Boosting isomorphic model filtering with invariants.
<em>Constr</em>, <em>27</em>(3), 360–379. (<a
href="https://doi.org/10.1007/s10601-022-09336-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The enumeration of finite models is very important to the working discrete mathematician (algebra, graph theory, etc) and hence the search for effective methods to do this task is a critical goal in discrete computational mathematics. However, it is hindered by the possible existence of many isomorphic models, which usually only add noise. Typically, they are filtered out a posteriori, a step that might take a long time just to discard redundant models. This paper proposes a novel approach to split the generated models into mutually non-isomorphic blocks. To do that we use well-designed hand-crafted invariants as well as randomly generated invariants. The blocks are then tackled separately and possibly in parallel. This approach is integrated into Mace4 (the most popular tool among mathematicians) where it shows tremendous speed-ups for a large variety of algebraic structures.},
  archive      = {J_Constr},
  author       = {Araújo, João and Chow, Choiwah and Janota, Mikoláš},
  doi          = {10.1007/s10601-022-09336-x},
  journal      = {Constraints},
  month        = {7},
  number       = {3},
  pages        = {360-379},
  shortjournal = {Constraints},
  title        = {Boosting isomorphic model filtering with invariants},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Propagation complete encodings of smooth DNNF theories.
<em>Constr</em>, <em>27</em>(3), 327–359. (<a
href="https://doi.org/10.1007/s10601-022-09331-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate conjunctive normal form (CNF) encodings of a function represented with a decomposable negation normal form (DNNF). Several encodings of DNNFs and decision diagrams were considered by (Abío et al., 2016). The authors differentiate between encodings which implement consistency or domain consistency by unit propagation from encodings which are unit refutation complete or propagation complete. The difference is that in the former case we do not care about propagation strength of the encoding with respect to the auxiliary variables while in the latter case we treat all variables (the main and the auxiliary ones) in the same way. The currently known encodings of DNNF theories implement domain consistency. Building on these encodings we generalize the result of (Abío et al., 2016) on a propagation complete encoding of decision diagrams and present a propagation complete encoding of a DNNF and its generalization for variables with finite domains.},
  archive      = {J_Constr},
  author       = {Kučera, Petr and Savický, Petr},
  doi          = {10.1007/s10601-022-09331-2},
  journal      = {Constraints},
  month        = {7},
  number       = {3},
  pages        = {327-359},
  shortjournal = {Constraints},
  title        = {Propagation complete encodings of smooth DNNF theories},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast and parallel decomposition of constraint satisfaction
problems. <em>Constr</em>, <em>27</em>(3), 284–326. (<a
href="https://doi.org/10.1007/s10601-022-09332-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constraint Satisfaction Problems (CSP) are notoriously hard. Consequently, powerful decomposition methods have been developed to overcome this complexity. However, this poses the challenge of actually computing such a decomposition for a given CSP instance, and previous algorithms have shown their limitations in doing so. In this paper, we present a number of key algorithmic improvements and parallelisation techniques to compute so-called Generalized Hypertree Decompositions (GHDs) faster. We thus advance the ability to compute optimal (i.e., minimal-width) GHDs for a significantly wider range of CSP instances on modern machines. This lays the foundation for more systems and applications in evaluating CSPs and related problems (such as Conjunctive Query answering) based on their structural properties.},
  archive      = {J_Constr},
  author       = {Gottlob, Georg and Okulmus, Cem and Pichler, Reinhard},
  doi          = {10.1007/s10601-022-09332-1},
  journal      = {Constraints},
  month        = {7},
  number       = {3},
  pages        = {284-326},
  shortjournal = {Constraints},
  title        = {Fast and parallel decomposition of constraint satisfaction problems},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A collection of constraint programming models for the
three-dimensional stable matching problem with cyclic preferences.
<em>Constr</em>, <em>27</em>(3), 249–283. (<a
href="https://doi.org/10.1007/s10601-022-09335-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce five constraint models for the 3-dimensional stable matching problem with cyclic preferences and study their relative performances under diverse configurations. While several constraint models have been proposed for variants of the two-dimensional stable matching problem, we are the first to present constraint models for a higher number of dimensions. We show for all five models how to capture two different stability notions, namely weak and strong stability. Additionally, we translate some well-known fairness notions (i.e. sex-equal, minimum regret, egalitarian) into 3-dimensional matchings, and present how to capture them in each model. Our tests cover dozens of problem sizes and four different instance generation methods. We explore two levels of commitment in our models: one where we have an individual variable for each agent (individual commitment), and another one where the determination of a variable involves pairing the three agents at once (group commitment). Our experiments show that the suitability of the commitment depends on the type of stability we are dealing with, and that the choice of the search heuristic can help improve performance. Our experiments not only brought light to the role that learning and restarts can play in solving this kind of problems, but also allowed us to discover that in some cases combining strong and weak stability leads to reduced runtimes for the latter.},
  archive      = {J_Constr},
  author       = {Cseh, Ágnes and Escamocher, Guillaume and Genç, Begüm and Quesada, Luis},
  doi          = {10.1007/s10601-022-09335-y},
  journal      = {Constraints},
  month        = {7},
  number       = {3},
  pages        = {249-283},
  shortjournal = {Constraints},
  title        = {A collection of constraint programming models for the three-dimensional stable matching problem with cyclic preferences},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). How constraint programming can help chemists to generate
benzenoid structures and assess the local aromaticity of benzenoids.
<em>Constr</em>, <em>27</em>(3), 192–248. (<a
href="https://doi.org/10.1007/s10601-022-09328-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benzenoids are a subfamily of hydrocarbons (molecules that are only made of hydrogen and carbon atoms) whose carbon atoms form hexagons. These molecules are widely studied in theoretical chemistry and have a lot of concrete applications. Then, there is a lot of problems relative to this subject, like the enumeration of all its Kekulé structures (i.e. all valid configurations of double bonds). In this article, we focus our attention on two issues: the generation of benzenoid structures and the assessment of the local aromaticity. On the one hand, generating benzenoids that have certain structural and/or chemical properties (e.g. having a given number of hexagons or a particular structure from a graph viewpoint) is an interesting and important problem. It constitutes a preliminary step for studying their chemical properties. In this paper, we show that modeling this problem in Choco Solver and just letting its search engine generate the solutions is a fast enough and very flexible approach. It can allow to generate many different kinds of benzenoids with predefined structural properties by posting new constraints, saving the efforts of developing bespoke algorithmic methods for each kind of benzenoids. On the other hand, we want to assess the local aromaticity of a given benzenoid. This is a central issue in theoretical chemistry since aromaticity cannot be measured. Nowadays, computing aromaticity requires quantum chemistry calculations that are too expensive to be used on medium to large-sized molecules. In this article, we describe how constraint programming can be useful in order to assess the aromaticity of benzenoids. Moreover, we show that our method is much faster than the reference one, namely NICS.},
  archive      = {J_Constr},
  author       = {Carissan, Yannick and Hagebaum-Reignier, Denis and Prcovic, Nicolas and Terrioux, Cyril and Varet, Adrien},
  doi          = {10.1007/s10601-022-09328-x},
  journal      = {Constraints},
  month        = {7},
  number       = {3},
  pages        = {192-248},
  shortjournal = {Constraints},
  title        = {How constraint programming can help chemists to generate benzenoid structures and assess the local aromaticity of benzenoids},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generative magic and designing magic performances with
constraint programming. <em>Constr</em>, <em>27</em>(3), 168–191. (<a
href="https://doi.org/10.1007/s10601-022-09334-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Professional magicians employ the use of interesting properties of a deck of cards to create magical effects. These properties were traditionally discovered through trial and error, the application of heuristics or analytical proofs. Those proofs come from diverse mathematical areas such as the set, number and graph theory. We discuss the limitations of relying on humans for such methods and present how professional magicians can use constraint programming as a computer-aided design tool (CAD) to search for desired properties in a deck of cards. Furthermore, we implement a solution in Python by making use of generative magic to design a new effect, demonstrating how this process broadens the level of freedom a magician can decree to their volunteers while retaining control of the outcomes of the magic. Finally, we demonstrate that the model can be easily adapted to multiple languages by presenting multiple variations of the effect supporting American English and Brazilian Portuguese.},
  archive      = {J_Constr},
  author       = {de Azevedo Silveira, Guilherme},
  doi          = {10.1007/s10601-022-09334-z},
  journal      = {Constraints},
  month        = {7},
  number       = {3},
  pages        = {168-191},
  shortjournal = {Constraints},
  title        = {Generative magic and designing magic performances with constraint programming},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). When bounds consistency implies domain consistency for
regular counting constraints. <em>Constr</em>, <em>27</em>(3), 161–167.
(<a href="https://doi.org/10.1007/s10601-022-09333-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finite automata with counters are often used to specify families of constraints. The addition of counters provides more power than membership in regular languages that is possible with finite automata. All available propagation algorithms for counter automata based constraints maintain only bounds consistency on counter variables, and although it is possible to maintain domain consistency it can be computationally very costly. In this paper we give an algorithm that decides when maintaining bounds consistency for an automata with a single counter implies domain consistency.},
  archive      = {J_Constr},
  author       = {Martin, Barnaby and Pearson, Justin},
  doi          = {10.1007/s10601-022-09333-0},
  journal      = {Constraints},
  month        = {7},
  number       = {3},
  pages        = {161-167},
  shortjournal = {Constraints},
  title        = {When bounds consistency implies domain consistency for regular counting constraints},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A constraint-based approach to learn temporal features on
action models from multiple plans. <em>Constr</em>, <em>27</em>(1),
134–160. (<a href="https://doi.org/10.1007/s10601-022-09330-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning in AI planning tries to recognize past conducts to predict features that help improve action models. We propose a constraint programming approach for learning the temporal features, i.e., the distribution of conditions/effects and durations, of actions in an expressive temporal planning model with overlapping actions, which makes it suitable for knowledge-based multi-agent systems. We automatically build a purely declarative formulation that models time-stamps for durative actions, causal link relationships, threats and effect interferences from an arbitrary number of input plans: from just a unique single trace to many. We accommodate different degrees of input knowledge and support a different range of expressiveness, subsuming the PDDL2.1 temporal semantics. The formulation is simple but effective, and is not only valid for learning, but also for plan validation, as shown in its evaluation that returns high precision and accuracy values.},
  archive      = {J_Constr},
  author       = {Garrido, Antonio},
  doi          = {10.1007/s10601-022-09330-3},
  journal      = {Constraints},
  month        = {4},
  number       = {1},
  pages        = {134-160},
  shortjournal = {Constraints},
  title        = {A constraint-based approach to learn temporal features on action models from multiple plans},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variable ordering for decision diagrams: A portfolio
approach. <em>Constr</em>, <em>27</em>(1), 116–133. (<a
href="https://doi.org/10.1007/s10601-021-09325-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relaxed decision diagrams have been successfully applied to solve combinatorial optimization problems, but their performance is known to strongly depend on the variable ordering. We propose a portfolio approach to selecting the best ordering among a set of alternatives. We consider several different portfolio mechanisms: a static uniform time-sharing portfolio, an offline predictive model of the single best algorithm using classifiers, a low-knowledge algorithm selection, and a dynamic online time allocator. As a case study, we compare and contrast their performance on the graph coloring problem. We find that on this problem domain, the dynamic online time allocator provides the best overall performance.},
  archive      = {J_Constr},
  author       = {Karahalios, Anthony and van Hoeve, Willem-Jan},
  doi          = {10.1007/s10601-021-09325-6},
  journal      = {Constraints},
  month        = {4},
  number       = {1},
  pages        = {116-133},
  shortjournal = {Constraints},
  title        = {Variable ordering for decision diagrams: A portfolio approach},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Concise integer linear programming formulation for clique
partitioning problems. <em>Constr</em>, <em>27</em>(1), 99–115. (<a
href="https://doi.org/10.1007/s10601-022-09326-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Clique Partitioning Problem (CPP) finds an optimal partition of a given edge-weighted undirected graph, such that the sum of the weights is maximized. This general graph problem has a wide range of real-world applications, including correlation clustering, group technology, community detection, and coalition structure generation. Although a CPP is NP-hard, due to the recent advance of Integer Linear Programming (ILP) solvers, we can solve reasonably large problem instances by formulating a CPP as an ILP instance. The first ILP formulation was introduced by Grötschel and Wakabayashi (Mathematical Programming, 45(1-3), 59–96, 1989). Recently, Miyauchi et al. (2018) proposed a more concise ILP formulation that can significantly reduce transitivity constraints as compared to previously introduced models. In this paper, we introduce a series of concise ILP formulations that can reduce even more transitivity constraints. We theoretically evaluate the amount of reduction based on a simple model in which edge signs (positive/negative) are chosen independently. We show that the reduction can be up to 50% (dependent of the ratio of negative edges) and experimentally evaluate the amount of reduction and the performance of our proposed formulation using a variety of graph data sets. Experimental evaluations show that the reduction can exceed 50% (where edge signs can be correlated), and our formulation outperforms the existing state-of-the-art formulations both in terms of memory usage and computational time for most problem instances.},
  archive      = {J_Constr},
  author       = {Koshimura, Miyuki and Watanabe, Emi and Sakurai, Yuko and Yokoo, Makoto},
  doi          = {10.1007/s10601-022-09326-z},
  journal      = {Constraints},
  month        = {4},
  number       = {1},
  pages        = {99-115},
  shortjournal = {Constraints},
  title        = {Concise integer linear programming formulation for clique partitioning problems},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning the travelling salesperson problem requires
rethinking generalization. <em>Constr</em>, <em>27</em>(1), 70–98. (<a
href="https://doi.org/10.1007/s10601-022-09327-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {End-to-end training of neural network solvers for graph combinatorial optimization problems such as the Travelling Salesperson Problem (TSP) have seen a surge of interest recently, but remain intractable and inefficient beyond graphs with few hundreds of nodes. While state-of-the-art learning-driven approaches for TSP perform closely to classical solvers when trained on trivially small sizes, they are unable to generalize the learnt policy to larger instances at practical scales. This work presents an end-to-end neural combinatorial optimization pipeline that unifies several recent papers in order to identify the inductive biases, model architectures and learning algorithms that promote generalization to instances larger than those seen in training. Our controlled experiments provide the first principled investigation into such zero-shot generalization, revealing that extrapolating beyond training data requires rethinking the neural combinatorial optimization pipeline, from network layers and learning paradigms to evaluation protocols. Additionally, we analyze recent advances in deep learning for routing problems through the lens of our pipeline and provide new directions to stimulate future research.},
  archive      = {J_Constr},
  author       = {Joshi, Chaitanya K. and Cappart, Quentin and Rousseau, Louis-Martin and Laurent, Thomas},
  doi          = {10.1007/s10601-022-09327-y},
  journal      = {Constraints},
  month        = {4},
  number       = {1},
  pages        = {70-98},
  shortjournal = {Constraints},
  title        = {Learning the travelling salesperson problem requires rethinking generalization},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correct approximation of IEEE 754 floating-point arithmetic
for program verification. <em>Constr</em>, <em>27</em>(1), 29–69. (<a
href="https://doi.org/10.1007/s10601-021-09322-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Verification of programs using floating-point arithmetic is challenging on several accounts. One of the difficulties of reasoning about such programs is due to the peculiarities of floating-point arithmetic: rounding errors, infinities, non-numeric objects (NaNs), signed zeroes, denormal numbers, different rounding modes, etc. One possibility to reason about floating-point arithmetic is to model a program computation path by means of a set of ternary constraints of the form and use constraint propagation techniques to infer new information on the variables’ possible values. In this setting, we define and prove the correctness of algorithms to precisely bound the value of one of the variables x, y or z, starting from the bounds known for the other two. We do this for each of the operations and for each rounding mode defined by the IEEE 754 binary floating-point standard, even in the case the rounding mode in effect is only partially known. This is the first time that such so-called filtering algorithms are defined and their correctness is formally proved. This is an important slab for paving the way to formal verification of programs that use floating-point arithmetics.},
  archive      = {J_Constr},
  author       = {Bagnara, Roberto and Bagnara, Abramo and Biselli, Fabio and Chiari, Michele and Gori, Roberta},
  doi          = {10.1007/s10601-021-09322-9},
  journal      = {Constraints},
  month        = {4},
  number       = {1},
  pages        = {29-69},
  shortjournal = {Constraints},
  title        = {Correct approximation of IEEE 754 floating-point arithmetic for program verification},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Complete symmetry breaking constraints for the class of
uniquely hamiltonian graphs. <em>Constr</em>, <em>27</em>(1), 8–28. (<a
href="https://doi.org/10.1007/s10601-021-09323-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces, for the first time, a complete symmetry breaking constraint of polynomial size for a significant class of graphs: the class of uniquely Hamiltonian graphs. We introduce a canonical form for uniquely Hamiltonian graphs and prove that testing whether a given uniquely Hamiltonian graph is canonical can be performed efficiently. Based on this canonicity test, we construct a complete symmetry breaking constraint of polynomial size which is satisfied only by uniquely Hamiltonian graphs which are canonical. We apply the proposed symmetry breaking constraint to show new results regarding the class of uniquely Hamiltonian graphs. We also show that the proposed approach applies almost directly for the class of graphs which contain any cycle of known length where it shown to result in a partial symmetry breaking constraint. Given that it is unknown if there exist complete symmetry breaking constraints for graphs of polynomial size, this paper makes a first step in the direction of identifying specific classes of graphs for which such constraints do exist.},
  archive      = {J_Constr},
  author       = {Itzhakov, Avraham and Codish, Michael},
  doi          = {10.1007/s10601-021-09323-8},
  journal      = {Constraints},
  month        = {4},
  number       = {1},
  pages        = {8-28},
  shortjournal = {Constraints},
  title        = {Complete symmetry breaking constraints for the class of uniquely hamiltonian graphs},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Global domain views for expressive and cross-domain
constraint programming. <em>Constr</em>, <em>27</em>(1), 1–7. (<a
href="https://doi.org/10.1007/s10601-021-09324-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of domain views is a powerful abstraction in constraint programming. It permits to define variables that do not declare any domain but instead rely on a variable x and a function f, such that $$y = f(x)$$ where y is the view. In addition to making modelling easier by providing an expressive layer of abstraction, views provide an alternative to constraint decomposition that does not involve auxiliary variables and propagators. In this article, we introduce the notion of global domain view and illustrate it on set and graph views. A global domain view relies on an arbitrary number of variables and a function such that $$y = f(x_1, ..., x_n)$$ . The combination of global domain views with set and graph variables extends the expressiveness of constraint programming by allowing the definition of complex relationships between different types of variables within a light and simple framework.},
  archive      = {J_Constr},
  author       = {Justeau-Allaire, Dimitri and Prud’homme, Charles},
  doi          = {10.1007/s10601-021-09324-7},
  journal      = {Constraints},
  month        = {4},
  number       = {1},
  pages        = {1-7},
  shortjournal = {Constraints},
  title        = {Global domain views for expressive and cross-domain constraint programming},
  volume       = {27},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
