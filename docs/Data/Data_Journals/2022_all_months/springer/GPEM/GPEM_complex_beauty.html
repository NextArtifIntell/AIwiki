<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>GPEM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="gpem---29">GPEM - 29</h2>
<ul>
<li><details>
<summary>
(2022). Ying bi, bing xue, mengjie zhang: Genetic programming for
image classification—an automated approach to feature learning.
<em>GPEM</em>, <em>23</em>(4), 589–590. (<a
href="https://doi.org/10.1007/s10710-022-09438-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_GPEM},
  author       = {Zafra, Amelia},
  doi          = {10.1007/s10710-022-09438-8},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {4},
  pages        = {589-590},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Ying bi, bing xue, mengjie zhang: Genetic programming for image classification—an automated approach to feature learning},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Book review: The evolution of complexity. <em>GPEM</em>,
<em>23</em>(4), 585–587. (<a
href="https://doi.org/10.1007/s10710-022-09443-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_GPEM},
  author       = {Dolson, Emily},
  doi          = {10.1007/s10710-022-09443-x},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {4},
  pages        = {585-587},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Book review: The evolution of complexity},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Review: Machado, romero and greenfield (editors): Artificial
intelligence and the arts. <em>GPEM</em>, <em>23</em>(4), 583–584. (<a
href="https://doi.org/10.1007/s10710-022-09440-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_GPEM},
  author       = {Jordanous, Anna},
  doi          = {10.1007/s10710-022-09440-0},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {4},
  pages        = {583-584},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Review: machado, romero and greenfield (editors): artificial intelligence and the arts},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Melanie mitchell: Artificial intelligence—a guide for
thinking humans. <em>GPEM</em>, <em>23</em>(4), 581–582. (<a
href="https://doi.org/10.1007/s10710-022-09439-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_GPEM},
  author       = {Özkiziltan, Didem},
  doi          = {10.1007/s10710-022-09439-7},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {4},
  pages        = {581-582},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Melanie mitchell: Artificial intelligence—a guide for thinking humans},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Experiments in evolutionary image enhancement with ELAINE.
<em>GPEM</em>, <em>23</em>(4), 557–579. (<a
href="https://doi.org/10.1007/s10710-022-09445-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image enhancement is an image processing procedure in which the image’s original information is refined, for example by highlighting specific features to ease post-processing analyses by a human or machine. This procedure remains challenging since each set of images is often taken under diverse conditions which makes it hard to find an image enhancement solution that fits all conditions. State-of-the-art image enhancement pipelines apply filters that solve specific issues; therefore, it is still hard to generalise these pipelines to all types of problems encountered. We have recently introduced a Genetic Programming approach named ELAINE (EvoLutionAry Image eNhancEment) for evolving image enhancement pipelines based on pre-defined image filters. In this paper, we showcase its potential to create solutions under a real-estate marketing scenario by comparing it with a manual approach and an existing tool for automatic image enhancement. The ELAINE obtained results far exceed those obtained by manual combinations of filters and by the one-click method, in all the metrics explored. We further explore the potential of creating non-photorealistic effects by applying the evolved pipelines to different types of images. The results highlight ELAINE’s potential to transform input images into either suitable real-estate images or non-photorealistic renderings, thus transforming contents and possibly enhancing its aesthetic appeal.},
  archive      = {J_GPEM},
  author       = {Correia, João and Lopes, Daniel and Vieira, Leonardo and Rodriguez-Fernandez, Nereida and Carballal, Adrian and Romero, Juan and Machado, Penousal},
  doi          = {10.1007/s10710-022-09445-9},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {4},
  pages        = {557-579},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Experiments in evolutionary image enhancement with ELAINE},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Complexity and aesthetics in generative and evolutionary
art. <em>GPEM</em>, <em>23</em>(4), 535–556. (<a
href="https://doi.org/10.1007/s10710-022-09429-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we examine the concept of complexity as it applies to generative and evolutionary art and design. Complexity has many different, discipline specific definitions, such as complexity in physical systems (entropy), algorithmic measures of information complexity and the field of “complex systems”. We apply a series of different complexity measures to three different evolutionary art datasets and look at the correlations between complexity and individual aesthetic judgement by the artist (in the case of two datasets) or the physically measured complexity of generative 3D forms. Our results show that the degree of correlation is different for each set and measure, indicating that there is no overall “better” measure. However, specific measures do perform well on individual datasets, indicating that careful choice can increase the value of using such measures. We then assess the value of complexity measures for the audience by undertaking a large-scale survey on the perception of complexity and aesthetics. We conclude by discussing the value of direct measures in generative and evolutionary art, reinforcing recent findings from neuroimaging and psychology which suggest human aesthetic judgement is informed by many extrinsic factors beyond the measurable properties of the object being judged.},
  archive      = {J_GPEM},
  author       = {McCormack, Jon and Cruz Gambardella, Camilo},
  doi          = {10.1007/s10710-022-09429-9},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {4},
  pages        = {535-556},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Complexity and aesthetics in generative and evolutionary art},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using estimation of distribution algorithm for procedural
content generation in video games. <em>GPEM</em>, <em>23</em>(4),
495–533. (<a href="https://doi.org/10.1007/s10710-022-09442-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content generation is one of the major challenges in the modern age. The video game industry is no exception and the ever-increasing demand for bigger titles containing vast volumes of content has become one of the vital challenges for the content generation domain. Conventional game development as a human product is not cost efficient and the need for more intelligent, advanced and procedural methods is evident in this field. In a sense, procedural content generation (PCG) is a Non-deterministic Polynomial-Hard optimization problem in which specific metrics should be optimized. In this paper, we use the Estimation of Distribution Algorithm (EDA) to optimize the task of PCG in digital video games. EDA is an evolutionary stochastic optimization method and the introduction of probabilistic modeling as one of the main features of EDA into this problem domain is a reliable way to mathematically apply human knowledge to the challenging field of content generation. Acceptable performance of the proposed method is reflected in the results, which can inform the academia of PCG and contribute to the game industry.},
  archive      = {J_GPEM},
  author       = {Moradi Karkaj, Arash and Lotfi, Shahriar},
  doi          = {10.1007/s10710-022-09442-y},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {4},
  pages        = {495-533},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Using estimation of distribution algorithm for procedural content generation in video games},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel tree-based representation for evolving analog
circuits and its application to memristor-based pulse generation
circuit. <em>GPEM</em>, <em>23</em>(4), 453–493. (<a
href="https://doi.org/10.1007/s10710-022-09436-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When applying evolutionary algorithms to circuit design automation, circuit representation is the first consideration. There have been several studies applying different circuit representations. However, they still have some problems, such as lack of design ability, which means the diversity of evolved circuits was limited by the circuit representation, and inefficient transformation from circuit representation into SPICE (Simulation Program with Integrated Circuit Emphasis) netlist. In this paper, a novel tree-based circuit representation for analog circuits is proposed, which is equipped with an intuitive and three-terminal devices friendly mapping rule between circuit representation and SPICE netlist, as well as a suitable crossover operator. Based on the proposed representation, a framework for automated analog circuit design using genetic programming is proposed to evolve both the circuit topology and device values. Three benchmark circuits are applied to evaluate the proposed approach, showing that the proposed method is feasible and evolves analog circuits with better fitness and number of components while using less fitness evaluations than existing approaches. Furthermore, considering physical scalability limits of conventional circuit elements and the increased interest in emerging technologies, a memristor-based pulse generation circuit is also evolved based on the proposed method. The feasibility of the evolved circuits is verified by circuit simulation successfully. The experiment results show that the evolved memristive circuit is more compact and has better energy efficiency compared with existing manually-designed circuits.},
  archive      = {J_GPEM},
  author       = {Shi, Xinming and Minku, Leandro L. and Yao, Xin},
  doi          = {10.1007/s10710-022-09436-w},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {4},
  pages        = {453-493},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {A novel tree-based representation for evolving analog circuits and its application to memristor-based pulse generation circuit},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A grammar-based GP approach applied to the design of deep
neural networks. <em>GPEM</em>, <em>23</em>(3), 427–452. (<a
href="https://doi.org/10.1007/s10710-022-09432-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning has been very successful in automating the feature engineering process, widely applied for various tasks, such as speech recognition, classification, segmentation of images, time-series forecasting, among others. Deep neural networks (DNNs) incorporate the power to learn patterns through data, following an end-to-end fashion and expand the applicability in real world problems, since less pre-processing is necessary. With the fast growth in both scale and complexity, a new challenge has emerged regarding the design and configuration of DNNs. In this work, we present a study on applying an evolutionary grammar-based genetic programming algorithm (GP) as a unified approach to the design of DNNs. Evolutionary approaches have been growing in popularity for this subject as Neuroevolution is studied more. We validate our approach in three different applications: the design of Convolutional Neural Networks for image classification, Graph Neural Networks for text classification, and U-Nets for image segmentation. The results show that evolutionary grammar-based GP can efficiently generate different DNN architectures, adapted to each problem, employing choices that differ from what is usually seen in networks designed by hand. This approach has shown a lot of promise regarding the design of architectures, reaching competitive results with their counterparts.},
  archive      = {J_GPEM},
  author       = {Lima, Ricardo H. R. and Magalhães, Dimmy and Pozo, Aurora and Mendiburu, Alexander and Santana, Roberto},
  doi          = {10.1007/s10710-022-09432-0},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {3},
  pages        = {427-452},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {A grammar-based GP approach applied to the design of deep neural networks},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Severe damage recovery in evolving soft robots through
differentiable programming. <em>GPEM</em>, <em>23</em>(3), 405–426. (<a
href="https://doi.org/10.1007/s10710-022-09433-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological systems are very robust to morphological damage, but artificial systems (robots) are currently not. In this paper we present a system based on neural cellular automata, in which locomoting robots are evolved and then given the ability to regenerate their morphology from damage through gradient-based training. Our approach thus combines the benefits of evolution to discover a wide range of different robot morphologies, with the efficiency of supervised training for robustness through differentiable update rules. The resulting neural cellular automata are able to grow virtual robots capable of regaining more than 80\% of their functionality, even after severe types of morphological damage.},
  archive      = {J_GPEM},
  author       = {Horibe, Kazuya and Walker, Kathryn and Berg Palm, Rasmus and Sudhakaran, Shyam and Risi, Sebastian},
  doi          = {10.1007/s10710-022-09433-z},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {3},
  pages        = {405-426},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Severe damage recovery in evolving soft robots through differentiable programming},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Applying genetic programming to PSB2: The next generation
program synthesis benchmark suite. <em>GPEM</em>, <em>23</em>(3),
375–404. (<a href="https://doi.org/10.1007/s10710-022-09434-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the past seven years, researchers in genetic programming and other program synthesis disciplines have used the General Program Synthesis Benchmark Suite (PSB1) to benchmark many aspects of systems that conduct programming by example, where the specifications of the desired program are given as input/output pairs. PSB1 has been used to make notable progress toward the goal of general program synthesis: automatically creating the types of software that human programmers code. Many of the systems that have attempted the problems in PSB1 have used it to demonstrate performance improvements granted through new techniques. Over time, the suite has gradually become outdated, hindering the accurate measurement of further improvements. The field needs a new set of more difficult benchmark problems to move beyond what was previously possible and ensure that systems do not overfit to one benchmark suite. In this paper, we describe the 25 new general program synthesis benchmark problems that make up PSB2, a new benchmark suite. These problems are curated from a variety of sources, including programming katas and college courses. We selected these problems to be more difficult than those in the original suite, and give results using PushGP showing this increase in difficulty. We additionally give an example of benchmarking using a state-of-the-art parent selection method, showing improved performance on PSB2 while still leaving plenty of room for improvement. These new problems will help guide program synthesis research for years to come.},
  archive      = {J_GPEM},
  author       = {Helmuth, Thomas and Kelly, Peter},
  doi          = {10.1007/s10710-022-09434-y},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {3},
  pages        = {375-404},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Applying genetic programming to PSB2: The next generation program synthesis benchmark suite},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary approximation and neural architecture search.
<em>GPEM</em>, <em>23</em>(3), 351–374. (<a
href="https://doi.org/10.1007/s10710-022-09441-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated neural architecture search (NAS) methods are now employed to routinely deliver high-quality neural network architectures for various challenging data sets and reduce the designer’s effort. The NAS methods utilizing multi-objective evolutionary algorithms are especially useful when the objective is not only to minimize the network error but also to reduce the number of parameters (weights) or power consumption of the inference phase. We propose a multi-objective NAS method based on Cartesian genetic programming for evolving convolutional neural networks (CNN). The method allows approximate operations to be used in CNNs to reduce the power consumption of a target hardware implementation. During the NAS process, a suitable CNN architecture is evolved together with selecting approximate multipliers to deliver the best trade-offs between accuracy, network size, and power consumption. The most suitable 8 × N-bit approximate multipliers are automatically selected from a library of approximate multipliers. Evolved CNNs are compared with CNNs developed by other NAS methods on the CIFAR-10 and SVHN benchmark problems.},
  archive      = {J_GPEM},
  author       = {Pinos, Michal and Mrazek, Vojtech and Sekanina, Lukas},
  doi          = {10.1007/s10710-022-09441-z},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {3},
  pages        = {351-374},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Evolutionary approximation and neural architecture search},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interpretability in symbolic regression: A benchmark of
explanatory methods using the feynman data set. <em>GPEM</em>,
<em>23</em>(3), 309–349. (<a
href="https://doi.org/10.1007/s10710-022-09435-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some situations, the interpretability of the machine learning models plays a role as important as the model accuracy. Interpretability comes from the need to trust the prediction model, verify some of its properties, or even enforce them to improve fairness. Many model-agnostic explanatory methods exists to provide explanations for black-box models. In the regression task, the practitioner can use white-boxes or gray-boxes models to achieve more interpretable results, which is the case of symbolic regression. When using an explanatory method, and since interpretability lacks a rigorous definition, there is a need to evaluate and compare the quality and different explainers. This paper proposes a benchmark scheme to evaluate explanatory methods to explain regression models, mainly symbolic regression models. Experiments were performed using 100 physics equations with different interpretable and non-interpretable regression methods and popular explanation methods, evaluating the performance of the explainers performance with several explanation measures. In addition, we further analyzed four benchmarks from the GP community. The results have shown that Symbolic Regression models can be an interesting alternative to white-box and black-box models that is capable of returning accurate models with appropriate explanations. Regarding the explainers, we observed that Partial Effects and SHAP were the most robust explanation models, with Integrated Gradients being unstable only with tree-based models. This benchmark is publicly available for further experiments.},
  archive      = {J_GPEM},
  author       = {Aldeia, Guilherme Seidyo Imai and de França, Fabrício Olivetti},
  doi          = {10.1007/s10710-022-09435-x},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {3},
  pages        = {309-349},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Interpretability in symbolic regression: A benchmark of explanatory methods using the feynman data set},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial introduction. <em>GPEM</em>, <em>23</em>(3),
305–307. (<a href="https://doi.org/10.1007/s10710-022-09437-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_GPEM},
  author       = {Trujillo, Leonardo and Hu, Ting and Lourenço, Nuno and Zhang, Mengjie},
  doi          = {10.1007/s10710-022-09437-9},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {3},
  pages        = {305-307},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Editorial introduction},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GP-DMD: A genetic programming variant with dynamic
management of diversity. <em>GPEM</em>, <em>23</em>(2), 279–304. (<a
href="https://doi.org/10.1007/s10710-021-09426-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proper management of diversity is essential to the success of Evolutionary Algorithms. Specifically, methods that explicitly relate the amount of diversity maintained in the population to the stopping criterion and elapsed period of execution, with the aim of attaining a gradual shift from exploration to exploitation, have been particularly successful. However, in the area of Genetic Programming, the performance of this design principle has not been studied. In this paper, a novel Genetic Programming method, Genetic Programming with Dynamic Management of Diversity (GP-DMD), is presented. GP-DMD applies this design principle through a replacement strategy that combines penalties based on distance-like functions with a multi-objective Pareto selection based on accuracy and simplicity. The proposed general method was adapted to the well-established Symbolic Regression benchmark problem using tree-based Genetic Programming. Several state-of-the-art diversity management approaches were considered for the experimental validation, and the results obtained showcase the improvements both in terms of mean square error and size. The effects of GP-DMD on the dynamics of the population are also analyzed, revealing the reasons for its superiority. As in other fields of Evolutionary Computation, this design principle contributes significantly to the area of Genetic Programming.},
  archive      = {J_GPEM},
  author       = {Nieto-Fuentes, Ricardo and Segura, Carlos},
  doi          = {10.1007/s10710-021-09426-4},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {2},
  pages        = {279-304},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {GP-DMD: A genetic programming variant with dynamic management of diversity},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Genetic programming for iterative numerical methods.
<em>GPEM</em>, <em>23</em>(2), 253–278. (<a
href="https://doi.org/10.1007/s10710-021-09425-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce GPLS (Genetic Programming for Linear Systems) as a GP system that finds mathematical expressions defining an iteration matrix. Stationary iterative methods use this iteration matrix to solve a system of linear equations numerically. GPLS aims at finding iteration matrices with a low spectral radius and a high sparsity, since these properties ensure a fast error reduction of the numerical solution method and enable the efficient implementation of the methods on parallel computer architectures. We study GPLS for various types of system matrices and find that it easily outperforms classical approaches like the Gauss–Seidel and Jacobi methods. GPLS not only finds iteration matrices for linear systems with a much lower spectral radius, but also iteration matrices for problems where classical approaches fail. Additionally, solutions found by GPLS for small problem instances show also good performance for larger instances of the same problem.},
  archive      = {J_GPEM},
  author       = {Sobania, Dominik and Schmitt, Jonas and Köstler, Harald and Rothlauf, Franz},
  doi          = {10.1007/s10710-021-09425-5},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {2},
  pages        = {253-278},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Genetic programming for iterative numerical methods},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolving cellular automata schemes for protein folding
modeling using the rosetta atomic representation. <em>GPEM</em>,
<em>23</em>(2), 225–252. (<a
href="https://doi.org/10.1007/s10710-022-09427-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein folding is the dynamic process by which a protein folds into its final native structure. This is different to the traditional problem of the prediction of the final protein structure, since it requires a modeling of how protein components interact over time to obtain the final folded structure. In this study we test whether a model of the folding process can be obtained exclusively through machine learning. To this end, protein folding is considered as an emergent process and the cellular automata tool is used to model the folding process. A neural cellular automaton is defined, using a connectionist model that acts as a cellular automaton through the protein chain to define the dynamic folding. Differential evolution is used to automatically obtain the optimized neural cellular automata that provide protein folding. We tested the methods with the Rosetta coarse-grained atomic model of protein representation, using different proteins to analyze the modeling of folding and the structure refinement that the modeling can provide, showing the potential advantages that such methods offer, but also difficulties that arise.},
  archive      = {J_GPEM},
  author       = {Varela, Daniel and Santos, José},
  doi          = {10.1007/s10710-022-09427-x},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {2},
  pages        = {225-252},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Evolving cellular automata schemes for protein folding modeling using the rosetta atomic representation},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the performance of the bayesian optimization algorithm
with combined scenarios of search algorithms and scoring metrics.
<em>GPEM</em>, <em>23</em>(2), 193–223. (<a
href="https://doi.org/10.1007/s10710-022-09430-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bayesian Optimization Algorithm (BOA) is one of the most prominent Estimation of Distribution Algorithms. It can detect the correlation between multiple variables and extract knowledge on regular patterns in solutions. Bayesian Networks (BNs) are used in BOA to represent the probability distributions of the best individuals. The BN’s construction is challenging since there is a trade-off between acuity and computational cost to generate it. This trade-off is determined by combining a search algorithm (SA) and a scoring metric (SM). The SA is responsible for generating a promising BN and the SM assesses the quality of such networks. Some studies have already analyzed how this relationship affects the learning process of a BN. However, such investigation had not yet been performed to determine the bond linking the selection of SA and SM and the BOA’s output quality. Acting on this research gap, a detailed comparative analysis involving two constructive heuristics and four scoring metrics is presented in this work. The classic version of BOA was applied to discrete and continuous optimization problems using binary and floating-point representations. The scenarios were compared through graphical analyses, statistical metrics, and difference detection tests. The results showed that the selection of SA and SM affects the quality of the BOA results since scoring metrics that penalize complex BN models perform better than metrics that do not consider the complexity of the networks. This study contributes to a discussion on this metaheuristic’s practical use, assisting users with implementation decisions.},
  archive      = {J_GPEM},
  author       = {Nametala, Ciniro A. L. and Faria, Wandry R. and Pereira Júnior, Benvindo R.},
  doi          = {10.1007/s10710-022-09430-2},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {2},
  pages        = {193-223},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {On the performance of the bayesian optimization algorithm with combined scenarios of search algorithms and scoring metrics},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Blood glucose prediction using multi-objective grammatical
evolution: Analysis of the “agnostic” and “what-if” scenarios.
<em>GPEM</em>, <em>23</em>(2), 161–192. (<a
href="https://doi.org/10.1007/s10710-021-09424-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we investigate the benefits of applying a multi-objective approach for solving a symbolic regression problem by means of Grammatical Evolution. In particular, we extend previous work, obtaining mathematical expressions to model glucose levels in the blood of diabetic patients. Here we use a multi-objective Grammatical Evolution approach based on the NSGA-II algorithm, considering the root-mean-square error and an ad-hoc fitness function as objectives. This ad-hoc function is based on the Clarke Error Grid analysis, which is useful for showing the potential danger of mispredictions in diabetic patients. In this work, we use two datasets to analyse two different scenarios: What-if and Agnostic, the most common in daily clinical practice. In the What-if scenario, where future events are evaluated, results show that the multi-objective approach improves previous results in terms of Clarke Error Grid analysis by reducing the number of dangerous mispredictions. In the Agnostic situation, with no available information about future events, results suggest that we can obtain good predictions with only information from the previous hour for both Grammatical Evolution and Multi-Objective Grammatical Evolution.},
  archive      = {J_GPEM},
  author       = {Contador, Sergio and Colmenar, J. Manuel and Garnica, Oscar and Velasco, J. Manuel and Hidalgo, J. Ignacio},
  doi          = {10.1007/s10710-021-09424-6},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {2},
  pages        = {161-192},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Blood glucose prediction using multi-objective grammatical evolution: Analysis of the “agnostic” and “what-if” scenarios},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence for fashion, leanne luce, apress
2019, ISBN 978-1-4842-3930-8 how AI is revolutionizing the fashion
industry. <em>GPEM</em>, <em>23</em>(1), 159–160. (<a
href="https://doi.org/10.1007/s10710-021-09422-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_GPEM},
  author       = {Buttler, Grace},
  doi          = {10.1007/s10710-021-09422-8},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {1},
  pages        = {159-160},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Artificial intelligence for fashion, leanne luce, apress 2019, ISBN 978-1-4842-3930-8 how AI is revolutionizing the fashion industry},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robert elliott smith: Rage inside the machine—the prejudice
of algorithms, and how to stop the internet making bigots of us all.
<em>GPEM</em>, <em>23</em>(1), 157–158. (<a
href="https://doi.org/10.1007/s10710-021-09420-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_GPEM},
  author       = {Magdy, Walid},
  doi          = {10.1007/s10710-021-09420-w},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {1},
  pages        = {157-158},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Robert elliott smith: Rage inside the machine—the prejudice of algorithms, and how to stop the internet making bigots of us all},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generating networks of genetic processors. <em>GPEM</em>,
<em>23</em>(1), 133–155. (<a
href="https://doi.org/10.1007/s10710-021-09423-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Networks of Genetic Processors (NGPs) are non-conventional models of computation based on genetic operations over strings, namely mutation and crossover operations as it was established in genetic algorithms. Initially, they have been proposed as acceptor machines which are decision problem solvers. In that case, it has been shown that they are universal computing models equivalent to Turing machines. In this work, we propose NGPs as enumeration devices and we analyze their computational power. First, we define the model and we propose its definition as parallel genetic algorithms. Once the correspondence between the two formalisms has been established, we carry out a study of the generation capacity of the NGPs under the research framework of the theory of formal languages. We investigate the relationships between the number of processors of the model and its generative power. Our results show that the number of processors is important to increase the generative capability of the model up to an upper bound, and that NGPs are universal models of computation if they are formulated as generation devices. This allows us to affirm that parallel genetic algorithms working under certain restrictions can be considered equivalent to Turing machines and, therefore, they are universal models of computation.},
  archive      = {J_GPEM},
  author       = {Campos, Marcelino and Sempere, José M.},
  doi          = {10.1007/s10710-021-09423-7},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {1},
  pages        = {133-155},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Generating networks of genetic processors},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic generation of regular expressions for the regex
golf challenge using a local search algorithm. <em>GPEM</em>,
<em>23</em>(1), 105–131. (<a
href="https://doi.org/10.1007/s10710-021-09411-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular expression is a technology widely used in software development for extracting textual data, validating the structure of textual documents, or formatting data. Regex Golf is a challenge that consists in finding the smallest possible regular expression given a set of sentences to perform matches and another set not to match. An algorithm capable of meeting the Regex Golf requirements is a relevant contribution to the area of semi-structured document data extraction. In this paper, we propose a heuristic search algorithm based on local search, combined with a regular expression shrinker, to find valid results for Regex Golf problems. An experimental study was conducted to compare the proposed technique with an exact algorithm and a genetic programming algorithm designed for the Regex Golf challenge. The proposed local search was shown to outperform both competing algorithms in six out of fifteen problem instances, tying in another three instances. On the other hand, all algorithms still lack the ability to outperform human software developers in designing regular expressions for the challenge.},
  archive      = {J_GPEM},
  author       = {de Almeida Farzat, André and de Oliveira Barros, Márcio},
  doi          = {10.1007/s10710-021-09411-x},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {1},
  pages        = {105-131},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Automatic generation of regular expressions for the regex golf challenge using a local search algorithm},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Genetic programming convergence. <em>GPEM</em>,
<em>23</em>(1), 71–104. (<a
href="https://doi.org/10.1007/s10710-021-09405-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study both genotypic and phenotypic convergence in GP floating point continuous domain symbolic regression over thousands of generations. Subtree fitness variation across the population is measured and shown in many cases to fall. In an expanding region about the root node, both genetic opcodes and function evaluation values are identical or nearly identical. Bottom up (leaf to root) analysis shows both syntactic and semantic (including entropy) similarity expand from the outermost node. Despite large regions of zero variation, fitness continues to evolve and near zero crossover disruption suggests improved GP systems within existing memory use.},
  archive      = {J_GPEM},
  author       = {Langdon, W. B.},
  doi          = {10.1007/s10710-021-09405-9},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {1},
  pages        = {71-104},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Genetic programming convergence},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constant optimization and feature standardization in
multiobjective genetic programming. <em>GPEM</em>, <em>23</em>(1),
37–69. (<a href="https://doi.org/10.1007/s10710-021-09410-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper extends the numerical tuning of tree constants in genetic programming (GP) to the multiobjective domain. Using ten real-world benchmark regression datasets and employing Bayesian comparison procedures, we first consider the effects of feature standardization (without constant tuning) and conclude that standardization generally produces lower test errors, but, contrary to other recently published work, we find much less clear trend for tree sizes. In addition, we consider the effects of constant tuning – with and without feature standardization – and observe that (1) constant tuning invariably improves test error, and (2) usually decreases tree size. Combined with standardization, constant tuning produces the best test error results; tree sizes, however, are increased. We also examine the effects of applying constant tuning only once at the end a conventional GP run which turns out to be surprisingly promising. Finally, we consider the merits of using numerical procedures to tune tree constants and observe that for around half the datasets evolutionary search alone is superior whereas for the remaining half, parameter tuning is superior. We identify a number of open research questions that arise from this work.},
  archive      = {J_GPEM},
  author       = {Rockett, Peter},
  doi          = {10.1007/s10710-021-09410-y},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {1},
  pages        = {37-69},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Constant optimization and feature standardization in multiobjective genetic programming},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inference of time series components by online co-evolution.
<em>GPEM</em>, <em>23</em>(1), 7–35. (<a
href="https://doi.org/10.1007/s10710-021-09408-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data is often composed of a multitude of individual, superimposed dynamics. We propose a novel algorithm for inferring time series compositions through evolutionary synchronization of modular networks (ESMoN). ESMoN orchestrates a set of trained dynamic modules, assuming that some of those modules’ dynamics, suitably parameterized, will be present in the targeted time series. With the help of iterative co-evolution techniques, ESMoN optimizes the activities of its modules dynamically, which effectively synchronizes the system with the unfolding time series signal and distributes the dynamic subcomponents present in the time series over the respective modules. We show that ESMoN can adapt modules of different types. Moreover, it is able to precisely identify the signal components of various time series dynamics. We thus expect that ESMoN will be useful also in other domains—including, for example, medical, physical, and behavioral data domains—where the data is composed of known signal sources.},
  archive      = {J_GPEM},
  author       = {Koryakin, Danil and Otte, Sebastian and Butz, Martin V.},
  doi          = {10.1007/s10710-021-09408-6},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {1},
  pages        = {7-35},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Inference of time series components by online co-evolution},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Acknowledgment to reviewers (2021). <em>GPEM</em>,
<em>23</em>(1), 3–5. (<a
href="https://doi.org/10.1007/s10710-022-09431-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_GPEM},
  author       = {Spector, Lee},
  doi          = {10.1007/s10710-022-09431-1},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {1},
  pages        = {3-5},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Acknowledgment to reviewers (2021)},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Editorial introduction. <em>GPEM</em>, <em>23</em>(1), 1–2.
(<a href="https://doi.org/10.1007/s10710-022-09428-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_GPEM},
  author       = {Spector, Lee},
  doi          = {10.1007/s10710-022-09428-w},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Editorial introduction},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Benchmarking ensemble genetic programming with a linked list
external memory on scalable partially observable tasks. <em>GPEM</em>,
<em>23</em>(1), 1–29. (<a
href="https://doi.org/10.1007/s10710-022-09446-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reactive learning agents cannot solve partially observable sequential decision-making tasks as they are limited to defining outcomes purely in terms of the observable state. However, augmenting reactive agents with external memory might provide a path for addressing this limitation. In this work, external memory takes the form of a linked list data structure that programs have to learn how to use. We identify conditions under which additional recurrent connectivity from program output to input is necessary for state disambiguation. Benchmarking against recent results from the neural network literature on three scalable partially observable sequential decision-making tasks demonstrates that the proposed approach scales much more effectively. Indeed, solutions are shown to generalize to far more difficult sequences than those experienced under training conditions. Moreover, recommendations are made regarding the instruction set and additional benchmarking is performed with input state values designed to explicitly disrupt the identification of useful states for later recall. The protected division operator appears to be particularly useful in developing simple solutions to all three tasks.},
  archive      = {J_GPEM},
  author       = {Al Masalma, Mihyar and Heywood, Malcolm},
  doi          = {10.1007/s10710-022-09446-8},
  journal      = {Genetic Programming and Evolvable Machines},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Benchmarking ensemble genetic programming with a linked list external memory on scalable partially observable tasks},
  volume       = {23},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
