<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="air---161">AIR - 161</h2>
<ul>
<li><details>
<summary>
(2022). Uncertainty modeling in multi-objective vehicle routing
problem under extreme environment. <em>AIR</em>, <em>55</em>(8),
6673–6707. (<a
href="https://doi.org/10.1007/s10462-022-10169-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assumption of fuzziness in the vehicle routing problems under extreme conditions is necessary for modelers, because there are usually insufficient objective input data. In extreme situations, the complexity of the description of vehicles’ movement on routes may cause by two poles: the imprecision of movement time and the uncertainty of the possibility of movement on roads. Traditionally, a fuzzy value has been used to represent the data’s impreciseness; hence, only one pole of expert’s information is taken in the aggregation results. The main objective of this paper is to present an efficient way for fuzzy vehicle routing modeling to minimize the decision-making risks in the optimal planning of routes network and from distribution centers to demand points. To address this, a new two-stage possibilistic bi-criteria vehicle routing problem (VRP) is presented under extreme conditions. In the first stage, the sample of so-called “promising” closed routes are selected based on a “constructive” approach using a simulation algorithm. The expected times of the vehicle movement between demand points are taken as fuzzy triangular numbers. In the second stage, based on Choquet integral’s, a bi-criteria partitioning model for the fuzzy VRP has been constructed. The constraint approach has been defined to obtain the optimal solution of the model. For numerical experiments, a parallel algorithm is created based on D. Knuth’s algorithm of dancing links. An example is presented with the results of our approach for the VRP, where all Pareto-optimal solutions are found from the promising routes.},
  archive      = {J_AIR},
  author       = {Sirbiladze, Gia and Garg, Harish and Ghvaberidze, Bezhan and Matsaberidze, Bidzina and Khutsishvili, Irina and Midodashvili, Bidzina},
  doi          = {10.1007/s10462-022-10169-6},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6673-6707},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Uncertainty modeling in multi-objective vehicle routing problem under extreme environment},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3DDACNN: 3D dense attention convolutional neural network for
point cloud based object recognition. <em>AIR</em>, <em>55</em>(8),
6655–6671. (<a
href="https://doi.org/10.1007/s10462-022-10165-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep CNN-based methods have achieved significant success in solving various 2D computer vision issues. However, directly processing 3D point clouds with CNNs remains a challenging problem due to their irregular characteristic, which results in the comprehensive performance far from optimal. In this paper, we propose a novel trainable architecture for 3D point cloud based object recognition from the perspective of depth of network and attention mechanism for the first time. We first transform the input point cloud into regular volumetric representation using binary occupancy grid strategy. The output is then fed into our proposed 3D Dense-Attention CNN framework, dubbed as $$\mathbf{3DDACNN }$$ , to obtain features with enhanced representation power. Extensive experiments on highly challenging datasets demonstrate the effectiveness of our proposed model, which can achieve remarkable performance.},
  archive      = {J_AIR},
  author       = {Han, Xian-Feng and Huang, Xin-Yi and Sun, Shi-Jie and Wang, Ming-Jie},
  doi          = {10.1007/s10462-022-10165-w},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6655-6671},
  shortjournal = {Artif. Intell. Rev.},
  title        = {3DDACNN: 3D dense attention convolutional neural network for point cloud based object recognition},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Product typicality attribute mining method based on a topic
clustering ensemble. <em>AIR</em>, <em>55</em>(8), 6629–6654. (<a
href="https://doi.org/10.1007/s10462-022-10163-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the extensive application of topic models in natural language processing tasks in recent years, the Chinese texts of short comments characterised by large scale, high noise and small information points have put forward higher requirements for the accuracy and stability of the results, which fails to be satisfied by existing topic models. In this paper, a product typicality attribute mining method based on a topic clustering ensemble was proposed. By introducing multiple topic models into ensemble learning, the problems of semantic representation loss, clustering inefficiency and lack of interpretability in the mining of product typicality attributes of short comment texts should be solved. By an effective combination of the topic clustering algorithm based on the diversity of speech, the topic clustering ensemble algorithm based on the Non-negative matrix factorization, and the interpretation method of product typicality attributes based on the mean-shift algorithm, an unsupervised model of product typicality attribute mining for short comment texts is constructed. As shown by the experimental results, the modelling method assumes favourable performance in topic clustering and feature selection, suggesting its advantages in product typicality attribute identification and interpretability compared with common methods.},
  archive      = {J_AIR},
  author       = {Sun, Jing-Tao and Zhang, Qiu-Yu},
  doi          = {10.1007/s10462-022-10163-y},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6629-6654},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Product typicality attribute mining method based on a topic clustering ensemble},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of algorithms to computing irreducible testors
applied to feature selection. <em>AIR</em>, <em>55</em>(8), 6607–6628.
(<a href="https://doi.org/10.1007/s10462-022-10162-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an important task in the areas of pattern recognition and data mining. Various approaches to feature selection have been developed. In particular, this paper focuses on the algorithms for computing irreducible testors, which have been used to solve feature selection problems. The calculation of irreducible testors is an expensive computational process; the complexity of the algorithms to calculate the complete set of irreducible testors exponentially depends on the number of characteristics that describe the objects in the problem. To improve the execution time of these algorithms, different alternatives have been developed, such as parallel implementations, hardware-software implementation, rearrangement of the data, as well as heuristics to generate just an irreducible testor or a subset of the entire set of irreducible testors, among other strategies. This paper presents a review of the literature on irreducible testors, with the aim of providing a guide for researchers working in the areas of pattern recognition and data mining, interested in feature selection, using heterogeneous data and possibly missing data.},
  archive      = {J_AIR},
  author       = {Sanchez-Diaz, Guillermo and Lazo-Cortes, Manuel S. and Aguirre-Salado, Carlos A. and Piza-Davila, Ivan and Garcia-Contreras, Jorge P.},
  doi          = {10.1007/s10462-022-10162-z},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6607-6628},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of algorithms to computing irreducible testors applied to feature selection},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling, reasoning, and application of fuzzy petri net
model: A survey. <em>AIR</em>, <em>55</em>(8), 6567–6605. (<a
href="https://doi.org/10.1007/s10462-022-10161-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fuzzy Petri net (FPN) is a powerful tool to model and analyze knowledge-based systems containing vague information. This paper systematically reviews recent developments of the FPN model from the following three perspectives: knowledge representation using FPN, reasoning mechanisms using an FPN framework, and the latest industrial applications using FPN. In addition, some specific modeling and reasoning approaches to FPN to solve the ‘state-explosion problem’ are illustrated. Furthermore, detailed analysis of the discussed aspects are shown to reveal some interesting findings, as well as their developmental history. Finally, we present conclusions and suggestions for future research directions.},
  archive      = {J_AIR},
  author       = {Jiang, Wei and Zhou, Kai-Qing and Sarkheyli-Hägele, Arezoo and Zain, Azlan Mohd},
  doi          = {10.1007/s10462-022-10161-0},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6567-6605},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Modeling, reasoning, and application of fuzzy petri net model: A survey},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combining filtered dictionary representation based deep
subspace filter learning with a discriminative classification criterion
for facial expression recognition. <em>AIR</em>, <em>55</em>(8),
6547–6566. (<a
href="https://doi.org/10.1007/s10462-022-10160-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic facial expression recognition is an active research area that has attracted much attention from both academics and practitioners of different fields. However, in reality, the problem of noise interference and cross-dataset expression recognition generally degrade the performance of recognition methods, we investigate the problems above, and propose a facial expression recognition approach from the perspective of deep subspace filter learning combined with discriminative classification criterion. Specifically, to derive an effective expression-related feature representation, we construct the filtered dictionaries based on deep subspace filter learning structure that corresponds to extract different expressions. Also, considering the similarities and discriminations existed in the filtered dictionaries, we further present a flexible classification criterion that adopt a dynamic weight to increase the adaptation between filtered dictionaries. To sum up, the proposed approach has more discriminative power from the aspect of representation and classification. Comprehensive experiments carried out using several public datasets, including JAFFE, CK+, and KDEF datasets, confirm that the proposed approach is superior compared to several state-of-the-art methods.},
  archive      = {J_AIR},
  author       = {Sun, Zhe and Zhang, Hehao and Ma, Suwei and Hu, Zhengping},
  doi          = {10.1007/s10462-022-10160-1},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6547-6566},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Combining filtered dictionary representation based deep subspace filter learning with a discriminative classification criterion for facial expression recognition},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optical flow for video super-resolution: A survey.
<em>AIR</em>, <em>55</em>(8), 6505–6546. (<a
href="https://doi.org/10.1007/s10462-022-10159-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video super-resolution is currently one of the most active research topics in computer vision as it plays an important role in many visual applications. Generally, video super-resolution contains a significant component, i.e., motion compensation, which is used to estimate the displacement between successive video frames for temporal alignment. Optical flow, which can supply dense and sub-pixel motion between consecutive frames, is among the most common ways for this task. To obtain a good understanding of the effect that optical flow acts in video super-resolution, in this work, we conduct a comprehensive review on this subject for the first time. This investigation covers the following major topics: the function of super-resolution (i.e., why we require super-resolution); the concept of video super-resolution (i.e., what is video super-resolution); the description of evaluation metrics (i.e., how (video) super-resolution performs); the introduction of optical flow based video super-resolution; the investigation of using optical flow to capture temporal dependency for video super-resolution. Prominently, we give an in-depth study of the deep learning based video super-resolution method, where some representative algorithms are analyzed and compared. Additionally, we highlight some promising research directions and open issues that should be further addressed.},
  archive      = {J_AIR},
  author       = {Tu, Zhigang and Li, Hongyan and Xie, Wei and Liu, Yuanzhong and Zhang, Shifu and Li, Baoxin and Yuan, Junsong},
  doi          = {10.1007/s10462-022-10159-8},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6505-6546},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Optical flow for video super-resolution: A survey},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An intelligent management of power flow in the smart grid
system using hybrid NPO-ATLA approach. <em>AIR</em>, <em>55</em>(8),
6461–6503. (<a
href="https://doi.org/10.1007/s10462-022-10158-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this manuscript, an intelligent hybrid approach is proposed to manage the power flow (PF) in the smart grid (SG) system. The proposed approach is the combined execution of Nomadic People Optimizer (NPO) algorithm and artificial transgender longicorn algorithm (ATLA), hence it is named NPO-ATLA approach. The Renewable energy system consists of photovoltaic (PV), wind turbine (WT), battery and grid. The major aim of this work is to control the power flow in the hybrid renewable energy sources (HRES) depending on parameter variation of source and load side and satisfies the load demand of the system. The voltage source inverter (VSI) control signals are generated through the NPO approach based upon the variation of power transfer amid the source and load side. ATLA is utilized to recognize the control signals of the system against the variation of active with reactive power. The proposed approach is carried out in MATLAB, then the performance is compared with various existing approaches.},
  archive      = {J_AIR},
  author       = {Dsouza, Anil Kumar and Thammaiah, Ananthapadmanabha and Venkatesh, Likith Kumar M.},
  doi          = {10.1007/s10462-022-10158-9},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6461-6503},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An intelligent management of power flow in the smart grid system using hybrid NPO-ATLA approach},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A new fusion of whale optimizer algorithm with kapur’s
entropy for multi-threshold image segmentation: Analysis and
validations. <em>AIR</em>, <em>55</em>(8), 6389–6459. (<a
href="https://doi.org/10.1007/s10462-022-10157-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The separation of an object from other objects or the background by selecting the optimal threshold values remains a challenge in the field of image segmentation. Threshold segmentation is one of the most popular image segmentation techniques. The traditional methods for finding the optimum threshold are computationally expensive, tedious, and may be inaccurate. Hence, this paper proposes an Improved Whale Optimization Algorithm (IWOA) based on Kapur’s entropy for solving multi-threshold segmentation of the gray level image. Also, IWOA supports its performance using linearly convergence increasing and local minima avoidance technique (LCMA), and ranking-based updating method (RUM). LCMA technique accelerates the convergence speed of the solutions toward the optimal solution and tries to avoid the local minima problem that may fall within the optimization process. To do that, it updates randomly the positions of the worst solutions to be near to the best solution and at the same time randomly within the search space according to a certain probability to avoid stuck into local minima. Because of the randomization process used in LCMA for updating the solutions toward the best solutions, a huge number of the solutions around the best are skipped. Therefore, the RUM is used to replace the unbeneficial solution with a novel updating scheme to cover this problem. We compare IWOA with another seven algorithms using a set of well-known test images. We use several performance measures, such as fitness values, Peak Signal to Noise Ratio, Structured Similarity Index Metric, Standard Deviation, and CPU time.},
  archive      = {J_AIR},
  author       = {Abdel-Basset, Mohamed and Mohamed, Reda and Abouhawwash, Mohamed},
  doi          = {10.1007/s10462-022-10157-w},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6389-6459},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A new fusion of whale optimizer algorithm with kapur’s entropy for multi-threshold image segmentation: Analysis and validations},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic recognition of woven fabric structural parameters:
A review. <em>AIR</em>, <em>55</em>(8), 6345–6387. (<a
href="https://doi.org/10.1007/s10462-022-10156-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a comprehensive review of automatic recognition of woven fabric structural parameters in recent years. Fabric structural parameters mainly include fabric density, weave pattern, color pattern, etc., which need to be pre-set before production and carefully checked during quality control. The analysis of these parameters is considered the most crucial step in the textile industry. The commonly used manual operations based on human eyes and experiences are time-consuming and labor-intensive. In contrast, computer-vision-based methods or other automatic methods hold the advantages of quick response, objective evaluation, and high stability. In this paper, the background and definition of the analysis of fabric structural parameters are first introduced. Secondly, it offers some automated recognition systems and their configurations. Then, it describes an up-to-date survey across the existing methods and performs a comparative study of their characteristics, strengths, and weaknesses. Besides, some evaluation matrixes are provided to evaluate the performance of automatic recognition methods. Finally, the report makes conclusions and discusses future research directions. This review can benefit researchers in understanding and utilizing automated methods to recognize fabric structural parameters. Promisingly, it can also provide some novel ideas for other recognition problems in the textile industry like fabric defect detection, fabric appearance analysis, and fabric inverse modelling.},
  archive      = {J_AIR},
  author       = {Meng, Shuo and Pan, Ruru and Gao, Weidong and Yan, Benchao and Peng, Yangyang},
  doi          = {10.1007/s10462-022-10156-x},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6345-6387},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Automatic recognition of woven fabric structural parameters: A review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence-enabled prediction model of student
academic performance in online engineering education. <em>AIR</em>,
<em>55</em>(8), 6321–6344. (<a
href="https://doi.org/10.1007/s10462-022-10155-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online education has been facing difficulty in predicting the academic performance of students due to the lack of usage of learning process, summative data and a precise prediction of quantitative relations between variables and achievements. To address these two obstacles, this study develops an artificial intelligence-enabled prediction model for student academic performance based on students’ learning process and summative data. The prediction criteria are first predefined to characterize and convert the learning data in an online engineering course. An evolutionary computation technique is then used to explore the best prediction model for the student academic performance. The model is validated using another online course that applies the same pedagogy and technology. Satisfactory agreements are obtained between the course outputs and model prediction results. The main findings indicate that the dominant variables in academic performance are the knowledge acquisition, the participation in class and the summative performance. The prerequisite knowledge tends not to play a key role in academic performance. Based on the results, pedagogical and analytical implications are provided. The proposed evolutionary computation-enabled prediction method is found to be a viable tool to evaluate the learning performance of students in online courses. Furthermore, the reported genetic programming model provides an acceptable prediction performance compared to other powerful artificial intelligence methods.},
  archive      = {J_AIR},
  author       = {Jiao, Pengcheng and Ouyang, Fan and Zhang, Qianyun and Alavi, Amir H.},
  doi          = {10.1007/s10462-022-10155-y},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6321-6344},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial intelligence-enabled prediction model of student academic performance in online engineering education},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EnvGAN: A GAN-based augmentation to improve environmental
sound classification. <em>AIR</em>, <em>55</em>(8), 6301–6320. (<a
href="https://doi.org/10.1007/s10462-022-10153-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several deep learning algorithms have emerged for the automatic classification of environmental sounds. However, the non-availability of adequate labeled data for training limits the performance of these algorithms. Data augmentation is an appropriate solution to this problem. Generative Adversarial Networks (GANs) can successfully generate synthetic speech and sounds of musical instruments for classification applications. In this paper, we present a method for GAN-based augmentation in the context of environmental sound classification. We introduce an architecture named EnvGAN for the adversarial generation of environmental sounds. To validate the quality of the generated sounds, we have conducted subjective and objective evaluations. The results indicate that EnvGAN can produce samples of various domains with an acceptable target quality. We applied this augmentation technique on three benchmark ESC datasets (ESC-10, UrbanSound8K, and TUT Urban Acoustic Scenes development dataset) and used it for training a CNN-based classifier. Experimental results show that this new augmentation method can outperform a baseline method with no augmentation by a relatively wide margin (10–12\% on ESC-10, 5–7\% on UrbanSound8K, and 4–5\% on TUT). In particular, the GAN-based approach reduces the confusion between all pairs of classes on UrbanSound8K. That is, the proposed method is especially suitable for handling class-imbalanced datasets.},
  archive      = {J_AIR},
  author       = {Madhu, Aswathy and K., Suresh},
  doi          = {10.1007/s10462-022-10153-0},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6301-6320},
  shortjournal = {Artif. Intell. Rev.},
  title        = {EnvGAN: A GAN-based augmentation to improve environmental sound classification},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An analysis of graph convolutional networks and recent
datasets for visual question answering. <em>AIR</em>, <em>55</em>(8),
6277–6300. (<a
href="https://doi.org/10.1007/s10462-022-10151-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network is a deep learning approach widely applied on structural and non-structural scenarios due to its substantial performance and interpretability recently. In a non-structural scenario, textual and visual research topics like visual question answering (VQA) are important, which need graph reasoning models. VQA aims to build a system that can answer related questions about given images as well as understand the underlying semantic meaning behind the image. The critical issues in VQA are to effectively extract the visual and textual features and subject both features into a common space. These issues have a great impact in handling goal-driven, reasoning, and scene classification subtasks. In the same vein, it is difficult to compare models&#39; performance because most existing datasets do not group instances into meaningful categories. With the recent advances in graph-based models, lots of efforts have been devoted to solving the problems mentioned above. This study focuses on graph convolutional networks (GCN) studies and recent datasets for visual question answering tasks. Specifically, we reviewed current related studies on GCN for the VQA task. Also, 18 common and recent datasets for VQA are well studied, though not all of them are discussed at the same level of detail. A critical review of GCN, datasets and VQA challenges is further highlighted. Finally, this study will help researchers to choose a suitable dataset for a particular VQA subtask, identify VQA challenges, the pros and cons of its approaches, and improve more on GCN for the VQA.},
  archive      = {J_AIR},
  author       = {Yusuf, Abdulganiyu Abdu and Chong, Feng and Xianling, Mao},
  doi          = {10.1007/s10462-022-10151-2},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6277-6300},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An analysis of graph convolutional networks and recent datasets for visual question answering},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the joint-effect of class imbalance and overlap: A
critical review. <em>AIR</em>, <em>55</em>(8), 6207–6275. (<a
href="https://doi.org/10.1007/s10462-022-10150-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current research on imbalanced data recognises that class imbalance is aggravated by other data intrinsic characteristics, among which class overlap stands out as one of the most harmful. The combination of these two problems creates a new and difficult scenario for classification tasks and has been discussed in several research works over the past two decades. In this paper, we argue that despite some insightful information can be derived from related research, the joint-effect of class overlap and imbalance is still not fully understood, and advocate for the need to move towards a unified view of the class overlap problem in imbalanced domains. To that end, we start by performing a thorough analysis of existing literature on the joint-effect of class imbalance and overlap, elaborating on important details left undiscussed on the original papers, namely the impact of data domains with different characteristics and the behaviour of classifiers with distinct learning biases. This leads to the hypothesis that class overlap comprises multiple representations, which are important to accurately measure and analyse in order to provide a full characterisation of the problem. Accordingly, we devise two novel taxonomies, one for class overlap measures and the other for class overlap-based approaches, both resonating with the distinct representations of class overlap identified. This paper therefore presents a global and unique view on the joint-effect of class imbalance and overlap, from precursor work to recent developments in the field. It meticulously discusses some concepts taken as implicit in previous research, explores new perspectives in light of the limitations found, and presents new ideas that will hopefully inspire researchers to move towards a unified view on the problem and the development of suitable strategies for imbalanced and overlapped domains.},
  archive      = {J_AIR},
  author       = {Santos, Miriam Seoane and Abreu, Pedro Henriques and Japkowicz, Nathalie and Fernández, Alberto and Soares, Carlos and Wilk, Szymon and Santos, João},
  doi          = {10.1007/s10462-022-10150-3},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6207-6275},
  shortjournal = {Artif. Intell. Rev.},
  title        = {On the joint-effect of class imbalance and overlap: A critical review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A formal proof and simple explanation of the QuickXplain
algorithm. <em>AIR</em>, <em>55</em>(8), 6185–6206. (<a
href="https://doi.org/10.1007/s10462-022-10149-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In his seminal paper of 2004, Ulrich Junker proposed the QuickXplain algorithm, which provides a divide-and-conquer computation strategy to find within a given set an irreducible subset with a particular (monotone) property. Beside its original application in the domain of constraint satisfaction problems, the algorithm has since then found widespread adoption in areas as different as model-based diagnosis, recommender systems, verification, or the Semantic Web. This popularity is due to the frequent occurrence of the problem of finding irreducible subsets on the one hand, and to QuickXplain’s general applicability and favorable computational complexity on the other hand. However, although (we regularly experience) people are having a hard time understanding QuickXplain and seeing why it works correctly, a proof of correctness of the algorithm has never been published. This is what we account for in this work, by explaining QuickXplain in a novel tried and tested way and by presenting an intelligible formal proof of it. Apart from showing the correctness of the algorithm and excluding the later detection of errors (proof and trust effect), the added value of the availability of a formal proof is, e.g., (i) that the workings of the algorithm often become completely clear only after studying, verifying and comprehending the proof (didactic effect), (ii) that the shown proof methodology can be used as a guidance for proving other recursive algorithms (transfer effect), and (iii) the possibility of providing “gapless” correctness proofs of systems that rely on (results computed by) QuickXplain, such as numerous model-based debuggers (completeness effect).},
  archive      = {J_AIR},
  author       = {Rodler, Patrick},
  doi          = {10.1007/s10462-022-10149-w},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6185-6206},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A formal proof and simple explanation of the QuickXplain algorithm},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AI on the edge: A comprehensive review. <em>AIR</em>,
<em>55</em>(8), 6125–6183. (<a
href="https://doi.org/10.1007/s10462-022-10141-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the Internet of Everything, the proliferation of data has put a huge burden on data centers and network bandwidth. To ease the pressure on data centers, edge computing, a new computing paradigm, is gradually gaining attention. Meanwhile, artificial intelligence services based on deep learning are also thriving. However, such intelligent services are usually deployed in data centers, which cause high latency. The combination of edge computing and artificial intelligence provides an effective solution to this problem. This new intelligence paradigm is called edge intelligence. In this paper, we focus on edge training and edge inference, the prior training models using local data at the resource-constrained edge devices. The latter deploying models at the edge devices through model compression and inference acceleration. This paper provides a comprehensive survey of existing architectures, technologies, frameworks and implementations in these two areas, and discusses existing challenges, possible solutions and future directions. We believe that this survey will make more researchers aware of edge intelligence.},
  archive      = {J_AIR},
  author       = {Su, Weixing and Li, Linfeng and Liu, Fang and He, Maowei and Liang, Xiaodan},
  doi          = {10.1007/s10462-022-10141-4},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6125-6183},
  shortjournal = {Artif. Intell. Rev.},
  title        = {AI on the edge: A comprehensive review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attention, please! A survey of neural attention models in
deep learning. <em>AIR</em>, <em>55</em>(8), 6037–6124. (<a
href="https://doi.org/10.1007/s10462-022-10148-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In humans, Attention is a core property of all perceptual and cognitive operations. Given our limited ability to process competing sources, attention mechanisms select, modulate, and focus on the information most relevant to behavior. For decades, concepts and functions of attention have been studied in philosophy, psychology, neuroscience, and computing. For the last 6 years, this property has been widely explored in deep neural networks. Currently, the state-of-the-art in Deep Learning is represented by neural attention models in several application domains. This survey provides a comprehensive overview and analysis of developments in neural attention models. We systematically reviewed hundreds of architectures in the area, identifying and discussing those in which attention has shown a significant impact. We also developed and made public an automated methodology to facilitate the development of reviews in the area. By critically analyzing 650 works, we describe the primary uses of attention in convolutional, recurrent networks, and generative models, identifying common subgroups of uses and applications. Furthermore, we describe the impact of attention in different application domains and their impact on neural networks’ interpretability. Finally, we list possible trends and opportunities for further research, hoping that this review will provide a succinct overview of the main attentional models in the area and guide researchers in developing future approaches that will drive further improvements.},
  archive      = {J_AIR},
  author       = {de Santana Correia, Alana and Colombini, Esther Luna},
  doi          = {10.1007/s10462-022-10148-x},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6037-6124},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Attention, please! a survey of neural attention models in deep learning},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Video super-resolution based on deep learning: A
comprehensive survey. <em>AIR</em>, <em>55</em>(8), 5981–6035. (<a
href="https://doi.org/10.1007/s10462-022-10147-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video super-resolution (VSR) is reconstructing high-resolution videos from low resolution ones. Recently, the VSR methods based on deep neural networks have made great progress. However, there is rarely systematical review on these methods. In this survey, we comprehensively investigate 37 state-of-the-art VSR methods based on deep learning. It is well known that the leverage of information contained in video frames is important for video super-resolution. Thus we propose a taxonomy and classify the methods into seven sub-categories according to the ways of utilizing inter-frame information. Moreover, descriptions on the architecture design and implementation details are also included. Finally, we summarize and compare the performance of the representative VSR methods on some benchmark datasets. We also discuss the applications, and some challenges, which need to be further addressed by researchers in the community of VSR. To the best of our knowledge, this work is the first systematic review on VSR tasks, and it is expected to make a contribution to the development of recent studies in this area and potentially deepen our understanding of the VSR techniques based on deep learning.},
  archive      = {J_AIR},
  author       = {Liu, Hongying and Ruan, Zhubo and Zhao, Peng and Dong, Chao and Shang, Fanhua and Liu, Yuanyuan and Yang, Linlin and Timofte, Radu},
  doi          = {10.1007/s10462-022-10147-y},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5981-6035},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Video super-resolution based on deep learning: A comprehensive survey},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of deep learning-based recommender system in
e-learning environments. <em>AIR</em>, <em>55</em>(8), 5953–5980. (<a
href="https://doi.org/10.1007/s10462-022-10135-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the recent emergence of a large number of online course resources has made life more convenient for many people, it has also caused information overload. According to a user’s situation and behavior, course recommendation systems can recommend courses of interest to the user, so that the user can quickly sift through a massive amount of information to find courses that meet his or her needs. This paper provide a systematic review of deep learning-based recommendation systems in e-learning environments. Firstly, the concept of recommendation systems is introduced in e-learning environments, and present a comprehensive survey and classification of deep learning techniques for course recommendation. And then, a detailed analysis of existing recommendation system is conducted based on the collected literature, and an overall course recommendation system framework is presented. Subsequently, this artical main focus is on multilayer perceptual machines, recurrent neural networks, convolutional neural networks, neural attention mechanisms, and deep reinforcement learning-based recommendation, and summarize the existing research on the use of the five techniques mentioned above in e-learning environments. The last section discusses seven flaws in the current recommendation systems used in e-learning environments and identify opportunities for future research.},
  archive      = {J_AIR},
  author       = {Liu, Tieyuan and Wu, Qiong and Chang, Liang and Gu, Tianlong},
  doi          = {10.1007/s10462-022-10135-2},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5953-5980},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of deep learning-based recommender system in e-learning environments},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computational knowledge vision: Paradigmatic knowledge based
prescriptive learning and reasoning for perception and vision.
<em>AIR</em>, <em>55</em>(8), 5917–5952. (<a
href="https://doi.org/10.1007/s10462-022-10166-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper outlines a novel advanced framework that combines structurized knowledge and visual models—Computational Knowledge Vision. In advanced studies of image and visual perception, a visual model’s understanding and reasoning ability often determines whether it works well in complex scenarios. This paper presents the state-of-the-art mainstream of vision models for visual perception. This paper then proposes a concept and basic framework of Computational Knowledge Vision that extends the knowledge engineering methodology to the computer vision field. In this paper, we first retrospect prior work related to Computational Knowledge Vision in the light of the connectionist and symbolist streams. We discuss neural network models, meta-learning models, graph models, and Transformer models in detail. We then illustrate a basic framework for Computational Knowledge Vision, whose essential techniques include structurized knowledge, knowledge projection, and conditional feedback. The goal of the framework is to enable visual models to gain the ability of representation, understanding, and reasoning. We also describe in-depth works in Computational Knowledge Vision and its extensions in other fields.},
  archive      = {J_AIR},
  author       = {Zheng, Wenbo and Yan, Lan and Gou, Chao and Wang, Fei-Yue},
  doi          = {10.1007/s10462-022-10166-9},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5917-5952},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Computational knowledge vision: Paradigmatic knowledge based prescriptive learning and reasoning for perception and vision},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal hybrid participation of customers in a smart
micro-grid based on day-ahead electrical market. <em>AIR</em>,
<em>55</em>(7), 5891–5915. (<a
href="https://doi.org/10.1007/s10462-022-10154-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of main challenges in the many countries with attention to growth people in the world is sustainable consumption and production of energy to improve environmental and economic issues by smart energy systems. In this paper, a multi-objective function model is developed to supply the demand of a smart micro-grid (SMG) with the aim of minimizing first) the operation cost, second) the emission pollution, and third) the deviation between the original demand curve and its desired level in the day-ahead time period. The third proposed objective function is a new strategy which can be used by the SMG operators to manage the demand consumption through responsible customers (RCs) with shiftable loads. Moreover, a number of consumers can participate in the energy management problem of the system through curtailing the demand as a reserve. The proposed objective functions are optimized to obtain the non-dominated solutions using the epsilon-constraint method. Then, the best solution is selected using combined fuzzy and Weighted sum approaches. To evaluate the effectiveness of the proposed model and its solution approach, it is applied on a test system considering four different case studies. The emission pollution and operation cost in the first case (base case) are 8832.24 kg and $692,930.2. In second case and with the participation of reserve, the reduction of the operation cost and the emission are equal to 6.03\% and 7.98\% than first case. With the participation of the demand shifting strategy in third case, operation cost and the emission are decreased by 20.2\% and 19.89\% according to base case. Finally, in fourth case and with participation of reserve and demand shifting strategy, the operation cost and the emission pollution are reduced by 26.5\% and 38.1\% in comparison with the base case.},
  archive      = {J_AIR},
  author       = {Chamandoust, Heydar},
  doi          = {10.1007/s10462-022-10154-z},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5891-5915},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Optimal hybrid participation of customers in a smart micro-grid based on day-ahead electrical market},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modality specific u-net variants for biomedical image
segmentation: A survey. <em>AIR</em>, <em>55</em>(7), 5845–5889. (<a
href="https://doi.org/10.1007/s10462-022-10152-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of advancements in deep learning approaches, such as deep convolution neural network, residual neural network, adversarial network; U-Net architectures are most widely utilized in biomedical image segmentation to address the automation in identification and detection of the target regions or sub-regions. In recent studies, U-Net based approaches have illustrated state-of-the-art performance in different applications for the development of computer-aided diagnosis systems for early diagnosis and treatment of diseases such as brain tumor, lung cancer, alzheimer, breast cancer, etc., using various modalities. This article contributes in presenting the success of these approaches by describing the U-Net framework, followed by the comprehensive analysis of the U-Net variants by performing (1) inter-modality, and (2) intra-modality categorization to establish better insights into the associated challenges and solutions. Besides, this article also highlights the contribution of U-Net based frameworks in the ongoing pandemic, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) also known as COVID-19. Finally, the strengths and similarities of these U-Net variants are analysed along with the challenges involved in biomedical image segmentation to uncover promising future research directions in this area.},
  archive      = {J_AIR},
  author       = {Punn, Narinder Singh and Agarwal, Sonali},
  doi          = {10.1007/s10462-022-10152-1},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5845-5889},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Modality specific U-net variants for biomedical image segmentation: A survey},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Putting ridesharing to the test: Efficient and scalable
solutions and the power of dynamic vehicle relocation. <em>AIR</em>,
<em>55</em>(7), 5781–5844. (<a
href="https://doi.org/10.1007/s10462-022-10145-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the optimization of large-scale, real-time ridesharing systems and propose a modular design methodology, Component Algorithms for Ridesharing (CAR). We evaluate a diverse set of CARs (14 in total), focusing on the key algorithmic components of ridesharing. We take a multi-objective approach, evaluating 10 metrics related to global efficiency, complexity, passenger, and platform incentives, in settings designed to closely resemble reality in every aspect, focusing on vehicles of capacity two. To the best of our knowledge, this is the largest and most comprehensive evaluation to date. We (i) identify CARs that perform well on global, passenger, or platform metrics, (ii) demonstrate that lightweight relocation schemes can significantly improve the Quality of Service by up to $$50\%$$ , and (iii) highlight a practical, scalable, on-device CAR that works well across all metrics.},
  archive      = {J_AIR},
  author       = {Danassis, Panayiotis and Sakota, Marija and Filos-Ratsikas, Aris and Faltings, Boi},
  doi          = {10.1007/s10462-022-10145-0},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5781-5844},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Putting ridesharing to the test: Efficient and scalable solutions and the power of dynamic vehicle relocation},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on sentiment analysis methods, applications, and
challenges. <em>AIR</em>, <em>55</em>(7), 5731–5780. (<a
href="https://doi.org/10.1007/s10462-022-10144-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of Internet-based applications, such as social media platforms and blogs, has resulted in comments and reviews concerning day-to-day activities. Sentiment analysis is the process of gathering and analyzing people’s opinions, thoughts, and impressions regarding various topics, products, subjects, and services. People’s opinions can be beneficial to corporations, governments, and individuals for collecting information and making decisions based on opinion. However, the sentiment analysis and evaluation procedure face numerous challenges. These challenges create impediments to accurately interpreting sentiments and determining the appropriate sentiment polarity. Sentiment analysis identifies and extracts subjective information from the text using natural language processing and text mining. This article discusses a complete overview of the method for completing this task as well as the applications of sentiment analysis. Then, it evaluates, compares, and investigates the approaches used to gain a comprehensive understanding of their advantages and disadvantages. Finally, the challenges of sentiment analysis are examined in order to define future directions.},
  archive      = {J_AIR},
  author       = {Wankhade, Mayur and Rao, Annavarapu Chandra Sekhara and Kulkarni, Chaitanya},
  doi          = {10.1007/s10462-022-10144-1},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5731-5780},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on sentiment analysis methods, applications, and challenges},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). When AI meets store layout design: A review. <em>AIR</em>,
<em>55</em>(7), 5707–5729. (<a
href="https://doi.org/10.1007/s10462-022-10142-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient store layout presents merchandise to attract customer attention and encourages customers to walk down more aisles which exposes them to more merchandise, which has been shown to be positively correlated with the sales. It is one of the most effective in-store marketing tactics which can directly influence customer decisions to boost store sales and profitability. The recent development of Artificial Intelligence techniques, especially with its sub-fields in Computer Vision and Deep Learning, has enabled retail stores to take advantage of existing CCTV infrastructure to extract in-store customer and business insights. This research aims to conduct a comprehensive review on existing approaches in store layout design and modern AI techniques that can be utilized in the layout design task. Based on this review, we propose an AI-powered store layout design framework. This framework applies advanced AI and data analysis techniques on top of existing CCTV video surveillance infrastructure to understand, predict and suggest a better store layout.},
  archive      = {J_AIR},
  author       = {Nguyen, Kien and Le, Minh and Martin, Brett and Cil, Ibrahim and Fookes, Clinton},
  doi          = {10.1007/s10462-022-10142-3},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5707-5729},
  shortjournal = {Artif. Intell. Rev.},
  title        = {When AI meets store layout design: A review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Employing a genetic algorithm and grey wolf optimizer for
optimizing RF models to evaluate soil liquefaction potential.
<em>AIR</em>, <em>55</em>(7), 5673–5705. (<a
href="https://doi.org/10.1007/s10462-022-10140-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among the research hotspots in geological/geotechnical engineering, research on the prediction of soil liquefaction potential is still limited. In this research, several machine-learning methods were developed to evaluate the liquefaction potential of soil using random forest (RF) as the base model. The parameters of the RF model were optimized using two optimization algorithms, namely, the grey wolf optimizer (GWO) and genetic algorithm (GA). In the experiment, three in situ databases based on the standard penetration test (SPT), shear wave velocity test (SWVT) and cone penetration test (CPT) were considered and used to investigate the applicability of GA-RF and GWO-RF models. For comparison purposes, a single RF model was also constructed to predict soil liquefaction. The developed models in this study were evaluated using four metrics, i.e., accuracy, recall, precision and F1-score (F1). Furthermore, receiver operating characteristic and precision-recall curves were also proposed for evaluation purposes. The results showed that the developed GA-RF and GWO-RF models can improve the performance of the original classifier. By comparing the two hybrid models, it was found that the GWO-RF performs better on two databases, i.e., CPT and SPT, while in the case of the SWVT database, the GA-RF has better performance. Considering a variety of metrics, the two hybrid models can be employed as powerful techniques to estimate soil liquefaction potential and may be feasible tools to assist technicians in making correct decisions. By implementing sensitivity analysis, the impact of each model predictor on soil liquefaction was evaluated, and the most influential parameters were identified.},
  archive      = {J_AIR},
  author       = {Zhou, Jian and Huang, Shuai and Zhou, Tao and Armaghani, Danial Jahed and Qiu, Yingui},
  doi          = {10.1007/s10462-022-10140-5},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5673-5705},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Employing a genetic algorithm and grey wolf optimizer for optimizing RF models to evaluate soil liquefaction potential},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). When CCN meets MCGDM: Optimal cache replacement policy
achieved by PRSRV with pythagorean fuzzy set pair analysis.
<em>AIR</em>, <em>55</em>(7), 5621–5671. (<a
href="https://doi.org/10.1007/s10462-022-10139-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cache replacement policy (CRP) in content-centric network (CCN) can reduce cache redundancy, optimize cache utility, and improve network performance. When assessing the CRPs in CCN, it is often full of great uncertainty. Set pair analysis (SPA) is a pioneering uncertainty theory, which consists of three components of the connection number (CN), and overlaps with Pythagorean fuzzy set. The goal of this article is to concentrate on multi-criteria group decision-making (MCGDM) method under Pythagorean fuzzy SPA environment. For it, some revised Pythagorean fuzzy aggregation operators are given for integrating multiple group information as one. Then, the CN has been constructed, and the distance measure between CNs is proposed. Later, the CN score function based distance measure is introduced for dealing with the comparison issue. In addition, the combined weight determining method by fusing the subjective weight preference and objective weight technology (water-filling theory) is shown. Subsequently, the PRSRV MCGDM approach fusing with aggregation operator, distance measure, score function and combined weight is developed for evaluating CRPs. In the end, a comparison with some existing approaches indicates that the developed approach has strong data adaptability.},
  archive      = {J_AIR},
  author       = {Peng, Xindong and Huang, Haihui and Luo, Zhigang},
  doi          = {10.1007/s10462-022-10139-y},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5621-5671},
  shortjournal = {Artif. Intell. Rev.},
  title        = {When CCN meets MCGDM: Optimal cache replacement policy achieved by PRSRV with pythagorean fuzzy set pair analysis},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved grey wolf optimizer based on opposition and quasi
learning approaches for optimization: Case study autonomous vehicle
including vision system. <em>AIR</em>, <em>55</em>(7), 5597–5620. (<a
href="https://doi.org/10.1007/s10462-022-10137-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adapting of lateral deviation during the change of road curvature with less error, system settling time, and overshoot is the main challenge against the steering angle control of autonomous vehicles (AVs). In this regard, this paper introduces new learning techniques defined opposition-based learning (OBL) and quasi OBL (QOBL) to improve the exploration as well as exploitation manner of the grey wolf optimizer (GWO). The involved approach can enhance the searching behavior of the original GWO against the trapping in local optima. The proposed modified GWO (MGWO) is applied to detect the optimal factors of the adaptive model predictive control (AMPC) for AVs. The suggested MGWO-based AMPC is evaluated with the classical MPC and the adaptive fuzzy logic controller. Furthermore, the inspired MGWO is compared with the original GWO, neural network algorithm (NNA), heap-based optimizer, and equilibrium optimizer in literature. The performance of the introduced technique is tested to follow different road curvatures. Moreover, the presented method is approved against the time delay of the vision system and the produced uncertainty of system variables from the change of vehicle speed and look–ahead distance. Furthermore, the introduced MGWO-based AMPC can tackle the system settling time and overshoot to be less than 1 s and 1.696\% respectively for the response of lateral deviation compared to other techniques. The attained results emphasize that the proposed MGWO-based AMPC controller has high damped and effective performance evaluated with other controllers.},
  archive      = {J_AIR},
  author       = {Elsisi, M.},
  doi          = {10.1007/s10462-022-10137-0},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5597-5620},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Improved grey wolf optimizer based on opposition and quasi learning approaches for optimization: Case study autonomous vehicle including vision system},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximate reasoning with aggregation functions satisfying
GMP rules. <em>AIR</em>, <em>55</em>(7), 5575–5595. (<a
href="https://doi.org/10.1007/s10462-022-10136-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To strengthen the effectiveness of approximate reasoning in fuzzy modus ponens (FMP) and fuzzy modus tollens (FMT) problems, three approximate reasoning methods with aggregation functions are developed and their validity are investigated respectively in this paper. We firstly study some properties of fuzzy implication generated by an aggregation function. And then present an A-compositional rule of inference as an extension of Zadeh’s CRI replacing t-norm by aggregation function. The similarity-based approximate reasoning with aggregation function is further discussed. Moreover, we provide the quintuple implication principle method with aggregation function to solve FMP and FMT problems. Finally, the validity of three approximate reasoning approaches is analyzed respectively using GMP rules in detail.},
  archive      = {J_AIR},
  author       = {Li, Dechao and Zeng, Qingxue},
  doi          = {10.1007/s10462-022-10136-1},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5575-5595},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Approximate reasoning with aggregation functions satisfying GMP rules},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). KnowMIS-ABSA: An overview and a reference model for
applications of sentiment analysis and aspect-based sentiment analysis.
<em>AIR</em>, <em>55</em>(7), 5543–5574. (<a
href="https://doi.org/10.1007/s10462-021-10134-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of the opinions of customers and users has been always of great interest in supporting decision-making in many fields, especially in marketing. Sentiment analysis (SA) is the umbrella term for techniques and approaches that analyze user’s sentiments, emotions, opinions in text or other media. The need for a better understanding of these opinions paved the way to novel approaches that focus on the analysis of the sentiment related to specific features of a product, giving birth to the field of aspect-based sentiment analysis (ABSA). Although the increasing interest in this discipline, there is still confusion regarding the basic concepts of ABSA: terms like sentiment, affect, emotion, opinion, are used as synonyms while they represent different concepts. This often leads to an incorrect analysis of the users’ opinions.This work presents an overview of the state-of-the-art techniques and approaches for ABSA, highlighting the main critical issues related to current trends in this field. Following this analysis, a new reference model for SA and ABSA, namely the KnowMIS-ABSA model, is proposed. The model is grounded on the consideration that sentiment, affect, emotion and opinion are very different concepts and that it is profoundly wrong to use the same metric and the same technique to measure them. Accordingly, we argue that different tools and metrics should be adopted to measure each of the dimensions of an opinion. A qualitative case study, regarding product reviews, is proposed to motivate the advantages of the KnowMIS-ABSA model.},
  archive      = {J_AIR},
  author       = {D’Aniello, Giuseppe and Gaeta, Matteo and La Rocca, Ilaria},
  doi          = {10.1007/s10462-021-10134-9},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5543-5574},
  shortjournal = {Artif. Intell. Rev.},
  title        = {KnowMIS-ABSA: An overview and a reference model for applications of sentiment analysis and aspect-based sentiment analysis},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-way decision model under a large-scale group
decision-making environment with detecting and managing non-cooperative
behaviors in consensus reaching process. <em>AIR</em>, <em>55</em>(7),
5517–5542. (<a
href="https://doi.org/10.1007/s10462-021-10133-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming of this paper is to introduce large-scale group decision-making (LSGDM) into three-way decisions (3WDs) with decision-theoretic rough sets (DTRSs) and propose LSGDM based 3WDs under linguistic assessments. There are two parameters involved of the 3WDs with DTRSs such as conditional probability and loss functions. Here we mainly focus on the calculation of loss function using LSGDM approach. LSGDM problem is characterized by a large number of experts, multiple clusters and a mass of evaluation data given by the experts. In some cases, experts are unwilling to revise their opinions to reach a consensus. So, the proper management of experts opinions and their non-cooperative behaviors (NCBs) is necessary to establish a consensus model. An appropriate adjustment of the credibility information is also essential. Using the clustering method, the proposed model divides the experts with similar evaluations into a subgroup. In each cluster, the experts’ opinions are then aggregate. In order to measure the level of consensus among clusters, the cluster consensus index (CCI) and group consensus index (GCI) have been developed. Then, using a tool for managing the NCBs of clusters includes two components: (1) for identifying the NCBs of clusters, NCB degree has defined using CCI and GCI; (2) for consensus improvement, implemented the weight punishment mechanism to NCBs clusters. Finally, we have designed a rule for classifying the objects into three regions, and the associated cost of each object is derived for ranking the objects in each region. An example is offered for selection of the Energy project to show the effectiveness of the proposed approach.},
  archive      = {J_AIR},
  author       = {Mandal, Prasenjit and Samanta, Sovan and Pal, Madhumangal and Ranadive, A. S.},
  doi          = {10.1007/s10462-021-10133-w},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5517-5542},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Three-way decision model under a large-scale group decision-making environment with detecting and managing non-cooperative behaviors in consensus reaching process},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven effort estimation techniques of agile user
stories: A systematic literature review. <em>AIR</em>, <em>55</em>(7),
5485–5516. (<a
href="https://doi.org/10.1007/s10462-021-10132-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At an early stage in the development process, a development team must obtain insight into the software being developed to establish a reliable plan. Thus, the team members should investigate, in depth, any information relating to the development. A major challenge for developers is software development effort estimation (SDEE), which refers to gauging the amount of effort needed to develop the software. In agile methodologies, a project is delivered in iterations, each of which delivers a set of requirements known as user stories. Therefore, SDEE in agile focuses on estimating a single user story’s effort, not the project as a whole, as in traditional development. Among the various techniques, data-driven methods have proved effective in effort estimation, as they are unaffected by external pressure from managers. Moreover, no experts have to be available at the point when estimation is undertaken. By conducting a systematic literature review, this study presents a comprehensive overview of data-driven techniques for user story effort estimation. The results show that there has been limited work on this topic. Studies were analysed to address questions covering five main points: technique; performance evaluation method; accuracy, independent factors (effort drivers); and the characteristics of the datasets. The main performance evaluation methods are performance measures, baseline benchmarks, statistical tests, distribution of estimates, comparison against similar existing techniques and human estimation. Four types of independent factors were identified: personnel; product; process; and estimation. Furthermore, the story point was found to be the most frequently used effort metric in agile user stories.},
  archive      = {J_AIR},
  author       = {Alsaadi, Bashaer and Saeedi, Kawther},
  doi          = {10.1007/s10462-021-10132-x},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5485-5516},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Data-driven effort estimation techniques of agile user stories: A systematic literature review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solutions to the routing problem: Towards trustworthy
autonomous vehicles. <em>AIR</em>, <em>55</em>(7), 5445–5484. (<a
href="https://doi.org/10.1007/s10462-021-10131-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The general expectation is that the traffic in the cities will be almost optimal when the collective behaviour of autonomous vehicles will determine the traffic. Each member of the collective of autonomous vehicles tries to adapt to the changing environment, therefore together they execute decentralised autonomous adaptation by exploiting real-time information about their environment. The routing of these vehicles needs proper computer science models to be able to develop the best information technology for their control. We review different traffic flow models in computer science, and we evaluate their usefulness and applicability to autonomous vehicles. The classical game theory model implies flow level decision making in route selection. Non-cooperative autonomous vehicles may produce unwanted traffic patterns. Improved decentralised autonomous adaptation techniques try to establish some kind of coordination among autonomous vehicles, mainly through intention awareness. The aggregation of the intentions of autonomous vehicles may help to predict future traffic situations. The novel intention-aware online routing game model points out that intention-awareness helps to avoid that the traffic generated by autonomous vehicles be worse than the traffic indicated by classical traffic flow models. The review helps to make the first steps towards research on global level control of autonomous vehicles by highlighting the strengths and weaknesses of the different formal models. The review also highlights the importance of research on intention-awareness and intention-aware traffic flow prediction methods.},
  archive      = {J_AIR},
  author       = {Varga, László Z.},
  doi          = {10.1007/s10462-021-10131-y},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5445-5484},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Solutions to the routing problem: Towards trustworthy autonomous vehicles},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid approach combining AHP with TODIM for blockchain
technology provider selection under the pythagorean fuzzy scenario.
<em>AIR</em>, <em>55</em>(7), 5411–5443. (<a
href="https://doi.org/10.1007/s10462-021-10128-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology draws worldwide attraction in the latest decade, and distributed ledger technology is widely used in various fields to increase efficiency, fairness, and security based on trust mechanisms. Blockchain technology represents a useful underlying technology to ensure trust in cross-border remittances for major banks and financial institutions. The selection of the appropriate blockchain technology provider is viewed as a classic multicriteria group decision-making (MCGDM) problem, which can be resolved to assist major banks in enhancing the quality of cross-border work. This article presents a combined MCGDM technique uniting the analytic hierarchy process (AHP) and TODIM, a Portuguese acronym for interactive multi-criteria decision making, for selecting an appropriate blockchain technology provider with Pythagorean fuzzy (PF) information. First, we establish hierarchical criteria for assessing the performance of blockchain technology providers in accordance with the available literature and characteristics of cross-border remittance work. Second, we adopt the PF–AHP technique to acquire relevant criterion weights, considering uncertainties of the decision-makers’ judgments over the criteria. Third, we utilize the PF–TODIM technique to compute the relevant dominance degree of the providers, taking into account the decision-makers’ psychological behaviors and preferences toward the risk of the blockchain technology. Fourth, we apply the proposed PF–AHP–TODIM technique to choose the appropriate blockchain provider for cross-border remittance work for a major bank and validate the efficiency and practicability of this hybrid technique over other available MCGDM methods.},
  archive      = {J_AIR},
  author       = {Zhou, Fang and Chen, Ting-Yu},
  doi          = {10.1007/s10462-021-10128-7},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5411-5443},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A hybrid approach combining AHP with TODIM for blockchain technology provider selection under the pythagorean fuzzy scenario},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Group decision-making with fermatean fuzzy soft expert
knowledge. <em>AIR</em>, <em>55</em>(7), 5349–5389. (<a
href="https://doi.org/10.1007/s10462-021-10119-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of population, the global impact of solar technology is increasing by the day due to its advantages over other power production technologies. Demand for solar panel systems is soaring, thus provoking the arrival of many new manufacturers. Sale dealers or suppliers face an uncertain problem to choose the most adequate technological solution. To effectively address such kind of issues, in this paper we propose the Fermatean fuzzy soft expert set model by combining Fermatean fuzzy sets and soft expert sets. We describe this hybrid model with numerical examples. From a theoretical standpoint, we demonstrate some essential properties and define operations for this setting. They comprise the definitions of complement, union and intersection, the OR operation and the AND operation. Concerning practice in this new environment, we provide an algorithm for multi-criteria group decision making whose productiveness and authenticity is dutifully tested. We explore a practical application of this approach (that is, the selection of a suitable brand of solar panel system). Lastly, we give a comparison of our model with certain related mathematical tools, including fuzzy and intuitionistic fuzzy soft expert set models.},
  archive      = {J_AIR},
  author       = {Akram, Muhammad and Ali, Ghous and Alcantud, José Carlos R. and Riaz, Aneesa},
  doi          = {10.1007/s10462-021-10119-8},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5349-5389},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Group decision-making with fermatean fuzzy soft expert knowledge},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attribute reduction in an incomplete categorical decision
information system based on fuzzy rough sets. <em>AIR</em>,
<em>55</em>(7), 5313–5348. (<a
href="https://doi.org/10.1007/s10462-021-10117-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Categorical data is an important class of data in machine learning. Information system based on categorical data is called a categorical information system (CIS), a CIS with missing values is known as an incomplete categorical information system (ICIS) and an ICIS with decision attributes is said to be an incomplete categorical decision information system (ICDIS). Attribute selection is an important subject in rough set theory. This paper investigates attribute reduction in an ICDIS based on fuzzy rough sets. To depict the similarity for incomplete categorical data, fuzzy symmetry relations in an ICDIS are first introduced. Then, some attribute-evaluation functions, such fuzzy positive regions, dependency function and attribute importance functions are given. Next, the fuzzy-rough iterative computation model for an ICDIS is presented, and an attribute reduction algorithm in an ICDIS based on fuzzy rough sets is given. Finally, experiments are carried out as so to evaluate the performance of the proposed algorithm, and Friedman test and Bonferroni-Dunn test in statistics are conducted. The experimental results indicate that the proposed algorithm is more effective than some existing algorithms.},
  archive      = {J_AIR},
  author       = {He, Jiali and Qu, Liangdong and Wang, Zhihong and Chen, Yiying and Luo, Damei and Wen, Ching-Feng},
  doi          = {10.1007/s10462-021-10117-w},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5313-5348},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Attribute reduction in an incomplete categorical decision information system based on fuzzy rough sets},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Brain-inspired models for visual object recognition: An
overview. <em>AIR</em>, <em>55</em>(7), 5263–5311. (<a
href="https://doi.org/10.1007/s10462-021-10130-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual object recognition is one of the most fundamental and challenging research topics in the field of computer vision. The research on the neural mechanism of the primates’ recognition function may bring revolutionary breakthroughs in brain-inspired vision. This Review aims to systematically review the recent works on the intersection of computational neuroscience and computer vision. It attempts to investigate the current brain-inspired object recognition models and their underlying visual neural mechanism. According to the technical architecture and exploitation methods, we describe the brain-inspired object recognition models and their advantages and disadvantages in realizing brain-inspired object recognition. We focus on analyzing the similarity between the artificial and biological neural network, and studying the biological credibility of the current popular DNN-based visual benchmark models. The analysis provides a guide for researchers to measure the occasion and condition when conducting visual object recognition research.},
  archive      = {J_AIR},
  author       = {Yang, Xi and Yan, Jie and Wang, Wen and Li, Shaoyi and Hu, Bo and Lin, Jian},
  doi          = {10.1007/s10462-021-10130-z},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5263-5311},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Brain-inspired models for visual object recognition: An overview},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The role of artificial intelligence and machine learning in
wireless networks security: Principle, practice and challenges.
<em>AIR</em>, <em>55</em>(7), 5215–5261. (<a
href="https://doi.org/10.1007/s10462-022-10143-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security is one of the biggest challenges concerning networks and communications. The problem becomes aggravated with the proliferation of wireless devices. Artificial Intelligence (AI) has emerged as a promising solution and a volume of literature exists on the methodological studies of AI to resolve the security challenge. In this survey, we present a taxonomy of security threats and review distinct aspects and the potential of AI to resolve the challenge. To the best of our knowledge, this is the first comprehensive survey to review the AI solutions for all possible security types and threats. We also present the lessons learned from the existing AI techniques and contributions of up-to-date literature, future directions of AI in security, open issues that need to be investigated further through AI, and discuss how AI can be more effectively used to overcome the upcoming advanced security threats.},
  archive      = {J_AIR},
  author       = {Waqas, Muhammad and Tu, Shanshan and Halim, Zahid and Rehman, Sadaqat Ur and Abbas, Ghulam and Abbas, Ziaul Haq},
  doi          = {10.1007/s10462-022-10143-2},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5215-5261},
  shortjournal = {Artif. Intell. Rev.},
  title        = {The role of artificial intelligence and machine learning in wireless networks security: Principle, practice and challenges},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Persistent-homology-based machine learning: A survey and a
comparative study. <em>AIR</em>, <em>55</em>(7), 5169–5213. (<a
href="https://doi.org/10.1007/s10462-022-10146-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A suitable feature representation that can both preserve the data intrinsic information and reduce data complexity and dimensionality is key to the performance of machine learning models. Deeply rooted in algebraic topology, persistent homology (PH) provides a delicate balance between data simplification and intrinsic structure characterization, and has been applied to various areas successfully. However, the combination of PH and machine learning has been hindered greatly by three challenges, namely topological representation of data, PH-based distance measurements or metrics, and PH-based feature representation. With the development of topological data analysis, progresses have been made on all these three problems, but widely scattered in different literatures. In this paper, we provide a systematical review of PH and PH-based supervised and unsupervised models from a computational perspective. Our emphasizes are the recent development of mathematical models and tools, including PH software and PH-based functions, feature representations, kernels, and similarity models. Essentially, this paper can work as a roadmap for the practical application of PH-based machine learning tools. Further, we compare between two types of simplicial complexes (alpha and Vietrois-Rips complexes), two types of feature extractions (barcode statistics and binned features), and three types of machine learning models (support vector machines, tree-based models, and neural networks), and investigate their impacts on the protein secondary structure classification.},
  archive      = {J_AIR},
  author       = {Pun, Chi Seng and Lee, Si Xian and Xia, Kelin},
  doi          = {10.1007/s10462-022-10146-z},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5169-5213},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Persistent-homology-based machine learning: A survey and a comparative study},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design possibilities and challenges of DNN models: A review
on the perspective of end devices. <em>AIR</em>, <em>55</em>(7),
5109–5167. (<a
href="https://doi.org/10.1007/s10462-022-10138-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Network (DNN) models for both resource-rich environments and resource-constrained devices have become abundant in recent years. As of now, the literature on different available options for the design, development, and deployment of DNN models to resource constrained-end devices is limited and demands extensive further study. This paper reviews vital research efforts for the design of DNN models while deploying them at the end devices such as smart cameras for real-time object detection tasks. The design ideas include the types of DNN models, hardware and software requirements for the development, resource constraints imposed by the computing devices, and the optimization techniques required for the efficient processing of DNN. The study also aims to conduct a systematic literature review on current trends in different real-time applications of DNN models and explores the following four dimensions: (1) DNN model perspective: to associate appropriate DNN models with the proper hardware to achieve optimal throughput. (2) Hardware perspective: to answer different available options in hardware platforms for achieving on-device intelligence. (3) Resources and optimization perspective: to analyze the type of resource limitations in hardware platforms and the use of optimization techniques to overcome the performance issues. (4) Application perspective: to understand the real-time uses of DNN models in different application domains. This work also explores different performance measures that need to be considered for on-device intelligence and provides possible future directions for the challenges reviewed.},
  archive      = {J_AIR},
  author       = {Hussain, Hanan and Tamizharasan, P. S. and Rahul, C. S.},
  doi          = {10.1007/s10462-022-10138-z},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5109-5167},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Design possibilities and challenges of DNN models: A review on the perspective of end devices},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Resources and components for gujarati NLP systems: A survey.
<em>AIR</em>, <em>55</em>(7), 1–19. (<a
href="https://doi.org/10.1007/s10462-021-10120-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural Language Processing (NLP) represents the task of automatic handling of natural human language by machines. There is a large spectrum of possible NLP applications which aid in automating tasks like text translation amongst languages, retrieving and summarizing data from very huge and complex repositories, spam email filtering, identifying fake news in digital media, finding political opinions, views and sentiments of people on various government policies, providing effective medical assistance based on past history records of patients etc. Gujarati language is an Indian language with more than sixty million users worldwide. At present, many efforts are laid for developing NLP applications and resources for Indian languages. This survey gives a taxonomy and comprehensive report regarding component and resource development for Gujarati NLP systems. Also, few prominent tools available in open domain are tested, and their posterior analysis is presented. Possible measures to handle the issues in resource and component development of Gujarati NLP system are also discussed. This report might be useful for industry, researchers and academicians to have a clear picture of the research gaps, challenges and opportunities in Gujarati NLP systems.},
  archive      = {J_AIR},
  author       = {Desai, Nikita P. and Dabhi, Vipul K.},
  doi          = {10.1007/s10462-021-10120-1},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Resources and components for gujarati NLP systems: A survey},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A complete framework for accurate recognition and prognosis
of COVID-19 patients based on deep transfer learning and feature
classification approach. <em>AIR</em>, <em>55</em>(6), 5063–5108. (<a
href="https://doi.org/10.1007/s10462-021-10127-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sudden appearance of COVID-19 has put the world in a serious situation. Due to the rapid spread of the virus and the increase in the number of infected patients and deaths, COVID-19 was declared a pandemic. This pandemic has its destructive effect not only on humans but also on the economy. Despite the development and availability of different vaccines for COVID-19, scientists still warn the citizens of new severe waves of the virus, and as a result, fast diagnosis of COVID-19 is a critical issue. Chest imaging proved to be a powerful tool in the early detection of COVID-19. This study introduces an entire framework for the early detection and early prognosis of COVID-19 severity in the diagnosed patients using laboratory test results. It consists of two phases (1) Early Diagnostic Phase (EDP) and (2) Early Prognostic Phase (EPP). In EDP, COVID-19 patients are diagnosed using CT chest images. In the current study, 5, 159 COVID-19 and 10, 376 normal computed tomography (CT) images of Egyptians were used as a dataset to train 7 different convolutional neural networks using transfer learning. Data augmentation normal techniques and generative adversarial networks (GANs), CycleGAN and CCGAN, were used to increase the images in the dataset to avoid overfitting issues. 28 experiments were applied and multiple performance metrics were captured. Classification with no augmentation yielded $$99.61\%$$ accuracy by EfficientNetB7 architecture. By applying CycleGAN and CC-GAN Augmentation, the maximum reported accuracies were $$99.57\%$$ and $$99.14\%$$ by MobileNetV1 and VGG-16 architectures respectively. In EPP, the prognosis of the severity of COVID-19 in patients is early determined using laboratory test results. In this study, 25 different classification techniques were applied and from the different results, the highest accuracies were $$98.70\%$$ and $$97.40\%$$ reported by the Ensemble Bagged Trees and Tree (Fine, Medium, and Coarse) techniques respectively.},
  archive      = {J_AIR},
  author       = {Balaha, Hossam Magdy and El-Gendy, Eman M. and Saafan, Mahmoud M.},
  doi          = {10.1007/s10462-021-10127-8},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5063-5108},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A complete framework for accurate recognition and prognosis of COVID-19 patients based on deep transfer learning and feature classification approach},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-criteria decision-making for coronavirus disease 2019
applications: A theoretical analysis review. <em>AIR</em>,
<em>55</em>(6), 4979–5062. (<a
href="https://doi.org/10.1007/s10462-021-10124-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The influence of the ongoing COVID-19 pandemic that is being felt in all spheres of our lives and has a remarkable effect on global health care delivery occurs amongst the ongoing global health crisis of patients and the required services. From the time of the first detection of infection amongst the public, researchers investigated various applications in the fight against the COVID-19 outbreak and outlined the crucial roles of different research areas in this unprecedented battle. In the context of existing studies in the literature surrounding COVID-19, related to medical treatment decisions, the dimensions of context addressed in previous multidisciplinary studies reveal the lack of appropriate decision mechanisms during the COVID-19 outbreak. Multiple criteria decision making (MCDM) has been applied widely in our daily lives in various ways with numerous successful stories to help analyse complex decisions and provide an accurate decision process. The rise of MCDM in combating COVID-19 from a theoretical perspective view needs further investigation to meet the important characteristic points that match integrating MCDM and COVID-19. To this end, a comprehensive review and an analysis of these multidisciplinary fields, carried out by different MCDM theories concerning COVID19 in complex case studies, are provided. Research directions on exploring the potentials of MCDM and enhancing its capabilities and power through two directions (i.e. development and evaluation) in COVID-19 are thoroughly discussed. In addition, Bibliometrics has been analysed, visualization and interpretation based on the evaluation and development category using R-tool involves; annual scientific production, country scientific production, Wordcloud, factor analysis in bibliographic, and country collaboration map. Furthermore, 8 characteristic points that go through the analysis based on new tables of information are highlighted and discussed to cover several important facts and percentages associated with standardising the evaluation criteria, MCDM theory in ranking alternatives and weighting criteria, operators used with the MCDM methods, normalisation types for the data used, MCDM theory contexts, selected experts ways, validation scheme for effective MCDM theory and the challenges of MCDM theory used in COVID-19 studies. Accordingly, a recommended MCDM theory solution is presented through three distinct phases as a future direction in COVID19 studies. Key phases of this methodology include the Fuzzy Delphi method for unifying criteria and establishing importance level, Fuzzy weighted Zero Inconsistency for weighting to mitigate the shortcomings of the previous weighting techniques and the MCDM approach by the name Fuzzy Decision by Opinion Score method for prioritising alternatives and providing a unique ranking solution. This study will provide MCDM researchers and the wider community an overview of the current status of MCDM evaluation and development methods and motivate researchers in harnessing MCDM potentials in tackling an accurate decision for different fields against COVID-19.},
  archive      = {J_AIR},
  author       = {Alsalem, M. A. and Alamoodi, A. H. and Albahri, O. S. and Dawood, K. A. and Mohammed, R. T. and Alnoor, Alhamzah and Zaidan, A. A. and Albahri, A. S. and Zaidan, B. B. and Jumaah, F. M. and Al-Obaidi, Jameel R.},
  doi          = {10.1007/s10462-021-10124-x},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4979-5062},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-criteria decision-making for coronavirus disease 2019 applications: A theoretical analysis review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using artificial intelligence technology to fight COVID-19:
A review. <em>AIR</em>, <em>55</em>(6), 4941–4977. (<a
href="https://doi.org/10.1007/s10462-021-10106-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In late December 2019, a new type of coronavirus was discovered, which was later named severe acute respiratory syndrome coronavirus 2(SARS-CoV-2). Since its discovery, the virus has spread globally, with 2,975,875 deaths as of 15 April 2021, and has had a huge impact on our health systems and economy. How to suppress the continued spread of new coronary pneumonia is the main task of many scientists and researchers. The introduction of artificial intelligence technology has provided a huge contribution to the suppression of the new coronavirus. This article discusses the main application of artificial intelligence technology in the suppression of coronavirus from three major aspects of identification, prediction, and development through a large amount of literature research, and puts forward the current main challenges and possible development directions. The results show that it is an effective measure to combine artificial intelligence technology with a variety of new technologies to predict and identify COVID-19 patients.},
  archive      = {J_AIR},
  author       = {Peng, Yong and Liu, Enbin and Peng, Shanbi and Chen, Qikun and Li, Dangjian and Lian, Dianpeng},
  doi          = {10.1007/s10462-021-10106-z},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4941-4977},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Using artificial intelligence technology to fight COVID-19: A review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decision support modeling for multiple criteria assessments
using a likelihood-based consensus ranking method under pythagorean
fuzzy uncertainty. <em>AIR</em>, <em>55</em>(6), 4879–4939. (<a
href="https://doi.org/10.1007/s10462-021-10122-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper intends to exploit point operator-oriented likelihood measures to constitute a likelihood-based consensus ranking model aimed at conducting multiple criteria decision making encompassing complex uncertain evaluations with Pythagorean fuzzy sets. This paper takes advantage of Pythagorean fuzzy point operators and the scalar functions of upper and lower estimations to formulate a point operator-oriented likelihood measure for preference intensity. On this basis, this paper propounds the notion of penalty weights to characterize dominated relations for acquiring the measurement of comprehensive disagreement and constituting a likelihood-based consensus ranking model. The primary contributions of this study are fourfold. Firstly, two useful point operators are initiated for upper and lower estimations towards Pythagorean membership grades. Secondly, an effective likelihood measure is exploited for determining outranking relations of Pythagorean fuzzy information. Thirdly, a pragmatic concept of penalty weights is proposed for characterizing the dominated relations among alternatives and measuring degrees of comprehensive disagreement. Fourthly, a functional likelihood-based consensus ranking model is constructed for implementing a multiple criteria evaluation with Pythagorean fuzzy uncertainty. Furthermore, a real-life application relating to a financing problem is presented to provide a justification for the practicability of the proposed methodology. This paper executes an analysis of parameters sensitivity and comparative studies for showing more theoretical insights.},
  archive      = {J_AIR},
  author       = {Chen, Ting-Yu},
  doi          = {10.1007/s10462-021-10122-z},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4879-4939},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Decision support modeling for multiple criteria assessments using a likelihood-based consensus ranking method under pythagorean fuzzy uncertainty},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive review of computer-aided whole-slide image
analysis: From datasets to feature extraction, segmentation,
classification and detection approaches. <em>AIR</em>, <em>55</em>(6),
4809–4878. (<a
href="https://doi.org/10.1007/s10462-021-10121-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of Computer-aided Diagnosis (CAD) and image scanning techniques, Whole-slide Image (WSI) scanners are widely used in the field of pathological diagnosis. Therefore, WSI analysis has become the key to modern digital histopathology. Since 2004, WSI has been used widely in CAD. Since machine vision methods are usually based on semi-automatic or fully automatic computer algorithms, they are highly efficient and labor-saving. The combination of WSI and CAD technologies for segmentation, classification, and detection helps histopathologists to obtain more stable and quantitative results with minimum labor costs and improved diagnosis objectivity. This paper reviews the methods of WSI analysis based on machine learning. Firstly, the development status of WSI and CAD methods are introduced. Secondly, we discuss publicly available WSI datasets and evaluation metrics for segmentation, classification, and detection tasks. Then, the latest development of machine learning techniques in WSI segmentation, classification, and detection are reviewed. Finally, the existing methods are studied, and the application prospects of the methods in this field are forecasted.},
  archive      = {J_AIR},
  author       = {Li, Xintong and Li, Chen and Rahaman, Md Mamunur and Sun, Hongzan and Li, Xiaoqi and Wu, Jian and Yao, Yudong and Grzegorzek, Marcin},
  doi          = {10.1007/s10462-021-10121-0},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4809-4878},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive review of computer-aided whole-slide image analysis: From datasets to feature extraction, segmentation, classification and detection approaches},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human activity recognition in artificial intelligence
framework: A narrative review. <em>AIR</em>, <em>55</em>(6), 4755–4808.
(<a href="https://doi.org/10.1007/s10462-021-10116-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) has multifaceted applications due to its worldly usage of acquisition devices such as smartphones, video cameras, and its ability to capture human activity data. While electronic devices and their applications are steadily growing, the advances in Artificial intelligence (AI) have revolutionized the ability to extract deep hidden information for accurate detection and its interpretation. This yields a better understanding of rapidly growing acquisition devices, AI, and applications, the three pillars of HAR under one roof. There are many review articles published on the general characteristics of HAR, a few have compared all the HAR devices at the same time, and few have explored the impact of evolving AI architecture. In our proposed review, a detailed narration on the three pillars of HAR is presented covering the period from 2011 to 2021. Further, the review presents the recommendations for an improved HAR design, its reliability, and stability. Five major findings were: (1) HAR constitutes three major pillars such as devices, AI and applications; (2) HAR has dominated the healthcare industry; (3) Hybrid AI models are in their infancy stage and needs considerable work for providing the stable and reliable design. Further, these trained models need solid prediction, high accuracy, generalization, and finally, meeting the objectives of the applications without bias; (4) little work was observed in abnormality detection during actions; and (5) almost no work has been done in forecasting actions. We conclude that: (a) HAR industry will evolve in terms of the three pillars of electronic devices, applications and the type of AI. (b) AI will provide a powerful impetus to the HAR industry in future.},
  archive      = {J_AIR},
  author       = {Gupta, Neha and Gupta, Suneet K. and Pathak, Rajesh K. and Jain, Vanita and Rashidi, Parisa and Suri, Jasjit S.},
  doi          = {10.1007/s10462-021-10116-x},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4755-4808},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Human activity recognition in artificial intelligence framework: A narrative review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy covering-based rough set on two different universes
and its application. <em>AIR</em>, <em>55</em>(6), 4717–4753. (<a
href="https://doi.org/10.1007/s10462-021-10115-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new type of fuzzy covering-based rough set model over two different universes by using Zadeh’s extension principle. We mainly address the following issues in this paper. First, we present the definition of fuzzy $$\beta$$ -neighborhood, which can be seen as a fuzzy mapping from a universe to the set of fuzzy sets on another universe and study its properties. Then we define a new type of fuzzy covering-based rough set model on two different universes and investigate the properties of this model. Meanwhile, we give a necessary and sufficient condition under which two fuzzy $$\beta$$ -coverings to generate the same fuzzy covering lower approximation or the same fuzzy covering upper approximation. Moreover, matrix representations of the fuzzy covering lower and fuzzy covering upper approximation operators are investigated. Finally, we propose a new approach to a kind of multiple criteria decision making problem based on fuzzy covering-based rough set model over two universes. The proposed models not only enrich the theory of fuzzy covering-based rough set but also provide a new perspective for multiple criteria decision making with uncertainty.},
  archive      = {J_AIR},
  author       = {Yang, Bin},
  doi          = {10.1007/s10462-021-10115-y},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4717-4753},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Fuzzy covering-based rough set on two different universes and its application},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel improved whale optimization algorithm to solve
numerical optimization and real-world applications. <em>AIR</em>,
<em>55</em>(6), 4605–4716. (<a
href="https://doi.org/10.1007/s10462-021-10114-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whale optimization algorithm (WOA) has been developed based on the hunting behavior of humpback whales. Though it has a considerable convergence speed, WOA suffers from diversity in the solution due to the low exploration of search space. As a result, it tends to trap in local optima and suffer from low solution accuracy. This study proposes a novel improved WOA method (ImWOA) with increased diversity in the solution to avoid the aforesaid gaps. The random solution selection process in the search prey phase is altered to increase exploration. The whale&#39;s cooperative hunting strategy is also incorporated in the algorithm&#39;s exploitation phase to balance the exploration and exploitation phase of WOA. Also, the total iterations are divided into two halves explicitly for exploration and exploitation purposes. The modifications facilitate WOA to jump out of local optima, increase solution accuracy, and increase convergence speed. The experiments were carried out evaluating IEEE CEC 2017 functions in dimensions 10, 30, 50, and 100. The performances were compared with basic algorithms as well as recent WOA variants. Three engineering design problems have also been solved to check its problem-solving ability and compared with a wide range of algorithms. Moreover, the image segmentation problem with multiple thresholding approaches has been solved by using the proposed ImWOA. Comparing results with state-of-the-art algorithms and modified WOAs, statistical analysis, diversity analysis, and convergence analysis validate that ImWOA is superior or competitive.},
  archive      = {J_AIR},
  author       = {Chakraborty, Sanjoy and Sharma, Sushmita and Saha, Apu Kumar and Saha, Ashim},
  doi          = {10.1007/s10462-021-10114-z},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4605-4716},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A novel improved whale optimization algorithm to solve numerical optimization and real-world applications},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey paper on design and implementation of multipliers
for digital system applications. <em>AIR</em>, <em>55</em>(6),
4575–4603. (<a
href="https://doi.org/10.1007/s10462-021-10113-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiplication is one of the essential functions in all digital systems. The evaluation of digital system, have brought out new challenges in VLSI (Very Large Scale Integration) designing. Multipliers are generally utilized in digital signal processing. Increasing technology has maximized the demand for rapid and efficient real-time digital signal processing applications. A huge number of multiplier designs have been developed for improving its speed. This manuscript provides an exploration of the different studies that have been conducted since 2015. This manuscript reviews investigation depends on various types of multipliers. A thorough statistical analysis is provided in this review which was conducted by extracting information from 100 papers published between the years 2015–2020. When comparing the adders, obtain the Ripple Carry Adder had lesser area while it had lower speed, in contrast to Carry Select Adders they are great speed but greater area. A Carry Look Ahead Adder sits among spectrum has a suitable balance among complexities of time and area. After designing and comparing the adders, turned to multipliers. At first opted for Parallel Multiplier and then Wallace Tree Multiplier. Meanwhile, learned the amount of delay was greatly decreased while Carry Save Adders were utilized on Wallace Tree applications. In this review, present the comparison and analysis of investigation manuscript depends on several criteria. In general, this manuscript summarizes the current state of knowledge of these multipliers. In this, the comparative analysis depends on timeline, reputation of simulation tools and types of device components are analyzed.},
  archive      = {J_AIR},
  author       = {Immareddy, Srikanth and Sundaramoorthy, Aunmetha},
  doi          = {10.1007/s10462-021-10113-0},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4575-4603},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey paper on design and implementation of multipliers for digital system applications},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of most effected cycles and busiest network route
based on complexity function of graph in fuzzy environment.
<em>AIR</em>, <em>55</em>(6), 4557–4574. (<a
href="https://doi.org/10.1007/s10462-021-10111-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connectivity and strength has a major role in the field of network connecting with real world life. Complexity function is one of these parameter which has manifold number of applications in molecular chemistry and the theory of network. Firstly, this paper introduces the thought of complexity function of fuzzy graph with its properties. Second, based on the highest and lowest load on a network system, the boundaries of complexity function of different types of fuzzy graphs are established. Third, the behavior of complexity function in fuzzy cycle, fuzzy tree and complete fuzzy graph are discussed with their properties. Fourth, applications of these thoughts are bestowed to identify the most effected COVID-19 cycles between some communicated countries using the concept of complexity function of fuzzy graph. Also the selection of the busiest network stations and connected internet paths can be done using the same concept in a graphical wireless network system.},
  archive      = {J_AIR},
  author       = {Poulik, Soumitra and Ghorai, Ganesh},
  doi          = {10.1007/s10462-021-10111-2},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4557-4574},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Estimation of most effected cycles and busiest network route based on complexity function of graph in fuzzy environment},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comparison of vector symbolic architectures. <em>AIR</em>,
<em>55</em>(6), 4523–4555. (<a
href="https://doi.org/10.1007/s10462-021-10110-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vector Symbolic Architectures combine a high-dimensional vector space with a set of carefully designed operators in order to perform symbolic computations with large numerical vectors. Major goals are the exploitation of their representational power and ability to deal with fuzziness and ambiguity. Over the past years, several VSA implementations have been proposed. The available implementations differ in the underlying vector space and the particular implementations of the VSA operators. This paper provides an overview of eleven available VSA implementations and discusses their commonalities and differences in the underlying vector space and operators. We create a taxonomy of available binding operations and show an important ramification for non self-inverse binding operations using an example from analogical reasoning. A main contribution is the experimental comparison of the available implementations in order to evaluate (1) the capacity of bundles, (2) the approximation quality of non-exact unbinding operations, (3) the influence of combining binding and bundling operations on the query answering performance, and (4) the performance on two example applications: visual place- and language-recognition. We expect this comparison and systematization to be relevant for development of VSAs, and to support the selection of an appropriate VSA for a particular task. The implementations are available.},
  archive      = {J_AIR},
  author       = {Schlegel, Kenny and Neubert, Peer and Protzel, Peter},
  doi          = {10.1007/s10462-021-10110-3},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4523-4555},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comparison of vector symbolic architectures},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AI-aided general clinical diagnoses verified by
third-parties with dynamic uncertain causality graph extended to also
include classification. <em>AIR</em>, <em>55</em>(6), 4485–4521. (<a
href="https://doi.org/10.1007/s10462-021-10109-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI)-aided general clinical diagnosis is helpful to primary clinicians. Machine learning approaches have problems of generalization, interpretability, etc. Dynamic Uncertain Causality Graph (DUCG) based on uncertain casual knowledge provided by clinical experts does not have these problems. This paper extends DUCG to include the representation and inference algorithm for non-causal classification relationships. As a part of general clinical diagnoses, six knowledge bases corresponding to six chief complaints (arthralgia, dyspnea, cough and expectoration, epistaxis, fever with rash and abdominal pain) were constructed through constructing subgraphs relevant to a chief complaint separately and synthesizing them together as the knowledge base of the chief complaint. A subgraph represents variables and causalities related to a single disease that may cause the chief complaint, regardless of which hospital department the disease belongs to. Verified by two groups of third-party hospitals independently, total diagnostic precisions of the six knowledge bases ranged in 96.5–100\%, in which the precision for every disease was no less than 80\%.},
  archive      = {J_AIR},
  author       = {Zhang, Zhan and Jiao, Yang and Zhang, Mingxia and Wei, Bing and Liu, Xiao and Zhao, Juan and Tian, Fengwei and Hu, Jie and Zhang, Qin},
  doi          = {10.1007/s10462-021-10109-w},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4485-4521},
  shortjournal = {Artif. Intell. Rev.},
  title        = {AI-aided general clinical diagnoses verified by third-parties with dynamic uncertain causality graph extended to also include classification},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Advantage matrix: Two novel multi-attribute decision-making
methods and their applications. <em>AIR</em>, <em>55</em>(6), 4463–4484.
(<a href="https://doi.org/10.1007/s10462-021-10126-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By comparing attributes of objects in an information system, the advantage matrix on the object set is established in this paper. The contributions can be identified as follows: (1) The advantage degree is proposed by the accumulation of the advantage matrix. (2) Based on the advantage matrix, the advantage (disadvantage) neighborhood approximation operator and the advantage (disadvantage) correlation approximation operator are defined and studied. Based on these two new operators, the neighborhood degree and the correlation degree are presented. The relationships between them are also investigated to demonstrate the value of the proposed method. (3) Finally, based on the above three degrees, new algorithms are designed, in which the effectiveness and robustness of the algorithms are analyzed by practical examples.},
  archive      = {J_AIR},
  author       = {Yu, Bin and Xu, Zeshui},
  doi          = {10.1007/s10462-021-10126-9},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4463-4484},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Advantage matrix: Two novel multi-attribute decision-making methods and their applications},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adversarial example detection for DNN models: A review and
experimental comparison. <em>AIR</em>, <em>55</em>(6), 4403–4462. (<a
href="https://doi.org/10.1007/s10462-021-10125-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) has shown great success in many human-related tasks, which has led to its adoption in many computer vision based applications, such as security surveillance systems, autonomous vehicles and healthcare. Such safety-critical applications have to draw their path to success deployment once they have the capability to overcome safety-critical challenges. Among these challenges are the defense against or/and the detection of the adversarial examples (AEs). Adversaries can carefully craft small, often imperceptible, noise called perturbations to be added to the clean image to generate the AE. The aim of AE is to fool the DL model which makes it a potential risk for DL applications. Many test-time evasion attacks and countermeasures, i.e., defense or detection methods, are proposed in the literature. Moreover, few reviews and surveys were published and theoretically showed the taxonomy of the threats and the countermeasure methods with little focus in AE detection methods. In this paper, we focus on image classification task and attempt to provide a survey for detection methods of test-time evasion attacks on neural network classifiers. A detailed discussion for such methods is provided with experimental results for eight state-of-the-art detectors under different scenarios on four datasets. We also provide potential challenges and future perspectives for this research direction.},
  archive      = {J_AIR},
  author       = {Aldahdooh, Ahmed and Hamidouche, Wassim and Fezza, Sid Ahmed and Déforges, Olivier},
  doi          = {10.1007/s10462-021-10125-w},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4403-4462},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Adversarial example detection for DNN models: A review and experimental comparison},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual privacy attacks and defenses in deep learning: A
survey. <em>AIR</em>, <em>55</em>(6), 4347–4401. (<a
href="https://doi.org/10.1007/s10462-021-10123-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concerns on visual privacy have been increasingly raised along with the dramatic growth in image and video capture and sharing. Meanwhile, with the recent breakthrough in deep learning technologies, visual data can now be easily gathered and processed to infer sensitive information. Therefore, visual privacy in the context of deep learning is now an important and challenging topic. However, there has been no systematic study on this topic to date. In this survey, we discuss algorithms of visual privacy attacks and the corresponding defense mechanisms in deep learning. We analyze the privacy issues in both visual data and visual deep learning systems. We show that deep learning can be used as a powerful privacy attack tool as well as preservation techniques with great potential. We also point out the possible direction and suggestions for future work. By thoroughly investigating the relationship of visual privacy and deep learning, this article sheds insights on incorporating privacy requirements in the deep learning era.},
  archive      = {J_AIR},
  author       = {Zhang, Guangsheng and Liu, Bo and Zhu, Tianqing and Zhou, Andi and Zhou, Wanlei},
  doi          = {10.1007/s10462-021-10123-y},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4347-4401},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Visual privacy attacks and defenses in deep learning: A survey},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of inverse reinforcement learning. <em>AIR</em>,
<em>55</em>(6), 4307–4346. (<a
href="https://doi.org/10.1007/s10462-021-10108-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from demonstration, or imitation learning, is the process of learning to act in an environment from examples provided by a teacher. Inverse reinforcement learning (IRL) is a specific form of learning from demonstration that attempts to estimate the reward function of a Markov decision process from examples provided by the teacher. The reward function is often considered the most succinct description of a task. In simple applications, the reward function may be known or easily derived from properties of the system and hard coded into the learning process. However, in complex applications, this may not be possible, and it may be easier to learn the reward function by observing the actions of the teacher. This paper provides a comprehensive survey of the literature on IRL. This survey outlines the differences between IRL and two similar methods - apprenticeship learning and inverse optimal control. Further, this survey organizes the IRL literature based on the principal method, describes applications of IRL algorithms, and provides areas of future research.},
  archive      = {J_AIR},
  author       = {Adams, Stephen and Cody, Tyler and Beling, Peter A.},
  doi          = {10.1007/s10462-021-10108-x},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4307-4346},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of inverse reinforcement learning},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comparative review of graph convolutional networks for
human skeleton-based action recognition. <em>AIR</em>, <em>55</em>(5),
4275–4305. (<a
href="https://doi.org/10.1007/s10462-021-10107-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action recognition is one of the hottest topics in the research field, so there are many relevant review papers illustrating the multi-modality of data, the selection of feature vectors, and the pros and cons of classification networks. With the continuous development of relational networks, graph convolutional networks (GCNs) have been applied to many different fields, including human action recognition. Although the graph convolutional networks have been demonstrated the powerful functionality in human action recognition, few literatures review GCN-based human action recognition. In this review, we not only give a detailed introduction to the structure of graph convolutional networks and data modalities used for human action recognition, but also focus on the application of GCNs in the field of human action recognition. Most importantly, we conduct experiments on five benchmark datasets for comparing the performance of seven state-of-the-art GCN-based algorithms for human skeleton-based action recognition. The five datasets selected in the experiments cover data of different scales (large-scale vs. small-scale) and different types (single-person, human-object interaction, and two-person-interaction) to explore the promising applicable scope of graph networks. We adopt the frequently used performance metrics such as accuracy, network parameters and loss function. Specifically, we analyze the impact of the multi-stream fusion strategies on improving the performance of the human action recognition schemes. To our best knowledge, it is the first time to survey human action recognition strategies related to GCNs, and to give a thorough experimental comparison of GCN-based human action recognition techniques with various datasets.},
  archive      = {J_AIR},
  author       = {Feng, Liqi and Zhao, Yaqin and Zhao, Wenxuan and Tang, Jiaxi},
  doi          = {10.1007/s10462-021-10107-y},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4275-4305},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comparative review of graph convolutional networks for human skeleton-based action recognition},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Information-utilization strengthened equilibrium optimizer.
<em>AIR</em>, <em>55</em>(5), 4241–4274. (<a
href="https://doi.org/10.1007/s10462-021-10105-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equilibrium Optimizer (EO) is a novel meta-heuristic algorithm proposed in 2020 and it has a unique search mechanism and good optimization performance. To further improve its optimization performance, this paper proposes an Information-utilization Strengthened EO (IS-EO). Firstly, a cross EO (CEO) is constructed under the guidance of the historical individual-best information to strengthen information guiding. Secondly, a Global-best opposition learning CEO (GCEO) is created under the guidance of the global best information to a random individual to further strengthen information guiding. Finally, a differential mutation strategy is incorporated into GCEO to construct IS-EO and strengthen information sharing between individuals. Experimental results on the 65 benchmark functions and the 3 engineering design problems show that IS-EO attains stronger search ability and faster running speed compared with EO and other state-of-the-art comparison algorithms and can solve the engineering problems more effectively.},
  archive      = {J_AIR},
  author       = {Zhang, Xinming and Lin, Qiuying},
  doi          = {10.1007/s10462-021-10105-0},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4241-4274},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Information-utilization strengthened equilibrium optimizer},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive review of the video-to-text problem.
<em>AIR</em>, <em>55</em>(5), 4165–4239. (<a
href="https://doi.org/10.1007/s10462-021-10104-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research in the Vision and Language area encompasses challenging topics that seek to connect visual and textual information. When the visual information is related to videos, this takes us into Video-Text Research, which includes several challenging tasks such as video question answering, video summarization with natural language, and video-to-text and text-to-video conversion. This paper reviews the video-to-text problem, in which the goal is to associate an input video with its textual description. This association can be mainly made by retrieving the most relevant descriptions from a corpus or generating a new one given a context video. These two ways represent essential tasks for Computer Vision and Natural Language Processing communities, called text retrieval from video task and video captioning/description task. These two tasks are substantially more complex than predicting or retrieving a single sentence from an image. The spatiotemporal information present in videos introduces diversity and complexity regarding the visual content and the structure of associated language descriptions. This review categorizes and describes the state-of-the-art techniques for the video-to-text problem. It covers the main video-to-text methods and the ways to evaluate their performance. We analyze twenty-six benchmark datasets, showing their drawbacks and strengths for the problem requirements. We also show the progress that researchers have made on each dataset, we cover the challenges in the field, and we discuss future research directions.},
  archive      = {J_AIR},
  author       = {Perez-Martin, Jesus and Bustos, Benjamin and Guimarães, Silvio Jamil F. and Sipiran, Ivan and Pérez, Jorge and Said, Grethel Coello},
  doi          = {10.1007/s10462-021-10104-1},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4165-4239},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive review of the video-to-text problem},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid group decision-making technique under spherical fuzzy
n-soft expert sets. <em>AIR</em>, <em>55</em>(5), 4117–4163. (<a
href="https://doi.org/10.1007/s10462-021-10103-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the concept of a new hybrid model called spherical fuzzy N-soft expert sets, which is an extension of spherical fuzzy soft expert sets. The proposed model is highly suitable to describe the multinary data evaluation in terms of spherical fuzzy soft information considering multiple experts’ opinions. Some fundamental properties, including subset, weak complement, spherical fuzzy complement, spherical fuzzy weak complement, union, intersection, AND operation, and OR operation, are discussed. Our proposed concepts are explained with detailed examples. An efficient algorithm is developed to solve multi-attribute group decision-making (MAGDM) problems. Further, to guarantee the high applicability scope and flexibility of our initiated framework, two real-world MAGDM problems, that is, predicting local election results using survey ratings before the election and ranking credibility of the smartphones using customer feedback, are solved. Finally, to endorse the accuracy and advantages of the proposed technique, a comprehensive comparative analysis of the presented approach with existing models such as spherical fuzzy soft expert sets and N-soft sets is provided.},
  archive      = {J_AIR},
  author       = {Akram, Muhammad and Ali, Ghous and Peng, Xindong and Ul Abidin, Muhammad Zain},
  doi          = {10.1007/s10462-021-10103-2},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4117-4163},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Hybrid group decision-making technique under spherical fuzzy N-soft expert sets},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent advances of deep learning algorithms for aquacultural
machine vision systems with emphasis on fish. <em>AIR</em>,
<em>55</em>(5), 4077–4116. (<a
href="https://doi.org/10.1007/s10462-021-10102-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring the growth conditions and behavior of fish will enable scientific management, reduce the threat of losses caused by disease and stress. Traditional monitoring methods are time-consuming, laborious, and untimely monitoring readily leads to aquaculture accidents. As a non-invasive, objective, and repeatable tool, machine vision systems have been widely used in various aspects of aquaculture monitoring. Nevertheless, the complex underwater environment makes it difficult to obtain ideal data processing results only using traditional image processing methods. Due to their powerful feature extraction capabilities, deep learning (DL) algorithms have been widely used in underwater image processing. Hence, the combination of DL algorithms and machine vision for the automated monitoring of aquaculture is of great importance. As evidence for the multidisciplinary aspects of DL applications, attention is focused on the latest DL methods applied to five fields of research: classification, detection, counting, behavior recognition, and biomass estimation. Meanwhile, due to the low training efficiency of DL models caused by insufficient dataset, transfer learning and GAN have also put into spotlight of this filed to pursue high performance of DL models. We also present the challenges and benchmarks in terms of the advantages and disadvantages of the selected method in each field. In addition, we review the sources of image acquisition and pre-processing methods in aquaculture. Finally, the challenges and prospects of DL in aquaculture machine vision systems are discussed. The literature review shows that the deep neural networks such as AlexNet, LSTM, VGG, and GoogLeNet, have been used for aquaculture machine vision systems.},
  archive      = {J_AIR},
  author       = {Li, Daoliang and Du, Ling},
  doi          = {10.1007/s10462-021-10102-3},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4077-4116},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Recent advances of deep learning algorithms for aquacultural machine vision systems with emphasis on fish},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved arithmetic optimization algorithm for design
optimization of fuzzy controllers in steel building structures with
nonlinear behavior considering near fault ground motion effects.
<em>AIR</em>, <em>55</em>(5), 4041–4075. (<a
href="https://doi.org/10.1007/s10462-021-10101-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, near fault ground motions has been of great importance due to the difference in characteristics of earthquake records in the regions near to the active faults. Most of the developed control systems for structural vibration control have difficulties in dealing with these kinds of strong ground motions regarding the deficiencies of the human knowledge-based control systems such as fuzzy logic controllers for this purpose. Hence, the optimization of these controllers has been concerned in recent years. The main aim of this paper is to optimize the fuzzy controllers implemented in steel structures with nonlinear behavior in which the arithmetic optimization algorithm (AOA) is utilized as the main optimization algorithm while an improved version of this algorithm as IAOA is also proposed for performance enhancement of the standard algorithm. In the IAOA, a new parameter identification process is proposed in which the Levy flight as a well-known stochastic process with step length determined by levy distribution is implemented in the main loop of the AOA. The IAOA and AOA are utilized for optimization of the membership functions and the rule base of the fuzzy controllers implemented in a large-scale building structure. The overall performance of the IAOA is compared with the standard AOA and other metaheuristics. The obtained results of the improved method demonstrate the capability of this method in providing very competitive solutions which results in decreasing structural responses and damages of the considered building in dealing with the near-fault strong ground motions.},
  archive      = {J_AIR},
  author       = {Azizi, Mahdi and Talatahari, Siamak},
  doi          = {10.1007/s10462-021-10101-4},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4041-4075},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Improved arithmetic optimization algorithm for design optimization of fuzzy controllers in steel building structures with nonlinear behavior considering near fault ground motion effects},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Chaotic slime mould optimization algorithm for global
optimization. <em>AIR</em>, <em>55</em>(5), 3979–4040. (<a
href="https://doi.org/10.1007/s10462-021-10100-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic optimization methods; It is a well-known global optimization approach for large-scale search and optimization problems, commonly used to find the solution many different optimization problems. Slime mould optimization algorithm (SMA) is a recently presented metaheuristic technique that is inspired by the behavior of slime mould. Slow convergence speed is a fundamental problem in SMA as in other metaheuristic optimization methods. In order to improve the SMA method, 10 different chaotic maps have been applied for the first time in this article to generate chaotic values instead of random values in SMA. Using chaotic maps, it is aimed to increase the speed of SMA’s global convergence and prevent it from getting stuck in its local solutions. The Chaotic SMA (CSMA) proposed for the first time in this study was applied to 62 different benchmark functions. These are unimodal, multimodal, fixed dimension, CEC2019, and CEC2017 test suite. The results of the application have been comparatively analyzed and statistical analysis performed with the well-known metaheuristic optimization methods, particle swarm optimization and differential evolution algorithm, and recently proposed grey wolf optimization (GWO) and whale optimization algorithm (WOA). In addition, in the CEC2017 test suite, the CSMA method has been compared with the SMA, WOA, GWO, harris hawk optimization, archimedes optimization algorithm and COOT algorithms that have been proposed in recent years, and statistical analyzes have been made. In addition, CSMA has been tested in 3 different real-world engineering design problems. According to the experimental results, it was observed that CSMA achieved relatively more successful results in 62 different benchmark functions and real-world engineering design problems compared to other compared methods and standard SMA.},
  archive      = {J_AIR},
  author       = {Altay, Osman},
  doi          = {10.1007/s10462-021-10100-5},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3979-4040},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Chaotic slime mould optimization algorithm for global optimization},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SFSADE: An improved self-adaptive differential evolution
algorithm with a shuffled frog-leaping strategy. <em>AIR</em>,
<em>55</em>(5), 3937–3978. (<a
href="https://doi.org/10.1007/s10462-021-10099-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The differential evolution (DE) algorithm is an efficient random search algorithm based on swarm intelligence for solving optimization problems. It has the advantages of easy implementation, fast convergence, strong optimization ability and good robustness. However, the performance of DE is very sensitive to the design of different operators and the setting of control parameters. To solve these key problems, this paper proposes an improved self-adaptive differential evolution algorithm with a shuffled frog-leaping strategy (SFSADE). It innovatively incorporates the idea of the shuffled frog-leaping algorithm into DE, and at the same time, it cleverly introduces a new strategy of classification mutation, and also designs a new adaptive adjustment mechanism for control parameters. In addition, we have carried out a large number of simulation experiments on the 25 benchmark functions of CEC 2005 and two nonparametric statistical tests to comprehensively evaluate the performance of SFSADE. Finally, the results of simulation experiments and nonparametric statistical tests show that SFSADE is very effective in improving DE, and significantly improves the overall diversity of the population in the process of dynamic evolution. Compared with other advanced DE variants, its global search speed and optimization performance also has strong competitiveness.},
  archive      = {J_AIR},
  author       = {Pan, Qingtao and Tang, Jun and Wang, Haoran and Li, Hao and Chen, Xi and Lao, Songyang},
  doi          = {10.1007/s10462-021-10099-9},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3937-3978},
  shortjournal = {Artif. Intell. Rev.},
  title        = {SFSADE: An improved self-adaptive differential evolution algorithm with a shuffled frog-leaping strategy},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Consensus in multi-agent systems: A review. <em>AIR</em>,
<em>55</em>(5), 3897–3935. (<a
href="https://doi.org/10.1007/s10462-021-10097-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a review of the consensus problem as one of the most challenging issues in the distributed control of the multi-agent systems (MASs). In this survey, firstly, the consensus algorithms for the agents with the single-integrator, double-integrator and high-order dynamic models were collected from various research works, and the convergence condition for each of these algorithms was explained. Secondly, all the consensus-related problems such as those in the sampled-data consensus, quantized consensus, random-network consensus, leader–follower consensus, finite-time consensus, bipartite consensus, group consensus/cluster consensus, and the scaled consensus were analyzed and compared with each other. Thirdly, we focused on the common control techniques used for the consensus problems in the presence of disturbance and divided all these control methods into two categories: robust control and adaptive control. Finally, we reviewed the most prevalent consensus applications in the MASs, including the subjects of rendezvous, formation control, axial alignment and the wireless sensor networks.},
  archive      = {J_AIR},
  author       = {Amirkhani, Abdollah and Barshooi, Amir Hossein},
  doi          = {10.1007/s10462-021-10097-x},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3897-3935},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Consensus in multi-agent systems: A review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intuitionistic principal value z-linguistic hybrid geometric
operator and their applications for multi-attribute group
decision-making. <em>AIR</em>, <em>55</em>(5), 3863–3896. (<a
href="https://doi.org/10.1007/s10462-021-10096-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problems often encountered in the modeling of uncertain linguistic multi-attribute group decision-making in targeted poverty alleviation are how to describe and aggregate uncertain and imprecise information more effectively. In this paper, in order to effectively describe the fuzziness and reliability of linguistic evaluation information, and emphasize the role of linguistic evaluation value, we firstly propose this concept of the intuitionistic principal value Z-linguistic set. Then, we propose intuitionistic principal value Z-linguistic hybrid geometric operator regarding the position and ordered weight to aggregate linguistic evaluation information more effectively. Finally, an example of targeted poverty alleviation is given to illustrate effectiveness and superiority based on the operator with different position weights.},
  archive      = {J_AIR},
  author       = {Xian, Sidong and Liu, Renping and Yang, Zhijun and Li, Xin},
  doi          = {10.1007/s10462-021-10096-y},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3863-3896},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Intuitionistic principal value Z-linguistic hybrid geometric operator and their applications for multi-attribute group decision-making},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural attention for image captioning: Review of outstanding
methods. <em>AIR</em>, <em>55</em>(5), 3833–3862. (<a
href="https://doi.org/10.1007/s10462-021-10092-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning is the task of automatically generating sentences that describe an input image in the best way possible. The most successful techniques for automatically generating image captions have recently used attentive deep learning models. There are variations in the way deep learning models with attention are designed. In this survey, we provide a review of literature related to attentive deep learning models for image captioning. Instead of offering a comprehensive review of all prior work on deep image captioning models, we explain various types of attention mechanisms used for the task of image captioning in deep learning models. The most successful deep learning models used for image captioning follow the encoder-decoder architecture, although there are differences in the way these models employ attention mechanisms. Via analysis on performance results from different attentive deep models for image captioning, we aim at finding the most successful types of attention mechanisms in deep models for image captioning. Soft attention, bottom-up attention, and multi-head attention are the types of attention mechanism widely used in state-of-the-art attentive deep learning models for image captioning. At the current time, the best results are achieved from variants of multi-head attention with bottom-up attention.},
  archive      = {J_AIR},
  author       = {Zohourianshahzadi, Zanyar and Kalita, Jugal K.},
  doi          = {10.1007/s10462-021-10092-2},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3833-3862},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Neural attention for image captioning: Review of outstanding methods},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New measures of uncertainty based on the granularity
distribution of approximation sets. <em>AIR</em>, <em>55</em>(5),
3801–3831. (<a
href="https://doi.org/10.1007/s10462-021-10089-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty measures can help people to effectively analyze data and to reveal the essential characteristics of data sets. The roughness, accuracy and approximation accuracy are effective evaluations of uncertainty measure based on the lower and upper approximation sets in the classical rough set. However, due to the lack of consideration of the size of the granularity and the granulation distribution of approximation sets, the classical uncertainty measures and its improved methods still have suffered from some shortcomings, such as inaccurate measurement in some special cases, inconsistent with people&#39;s cognition and so on, which motivate the study in this paper. In view of the fact that the upper and lower approximation sets are the basic concepts which are used to express the imprecision of knowledge. The paper introduces a more appropriate measure for evaluating the uncertainty, which combines the granularity of knowledge, the cardinality of the lower and upper approximation sets and the granularity distribution of the lower and upper approximation sets. Firstly, the roughness and accuracy based on the granularity distribution of the approximation sets are proposed, and the corresponding properties of the new roughness and accuracy are discussed. Two types of definitions of the approximation accuracy are investigated in the decision systems and their some properties are induced. Theoretical analyses indicate that the proposed measurements can be used to reasonably evaluate the uncertainty of information systems and decision systems. Finally, some experiments on nine UCI data sets are conducted and experimental results demonstrate that the proposed methods of uncertainty measurements are effective for evaluating the uncertainty of rough sets.},
  archive      = {J_AIR},
  author       = {Hao, Ge and Chuanjian, Yang},
  doi          = {10.1007/s10462-021-10089-x},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3801-3831},
  shortjournal = {Artif. Intell. Rev.},
  title        = {New measures of uncertainty based on the granularity distribution of approximation sets},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on artificial intelligence techniques for chronic
diseases: Open issues and challenges. <em>AIR</em>, <em>55</em>(5),
3747–3800. (<a
href="https://doi.org/10.1007/s10462-021-10084-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) has given significant solutions to the healthcare domain for analyzing various chronic diseases. With the advent of high-end systems, i.e., Graphics Processing Units, AI widespread the healthcare domain, where human experts dominate. AI techniques make the early identification and diagnosis of diseases, which aid the clinicians in mitigating the associated risk. This survey comprehensively reviews the existing literature on AI-assisted chronic disease prediction by considering cancer, heart, and brain-related diseases. However, research is underway to design and develop efficient AI techniques to aid the early prediction of diseases and render valuable insights into the patient’s profile. We conclude with the open issues and challenges faced by the current AI techniques for the prediction and early detection of chronic diseases and discuss future work in the diagnosis of these diseases.},
  archive      = {J_AIR},
  author       = {Patel, Keyur and Mistry, Chinmay and Mehta, Dev and Thakker, Urvish and Tanwar, Sudeep and Gupta, Rajesh and Kumar, Neeraj},
  doi          = {10.1007/s10462-021-10084-2},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3747-3800},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on artificial intelligence techniques for chronic diseases: Open issues and challenges},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fine-grained attention-based phrase-aware network for
aspect-level sentiment analysis. <em>AIR</em>, <em>55</em>(5),
3727–3746. (<a
href="https://doi.org/10.1007/s10462-021-10080-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-level sentiment classification aims to identify the sentiment polarity of a specific aspect in a sentence. In recent years, many researchers have sought to explore aspect-specific representation via attention mechanisms. Although a remarkable improvement in aspect-level sentiment classification has been achieved, these methods still suffer from deteriorative performance in certain cases for multiple reasons. First, they adopt a coarse-grained attention mechanism, which may cause information loss when the contextual sentence is long or includes multiple sentiments, and the aspect contains multiple words. Second, they consider only the influence of contextual keywords on sentiment polarity, ignoring the importance of key phrases in a sentence. To address these issues, a phrase-aware neural network based on fine-grained attention,referred to as FAPN, is proposed. The FAPN employs a convolutional neural network to extract phrase representations in the context and concatenates the representations with the corresponding word vector as input. Additionally, a fine-grained attention module is designed to generate aspect-specific representations by capturing the word-level interactions between the aspect and the sentence. Extensive experiments on five widely used benchmark datasets demonstrate the effectiveness of the proposed FAPN method.},
  archive      = {J_AIR},
  author       = {Liao, Weizhi and Zhou, Jiarui and Wang, Yu and Yin, Yanchao and Zhang, Xiaobing},
  doi          = {10.1007/s10462-021-10080-6},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3727-3746},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Fine-grained attention-based phrase-aware network for aspect-level sentiment analysis},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey, taxonomy and progress evaluation of three decades
of swarm optimisation. <em>AIR</em>, <em>55</em>(5), 3607–3725. (<a
href="https://doi.org/10.1007/s10462-021-10095-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the concept of swarm intelligence was introduced in 1980s, the first swarm optimisation algorithm was introduced a decade later, in 1992. In this paper, nineteen representative original swarm optimisation algorithms are analysed to extract their common features and design a taxonomy for swarm optimisation. We use twenty-nine benchmark problems to compare the performance of these nineteen algorithms in the form they were first introduced in the literature against five state-of-the-art swarm algorithms. This comparison reveals the advancements made in this field over three decades. It reveals that, while the state-of-the-art swarm optimisation algorithms are indeed competitive in terms of the quality of solutions they find, their complexities have evolved to be more computationally demanding when compared to the nineteen original algorithms of swarm optimisation. The investigation suggests that there is an urge to continue to design swarm optimisation algorithms that are simpler, while maintaining their current competitive performance.},
  archive      = {J_AIR},
  author       = {Liu, Jing and Anavatti, Sreenatha and Garratt, Matthew and Tan, Kay Chen and Abbass, Hussein A.},
  doi          = {10.1007/s10462-021-10095-z},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3607-3725},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey, taxonomy and progress evaluation of three decades of swarm optimisation},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Federated learning attack surface: Taxonomy, cyber defences,
challenges, and future directions. <em>AIR</em>, <em>55</em>(5),
3569–3606. (<a
href="https://doi.org/10.1007/s10462-021-10098-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has received a great deal of research attention in the context of privacy protection restrictions. By jointly training deep learning models, a variety of training tasks can be competently performed with the help of invited participants. However, FL is concerned with a large number of attacks involving privacy and security aspects. This paper shows a federated learning workflow process and how a malicious client can exploit vulnerabilities in the FL system to attack the system. A systematic survey of existing research on the taxonomy of federated learning attack surface and the classification is presented. As with the FL attack surface, attackers compromise security, privacy, gain free incentives and abuse the Confidentiality, Integrity, and Availability (CIA) security triad. In addition, state-of-the-art defensive approaches against FL attacks are elaborated which help to protect and minimize the likelihood of attacks. FL models and tools for privacy attacks are explained, along with their best aspects and drawbacks. Finally, technical challenges and possible research guidelines are discussed as future work to build robust FL systems.},
  archive      = {J_AIR},
  author       = {Qammar, Attia and Ding, Jianguo and Ning, Huansheng},
  doi          = {10.1007/s10462-021-10098-w},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3569-3606},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Federated learning attack surface: Taxonomy, cyber defences, challenges, and future directions},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explainable artificial intelligence: A comprehensive review.
<em>AIR</em>, <em>55</em>(5), 3503–3568. (<a
href="https://doi.org/10.1007/s10462-021-10088-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to the exponential growth in computing power and vast amounts of data, artificial intelligence (AI) has witnessed remarkable developments in recent years, enabling it to be ubiquitously adopted in our daily lives. Even though AI-powered systems have brought competitive advantages, the black-box nature makes them lack transparency and prevents them from explaining their decisions. This issue has motivated the introduction of explainable artificial intelligence (XAI), which promotes AI algorithms that can show their internal process and explain how they made decisions. The number of XAI research has increased significantly in recent years, but there lacks a unified and comprehensive review of the latest XAI progress. This review aims to bridge the gap by discovering the critical perspectives of the rapidly growing body of research associated with XAI. After offering the readers a solid XAI background, we analyze and review various XAI methods, which are grouped into (i) pre-modeling explainability, (ii) interpretable model, and (iii) post-modeling explainability. We also pay attention to the current methods that dedicate to interpret and analyze deep learning methods. In addition, we systematically discuss various XAI challenges, such as the trade-off between the performance and the explainability, evaluation methods, security, and policy. Finally, we show the standard approaches that are leveraged to deal with the mentioned challenges.},
  archive      = {J_AIR},
  author       = {Minh, Dang and Wang, H. Xiang and Li, Y. Fen and Nguyen, Tan N.},
  doi          = {10.1007/s10462-021-10088-y},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3503-3568},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Explainable artificial intelligence: A comprehensive review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Traditional to transfer learning progression on scene text
detection and recognition: A survey. <em>AIR</em>, <em>55</em>(4),
3457–3502. (<a
href="https://doi.org/10.1007/s10462-021-10091-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many computer vision-based techniques utilize semantic information i.e. scene text present in a natural scene for image analysis. Subsequently, in recent times researchers pay more attention to key tasks such as scene text detection, recognition, and end-to-end system. In this survey, we have given a comprehensive review of the recent advances on these key tasks. The review focused firstly on the traditional methods and their categorization, also show the evolution of scene text detection, recognition methods, and end-to-end systems with their pros and cons. Secondly, this survey focuses on the latest state-of-the-art (SOTA) methods based on transfer learning and additionally do the extension of scene text reading system i.e. salient text detection, text or non-text image classification, a fusion of scene text in vision and language, etc. After that, we have done a performance analysis on various SOTA methods on the various key issues and techniques. Finally, we discuss the various evaluation metrics and standard dataset on which the various SOTA methods of scene text detection is investigated and compared.},
  archive      = {J_AIR},
  author       = {Gupta, Neeraj and Jalal, Anand Singh},
  doi          = {10.1007/s10462-021-10091-3},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3457-3502},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Traditional to transfer learning progression on scene text detection and recognition: A survey},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A study on the challenges and opportunities of speech
recognition for bengali language. <em>AIR</em>, <em>55</em>(4),
3431–3455. (<a
href="https://doi.org/10.1007/s10462-021-10083-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech recognition is a fascinating process that offers the opportunity to interact and command the machine in the field of human-computer interactions. Speech recognition is a language-dependent system constructed directly based on the linguistic and textual properties of any language. Automatic speech recognition (ASR) systems are currently being used to translate speech to text flawlessly. Although ASR systems are being strongly executed in international languages, ASR systems’ implementation in the Bengali language has not reached an acceptable state. In this research work, we sedulously disclose the current status of the Bengali ASR system’s research endeavors. In what follows, we acquaint the challenges that are mostly encountered while constructing a Bengali ASR system. We split the challenges into language-dependent and language-independent challenges and guide how the particular complications may be overhauled. Following a rigorous investigation and highlighting the challenges, we conclude that Bengali ASR systems require specific construction of ASR architectures based on the Bengali language’s grammatical and phonetic structure.},
  archive      = {J_AIR},
  author       = {Mridha, M. F. and Ohi, Abu Quwsar and Hamid, Md Abdul and Monowar, Muhammad Mostafa},
  doi          = {10.1007/s10462-021-10083-3},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3431-3455},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A study on the challenges and opportunities of speech recognition for bengali language},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Natural language processing for nepali text: A review.
<em>AIR</em>, <em>55</em>(4), 3401–3429. (<a
href="https://doi.org/10.1007/s10462-021-10093-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the proliferation of Nepali textual documents online, researchers in Nepal and overseas have started working towards its automated analysis for quick inferences, using different machine learning (ML) algorithms, ranging from traditional ML-based algorithms to recent deep learning (DL)-based algorithms. However, researchers are still unaware about the recent trends of NLP research direction in the Nepali language. In this paper, we survey different natural language processing (NLP) research works with associated resources in Nepali language. Furthermore, we organize the NLP approaches, techniques, and application tasks used in the Nepali language processing using the comprehensive taxonomy for each of them. Finally, we discuss and analyze based on such assimilated information for further improvement in NLP research works in the Nepali language. Our thorough survey bestows the detailed backgrounds and motivations to researchers, which not only opens up new potential avenues but also ushers towards further progress of NLP research works in the Nepali language.},
  archive      = {J_AIR},
  author       = {Shahi, Tej Bahadur and Sitaula, Chiranjibi},
  doi          = {10.1007/s10462-021-10093-1},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3401-3429},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Natural language processing for nepali text: A review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on the use of machine learning methods in
context-aware middlewares for human activity recognition. <em>AIR</em>,
<em>55</em>(4), 3369–3400. (<a
href="https://doi.org/10.1007/s10462-021-10094-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) essentially uses (past) sensor data or complex context information for inferring the activities a user performs in his daily tasks. HAR has been extensively studied using different paradigms, such as different reasoning mechanisms, including probabilistic, rule-based, statistical, logical reasoning, or the machine learning (ML) paradigm, to construct inference models to recognize or predict user activities. ML for HAR allows that activities can be recognized and even anticipated through the analysis of collected data from different sensors, with greater accuracy than the other paradigms. On the other hand, context-aware middlewares (CAMs) can efficiently integrate a large number of different devices and sensors. Moreover, they provide a programmable and auto-configurable infrastructure for streamline the design and construction of software solutions in scenarios where lots of sensors and data are their bases, such as ambient intelligence, smart cities, and e-health domains. In this way, the full integration of ML capabilities as services in CAMs can advance the development of software solutions in these domains when ML is necessary, specially for HAR, which is the basis for many scenarios in these domains. In this work, we present a survey for identifying the state-of-the-art in using ML for HAR in CAMs through a systematic literature review (SLR). In our SLR, we worked to answer four research questions: (i) what are the different types of context reasoners available in CAMs; (ii) what are the ML algorithms and methods used for generating models for context reasoning; (iii) which CAMs support data processing in real time; and (iv) what are the HAR scenarios usually tackled by the research works. In our analysis, we observed that, although ML offers viable approaches to construct inference models for HAR using different ML approaches, including batch learning, adaptive learning and data stream learning, there are yet some gaps and research challenges to be tackled, specially on the use of data stream learning considering concept drift on data, mechanisms for adapting the inference models, and further considering all of this as services in CAMs, specially for HAR.},
  archive      = {J_AIR},
  author       = {Miranda, Leandro and Viterbo, José and Bernardini, Flávia},
  doi          = {10.1007/s10462-021-10094-0},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3369-3400},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on the use of machine learning methods in context-aware middlewares for human activity recognition},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Hybrid marine predators algorithm for image segmentation:
Analysis and validations. <em>AIR</em>, <em>55</em>(4), 3315–3367. (<a
href="https://doi.org/10.1007/s10462-021-10086-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Naturally, to analyze an image accurately, all the similar objects within it should be separated to pay attention to the most important object for reaching more details and hence achieving better accuracy. Therefore, multilevel thresholding is an indispensable image processing technique in the field of image segmentation and is employed widely to separate those similar objects. However, with increasing thresholds, the existing image segmentation techniques might suffer from exponentially-grown computational cost and low accuracy due to local optima shortage. Therefore, in this paper, a new image segmentation algorithm based on the improved marine predators algorithm (MPA) is proposed. MPA is improved using a strategy to find a number of the worst solutions within the population then tries to search for other better ones for those solutions by moving them gradually towards the best solutions to avoid accelerating to local optima and randomly within the search space based on a certain probability. In addition, this number of the worst solutions is increased with the iteration. This strategy is known as the linearly increased worst solutions improvement strategy (LIS). Also, we suggested that apply the ranking strategy based on a novel updating scheme, namely ranking-based updating strategy (RUS), on the solutions that could find better solutions in the last number iterations, perIter, in the hope of finding better solutions near it. RUS updates the particles/solutions which could not find better solutions than the best-local one in a number of consecutive iterations, with those that are generated based on a novel updating strategy. LIS is integrated with MPA to produce a new segmentation meta-heuristic algorithm abbreviated as MPALS. Also, MPALS and RUS are combined to tackle ISP in a strong variant abbreviated as HMPA for overcoming the image segmentation problem. The two proposed algorithms are validated on 14 test images and compared with seven state-of-the-arts meta-heuristic algorithms. The experimental results show the effectiveness of HMPA with increasing the threshold levels compared to the seven state-of-the-arts algorithms when segmenting an image, while their performance is roughly the same for the image with a small threshold level.},
  archive      = {J_AIR},
  author       = {Abdel-Basset, Mohamed and Mohamed, Reda and Abouhawwash, Mohamed},
  doi          = {10.1007/s10462-021-10086-0},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3315-3367},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Hybrid marine predators algorithm for image segmentation: Analysis and validations},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimized decomposition and two-step nonlinear integration
model with error correction strategy coupled interval prediction for
digital currency price forecast. <em>AIR</em>, <em>55</em>(4),
3283–3314. (<a
href="https://doi.org/10.1007/s10462-021-10090-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital currency price prediction is vital to both sellers and purchasers. Over these years, decomposition and integration models have been applied more and more to realize the goal of precise prediction, however, many of them tend to neglect the reconstruction of features or the residual series. Altogether, one of the biggest drawbacks of the decomposition and integration framework is the method applied requires manual parameter setting whether it is for decomposition or integration. Still, for the results, they are merely satisfied with the point prediction which brings high uncertainty. In this paper, an optimized feature reconstruction decomposition and two-step nonlinear integration method is proposed which gives consideration to feature reconstruction, nonlinear integration, optimization and interval prediction. The original data series is decomposed through improved variational mode decomposition based approximate entropy feature reconstruction system. Then, improved particle swarm optimization-gated recurrent unit (iPSO-GRU) is utilized in the first and second nonlinear integration part separately. Meanwhile, the residual series is given attention, if it is not a white noise series, the residual will be the input of iPSO-GRU whose result will be added back to the second integration result to form the point prediction result. Based on the point prediction result, interval prediction estimate will be generated as well via maximum likelihood function. This study chooses three kinds of digital currency as cases and the results show that the MAPE values of point prediction are all below 3.5\%, and CP values of interval prediction are all 1 with suitable MWP. In addition, compared with other benchmark models, the proposed model shows better performance.},
  archive      = {J_AIR},
  author       = {Wang, Jujie and Qiu, Shiyao},
  doi          = {10.1007/s10462-021-10090-4},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3283-3314},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Optimized decomposition and two-step nonlinear integration model with error correction strategy coupled interval prediction for digital currency price forecast},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical classification of data streams: A systematic
literature review. <em>AIR</em>, <em>55</em>(4), 3243–3282. (<a
href="https://doi.org/10.1007/s10462-021-10087-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification task usually works with flat and batch learners, assuming problems as stationary and without relations between class labels. Nevertheless, several real-world problems do not assume these premises, i.e., data have labels organized hierarchically and are made available in streaming fashion, meaning that their behavior can drift over time. Existing studies on hierarchical classification do not consider data streams as input of their process, and thus, data is assumed as stationary and handled through batch learners. The same can be said about works on streaming data, as the hierarchical classification is overlooked. Studies concerning each area individually are promising, yet, do not tackle their intersection. This study analyzes the main characteristics of the state-of-the-art works on hierarchical classification for streaming data concerning five aspects: (i) problems tackled, (ii) datasets, (iii) algorithms, (iv) evaluation metrics, and (v) research gaps in the area. We performed a systematic literature review of primary studies and retrieved 3,722 papers, of which 42 were identified as relevant and used to answer the aforementioned research questions. We found that the problems handled by hierarchical classification of data streams include mainly classification of images, human activities, texts, and audio; the datasets are mostly created or synthetic data; the algorithms and evaluation metrics are well-known techniques or based on those; and research gaps are related to dynamic context, data complexity, and computational resources constraints. We also provide implications for future research and experiments to consider common characteristics shared amongst hierarchical classification and data stream classification.},
  archive      = {J_AIR},
  author       = {Tieppo, Eduardo and Santos, Roger Robson dos and Barddal, Jean Paul and Nievola, Júlio Cesar},
  doi          = {10.1007/s10462-021-10087-z},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3243-3282},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Hierarchical classification of data streams: A systematic literature review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Model-free reinforcement learning from expert
demonstrations: A survey. <em>AIR</em>, <em>55</em>(4), 3213–3241. (<a
href="https://doi.org/10.1007/s10462-021-10085-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning from expert demonstrations (RLED) is the intersection of imitation learning with reinforcement learning that seeks to take advantage of these two learning approaches. RLED uses demonstration trajectories to improve sample efficiency in high-dimensional spaces. RLED is a new promising approach to behavioral learning through demonstrations from an expert teacher. RLED considers two possible knowledge sources to guide the reinforcement learning process: prior knowledge and online knowledge. This survey focuses on novel methods for model-free reinforcement learning guided through demonstrations, commonly but not necessarily provided by humans. The methods are analyzed and classified according to the impact of the demonstrations. Challenges, applications, and promising approaches to improve the discussed methods are also discussed.},
  archive      = {J_AIR},
  author       = {Ramírez, Jorge and Yu, Wen and Perrusquía, Adolfo},
  doi          = {10.1007/s10462-021-10085-1},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3213-3241},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Model-free reinforcement learning from expert demonstrations: A survey},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A systematic review on time-constrained ontology evolution
in predictive maintenance. <em>AIR</em>, <em>55</em>(4), 3183–3211. (<a
href="https://doi.org/10.1007/s10462-021-10079-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the modernization of industry and introduction of IoT, maintenance practices have been moving from reactive to proactive and predictive approaches. The identification of faults often relies on the analysis of real-time data provided by streams and unstructured sources. Ontologies have been applied to the maintenance field in order to add a semantic layer to the data and facilitate interoperability, and combined with other approaches for explainability and fault diagnosis, among others. In such a time-sensitive domain, it is important that ontologies go beyond static representations of the domain and allow not only for the incorporation of time related knowledge, but must also be able to adapt to new knowledge and evolve. This systematic review presents four research questions to provide a general understanding of the state of the art of the representation of time and ontology evolution in the predictive maintenance field. The results have shown that there are several ways of representing the evolution of knowledge that are fairly established and several specific evolutionary actions are discriminated and analyzed. Similarly, there is a diverse group of metrics that can be exploited to measure change and to establish evolutionary trends and even predict future stages of the ontology. Studies on the representation of time show us that it can be done either quantitative or qualitatively, with some approaches combining the two. Applications of these to the problem of ontology evolution are still in the open. Finally, results show that while applications of ontologies to the field of predictive maintenance are plenty, there are not many studies focusing on their evolution or in the effective application of their ability to reason with time constraints. The results obtained in this systematic review are particularly relevant for devising solutions that make use of the ontology’s potential for time representation and evolution in the predictive maintenance field.},
  archive      = {J_AIR},
  author       = {Canito, Alda and Corchado, Juan and Marreiros, Goreti},
  doi          = {10.1007/s10462-021-10079-z},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3183-3211},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic review on time-constrained ontology evolution in predictive maintenance},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comparative study of multi-objective optimization
algorithms for sparse signal reconstruction. <em>AIR</em>,
<em>55</em>(4), 3153–3181. (<a
href="https://doi.org/10.1007/s10462-021-10073-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of the efficient sparse signal recovery algorithm is one of the important problems of the compressive sensing theory. There exist many types of sparse signal recovery methods in compressive sensing theory. These algorithms are classified into several categories like convex optimization, non-convex optimization, and greedy methods. Lately, intelligent optimization techniques like multi-objective approaches have been used in compressed sensing. Firstly, in this paper, the basic principles of the compressive sensing theory are summarized. And then, brief information about multi-objective algorithms, local search methods, and knee point selection methods are given. Afterward, multi-objective sparse recovery methods in the literature are reviewed and investigated in accordance with their multi-objective optimization algorithm, the local search method, and the knee point selection method. Also in this study, examples of multi-objective sparse reconstruction methods are designed according to the existing studies. Finally, the designed algorithms are tested and compared by using various types of sparse reconstruction test problems.},
  archive      = {J_AIR},
  author       = {Erkoc, Murat Emre and Karaboga, Nurhan},
  doi          = {10.1007/s10462-021-10073-5},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3153-3181},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comparative study of multi-objective optimization algorithms for sparse signal reconstruction},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modal context restriction for multiagent BDI logics.
<em>AIR</em>, <em>55</em>(4), 3075–3151. (<a
href="https://doi.org/10.1007/s10462-021-10064-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present and discuss a novel language restriction for modal logics for multiagent systems, called modal context restriction, that reduces the complexity of the satisfiability problem from EXPTIME complete to NPTIME complete. We focus on BDI multimodal logics that contain fix-point modalities like common beliefs and mutual intentions together with realism and introspection axioms. We show how this combination of modalities and axioms affects complexity of the satisfiability problem and how it can be reduced by restricting the modal context of formulas.},
  archive      = {J_AIR},
  author       = {Dziubiński, Marcin},
  doi          = {10.1007/s10462-021-10064-6},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3075-3151},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Modal context restriction for multiagent BDI logics},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A quantum mutation-based backtracking search algorithm.
<em>AIR</em>, <em>55</em>(4), 3019–3073. (<a
href="https://doi.org/10.1007/s10462-021-10078-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exposition of any nature-inspired optimization technique relies firmly upon its executed organized framework. Since the regularly utilized backtracking search algorithm (BSA) is a fixed framework, it is not always appropriate for all difficulty levels of problems and, in this manner, probably does not search the entire search space proficiently. To address this limitation, we propose a modified BSA framework, called gQR-BSA, based on the quasi reflection-based initialization, quantum Gaussian mutations, adaptive parameter execution, and quasi-reflection-based jumping to change the coordinate structure of the BSA. In gQR-BSA, a quantum Gaussian mechanism was developed based on the best population information mechanism to boost the population distribution information. As population distribution data can represent characteristics of a function landscape, gQR-BSA has the ability to distinguish the methodology of the landscape in the quasi-reflection-based jumping. The updated automatically managed parameter control framework is also connected to the proposed algorithm. In every iteration, the quasi-reflection-based jumps aim to jump from local optima and are adaptively modified based on knowledge obtained from offspring to global optimum. Herein, the proposed gQR-BSA was utilized to solve three sets of well-known standards of functions, including unimodal, multimodal, and multimodal fixed dimensions, and to solve three well-known engineering optimization problems. The numerical and experimental results reveal that the algorithm can obtain highly efficient solutions to both benchmark and real-life optimization problems.},
  archive      = {J_AIR},
  author       = {Nama, Sukanta and Sharma, Sushmita and Saha, Apu Kumar and Gandomi, Amir H.},
  doi          = {10.1007/s10462-021-10078-0},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3019-3073},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A quantum mutation-based backtracking search algorithm},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Secure video communication using firefly optimization and
visual cryptography. <em>AIR</em>, <em>55</em>(4), 2997–3017. (<a
href="https://doi.org/10.1007/s10462-021-10070-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, we face an increasing interest in protecting multimedia data and copyrights due to the high exchange of information. Attackers are trying to get confidential information from various sources, which brings the importance of securing the data. Many researchers implemented techniques to hide secret information to maintain the integrity and privacy of data. In order to protect confidential data, histogram-based reversible data hiding with other cryptographic algorithms are widely used. Therefore, in the proposed work, a robust method for securing digital video is suggested. We implemented histogram bit shifting based reversible data hiding by embedding the encrypted watermark in featured video frames. Histogram bit shifting is used for hiding highly secured watermarks so that security for the watermark symbol is also being achieved. The novelty of the work is that only based on the quality threshold a few unique frames are selected, which holds the encrypted watermark symbol. The optimal value for this threshold is obtained using the Firefly Algorithm. The proposed method is capable of hiding high-capacity data in the video signal. The experimental result shows the higher capacity and video quality compared to other reversible data hiding techniques. The recovered watermark provides better identity identification against various attacks. A high value of PSNR and a low value of BER and MSE is reported from the results.},
  archive      = {J_AIR},
  author       = {Kumar, Manoj and Aggarwal, Jyoti and Rani, Anuj and Stephan, Thompson and Shankar, Achyut and Mirjalili, Seyedali},
  doi          = {10.1007/s10462-021-10070-8},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2997-3017},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Secure video communication using firefly optimization and visual cryptography},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent trends in distributed production network scheduling
problem. <em>AIR</em>, <em>55</em>(4), 2945–2995. (<a
href="https://doi.org/10.1007/s10462-021-10081-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex problems in the real world, an increase in competition among producers, the advancements in equipment and manufacturing products, the high cost of factory equipment and, etc., have led to the production structure change from a centralized structure to a decentralized one. In recent years, distributed systems have become increasingly important. So in order to adapt to market competition and to respond quickly to changing market demand, there is a need to study this problem. An important aspect of planning in a distributed environment is decentralized production. In such cases, it becomes more important to consider the problem of distributed scheduling. In this regard, this paper provides a systematic literature review on the multi-factory scheduling problems in the past eleven years and report the research gaps. To this end, first, the related research was classified based on the shop environments. Then, after reviewing the existing papers and summarizing them, future researches and emerging research fields of the multi-factory scheduling problem are reported. This review indicates that future research should focus on open shop production environments. The results also show only 4\% of the papers focus on the virtual alliance. Therefore, researchers need to consider the virtual alliance in the production network and investigate the participation and competition between the partners in such network. Studying the topic of Industry 4.0 in multi-factory scheduling and subsequently investigating the related topics such as information sharing and real-time data are also the new trends in this field. Considering the complex series–parallel structures in the multi-factory production and defining objective functions related to environmental issues such as reducing pollutants and noise are other suggestions for future studies.},
  archive      = {J_AIR},
  author       = {Bagheri Rad, N. and Behnamian, J.},
  doi          = {10.1007/s10462-021-10081-5},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2945-2995},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Recent trends in distributed production network scheduling problem},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive review of image analysis methods for
microorganism counting: From classical image processing to deep learning
approaches. <em>AIR</em>, <em>55</em>(4), 2875–2944. (<a
href="https://doi.org/10.1007/s10462-021-10082-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microorganisms such as bacteria and fungi play essential roles in many application fields, like biotechnique, medical technique and industrial domain. Microorganism counting techniques are crucial in microorganism analysis, helping biologists and related researchers quantitatively analyze the microorganisms and calculate their characteristics, such as biomass concentration and biological activity. However, traditional microorganism manual counting methods, such as plate counting method, hemocytometry and turbidimetry, are time-consuming, subjective and need complex operations, which are difficult to be applied in large-scale applications. In order to improve this situation, image analysis is applied for microorganism counting since the 1980s, which consists of digital image processing, image segmentation, image classification and suchlike. Image analysis-based microorganism counting methods are efficient comparing with traditional plate counting methods. In this article, we have studied the development of microorganism counting methods using digital image analysis. Firstly, the microorganisms are grouped as bacteria and other microorganisms. Then, the related articles are summarized based on image segmentation methods. Each part of the article is reviewed by methodologies. Moreover, commonly used image processing methods for microorganism counting are summarized and analyzed to find common technological points. More than 144 papers are outlined in this article. In conclusion, this paper provides new ideas for the future development trend of microorganism counting, and provides systematic suggestions for implementing integrated microorganism counting systems in the future. Researchers in other fields can refer to the techniques analyzed in this paper.},
  archive      = {J_AIR},
  author       = {Zhang, Jiawei and Li, Chen and Rahaman, Md Mamunur and Yao, Yudong and Ma, Pingli and Zhang, Jinghua and Zhao, Xin and Jiang, Tao and Grzegorzek, Marcin},
  doi          = {10.1007/s10462-021-10082-4},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2875-2944},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive review of image analysis methods for microorganism counting: From classical image processing to deep learning approaches},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development and use of a convolutional neural network for
hierarchical appearance-based localization. <em>AIR</em>,
<em>55</em>(4), 2847–2874. (<a
href="https://doi.org/10.1007/s10462-021-10076-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reports and evaluates the adaption and re-training of a Convolutional Neural Network (CNN) with the aim of tackling the visual localization of a mobile robot by means of a hierarchical approach. The proposed method addresses the localization problem from the information captured by a catadioptric vision sensor mounted on the mobile robot. A CNN is adapted and evaluated with a twofold purpose. First, to perform a rough localization step (room retrieval) by means of the output layer. Second, to refine this localization in the retrieved room (fine localization step) by means of holistic descriptors obtained from intermediate layers of the same CNN. The robot estimates its position within the selected room/s through a nearest neighbour search by comparing the obtained holistic descriptor with the visual model of the retrieved room/s. Additionally, this method takes advantage of the likelihood information provided by the output layer of the CNN. This likelihood is helpful to determine which rooms should be considered in the fine localization process. This novel hierarchical localization method constitutes an efficient and robust solution, as shown in the experimental section even in presence of severe changes of the lighting conditions.},
  archive      = {J_AIR},
  author       = {Cebollada, S. and Payá, L. and Jiang, X. and Reinoso, O.},
  doi          = {10.1007/s10462-021-10076-2},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2847-2874},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Development and use of a convolutional neural network for hierarchical appearance-based localization},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on feature selection methods for mixed data.
<em>AIR</em>, <em>55</em>(4), 2821–2846. (<a
href="https://doi.org/10.1007/s10462-021-10072-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature Selection for mixed data is an active research area with many applications in practical problems where numerical and non-numerical features describe the objects of study. This paper provides the first comprehensive and structured revision of the existing supervised and unsupervised feature selection methods for mixed data reported in the literature. Additionally, we present an analysis of the main characteristics, advantages, and disadvantages of the feature selection methods reviewed in this survey and discuss some important open challenges and potential future research opportunities in this field.},
  archive      = {J_AIR},
  author       = {Solorio-Fernández, Saúl and Carrasco-Ochoa, J. Ariel and Martínez-Trinidad, José Francisco},
  doi          = {10.1007/s10462-021-10072-6},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2821-2846},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on feature selection methods for mixed data},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep reinforcement learning in computer vision: A
comprehensive survey. <em>AIR</em>, <em>55</em>(4), 2733–2819. (<a
href="https://doi.org/10.1007/s10462-021-10061-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning augments the reinforcement learning framework and utilizes the powerful representation of deep neural networks. Recent works have demonstrated the remarkable successes of deep reinforcement learning in various domains including finance, medicine, healthcare, video games, robotics, and computer vision. In this work, we provide a detailed review of recent and state-of-the-art research advances of deep reinforcement learning in computer vision. We start with comprehending the theories of deep learning, reinforcement learning, and deep reinforcement learning. We then propose a categorization of deep reinforcement learning methodologies and discuss their advantages and limitations. In particular, we divide deep reinforcement learning into seven main categories according to their applications in computer vision, i.e. (i) landmark localization (ii) object detection; (iii) object tracking; (iv) registration on both 2D image and 3D image volumetric data (v) image segmentation; (vi) videos analysis; and (vii) other applications. Each of these categories is further analyzed with reinforcement learning techniques, network design, and performance. Moreover, we provide a comprehensive analysis of the existing publicly available datasets and examine source code availability. Finally, we present some open issues and discuss future research directions on deep reinforcement learning in computer vision.},
  archive      = {J_AIR},
  author       = {Le, Ngan and Rathour, Vidhiwar Singh and Yamazaki, Kashu and Luu, Khoa and Savvides, Marios},
  doi          = {10.1007/s10462-021-10061-9},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2733-2819},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep reinforcement learning in computer vision: A comprehensive survey},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-leader harris hawk optimization based on
differential evolution for feature selection and prediction influenza
viruses H1N1. <em>AIR</em>, <em>55</em>(4), 2675–2732. (<a
href="https://doi.org/10.1007/s10462-021-10075-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, a modification of the Harris hawk optimization (HHO) is introduced and applied to feature selection. The proposed HHO variant is termed as hybrid multi-leader HHO with differential evolution (MLHHDE). To help hawks overcome the situation of falling into local optimum during the searching process, an improved memory structure is introduced, which makes the hawks learn simultaneously from the historical best and global best positions. Besides, the multi-leader mechanism is also introduced to make full use of the valuable information from global best memories (leaders), enhance the diversity of hawks’ search mode, and improve the hawks’ exploration capability. Furthermore, differential evolution operations are integrated into HHO to further improve the weak exploration phase. Our proposed MLHHDE algorithm integrates a V-shaped transfer function, which can convert continuous solutions to binary solutions. To validate the modification of MLHHDE, we compared its performance with the advanced optimization algorithms through three experiments. In the first experiment, the performance of MLHHDE to solve a set of problems from the CEC 2017 benchmark is evaluated. Meanwhile, the second experiment aims to apply the binary version of MLHHDE to tackle the feature selection task by applying it to a set of sixteen datasets from the UCI repository. In the third, we applied the proposed model as a quantitative structure-activity relationship method to predict the influenza viruses H1N1 as a real-world application. The performance of the proposed MLHHDE is assessed using a number of evaluation indicators. The experiment results prove the powerful capability of MLHHDE to find the optimal solution in the two experiments as well as it outperforms other methods (i.e., either global optimization or feature selection). In addition, the developed MLHHDE provides accuracy overall the UCI datasets nearly 84\% with difference 5\% between it and traditional HHO, also, it provides accuracy 92\% with standard deviation when applied to predict H1N1.},
  archive      = {J_AIR},
  author       = {Abd Elaziz, Mohamed and Yang, Huiting and Lu, Songfeng},
  doi          = {10.1007/s10462-021-10075-3},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2675-2732},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A multi-leader harris hawk optimization based on differential evolution for feature selection and prediction influenza viruses H1N1},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cancer diagnosis using artificial intelligence: A review.
<em>AIR</em>, <em>55</em>(4), 2641–2673. (<a
href="https://doi.org/10.1007/s10462-021-10074-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) is the usage of scientific techniques to simulate human intellectual skills and to tackle complex medical issues involving complicated genetic defects such as cancer. The rapid expansion of AI in the past era has paved the way to optimum judgment-making by superior intellect, where the human brain is constrained to manage large information in a limited period. Cancer is a complicated ailment along with several genomic variants. AI-centred systems carry enormous potential in detecting these genomic alterations and abnormal protein communications at a very initial phase. The contemporary biomedical study is also dedicated to bringing AI expertise to hospitals securely and ethically. AI-centred support to diagnosticians and doctors can be the big surge ahead for the forecast of illness threat, identification, diagnosis, and therapies. The applications related to AI and Machine Learning (ML) in the identification of cancer and its therapy possess the potential to provide therapeutic support for quicker planning of a novel therapy for each person. Through the utilization of AI- based methods, scientists can work together in real-time and distribute their expertise digitally to possibly cure billions. In this review, the focus was on the study of linking biology with AI and describe how AI-centred support could assist oncologists in accurate therapy. It is essential to identify new biomarkers that inject drug defiance and discover medicinal goals to improve medication methods. The advent of the “next-generation sequencing” (NGS) programs resolves these challenges and has transformed the prospect of “Precision Oncology” (PO). NGS delivers numerous medical functions which are vital for hazard prediction, initial diagnosis of infection, “Sequence” identification and “Medical Imaging” (MI), precise diagnosis, “biomarker” detection, and recognition of medicinal goals for innovation in medicine. NGS creates a huge repository that requires specific “bioinformatics” sources to examine the information that is pertinent and medically important. The malignancy diagnostics and analytical forecast are improved with NGS and MI that provide superior quality images via AI technology. Irrespective of the advancements in technology, AI faces a few problems and constraints, and the clinical application of NGS continues to be authenticated. Through the steady progress of invention and expertise, the prospects of AI and PO look promising. The purpose of this review was to assess, evaluate, classify, and tackle the present developments in cancer diagnosis utilizing AI methods for breast, lung, liver, skin cancer, and leukaemia. The research emphasizes in what way cancer identification, the treatment procedure is aided by utilizing AI with supervised, unsupervised, and deep learning (DL) methods. Numerous AI methods were assessed on benchmark datasets with respect to “accuracy”, “sensitivity”, “specificity”, and “false-positive” (FP) metrics. Lastly, challenges along with future work were discussed.},
  archive      = {J_AIR},
  author       = {Shastry, K Aditya and Sanjay, H A},
  doi          = {10.1007/s10462-021-10074-4},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2641-2673},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Cancer diagnosis using artificial intelligence: A review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving continuous optimization problems using the ımproved
jaya algorithm (IJaya). <em>AIR</em>, <em>55</em>(3), 2575–2639. (<a
href="https://doi.org/10.1007/s10462-021-10077-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Jaya algorithm is one of the heuristic algorithms developed in recent years. The most important difference from other heuristic algorithms is that it updates its position according to its best and worst position. In addition to its simplicity, there is no algorithm-specific parameter. Because of these advantages, it has been preferred by researchers for problem-solving in the literature. In this study, the random walk phase of the original Jaya algorithm is developed and the Improved Jaya Algorithm (IJaya) is proposed. IJaya has been tested for success in eighteen classic benchmark test functions. Although the performance of the original Jaya algorithm has been tested at low dimensions in the literature, its success in large sizes has not been tested. In this study, IJaya&#39;s success in 10, 20, 30, 100, 500, and 1000 dimensions was examined. Also, the success of IJaya was tested in different population sizes. It has been proven that IJaya&#39;s performance has increased with the tests performed. Test results show that IJaya displays good performance and can be used as an alternative method for constrained optimization. In addition, three different engineering design problems were tested in different population sizes to demonstrate the achievements of Jaya and IJaya. According to the results, IJaya can be used as an optimization algorithm in the literature for continuous optimization and large-scale optimization problems.},
  archive      = {J_AIR},
  author       = {Baş, Emine},
  doi          = {10.1007/s10462-021-10077-1},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2575-2639},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Solving continuous optimization problems using the ımproved jaya algorithm (IJaya)},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent advancement in VM task allocation system for cloud
computing: Review from 2015 to2021. <em>AIR</em>, <em>55</em>(3),
2529–2573. (<a
href="https://doi.org/10.1007/s10462-021-10071-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is new technology that has considerably changed human life at different aspect over the last decade. Especially after the COVID-19 pandemic, almost all life activity shifted into cloud base. Cloud computing is a utility where different hardware and software resources are accessed on pay per user ground base. Most of these resources are available in virtualized form and virtual machine (VM) is one of the main elements of visualization.VM used in data center for distribution of resource and application according to benefactor demand. Cloud data center faces different issue in respect of performance and efficiency for improvement of these issues different approaches are used. Virtual machine play important role for improvement of data center performance therefore different approach are used for improvement of virtual machine efficiency (i-e) load balancing of resource and task. For the improvement of this section different parameter of VM improve like makespan, quality of service, energy, data accuracy and network utilization. Improvement of different parameter in VM directly improve the performance of cloud computing. Therefore, we conducting this review paper that we can discuss about various improvements that took place in VM from 2015 to 20,201. This review paper also contain information about various parameter of cloud computing and final section of paper present the role of machine learning algorithm in VM as well load balancing approach along with the future direction of VM in cloud data center.},
  archive      = {J_AIR},
  author       = {Ullah, Arif and Nawi, Nazri Mohd and Ouhame, Soukaina},
  doi          = {10.1007/s10462-021-10071-7},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2529-2573},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Recent advancement in VM task allocation system for cloud computing: Review from 2015 to2021},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An automated essay scoring systems: A systematic literature
review. <em>AIR</em>, <em>55</em>(3), 2495–2527. (<a
href="https://doi.org/10.1007/s10462-021-10068-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessment in the Education system plays a significant role in judging student performance. The present evaluation system is through human assessment. As the number of teachers&#39; student ratio is gradually increasing, the manual evaluation process becomes complicated. The drawback of manual evaluation is that it is time-consuming, lacks reliability, and many more. This connection online examination system evolved as an alternative tool for pen and paper-based methods. Present Computer-based evaluation system works only for multiple-choice questions, but there is no proper evaluation system for grading essays and short answers. Many researchers are working on automated essay grading and short answer scoring for the last few decades, but assessing an essay by considering all parameters like the relevance of the content to the prompt, development of ideas, Cohesion, and Coherence is a big challenge till now. Few researchers focused on Content-based evaluation, while many of them addressed style-based assessment. This paper provides a systematic literature review on automated essay scoring systems. We studied the Artificial Intelligence and Machine Learning techniques used to evaluate automatic essay scoring and analyzed the limitations of the current studies and research trends. We observed that the essay evaluation is not done based on the relevance of the content and coherence.},
  archive      = {J_AIR},
  author       = {Ramesh, Dadi and Sanampudi, Suresh Kumar},
  doi          = {10.1007/s10462-021-10068-2},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2495-2527},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An automated essay scoring systems: A systematic literature review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interval valued demand related inventory model under all
units discount facility and deterioration via parametric approach.
<em>AIR</em>, <em>55</em>(3), 2455–2494. (<a
href="https://doi.org/10.1007/s10462-021-10069-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the yard of business organization, due to a major number of competitors and uncertainty of customers’ demand, everyone faces some disturbances for smoothly running of their business. To survive in the fierce competition some modern business policies are required and accordingly the formulation of an advanced inventory model is indispensable by handling the uncertainty of customers’ demand. In this model formulation, discount facility is considered as a business policy whereas interval valued demand is proposed to tackle the uncertainty of customers’ demand. The purpose of this work is to analyze a model with interval valued parameters for deteriorating items considering two situations (with shortages and without shortage) in the discount environment. Moreover, deterioration rate is taken into account as interval valued and unit carrying cost is supposed to be a function of the length of storage time as well as interval valued purchase cost. Also, the interval valued purchase cost is assumed to be a step function (decreasing) of lot size under discount business policy. Considering without shortage and with shortages separately, using parametric approach of interval differential equations, the proposed model is formulated in two different cases. After formulating the proposed model properly, the corresponding profit functions are obtained for two different cases (without shortage and with shortages). In order to optimize the profit, various types of meta-heuristic algorithms (weighted quantum behaved particle swarm optimization and Gaussian quantum behaved particle swarm optimization) are used and then the obtained results are compared. Finally, to justify the reality of the model, numerical illustrations are presented and also post optimality analyses are performed with the changes of known parameters.},
  archive      = {J_AIR},
  author       = {Rahman, Md Sadikur and Duary, Avijit and Khan, Md. Al-Amin and Shaikh, Ali Akbar and Bhunia, Asoke Kumar},
  doi          = {10.1007/s10462-021-10069-1},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2455-2494},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Interval valued demand related inventory model under all units discount facility and deterioration via parametric approach},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on personality-aware recommendation systems.
<em>AIR</em>, <em>55</em>(3), 2409–2454. (<a
href="https://doi.org/10.1007/s10462-021-10063-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of personality computing as a new research field related to artificial intelligence and personality psychology, we have witnessed an unprecedented proliferation of personality-aware recommendation systems. Unlike conventional recommendation systems, these new systems solve traditional problems such as the cold start and data sparsity problems. This survey aims to study and systematically classify personality-aware recommendation systems. To the best of our knowledge, this survey is the first that focuses on personality-aware recommendation systems. We explore the different design choices of personality-aware recommendation systems, by comparing their personality modeling methods, as well as their recommendation techniques. Furthermore, we present the commonly used datasets and point out some of the challenges of personality-aware recommendation systems.},
  archive      = {J_AIR},
  author       = {Dhelim, Sahraoui and Aung, Nyothiri and Bouras, Mohammed Amine and Ning, Huansheng and Cambria, Erik},
  doi          = {10.1007/s10462-021-10063-7},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2409-2454},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on personality-aware recommendation systems},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attention-based neural joint source-channel coding of text
for point to point and broadcast channel. <em>AIR</em>, <em>55</em>(3),
2379–2407. (<a
href="https://doi.org/10.1007/s10462-021-10067-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider the transmissions of structured data such as text over a noisy channel and correlated texts over a broadcast channel. As the separate source-channel coding principle no longer holds in such scenarios, we propose a joint source-channel coding scheme which is based on deep learning architecture. In order to enhance the convergence speed, we adopt the bidirectional gated recurrent unit at the encoder. For the decoder, to improve the recovery quality, we propose the following two types of strategies: (1) After a unidirectional neural network based decoder is used, a generative adversarial network is applied to train the whole joint source-channel coding framework and pointwise mutual information is added to the objective function of beam search process; (2) Rather than using a unidirectional neural network-based decoder, we develop a bidirectional neural network based and bidirectional attention mechanism integrated decoder to utilize past and future information. Experiments under different types of channels show that our schemes are superior to the existing deep learning joint source-channel coding method and in the case of low bit budget, long sentence length and small channel signal to noise ratio, our models are significantly superior to those of separate source-channel coding. In addition, we extend the proposed unidirectional and bidirectional decoders to the broadcast channel. Additionally, to improve the performance of unidirectional decoding, we utilize not only the correlation between adjacent words in the same text but also the correlation between words in different languages with the same meaning in the beam search process.},
  archive      = {J_AIR},
  author       = {Liu, Ting and Chen, Xuechen},
  doi          = {10.1007/s10462-021-10067-3},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2379-2407},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Attention-based neural joint source-channel coding of text for point to point and broadcast channel},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive survey of recent trends in deep learning for
digital images augmentation. <em>AIR</em>, <em>55</em>(3), 2351–2377.
(<a href="https://doi.org/10.1007/s10462-021-10066-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning proved its efficiency in many fields of computer science such as computer vision, image classifications, object detection, image segmentation, and more. Deep learning models primarily depend on the availability of huge datasets. Without the existence of many images in datasets, different deep learning models will not be able to learn and produce accurate models. Unfortunately, several fields don&#39;t have access to large amounts of evidence, such as medical image processing. For example. The world is suffering from the lack of COVID-19 virus datasets, and there is no benchmark dataset from the beginning of 2020. This pandemic was the main motivation of this survey to deliver and discuss the current image data augmentation techniques which can be used to increase the number of images. In this paper, a survey of data augmentation for digital images in deep learning will be presented. The study begins and with the introduction section, which reflects the importance of data augmentation in general. The classical image data augmentation taxonomy and photometric transformation will be presented in the second section. The third section will illustrate the deep learning image data augmentation. Finally, the fourth section will survey the state of the art of using image data augmentation techniques in the different deep learning research and application.},
  archive      = {J_AIR},
  author       = {Khalifa, Nour Eldeen and Loey, Mohamed and Mirjalili, Seyedali},
  doi          = {10.1007/s10462-021-10066-4},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2351-2377},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive survey of recent trends in deep learning for digital images augmentation},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An optimized system of GMDH-ANFIS predictive model by ICA
for estimating pile bearing capacity. <em>AIR</em>, <em>55</em>(3),
2313–2350. (<a
href="https://doi.org/10.1007/s10462-021-10065-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pile bearing capacity is considered as the most essential factor in designing deep foundations. Direct determination of this parameter in site is costly and difficult. Hence, this study presents a new technique of intelligence system based on the adaptive neuro-fuzzy inference system (ANFIS)-group method of data handling (GMDH) optimized by the imperialism competitive algorithm (ICA), ANFIS-GMDH-ICA for forecasting pile bearing capacity. In this advanced structure, the ICA role is to optimize the membership functions obtained by ANFIS-GMDH technique for receiving a higher accuracy level and lower error. To develop this model, the results of 257 high strain dynamic load tests (performed by authors) were considered and used in the analysis. For comparison purposes, ANFIS and GMDH models were selected and built for pile bearing capacity estimation. In terms of model accuracy, the obtained results showed that the newly developed model (i.e., ANFIS-GMDH-ICA) receives more accurate predicted values of pile bearing capacity compared to those obtained by ANFIS and GMDH predictive models. The proposed ANFIS-GMDH-ICA can be utilized as an advanced, applicable and powerful technique in issues related to foundation engineering and its design.},
  archive      = {J_AIR},
  author       = {Armaghani, Danial Jahed and Harandizadeh, Hooman and Momeni, Ehsan and Maizir, Harnedi and Zhou, Jian},
  doi          = {10.1007/s10462-021-10065-5},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2313-2350},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An optimized system of GMDH-ANFIS predictive model by ICA for estimating pile bearing capacity},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neurological abnormality detection from
electroencephalography data: A review. <em>AIR</em>, <em>55</em>(3),
2275–2312. (<a
href="https://doi.org/10.1007/s10462-021-10062-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficient detection of neurological abnormalities (disorders) is very important in clinical diagnosis for modern medical applications. As stated by the World Health Organization’s (WHO), brain diseases like Alzheimer’s disease, epilepsy, and stroke to headache, infected almost one billion people globally. Electroencephalography (EEG) is the current reference standard for diagnosis of most of the neurological diseases as it is inexpensive, bearable, and non-invasive compared to other tests (e.g. computed tomography, positron emission tomography, mini-mental state examination, and magnetic resonance imaging). Many studies are performed using EEG signals to detect the neurodegenerative abnormalities in the preliminary stage. This paper attempts to provide a comprehensive survey on the recent studies which are made using EEG signals to detect the neurological diseases: Dementia, Mild Cognitive Impairment, Alzheimer, Schizophrenia, and Parkinson. This paper focuses on the following key research questions: (1) what are the key components of EEG signal processing, (2) what algorithms have been used in this processing, (3) which signal processing techniques have received more attention? The paper provides a clear description of the mentioned neuro-diseases along with the relevant studies. Moreover, this study presents all the recent efforts of the methods that are obtained various step of signal data processing including feature extraction and classification phases. Finally, an elaborated comparison of the existing efforts with their drawbacks and performance are reported. This will guide the medical field researchers and technology experts to discover more accurate solutions for neuro-diseases and come up with a neurological abnormality detection framework.},
  archive      = {J_AIR},
  author       = {Alvi, Ashik Mostafa and Siuly, Siuly and Wang, Hua},
  doi          = {10.1007/s10462-021-10062-8},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2275-2312},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Neurological abnormality detection from electroencephalography data: A review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Making accurate object detection at the edge: Review and new
approach. <em>AIR</em>, <em>55</em>(3), 2245–2274. (<a
href="https://doi.org/10.1007/s10462-021-10059-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of Internet of Things (IoT), data are increasingly appearing at the edge of a network. Processing tasks at the network edge can effectively solve the problems of personal privacy leakage and server overloading. As a result, it has attracted a great deal of attention. A number of efficient convolutional neural network (CNN) models are proposed to do so. However, since they require much computing and memory resources, none of them can be deployed to such typical edge computing devices as Raspberry Pi 3B+ and 4B+ to meet the real-time requirements of user tasks. Considering that a traditional machine learning method can precisely locate an object with a highly acceptable calculation load, this work reviews state-of-the-art literature and then proposes a CNN with reduced input size for an object detection system that can be deployed in edge computing devices. It splits an object detection task into object positioning and classification. In particular, this work proposes a CNN model with 44 $$\times$$ 44-pixel inputs instead of much more inputs, e.g., 224 $$\times$$ 224-pixel in many existing methods, for edge computing devices with slow memory access and limited computing resources. Its overall performance has been verified via a facial expression detection system realized in Raspberry Pi 3B+ and 4B+. The work makes accurate object detection at the edge possible.},
  archive      = {J_AIR},
  author       = {Huang, Zhenhua and Yang, Shunzhi and Zhou, MengChu and Gong, Zheng and Abusorrah, Abdullah and Lin, Chen and Huang, Zheng},
  doi          = {10.1007/s10462-021-10059-3},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2245-2274},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Making accurate object detection at the edge: Review and new approach},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An absolute magnitude deviation of HRV for the prediction of
prediabetes with combined artificial neural network and regression tree
methods. <em>AIR</em>, <em>55</em>(3), 2221–2244. (<a
href="https://doi.org/10.1007/s10462-021-10040-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early diagnosis of prediabetes is an effective solution to the rising cases of diabetes around the world. The heterogeneous physiological characteristics of the ECG signal recorded from the heart make it challenging to implement an efficient diagnostic system. Therefore, this paper proposes a new approach to handling the heterogeneous characteristics of heart rate variability (HRV) with an absolute magnitude deviation analysis and an integrated machine learning technique for prediabetes prediction. We conducted an oral glucose tolerance test to acquire a resting-state ECG signal and the corresponding blood glucose value. We analyzed the HRV pattern from the ECG signal with a block-sliding window technique. We proposed a hybrid model to classify normal and prediabetes based on the extent of the absolute deviation of HRV values and avoiding a single point of failure. We adopted the model from the classification and regression tree (CART) and neural network (NN) algorithms. The experimental results reveal that when the blood glucose level increases, the maximum and range values of CARTHRV decreases while the minimum value increases. The proposed hybrid model had a better performance than the two methods with 100\% sensitivity, specificity, and F1-score measures against CART and NN that recorded &lt; 100\% for the same number of prediabetes in the training and test sets. The outcome from the analysis shows that the changes in blood glucose can be observed in ECG signals. The fast approximation of the proposed method to 100\% accuracy suggests that it is possible to achieve the diagnosis of prediabetes and overcome the discrepancies in physiological signals among individuals.},
  archive      = {J_AIR},
  author       = {Igbe, Tobore and Li, Jingzhen and Kandwal, Abhishek and Omisore, Olatunji Mumini and Yetunde, Efetobore and Yuhang, Liu and Wang, Lei and Nie, Zedong},
  doi          = {10.1007/s10462-021-10040-0},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2221-2244},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An absolute magnitude deviation of HRV for the prediction of prediabetes with combined artificial neural network and regression tree methods},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Differential evolution and particle swarm optimization
against COVID-19. <em>AIR</em>, <em>55</em>(3), 2149–2219. (<a
href="https://doi.org/10.1007/s10462-021-10052-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 disease, which highly affected global life in 2020, led to a rapid scientific response. Versatile optimization methods found their application in scientific studies related to COVID-19 pandemic. Differential Evolution (DE) and Particle Swarm Optimization (PSO) are two metaheuristics that for over two decades have been widely researched and used in various fields of science. In this paper a survey of DE and PSO applications for problems related with COVID-19 pandemic that were rapidly published in 2020 is presented from two different points of view: 1. practitioners seeking the appropriate method to solve particular problem, 2. experts in metaheuristics that are interested in methodological details, inter comparisons between different methods, and the ways for improvement. The effectiveness and popularity of DE and PSO is analyzed in the context of other metaheuristics used against COVID-19. It is found that in COVID-19 related studies: 1. DE and PSO are most frequently used for calibration of epidemiological models and image-based classification of patients or symptoms, but applications are versatile, even interconnecting the pandemic and humanities; 2. reporting on DE or PSO methodological details is often scarce, and the choices made are not necessarily appropriate for the particular algorithm or problem; 3. mainly the basic variants of DE and PSO that were proposed in the late XX century are applied, and research performed in recent two decades is rather ignored; 4. the number of citations and the availability of codes in various programming languages seems to be the main factors for choosing metaheuristics that are finally used.},
  archive      = {J_AIR},
  author       = {Piotrowski, Adam P. and Piotrowska, Agnieszka E.},
  doi          = {10.1007/s10462-021-10052-w},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2149-2219},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Differential evolution and particle swarm optimization against COVID-19},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Similarity-based multi-criteria decision making technique of
pythagorean fuzzy sets. <em>AIR</em>, <em>55</em>(3), 2103–2148. (<a
href="https://doi.org/10.1007/s10462-021-10054-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pythagorean fuzzy set (PFS) is a more flexible and effective way than intuitionistic fuzzy set (IFS) to seize indeterminacy. In this context, the main aim is to develop a number of new diverse types of PFS similarity measures which not only satisfy the well-known axioms, but also conquer the division-by-zero problem successfully. Moreover, the developed measures are based on two concepts of t-norm and s-norm together with the distance measure between PFSs. In order for further clarifying the role of proposed PFS similarity measures, we assess here two aspects of comparison: the microscopy aspect and the macroscopy aspect. The latter aspect allows us to know how the results are actually obtained on the basis of structural form of similarity measures, and the former aspect enables us to judge about the results of similarity measures without considering how they have been concluded. We then investigate a number of desirable properties of proposed PFS similarity measures, and show their effectiveness compared to the existing ones by encountering both of existing and newly constructed measures in some case studies concerning pattern recognition and medical diagnosis.},
  archive      = {J_AIR},
  author       = {Farhadinia, Bahram},
  doi          = {10.1007/s10462-021-10054-8},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2103-2148},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Similarity-based multi-criteria decision making technique of pythagorean fuzzy sets},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Measuring associational thinking through word embeddings.
<em>AIR</em>, <em>55</em>(3), 2065–2102. (<a
href="https://doi.org/10.1007/s10462-021-10056-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of a model to quantify semantic similarity and relatedness between words has been the major focus of many studies in various fields, e.g. psychology, linguistics, and natural language processing. Unlike the measures proposed by most previous research, this article is aimed at estimating automatically the strength of associative words that can be semantically related or not. We demonstrate that the performance of the model depends not only on the combination of independently constructed word embeddings (namely, corpus- and network-based embeddings) but also on the way these word vectors interact. The research concludes that the weighted average of the cosine-similarity coefficients derived from independent word embeddings in a double vector space tends to yield high correlations with human judgements. Moreover, we demonstrate that evaluating word associations through a measure that relies on not only the rank ordering of word pairs but also the strength of associations can reveal some findings that go unnoticed by traditional measures such as Spearman’s and Pearson’s correlation coefficients.},
  archive      = {J_AIR},
  author       = {Periñán-Pascual, Carlos},
  doi          = {10.1007/s10462-021-10056-6},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2065-2102},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Measuring associational thinking through word embeddings},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Handling class-imbalance with KNN (neighbourhood)
under-sampling for software defect prediction. <em>AIR</em>,
<em>55</em>(3), 2023–2064. (<a
href="https://doi.org/10.1007/s10462-021-10044-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Defect Prediction (SDP) is highly crucial task in software development process to forecast about which modules are more prone to errors and faults before the instigation of the testing phase. It aims to reduce the development cost of the software by focusing the testing efforts to those predicted faulty modules. Though, it ensures in-time delivery of good quality end-product, but class-imbalance of dataset is a major hinderance to SDP. This paper proposes a novel Neighbourhood based Under-Sampling (N-US) algorithm to handle class imbalance issue. This work is dedicated to demonstrating the effectiveness of proposed Neighbourhood based Under-Sampling (N-US) approach to attain high accuracy while predicting the defective modules. The algorithm N-US under samples the dataset to maximize the visibility of minority data points while restricting the excessive elimination of majority data points to avoid information loss. To assess the applicability of N-US, it is compared with three standard under-sampling techniques. Further, this study investigates the performance of N-US as a trusted ally for SDP classifiers. Extensive experiments are conducted using benchmark datasets from NASA repository which are CM1, JM1, KC1, KC2 and PC1. The proposed SDP classifier with N-US technique is compared with baseline models statistically to assess the effectiveness of N-US algorithm for SDP. The proposed model outperforms the rest of the candidate SDP models with the highest AUC score (= 95.6\%), the maximum Accuracy value (= 96.9\%) and the closest ROC curve to the top left corner. It shows up with the best prediction power statistically with confidence level of 95\%.},
  archive      = {J_AIR},
  author       = {Goyal, Somya},
  doi          = {10.1007/s10462-021-10044-w},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2023-2064},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Handling class-imbalance with KNN (Neighbourhood) under-sampling for software defect prediction},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pupil size variation in primary facial expressions–testing
potential biomarker of self-criticism. <em>AIR</em>, <em>55</em>(3),
2001–2022. (<a
href="https://doi.org/10.1007/s10462-021-10057-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is no previous research exploring the relationship between self-criticism and pupillary reactivity. Biomarkers such as pupillary reactivity inform about the quantity of the information being processed. Potentially, they can improve predictions of self-criticism levels and identification of pathological levels of self-criticism. The goal of our study is to test whether changes in pupil size act as predictors of self-criticism in participants viewing facial emotional stimuli. This is a first study that includes all basic emotions, and allows detailed analyses of pupillary reactivity predictors. Our results show that the pathological form of self-criticism, which is Hated Self in The Forms of Self-Criticizing/Attacking and Self-Reassuring Scale (FSCRS), was significantly predicted by enlarged pupils in the presence of Anger and Disgust and by narrowed pupils in the presence of Happiness. Greater information gain for Disgust predicted higher score in Inadequate Self and Hated Self measures and lower score for Reassuring Self. The greater information gain for Anger predicted higher score in Inadequate Self and Hated Self measures, but not lower score for Reassuring Self. Pupillary reactivity seems to be a promising biomarker in diagnosing the level of self-criticism and self-reassurance by different pupilar reactions to facial emotion expression especially for Disgust. Greater information gain for Disgust predicts higher score in Inadequate Self and Hated Self measures and lower score for Reassuring Self. In the future, this finding could help create a screening tool for diagnosing pathologically self-critical people without having to rely on self-reporting instruments, which are prone to numerous biases.},
  archive      = {J_AIR},
  author       = {Kanovský, Martin and Halamová, Júlia and Strnádelová, Bronislava and Moro, Robert and Bielikova, Maria},
  doi          = {10.1007/s10462-021-10057-5},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2001-2022},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Pupil size variation in primary facial expressions–testing potential biomarker of self-criticism},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning in drug discovery: A review. <em>AIR</em>,
<em>55</em>(3), 1947–1999. (<a
href="https://doi.org/10.1007/s10462-021-10058-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review provides the feasible literature on drug discovery through ML tools and techniques that are enforced in every phase of drug development to accelerate the research process and deduce the risk and expenditure in clinical trials. Machine learning techniques improve the decision-making in pharmaceutical data across various applications like QSAR analysis, hit discoveries, de novo drug architectures to retrieve accurate outcomes. Target validation, prognostic biomarkers, digital pathology are considered under problem statements in this review. ML challenges must be applicable for the main cause of inadequacy in interpretability outcomes that may restrict the applications in drug discovery. In clinical trials, absolute and methodological data must be generated to tackle many puzzles in validating ML techniques, improving decision-making, promoting awareness in ML approaches, and deducing risk failures in drug discovery.},
  archive      = {J_AIR},
  author       = {Dara, Suresh and Dhamercherla, Swetha and Jadav, Surender Singh and Babu, CH Madhu and Ahsan, Mohamed Jawed},
  doi          = {10.1007/s10462-021-10058-4},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1947-1999},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Machine learning in drug discovery: A review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimized fuzzy clustering using moth-flame optimization
algorithm in wireless sensor networks. <em>AIR</em>, <em>55</em>(3),
1915–1945. (<a
href="https://doi.org/10.1007/s10462-021-09957-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy consumption is one of the main concerns in wireless sensor networks (WSNs). In this context, congestion is one of the problems which by dropping the data packets, increases the energy consumption of WSN, and reduces its lifetime. In this paper, we deal with these problems and present a distributed fuzzy clustering scheme that uses two Fuzzy Logic Controllers (FLCs) to organize WSN into some clusters. Besides, in this scheme, we consider multiple mobile sink nodes and provide another FLC for fuzzy sink selection used by cluster heads (CHs). In this scheme, CHs cooperate in multi-hop routing of data packets to minimize the energy consumption of WSN. However, in the data routing step, congestion may happen in the data forwarding nodes. In this scheme, we deal with the congestion problem by proposing a distance-based version of the Random Early Detection (RED) congestion control method to drop the data packets more intelligently. Besides, to increase the effectiveness of the proposed FLCs, we tune them using the Moth-Flame Optimization algorithm and minimize their rules. Simulation results indicate the effectiveness of the proposed clustering and distance-based RED congestion control method in improving the WSN’s lifespan, reducing the number of retransmissions, and mitigating the percentage of packet loss.},
  archive      = {J_AIR},
  author       = {Trinh, Cuong and Huynh, Bao and Bidaki, Moazam and Rahmani, Amir Masoud and Hosseinzadeh, Mehdi and Masdari, Mohammad},
  doi          = {10.1007/s10462-021-09957-3},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1915-1945},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Optimized fuzzy clustering using moth-flame optimization algorithm in wireless sensor networks},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An approach to MCGDM based on multi-granulation pythagorean
fuzzy rough set over two universes and its application to medical
decision problem. <em>AIR</em>, <em>55</em>(3), 1887–1913. (<a
href="https://doi.org/10.1007/s10462-021-10048-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring efficiency approaches to solve the problems of decision making under uncertainty is a mainstream direction. This article explores the rough approximation of the uncertainty information with Pythagorean fuzzy information on multi-granularity space over two universes combined with grey relational analysis. Based on grey relational analysis, we present a new approach to calculate the relative degree or the attribute weight with Pythagorean fuzzy set and give a new descriptions for membership degree and non-membership. Then, this paper proposes a multi-granulation rough sets combined with Pythagorean fuzzy set, including optimistic multi-granulation Pythagorean fuzzy rough set, pessimistic multi-granulation Pythagorean fuzzy rough set and variable precision Pythagorean fuzzy rough set. Several basic properties for the established models are investigated in detail. Meanwhile, we present an approach to solving the multiple-criteria group decision making problems with fuzzy information based on the proposed model. Eventually, a case study of psychological evaluation of health care workers in COVID-19 show the principle of the established model and is utilized to verify the availability. The main contributions have three aspects. The first contribution of an approach of calculating the attribute weight is presented based on Grey Relational Analysis and gives a new perspective for the Pythagorean fuzzy set. Then, this paper proposes a mutli-granulation rough set model with Pythagorean fuzzy set over two universes. Finally, we apply the proposed model to solving the psychological evaluation problems.},
  archive      = {J_AIR},
  author       = {Sun, Bingzhen and Tong, Sirong and Ma, Weimin and Wang, Ting and Jiang, Chao},
  doi          = {10.1007/s10462-021-10048-6},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1887-1913},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An approach to MCGDM based on multi-granulation pythagorean fuzzy rough set over two universes and its application to medical decision problem},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spherical fuzzy decision making method based on combined
compromise solution for IIoT industry evaluation. <em>AIR</em>,
<em>55</em>(3), 1857–1886. (<a
href="https://doi.org/10.1007/s10462-021-10055-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Industrial Internet of Things is crucial for enterprise and country to drive the strategic upgrade and raise the level of national intelligent manufacturing. When pondering the IIoT industry evaluation, the corresponding dominating issues involve numerous indeterminacies. Spherical fuzzy set, portrayed by memberships of positive, neutral and negative, is a more efficient methods of seizing indeterminacy. In this article, firstly, the fire-new spherical fuzzy score function is explored for solving some suspensive comparison issues. Moreover, the objective weight and combined weight are determined by Renyi entropy method and non-linear weighted comprehensive method, respectively. Later, the multi-criteria decision making method based on combined compromise solutionis developed under spherical fuzzy environment. Finally, the corresponding method is effectively validated by the issue of IIoT industry evaluation. The main characteristics of the presented algorithm are: (1) without counterintuitive phenomena; (2) no division or antilogarithm by zero problem; (3) no square root by negative number issue; (4) no violation of the original definition issue.},
  archive      = {J_AIR},
  author       = {Peng, Xindong and Li, Wenquan},
  doi          = {10.1007/s10462-021-10055-7},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1857-1886},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Spherical fuzzy decision making method based on combined compromise solution for IIoT industry evaluation},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Updating approximations with dynamic objects based on local
multigranulation rough sets in ordered information systems.
<em>AIR</em>, <em>55</em>(3), 1821–1855. (<a
href="https://doi.org/10.1007/s10462-021-10053-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main task of local rough set model is to avoid the interference of complicated calculation and invalid information in the formation of approximation space. In this paper, we first present a local rough set model based on dominance relation to make the local rough set theory applicable to the ordered information system, then two kinds of local multigranulation rough set models in the ordered information system are constructed by extending the single granulation environment to a multigranulation case. Moreover, the updating processes of dynamic objects based on global (classical) and local multigranulation rough sets in the ordered information system are analyzed and compared carefully. It is addressed about how the rough approximation spaces of global multigranulation rough set and local multigranulation rough set change when the object set increase or decrease in an ordered information system. The relevant algorithms for updating approximations with dynamic objects on global and local multigranulation rough sets are provided in ordered information systems. To illustrate the superiority and the effectiveness of the proposed dynamic updating approaches in the ordered information system, experimental evaluation is performed using six datasets coming from the University of California-Irvine repository.},
  archive      = {J_AIR},
  author       = {Li, Wentao and Xu, Weihua and Zhang, Xiaoyan and Zhang, Jia},
  doi          = {10.1007/s10462-021-10053-9},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1821-1855},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Updating approximations with dynamic objects based on local multigranulation rough sets in ordered information systems},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An empirical evaluation of kernels for time series.
<em>AIR</em>, <em>55</em>(3), 1803–1820. (<a
href="https://doi.org/10.1007/s10462-021-10050-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There exist a variety of distance measures which operate on time series kernels. The objective of this article is to compare those distance measures in a support vector machine setting. A support vector machine is a state-of-the-art classifier for static (non-time series) datasets and usually outperforms k-Nearest Neighbour, however it is often noted that that 1-NN DTW is a robust baseline for time-series classification. Through a collection of experiments we determine that the most effective distance measure is Dynamic Time Warping and the most effective classifier is kNN. However, a surprising result is that the pairing of kNN and DTW is not the most effective model. Instead we have discovered via experimentation that Dynamic Time Warping paired with the Gaussian Support Vector Machine is the most accurate time series classifier. Finally, with good reason we recommend a slightly inferior (in terms of accuracy) model Time Warp Edit Distance paired with the Gaussian Support Vector Machine as it has a better theoretical basis. We also discuss the reduction in computational cost achieved by using a Support Vector Machine, finding that the Negative Kernel paired with the Dynamic Time Warping distance produces the greatest reduction in computational cost.},
  archive      = {J_AIR},
  author       = {Badiane, Mourtadha and Cunningham, Pádraig},
  doi          = {10.1007/s10462-021-10050-y},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1803-1820},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An empirical evaluation of kernels for time series},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary design of neural network architectures: A
review of three decades of research. <em>AIR</em>, <em>55</em>(3),
1723–1802. (<a
href="https://doi.org/10.1007/s10462-021-10049-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a comprehensive review of the evolutionary design of neural network architectures. This work is motivated by the fact that the success of an Artificial Neural Network (ANN) highly depends on its architecture and among many approaches Evolutionary Computation, which is a set of global-search methods inspired by biological evolution has been proved to be an efficient approach for optimizing neural network structures. Initial attempts for automating architecture design by applying evolutionary approaches start in the late 1980s and have attracted significant interest until today. In this context, we examined the historical progress and analyzed all relevant scientific papers with a special emphasis on how evolutionary computation techniques were adopted and various encoding strategies proposed. We summarized key aspects of methodology, discussed common challenges, and investigated the works in chronological order by dividing the entire timeframe into three periods. The first period covers early works focusing on the optimization of simple ANN architectures with a variety of solutions proposed on chromosome representation. In the second period, the rise of more powerful methods and hybrid approaches were surveyed. In parallel with the recent advances, the last period covers the Deep Learning Era, in which research direction is shifted towards configuring advanced models of deep neural networks. Finally, we propose open problems for future research in the field of neural architecture search and provide insights for fully automated machine learning. Our aim is to provide a complete reference of works in this subject and guide researchers towards promising directions.},
  archive      = {J_AIR},
  author       = {Ünal, Hamit Taner and Başçiftçi, Fatih},
  doi          = {10.1007/s10462-021-10049-5},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1723-1802},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Evolutionary design of neural network architectures: A review of three decades of research},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Capitalization and punctuation restoration: A survey.
<em>AIR</em>, <em>55</em>(3), 1681–1722. (<a
href="https://doi.org/10.1007/s10462-021-10051-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring proper punctuation and letter casing is a key pre-processing step towards applying complex natural language processing algorithms. This is especially significant for textual sources where punctuation and casing are missing, such as the raw output of automatic speech recognition systems. Additionally, short text messages and micro-blogging platforms offer unreliable and often wrong punctuation and casing. This survey offers an overview of both historical and state-of-the-art techniques for restoring punctuation and correcting word casing. Furthermore, current challenges and research directions are highlighted.},
  archive      = {J_AIR},
  author       = {Păiş, Vasile and Tufiş, Dan},
  doi          = {10.1007/s10462-021-10051-x},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1681-1722},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Capitalization and punctuation restoration: A survey},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Passive image forensics using universal techniques: A
review. <em>AIR</em>, <em>55</em>(3), 1629–1679. (<a
href="https://doi.org/10.1007/s10462-021-10046-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital tamper detection is a substantial research area of image analysis that identifies the manipulation in the image. This domain has matured with time and incredible accuracy in the last five years using machine learning and deep learning-based approaches. Now, it is time for the evolution of fusion and reinforcement-based learning techniques. Nevertheless, before commencing any experimentation, a researcher needs a comprehensive state of the art in that domain. Various directions, their outcome, and analysis form the basis for successful experiments and ensure better results. Universal image forensics approaches are a significant subset of image forensic techniques and must be explored thoroughly before experimentation. This motivated authors to write a review of these approaches. In contrast to the existing recent surveys that aim at image splicing or copy-move detection, our study aims to explore the universal type-independent techniques required to highlight image tampering. Several universal approaches based on resampling, compression, and inconsistency-based detection are compared and evaluated in the presented work. This review communicates the approach used for review, analysed literature, and lastly, the conclusive remarks. Various resources beneficial for the research community, i.e. journals and datasets, are explored and enumerated. Lastly, a futuristic reinforcement learning-based model is proposed.},
  archive      = {J_AIR},
  author       = {Gupta, Surbhi and Mohan, Neeraj and Kaushal, Priyanka},
  doi          = {10.1007/s10462-021-10046-8},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1629-1679},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Passive image forensics using universal techniques: A review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of global spread of COVID-19 pandemic: A review
and research challenges. <em>AIR</em>, <em>55</em>(3), 1607–1628. (<a
href="https://doi.org/10.1007/s10462-021-09988-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the initial reports of the Coronavirus surfacing in Wuhan, China, the novel virus currently without a cure has spread like wildfire across the globe, the virus spread exponentially across all inhabited continent, catching local governments by surprise in many cases and bringing the world economy to a standstill. As local authorities work on a response to deal with the virus, the scientific community has stepped in to help analyze and predict the pattern and conditions that would influence the spread of this unforgiving virus. Using existing statistical modeling tools to the latest artificial intelligence technology, the scientific community has used public and privately available data to help with predictions. A lot of this data research has enabled local authorities to plan their response—whether that is to deploy tightly available medical resources like ventilators or how and when to enforce policies to social distance, including lockdowns. On the one hand, this paper shows what accuracy of research brings to enable fighting this disease; while on the other hand, it also shows what lack of response from local authorities can do in spreading this virus. This is our attempt to compile different research methods and comparing their accuracy in predicting the spread of COVID-19.},
  archive      = {J_AIR},
  author       = {Shah, Saloni and Mulahuwaish, Aos and Ghafoor, Kayhan Zrar and Maghdid, Halgurd S.},
  doi          = {10.1007/s10462-021-09988-w},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1607-1628},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Prediction of global spread of COVID-19 pandemic: A review and research challenges},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction to: QoS-driven metaheuristic service composition
schemes: A comprehensive overview. <em>AIR</em>, <em>55</em>(2), 1605.
(<a href="https://doi.org/10.1007/s10462-021-09971-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the original publication of the article, the corresponding author name and the e-mail ID was incorrect. The correct name and e-mail ID is given in this correction.},
  archive      = {J_AIR},
  author       = {Masdari, Mohammad and Nozad Bonab, Mehdi and Ozdemir, Suat},
  doi          = {10.1007/s10462-021-09971-5},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1605},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Correction to: QoS-driven metaheuristic service composition schemes: a comprehensive overview},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intuitionistic fuzzy soft decision making method based on
CoCoSo and CRITIC for CCN cache placement strategy selection.
<em>AIR</em>, <em>55</em>(2), 1567–1604. (<a
href="https://doi.org/10.1007/s10462-021-09995-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The CCN cache placement strategy is of great concern to optimize the energy consumption of the network, and provide better security and delivery efficiency. When considering the CCN cache placement strategy evaluation, the fundamental issues frequently involve great uncertainty. Intuitionistic fuzzy soft set, portrayed by the parameterized form of membership and nonmembership, is a more effectual pattern for seizing uncertainty. In this article, the comparison problem in intuitionistic fuzzy soft (IFS) environment is solved by new score function. Later, some novel properties of IFS matrix are explored in detail. In addition, the objective weight information is determined by CRITIC approach. At the same time, the combined weight is calculated by revealing concurrently subjective weight preference and the objective weight information. Then, IFS decision making method based CoCoSo (Combined Compromise Solution) is proposed. Finally, the effectiveness of the method is elaborated by CCN cache placement strategy selection, along with corresponding sensitivity analysis. The dominating traits of the explored algorithm are listed as follows: (1) have no counterintuitive phenomena; (2) without data requirements; (3) own strong discriminating ability.},
  archive      = {J_AIR},
  author       = {Peng, Xindong and Garg, Harish},
  doi          = {10.1007/s10462-021-09995-x},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1567-1604},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Intuitionistic fuzzy soft decision making method based on CoCoSo and CRITIC for CCN cache placement strategy selection},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence methods for analysis of
electrocardiogram signals for cardiac abnormalities: State-of-the-art
and future challenges. <em>AIR</em>, <em>55</em>(2), 1519–1565. (<a
href="https://doi.org/10.1007/s10462-021-09999-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases (CVDs) in India and globally are the major cause of mortality, as revealed by the World Health Organization (WHO). The irregularities in the pace of heartbeats, called cardiac arrhythmias or heart arrhythmias, are one of the commonly diagnosed CVDs caused by ischemic heart disease, hypertension, alcohol intake, and stressful lifestyle. Other than the listed CVDs, the abnormality in the cardiac rhythm caused by the long term mental stress (stimulated by Autonomic Nervous System (ANS)) is a challenging issue for researchers. Early detection of cardiac arrhythmias through automatic electronic techniques is an important research field since the invention of electrocardiogram (ECG or EKG) and advanced machine learning algorithms. ECG (EKG) provides the record of variations in electrical activity associated with the cardiac cycle, used by cardiologists and researchers as a gold standard to study the heart function. The present work is aimed to provide an extensive survey of work done by researchers in the area of automated ECG analysis and classification of regular &amp; irregular classes of heartbeats by conventional and modern artificial intelligence (AI) methods. The artificial intelligence (AI) based methods have emerged popularly during the last decade for the automatic and early diagnosis of clinical symptoms of arrhythmias. In this work, the literature is explored for the last two decades to review the performance of AI and other computer-based techniques to analyze the ECG signals for the prediction of cardiac (heart rhythm) disorders. The existing ECG feature extraction techniques and machine learning (ML) methods used for ECG signal analysis and classification are compared using the performance metrics like specificity, sensitivity, accuracy, positive predictivity value, etc. Some popular AI methods, which include, artificial neural networks (ANN), Fuzzy logic systems, and other machine learning algorithms (support vector machines (SVM), k-nearest neighbor (KNN), etc.) are considered in this review work for the applications of cardiac arrhythmia classification. The popular ECG databases available publicly to evaluate the classification accuracy of the classifier are also mentioned. The aim is to provide the reader, the prerequisites, the methods used in the last two decades, and the systematic approach, all at one place to further purse a research work in the area of cardiovascular abnormalities detection using the ECG signal. As a contribution to the current work, future challenges for real-time remote ECG acquisition and analysis using the emerging technologies like wireless body sensor network (WBSN) and the internet of things (IoT) are identified.},
  archive      = {J_AIR},
  author       = {Saini, Sanjeev Kumar and Gupta, Rashmi},
  doi          = {10.1007/s10462-021-09999-7},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1519-1565},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial intelligence methods for analysis of electrocardiogram signals for cardiac abnormalities: State-of-the-art and future challenges},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ranking of single-valued neutrosophic numbers through the
index of optimism and its reasonable properties. <em>AIR</em>,
<em>55</em>(2), 1489–1518. (<a
href="https://doi.org/10.1007/s10462-021-09981-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper an innovative method of ranking neutrosophic number based on the notions of value and ambiguity of a single-valued neutrosophic number is being developed. The method is based on the convex combination of value and ambiguity of truth-membership function with the sum of values and ambiguities of indeterminacy-membership and falsity-membership functions. This convex combination is also termed as an index of optimism. The index of optimism, $$\lambda =1$$ , is termed as optimistic decision-maker as it considers the value and the ambiguity of the truth-membership function, ignoring the contributions from indeterminacy-membership and falsity-membership functions. Similarly, the index of optimism, $$\lambda =0$$ , is termed as pessimistic decision-maker as it considers the values and the ambiguities of the indeterminacy-membership and falsity-membership functions, ignoring the contribution from truth-membership function. Further, the index of optimism, $$\lambda =0.5$$ , is termed as moderate decision-maker as it considers the values and the ambiguities of all the membership functions. The approach is a novel as it completely oath to follow the reasonable properties of a ranking method. It is worth to mention that the current approach consistently ranks the single-valued neutrosophic numbers as well as their corresponding images.},
  archive      = {J_AIR},
  author       = {Chutia, Rituparna and Smarandache, Florentin},
  doi          = {10.1007/s10462-021-09981-3},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1489-1518},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Ranking of single-valued neutrosophic numbers through the index of optimism and its reasonable properties},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatiotemporal data mining: A survey on challenges and open
problems. <em>AIR</em>, <em>55</em>(2), 1441–1488. (<a
href="https://doi.org/10.1007/s10462-021-09994-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporal data mining (STDM) discovers useful patterns from the dynamic interplay between space and time. Several available surveys capture STDM advances and report a wealth of important progress in this field. However, STDM challenges and problems are not thoroughly discussed and presented in articles of their own. We attempt to fill this gap by providing a comprehensive literature survey on state-of-the-art advances in STDM. We describe the challenging issues and their causes and open gaps of multiple STDM directions and aspects. Specifically, we investigate the challenging issues in regards to spatiotemporal relationships, interdisciplinarity, discretisation, and data characteristics. Moreover, we discuss the limitations in the literature and open research problems related to spatiotemporal data representations, modelling and visualisation, and comprehensiveness of approaches. We explain issues related to STDM tasks of classification, clustering, hotspot detection, association and pattern mining, outlier detection, visualisation, visual analytics, and computer vision tasks. We also highlight STDM issues related to multiple applications including crime and public safety, traffic and transportation, earth and environment monitoring, epidemiology, social media, and Internet of Things.},
  archive      = {J_AIR},
  author       = {Hamdi, Ali and Shaban, Khaled and Erradi, Abdelkarim and Mohamed, Amr and Rumi, Shakila Khan and Salim, Flora D.},
  doi          = {10.1007/s10462-021-09994-y},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1441-1488},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Spatiotemporal data mining: A survey on challenges and open problems},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence (AI) for medical imaging to combat
coronavirus disease (COVID-19): A detailed review with direction for
future research. <em>AIR</em>, <em>55</em>(2), 1409–1439. (<a
href="https://doi.org/10.1007/s10462-021-09985-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since early 2020, the whole world has been facing the deadly and highly contagious disease named coronavirus disease (COVID-19) and the World Health Organization declared the pandemic on 11 March 2020. Over 23 million positive cases of COVID-19 have been reported till late August 2020. Medical images such as chest X-rays and Computed Tomography scans are becoming one of the main leading clinical diagnosis tools in fighting against COVID-19, underpinned by Artificial Intelligence based techniques, resulting in rapid decision-making in saving lives. This article provides an extensive review of AI-based methods to assist medical practitioners with comprehensive knowledge of the efficient AI-based methods for efficient COVID-19 diagnosis. Nearly all the reported methods so far along with their pros and cons as well as recommendations for improvements are discussed, including image acquisition, segmentation, classification, and follow-up diagnosis phases developed between 2019 and 2020. AI and machine learning technologies have boosted the accuracy of Covid-19 diagnosis, and most of the widely used deep learning methods have been implemented and worked well with a small amount of data for COVID-19 diagnosis. This review presents a detailed mythological analysis for the evaluation of AI-based methods used in the process of detecting COVID-19 from medical images. However, due to the quick outbreak of Covid-19, there are not many ground-truth datasets available for the communities. It is necessary to combine clinical experts’ observations and information from images to have a reliable and efficient COVID-19 diagnosis. This paper suggests that future research may focus on multi-modality based models as well as how to select the best model architecture where AI can introduce more intelligence to medical systems to capture the characteristics of diseases by learning from multi-modality data to obtain reliable results for COVID-19 diagnosis for timely treatment .},
  archive      = {J_AIR},
  author       = {Soomro, Toufique A. and Zheng, Lihong and Afifi, Ahmed J. and Ali, Ahmed and Yin, Ming and Gao, Junbin},
  doi          = {10.1007/s10462-021-09985-z},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1409-1439},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial intelligence (AI) for medical imaging to combat coronavirus disease (COVID-19): A detailed review with direction for future research},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy community detection on the basis of similarities in
structural/attribute in large-scale social networks. <em>AIR</em>,
<em>55</em>(2), 1373–1407. (<a
href="https://doi.org/10.1007/s10462-021-09987-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection aims to partition a set of nodes with more similarities in the set than out of it based on different criteria like neighborhood similarity or vertex connectivity. Most present day community detection methods principally concentrate on the topological structure, largely ignoring the heterogeneous properties of the vertex. This paper proposes a new community detection model, based on the possibilistic c-means model, by using structural as well as attribute similarities in a large scale in social networks. In the majority of real social networks, different clusters share nodes, resulting in the formation of overlapping communities. The proposed model, on the basis of structural and attribute similarity (PCMSA), serves as a fuzzy community detection model addressing the overlapping community detection problem, and detecting communities in a way that each community has a densely connected sub-graph with homogeneous attribute values. The function of the proposed model is assessed by a trade-off between intra-cluster and inter-cluster density and homogeneity. Therefore, to validate the proposed community detection algorithm (PCMSA) and its results, an index, compatible with the proposed model, is defined; and to assess the efficiency of the proposed fuzzy community detection, several experimental results in variety sizes from very small to very large sizes of real social networks are given, and the results are contrasted with other community detection models like FCAN, CODICIL, SA-cluster, K-SNAP and PCM. The experimental findings reveal the superiority of this novel model and its promising scalability and computational complexity over others.},
  archive      = {J_AIR},
  author       = {Naderipour, Mansoureh and Fazel Zarandi, Mohammad Hossein and Bastani, Susan},
  doi          = {10.1007/s10462-021-09987-x},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1373-1407},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Fuzzy community detection on the basis of similarities in structural/attribute in large-scale social networks},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A computational literature review of football performance
analysis through probabilistic topic modeling. <em>AIR</em>,
<em>55</em>(2), 1351–1371. (<a
href="https://doi.org/10.1007/s10462-021-09998-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research aims to illustrate the potential use of concepts, techniques, and mining process tools to improve the systematic review process. Thus, a review was performed on two online databases (Scopus and ISI Web of Science) from 2012 to 2019. A total of 9649 studies were identified, which were analyzed using probabilistic topic modeling procedures within a machine learning approach. The Latent Dirichlet Allocation method, chosen for modeling, required the following stages: 1) data cleansing, and 2) data modeling into topics for coherence and perplexity analysis. All research was conducted according to the standards of the Preferred Reporting Items for Systematic Reviews and Meta-Analyses in a fully computerized way. The computational literature review is an integral part of a broader literature review process. The results presented met three criteria: (1) literature review for a research area, (2) analysis and classification of journals, and (3) analysis and classification of academic and individual research teams. The contribution of the article is to demonstrate how the publication network is formed in this particular field of research, and how the content of abstracts can be automatically analyzed to provide a set of research topics for quick understanding and application in future projects.},
  archive      = {J_AIR},
  author       = {Principe, Vitor Ayres and de Souza Vale, Rodrigo Gomes and de Castro, Juliana Brandão Pinto and Carvano, Luiz Marcelo and Henriques, Roberto André Pereira and de Almeida e Sousa Lobo, Victor José and de Alkmim Moreira Nunes, Rodolfo},
  doi          = {10.1007/s10462-021-09998-8},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1351-1371},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A computational literature review of football performance analysis through probabilistic topic modeling},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel distance measure on q-rung picture fuzzy sets and
its application to decision making and classification problems.
<em>AIR</em>, <em>55</em>(2), 1317–1350. (<a
href="https://doi.org/10.1007/s10462-021-09990-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, different higher order fuzzy sets have been introduced to better handle the uncertainty in many practical decision making and data mining problems. The recent proposal of higher order fuzzy set is q-rung picture fuzzy set (q-RPFS) modeled by three parameters positive, negative, and neutral membership function. One of the important topics in q-RPFS is distance measures which play a crucial role in many multi criteria decision making methods and data mining applications. In this paper, we introduce a novel distance measure for q-RPFS which is the combination of q-rung orthopair fuzzy set (q-ROFS) and picture fuzzy set (PFS). The proposed distance measure is used in q-rung picture fuzzy (q-RPF) ELECTRE integrated with TOPSIS as a new approach for group decision making in q-RPF environment. To demonstrate the effectiveness of our proposed method, a comparison is made with the q-RPF approach based on aggregation operators using a numerical example for decision making problem. Furthermore, the proposed distance measure is utilized in a q-RPF k nearest neighborhood (kNN) algorithm for classification. The proposed classification algorithm is applied to twenty UCI machine learning classification data sets. A comparison with other algorithms is performed and the results show that the proposed classification algorithm has the highest average classification accuracy.},
  archive      = {J_AIR},
  author       = {Pinar, Adem and Boran, Fatih Emre},
  doi          = {10.1007/s10462-021-09990-2},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1317-1350},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A novel distance measure on q-rung picture fuzzy sets and its application to decision making and classification problems},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel fault diagnosis method based on CNN and LSTM and its
application in fault diagnosis for complex systems. <em>AIR</em>,
<em>55</em>(2), 1289–1315. (<a
href="https://doi.org/10.1007/s10462-021-09993-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis plays an important role in actual production activities. As large amounts of data can be collected efficiently and economically, data-driven methods based on deep learning have achieved remarkable results of fault diagnosis of complex systems due to their superiority in feature extraction. However, existing techniques rarely consider time delay of occurrence of faults, which affects the performance of fault diagnosis. In this paper, by synthetically considering feature extraction and time delay of occurrence of faults, we propose a novel fault diagnosis method that consists of two parts, namely, sliding window processing and CNN-LSTM model based on a combination of Convolutional Neural Network (CNN) and Long Short-Term Memory Network (LSTM). Firstly, samples obtained from multivariate time series by the sliding window processing integrates feature information and time delay information. Then, the obtained samples are fed into the proposed CNN-LSTM model including CNN layers and LSTM layers. The CNN layers perform feature learning without relying on prior knowledge. Time delay information is captured with the use of the LSTM layers. The fault diagnosis of the Tennessee Eastman chemical process is addressed, and it is verified that the predictive accuracy and noise sensitivity of fault diagnosis can be greatly improved when the proposed method is applied. Comparisons with five existing fault diagnosis methods show the superiority of the proposed method.},
  archive      = {J_AIR},
  author       = {Huang, Ting and Zhang, Qiang and Tang, Xiaoan and Zhao, Shuangyao and Lu, Xiaonong},
  doi          = {10.1007/s10462-021-09993-z},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1289-1315},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A novel fault diagnosis method based on CNN and LSTM and its application in fault diagnosis for complex systems},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High granular and short term time series forecasting of
<span class="math display">$$\hbox {PM}_{2.5}$$</span> air pollutant - a
comparative review. <em>AIR</em>, <em>55</em>(2), 1253–1287. (<a
href="https://doi.org/10.1007/s10462-021-09991-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting time series has acquired immense research importance and has vast applications in the area of air pollution monitoring. This work attempts to investigate the abilities of various existing techniques when applied for short term, high granular time series forecasting of PM2.5. More specifically, a comparative study has been provided, taking into account both popularly used models and lesser-used models in this area. The study has been carried out considering ten well defined models that are ARIMA (auto-regressive integrated moving average), SARIMA (seasonal ARIMA), SES (single exponential smoothing), DES (double exponential smoothing), TES (triple exponential smoothing), ANN (artificial neural network), DT (decision tree), kNN (k-nearest neighbor), LSTM (long short-term memory) and MCFO (markov chain first order). A framework has been built that categories the models, implements them under identical execution environment and forecasts succeeding values. Implementation has been carried out over five data sets of real-world air pollution time series, that are collected from five differently located government setup monitoring stations over a period of 1 year (July 2018-June 2019). Rigorous statistical analysis has been performed that yields an insight to the nature and variability of these time series data. Forecasting has been carried out on short term basis, focusing on high granularity whereas, three different lengths of forecast horizon (1 day, 1 week, and 1 month) have been tested. Eventually, the models have been compared in terms of their associated performance measuring units namely, RMSE (root mean of squared error), MAE (mean absolute error) and MAPE (mean absolute percentage error). The comparative results verified with multiple datasets show that all the models posses less error for a shorter forecast horizon, where LSTM providing the best performance. Superiority of machine learning and deep learning models are found in case of longer length of forecast horizon with kNN achieving best accuracy whereas, significant performance degradation of ARIMA is found for longer forecast horizon. Moreover, TES, DT, kNN, LSTM, MCFO are found to be well adopted in relation with shape and variability of the data. Note that the performance on various length of high granular forecast horizon have been studied over multiple datasets that give an added value to this work.},
  archive      = {J_AIR},
  author       = {Das, Rituparna and Middya, Asif Iqbal and Roy, Sarbani},
  doi          = {10.1007/s10462-021-09991-1},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1253-1287},
  shortjournal = {Artif. Intell. Rev.},
  title        = {High granular and short term time series forecasting of $$\hbox {PM}_{2.5}$$ air pollutant - a comparative review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diagnosis and prognosis of mental disorders by means of EEG
and deep learning: A systematic mapping study. <em>AIR</em>,
<em>55</em>(2), 1209–1251. (<a
href="https://doi.org/10.1007/s10462-021-09986-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) is used in the diagnosis and prognosis of mental disorders because it provides brain biomarkers. However, only highly trained doctors can interpret EEG signals due to its complexity. Machine learning has been successfully trained with EEG signals for classifying mental disorders, but a time consuming and disorder-dependant feature engineering (FE) and subsampling process is required over raw EEG data. Deep Learning (DL) is positioned as a prominent research field to process EEG data because (i) it features automated FE by taking advantage of raw EEG signals improving results and (ii) it can be trained over the vast amount of data generated by EEG. In this work, a systematic mapping study has been performed with 46 carefully selected primary studies. Our goals were (i) to provide a clear view of which are the most prominent study topics in diagnosis and prognosis of mental disorders by using EEG with DL, and (ii) to give some recommendations for future works. Some results are: epilepsy was the predominant mental disorder present in around half of the studies, convolutional neural networks also appear in approximate 50\% of the works. The main conclusions are (i) processing EEG with DL to detect mental disorders is a promising research field and (ii) to objectively compare performance between studies: public datasets, intra-subject validation, and standard metrics should be used. Additionally, we suggest to pay more attention to ease the reproducibility, and to use (when possible) an available framework to explain the results of the created DL models.},
  archive      = {J_AIR},
  author       = {Rivera, Manuel J. and Teruel, Miguel A. and Maté, Alejandro and Trujillo, Juan},
  doi          = {10.1007/s10462-021-09986-y},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1209-1251},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Diagnosis and prognosis of mental disorders by means of EEG and deep learning: A systematic mapping study},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Picture fuzzy interactional partitioned heronian mean
aggregation operators: An application to MADM process. <em>AIR</em>,
<em>55</em>(2), 1171–1208. (<a
href="https://doi.org/10.1007/s10462-021-09953-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The picture fuzzy sets (PFSs) state or model the voting information accurately without information loss. However, their existing operational laws usually generate unreasonable computing results, especially when the agreement degree (AD) or neutrality degree (ND) or opposition degree (OD) is zero. To tackle this issue, we propose the interactional operational laws (IOLs) to compute picture fuzzy numbers (PFNs), which can capture the interaction between the ADs and NDs in two PFNs, as well as the interaction between the ADs and ODs in two PFNs. Based on the proposed novel IOLs, partitioned Heronian mean (PHM) operator, and partitioned geometric Heronian mean (PGHM) operator, some picture fuzzy interactional PHM (PFIPHM), weighted PFIPHM (PFIWPHM), geometric PFIPHM (PFIPGHM), and weighted PFIPGHM (PFIWPGHM) operators are proposed in this paper. Afterwards, we investigate the properties of these operators. Using the PFIWPHM and PFIWPGHM operators, a novel multiple attribute decision-making (MADM) method with PFNs is elaborated. Finally, a study example that involves the service quality ranking of nursing facilities is provided to show the decision procedure of the proposed MADM method and we also give the comparative analysis between the proposed operators and the existing aggregation operators developed for PFNs.},
  archive      = {J_AIR},
  author       = {Lin, Mingwei and Li, Xinmei and Chen, Riqing and Fujita, Hamido and Lin, Jian},
  doi          = {10.1007/s10462-021-09953-7},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1171-1208},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Picture fuzzy interactional partitioned heronian mean aggregation operators: An application to MADM process},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pattern identification of different human joints for
different human walking styles using inertial measurement unit (IMU)
sensor. <em>AIR</em>, <em>55</em>(2), 1149–1169. (<a
href="https://doi.org/10.1007/s10462-021-09979-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A bipedal walking robot is a kind of humanoid robot. It is suppose to mimics human behavior and designed to perform human specific tasks. Currently, humanoid robots are not capable to walk like human being. To perform the walking task, in the current work, human gait data of six different walking styles named brisk walk, normal walk, very slow walk, medium walk, jogging and fast walk is collected through our configured IMU sensor and mobile-based accelerometers device. To capture the pattern for six different walking styles, data is extracted for hip, knee, ankle, shank, thigh and foot. A total six classes of walking activities are explored for clinical examination. The accelerometer is placed at center of the human body of 15 male and 10 female subjects. In the experimental setup, we have done exploratory analysis over the different gait capturing techniques, different gait features and different gait classification techniques. For the classification purpose, three state of art techniques are used as artificial neural network, extreme learning machine and deep neural network learning based CNN mode. The model classification accuracy is obtained as 87.4\%, 88\% and 92\%, respectively. Here, WISDM activity data set is also used for verification purpose.},
  archive      = {J_AIR},
  author       = {Semwal, Vijay Bhaskar and Gaud, Neha and Lalwani, Praveen and Bijalwan, Vishwanath and Alok, Abhay Kumar},
  doi          = {10.1007/s10462-021-09979-x},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1149-1169},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Pattern identification of different human joints for different human walking styles using inertial measurement unit (IMU) sensor},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tangent-cut optimizer on gradient descent: An approach
towards hybrid heuristics. <em>AIR</em>, <em>55</em>(2), 1121–1147. (<a
href="https://doi.org/10.1007/s10462-021-09984-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The world has witnessed a surfeit of usage of Artificial Intelligence systems for a long time. Nowadays, most of the problems are transforming from logical solutions into statistical domains. This requires the implementation of machine learning algorithms to mine useful data from the statistical datasets which in turn demands high-end computing. Generally, machine learning algorithms utilize Gradient Descent as a tool to find the optimal solution of computationally expensive problems. This gave rise to the development of optimization algorithms like Momentum, RMSProp, Adam and the like, which could speed up the convergence to the global optimum besides increasing the learning accuracy. However, nowadays the supervised machine learning models got more data intensive which increased their computational cost, putting the efficiency of these algorithms into question. In this context, a new optimization algorithm namely, the Tangent-Cut Optimizer (TC-Opt) has been proposed which can converge faster than the traditional optimization algorithms for supervised machine learning models. Furthermore, the proposed work brings forward a phenomenon that intertwines the statistical and logical decision-making model into a single unit while shedding light on a new heuristic approach named “Hybrid Heuristics”. The proposed algorithm has been implemented on the standard dataset of Boston House Pricing Dataset for linear regression and MNIST image dataset of handwritten digits from 0 to 9 for logistic regression and its performance has been compared with the existing algorithms. Finally, the robustness and high accuracy of the proposed optimization algorithm have been proved and demonstrated in the presentation.},
  archive      = {J_AIR},
  author       = {Biswas, Saptarshi and Nath, Subhrapratim and Dey, Sumagna and Majumdar, Utsha},
  doi          = {10.1007/s10462-021-09984-0},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1121-1147},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Tangent-cut optimizer on gradient descent: An approach towards hybrid heuristics},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Postal address extraction from the web: A comprehensive
survey. <em>AIR</em>, <em>55</em>(2), 1085–1120. (<a
href="https://doi.org/10.1007/s10462-021-09983-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Web is a source of information for Location-Based Service (LBS) applications. These applications lack postal addresses for the user’s Point of Interests (POIs) such as schools, hospitals, restaurants, etc., as these locations are annotated manually by using the yellow pages or by the location owners (users/companies). Our study in this paper confirms that Google Maps, a common LBS application, only contains about $$32.5\%$$ of the public schools that are registered officially in the documents provided by the Directorate of Education in Egypt. However, the remaining missed school addresses could be fished from the Web (e.g., social media). To the best of our knowledge, no prior survey has been published to compare the previous Web postal address extraction approaches. Additionally, all proposed approaches for address extraction are local (could be working in specific countries/locations with particular languages) and could not be used or even adapted to work in other countries/locations with other languages. Furthermore, the problem of Web postal address extraction is not addressed in many countries such as Arab countries (e.g. Egypt). This paper discusses the issue of address extraction, highlights and compares the recently used techniques in extracting addresses from Web pages. In addition, it investigates the discrepancy of knowledge among existing systems. Moreover, it provides a comprehensive review of the geographical Gazetteers used in the Web postal address approaches and compares their data quality dimensions.},
  archive      = {J_AIR},
  author       = {Kayed, Mohammed and Dakrory, Sara and Ali, A. A.},
  doi          = {10.1007/s10462-021-09983-1},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1085-1120},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Postal address extraction from the web: A comprehensive survey},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Use of learning approaches to predict clinical deterioration
in patients based on various variables: A review of the literature.
<em>AIR</em>, <em>55</em>(2), 1055–1084. (<a
href="https://doi.org/10.1007/s10462-021-09982-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning can be considered as the current gold standard for predicting deterioration in Intensive Care Unit patients and is in extensive use throughout the world in different fields. As confirmed by many studies, preventing the occurrence of the onset of deterioration in a sufficient time window is a priority in healthcare centers. Also, the significance of enhancing the quality of hospital care and the reduction of adverse outcomes is of great importance. Notably, it is hypothesized that by exploiting recent technologies, models built upon dynamic variables (e.g. vital signs, lab tests, and demographic variables) could reinforce the predictive ability of models aimed at detection of in clinical deterioration with high accuracy, sensitivity and specificity. This manuscript summarises the techniques and approaches proposed in the literature for predicting deterioration and compares the performance and limitations of various approaches grouped based on their application. While several approaches can attain promising results, there is still room for additional improvement, especially in pre-processing and modeling enhancement steps where most methods do not take the necessary steps for ensuring a high-performance result. In this manuscript, the most effective machine learning models, as well as deep learning models, for predicting deterioration of patients are discussed in hopes of assisting the readers with ascertaining the best possible solutions for this problem.},
  archive      = {J_AIR},
  author       = {Al-Shwaheen, Tariq Ibrahim and Moghbel, Mehrdad and Hau, Yuan Wen and Ooi, Chia Yee},
  doi          = {10.1007/s10462-021-09982-2},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1055-1084},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Use of learning approaches to predict clinical deterioration in patients based on various variables: A review of the literature},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence in cyber security: Research
advances, challenges, and opportunities. <em>AIR</em>, <em>55</em>(2),
1029–1053. (<a
href="https://doi.org/10.1007/s10462-021-09976-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, there have been attempts to leverage artificial intelligence (AI) techniques in a broad range of cyber security applications. Therefore, this paper surveys the existing literature (comprising 54 papers mainly published between 2016 and 2020) on the applications of AI in user access authentication, network situation awareness, dangerous behavior monitoring, and abnormal traffic identification. This paper also identifies a number of limitations and challenges, and based on the findings, a conceptual human-in-the-loop intelligence cyber security model is presented.},
  archive      = {J_AIR},
  author       = {Zhang, Zhimin and Ning, Huansheng and Shi, Feifei and Farha, Fadi and Xu, Yang and Xu, Jiabo and Zhang, Fan and Choo, Kim-Kwang Raymond},
  doi          = {10.1007/s10462-021-09976-0},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1029-1053},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial intelligence in cyber security: Research advances, challenges, and opportunities},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uncertainty measurement for heterogeneous data: An
application in attribute reduction. <em>AIR</em>, <em>55</em>(2),
991–1027. (<a href="https://doi.org/10.1007/s10462-021-09978-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, multimedia, hyper-media and social networks are emerging, and the amount of information is growing rapidly. When people participate in the process of massive data processing, they will encounter data with different structures, so data has heterogeneity. How to acquire hidden and valuable knowledge from heterogeneous data and measure its uncertainty is an important problem in artificial intelligence. This paper investigates uncertainty measurement for heterogeneous data and gives its application in attribute reduction. The concept of a heterogeneous information system (HIS) is first proposed. Then, an equivalence relation on the object set is constructed. Next, uncertainty measurement for a HIS is investigated, a numerical experiment is given, and dispersion analysis, correlation analysis, and Friedman test and Bonferroni–Dunn test in statistics are conducted. Finally, as an application of the proposed measures, attribute reduction in a HIS is studied, and the corresponding algorithms and their analysis are proposed.},
  archive      = {J_AIR},
  author       = {Song, Yan and Zhang, Gangqiang and He, Jiali and Liao, Shimin and Xie, Ningxin},
  doi          = {10.1007/s10462-021-09978-y},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {991-1027},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Uncertainty measurement for heterogeneous data: An application in attribute reduction},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reinforcement learning in robotic applications: A
comprehensive survey. <em>AIR</em>, <em>55</em>(2), 945–990. (<a
href="https://doi.org/10.1007/s10462-021-09997-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent trends, artificial intelligence (AI) is used for the creation of complex automated control systems. Still, researchers are trying to make a completely autonomous system that resembles human beings. Researchers working in AI think that there is a strong connection present between the learning pattern of human and AI. They have analyzed that machine learning (ML) algorithms can effectively make self-learning systems. ML algorithms are a sub-field of AI in which reinforcement learning (RL) is the only available methodology that resembles the learning mechanism of the human brain. Therefore, RL must take a key role in the creation of autonomous robotic systems. In recent years, RL has been applied on many platforms of the robotic systems like an air-based, under-water, land-based, etc., and got a lot of success in solving complex tasks. In this paper, a brief overview of the application of reinforcement algorithms in robotic science is presented. This survey offered a comprehensive review based on segments as (1) development of RL (2) types of RL algorithm like; Actor-Critic, DeepRL, multi-agent RL and Human-centered algorithm (3) various applications of RL in robotics based on their usage platforms such as land-based, water-based and air-based, (4) RL algorithms/mechanism used in robotic applications. Finally, an open discussion is provided that potentially raises a range of future research directions in robotics. The objective of this survey is to present a guidance point for future research in a more meaningful direction.},
  archive      = {J_AIR},
  author       = {Singh, Bharat and Kumar, Rajesh and Singh, Vinay Pratap},
  doi          = {10.1007/s10462-021-09997-9},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {945-990},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Reinforcement learning in robotic applications: A comprehensive survey},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-agent deep reinforcement learning: A survey.
<em>AIR</em>, <em>55</em>(2), 895–943. (<a
href="https://doi.org/10.1007/s10462-021-09996-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advances in reinforcement learning have recorded sublime success in various domains. Although the multi-agent domain has been overshadowed by its single-agent counterpart during this progress, multi-agent reinforcement learning gains rapid traction, and the latest accomplishments address problems with real-world complexity. This article provides an overview of the current developments in the field of multi-agent deep reinforcement learning. We focus primarily on literature from recent years that combines deep reinforcement learning methods with a multi-agent scenario. To survey the works that constitute the contemporary landscape, the main contents are divided into three parts. First, we analyze the structure of training schemes that are applied to train multiple agents. Second, we consider the emergent patterns of agent behavior in cooperative, competitive and mixed scenarios. Third, we systematically enumerate challenges that exclusively arise in the multi-agent domain and review methods that are leveraged to cope with these challenges. To conclude this survey, we discuss advances, identify trends, and outline possible directions for future work in this research area.},
  archive      = {J_AIR},
  author       = {Gronauer, Sven and Diepold, Klaus},
  doi          = {10.1007/s10462-021-09996-w},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {895-943},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-agent deep reinforcement learning: A survey},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive survey on optimizing deep learning models by
metaheuristics. <em>AIR</em>, <em>55</em>(2), 829–894. (<a
href="https://doi.org/10.1007/s10462-021-09992-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs), which are extensions of artificial neural networks, can learn higher levels of feature hierarchy established by lower level features by transforming the raw feature space to another complex feature space. Although deep networks are successful in a wide range of problems in different fields, there are some issues affecting their overall performance such as selecting appropriate values for model parameters, deciding the optimal architecture and feature representation and determining optimal weight and bias values. Recently, metaheuristic algorithms have been proposed to automate these tasks. This survey gives brief information about common basic DNN architectures including convolutional neural networks, unsupervised pre-trained models, recurrent neural networks and recursive neural networks. We formulate the optimization problems in DNN design such as architecture optimization, hyper-parameter optimization, training and feature representation level optimization. The encoding schemes used in metaheuristics to represent the network architectures are categorized. The evolutionary and selection operators, and also speed-up methods are summarized, and the main approaches to validate the results of networks designed by metaheuristics are provided. Moreover, we group the studies on the metaheuristics for deep neural networks based on the problem type considered and present the datasets mostly used in the studies for the readers. We discuss about the pros and cons of utilizing metaheuristics in deep learning field and give some future directions for connecting the metaheuristics and deep learning. To the best of our knowledge, this is the most comprehensive survey about metaheuristics used in deep learning field.},
  archive      = {J_AIR},
  author       = {Akay, Bahriye and Karaboga, Dervis and Akay, Rustu},
  doi          = {10.1007/s10462-021-09992-0},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {829-894},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive survey on optimizing deep learning models by metaheuristics},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A systematic literature review on state-of-the-art deep
learning methods for process prediction. <em>AIR</em>, <em>55</em>(2),
801–827. (<a href="https://doi.org/10.1007/s10462-021-09960-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process mining enables the reconstruction and evaluation of business processes based on digital traces in IT systems. An increasingly important technique in this context is process prediction. Given a sequence of events of an ongoing trace, process prediction allows forecasting upcoming events or performance measurements. In recent years, multiple process prediction approaches have been proposed, applying different data processing schemes and prediction algorithms. This study focuses on deep learning algorithms since they seem to outperform their machine learning alternatives consistently. Whilst having a common learning algorithm, they use different data preprocessing techniques, implement a variety of network topologies and focus on various goals such as outcome prediction, time prediction or control-flow prediction. Additionally, the set of log-data, evaluation metrics and baselines used by the authors diverge, making the results hard to compare. This paper attempts to synthesise the advantages and disadvantages of the procedural decisions in these approaches by conducting a systematic literature review.},
  archive      = {J_AIR},
  author       = {Neu, Dominic A. and Lahann, Johannes and Fettke, Peter},
  doi          = {10.1007/s10462-021-09960-8},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {801-827},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic literature review on state-of-the-art deep learning methods for process prediction},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). News recommender system: A review of recent progress,
challenges, and opportunities. <em>AIR</em>, <em>55</em>(1), 749–800.
(<a href="https://doi.org/10.1007/s10462-021-10043-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, more and more news readers read news online where they have access to millions of news articles from multiple sources. In order to help users find the right and relevant content, news recommender systems (NRS) are developed to relieve the information overload problem and suggest news items that might be of interest for the news readers. In this paper, we highlight the major challenges faced by the NRS and identify the possible solutions from the state-of-the-art. Our discussion is divided into two parts. In the first part, we present an overview of the recommendation solutions, datasets, evaluation criteria beyond accuracy and recommendation platforms being used in the NRS. We also talk about two popular classes of models that have been successfully used in recent years. In the second part, we focus on the deep neural networks as solutions to build the NRS. Different from previous surveys, we study the effects of news recommendations on user behaviors and try to suggest possible remedies to mitigate those effects. By providing the state-of-the-art knowledge, this survey can help researchers and professional practitioners have a better understanding of the recent developments in news recommendation algorithms. In addition, this survey sheds light on the potential new directions.},
  archive      = {J_AIR},
  author       = {Raza, Shaina and Ding, Chen},
  doi          = {10.1007/s10462-021-10043-x},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {749-800},
  shortjournal = {Artif. Intell. Rev.},
  title        = {News recommender system: A review of recent progress, challenges, and opportunities},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Arabic sentiment analysis using recurrent neural networks: A
review. <em>AIR</em>, <em>55</em>(1), 707–748. (<a
href="https://doi.org/10.1007/s10462-021-09989-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last decade, the amount of Arabic content created on websites and social media has grown significantly. Opinions are shared openly and freely on social media and thus provide a rich source for trend analyses, which are accomplished by conventional methods of language interpretation, such as sentiment analysis. Due to its accuracy in studying unstructured data, deep learning has been increasingly used to test opinions. Recurrent neural networks (RNNs) are a promising approach in textual analysis and exhibit large morphological variations. In total, 193 studies used RNNs in English-language sentiment analysis, and 24 studies used RNNs in Arabic-language sentiment analysis. Those studies varied in the areas they address, the functionality and weaknesses of the models, and the number and scale of the available datasets for different dialects. Such variations are worthy of attention and monitoring; thus, this paper presents a systematic examination of the literature to label, evaluate, and identify state-of-the-art studies using RNNs for Arabic sentiment analysis.},
  archive      = {J_AIR},
  author       = {Alhumoud, Sarah Omar and Al Wazrah, Asma Ali},
  doi          = {10.1007/s10462-021-09989-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {707-748},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Arabic sentiment analysis using recurrent neural networks: A review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using proposed optimization algorithm for solving inverse
kinematics of human upper limb applying in rehabilitation robotic.
<em>AIR</em>, <em>55</em>(1), 679–705. (<a
href="https://doi.org/10.1007/s10462-021-10041-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The requirement to solve the problem of Inverse Kinetics (IK) plays a very important role in the robotics field in general, and especially in the field of rehabilitation robots, in particular. If the solutions of this problem are not suitable, it can cause undesirable damage to the patient when exercising. Normally, the problem of Inverse Kinematics in the robotics field, as well as the natural field, especially for redundant driven systems, often requires the application of a lot of techniques. The redundancy in Degree of Freedom (DoF), the nonlinearity of the system leads to solve inverse kinematics problem more challenge. In this study, we proposed to apply the self-adaptive control parameters in Differential Evolution with search space improvement (Pro-ISADE) to solve the problem for the human upper limb, which is a very typical redundancy model in nature. First of all, the angles of the joints were measured by a proposed Exoskeleton type Human Motion Capture System (E-HMCS) when the wearer performs some Activities of Daily Living (ADL) and athletic activities. The values of these measured angles joints then were put into the forward kinematics model to find the end effector trajectories. After having these orbits, they were re-fed into the proposed Pro-ISADE algorithm mentioned above to process the IK problem and obtain the predicted joints angular values. The experimental results showed that the predicted joints’ values closely follow the measured joints’ values. That demonstrates the ability to apply the Pro-ISADE algorithm to solve the problem of Inverse Kinetics of the human upper limb as well as the upper limb rehabilitation robot arm.},
  archive      = {J_AIR},
  author       = {Nguyen, Trung and Bui, Tam and Pham, Ha},
  doi          = {10.1007/s10462-021-10041-z},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {679-705},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Using proposed optimization algorithm for solving inverse kinematics of human upper limb applying in rehabilitation robotic},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reduction 93.7% time and power consumption using a
memristor-based imprecise gradient update algorithm. <em>AIR</em>,
<em>55</em>(1), 657–677. (<a
href="https://doi.org/10.1007/s10462-021-10060-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional computing system with the architecture of von Neumann has greatly benefited our humans for past decades, while it is also suffered from low efficiency due to the separation between a memory block and a processing unit. Memristor, which is an emerging electron device with the capability of data storage and processing information simultaneously, can be employed to construct a bioinspired neuromorphic computing system. Simulation as one of the most powerful methods to obtain the optimizing result for the memristor-based neuromorphic network has been extensively focused to realize the high precision calculation. It becomes very difficult because the pulse-to-pulse (P2P) model is limited by the updating process. The memristor-based multi-layer Perceptron (MLP) network online training generally presents a low accuracy. Therefore, an efficiency training schedual is urgently desired to improve the accuracy. Based on the resistive switching behavior observed in the Ag/TiOx/F-doped SnO2 memristor, the weight update by the P2P model enables the MLP network online training in the low accuracy memristor with high performance. The low bits MLP optimized by a novel weight update schedual can realize high precision identification and classification. By that, the time and power consumption of memristor can be largely reduced. The experiment result illustrates that the high accuracy of 90.82\% and 95.44\% can be obtained at the first and final epoch of the MNIST handwritten digital datasets, respectively. Importantly, the number of the weight update, and the online training time and power consumption can be reduced by 81\% and 93.7\%, respectively. The scheme provides high precision, low power consumption, and fast convergence solution for the in-situ training of the imprecise memristor-based neuromorphic network.},
  archive      = {J_AIR},
  author       = {Li, Jie and Zhou, Guangdong and Li, Yingying and Chen, Jiahao and Ge, Yuan and Mo, Yan and Yang, Yuanlei and Qian, Xicong and Jiang, Wenwu and Liu, Hongbo and Guo, Mingjian and Wang, Lidan and Duan, Shukai},
  doi          = {10.1007/s10462-021-10060-w},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {657-677},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Reduction 93.7\% time and power consumption using a memristor-based imprecise gradient update algorithm},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence in the creative industries: A
review. <em>AIR</em>, <em>55</em>(1), 589–656. (<a
href="https://doi.org/10.1007/s10462-021-10039-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reviews the current state of the art in artificial intelligence (AI) technologies and applications in the context of the creative industries. A brief background of AI, and specifically machine learning (ML) algorithms, is provided including convolutional neural networks (CNNs), generative adversarial networks (GANs), recurrent neural networks (RNNs) and deep Reinforcement Learning (DRL). We categorize creative applications into five groups, related to how AI technologies are used: (i) content creation, (ii) information analysis, (iii) content enhancement and post production workflows, (iv) information extraction and enhancement, and (v) data compression. We critically examine the successes and limitations of this rapidly advancing technology in each of these areas. We further differentiate between the use of AI as a creative tool and its potential as a creator in its own right. We foresee that, in the near future, ML-based AI will be adopted widely as a tool or collaborative assistant for creativity. In contrast, we observe that the successes of ML in domains with fewer constraints, where AI is the ‘creator’, remain modest. The potential of AI (or its developers) to win awards for its original creations in competition with human creatives is also limited, based on contemporary technologies. We therefore conclude that, in the context of creative industries, maximum benefit from AI will be derived where its focus is human-centric—where it is designed to augment, rather than replace, human creativity.},
  archive      = {J_AIR},
  author       = {Anantrasirichai, Nantheera and Bull, David},
  doi          = {10.1007/s10462-021-10039-7},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {589-656},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial intelligence in the creative industries: A review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial neural networks for water quality soft-sensing in
wastewater treatment: A review. <em>AIR</em>, <em>55</em>(1), 565–587.
(<a href="https://doi.org/10.1007/s10462-021-10038-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to present a comprehensive survey on water quality soft-sensing of a wastewater treatment process (WWTP) based on artificial neural networks (ANNs). We mainly present problem formulation of water quality soft-sensing, common soft-sensing models, practical soft-sensing examples and discussion on the performance of soft-sensing models. In details, problem formulation includes characteristic analysis and modeling principle of water quality soft-sensing. The common soft-sensing models mainly include a back-propagation neural network, radial basis function neural network, fuzzy neural network (FNN), echo state network (ESN), growing deep belief network and deep belief network with event-triggered learning (DBN-EL). They are compared in terms of accuracy, efficiency and computational complexity with partial-least-square-regression DBN (PLSR-DBN), growing ESN, sparse deep belief FNN, self-organizing DBN, wavelet-ANN and self-organizing cascade neural network (SCNN). In addition, this paper generally discusses and explains what factors affect the accuracy of the ANNs-based soft-sensing models. Finally, this paper points out several challenges in soft-sensing models of WWTP, which may be helpful for researchers and practitioner to explore the future solutions for their particular applications.},
  archive      = {J_AIR},
  author       = {Wang, Gongming and Jia, Qing-Shan and Zhou, MengChu and Bi, Jing and Qiao, Junfei and Abusorrah, Abdullah},
  doi          = {10.1007/s10462-021-10038-8},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {565-587},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial neural networks for water quality soft-sensing in wastewater treatment: A review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on intrusion detection system: Feature selection,
model, performance measures, application perspective, challenges, and
future research directions. <em>AIR</em>, <em>55</em>(1), 453–563. (<a
href="https://doi.org/10.1007/s10462-021-10037-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase in the usage of the Internet, a large amount of information is exchanged between different communicating devices. The data should be communicated securely between the communicating devices and therefore, network security is one of the dominant research areas for the current network scenario. Intrusion detection systems (IDSs) are therefore widely used along with other security mechanisms such as firewall and access control. Many research ideas have been proposed pertaining to the IDS using machine learning (ML) techniques, deep learning (DL) techniques, and swarm and evolutionary algorithms (SWEVO). These methods have been tested on the datasets such as DARPA, KDD CUP 99, and NSL-KDD using network features to classify attack types. This paper surveys the intrusion detection problem by considering algorithms from areas such as ML, DL, and SWEVO. The survey is a representative research work carried out in the field of IDS from the year 2008 to 2020. The paper focuses on the methods that have incorporated feature selection in their models for performance evaluation. The paper also discusses the different datasets of IDS and a detailed description of recent dataset CIC IDS-2017. The paper presents applications of IDS with challenges and potential future research directions. The study presented, can serve as a pedestal for research communities and novice researchers in the field of network security for understanding and developing efficient IDS models.},
  archive      = {J_AIR},
  author       = {Thakkar, Ankit and Lohiya, Ritika},
  doi          = {10.1007/s10462-021-10037-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {453-563},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on intrusion detection system: Feature selection, model, performance measures, application perspective, challenges, and future research directions},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Population-based optimization in structural engineering: A
review. <em>AIR</em>, <em>55</em>(1), 345–452. (<a
href="https://doi.org/10.1007/s10462-021-10036-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural engineering is focused on the safe and efficient design of infrastructure. Projects can range in size and complexity, many requiring massive amounts of materials and expensive construction and operational costs. Therefore, one of the primary objectives for structural engineers is a cost-effective design. Incorporating optimality criteria into the design procedure introduces additional complexities that result in problems that are nonlinear, nonconvex, and have a discontinuous solution space. Population-based optimization algorithms (known as metaheuristics) have been found to be very efficient approaches to these problems. Many researchers have developed and applied state-of-art metaheuristics to automate and optimize the design of real-world civil engineering problems. While there is a large body of published papers in this area, there are few comprehensive reviews that list, summarize, and categorize metaheuristic optimization in structural engineering. This paper provides an extensive survey of a wide range of metaheuristic techniques to structural engineering optimization problems. Also, information is provided on available structural engineering benchmark problems, the formulation of different objective functions, and the handling of various types of constraints. The performance of different optimization techniques is compared for many benchmark problems.},
  archive      = {J_AIR},
  author       = {Kashani, Ali R. and Camp, Charles V. and Rostamian, Mehdi and Azizi, Koorosh and Gandomi, Amir H.},
  doi          = {10.1007/s10462-021-10036-w},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {345-452},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Population-based optimization in structural engineering: A review},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The role of AI technology in prediction, diagnosis and
treatment of colorectal cancer. <em>AIR</em>, <em>55</em>(1), 323–343.
(<a href="https://doi.org/10.1007/s10462-021-10034-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) is a fascinating new technology that incorporates machine learning and neural networks to improve existing technology or create new ones. Potential applications of AI are introduced to aid in the fight against colorectal cancer (CRC). This includes how AI will affect the epidemiology of colorectal cancer and the new methods of mass information gathering like GeoAI, digital epidemiology and real-time information collection. Meanwhile, this review also examines existing tools for diagnosing disease like CT/MRI, endoscopes, genetics, and pathological assessments also benefitted greatly from implementation of deep learning. Finally, how treatment and treatment approaches to CRC can be enhanced when applying AI is under discussion. The power of AI regarding the therapeutic recommendation in colorectal cancer demonstrates much promise in clinical and translational field of oncology, which means better and personalized treatments for those in need.},
  archive      = {J_AIR},
  author       = {Yu, Chaoran and Helwig, Ernest Johann},
  doi          = {10.1007/s10462-021-10034-y},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {323-343},
  shortjournal = {Artif. Intell. Rev.},
  title        = {The role of AI technology in prediction, diagnosis and treatment of colorectal cancer},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review on weight initialization strategies for neural
networks. <em>AIR</em>, <em>55</em>(1), 291–322. (<a
href="https://doi.org/10.1007/s10462-021-10033-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few years, neural networks have exhibited remarkable results for various applications in machine learning and computer vision. Weight initialization is a significant step employed before training any neural network. The weights of a network are initialized and then adjusted repeatedly while training the network. This is done till the loss converges to a minimum value and an ideal weight matrix is obtained. Thus weight initialization directly drives the convergence of a network. Therefore, the selection of an appropriate weight initialization scheme becomes necessary for end-to-end training. An appropriate technique initializes the weights such that the training of the network is accelerated and the performance is improved. This paper discusses various advances in weight initialization for neural networks. The weight initialization techniques in the literature adopted for feed-forward neural network, convolutional neural network, recurrent neural network and long short term memory network have been discussed in this paper. These techniques are classified as (1) initialization techniques without pre-training, which are further classified into random initialization and data-driven initialization, (2) initialization techniques with pre-training. The different weight initialization and weight optimization techniques which select optimal weights for non-iterative training mechanism have also been discussed. We provide a close overview of different initialization schemes in these categories. This paper concludes with discussions on existing schemes and the future scope for research.},
  archive      = {J_AIR},
  author       = {Narkhede, Meenal V. and Bartakke, Prashant P. and Sutaone, Mukul S.},
  doi          = {10.1007/s10462-021-10033-z},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {291-322},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review on weight initialization strategies for neural networks},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A systemic approach to classification for knowledge
discovery with applications to the identification of boundary equations
in complex systems. <em>AIR</em>, <em>55</em>(1), 255–289. (<a
href="https://doi.org/10.1007/s10462-021-10032-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification, which means discrimination between examples belonging to different classes, is a fundamental aspect of most scientific and engineering activities. Machine Learning (ML) tools have proved to be very performing in this task, in the sense that they can achieve very high success rates. However, both “realism” and interpretability of their models are low, leading to modest increases of knowledge and limited applicability, particularly in applications related to nonlinear and complex systems. In this paper, a methodology is described, which, by applying ML tools directly to the data, allows formulating new scientific models that describe the actual “physics” determining the boundary between the classes. The proposed technique consists of a stack of different ML tools, each one applied to a specific subtask of the scientific analysis; all together they form a system, which combines all the major strands of machine learning, from rule based classifiers and Bayesian statistics to genetic programming and symbolic manipulation. To take into account the error bars of the measurements generating the data, an essential aspect of scientific inference, the novel concept of the Geodesic Distance on Gaussian manifolds is adopted. The properties of the methodology have been investigated with a series of systematic numerical tests for different types of classification problems. The potential of the approach to handle real data has been tested with various experimental databases, built using measurements collected in the investigations of complex systems. The obtained results indicate that the proposed method permits to find physically meaningful mathematical equations, which reflect the actual phenomena under study. The developed techniques therefore constitute a very useful information processing system to bridge the gap between data, machine learning models and scientific theories.},
  archive      = {J_AIR},
  author       = {Murari, A. and Gelfusa, M. and Lungaroni, M. and Gaudio, P. and Peluso, E.},
  doi          = {10.1007/s10462-021-10032-0},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {255-289},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systemic approach to classification for knowledge discovery with applications to the identification of boundary equations in complex systems},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Arabic question answering system: A survey. <em>AIR</em>,
<em>55</em>(1), 207–253. (<a
href="https://doi.org/10.1007/s10462-021-10031-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question answering is a subfield of information retrieval. It is a task of answering a question posted in a natural language. A question answering system (QAS) may be considered a good alternative to search engines that return a set of related documents. The QAS system is composed of three main modules; question analysis, passage retrieval, and answer extraction. Over the years, numerous QASs have been presented for use in different languages. However, the the development of Arabic QASs has been slowed by linguistic challenges and the lack of resources and tools available to researchers. In this survey, we start with the challenges due to the language and how these challenges make the development of new Arabic QAS more difficult. Next, we do a detailed review of several Arabic QASs. This is followed by an in-depth analysis of the techniques and approaches in the three modules of a QAS. We present an overview of important and recent tools that were developed to help the researchers in this field. We also cover the available Arabic and multilingual datasets, and a look at the different measures used to assess QASs. Finally, the survey delves into the future direction of Arabic QAS systems based on the current state-of-the-art techniques developed for question answering in other languages.},
  archive      = {J_AIR},
  author       = {Alwaneen, Tahani H. and Azmi, Aqil M. and Aboalsamh, Hatim A. and Cambria, Erik and Hussain, Amir},
  doi          = {10.1007/s10462-021-10031-1},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {207-253},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Arabic question answering system: A survey},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An extended hesitant fuzzy set using SWARA-MULTIMOORA
approach to adapt online education for the control of the pandemic
spread of COVID-19 in higher education institutions. <em>AIR</em>,
<em>55</em>(1), 181–206. (<a
href="https://doi.org/10.1007/s10462-021-10029-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The world has been challenged since late 2019 by COVID-19. Higher education institutions have faced various challenges in adapting online education to control the pandemic spread of COVID-19. The present study aims to conduct a survey study through the interview and scrutinizing the literature to find the key challenges. Subsequently, an integrated MCDM framework, including Stepwise Weight Assessment Ratio Analysis (SWARA) and Multiple Objective Optimization based on Ratio Analysis plus Full Multiplicative Form (MULTIMOORA), is developed. The SWARA procedure is applied to the analysis and assesses the challenges to adapt the online education during the COVID-19 outbreak, and the MULTIMOORA approach is utilized to rank the higher education institutions on hesitant fuzzy sets. Further, an illustrative case study is considered to express the proposed idea&#39;s feasibility and efficacy in real-world decision-making. Finally, the obtained result is compared with other existing approaches, confirming the proposed framework&#39;s strength and steadiness. The identified challenges were systemic, pedagogical, and psychological challenges, while the analysis results found that the pedagogical challenges, including the lack of experience and student engagement, were the main essential challenges to adapting online education in higher education institutions during the COVID-19 outbreak.},
  archive      = {J_AIR},
  author       = {Saraji, Mahyar Kamali and Mardani, Abbas and Köppen, Mario and Mishra, Arunodaya Raj and Rani, Pratibha},
  doi          = {10.1007/s10462-021-10029-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {181-206},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An extended hesitant fuzzy set using SWARA-MULTIMOORA approach to adapt online education for the control of the pandemic spread of COVID-19 in higher education institutions},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ocular recognition databases and competitions: A survey.
<em>AIR</em>, <em>55</em>(1), 129–180. (<a
href="https://doi.org/10.1007/s10462-021-10028-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of the iris and periocular region as biometric traits has been extensively investigated, mainly due to the singularity of the iris features and the use of the periocular region when the image resolution is not sufficient to extract iris information. In addition to providing information about an individual’s identity, features extracted from these traits can also be explored to obtain other information such as the individual’s gender, the influence of drug use, the use of contact lenses, spoofing, among others. This work presents a survey of the databases created for ocular recognition, detailing their protocols and how their images were acquired. We also describe and discuss the most popular ocular recognition competitions (contests), highlighting the submitted algorithms that achieved the best results using only iris trait and also fusing iris and periocular region information. Finally, we describe some relevant works applying deep learning techniques to ocular recognition and point out new challenges and future directions. Considering that there are a large number of ocular databases, and each one is usually designed for a specific problem, we believe this survey can provide a broad overview of the challenges in ocular biometrics.},
  archive      = {J_AIR},
  author       = {Zanlorensi, Luiz A. and Laroca, Rayson and Luz, Eduardo and Britto, Alceu S. and Oliveira, Luiz S. and Menotti, David},
  doi          = {10.1007/s10462-021-10028-w},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {129-180},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Ocular recognition databases and competitions: A survey},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised learning in images and audio to produce neural
receptive fields: A primer and accessible notebook. <em>AIR</em>,
<em>55</em>(1), 111–128. (<a
href="https://doi.org/10.1007/s10462-021-10047-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensory processing relies on efficient computation driven by a combination of low-level unsupervised, statistical structural learning, and high-level task-dependent learning. In the earliest stages of sensory processing, sparse and independent coding strategies are capable of modeling neural processing using the same coding strategy with only a change in the input (e.g., grayscale images, color images, and audio). We present a consolidated review of Independent Component Analysis (ICA) as an efficient neural coding scheme with the ability to model early visual and auditory neural processing. We created a self-contained, accessible Jupyter notebook using Python to demonstrate the efficient coding principle for different modalities following a consistent five-step strategy. For each modality, derived receptive field models from natural and non-natural inputs are contrasted, demonstrating how neural codes are not produced when the inputs sufficiently deviate from those animals were evolved to process. Additionally, the demonstration shows that ICA produces more neurally-appropriate receptive field models than those based on common compression strategies, such as Principal Component Analysis. The five-step strategy not only produces neural-like models but also promotes reuse of code to emphasize the input-agnostic nature where each modality can be modeled with only a change in inputs. This notebook can be used to readily observe the links between unsupervised machine learning strategies and early sensory neuroscience, improving our understanding of flexible data-driven neural development in nature and future applications.},
  archive      = {J_AIR},
  author       = {Urs, Namratha and Behpour, Sahar and Georgaras, Angie and Albert, Mark V.},
  doi          = {10.1007/s10462-021-10047-7},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {111-128},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Unsupervised learning in images and audio to produce neural receptive fields: A primer and accessible notebook},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on evolutionary computation for complex continuous
optimization. <em>AIR</em>, <em>55</em>(1), 59–110. (<a
href="https://doi.org/10.1007/s10462-021-10042-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex continuous optimization problems widely exist nowadays due to the fast development of the economy and society. Moreover, the technologies like Internet of things, cloud computing, and big data also make optimization problems with more challenges including Many-dimensions, Many-changes, Many-optima, Many-constraints, and Many-costs. We term these as 5-M challenges that exist in large-scale optimization problems, dynamic optimization problems, multi-modal optimization problems, multi-objective optimization problems, many-objective optimization problems, constrained optimization problems, and expensive optimization problems in practical applications. The evolutionary computation (EC) algorithms are a kind of promising global optimization tools that have not only been widely applied for solving traditional optimization problems, but also have emerged booming research for solving the above-mentioned complex continuous optimization problems in recent years. In order to show how EC algorithms are promising and efficient in dealing with the 5-M complex challenges, this paper presents a comprehensive survey by proposing a novel taxonomy according to the function of the approaches, including reducing problem difficulty, increasing algorithm diversity, accelerating convergence speed, reducing running time, and extending application field. Moreover, some future research directions on using EC algorithms to solve complex continuous optimization problems are proposed and discussed. We believe that such a survey can draw attention, raise discussions, and inspire new ideas of EC research into complex continuous optimization problems and real-world applications.},
  archive      = {J_AIR},
  author       = {Zhan, Zhi-Hui and Shi, Lin and Tan, Kay Chen and Zhang, Jun},
  doi          = {10.1007/s10462-021-10042-y},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {59-110},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on evolutionary computation for complex continuous optimization},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sparse online kernelized actor-critic learning in
reproducing kernel hilbert space. <em>AIR</em>, <em>55</em>(1), 23–58.
(<a href="https://doi.org/10.1007/s10462-021-10045-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a novel non-parametric online actor-critic reinforcement learning (RL) algorithm to solve optimal regulation problems for a class of continuous-time affine nonlinear dynamical systems. To deal with the value function approximation (VFA) with inherent nonlinear and unknown structure, a reproducing kernel Hilbert space (RKHS)-based kernelized method is designed through online sparsification, where the dictionary size is fixed and consists of updated elements. In addition, the linear independence check condition, i.e., an online criteria, is designed to determine whether the online data should be inserted into the dictionary. The RHKS-based kernelized VFA has a variable structure in accordance with the online data collection, which is different from classical parametric VFA methods with a fixed structure. Furthermore, we develop a sparse online kernelized actor-critic learning RL method to learn the unknown optimal value function and the optimal control policy in an adaptive fashion. The convergence of the presented kernelized actor-critic learning method to the optimum is provided. The boundedness of the closed-loop signals during the online learning phase can be guaranteed. Finally, a simulation example is conducted to demonstrate the effectiveness of the presented kernelized actor-critic learning algorithm.},
  archive      = {J_AIR},
  author       = {Yang, Yongliang and Zhu, Hufei and Zhang, Qichao and Zhao, Bo and Li, Zhenning and Wunsch, Donald C.},
  doi          = {10.1007/s10462-021-10045-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {23-58},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Sparse online kernelized actor-critic learning in reproducing kernel hilbert space},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The intelligent critic framework for advanced optimal
control. <em>AIR</em>, <em>55</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s10462-021-10118-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The idea of optimization can be regarded as an important basis of many disciplines and hence is extremely useful for a large number of research fields, particularly for artificial-intelligence-based advanced control design. Due to the difficulty of solving optimal control problems for general nonlinear systems, it is necessary to establish a kind of novel learning strategies with intelligent components. Besides, the rapid development of computer and networked techniques promotes the research on optimal control within discrete-time domain. In this paper, the bases, the derivation, and recent progresses of critic intelligence for discrete-time advanced optimal control design are presented with an emphasis on the iterative framework. Among them, the so-called critic intelligence methodology is highlighted, which integrates learning approximators and the reinforcement formulation.},
  archive      = {J_AIR},
  author       = {Wang, Ding and Ha, Mingming and Zhao, Mingming},
  doi          = {10.1007/s10462-021-10118-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Artif. Intell. Rev.},
  title        = {The intelligent critic framework for advanced optimal control},
  volume       = {55},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
