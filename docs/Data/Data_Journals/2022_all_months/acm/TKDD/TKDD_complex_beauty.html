<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TKDD_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tkdd---68">TKDD - 68</h2>
<ul>
<li><details>
<summary>
(2022). Urban knowledge graph aided mobile user profiling.
<em>TKDD</em>, <em>18</em>(1), 1–30. (<a
href="https://doi.org/10.1145/3596604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the explosive growth of personalized web applications and the rapid development of artificial intelligence technology have flourished the recent research on mobile user profiling, i.e., inferring the user profile from mobile behavioral data. Particularly, existing studies mainly follow the data-driven paradigm to develop feature engineering and representation learning on such data, which however suffer from the robustness issue, i.e., generalizing poorly across datasets and profiles without considering semantic knowledge therein. In comparison, the rising knowledge-driven paradigm built upon the knowledge graph (KG) offers a potential solution to mitigate such weakness. Therefore, in this article, we propose a Knowledge Graph aided framework for Mobile User Profiling (KG-MUP). Specifically, to distil semantic knowledge among data, we firstly construct an urban knowledge graph (UrbanKG) with domain entities like users, regions, point of interests (POIs), and so on. identified, as well as semantic relations for home, workplace, spatiality, and so on. extracted. Moreover, we leverage tensor decomposition and graph neural network to obtain knowledgeable user representations from UrbanKG. In addition, we introduce several customized features to quantify individual mobility characteristics for mobile user profiling. Extensive experiments on three real-world mobility datasets demonstrate that KG-MUP achieves state-of-the-art performance on user profile inference tasks. Moreover, further results also reveal the importance of various semantic knowledge to user profile inference, which provides meaningful insights on user modeling with mobile behavioral data.},
  archive      = {J_TKDD},
  doi          = {10.1145/3596604},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {1},
  pages        = {1-30},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Urban knowledge graph aided mobile user profiling},
  volume       = {18},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transfer learning across graph convolutional networks:
Methods, theory, and applications. <em>TKDD</em>, <em>18</em>(1), 1–23.
(<a href="https://doi.org/10.1145/3617376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks have been widely used for learning representations of nodes for many downstream tasks on graph data. Existing models were designed for the nodes on a single graph, which would not be able to utilize information across multiple graphs. The real world does have multiple graphs where the nodes are often partially aligned . For examples, knowledge graphs share a number of named entities though they may have different relation schema; collaboration networks on publications and awarded projects share some researcher nodes who are authors and investigators, respectively; people use multiple web services, shopping, tweeting, rating movies, and some may register the same e-mail account across the platforms. In this article, we propose partially aligned graph convolutional networks to learn node representations across the models. We provide multiple methods such as model sharing, regularization, and alignment reconstruction, as well as theoretical analysis to positively transfer knowledge across the set of partially aligned nodes. Extensive experiments on real-world knowledge graphs, collaboration networks, and bipartite rating graphs show the superior performance of our proposed methods on relation classification, link prediction, and item recommendation.},
  archive      = {J_TKDD},
  doi          = {10.1145/3617376},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {1},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Transfer learning across graph convolutional networks: Methods, theory, and applications},
  volume       = {18},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive neighbor graph aggregated graph attention network
for heterogeneous graph embedding. <em>TKDD</em>, <em>18</em>(1), 1–21.
(<a href="https://doi.org/10.1145/3616377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph attention network can generate effective feature embedding by specifying different weights to different nodes. The key of the research on heterogeneous graph embedding is the way to combine its rich structural information with semantic relations to aggregate the neighborhood information. Most of the existing heterogeneous graph representation learning methods guide the selection of neighbors by defining various meta-paths on heterogeneous graphs. However, these models only consider the information contained in the nodes under different paths and ignore the potential semantic relationships of nodes in different neighbor graph structures, which leads to the underutilization of graph structure information. In this article, we propose a novel adaptive framework named Neighbor Graph Aggregated Graph Attention Network (NGGAN) to fully exploit graph topological details in heterogeneous graph, and aggregates their information to obtain an effective embedding. The key idea is to use different levels of sampling methods to define neighborhood, and use neighbor graphs to represent the complex structural interaction between nodes. In this way, the high-order relationship between nodes and the latent semantics of neighbor graphs can be fully explored. Afterward, a hierarchical attention mechanism is applied to adaptively learn the importance of different objects, including node information, path information, and neighbor graph information. Multiple downstream tasks are performed on four real-world heterogeneous graph datasets, and the experimental results demonstrate the effectiveness of NGGAN.},
  archive      = {J_TKDD},
  doi          = {10.1145/3616377},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {1},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Adaptive neighbor graph aggregated graph attention network for heterogeneous graph embedding},
  volume       = {18},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning-based short-term rainfall prediction from
sky data. <em>TKDD</em>, <em>16</em>(6), 1–18. (<a
href="https://doi.org/10.1145/3502731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To predict rainfall, our proposed model architecture combines the Convolutional Neural Network (CNN), which uses the ResNet-152 pre-training model, with the Recurrent Neural Network (RNN), which uses the Long Short-term Memory Network (LSTM) layer, for model training. By encoding the cloud images through CNN, we extract the image feature vectors in the training process and train the vectors and meteorological data as the input of RNN. After training, the accuracy of the prediction model can reach up to 82%. The result has proven not only the outperformance of our proposed rainfall prediction method in terms of cost and prediction time, but also its accuracy and feasibility compared with general prediction methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3502731},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Machine learning-based short-term rainfall prediction from sky data},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incremental feature spaces learning with label scarcity.
<em>TKDD</em>, <em>16</em>(6), 1–26. (<a
href="https://doi.org/10.1145/3516368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, learning and mining from data streams with incremental feature spaces have attracted extensive attention, where data may dynamically expand over time in both volume and feature dimensions. Existing approaches usually assume that the incoming instances can always receive true labels. However, in many real-world applications, e.g., environment monitoring, acquiring the true labels is costly due to the need of human effort in annotating the data. To tackle this problem, we propose a novel incremental Feature spaces Learning with Label Scarcity (FLLS) algorithm, together with its two variants. When data streams arrive with augmented features, we first leverage the margin-based online active learning to select valuable instances to be labeled and thus build superior predictive models with minimal supervision. After receiving the labels, we combine the online passive-aggressive update rule and margin-maximum principle to jointly update the dynamic classifier in the shared and augmented feature space. Finally, we use the projected truncation technique to build a sparse but efficient model. We theoretically analyze the error bounds of FLLS and its two variants. Also, we conduct experiments on synthetic data and real-world applications to further validate the effectiveness of our proposed algorithms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3516368},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Incremental feature spaces learning with label scarcity},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Segment-wise time-varying dynamic bayesian network with
graph regularization. <em>TKDD</em>, <em>16</em>(6), 1–23. (<a
href="https://doi.org/10.1145/3522589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-varying dynamic Bayesian network (TVDBN) is essential for describing time-evolving directed conditional dependence structures in complex multivariate systems. In this article, we construct a TVDBN model, together with a score-based method for its structure learning. The model adopts a vector autoregressive (VAR) model to describe inter-slice and intra-slice relations between variables. By allowing VAR parameters to change segment-wisely over time, the time-varying dynamics of the network structure can be described. Furthermore, considering some external information can provide additional similarity information of variables. Graph Laplacian is further imposed to regularize similar nodes to have similar network structures. The regularized maximum a posterior estimation in the Bayesian inference framework is used as a score function for TVDBN structure evaluation, and the alternating direction method of multipliers (ADMM) with L-BFGS-B algorithm is used for optimal structure learning. Thorough simulation studies and a real case study are carried out to verify our proposed method’s efficacy and efficiency.},
  archive      = {J_TKDD},
  doi          = {10.1145/3522589},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Segment-wise time-varying dynamic bayesian network with graph regularization},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GrOD: Deep learning with gradients orthogonal decomposition
for knowledge transfer, distillation, and adversarial training.
<em>TKDD</em>, <em>16</em>(6), 1–25. (<a
href="https://doi.org/10.1145/3530836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regularization that incorporates the linear combination of empirical loss and explicit regularization terms as the loss function has been frequently used for many machine learning tasks. The explicit regularization term is designed in different types, depending on its applications. While regularized learning often boost the performance with higher accuracy and faster convergence, the regularization would sometimes hurt the empirical loss minimization and lead to poor performance. To deal with such issues in this work, we propose a novel strategy, namely Gr adients O rthogonal D ecomposition ( GrOD ), that improves the training procedure of regularized deep learning. Instead of linearly combining gradients of the two terms, GrOD re-estimates a new direction for iteration that does not hurt the empirical loss minimization while preserving the regularization affects, through orthogonal decomposition. We have performed extensive experiments to use GrOD improving the commonly used algorithms of transfer learning [ 2 ], knowledge distillation [ 3 ], and adversarial learning [ 4 ]. The experiment results based on large datasets, including Caltech 256 [ 5 ], MIT indoor 67 [ 6 ], CIFAR-10 [ 7 ], and ImageNet [ 8 ], show significant improvement made by GrOD for all three algorithms in all cases.},
  archive      = {J_TKDD},
  doi          = {10.1145/3530836},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {GrOD: Deep learning with gradients orthogonal decomposition for knowledge transfer, distillation, and adversarial training},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The distance function optimization for the near
neighbors-based classifiers. <em>TKDD</em>, <em>16</em>(6), 1–21. (<a
href="https://doi.org/10.1145/3434769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the analysis of conditions for a good distance function we found four rules that should be fulfilled. Then, we introduce two new distance functions, a metric and a pseudometric one. We have tested how they fit for distance-based classifiers, especially for the IINC classifier. We rank distance functions according to several criteria and tests. Rankings depend not only on criteria or nature of the statistical test, but also whether it takes into account different difficulties of tasks or whether it considers all tasks as equally difficult. We have found that the new distance functions introduced belong among the four or five best out of 23 distance functions. We have tested them on 24 different tasks, using the mean, the median, the Friedman aligned test, and the Quade test. Our results show that a suitable distance function can improve behavior of distance-based classification rules.},
  archive      = {J_TKDD},
  doi          = {10.1145/3434769},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {The distance function optimization for the near neighbors-based classifiers},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective learning to overcome catastrophic forgetting
in time-series applications. <em>TKDD</em>, <em>16</em>(6), 1–20. (<a
href="https://doi.org/10.1145/3502728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One key objective of artificial intelligence involves the continuous adaptation of machine learning models to new tasks. This branch of continual learning is also referred to as lifelong learning (LL), where a major challenge is to minimize catastrophic forgetting, or forgetting previously learned tasks. While previous work on catastrophic forgetting has been focused on vision problems; this work targets time-series data. In addition to choosing an architecture appropriate for time-series sequences, our work addresses limitations in previous work, including the handling of distribution shifts in class labels. We present multi-objective learning with three loss functions to minimize catastrophic forgetting, prediction error, and errors in generalizing across label shifts, simultaneously. We build a multi-task autoencoder network with a hierarchical convolutional recurrent architecture. The proposed method is capable of learning multiple time-series tasks simultaneously. For cases where the model needs to learn multiple new tasks, we propose sequential learning, starting with tasks that have the best individual performances. This solution was evaluated on four benchmark human activity recognition datasets collected from mobile sensing devices. A wide set of baseline comparisons is performed, and an ablation analysis is run to evaluate the impact of the different losses in the proposed multi-objective method. The results demonstrate an up to 4% performance improvement in catastrophic forgetting compared to the use of loss functions in state-of-the-art solutions while demonstrating minimal losses compared to upper bound methods of traditional fine-tuning (FT) and multi-task learning (MTL).},
  archive      = {J_TKDD},
  doi          = {10.1145/3502728},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Multi-objective learning to overcome catastrophic forgetting in time-series applications},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph-enhanced spatial-temporal network for next POI
recommendation. <em>TKDD</em>, <em>16</em>(6), 1–21. (<a
href="https://doi.org/10.1145/3513092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of next Point-of-Interest (POI) recommendation aims at recommending a list of POIs for a user to visit at the next timestamp based on his/her previous interactions, which is valuable for both location-based service providers and users. Recent state-of-the-art studies mainly employ recurrent neural network (RNN) based methods to model user check-in behaviors according to user’s historical check-in sequences. However, most of the existing RNN-based methods merely capture geographical influences depending on physical distance or successive relation among POIs. They are insufficient to capture the high-order complex geographical influences among POI networks, which are essential for estimating user preferences. To address this limitation, we propose a novel Graph-based Spatial Dependency modeling (GSD) module, which focuses on explicitly modeling complex geographical influences by leveraging graph embedding. GSD captures two types of geographical influences, i.e., distance-based and transition-based influences from designed POI semantic graphs. Additionally, we propose a novel Graph-enhanced Spatial-Temporal network (GSTN), which incorporates user spatial and temporal dependencies for next POI recommendation. Specifically, GSTN consists of a Long Short-Term Memory (LSTM) network for user-specific temporal dependencies modeling and GSD for user spatial dependencies learning. Finally, we evaluate the proposed model using three real-world datasets. Extensive experiments demonstrate the effectiveness of GSD in capturing various geographical influences and the improvement of GSTN over state-of-the-art methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3513092},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Graph-enhanced spatial-temporal network for next POI recommendation},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-supervised transformer for sparse and irregularly
sampled multivariate clinical time-series. <em>TKDD</em>,
<em>16</em>(6), 1–17. (<a
href="https://doi.org/10.1145/3516367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time-series data are frequently observed in critical care settings and are typically characterized by sparsity (missing information) and irregular time intervals. Existing approaches for learning representations in this domain handle these challenges by either aggregation or imputation of values, which in-turn suppresses the fine-grained information and adds undesirable noise/overhead into the machine learning model. To tackle this problem, we propose a S elf-supervised Tra nsformer for T ime- S eries (STraTS) model, which overcomes these pitfalls by treating time-series as a set of observation triplets instead of using the standard dense matrix representation. It employs a novel Continuous Value Embedding technique to encode continuous time and variable values without the need for discretization. It is composed of a Transformer component with multi-head attention layers, which enable it to learn contextual triplet embeddings while avoiding the problems of recurrence and vanishing gradients that occur in recurrent architectures. In addition, to tackle the problem of limited availability of labeled data (which is typically observed in many healthcare applications), STraTS utilizes self-supervision by leveraging unlabeled data to learn better representations by using time-series forecasting as an auxiliary proxy task. Experiments on real-world multivariate clinical time-series benchmark datasets demonstrate that STraTS has better prediction performance than state-of-the-art methods for mortality prediction, especially when labeled data is limited. Finally, we also present an interpretable version of STraTS, which can identify important measurements in the time-series data. Our data preprocessing and model implementation codes are available at https://github.com/sindhura97/STraTS .},
  archive      = {J_TKDD},
  doi          = {10.1145/3516367},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-17},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Self-supervised transformer for sparse and irregularly sampled multivariate clinical time-series},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving bandit learning via heterogeneous information
networks: Algorithms and applications. <em>TKDD</em>, <em>16</em>(6),
1–25. (<a href="https://doi.org/10.1145/3522590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contextual bandit serves as an invaluable tool to balance the exploration vs. exploitation tradeoff in various applications such as online recommendation. In many applications, heterogeneous information networks (HINs) provide rich side information for contextual bandits, such as different types of attributes and relationships among users and items. In this article, we propose the first HIN-assisted contextual bandit framework, which utilizes a given HIN to assist contextual bandit learning. The proposed framework uses meta-paths in HIN to extract rich relations among users and items for the contextual bandit. The main challenge is how to leverage these relations, since users’ preference over items, the target of our online learning, are closely related to users’ preference over meta-paths. However, it is unknown which meta-path a user prefers more. Thus, both preferences are needed to be learned in an online fashion with exploration vs. exploitation tradeoff balanced. We propose the HIN-assisted upper confidence bound (HUCB) algorithm to address such a challenge. For each meta-path, the HUCB algorithm employs an independent base bandit algorithm to handle online item recommendations by leveraging the relationship captured in this meta-path. A bandit master is then employed to learn users’ preference over meta-paths to dynamically combine base bandit algorithms with a balance of exploration vs. exploitation tradeoff. We theoretically prove that the HUCB algorithm can achieve similar performance compared with the optimal algorithm where each user is served according to his true preference over meta-paths (assuming the optimal algorithm knows the preference). Moreover, we prove that the HUCB algorithm benefits from leveraging HIN in achieving a smaller regret upper bound than the baseline algorithm without leveraging HIN. Experimental results on a synthetic dataset, as well as real datasets from LastFM and Yelp demonstrate the fast learning speed of the HUCB algorithm.},
  archive      = {J_TKDD},
  doi          = {10.1145/3522590},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Improving bandit learning via heterogeneous information networks: Algorithms and applications},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward quality of information aware distributed machine
learning. <em>TKDD</em>, <em>16</em>(6), 1–28. (<a
href="https://doi.org/10.1145/3522591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, data are usually distributed across numerous connected computing and storage units (i.e., nodes or workers). Under such an environment, many machine learning problems can be reformulated as a consensus optimization problem, which consists of one objective and constraint terms splitting into N parts (each corresponds to a node). Such a problem can be solved efficiently in a distributed manner via Alternating Direction Method of Multipliers ( ADMM ). However, existing consensus optimization frameworks assume that every node has the same quality of information (QoI) , i.e., the data from all the nodes are equally informative for the estimation of global model parameters. As a consequence, they may lead to inaccurate estimates in the presence of nodes with low QoI. To overcome this challenge, in this article, we propose a novel consensus optimization framework for distributed machine-learning that incorporates the crucial metric, QoI. Theoretically, we prove that the convergence rate of the proposed framework is linear to the number of iterations, but has a tighter upper bound compared with ADMM . Experimentally, we show that the proposed framework is more efficient and effective than existing ADMM -based solutions on both synthetic and real-world datasets due to its faster convergence rate and higher accuracy.},
  archive      = {J_TKDD},
  doi          = {10.1145/3522591},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Toward quality of information aware distributed machine learning},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ARIS: A noise insensitive data pre-processing scheme for
data reduction using influence space. <em>TKDD</em>, <em>16</em>(6),
1–39. (<a href="https://doi.org/10.1145/3522592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extensive growth of data quantity has posed many challenges to data analysis and retrieval. Noise and redundancy are typical representatives of the above-mentioned challenges, which may reduce the reliability of analysis and retrieval results and increase storage and computing overhead. To solve the above problems, a two-stage data pre-processing framework for noise identification and data reduction, called ARIS, is proposed in this article. The first stage identifies and removes noises by the following steps: First, the influence space (IS) is introduced to elaborate data distribution. Second, a ranking factor (RF) is defined to describe the possibility that the points are regarded as noises, then, the definition of noise is given based on RF. Third, a clean dataset (CD) is obtained by removing noise from the original dataset. The second stage learns representative data and realizes data reduction. In this process, CD is divided into multiple small regions by IS. Then the reduced dataset is formed by collecting the representations of each region. The performance of ARIS is verified by experiments on artificial and real datasets. Experimental results show that ARIS effectively weakens the impact of noise and reduces the amount of data and significantly improves the accuracy of data analysis within a reasonable time cost range.},
  archive      = {J_TKDD},
  doi          = {10.1145/3522592},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-39},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {ARIS: A noise insensitive data pre-processing scheme for data reduction using influence space},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nested named entity recognition: A survey. <em>TKDD</em>,
<em>16</em>(6), 1–29. (<a
href="https://doi.org/10.1145/3522593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of text mining, many studies observe that text generally contains a variety of implicit information, and it is important to develop techniques for extracting such information. Named Entity Recognition (NER), the first step of information extraction, mainly identifies names of persons, locations, and organizations in text. Although existing neural-based NER approaches achieve great success in many language domains, most of them normally ignore the nested nature of named entities. Recently, diverse studies focus on the nested NER problem and yield state-of-the-art performance. This survey attempts to provide a comprehensive review on existing approaches for nested NER from the perspectives of the model architecture and the model property, which may help readers have a better understanding of the current research status and ideas. In this survey, we first introduce the background of nested NER, especially the differences between nested NER and traditional (i.e., flat) NER. We then review the existing nested NER approaches from 2002 to 2020 and mainly classify them into five categories according to the model architecture, including early rule-based, layered-based, region-based, hypergraph-based, and transition-based approaches. We also explore in greater depth the impact of key properties unique to nested NER approaches from the model property perspective, namely entity dependency, stage framework, error propagation, and tag scheme. Finally, we summarize the open challenges and point out a few possible future directions in this area. This survey would be useful for three kinds of readers: (i) Newcomers in the field who want to learn about NER, especially for nested NER. (ii) Researchers who want to clarify the relationship and advantages between flat NER and nested NER. (iii) Practitioners who just need to determine which NER technique (i.e., nested or not) works best in their applications.},
  archive      = {J_TKDD},
  doi          = {10.1145/3522593},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Nested named entity recognition: A survey},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Factorization of binary matrices: Rank relations, uniqueness
and model selection of boolean decomposition. <em>TKDD</em>,
<em>16</em>(6), 1–24. (<a
href="https://doi.org/10.1145/3522594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of binary matrices are numerous. Representing a matrix as a mixture of a small collection of latent vectors via low-rank decomposition is often seen as an advantageous method to interpret and analyze data. In this work, we examine the factorizations of binary matrices using standard arithmetic (real and nonnegative) and logical operations (Boolean and ℤ 2 ). We examine the relationships between the different ranks, and discuss when factorization is unique. In particular, we characterize when a Boolean factorization X = W ∧ H has a unique W , a unique H (for a fixed W ), and when both W and H are unique, given a rank constraint. We introduce a method for robust Boolean model selection, called BMF k , and show on numerical examples that BMF k not only accurately determines the correct number of Boolean latent features but reconstruct the pre-determined factors accurately.},
  archive      = {J_TKDD},
  doi          = {10.1145/3522594},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Factorization of binary matrices: Rank relations, uniqueness and model selection of boolean decomposition},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computer science diagram understanding with topology
parsing. <em>TKDD</em>, <em>16</em>(6), 1–20. (<a
href="https://doi.org/10.1145/3522689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagram is a special form of visual expression for representing complex concepts, logic, and knowledge, which widely appears in educational scenes such as textbooks, blogs, and encyclopedias. Current research on diagrams preliminarily focuses on natural disciplines such as Biology and Geography, whose expressions are still similar to natural images. In this article, we construct the first novel geometric type of diagrams dataset in Computer Science field, which has more abstract expressions and complex logical relations. The dataset has exhaustive annotations of objects and relations for about 1,300 diagrams and 3,500 question-answer pairs. We introduce the tasks of diagram classification (DC) and diagram question answering (DQA) based on the new dataset, and propose the Diagram Paring Net (DPN) that focuses on analyzing the topological structure and text information of diagrams. We use DPN-based models to solve DC and DQA tasks, and compare the performances to well-known natural images classification models and visual question answering models. Our experiments show the effectiveness of the proposed DPN-based models on diagram understanding tasks, also indicate that our dataset is more complex compared to previous natural image understanding datasets. The presented dataset opens new challenges for research in diagram understanding, and the DPN method provides a novel perspective for studying such data. Our dataset can be available from https://github.com/WayneWong97/CSDia.},
  archive      = {J_TKDD},
  doi          = {10.1145/3522689},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Computer science diagram understanding with topology parsing},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dual-MGAN: An efficient approach for semi-supervised outlier
detection with few identified anomalies. <em>TKDD</em>, <em>16</em>(6),
1–30. (<a href="https://doi.org/10.1145/3522690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is an important task in data mining, and many technologies for it have been explored in various applications. However, owing to the default assumption that outliers are not concentrated, unsupervised outlier detection may not correctly identify group anomalies with higher levels of density. Although high detection rates and optimal parameters can usually be achieved by using supervised outlier detection, obtaining a sufficient number of correct labels is a time-consuming task. To solve these problems, we focus on semi-supervised outlier detection with few identified anomalies and a large amount of unlabeled data. The task of semi-supervised outlier detection is first decomposed into the detection of discrete anomalies and that of partially identified group anomalies, and a distribution construction sub-module and a data augmentation sub-module are then proposed to identify them, respectively. In this way, the dual multiple generative adversarial networks (Dual-MGAN) that combine the two sub-modules can identify discrete as well as partially identified group anomalies. In addition, in view of the difficulty of determining the stop node of training, two evaluation indicators are introduced to evaluate the training status of the sub-GANs. Extensive experiments on synthetic and real-world data show that the proposed Dual-MGAN can significantly improve the accuracy of outlier detection, and the proposed evaluation indicators can reflect the training status of the sub-GANs.},
  archive      = {J_TKDD},
  doi          = {10.1145/3522690},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-30},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Dual-MGAN: An efficient approach for semi-supervised outlier detection with few identified anomalies},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finding key structures in MMORPG graph with hierarchical
graph summarization. <em>TKDD</em>, <em>16</em>(6), 1–21. (<a
href="https://doi.org/10.1145/3522691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {What are the key structures existing in a large real-world MMORPG (Massively Multiplayer Online Role-Playing Game) graph? How can we compactly summarize an MMORPG graph with hierarchical node labels, considering substructures at different levels of hierarchy? Recent MMORPGs generate complex interactions between entities inducing a heterogeneous graph where each entity has hierarchical labels. Succinctly summarizing a heterogeneous MMORPG graph is crucial to better understand its structure; however it is a challenging task since it needs to handle complex interactions and hierarchical labels efficiently. Although there exist few methods to summarize a large-scale graph, they do not deal with heterogeneous graphs with hierarchical node labels.We propose GSHL , a novel method that summarizes a heterogeneous graph with hierarchical labels. We formulate the encoding cost of hierarchical labels using MDL (Minimum Description Length). GSHL exploits the formulation to identify and segment subgraphs, and discovers compact and consistent structures in the graph. Experiments on a large real-world MMORPG graph with multi-million edges show that GSHL is a useful and scalable tool for summarizing the graph, finding important structures in the graph, and finding similar users.},
  archive      = {J_TKDD},
  doi          = {10.1145/3522691},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Finding key structures in MMORPG graph with hierarchical graph summarization},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting a person’s next activity region with a dynamic
region-relation-aware graph neural network. <em>TKDD</em>,
<em>16</em>(6), 1–23. (<a
href="https://doi.org/10.1145/3529091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The understanding of people’s inter-regional mobility behaviors, such as predicting the next activity region (AR) or uncovering the intentions for regional mobility, is of great value to public administration or business interests. While there are numerous studies on human mobility, these studies are mainly from a statistical view or study movement behaviors within a region. The work on individual-level inter-regional mobility behavior is limited. To this end, in this article, we propose a dynamic region-relation-aware graph neural network (DRRGNN) for exploring individual mobility behaviors over ARs. Specifically, we aim at developing models that can answer three questions: (1) Which regions are the ARs? (2) Which region will be the next AR, and (3) Why do people make this regional mobility? To achieve these tasks, we first propose a method to find out people’s ARs. Then, the designed model integrates a dynamic graph convolution network (DGCN) and a recurrent neural network (RNN) to depict the evolution of relations between ARs and mine the regional mobility patterns. In the learning process, the model further considers peoples’ profiles and visited point-of-interest (POIs). Finally, extensive experiments on two real-world datasets show that the proposed model can significantly improve accuracy for both the next AR prediction and mobility intention prediction.},
  archive      = {J_TKDD},
  doi          = {10.1145/3529091},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Predicting a person’s next activity region with a dynamic region-relation-aware graph neural network},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Synthesis of longitudinal human location sequences:
Balancing utility and privacy. <em>TKDD</em>, <em>16</em>(6), 1–27. (<a
href="https://doi.org/10.1145/3529260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People’s location data are continuously tracked from various devices and sensors, enabling an ongoing analysis of sensitive information that can violate people’s privacy and reveal confidential information. Synthetic data have been used to generate representative location sequences yet to maintain the users’ privacy. Nonetheless, the privacy-accuracy tradeoff between these two measures has not been addressed systematically. In this article, we analyze the use of different synthetic data generation models for long location sequences, including extended short-term memory networks (LSTMs), Markov Chains (MC), and variable-order Markov models (VMMs). We employ different performance measures, such as data similarity and privacy, and discuss the inherent tradeoff. Furthermore, we introduce other measurements to quantify each of these measures. Based on the anonymous data of 300 thousand cellular-phone users, our work offers a road map for developing policies for synthetic data generation processes. We propose a framework for building data generation models and evaluating their effectiveness regarding those accuracy and privacy measures.},
  archive      = {J_TKDD},
  doi          = {10.1145/3529260},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Synthesis of longitudinal human location sequences: Balancing utility and privacy},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalized euclidean measure to estimate distances on
multilayer networks. <em>TKDD</em>, <em>16</em>(6), 1–22. (<a
href="https://doi.org/10.1145/3529396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the distance covered by a spreading event on a network can lead to a better understanding of epidemics, economic growth, and human behavior. There are many methods solving this problem—which has been called Node Vector Distance (NVD)—for single layer networks. However, many phenomena are better represented by multilayer networks: networks in which nodes can connect in qualitatively different ways. In this article, we extend the literature by proposing an algorithm solving NVD for multilayer networks. We do so by adapting the Mahalanobis distance, incorporating the graph’s topology via the pseudoinverse of its Laplacian. Since this is a proper generalization of the Euclidean distance in a complex space defined by the topology of the graph, and that it works on multilayer networks, we call our measure the Multi Layer Generalized Euclidean (MLGE). In our experiments, we show that MLGE is intuitive, theoretically simpler than the alternatives, performs well in recovering infection parameters, and it is useful in specific case studies. MLGE requires solving a special case of the effective resistance on the graph, which has a high time complexity. However, this needs to be done only once per network. In the experiments, we show that MLGE can cache its most computationally heavy parts, allowing it to solve hundreds of NVD problems on the same network with little to no additional runtime. MLGE is provided as a free open source tool, along with the data and the code necessary to replicate our results.},
  archive      = {J_TKDD},
  doi          = {10.1145/3529396},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Generalized euclidean measure to estimate distances on multilayer networks},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spectral ranking regression. <em>TKDD</em>, <em>16</em>(6),
1–38. (<a href="https://doi.org/10.1145/3530693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of ranking regression, in which a dataset of rankings is used to learn Plackett–Luce scores as functions of sample features. We propose a novel spectral algorithm to accelerate learning in ranking regression. Our main technical contribution is to show that the Plackett–Luce negative log-likelihood augmented with a proximal penalty has stationary points that satisfy the balance equations of a Markov Chain. This allows us to tackle the ranking regression problem via an efficient spectral algorithm by using the Alternating Directions Method of Multipliers (ADMM). ADMM separates the learning of scores and model parameters, and in turn, enables us to devise fast spectral algorithms for ranking regression via both shallow and deep neural network (DNN) models. For shallow models, our algorithms are up to 579 times faster than the Newton’s method. For DNN models, we extend the standard ADMM via a Kullback–Leibler proximal penalty and show that this is still amenable to fast inference via a spectral approach. Compared to a state-of-the-art siamese network, our resulting algorithms are up to 175 times faster and attain better predictions by up to 26% Top-1 Accuracy and 6% Kendall-Tau correlation over five real-life ranking datasets.},
  archive      = {J_TKDD},
  doi          = {10.1145/3530693},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-38},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Spectral ranking regression},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Profile decomposition based hybrid transfer learning for
cold-start data anomaly detection. <em>TKDD</em>, <em>16</em>(6), 1–28.
(<a href="https://doi.org/10.1145/3530990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is an essential task for quality management in smart manufacturing. An accurate data-driven detection method usually needs enough data and labels. However, in practice, there commonly exist newly set-up processes in manufacturing, and they only have quite limited data available for analysis. Borrowing the name from the recommender system, we call this process a cold-start process. The sparsity of anomaly, the deviation of the profile, and noise aggravate the detection difficulty. Transfer learning could help to detect anomalies for cold-start processes by transferring the knowledge from more experienced processes to the new processes. However, the existing transfer learning and multi-task learning frameworks are established on task- or domain-level relatedness. We observe instead, within a domain, some components (background and anomaly) share more commonality, others (profile deviation and noise) not. To this end, we propose a more delicate component-level transfer learning scheme, i.e., decomposition-based hybrid transfer learning ( DHTL ): It first decomposes a domain (e.g., a data source containing profiles) into different components (smooth background, profile deviation, anomaly, and noise); then, each component’s transferability is analyzed by expert knowledge; Lastly, different transfer learning techniques could be tailored accordingly. We adopted the Bayesian probabilistic hierarchical model to formulate parameter transfer for the background, and “ L 2,1 + L 1 ”-norm to formulate low dimension feature-representation transfer for the anomaly. An efficient algorithm based on Block Coordinate Descend is proposed to learn the parameters. A case study based on glass coating pressure profiles demonstrates the improved accuracy and completeness of detected anomaly, and a simulation demonstrates the fidelity of the decomposition results.},
  archive      = {J_TKDD},
  doi          = {10.1145/3530990},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Profile decomposition based hybrid transfer learning for cold-start data anomaly detection},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A news-based framework for uncovering and tracking city area
profiles: Assessment in covid-19 setting. <em>TKDD</em>, <em>16</em>(6),
1–29. (<a href="https://doi.org/10.1145/3532186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last years, there has been an ever-increasing interest in profiling various aspects of city life, especially in the context of smart cities. This interest has become even more relevant recently when we have realized how dramatic events, such as the Covid-19 pandemic, can deeply affect the city life, producing drastic changes. Identifying and analyzing such changes, both at the city level and within single neighborhoods, may be a fundamental tool to better manage the current situation and provide sound strategies for future planning. Furthermore, such fine-grained and up-to-date characterization can represent a valuable asset for other tools and services, e.g., web mapping applications or real estate agency platforms. In this article, we propose a framework featuring a novel methodology to model and track changes in areas of the city by extracting information from online newspaper articles. The problem of uncovering clusters of news at specific times is tackled by means of the joint use of state-of-the-art language models to represent the articles, and of a density-based streaming clustering algorithm, properly shaped to deal with high-dimensional text embeddings. Furthermore, we propose a method to automatically label the obtained clusters in a semantically meaningful way, and we introduce a set of metrics aimed at tracking the temporal evolution of clusters. A case study focusing on the city of Rome during the Covid-19 pandemic is illustrated and discussed to evaluate the effectiveness of the proposed approach.},
  archive      = {J_TKDD},
  doi          = {10.1145/3532186},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A news-based framework for uncovering and tracking city area profiles: Assessment in covid-19 setting},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MCRapper: Monte-carlo rademacher averages for poset families
and approximate pattern mining. <em>TKDD</em>, <em>16</em>(6), 1–29. (<a
href="https://doi.org/10.1145/3532187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“I’m an MC still as honest” – Eminem, Rap God We present MCRapper , an algorithm for efficient computation of Monte-Carlo Empirical Rademacher Averages (MCERA) for families of functions exhibiting poset (e.g., lattice) structure, such as those that arise in many pattern mining tasks. The MCERA allows us to compute upper bounds to the maximum deviation of sample means from their expectations, thus it can be used to find both (1) statistically-significant functions (i.e., patterns) when the available data is seen as a sample from an unknown distribution, and (2) approximations of collections of high-expectation functions (e.g., frequent patterns) when the available data is a small sample from a large dataset. This flexibility offered by MCRapper is a big advantage over previously proposed solutions, which could only achieve one of the two. MCRapper uses upper bounds to the discrepancy of the functions to efficiently explore and prune the search space, a technique borrowed from pattern mining itself. To show the practical use of MCRapper , we employ it to develop an algorithm TFP-R for the task of True Frequent Pattern (TFP) mining, by appropriately computing approximations of the negative and positive borders of the collection of patterns of interest, which allow an effective pruning of the pattern space and the computation of strong bounds to the supremum deviation. TFP-R gives guarantees on the probability of including any false positives (precision) and exhibits higher statistical power (recall) than existing methods offering the same guarantees. We evaluate MCRapper and TFP-R and show that they outperform the state-of-the-art for their respective tasks.},
  archive      = {J_TKDD},
  doi          = {10.1145/3532187},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {MCRapper: Monte-carlo rademacher averages for poset families and approximate pattern mining},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Streaming data preprocessing via online tensor recovery for
large environmental sensor networks. <em>TKDD</em>, <em>16</em>(6),
1–24. (<a href="https://doi.org/10.1145/3532189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring the built and natural environment at a fine-grained scale is now possible with low-cost urban environmental sensor networks. However, fine-grained city-scale data analysis is complicated by tedious data cleaning including removing outliers and imputing missing data. While many methods exist to automatically correct anomalies and impute missing entries, challenges still exist on data with large spatial-temporal scales and shifting patterns. To address these challenges, we propose an online robust tensor recovery (OLRTR) method to preprocess streaming high-dimensional urban environmental datasets. A small-sized dictionary that captures the underlying patterns of the data is computed and constantly updated with new data. OLRTR enables online recovery for large-scale sensor networks that provide continuous data streams, with a lower computational memory usage compared to offline batch counterparts. In addition, we formulate the objective function so that OLRTR can detect structured outliers, such as faulty readings over a long period of time. We validate OLRTR on a synthetically degraded National Oceanic and Atmospheric Administration temperature dataset, and apply it to the Array of Things city-scale sensor network in Chicago, IL, showing superior results compared with several established online and batch-based low-rank decomposition methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3532189},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Streaming data preprocessing via online tensor recovery for large environmental sensor networks},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HW-forest: Deep forest with hashing screening and window
screening. <em>TKDD</em>, <em>16</em>(6), 1–24. (<a
href="https://doi.org/10.1145/3532193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a novel deep learning model, gcForest has been widely used in various applications. However, current multi-grained scanning of gcForest produces many redundant feature vectors, and this increases the time cost of the model. To screen out redundant feature vectors, we introduce a hashing screening mechanism for multi-grained scanning and propose a model called HW-Forest which adopts two strategies: hashing screening and window screening. HW-Forest employs perceptual hashing algorithm to calculate the similarity between feature vectors in hashing screening strategy, which is used to remove the redundant feature vectors produced by multi-grained scanning and can significantly decrease the time cost and memory consumption. Furthermore, we adopt a self-adaptive instance screening strategy called window screening to improve the performance of our approach, which can achieve higher accuracy without hyperparameter tuning on different datasets. Our experimental results show that HW-Forest has higher accuracy than other models, and the time cost is also reduced.},
  archive      = {J_TKDD},
  doi          = {10.1145/3532193},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {HW-forest: Deep forest with hashing screening and window screening},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combining filtering and cross-correlation efficiently for
streaming time series. <em>TKDD</em>, <em>16</em>(5), 1–24. (<a
href="https://doi.org/10.1145/3502738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring systems have hundreds or thousands of distributed sensors gathering and transmitting real-time streaming data. The early detection of events in these systems, such as an earthquake in a seismic monitoring system, is the base for essential tasks as warning generations. To detect such events is usual to compute pairwise correlation across the disparate signals generated by the sensors. Since the data sources (e.g., sensors) are spatially separated, it is essential to consider the lagged correlation between the signals. Besides, many applications require to process a specific band of frequencies depending on the event’s type, demanding a pre-processing step of filtering before computing correlations. Due to the high speed of data generation and a large number of sensors in these systems, the operations of filtering and lagged cross-correlation need to be efficient to provide real-time responses without data losses. This article proposes a technique named FilCorr that efficiently computes both operations in one single step. We achieve an order of magnitude speedup by maintaining frequency transforms over sliding windows. Our method is exact, devoid of sensitive parameters, and easily parallelizable. Besides our algorithm, we also provide a publicly available real-time system named Seisviz that employs FilCorr in its core mechanism for monitoring a seismometer network. We demonstrate that our technique is suitable for several monitoring applications as seismic signal monitoring, motion monitoring, and neural activity monitoring.},
  archive      = {J_TKDD},
  doi          = {10.1145/3502738},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Combining filtering and cross-correlation efficiently for streaming time series},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the robustness of metric learning: An adversarial
perspective. <em>TKDD</em>, <em>16</em>(5), 1–25. (<a
href="https://doi.org/10.1145/3502726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metric learning aims at automatically learning a distance metric from data so that the precise similarity between data instances can be faithfully reflected, and its importance has long been recognized in many fields. An implicit assumption in existing metric learning works is that the learned models are performed in a reliable and secure environment. However, the increasingly critical role of metric learning makes it susceptible to a risk of being malicious attacked. To well understand the performance of metric learning models in adversarial environments, in this article, we study the robustness of metric learning to adversarial perturbations, which are also known as the imperceptible changes to the input data that are crafted by an attacker to fool a well-learned model. However, different from traditional classification models, metric learning models take instance pairs rather than individual instances as input, and the perturbation on one instance may not necessarily affect the prediction result for an instance pair, which makes it more difficult to study the robustness of metric learning. To address this challenge, in this article, we first provide a definition of pairwise robustness for metric learning, and then propose a novel projected gradient descent-based attack method (called AckMetric) to evaluate the robustness of metric learning models. To further explore the capability of the attacker to change the prediction results, we also propose a theoretical framework to derive the upper bound of the pairwise adversarial loss. Finally, we incorporate the derived bound into the training process of metric learning and design a novel defense method to make the learned models more robust. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3502726},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {5},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {On the robustness of metric learning: An adversarial perspective},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quality-informed process mining: A case for standardised
data quality annotations. <em>TKDD</em>, <em>16</em>(5), 1–47. (<a
href="https://doi.org/10.1145/3511707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-life event logs, reflecting the actual executions of complex business processes, are faced with numerous data quality issues. Extensive data sanity checks and pre-processing are usually needed before historical data can be used as input to obtain reliable data-driven insights. However, most of the existing algorithms in process mining, a field focusing on data-driven process analysis, do not take any data quality issues or the potential effects of data pre-processing into account explicitly. This can result in erroneous process mining results, leading to inaccurate, or misleading conclusions about the process under investigation. To address this gap, we propose data quality annotations for event logs, which can be used by process mining algorithms to generate quality-informed insights. Using a design science approach, requirements are formulated, which are leveraged to propose data quality annotations. Moreover, we present the “Quality-Informed visual Miner” plug-in to demonstrate the potential utility and impact of data quality annotations. Our experimental results, utilising both synthetic and real-life event logs, show how the use of data quality annotations by process mining techniques can assist in increasing the reliability of performance analysis results.},
  archive      = {J_TKDD},
  doi          = {10.1145/3511707},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {5},
  pages        = {1-47},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Quality-informed process mining: A case for standardised data quality annotations},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Who will win the data science competition? Insights from KDD
cup 2019 and beyond. <em>TKDD</em>, <em>16</em>(5), 1–24. (<a
href="https://doi.org/10.1145/3511896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data science competitions are becoming increasingly popular for enterprises collecting advanced innovative solutions and allowing contestants to sharpen their data science skills. Most existing studies about data science competitions have a focus on improving task-specific data science techniques, such as algorithm design and parameter tuning. However, little effort has been made to understand the data science competition itself. To this end, in this article, we shed light on the team’s competition performance, and investigate the team’s evolving performance in the crowd-sourcing competitive innovation context. Specifically, we first acquire and construct multi-sourced datasets of various data science competitions, including the KDD Cup 2019 machine learning competition and beyond. Then, we conduct an empirical analysis to identify and quantify a rich set of features that are significantly correlated with teams’ future performances. By leveraging team’s rank as a proxy, we observe “the stronger, the stronger” rule; that is, top-ranked teams tend to keep their advantages and dominate weaker teams for the rest of the competition. Our results also confirm that teams with diversified backgrounds tend to achieve better performances. After that, we formulate the team’s future rank prediction problem and propose the Multi-Task Representation Learning (MTRL) framework to model both static features and dynamic features. Extensive experimental results on four real-world data science competitions demonstrate the team’s future performance can be well predicted by using MTRL. Finally, we envision our study will not only help competition organizers to understand the competition in a better way, but also provide strategic implications to contestants, such as guiding the team formation and designing the submission strategy.},
  archive      = {J_TKDD},
  doi          = {10.1145/3511896},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {5},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Who will win the data science competition? insights from KDD cup 2019 and beyond},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymmetric multi-task learning with local transference.
<em>TKDD</em>, <em>16</em>(5), 1–30. (<a
href="https://doi.org/10.1145/3514252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present the Group Asymmetric Multi-Task Learning (GAMTL) algorithm that automatically learns from data how tasks transfer information among themselves at the level of a subset of features. In practice, for each group of features GAMTL extracts an asymmetric relationship supported by the tasks, instead of assuming a single structure for all features. The additional flexibility promoted by local transference in GAMTL allows any two tasks to have multiple asymmetric relationships. The proposed method leverages the information present in these multiple structures to bias the training of individual tasks towards more generalizable models. The solution to the GAMTL’s associated optimization problem is an alternating minimization procedure involving tasks parameters and multiple asymmetric relationships, thus guiding to convex smaller sub-problems. GAMTL was evaluated on both synthetic and real datasets. To evidence GAMTL versatility, we generated a synthetic scenario characterized by diverse profiles of structural relationships among tasks. GAMTL was also applied to the problem of Alzheimer’s Disease (AD) progression prediction. Our experiments indicated that the proposed approach not only increased prediction performance, but also estimated scientifically grounded relationships among multiple cognitive scores, taken here as multiple regression tasks, and regions of interest in the brain, directly associated here with groups of features. We also employed stability selection analysis to investigate GAMTL’s robustness to data sampling rate and hyper-parameter configuration. GAMTL source code is available on GitHub: https://github.com/shgo/gamtl .},
  archive      = {J_TKDD},
  doi          = {10.1145/3514252},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {5},
  pages        = {1-30},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Asymmetric multi-task learning with local transference},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-relation graph summarization. <em>TKDD</em>,
<em>16</em>(5), 1–30. (<a
href="https://doi.org/10.1145/3494561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph summarization is beneficial in a wide range of applications, such as visualization, interactive and exploratory analysis, approximate query processing, reducing the on-disk storage footprint, and graph processing in modern hardware. However, the bulk of the literature on graph summarization surprisingly overlooks the possibility of having edges of different types. In this article, we study the novel problem of producing summaries of multi-relation networks, i.e., graphs where multiple edges of different types may exist between any pair of nodes. Multi-relation graphs are an expressive model of real-world activities, in which a relation can be a topic in social networks, an interaction type in genetic networks, or a snapshot in temporal graphs. The first approach that we consider for multi-relation graph summarization is a two-step method based on summarizing each relation in isolation, and then aggregating the resulting summaries in some clever way to produce a final unique summary. In doing this, as a side contribution, we provide the first polynomial-time approximation algorithm based on the k -Median clustering for the classic problem of lossless single-relation graph summarization. Then, we demonstrate the shortcomings of these two-step methods, and propose holistic approaches, both approximate and heuristic algorithms, to compute a summary directly for multi-relation graphs. In particular, we prove that the approximation bound of k -Median clustering for the single relation solution can be maintained in a multi-relation graph with proper aggregation operation over adjacency matrices corresponding to its multiple relations. Experimental results and case studies (on co-authorship networks and brain networks) validate the effectiveness and efficiency of the proposed algorithms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3494561},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {5},
  pages        = {1-30},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Multi-relation graph summarization},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent data analysis using optimized support vector
machine based data mining approach for tourism industry. <em>TKDD</em>,
<em>16</em>(5), 1–20. (<a
href="https://doi.org/10.1145/3494566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data analysis involves the deployment of sophisticated approaches from data mining methods, information theory, and artificial intelligence in various fields like tourism, hospitality, and so on for the extraction of knowledge from the gathered and preprocessed data. In tourism, pattern analysis or data analysis using classification is significant for finding the patterns that represent new and potentially useful information or knowledge about the destination and other data. Several data mining techniques are introduced for the classification of data or patterns. However, overfitting, less accuracy, local minima, sensitive to noise are the drawbacks in some existing data mining classification methods. To overcome these challenges, Support vector machine with Red deer optimization (SVM-RDO) based data mining strategy is proposed in this article. Extended Kalman filter (EKF) is utilized in the first phase, i.e., data cleaning to remove the noise and missing values from the input data. Mantaray foraging algorithm (MaFA) is used in the data selection phase, in which the significant data are selected for the further process to reduce the computational complexity. The final phase is the classification, in which SVM-RDO is proposed to access the useful pattern from the selected data. PYTHON is the implementation tool used for the experiment of the proposed model. The experimental analysis is done to show the efficacy of the proposed work. From the experimental results, the proposed SVM-RDO achieved better accuracy, precision, recall, and F1 score than the existing methods for the tourism dataset. Thus, it is showed the effectiveness of the proposed SVM-RDO for pattern analysis.},
  archive      = {J_TKDD},
  doi          = {10.1145/3494566},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {5},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Intelligent data analysis using optimized support vector machine based data mining approach for tourism industry},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MBN: Towards multi-behavior sequence modeling for next
basket recommendation. <em>TKDD</em>, <em>16</em>(5), 1–23. (<a
href="https://doi.org/10.1145/3497748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next basket recommendation aims at predicting the next set of items that a user would likely purchase together, which plays an important role in e-commerce platforms. Unlike conventional item recommendation, the next basket recommendation focuses on capturing item correlations among baskets and learning the user’s temporal interest from the past purchasing basket sequence. In practice, most users interact with items in various kinds of behaviors. The multi-behavior data sheds light on user’s potential purchasing intention and resolves noisy signals from accidentally purchased items. In this article, we conduct an empirical study on real datasets to exploit the characteristics of multi-behavior data and confirm its positive effects on next basket recommendation. We develop a novel Multi-Behavior Network (MBN) model that captures item correlations and acquires meta-knowledge from multi-behavior basket sequences effectively. MBN employs the meta multi-behavior sequence encoder to model temporal dependencies of each individual behavior and extract meta-knowledge across different behaviors. Furthermore, we design the recurring-item-aware predictor in MBN to realize the high degree of the repeated occurrences of items, leading to better recommendation performance. We conduct extensive experiments to evaluate the performance of our proposed MBN model using real-world multi-behavior data. The results demonstrate the superior recommendation performance of MBN compared with various state-of-the-art methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3497748},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {5},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {MBN: Towards multi-behavior sequence modeling for next basket recommendation},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic variational optimization of a hierarchical
dirichlet process latent beta-liouville topic model. <em>TKDD</em>,
<em>16</em>(5), 1–48. (<a
href="https://doi.org/10.1145/3502727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In topic models, collections are organized as documents where they arise as mixtures over latent clusters called topics. A topic is a distribution over the vocabulary. In large-scale applications, parametric or finite topic mixture models such as LDA (latent Dirichlet allocation) and its variants are very restrictive in performance due to their reduced hypothesis space. In this article, we address the problem related to model selection and sharing ability of topics across multiple documents in standard parametric topic models. We propose as an alternative a BNP (Bayesian nonparametric) topic model where the HDP (hierarchical Dirichlet process) prior models documents topic mixtures through their multinomials on infinite simplex. We, therefore, propose asymmetric BL (Beta-Liouville) as a diffuse base measure at the corpus level DP (Dirichlet process) over a measurable space. This step illustrates the highly heterogeneous structure in the set of all topics that describes the corpus probability measure. For consistency in posterior inference and predictive distributions, we efficiently characterize random probability measures whose limits are the global and local DPs to approximate the HDP from the stick-breaking formulation with the GEM (Griffiths-Engen-McCloskey) random variables. Due to the diffuse measure with the BL prior as conjugate to the count data distribution, we obtain an improved version of the standard HDP that is usually based on symmetric Dirichlet (Dir). In addition, to improve coordinate ascent framework while taking advantage of its deterministic nature, our model implements an online optimization method based on stochastic, at document level, variational inference to accommodate fast topic learning when processing large collections of text documents with natural gradient. The high value in the predictive likelihood per document obtained when compared to the performance of its competitors is also consistent with the robustness of our fully asymmetric BL-based HDP. While insuring the predictive accuracy of the model using the probability of the held-out documents, we also added a combination of metrics such as the topic coherence and topic diversity to improve the quality and interpretability of the topics discovered. We also compared the performance of our model using these metrics against the standard symmetric LDA. We show that online HDP-LBLA (Latent BL Allocation)’s performance is the asymptote for parametric topic models. The accuracy in the results (improved predictive distributions of the held out) is a product of the model’s ability to efficiently characterize dependency between documents (topic correlation) as now they can easily share topics, resulting in a much robust and realistic compression algorithm for information modeling.},
  archive      = {J_TKDD},
  doi          = {10.1145/3502727},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {5},
  pages        = {1-48},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Stochastic variational optimization of a hierarchical dirichlet process latent beta-liouville topic model},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-label deep convolutional transform learning for
non-intrusive load monitoring. <em>TKDD</em>, <em>16</em>(5), 1–6. (<a
href="https://doi.org/10.1145/3502729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this letter is to propose a novel computational method to learn the state of an appliance (ON / OFF) given the aggregate power consumption recorded by the smart-meter. We formulate a multi-label classification problem where the classes correspond to the appliances. The proposed approach is based on our recently introduced framework of convolutional transform learning. We propose a deep supervised version of it relying on an original multi-label cost. Comparisons with state-of-the-art techniques show that our proposed method improves over the benchmarks on popular non-intrusive load monitoring datasets.},
  archive      = {J_TKDD},
  doi          = {10.1145/3502729},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {5},
  pages        = {1-6},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Multi-label deep convolutional transform learning for non-intrusive load monitoring},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploiting higher order multi-dimensional relationships with
self-attention for author name disambiguation. <em>TKDD</em>,
<em>16</em>(5), 1–23. (<a
href="https://doi.org/10.1145/3502730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Name ambiguity is a prevalent problem in scholarly publications due to the unprecedented growth of digital libraries and number of researchers. An author is identified by their name in the absence of a unique identifier. The documents of an author are mistakenly assigned due to underlying ambiguity, which may lead to an improper assessment of the author. Various efforts have been made in the literature to solve the name disambiguation problem with supervised and unsupervised approaches. The unsupervised approaches for author name disambiguation are preferred due to the availability of a large amount of unlabeled data. Bibliographic data contain heterogeneous features, thus recently, representation learning-based techniques have been used in literature to embed heterogeneous features in common space. Documents of a scholar are connected by multiple relations. Recently, research has shifted from a single homogeneous relation to multi-dimensional (heterogeneous) relations for the latent representation of document. Connections in graphs are sparse, and higher order links between documents give an additional clue. Therefore, we have used multiple neighborhoods in different relation types in heterogeneous graph for representation of documents. However, different order neighborhood in each relation type has different importance which we have empirically validated also. Therefore, to properly utilize the different neighborhoods in relation type and importance of each relation type in the heterogeneous graph, we propose attention-based multi-dimensional multi-hop neighborhood-based graph convolution network for embedding that uses the two levels of an attention, namely, (i) relation level and (ii) neighborhood level, in each relation. A significant improvement over existing state-of-the-art methods in terms of various evaluation matrices has been obtained by the proposed approach.},
  archive      = {J_TKDD},
  doi          = {10.1145/3502730},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {5},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Exploiting higher order multi-dimensional relationships with self-attention for author name disambiguation},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evidence transfer: Learning improved representations
according to external heterogeneous task outcomes. <em>TKDD</em>,
<em>16</em>(5), 1–22. (<a
href="https://doi.org/10.1145/3502732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised representation learning tends to produce generic and reusable latent representations. However, these representations can often miss high-level features or semantic information, since they only observe the implicit properties of the dataset. On the other hand, supervised learning frameworks learn task-oriented latent representations that may not generalise in other tasks or domains. In this article, we introduce evidence transfer, a deep learning method that incorporates the outcomes of external tasks in the unsupervised learning process of an autoencoder. External task outcomes also referred to as categorical evidence, are represented by categorical variables, and are either directly or indirectly related to the primary dataset—in the most straightforward case they are the outcome of another task on the same dataset. Evidence transfer allows the manipulation of generic latent representations in order to include domain or task-specific knowledge that will aid their effectiveness in downstream tasks. Evidence transfer is robust against evidence of low quality and effective when introduced with related, corresponding, or meaningful evidence.},
  archive      = {J_TKDD},
  doi          = {10.1145/3502732},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {5},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Evidence transfer: Learning improved representations according to external heterogeneous task outcomes},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constant time graph neural networks. <em>TKDD</em>,
<em>16</em>(5), 1–31. (<a
href="https://doi.org/10.1145/3502733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent advancements in graph neural networks (GNNs) have led to state-of-the-art performances in various applications, including chemo-informatics, question-answering systems, and recommender systems. However, scaling up these methods to huge graphs, such as social networks and Web graphs, remains a challenge. In particular, the existing methods for accelerating GNNs either are not theoretically guaranteed in terms of the approximation error or incurred at least a linear time computation cost. In this study, we reveal the query complexity of the uniform node sampling scheme for Message Passing Neural Networks, including GraphSAGE, graph attention networks (GATs), and graph convolutional networks (GCNs). Surprisingly, our analysis reveals that the complexity of the node sampling method is completely independent of the number of the nodes, edges, and neighbors of the input and depends only on the error tolerance and confidence probability while providing a theoretical guarantee for the approximation error. To the best of our knowledge, this is the first article to provide a theoretical guarantee of approximation for GNNs within constant time. Through experiments with synthetic and real-world datasets, we investigated the speed and precision of the node sampling scheme and validated our theoretical results.},
  archive      = {J_TKDD},
  doi          = {10.1145/3502733},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {5},
  pages        = {1-31},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Constant time graph neural networks},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online learning bipartite matching with non-stationary
distributions. <em>TKDD</em>, <em>16</em>(5), 1–22. (<a
href="https://doi.org/10.1145/3502734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online bipartite matching has attracted wide interest since it can successfully model the popular online car-hailing problem and sharing economy. Existing works consider this problem under either adversary setting or i.i.d. setting. The former is too pessimistic to improve the performance in the general case; the latter is too optimistic to deal with the varying distribution of vertices. In this article, we initiate the study of the non-stationary online bipartite matching problem, which allows the distribution of vertices to vary with time and is more practical. We divide the non-stationary online bipartite matching problem into two subproblems, the matching problem and the selecting problem, and solve them individually. Combining Batch algorithms and deep Q-learning networks, we first construct a candidate algorithm set to solve the matching problem. For the selecting problem, we use a classical online learning algorithm, Exp3, as a selector algorithm and derive a theoretical bound. We further propose CDUCB as a selector algorithm by integrating distribution change detection into UCB. Rigorous theoretical analysis demonstrates that the performance of our proposed algorithms is no worse than that of any candidate algorithms in terms of competitive ratio. Finally, extensive experiments show that our proposed algorithms have much higher performance for the non-stationary online bipartite matching problem comparing to the state-of-the-art.},
  archive      = {J_TKDD},
  doi          = {10.1145/3502734},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {5},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Online learning bipartite matching with non-stationary distributions},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BhBF: A bloom filter using bh sequences for multi-set
membership query. <em>TKDD</em>, <em>16</em>(5), 1–26. (<a
href="https://doi.org/10.1145/3502735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-set membership query is a fundamental issue for network functions such as packet processing and state machines monitoring. Given the rigid query speed and memory requirements, it would be promising if a multi-set query algorithm can be designed based on Bloom filter (BF), a space-efficient probabilistic data structure. However, existing efforts on multi-set query based on BF suffer from at least one of the following drawbacks: low query speed, low query accuracy, limitation in only supporting insertion and query operations, or limitation in the set size. To address the issues, we design a novel B h sequence-based Bloom filter (B h BF) for multi-set query, which supports four operations: insertion, query, deletion, and update. In B h BF, the set ID is encoded as a code in a B h sequence. Exploiting good properties of B h sequences, we can correctly decode the BF cells to obtain the set IDs even when the number of hash collisions is high, which brings high query accuracy. In B h BF, we propose two strategies to further speed up the query speed and increase the query accuracy. On the theoretical side, we analyze the false positive and classification failure rate of our B h BF. Our results from extensive experiments over two real datasets demonstrate that B h BF significantly advances state-of-the-art multi-set query algorithms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3502735},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {5},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {BhBF: A bloom filter using bh sequences for multi-set membership query},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computational estimation by scientific data mining with
classical methods to automate learning strategies of scientists.
<em>TKDD</em>, <em>16</em>(5), 1–52. (<a
href="https://doi.org/10.1145/3502736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experimental results are often plotted as 2-dimensional graphical plots (aka graphs) in scientific domains depicting dependent versus independent variables to aid visual analysis of processes. Repeatedly performing laboratory experiments consumes significant time and resources, motivating the need for computational estimation. The goals are to estimate the graph obtained in an experiment given its input conditions, and to estimate the conditions that would lead to a desired graph. Existing estimation approaches often do not meet accuracy and efficiency needs of targeted applications. We develop a computational estimation approach called AutoDomainMine that integrates clustering and classification over complex scientific data in a framework so as to automate classical learning methods of scientists. Knowledge discovered thereby from a database of existing experiments serves as the basis for estimation. Challenges include preserving domain semantics in clustering, finding matching strategies in classification, striking a good balance between elaboration and conciseness while displaying estimation results based on needs of targeted users, and deriving objective measures to capture subjective user interests. These and other challenges are addressed in this work. The AutoDomainMine approach is used to build a computational estimation system, rigorously evaluated with real data in Materials Science. Our evaluation confirms that AutoDomainMine provides desired accuracy and efficiency in computational estimation. It is extendable to other science and engineering domains as proved by adaptation of its sub-processes within fields such as Bioinformatics and Nanotechnology.},
  archive      = {J_TKDD},
  doi          = {10.1145/3502736},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {5},
  pages        = {1-52},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Computational estimation by scientific data mining with classical methods to automate learning strategies of scientists},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online scalable streaming feature selection via dynamic
decision. <em>TKDD</em>, <em>16</em>(5), 1–20. (<a
href="https://doi.org/10.1145/3502737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is one of the core concepts in machine learning, which hugely impacts the model’s performance. For some real-world applications, features may exist in a stream mode that arrives one by one over time, while we cannot know the exact number of features before learning. Online streaming feature selection aims at selecting optimal stream features at each timestamp on the fly. Without the global information of the entire feature space, most of the existing methods select stream features in terms of individual feature information or the comparison of features in pairs. This article proposes a new online scalable streaming feature selection framework from the dynamic decision perspective that is scalable on running time and selected features by dynamic threshold adjustment. Regarding the philosophy of “Thinking-in-Threes”, we classify each new arrival feature as selecting, discarding, or delaying, aiming at minimizing the overall decision risks. With the dynamic updating of global statistical information, we add the selecting features into the candidate feature subset, ignore the discarding features, cache the delaying features into the undetermined feature subset, and wait for more information. Meanwhile, we perform the redundancy analysis for the candidate features and uncertainty analysis for the undetermined features. Extensive experiments on eleven real-world datasets demonstrate the efficiency and scalability of our new framework compared with state-of-the-art algorithms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3502737},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {5},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Online scalable streaming feature selection via dynamic decision},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DexDeepFM: Ensemble diversity enhanced extreme deep
factorization machine model. <em>TKDD</em>, <em>16</em>(5), 1–17. (<a
href="https://doi.org/10.1145/3505272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting user positive response (e.g., purchases and clicks) probability is a critical task in Web applications. To identify predictive features from raw data, the state-of-the-art extreme deep factorization machine model (xDeepFM) introduces a new interaction network to leverage feature interactions at the vector-wise level explicitly. However, since each hidden layer in the interaction network is a collection of feature maps, it can be viewed essentially as an ensemble of different feature maps. In this case, only using a single objective to minimize the prediction loss may lead to overfitting and generate correlated errors. In this article, an ensemble diversity enhanced extreme deep factorization machine model (DexDeepFM) is proposed, which designs the ensemble diversity measure in each hidden layer and considers both ensemble diversity and prediction accuracy in the objective function. In addition, the attention mechanism is introduced to discriminate the importance of ensemble diversity measures with different feature interaction orders. Extensive experiments on three public real-world datasets are conducted to show the effectiveness of the proposed model.},
  archive      = {J_TKDD},
  doi          = {10.1145/3505272},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {5},
  pages        = {1-17},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {DexDeepFM: Ensemble diversity enhanced extreme deep factorization machine model},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PSL: An algorithm for partial bayesian network structure
learning. <em>TKDD</em>, <em>16</em>(5), 1–25. (<a
href="https://doi.org/10.1145/3508071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning partial Bayesian network (BN) structure is an interesting and challenging problem. In this challenge, it is computationally expensive to use global BN structure learning algorithms, while only one part of a BN structure is interesting, local BN structure learning algorithms are not a favourable solution either due to the issue of false edge orientation. To address the problem, this article first presents a detailed analysis of the false edge orientation issue with local BN structure learning algorithms and then proposes PSL, an efficient and accurate P artial BN S tructure L earning (PSL) algorithm. Specifically, PSL divides V-structures in a Markov blanket (MB) into two types: Type-C V-structures and Type-NC V-structures, then it starts from the given node of interest and recursively finds both types of V-structures in the MB of the current node until all edges in the partial BN structure are oriented. To further improve the efficiency of PSL, the PSL-FS algorithm is designed by incorporating F eature S election (FS) into PSL. Extensive experiments with six benchmark BNs validate the efficiency and accuracy of the proposed algorithms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3508071},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {5},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {PSL: An algorithm for partial bayesian network structure learning},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph neural news recommendation with user existing and
potential interest modeling. <em>TKDD</em>, <em>16</em>(5), 1–17. (<a
href="https://doi.org/10.1145/3511708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized news recommendations can alleviate the information overload problem. To enable personalized recommendation, one critical step is to learn a comprehensive user representation to model her/his interests. Many existing works learn user representations from the historical clicked news articles, which reflect their existing interests. However, these approaches ignore users’ potential interests and pay less attention to news that may interest the users in the future. To address this problem, we propose a novel G raph neural news R ecommendation model with user E xisting and P otential interest modeling, named GREP. Different from existing works, GREP introduces three modules to jointly model users’ existing and potential interests: (1) Existing Interest Encoding module mines user historical clicked news and applies the multi-head self-attention mechanism to capture the relatedness among the news; (2) Potential Interest Encoding module leverages the graph neural network to explore the user potential interests on the knowledge graph; and (3) Bi-directional Interaction module dynamically builds a news-entity bipartite graph to further enrich two interest representations. Finally, GREP combines the existing and potential interest representations to represent the user and leverages a prediction layer to estimate the clicking probability of the candidate news. Experiments on two real-world large-scale datasets demonstrate the state-of-the-art performance of GREP.},
  archive      = {J_TKDD},
  doi          = {10.1145/3511708},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {5},
  pages        = {1-17},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Graph neural news recommendation with user existing and potential interest modeling},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Compression of deep learning models for text: A survey.
<em>TKDD</em>, <em>16</em>(4), 1–55. (<a
href="https://doi.org/10.1145/3487045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the fields of natural language processing (NLP) and information retrieval (IR) have made tremendous progress thanks to deep learning models like Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs) and Long Short-Term Memory (LSTMs) networks, and Transformer [ 121 ] based models like Bidirectional Encoder Representations from Transformers (BERT) [ 24 ], Generative Pre-training Transformer (GPT-2) [ 95 ], Multi-task Deep Neural Network (MT-DNN) [ 74 ], Extra-Long Network (XLNet) [ 135 ], Text-to-text transfer transformer (T5) [ 96 ], T-NLG [ 99 ], and GShard [ 64 ]. But these models are humongous in size. On the other hand, real-world applications demand small model size, low response times, and low computational power wattage. In this survey, we discuss six different types of methods (Pruning, Quantization, Knowledge Distillation (KD), Parameter Sharing, Tensor Decomposition, and Sub-quadratic Transformer-based methods) for compression of such models to enable their deployment in real industry NLP projects. Given the critical need of building applications with efficient and small models, and the large amount of recently published work in this area, we believe that this survey organizes the plethora of work done by the “deep learning for NLP” community in the past few years and presents it as a coherent story.},
  archive      = {J_TKDD},
  doi          = {10.1145/3487045},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-55},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Compression of deep learning models for text: A survey},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TRACE: Travel reinforcement recommendation based on
location-aware context extraction. <em>TKDD</em>, <em>16</em>(4), 1–22.
(<a href="https://doi.org/10.1145/3487047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the popularity of online travel platforms increases, users tend to make ad-hoc decisions on places to visit rather than preparing the detailed tour plans in advance. Under the situation of timeliness and uncertainty of users’ demand, how to integrate real-time context into dynamic and personalized recommendations have become a key issue in travel recommender system. In this article, by integrating the users’ historical preferences and real-time context, a location-aware recommender system called TRACE ( T ravel R einforcement Recommendations Based on Location- A ware C ontext E xtraction) is proposed. It captures users’ features based on location-aware context learning model, and makes dynamic recommendations based on reinforcement learning. Specifically, this research: (1) designs a travel reinforcing recommender system based on an Actor-Critic framework, which can dynamically track the user preference shifts and optimize the recommender system performance; (2) proposes a location-aware context learning model, which aims at extracting user context from real-time location and then calculating the impacts of nearby attractions on users’ preferences; and (3) conducts both offline and online experiments. Our proposed model achieves the best performance in both of the two experiments, which demonstrates that tracking the users’ preference shifts based on real-time location is valuable for improving the recommendation results.},
  archive      = {J_TKDD},
  doi          = {10.1145/3487047},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {TRACE: Travel reinforcement recommendation based on location-aware context extraction},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mixed information flow for cross-domain sequential
recommendations. <em>TKDD</em>, <em>16</em>(4), 1–32. (<a
href="https://doi.org/10.1145/3487331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain sequential recommendation is the task of predict the next item that the user is most likely to interact with based on past sequential behavior from multiple domains. One of the key challenges in cross-domain sequential recommendation is to grasp and transfer the flow of information from multiple domains so as to promote recommendations in all domains. Previous studies have investigated the flow of behavioral information by exploring the connection between items from different domains. The flow of knowledge (i.e., the connection between knowledge from different domains) has so far been neglected. In this article, we propose a mixed information flow network for cross-domain sequential recommendation to consider both the flow of behavioral information and the flow of knowledge by incorporating a behavior transfer unit and a knowledge transfer unit . The proposed mixed information flow network is able to decide when cross-domain information should be used and, if so, which cross-domain information should be used to enrich the sequence representation according to users’ current preferences. Extensive experiments conducted on four e-commerce datasets demonstrate that the proposed mixed information flow network is able to improve recommendation performance in different domains by modeling mixed information flow. In this article, we focus on the application of mixed information flow network s to a scenario with two domains, but the method can easily be extended to multiple domains.},
  archive      = {J_TKDD},
  doi          = {10.1145/3487331},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-32},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Mixed information flow for cross-domain sequential recommendations},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Causal feature selection with missing data. <em>TKDD</em>,
<em>16</em>(4), 1–24. (<a
href="https://doi.org/10.1145/3488055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal feature selection aims at learning the Markov blanket (MB) of a class variable for feature selection. The MB of a class variable implies the local causal structure among the class variable and its MB and all other features are probabilistically independent of the class variable conditioning on its MB, this enables causal feature selection to identify potential causal features for feature selection for building robust and physically meaningful prediction models. Missing data, ubiquitous in many real-world applications, remain an open research problem in causal feature selection due to its technical complexity. In this article, we discuss a novel multiple imputation MB (MimMB) framework for causal feature selection with missing data. MimMB integrates Data Imputation with MB Learning in a unified framework to enable the two key components to engage with each other. MB Learning enables Data Imputation in a potentially causal feature space for achieving accurate data imputation, while accurate Data Imputation helps MB Learning identify a reliable MB of the class variable in turn. Then, we further design an enhanced kNN estimator for imputing missing values and instantiate the MimMB. In our comprehensively experimental evaluation, our new approach can effectively learn the MB of a given variable in a Bayesian network and outperforms other rival algorithms using synthetic and real-world datasets.},
  archive      = {J_TKDD},
  doi          = {10.1145/3488055},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Causal feature selection with missing data},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting the market with machine learning algorithms: An
application of NMC-BERT-LSTM-DQN-x algorithm in quantitative trading.
<em>TKDD</em>, <em>16</em>(4), 1–22. (<a
href="https://doi.org/10.1145/3488378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although machine learning (ML) algorithms have been widely used in forecasting the trend of stock market indices, they failed to consider the following crucial aspects for market forecasting: (1) that investors’ emotions and attitudes toward future market trends have material impacts on market trend forecasting (2) the length of past market data should be dynamically adjusted according to the market status and (3) the transition of market statutes should be considered when forecasting market trends. In this study, we proposed an innovative ML method to forecast China&#39;s stock market trends by addressing the three issues above. Specifically, sentimental factors (see Appendix [1] for full trans) were first collected to measure investors’ emotions and attitudes. Then, a non-stationary Markov chain (NMC) model was used to capture dynamic transitions of market statutes. We choose the state-of-the-art (SOTA) method, namely, Bidirectional Encoder Representations from Transformers ( BERT ), to predict the state of the market at time t , and a long short-term memory ( LSTM ) model was used to estimate the varying length of past market data in market trend prediction, where the input of LSTM (the state of the market at time t ) was the output of BERT and probabilities for opening and closing of the gates in the LSTM model were based on outputs of the NMC model. Finally, the optimum parameters of the proposed algorithm were calculated using a reinforced learning-based deep Q-Network. Compared to existing forecasting methods, the proposed algorithm achieves better results with a forecasting accuracy of 61.77%, annualized return of 29.25%, and maximum losses of −8.29%. Furthermore, the proposed model achieved the lowest forecasting error: mean square error (0.095), root mean square error (0.0739), mean absolute error (0.104), and mean absolute percent error (15.1%). As a result, the proposed market forecasting model can help investors obtain more accurate market forecast information.},
  archive      = {J_TKDD},
  doi          = {10.1145/3488378},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Forecasting the market with machine learning algorithms: An application of NMC-BERT-LSTM-DQN-X algorithm in quantitative trading},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RHPTree—risk hierarchical pattern tree for scalable long
pattern mining. <em>TKDD</em>, <em>16</em>(4), 1–33. (<a
href="https://doi.org/10.1145/3488380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Risk patterns are crucial in biomedical research and have served as an important factor in precision health and disease prevention. Despite recent development in parallel and high-performance computing, existing risk pattern mining methods still struggle with problems caused by large-scale datasets, such as redundant candidate generation, inability to discover long significant patterns, and prolonged post pattern filtering. In this article, we propose a novel dynamic tree structure, Risk Hierarchical Pattern Tree (RHPTree), and a top-down search method, RHPSearch, which are capable of efficiently analyzing a large volume of data and overcoming the limitations of previous works. The dynamic nature of the RHPTree avoids costly tree reconstruction for the iterative search process and dataset updates. We also introduce two specialized search methods, the extended target search (RHPSearch-TS) and the parallel search approach (RHPSearch-SD), to further speed up the retrieval of certain items of interest. Experiments on both UCI machine learning datasets and sampled datasets of the Simons Foundation Autism Research Initiative (SFARI)—Simon’s Simplex Collection (SSC) datasets demonstrate that our method is not only faster but also more effective in identifying comprehensive long risk patterns than existing works. Moreover, the proposed new tree structure is generic and applicable to other pattern mining problems.},
  archive      = {J_TKDD},
  doi          = {10.1145/3488380},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-33},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {RHPTree—Risk hierarchical pattern tree for scalable long pattern mining},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A trajectory evaluator by sub-tracks for detecting VOT-based
anomalous trajectory. <em>TKDD</em>, <em>16</em>(4), 1–19. (<a
href="https://doi.org/10.1145/3490032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularization of visual object tracking (VOT), more and more trajectory data are obtained and have begun to gain widespread attention in the fields of mobile robots, intelligent video surveillance, and the like. How to clean the anomalous trajectories hidden in the massive data has become one of the research hotspots. Anomalous trajectories should be detected and cleaned before the trajectory data can be effectively used. In this article, a Trajectory Evaluator by Sub-tracks (TES) for detecting VOT-based anomalous trajectory is proposed. Feature of Anomalousness is defined and described as the Eigenvector of classifier to filter Track Lets anomalous trajectory and IDentity Switch anomalous trajectory, which includes Feature of Anomalous Pose and Feature of Anomalous Sub-tracks (FAS). In the comparative experiments, TES achieves better results on different scenes than state-of-the-art methods. Moreover, FAS makes better performance than point flow, least square method fitting and Chebyshev Polynomial Fitting. It is verified that TES is more accurate and effective and is conducive to the sub-tracks trajectory data analysis.},
  archive      = {J_TKDD},
  doi          = {10.1145/3490032},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A trajectory evaluator by sub-tracks for detecting VOT-based anomalous trajectory},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A self-supervised representation learning of sentence
structure for authorship attribution. <em>TKDD</em>, <em>16</em>(4),
1–16. (<a href="https://doi.org/10.1145/3491203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The syntactic structure of sentences in a document substantially informs about its authorial writing style. Sentence representation learning has been widely explored in recent years and it has been shown that it improves the generalization of different downstream tasks across many domains. Even though utilizing probing methods in several studies suggests that these learned contextual representations implicitly encode some amount of syntax, explicit syntactic information further improves the performance of deep neural models in the domain of authorship attribution. These observations have motivated us to investigate the explicit representation learning of syntactic structure of sentences. In this article, we propose a self-supervised framework for learning structural representations of sentences. The self-supervised network contains two components; a lexical sub-network and a syntactic sub-network which take the sequence of words and their corresponding structural labels as the input, respectively. Due to the n -to-1 mapping of words to their structural labels, each word will be embedded into a vector representation which mainly carries structural information. We evaluate the learned structural representations of sentences using different probing tasks, and subsequently utilize them in the authorship attribution task. Our experimental results indicate that the structural embeddings significantly improve the classification tasks when concatenated with the existing pre-trained word embeddings.},
  archive      = {J_TKDD},
  doi          = {10.1145/3491203},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A self-supervised representation learning of sentence structure for authorship attribution},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Privacy-preserving mechanisms for multi-label image
recognition. <em>TKDD</em>, <em>16</em>(4), 1–21. (<a
href="https://doi.org/10.1145/3491231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label image recognition has been an indispensable fundamental component for many real computer vision applications. However, a severe threat of privacy leakage in multi-label image recognition has been overlooked by existing studies. To fill this gap, two privacy-preserving models, Privacy-Preserving Multi-label Graph Convolutional Networks (P2-ML-GCN) and Robust P2-ML-GCN (RP2-ML-GCN), are developed in this article, where differential privacy mechanism is implemented on the model’s outputs so as to defend black-box attack and avoid large aggregated noise simultaneously. In particular, a regularization term is exploited in the loss function of RP2-ML-GCN to increase the model prediction accuracy and robustness. After that, a proper differential privacy mechanism is designed with the intention of decreasing the bias of loss function in P2-ML-GCN and increasing prediction accuracy. Besides, we analyze that a bounded global sensitivity can mitigate excessive noise’s side effect and obtain a performance improvement for multi-label image recognition in our models. Theoretical proof shows that our two models can guarantee differential privacy for model’s outputs, weights and input features while preserving model robustness. Finally, comprehensive experiments are conducted to validate the advantages of our proposed models, including the implementation of differential privacy on model’s outputs, the incorporation of regularization term into loss function, and the adoption of bounded global sensitivity for multi-label image recognition.},
  archive      = {J_TKDD},
  doi          = {10.1145/3491231},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Privacy-preserving mechanisms for multi-label image recognition},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiple graphs and low-rank embedding for multi-source
heterogeneous domain adaptation. <em>TKDD</em>, <em>16</em>(4), 1–25.
(<a href="https://doi.org/10.1145/3492804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-source domain adaptation is a challenging topic in transfer learning, especially when the data of each domain are represented by different kinds of features, i.e., Multi-source Heterogeneous Domain Adaptation (MHDA). It is important to take advantage of the knowledge extracted from multiple sources as well as bridge the heterogeneous spaces for handling the MHDA paradigm. This article proposes a novel method named Multiple Graphs and Low-rank Embedding (MGLE), which models the local structure information of multiple domains using multiple graphs and learns the low-rank embedding of the target domain. Then, MGLE augments the learned embedding with the original target data. Specifically, we introduce the modules of both domain discrepancy and domain relevance into the multiple graphs and low-rank embedding learning procedure. Subsequently, we develop an iterative optimization algorithm to solve the resulting problem. We evaluate the effectiveness of the proposed method on several real-world datasets. Promising results show that the performance of MGLE is better than that of the baseline methods in terms of several metrics, such as AUC, MAE, accuracy, precision, F1 score, and MCC, demonstrating the effectiveness of the proposed method.},
  archive      = {J_TKDD},
  doi          = {10.1145/3492804},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Multiple graphs and low-rank embedding for multi-source heterogeneous domain adaptation},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ABLE: Meta-path prediction in heterogeneous information
networks. <em>TKDD</em>, <em>16</em>(4), 1–21. (<a
href="https://doi.org/10.1145/3494558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a heterogeneous information network (HIN) H, a head node h , a meta-path P, and a tail node t , the meta-path prediction aims at predicting whether h can be linked to t by an instance of P. Most existing solutions either require predefined meta-paths, which limits their scalability to schema-rich HINs and long meta-paths, or do not aim at predicting the existence of an instance of P. To address these issues, in this article, we propose a novel prediction model, called ABLE, by exploiting the A ttention mechanism and B i L STM for E mbedding. Particularly, we present a concatenation node embedding method by considering the node types and a dynamic meta-path embedding method that carefully considers the importance and positions of edge types in the meta-paths by the Attention mechanism and BiLSTM model, respectively. A triplet embedding is then derived to complete the prediction. We conduct extensive experiments on four real datasets. The empirical results show that ABLE outperforms the state-of-the-art methods by up to 20% and 22% of improvement of AUC and AP scores, respectively.},
  archive      = {J_TKDD},
  doi          = {10.1145/3494558},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {ABLE: Meta-path prediction in heterogeneous information networks},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive model scheduling for resource-efficient data
labeling. <em>TKDD</em>, <em>16</em>(4), 1–22. (<a
href="https://doi.org/10.1145/3494559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Labeling data (e.g., labeling the people, objects, actions, and scene in images) comprehensively and efficiently is a widely needed but challenging task. Numerous models were proposed to label various data and many approaches were designed to enhance the ability of deep learning models or accelerate them. Unfortunately, a single machine-learning model is not powerful enough to extract various semantic information from data. Given certain applications, such as image retrieval platforms and photo album management apps, it is often required to execute a collection of models to obtain sufficient labels. With limited computing resources and stringent delay, given a data stream and a collection of applicable resource-hungry deep-learning models, we design a novel approach to adaptively schedule a subset of these models to execute on each data item, aiming to maximize the value of the model output (e.g., the number of high-confidence labels). Achieving this lofty goal is nontrivial since a model’s output on any data item is content-dependent and unknown until we execute it. To tackle this, we propose an Adaptive Model Scheduling framework, consisting of (1) a deep reinforcement learning-based approach to predict the value of unexecuted models by mining semantic relationship among diverse models, and (2) two heuristic algorithms to adaptively schedule the model execution order under a deadline or deadline-memory constraints, respectively. The proposed framework does not require any prior knowledge of the data, which works as a powerful complement to existing model optimization technologies. We conduct extensive evaluations on five diverse image datasets and 30 popular image labeling models to demonstrate the effectiveness of our design: our design could save around 53% execution time without loss of any valuable labels.},
  archive      = {J_TKDD},
  doi          = {10.1145/3494559},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Adaptive model scheduling for resource-efficient data labeling},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain-specific keyword extraction using joint modeling of
local and global contextual semantics. <em>TKDD</em>, <em>16</em>(4),
1–30. (<a href="https://doi.org/10.1145/3494560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain-specific keyword extraction is a vital task in the field of text mining. There are various research tasks, such as spam e-mail classification, abusive language detection, sentiment analysis, and emotion mining, where a set of domain-specific keywords (aka lexicon) is highly effective. Existing works for keyword extraction list all keywords rather than domain-specific keywords from a document corpus. Moreover, most of the existing approaches perform well on formal document corpuses but fail on noisy and informal user-generated content in online social media. In this article, we present a hybrid approach by jointly modeling the local and global contextual semantics of words, utilizing the strength of distributional word representation and contrasting-domain corpus for domain-specific keyword extraction. Starting with a seed set of a few domain-specific keywords, we model the text corpus as a weighted word-graph. In this graph, the initial weight of a node (word) represents its semantic association with the target domain calculated as a linear combination of three semantic association metrics, and the weight of an edge connecting a pair of nodes represents the co-occurrence count of the respective words. Thereafter, a modified PageRank method is applied to the word-graph to identify the most relevant words for expanding the initial set of domain-specific keywords. We evaluate our method over both formal and informal text corpuses (comprising six datasets), and show that it performs significantly better in comparison to state-of-the-art methods. Furthermore, we generalize our approach to handle the language-agnostic case, and show that it outperforms existing language-agnostic approaches.},
  archive      = {J_TKDD},
  doi          = {10.1145/3494560},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-30},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Domain-specific keyword extraction using joint modeling of local and global contextual semantics},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed triangle approximately counting algorithms in
simple graph stream. <em>TKDD</em>, <em>16</em>(4), 1–43. (<a
href="https://doi.org/10.1145/3494562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the counting algorithm of local topology structures, such as triangles, has been widely used in social network analysis, recommendation systems, user portraits and other fields. At present, the problem of counting global and local triangles in a graph stream has been widely studied, and numerous triangle counting steaming algorithms have emerged. To improve the throughput and scalability of streaming algorithms, many researches of distributed streaming algorithms on multiple machines are studied. In this article, we first propose a framework of distributed streaming algorithm based on the Master-Worker-Aggregator architecture. The two core parts of this framework are an edge distribution strategy, which plays a key role to affect the performance, including the communication overhead and workload balance, and aggregation method, which is critical to obtain the unbiased estimations of the global and local triangle counts in a graph stream. Then, we extend the state-of-the-art centralized algorithm TRIÈST into four distributed algorithms under our framework. Compared to their competitors, experimental results show that DVHT-i is excellent in accuracy and speed, performing better than the best existing distributed streaming algorithm. DEHT-b is the fastest algorithm and has the least communication overhead. What’s more, it almost achieves absolute workload balance.},
  archive      = {J_TKDD},
  doi          = {10.1145/3494562},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-43},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Distributed triangle approximately counting algorithms in simple graph stream},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). When less is more: Systematic analysis of cascade-based
community detection. <em>TKDD</em>, <em>16</em>(4), 1–22. (<a
href="https://doi.org/10.1145/3494563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information diffusion, spreading of infectious diseases, and spreading of rumors are fundamental processes occurring in real-life networks. In many practical cases, one can observe when nodes become infected, but the underlying network, over which a contagion or information propagates, is hidden. Inferring properties of the underlying network is important since these properties can be used for constraining infections, forecasting, viral marketing, and so on. Moreover, for many applications, it is sufficient to recover only coarse high-level properties of this network rather than all its edges. This article conducts a systematic and extensive analysis of the following problem: Given only the infection times, find communities of highly interconnected nodes. This task significantly differs from the well-studied community detection problem since we do not observe a graph to be clustered. We carry out a thorough comparison between existing and new approaches on several large datasets and cover methodological challenges specific to this problem. One of the main conclusions is that the most stable performance and the most significant improvement on the current state-of-the-art are achieved by our proposed simple heuristic approaches agnostic to a particular graph structure and epidemic model. We also show that some well-known community detection algorithms can be enhanced by including edge weights based on the cascade data.},
  archive      = {J_TKDD},
  doi          = {10.1145/3494563},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {When less is more: Systematic analysis of cascade-based community detection},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time anomaly detection in edge streams. <em>TKDD</em>,
<em>16</em>(4), 1–22. (<a
href="https://doi.org/10.1145/3494564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a stream of graph edges from a dynamic graph, how can we assign anomaly scores to edges in an online manner, for the purpose of detecting unusual behavior, using constant time and memory? Existing approaches aim to detect individually surprising edges. In this work, we propose Midas , which focuses on detecting microcluster anomalies , or suddenly arriving groups of suspiciously similar edges, such as lockstep behavior, including denial of service attacks in network traffic data. We further propose Midas -F, to solve the problem by which anomalies are incorporated into the algorithm’s internal states, creating a “poisoning” effect that can allow future anomalies to slip through undetected. Midas -F introduces two modifications: (1) we modify the anomaly scoring function, aiming to reduce the “poisoning” effect of newly arriving edges; (2) we introduce a conditional merge step, which updates the algorithm’s data structures after each time tick, but only if the anomaly score is below a threshold value, also to reduce the “poisoning” effect. Experiments show that Midas -F has significantly higher accuracy than Midas . In general, the algorithms proposed in this work have the following properties: (a) they detects microcluster anomalies while providing theoretical guarantees about the false positive probability; (b) they are online, thus processing each edge in constant time and constant memory, and also processes the data orders-of-magnitude faster than state-of-the-art approaches; and (c) they provides up to 62% higher area under the receiver operating characteristic curve than state-of-the-art approaches.},
  archive      = {J_TKDD},
  doi          = {10.1145/3494564},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Real-time anomaly detection in edge streams},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Disambiguation enabled linear discriminant analysis for
partial label dimensionality reduction. <em>TKDD</em>, <em>16</em>(4),
1–18. (<a href="https://doi.org/10.1145/3494565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging weakly supervised learning framework, partial label learning considers inaccurate supervision where each training example is associated with multiple candidate labels among which only one is valid. In this article, a first attempt toward employing dimensionality reduction to help improve the generalization performance of partial label learning system is investigated. Specifically, the popular linear discriminant analysis (LDA) techniques are endowed with the ability of dealing with partial label training examples. To tackle the challenge of unknown ground-truth labeling information, a novel learning approach named Delin is proposed which alternates between LDA dimensionality reduction and candidate label disambiguation based on estimated labeling confidences over candidate labels. On one hand, the (kernelized) projection matrix of LDA is optimized by utilizing disambiguation-guided labeling confidences. On the other hand, the labeling confidences are disambiguated by resorting to k NN aggregation in the LDA-induced feature space. Extensive experiments over a broad range of partial label datasets clearly validate the effectiveness of Delin in improving the generalization performance of well-established partial label learning algorithms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3494565},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Disambiguation enabled linear discriminant analysis for partial label dimensionality reduction},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hypergraph convolution on nodes-hyperedges network for
semi-supervised node classification. <em>TKDD</em>, <em>16</em>(4),
1–19. (<a href="https://doi.org/10.1145/3494567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraphs have shown great power in representing high-order relations among entities, and lots of hypergraph-based deep learning methods have been proposed to learn informative data representations for the node classification problem. However, most of these deep learning approaches do not take full consideration of either the hyperedge information or the original relationships among nodes and hyperedges. In this article, we present a simple yet effective semi-supervised node classification method named Hypergraph Convolution on Nodes-Hyperedges network, which performs filtering on both nodes and hyperedges as well as recovers the original hypergraph with the least information loss. Instead of only reducing the cross-entropy loss over the labeled samples as most previous approaches do, we additionally consider the hypergraph reconstruction loss as prior information to improve prediction accuracy. As a result, by taking both the cross-entropy loss on the labeled samples and the hypergraph reconstruction loss into consideration, we are able to achieve discriminative latent data representations for training a classifier. We perform extensive experiments on the semi-supervised node classification problem and compare the proposed method with state-of-the-art algorithms. The promising results demonstrate the effectiveness of the proposed method.},
  archive      = {J_TKDD},
  doi          = {10.1145/3494567},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Hypergraph convolution on nodes-hyperedges network for semi-supervised node classification},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Auto IV: Counterfactual prediction via automatic
instrumental variable decomposition. <em>TKDD</em>, <em>16</em>(4),
1–20. (<a href="https://doi.org/10.1145/3494568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instrumental variables (IVs), sources of treatment randomization that are conditionally independent of the outcome, play an important role in causal inference with unobserved confounders. However, the existing IV-based counterfactual prediction methods need well-predefined IVs, while it’s an art rather than science to find valid IVs in many real-world scenes. Moreover, the predefined hand-made IVs could be weak or erroneous by violating the conditions of valid IVs. These thorny facts hinder the application of the IV-based counterfactual prediction methods. In this article, we propose a novel Automatic Instrumental Variable decomposition (AutoIV) algorithm to automatically generate representations serving the role of IVs from observed variables (IV candidates). Specifically, we let the learned IV representations satisfy the relevance condition with the treatment and exclusion condition with the outcome via mutual information maximization and minimization constraints, respectively. We also learn confounder representations by encouraging them to be relevant to both the treatment and the outcome. The IV and confounder representations compete for the information with their constraints in an adversarial game, which allows us to get valid IV representations for IV-based counterfactual prediction. Extensive experiments demonstrate that our method generates valid IV representations for accurate IV-based counterfactual prediction.},
  archive      = {J_TKDD},
  doi          = {10.1145/3494568},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Auto IV: Counterfactual prediction via automatic instrumental variable decomposition},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SGrapp: Butterfly approximation in streaming graphs.
<em>TKDD</em>, <em>16</em>(4), 1–43. (<a
href="https://doi.org/10.1145/3495011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the fundamental problem of butterfly (i.e., (2,2)-bicliques) counting in bipartite streaming graphs. Similar to triangles in unipartite graphs, enumerating butterflies is crucial in understanding the structure of bipartite graphs. This benefits many applications where studying the cohesion in a graph shaped data is of particular interest. Examples include investigating the structure of computational graphs or input graphs to the algorithms, as well as dynamic phenomena and analytic tasks over complex real graphs. Butterfly counting is computationally expensive, and known techniques do not scale to large graphs; the problem is even harder in streaming graphs. In this article, following a data-driven methodology, we first conduct an empirical analysis to uncover temporal organizing principles of butterflies in real streaming graphs and then we introduce an approximate adaptive window-based algorithm, sGrapp, for counting butterflies as well as its optimized version sGrapp-x. sGrapp is designed to operate efficiently and effectively over any graph stream with any temporal behavior. Experimental studies of sGrapp and sGrapp-x show superior performance in terms of both accuracy and efficiency.},
  archive      = {J_TKDD},
  doi          = {10.1145/3495011},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {4},
  pages        = {1-43},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {SGrapp: Butterfly approximation in streaming graphs},
  volume       = {16},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
